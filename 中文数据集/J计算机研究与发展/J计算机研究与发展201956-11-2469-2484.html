

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127119701707500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJFYZ201911016%26RESULT%3d1%26SIGN%3dx0X2MdHjgEafS3xdooJw5R0mnvc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201911016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201911016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201911016&amp;v=MzA1OTh2Skx5dlNkTEc0SDlqTnJvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="&lt;b&gt;2 弹性运动模型及其高斯-牛顿求解方法&lt;/b&gt; "><b>2 弹性运动模型及其高斯-牛顿求解方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title="&lt;b&gt;2.1 弹性运动模型的基本定义&lt;/b&gt;"><b>2.1 弹性运动模型的基本定义</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;2.2 弹性运动模型的高斯-牛顿解法&lt;/b&gt;"><b>2.2 弹性运动模型的高斯-牛顿解法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;3 基于Prewitt梯度算子的2 b变换&lt;/b&gt; "><b>3 基于Prewitt梯度算子的2 b变换</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#111" data-title="&lt;b&gt;3.1 本文的2 b变换算法&lt;/b&gt;"><b>3.1 本文的2 b变换算法</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;3.2 2 b深度像素的匹配误差曲面的特点&lt;/b&gt;"><b>3.2 2 b深度像素的匹配误差曲面的特点</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="&lt;b&gt;4 低位深度的弹性运动模型&lt;/b&gt; "><b>4 低位深度的弹性运动模型</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#146" data-title="&lt;b&gt;5 迭代步长的自适应计算&lt;/b&gt; "><b>5 迭代步长的自适应计算</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#171" data-title="&lt;b&gt;6 2 b深度像素的弹性运动估计步骤&lt;/b&gt; "><b>6 2 b深度像素的弹性运动估计步骤</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#174" data-title="&lt;b&gt;7 实验结果与分析&lt;/b&gt; "><b>7 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#178" data-title="&lt;b&gt;7.1 运动估计/补偿质量的比较&lt;/b&gt;"><b>7.1 运动估计/补偿质量的比较</b></a></li>
                                                <li><a href="#184" data-title="&lt;b&gt;7.2 收敛速度与迭代次数的讨论&lt;/b&gt;"><b>7.2 收敛速度与迭代次数的讨论</b></a></li>
                                                <li><a href="#188" data-title="&lt;b&gt;7.3 计算复杂度分析&lt;/b&gt;"><b>7.3 计算复杂度分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#197" data-title="&lt;b&gt;8 结 论&lt;/b&gt; "><b>8 结 论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#108" data-title="图1 基于高斯-牛顿法的弹性运动估计流程图">图1 基于高斯-牛顿法的弹性运动估计流程图</a></li>
                                                <li><a href="#117" data-title="图2 本文提出的2 b变换流程图">图2 本文提出的2 b变换流程图</a></li>
                                                <li><a href="#119" data-title="图3 不同的2 b变换方法的效果对比">图3 不同的2 b变换方法的效果对比</a></li>
                                                <li><a href="#123" data-title="图4 8 b全搜索与2 b全搜索的匹配误差曲面比较">图4 8 b全搜索与2 b全搜索的匹配误差曲面比较</a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表1 8 b乘法运算的符号表&lt;/b&gt;"><b>表1 8 b乘法运算的符号表</b></a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;表2 1 b异或运算的真值表&lt;/b&gt;"><b>表2 1 b异或运算的真值表</b></a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表3 改进的异或运算真值表&lt;/b&gt;"><b>表3 改进的异或运算真值表</b></a></li>
                                                <li><a href="#150" data-title="图5 不同初始步长&lt;i&gt;s&lt;/i&gt;下的运动补偿PSNR对比">图5 不同初始步长<i>s</i>下的运动补偿PSNR对比</a></li>
                                                <li><a href="#173" data-title="图6 本文提出的2 b弹性运动估计流程图">图6 本文提出的2 b弹性运动估计流程图</a></li>
                                                <li><a href="#177" data-title="&lt;b&gt;表4 测试视频序列名称及其格式&lt;/b&gt;"><b>表4 测试视频序列名称及其格式</b></a></li>
                                                <li><a href="#181" data-title="&lt;b&gt;表5 运动补偿的PSNR 比较&lt;/b&gt;"><b>表5 运动补偿的PSNR 比较</b></a></li>
                                                <li><a href="#182" data-title="图7 Akiyo,Husky,City,Flowervase的前90帧采用不同运动估计算法所得到的PSNR比较">图7 Akiyo,Husky,City,Flowervase的前90帧采用不同运动估计算法所得到的P......</a></li>
                                                <li><a href="#186" data-title="图8 Akiyo,Husky,City的第2帧的前15次迭代结果">图8 Akiyo,Husky,City的第2帧的前15次迭代结果</a></li>
                                                <li><a href="#196" data-title="&lt;b&gt;表6 不同运动估计算法对每个块的平均操作次数比较&lt;/b&gt;"><b>表6 不同运动估计算法对每个块的平均操作次数比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="275">


                                    <a id="bibliography_1" title="Ma Siwei.History and recent development of AVS video coding standards[J].Journal of Computer Research and Development,2015,52(1):27- 37 (in Chinese)(马思伟.AVS视频编码标准技术回顾及最新进展[J].计算机研究与发展,2015,52(1):27- 37)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201501004&amp;v=MTU5OTh0R0ZyQ1VSTE9lWmVSc0Z5em5VTHZKTHl2U2RMRzRIOVRNcm85RllJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Ma Siwei.History and recent development of AVS video coding standards[J].Journal of Computer Research and Development,2015,52(1):27- 37 (in Chinese)(马思伟.AVS视频编码标准技术回顾及最新进展[J].计算机研究与发展,2015,52(1):27- 37)
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                    Sinangil M E,Sze V,Zhou Minhua,et al.Cost and coding efficient motion estimation design considerations for high efficiency video coding (HEVC) standard[J].IEEE Journal of Selected Topics in Signal Processing,2013,7(6):1017- 1028</a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                    Narroschke M,Swoboda R.Extending HEVC by an affine motion model[C] //Proc of the 30th PCS.Piscataway,NJ:IEEE,2013:321- 324</a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_4" >
                                        <b>[4]</b>
                                    Ahmmed A,Hannuksela M M,Gabbouj M.Fisheye video coding using elastic motion compensated reference frames[C] //Proc of the 23rd IEEE ICIP.Piscataway,NJ:IEEE,2016:2027- 2031</a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                    Liu Dong,Wu Feng.Advances and trends of video coding technologies[J].Communications of the CCF,2016,12(6):20- 23 (in Chinese)(刘东,吴枫.视频编码技术发展与趋势[J].中国计算机学会通讯,2016,12(6):20- 23)</a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                    Ahmmed A,Xu Rui,Naman A T,et al.Motion segmentation initialization strategies for bi-directional inter-frame prediction[C] //Proc of the 15th IEEE MMSP.Piscataway,NJ:IEEE,2013:58- 63</a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_7" title="Wu Feng,Gao Peng,Gao Wen.Motion estimation technologies based on mesh model[J].Acta Electronica Sinica,2000,28(5):47- 51 (in Chinese)(吴枫,高鹏,高文.基于网格模型的运动估计技术[J].电子学报,2000,28(5):47- 51)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200005014&amp;v=MTMyOTZxQnRHRnJDVVJMT2VaZVJzRnl6blVMdkpJVGZUZTdHNEh0SE1xbzlFWUlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        Wu Feng,Gao Peng,Gao Wen.Motion estimation technologies based on mesh model[J].Acta Electronica Sinica,2000,28(5):47- 51 (in Chinese)(吴枫,高鹏,高文.基于网格模型的运动估计技术[J].电子学报,2000,28(5):47- 51)
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                    Al-Regib G,Altunbasak Y,Mersereau R M.Hierarchical motion estimation with content-based meshes[J].IEEE Transactions on Circuits and System for Video Technology,2003,13(10):1000- 1005</a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_9" title="Cui Suxia,Wang Yonghui,Fowler J E.Motion estimation and compensation in the redundant-wavelet domain using triangle meshes[J].Signal Processing:Image Communication,2006,21(7):586- 598" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501985863&amp;v=MDgzMTRNS0JIbzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMM0lKRndYYmhNPU5pZk9mYks3SHRETnFvOUViZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Cui Suxia,Wang Yonghui,Fowler J E.Motion estimation and compensation in the redundant-wavelet domain using triangle meshes[J].Signal Processing:Image Communication,2006,21(7):586- 598
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                    Huang Han,Woods J W,Zhao Yao,et al.Control-point representation and differential coding affine-motion compensation[J].IEEE Transactions on Circuits and Systems for Video Technology,2013,23(10):1651- 1660</a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                    Li Li,Li Houqiang,Liu Dong,et al.An efficient four-parameter affine motion model for video coding[J].IEEE Transactions on Circuits and Systems for Video Technology,2018,28(8):1934- 1947</a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_12" title="Zheng Jiali,Qin Tuanfa,Ni Guangnan.Adaptive global motion estimation method based on rate distortion optimization[J].Journal of Image and Graphics,2011,16(8):1346- 1352 (in Chinese)(郑嘉利,覃团发,倪光南.结合率失真优化的自适应全局运动估计方法[J].中国图象图形学报,2011,16(8):1346- 1352)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201108001&amp;v=MTIzOTE0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUx2SlB5cmZiTEc0SDlETXA0OUZaWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Zheng Jiali,Qin Tuanfa,Ni Guangnan.Adaptive global motion estimation method based on rate distortion optimization[J].Journal of Image and Graphics,2011,16(8):1346- 1352 (in Chinese)(郑嘉利,覃团发,倪光南.结合率失真优化的自适应全局运动估计方法[J].中国图象图形学报,2011,16(8):1346- 1352)
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                    Po L M,Wong K M,Cheung K W,et al.Subsampled block-matching for zoom motion compensated prediction[J].IEEE Transactions on Circuits and Systems for Video Technology,2010,20(11):1625- 1637</a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                    Yuan Hui,Liu Ju,Sun Jiande,et al.Affine model based motion compensation prediction for zoom[J].IEEE Transactions on Multimedia,2012,14(4):1370- 1375</a>
                                </li>
                                <li id="303">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                    Kim H S,Lee J H,Kim C K,et al.Zoom motion estimation using block-based fast local area scaling[J].IEEE Transactions on Circuits and Systems for Video Technology,2012,22(9):1280- 1291</a>
                                </li>
                                <li id="305">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                    Muhit A A,Pickering M R,Frater M R,et al.Video coding using elastic motion model and larger blocks[J].IEEE Transactions on Circuits and Systems for Video Technology,2010,20(5):661- 672</a>
                                </li>
                                <li id="307">


                                    <a id="bibliography_17" title="Muhit A A,Pickering M R,Frater M R,et al.Video coding using fast geometry-adaptive partitioning and an elastic motion model[J].Journal of Visual Communication and Image Representation,2012,23(1):31- 41" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501263353&amp;v=MDI5MjROaWZPZmJLN0h0RE5xbzlFWnUwTUQzazZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMM0lKRndYYmhNPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        Muhit A A,Pickering M R,Frater M R,et al.Video coding using fast geometry-adaptive partitioning and an elastic motion model[J].Journal of Visual Communication and Image Representation,2012,23(1):31- 41
                                    </a>
                                </li>
                                <li id="309">


                                    <a id="bibliography_18" title="Deng Binyou.Study on video compression based on elastic motion model[D].Xiamen:Xiamen University,2014 (in Chinese)(邓斌攸.基于弹性运动模型的视频压缩算法研究[D].厦门:厦门大学,2014)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014223317.nh&amp;v=MzA2MzVxcUJ0R0ZyQ1VSTE9lWmVSc0Z5em5VTHZKVkYyNkdyRzZIZExOcUpFYlBJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        Deng Binyou.Study on video compression based on elastic motion model[D].Xiamen:Xiamen University,2014 (in Chinese)(邓斌攸.基于弹性运动模型的视频压缩算法研究[D].厦门:厦门大学,2014)
                                    </a>
                                </li>
                                <li id="311">


                                    <a id="bibliography_19" title="Song Chuanming,Zhao Changwei,Liu Dan,et al.Elastic motion estimation of video using improved Gauss-Newton method[J].Journal of Software,2016,27(11):2946- 2960 (in Chinese)(宋传鸣,赵长伟,刘丹,等.采用改进高斯-牛顿法的视频弹性运动估计[J].软件学报,2016,27(11):2946- 2960)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201611018&amp;v=MDg2OTVuVUx2Sk55ZlRiTEc0SDlmTnJvOUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Song Chuanming,Zhao Changwei,Liu Dan,et al.Elastic motion estimation of video using improved Gauss-Newton method[J].Journal of Software,2016,27(11):2946- 2960 (in Chinese)(宋传鸣,赵长伟,刘丹,等.采用改进高斯-牛顿法的视频弹性运动估计[J].软件学报,2016,27(11):2946- 2960)
                                    </a>
                                </li>
                                <li id="313">


                                    <a id="bibliography_20" title="Zhao Changwei.Research on motion estimation algorithm using elastic model[D].Dalian:Liaoning Normal University,2015 (in Chinese)(赵长伟.基于弹性模型的运动估计算法研究[D].大连:辽宁师范大学,2015)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015637459.nh&amp;v=MjQ4NzMzenFxQnRHRnJDVVJMT2VaZVJzRnl6blVMdkpWRjI2RzdXN0dkWEpwcEViUElRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        Zhao Changwei.Research on motion estimation algorithm using elastic model[D].Dalian:Liaoning Normal University,2015 (in Chinese)(赵长伟.基于弹性模型的运动估计算法研究[D].大连:辽宁师范大学,2015)
                                    </a>
                                </li>
                                <li id="315">


                                    <a id="bibliography_21" >
                                        <b>[21]</b>
                                    Huang Han.Research on inter/intra prediction and optimization techniques in HEVC[D].Beijing:Beijing Jiaotong University,2013 (in Chinese)(黄晗.HEVC帧间/帧内预测及优化技术研究[D].北京:北京交通大学,2013)</a>
                                </li>
                                <li id="317">


                                    <a id="bibliography_22" title="Song Chuanming,Min Xin,Yan Xiaohong,et al.Fast elastic motion estimation using improved Levenberg-Marquardt method[J/OL].Journal of Software,2019.[2019-02-09].http://www.jos.org.cn/1000-9825/5487.htm (in Chinese)(宋传鸣,闵新,闫小红,等.采用改进Levenberg-Marquardt法的快速弹性运动估计[J/OL].软件学报,2019.[2019-02-09].http://www.jos.org.cn/1000-9825/5487.htm)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201907019&amp;v=MDE5ODc0SDlqTXFJOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUx2Sk55ZlRiTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        Song Chuanming,Min Xin,Yan Xiaohong,et al.Fast elastic motion estimation using improved Levenberg-Marquardt method[J/OL].Journal of Software,2019.[2019-02-09].http://www.jos.org.cn/1000-9825/5487.htm (in Chinese)(宋传鸣,闵新,闫小红,等.采用改进Levenberg-Marquardt法的快速弹性运动估计[J/OL].软件学报,2019.[2019-02-09].http://www.jos.org.cn/1000-9825/5487.htm)
                                    </a>
                                </li>
                                <li id="319">


                                    <a id="bibliography_23" >
                                        <b>[23]</b>
                                    Haque M N,Biswas M,Pickering M R,et al.A low complexity algorithm for global motion parameter estimation targeting hardware implementation[C] //Proc of the 11th DICTA.Piscataway,NJ:IEEE,2009:1- 5</a>
                                </li>
                                <li id="321">


                                    <a id="bibliography_24" >
                                        <b>[24]</b>
                                    Haque M N,Biswas M,Pickering M R,et al.An adaptive low-complexity global motion estimation algorithm[C] //Proc of the 27th PCS.Piscataway,NJ:IEEE,2010:598- 601</a>
                                </li>
                                <li id="323">


                                    <a id="bibliography_25" >
                                        <b>[25]</b>
                                    Haque M N,Biswas M,Pickering M R,et al.A low-complexity image registration algorithm for global motion estimation[J].IEEE Transactions on Circuits and Systems for Video Technology,2012,22(3):426- 433</a>
                                </li>
                                <li id="325">


                                    <a id="bibliography_26" title="Song Chuanming,Guo Yanwen,Wang Xianghai,et al.Fuzzy quantization based bit transform for low bit-resolution motion estimation[J].Signal Processing:Image Communication,2013,28(10):1435- 1447" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600363711&amp;v=MTk0NzRNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTDNJSkZ3WGJoTT1OaWZPZmJLOEh0RE1xWTlGWiswTUMzMDRvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                        Song Chuanming,Guo Yanwen,Wang Xianghai,et al.Fuzzy quantization based bit transform for low bit-resolution motion estimation[J].Signal Processing:Image Communication,2013,28(10):1435- 1447
                                    </a>
                                </li>
                                <li id="327">


                                    <a id="bibliography_27" title="Song Chuanming,Guo Yanwen,Wang Xianghai,et al.Motion estimation algorithm using 2 bit-depth pixel and fuzzy quantization[J].Journal on Communications,2013,34(7):59- 70 (in Chinese)(宋传鸣,郭延文,王相海,等.基于模糊量化和2 bit深度像素的运动估计算法[J].通信学报,2013,34(7):59- 70)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201307006&amp;v=MjY4MTdMdkpNVFhUYkxHNEg5TE1xSTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJzRnl6blU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[27]</b>
                                        Song Chuanming,Guo Yanwen,Wang Xianghai,et al.Motion estimation algorithm using 2 bit-depth pixel and fuzzy quantization[J].Journal on Communications,2013,34(7):59- 70 (in Chinese)(宋传鸣,郭延文,王相海,等.基于模糊量化和2 bit深度像素的运动估计算法[J].通信学报,2013,34(7):59- 70)
                                    </a>
                                </li>
                                <li id="329">


                                    <a id="bibliography_28" >
                                        <b>[28]</b>
                                    He Zhongli,Tsui C Y,Chan K K,et al.Low-power VLSI design for motion estimation using adaptive pixel truncation[J].IEEE Transactions on Circuits Systems for Video Technology,2000,10(8):669- 678</a>
                                </li>
                                <li id="331">


                                    <a id="bibliography_29" >
                                        <b>[29]</b>
                                    Ert&#252;rk A,Ert&#252;rk S.Two-bit transform for binary block motion estimation[J].IEEE Transactions on Circuits and Systems for Video Technology,2005,15(7):938- 946</a>
                                </li>
                                <li id="333">


                                    <a id="bibliography_30" >
                                        <b>[30]</b>
                                    Diniz P S R.Adaptive Filtering:Algorithm and Practical Implementation[M].New York:Springer US,2013</a>
                                </li>
                                <li id="335">


                                    <a id="bibliography_31" >
                                        <b>[31]</b>
                                    Zhu Shan,Ma K K.A new diamond search algorithm for fast block-matching motion estimation[J].IEEE Transactions on Image Processing,2000,9(2):287- 290</a>
                                </li>
                                <li id="337">


                                    <a id="bibliography_32" >
                                        <b>[32]</b>
                                    Li Renxiang,Zeng Bing,Liou M L.A new three-step search algorithm for block motion estimation[J].IEEE Transactions on Circuits and Systems for Video Technology,1994,4(4):438- 442</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(11),2469-2484 DOI:10.7544/issn1000-1239.2019.20180699            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>采用2 b深度像素的弹性运动估计算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AE%8B%E4%BC%A0%E9%B8%A3&amp;code=07947066&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宋传鸣</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%97%B5%E6%96%B0&amp;code=35649941&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">闵新</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%A2%E7%BB%B4%E5%86%AC&amp;code=40991371&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谢维冬</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%B9%E5%AE%9D%E6%89%8D&amp;code=38494733&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尹宝才</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E7%9B%B8%E6%B5%B7&amp;code=07959690&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王相海</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BE%BD%E5%AE%81%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0007183&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辽宁师范大学计算机与信息技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A7%E8%BF%9E%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0222286&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大连理工大学计算机科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E6%96%B0%E6%8A%80%E6%9C%AF%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%8D%97%E4%BA%AC%E5%A4%A7%E5%AD%A6)&amp;code=0069758&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机软件新技术国家重点实验室(南京大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%9C%E5%8C%97%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0111402&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">东北大学计算机科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为降低传统弹性运动估计的计算复杂度,提出一种2 b深度像素的弹性运动估计方法.首先,利用Prewitt算子提取视频帧的梯度,借助梯度模长的均值和标准差将像素深度从8 b降采样为2 b.其次,引进基于位操作的矩阵乘法和基于比较操作的偏导运算,提出了2 b深度像素的弹性运动模型以及求解该模型的简化高斯-牛顿法,避免了黑塞矩阵及其逆矩阵的重复计算.同时,采用1阶线性逼近,得出阻尼步长与运动向量增量、运动补偿误差之间的函数关系以及初始步长的近似计算策略,进而以菱形搜索为初始搜索,给出了2 b深度像素的弹性运动模型的快速求解算法.实验表明:该算法的平均峰值信噪比和计算效率明显优于8 b全搜索、2 b全搜索和传统8 b弹性运动估计.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视频编码;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%90%E5%8A%A8%E4%BC%B0%E8%AE%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">运动估计;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8E%E4%BD%8D%E6%B7%B1%E5%BA%A6%E5%83%8F%E7%B4%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">低位深度像素;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%B9%E6%80%A7%E8%BF%90%E5%8A%A8%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">弹性运动模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E9%80%82%E5%BA%94%E9%98%BB%E5%B0%BC%E7%B3%BB%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自适应阻尼系数;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    宋传鸣,chmsong@lnnu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目（61402214,41671439,61632006）;</span>
                                <span>辽宁省自然科学基金项目（20180550570）;</span>
                                <span>辽宁省高等学校创新人才支持计划项目（64）;</span>
                                <span>南京大学计算机软件新技术国家重点实验室开放课题项目（KFKT2018B07）;</span>
                    </p>
            </div>
                    <h1><b>Elastic Motion Estimation Algorithm Using Two-Bit-Depth Pixels</b></h1>
                    <h2>
                    <span>Song Chuanming</span>
                    <span>Min Xin</span>
                    <span>Xie Weidong</span>
                    <span>Yin Baocai</span>
                    <span>Wang Xianghai</span>
            </h2>
                    <h2>
                    <span>School of Computer and Information Technology, Liaoning Normal University</span>
                    <span>School of Computer Science and Technology, Dalian University of Technology</span>
                    <span>State Key Laboratory for Novel Software Technology (Nanjing University)</span>
                    <span>School of Computer Science and Engineering, Northeastern University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To reduce the computational complexity of traditional elastic motion estimation, this paper proposes a novel elastic motion estimation algorithm using two-bit-depth pixels. First, the Prewitt operator is employed to calculate the gradient of each video frame. The mean and standard deviation of the gradient norm is utilized to down-sample each pixel's depth from 8 b into 2 b. Second, the bitwise operation-based matrix multiplication and the comparison based partial derivative computation are introduced. We subsequently describe an elastic motion model using two-bit-depth pixels, as well as a simplified Gaussian-Newton method which avoids the repetitive computation of the Hessian matrix and its inverse matrix. Meanwhile, we establish the functional relationship of the damping step size versus motion vector increment and motion-compensated errors by the first-order linear approximation, obtaining a method for approximately calculating the initial step size. Furthermore, we address a fast method for solving the elastic motion model with two-bit-depth pixels, using the diamond search algorithm as initial search. Experimental results illustrate that our algorithm obviously outperforms the full search with eight-bit-depth pixels, the full search with two-bit-depth pixels, as well as the conventional elastic motion estimation with eight-bit-depth pixels in terms of the peak signal-to-noise ratio(PSNR) and computational efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=video%20coding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">video coding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=motion%20estimation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">motion estimation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=low%20bit-depth%20pixel&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">low bit-depth pixel;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=elastic%20motion%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">elastic motion model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=adaptive%20damping%20coefficient&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">adaptive damping coefficient;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Song Chuanming,born in 1980.Associate professor of the School of Computer and Information Technology of Liaoning Normal University.Received his PhD degree at the Department of Computer Science&amp;amp;Technology of Nanjing University.Member of CCF.His main research interests include image and video coding,and digital watermarking of multimedia.<image id="387" type="formula" href="images/JFYZ201911016_38700.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Min Xin,born in 1992.Received his master degree in computer science and technology at the School of Computer and Information Technology of Liaoning Normal University.His main research interests include video coding.(hy＿minxin@126.com)<image id="388" type="formula" href="images/JFYZ201911016_38800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Xie Weidong,born 1992.PhD candidate.Received his master degree in computer science and technology from the School of Computer and Information Technology of Liaoning Normal University.His main research interests include video and image coding.(xwdshiwo@163.com)<image id="389" type="formula" href="images/JFYZ201911016_38900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Yin Baocai,born in 1963.Professor and PhD supervisor of the School of Computer Science and Technology of Dalian University of Technology.Senior member of CCF.His main research interests include digital multimedia,multi-functional perception,virtual reality,as well as computer graphics.(ybc@dlut.edu.cn)<image id="390" type="formula" href="images/JFYZ201911016_39000.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Xianghai,born in 1965.Professor and PhD supervisor of the School of Computer and Information Technology of Liaoning Normal University.Senior member of CCF.His main research interests include computer graphics and multimedia information processing.(xhwang@lnnu.edu.cn)<image id="391" type="formula" href="images/JFYZ201911016_39100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61402214,41671439,61632006);</span>
                                <span>the Natural Science Foundation of Liaoning Province of China(20180550570);</span>
                                <span>the Program for Liaoning Excellent Talents in University(64);</span>
                                <span>the Open Foundation of State Key Laboratory for Novel Software Technology(Nanjing University)(KFKT2018B07);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="72">运动估计是一项去除视频冗余的时间域预测技术,为H.264和高效率视频编码(high efficiency video coding, HEVC)等编码标准贡献了大部分的性能提升<citation id="339" type="reference"><link href="275" rel="bibliography" /><link href="277" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>.提高运动估计的效率,使其搜索过程更加健壮和高效不仅是视频编码领域的热点问题,也是进一步改善视频编码效率的重要途径之一.</p>
                </div>
                <div class="p1">
                    <p id="73">多年来,视频编码标准始终采用了仅能刻画水平、竖直等平移运动的块匹配算法,可是块平移模型既无法有效预测由物体旋转、缩放、变形和摄像机运动产生的非刚性复合运动,又不能准确表示具有复杂形状的运动区域,导致在运动物体边缘产生大幅值的预测残差.并且,随着块尺寸的减小和运动向量精度的提高,用于编码运动向量、块划分方式的码流开销以及各种软硬件资源开销的增加幅度甚至超过了率失真性能的提升幅度<citation id="340" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.故此,研究能有效表示复杂运动场的运动模型及相应的帧间运动估计方法,对下一代视频编码效率的提升具有重要意义<citation id="341" type="reference"><link href="279" rel="bibliography" /><link href="281" rel="bibliography" /><link href="283" rel="bibliography" /><link href="285" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="74">鉴于平移运动模型的不足,研究人员将高阶运动模型引入运动估计,利用高阶函数产生1个或多个扭曲的参考帧实现了更高质量的运动补偿.依据模型显式表现形式的不同,本文将这些运动估计/补偿算法划分为4类:1)基于网格模型的运动估计<citation id="343" type="reference"><link href="287" rel="bibliography" /><link href="289" rel="bibliography" /><link href="291" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>;2)基于多项式模型的运动估计<citation id="344" type="reference"><link href="293" rel="bibliography" /><link href="295" rel="bibliography" /><link href="297" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>;3)基于缩放模型的运动估计<citation id="345" type="reference"><link href="299" rel="bibliography" /><link href="301" rel="bibliography" /><link href="303" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>;4)基于弹性模型的运动估计<citation id="346" type="reference"><link href="305" rel="bibliography" /><link href="307" rel="bibliography" /><link href="309" rel="bibliography" /><link href="311" rel="bibliography" /><link href="313" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>.其中,算法1对编码率失真的优化较为困难<citation id="342" type="reference"><link href="315" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>;算法2的参数偏多,搜索复杂度高,且对局部运动的刻画能力不足;算法3无法有效描述物体的旋转、错切和局部变形运动;算法4可刻画物体的平移、错切和扭曲运动,既能表示全局和局部运动,又可通过调整模型参数个数来控制运动估计的计算复杂度.因此,对比各类高阶运动模型并综合现有研究结论,弹性运动模型是一种表示复杂运动场的高效模型.</p>
                </div>
                <div class="p1">
                    <p id="75">本文首先简要介绍弹性运动估计的相关工作,然后针对其存在的计算量高的问题,引进一种视频帧的2 b深度像素表示方法,进而提出低位深度的弹性运动模型,并从模型的快速计算和自适应步长选取策略2个方面展开论述,提出一种采用2 b深度像素加速的弹性运动估计算法.本文的主要贡献有3个方面:</p>
                </div>
                <div class="p1">
                    <p id="76">1) 利用Prewitt梯度算子和梯度模长的均值、标准差提取视频帧的纹理信息,设计了一种将像素从8 b深度向2 b深度进行变换的方法,可避免视频帧在像素深度降采样后出现大面积的光滑区域;</p>
                </div>
                <div class="p1">
                    <p id="77">2) 引进基于位操作的矩阵乘法和基于比较操作的偏导运算,提出了一种基于2 b深度像素的弹性运动估计模型,并根据8 b乘法运算的符号表,进一步给出求解该模型的简化高斯-牛顿法,其优点在于用异或操作替代乘法运算,且无需反复计算黑塞矩阵及其逆矩阵,计算复杂度明显降低;</p>
                </div>
                <div class="p1">
                    <p id="78">3) 根据运动补偿误差的分布特性,利用1阶线性逼近策略,推导出高斯-牛顿法的自适应步长与弹性运动向量增量、运动补偿误差之间的函数关系,进而得出其近似计算方法,保证了算法具有较稳定的收敛性.</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="80">弹性运动模型采用离散余弦函数、小波函数和样条函数等调和函数来描述物体的非刚性运动,最初主要应用于医学影像配准、物体跟踪等领域.文献<citation id="348" type="reference">[<a class="sup">16</a>,<a class="sup">17</a>]</citation>将弹性模型引进视频编码中,提出了基于弹性模型的运动估计,在相同码率下获得了比块平移运动估计高出0.70 dB的运动补偿峰值信噪比(peak signal-to-noise ratio, PSNR);文献<citation id="347" type="reference">[<a class="sup">18</a>]</citation>的结论显示,弹性运动模型可将H.265的输出码率降低3%～12%;文献<citation id="349" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">22</a>]</citation>则通过优化弹性模型的求解方法取得了更加理想的预测效率,将传统弹性运动估计的平均PSNR又提高了1.42～1.77 dB,比基于块平移模型的全搜索算法高出1.73～2.54 dB.然而,上述文献均采用高斯-牛顿法来迭代地求解弹性运动模型,在每次迭代过程中需计算偏导数、黑塞矩阵、逆矩阵和矩阵乘法,其计算复杂度甚至高于块平移模型的全搜索(full search, FS).尽管经过文献<citation id="350" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">22</a>]</citation>改进后的弹性运动估计仅需2～3次迭代即可达到块匹配全搜索的补偿质量,可是仍然无法避免黑塞矩阵及其逆矩阵等的反复求解,计算量约为FS的25.62%,高于菱形搜索(diamond search, DS)和测试域搜索(test zone search, TZSearch)等快速块匹配运动估计.</p>
                </div>
                <div class="p1">
                    <p id="81">为了增强高阶运动模型求解的实时性,文献<citation id="351" type="reference">[<a class="sup">23</a>]</citation>提出一种1 b深度像素的高斯-牛顿迭代法,并将其应用到基于6-参数仿射变换的图像配准中.然而,由于1 b匹配误差曲面的梯度较小,该算法至少需迭代50次才能缓慢趋于收敛,计算复杂度并未显著降低.文献<citation id="353" type="reference">[<a class="sup">24</a>,<a class="sup">25</a>]</citation>进一步将文献<citation id="352" type="reference">[<a class="sup">23</a>]</citation>的思路推广到2 b深度像素,实现了一种基于仿射模型的2 b全局运动估计.可是,为节省逆矩阵的计算量,该方法要求保持迭代步长固定不变,无法实现自适应,且只能朝着单一方向进行迭代.而文献<citation id="354" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">22</a>]</citation>的研究结论却表明,高斯-牛顿法对初始迭代步长和迭代方向均较为敏感,这就不可避免地导致文献<citation id="355" type="reference">[<a class="sup">24</a>,<a class="sup">25</a>]</citation>在大多数情况下都无法求解出全局最优解.同时,文献<citation id="356" type="reference">[<a class="sup">23</a>,<a class="sup">24</a>,<a class="sup">25</a>]</citation>均利用8 b深度表示的图像计算1阶偏导,再结合经过位截断后的低位深度图像得到匹配误差和最速下降方向.由于低位深像素的梯度往往不同于8 b深度像素,两者混合作用很难保证下降方向的准确性;另一方面,文献<citation id="357" type="reference">[<a class="sup">26</a>,<a class="sup">27</a>]</citation>指出,匹配误差往往产生在较低的位,直接截断低位无法有效保留图像的边缘特征,还将使位于最佳匹配块周围的一定区域内的所有像素被量化成相同值,以致失去对最优向量的判断能力.综合来看,无论是运动估计的精度,抑或收敛速度,文献<citation id="358" type="reference">[<a class="sup">23</a>,<a class="sup">24</a>,<a class="sup">25</a>]</citation>的方法尚不够令人满意,且只能求解仿射模型下的运动向量.因此,研究更加有效的、基于低位深度像素的高斯-牛顿法和弹性运动估计,有助于以弹性模型为代表的高阶运动估计走向实用,对新一代视频编码的发展具有一定意义.从本文作者所掌握的文献来看,目前尚鲜见相关研究.</p>
                </div>
                <div class="p1">
                    <p id="82">本文提出的2 b深度像素的弹性运动估计,利用梯度均值和标准差提取图像的边缘和纹理特征,将像素从8 b深度向2 b深度进行转换,并实现了基于位操作的快速高斯-牛顿优化求解.不仅解决了初始迭代步长的自适应选取和迭代方向的多样性,也使得1阶偏导与最速下降方向均在2 b深度像素域进行统一计算,从而保证基于低位深像素的弹性运动估计精度和收敛速度.</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag"><b>2 弹性运动模型及其高斯-牛顿求解方法</b></h3>
                <div class="p1">
                    <p id="84">为便于下文工作的论述,本节首先介绍弹性运动模型的定义,再给出求解弹性运动向量的高斯-牛顿方法.</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>2.1 弹性运动模型的基本定义</b></h4>
                <div class="p1">
                    <p id="86">视频运动估计的目标是在参考帧的某个搜索窗口内,为当前待预测块<i><b>I</b></i>(尺寸为<i>B</i>×<i>B</i>像素)搜索到1个运动向量,使得<i><b>I</b></i>与其最佳匹配块<i><b>R</b></i>之间的误差平方和(sum of squared difference, SSD )最小,即:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">m</mi></munder><mo stretchy="false">{</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>R</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mi>w</mi><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>-</mo><mi>Ι</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中,<i>x</i><sub><i>ij</i></sub>和<i>y</i><sub><i>ij</i></sub>分别表示当前待预测块中<i>i</i>行<i>j</i>列像素的<i>x</i>坐标和<i>y</i>坐标,<i><b>m</b></i>表示某种运动模型<i>w</i>下的运动向量.对于弹性运动模型,采用弹性基函数<i>φ</i><sub><i>k</i></sub>建立待预测块中每个像素的坐标及其匹配像素的坐标映射,其定义为</p>
                </div>
                <div class="p1">
                    <p id="89"><i>x</i>′<sub><i>ij</i></sub>=<i>w</i>(<i>x</i><sub><i>ij</i></sub>;<mathml id="200"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>p</mi><mo>/</mo><mn>2</mn></mrow></munderover><mi>m</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi>φ</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></math></mathml>,(2)</p>
                </div>
                <div class="p1">
                    <p id="90"><i>y</i>′<sub><i>ij</i></sub>=<i>w</i>(<i>y</i><sub><i>ij</i></sub>;<mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>=</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mi>p</mi><mo>/</mo><mn>2</mn><mo>+</mo><mn>1</mn></mrow><mi>p</mi></munderover><mi>m</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi>φ</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></math></mathml>,(3)</p>
                </div>
                <div class="p1">
                    <p id="91">其中,<i>p</i>表示运动矢量的分量数目,<i>m</i><sub><i>k</i></sub>表示<i><b>m</b></i>的第<i>k</i>个分量,且<i>φ</i><sub><i>k</i></sub>为离散余弦函数:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>φ</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mi>φ</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mi>p</mi><mo>/</mo><mn>2</mn></mrow></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mi>cos</mi></mrow><mrow><mo>[</mo><mrow><mfrac><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mtext>π</mtext><mi>u</mi></mrow><mrow><mn>2</mn><mi>B</mi></mrow></mfrac></mrow><mo>]</mo></mrow><mrow><mi>cos</mi></mrow><mrow><mo>[</mo><mrow><mfrac><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>j</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mtext>π</mtext><mi>v</mi></mrow><mrow><mn>2</mn><mi>B</mi></mrow></mfrac></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">其中,<mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo>=</mo><mn>8</mn><mo>,</mo><mi>k</mi><mo>=</mo><mi>q</mi><mi>u</mi><mo>+</mo><mi>v</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>q</mi><mo>-</mo><mn>1</mn><mo>,</mo><mi>q</mi><mo>=</mo><msqrt><mrow><mi>p</mi><mo>/</mo><mn>2</mn></mrow></msqrt><mo>,</mo><mn>0</mn><mo>≤</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>&lt;</mo><mi>B</mi><mo>.</mo></mrow></math></mathml></p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>2.2 弹性运动模型的高斯-牛顿解法</b></h4>
                <div class="p1">
                    <p id="95">为了获得弹性运动向量<i><b>m</b></i>,文献<citation id="359" type="reference">[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>]</citation>均采用了高斯-牛顿法进行求解,主要思想是对匹配误差函数进行线性逼近,再通过反复迭代求出极小值.具体地,假设当前迭代点为<i><b>m</b></i>,并令(<i>x</i><sub><i>ij</i></sub>,<i>y</i><sub><i>ij</i></sub>)处的预测误差为<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)=<i>R</i>(<i>w</i>(<i>x</i><sub><i>ij</i></sub>,<i><b>m</b></i>),<i>w</i>(<i>y</i><sub><i>ij</i></sub>,<i><b>m</b></i>))-<i>I</i>(<i>x</i><sub><i>ij</i></sub>,<i>y</i><sub><i>ij</i></sub>),则<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)可用其在<i><b>m</b></i>处的1阶泰勒展开式近似表示,即:</p>
                </div>
                <div class="p1">
                    <p id="96"><i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>+Δ<i><b>m</b></i>)≈<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)+<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)Δ<i><b>m</b></i>,(5)</p>
                </div>
                <div class="p1">
                    <p id="97">其中,<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)表示<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)在<i><b>m</b></i>处的1阶偏导数<mathml id="203"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi></mrow></mfrac></mrow></math></mathml>.将式(5)代入式(1),则有</p>
                </div>
                <div class="area_img" id="392">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201911016_39200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="100">为取得式(6)的最小值,将其对Δ<i><b>m</b></i>取导并令导数为0,整理后得到:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mtext>Δ</mtext><mi mathvariant="bold-italic">m</mi><mo>=</mo></mtd></mtr><mtr><mtd><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">令<mathml id="204"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">b</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow></math></mathml>,(8)</p>
                </div>
                <div class="p1">
                    <p id="103"><mathml id="205"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Η</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow></math></mathml>,(9)</p>
                </div>
                <div class="p1">
                    <p id="104">显然,<i><b>H</b></i>是1个<i>p</i>×<i>p</i>阶的黑塞矩阵,并且根据求导的链式法则和<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)、式(2)、式(3)的定义,有:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Η</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mrow><mo>[</mo><mrow><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">R</mi></mrow><mrow><mo>∂</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mfrac><mrow><mo>∂</mo><mi>w</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">R</mi></mrow><mrow><mo>∂</mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mfrac><mrow><mo>∂</mo><mi>w</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi></mrow></mfrac></mrow><mo>]</mo></mrow></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>×</mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mrow><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">R</mi></mrow><mrow><mo>∂</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mfrac><mrow><mo>∂</mo><mi>w</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">R</mi></mrow><mrow><mo>∂</mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mfrac><mrow><mo>∂</mo><mi>w</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi></mrow></mfrac></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">其中,<mathml id="206"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">R</mi></mrow><mrow><mo>∂</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac></mrow></math></mathml>和<mathml id="207"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">R</mi></mrow><mrow><mo>∂</mo><msup><mi>y</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac></mrow></math></mathml>分别表示匹配块沿着水平和竖直方向的梯度分量,<mathml id="208"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>w</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi></mrow></mfrac></mrow></math></mathml>是雅克比矩阵,并且<mathml id="209"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>w</mi></mrow><mrow><mo>∂</mo><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mo>∂</mo><mi>w</mi></mrow><mrow><mo>∂</mo><mi>m</mi><msub><mrow></mrow><mrow><mi>p</mi><mo>/</mo><mn>2</mn><mo>+</mo><mi>k</mi></mrow></msub></mrow></mfrac><mo>=</mo><mi>φ</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>,</mo><mi>k</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo>,</mo><mi>p</mi><mo>/</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></math></mathml>.于是,有Δ<i><b>m</b></i>=<i><b>H</b></i><sup>-1</sup><i><b>b</b></i>,进而得到更新后的弹性运动向量<i><b>m</b></i>:<i><b>m</b></i>←<i><b>m</b></i>+Δ<i><b>m</b></i>.</p>
                </div>
                <div class="p1">
                    <p id="107">图1给出了基于高斯-牛顿法的弹性运动估计过程,其中<i>T</i>表示迭代次数,<i>T</i><sub>min</sub>表示迭代的条件阈值,<mathml id="210"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow></mrow></math></mathml>表示向量的模长.</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于高斯-牛顿法的弹性运动估计流程图" src="Detail/GetImg?filename=images/JFYZ201911016_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于高斯-牛顿法的弹性运动估计流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flowchart of elastic motion estimation using
 the Gauss-Newton Method</p>

                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>3 基于Prewitt梯度算子的2 b变换</b></h3>
                <div class="p1">
                    <p id="110">由2.2节可见,弹性运动模型的高斯-牛顿解法需反复计算偏导数、黑塞矩阵、逆矩阵和矩阵乘法,计算量明显高于块平移模型的全搜索.为此,我们引进基于低位深度像素的策略,将像素从8 b深度降采样为2 b深度,以达到降低计算开销的目的.</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>3.1 本文的2 b变换算法</b></h4>
                <div class="p1">
                    <p id="112">将像素从8 b深度转换至2 b深度,势必会丢失视频帧的部分信息,尤其是细腻的纹理细节,产生大面积的平滑区域,这是导致基于低位截断的低位深度像素运动估计出现性能下降的重要原因<citation id="360" type="reference"><link href="325" rel="bibliography" /><link href="327" rel="bibliography" /><sup>[<a class="sup">26</a>,<a class="sup">27</a>]</sup></citation>.故此,在像素深度变换过程中尽可能保持视频的纹理特征,对于衡量像素深度降采样的有效性、保证运动估计精度具有重要意义.为了达到这一目的,我们首先通过Prewitt算子计算待预测帧的梯度;其次,假定像素梯度的模长服从正态分布,若用均值<i>μ</i><sub><i><b>C</b></i></sub>和标准差<i>σ</i><sub><i><b>C</b></i></sub>将概率密度划分为4个区间,则知梯度模长位于区间(-∞,<i>μ</i><sub><i><b>C</b></i></sub>-0.68<i>σ</i><sub><i><b>C</b></i></sub>),[<i>μ</i><sub><i><b>C</b></i></sub>-0.68<i>σ</i><sub><i><b>C</b></i></sub>,<i>μ</i><sub><i><b>C</b></i></sub>),[<i>μ</i><sub><i><b>C</b></i></sub>,<i>μ</i><sub><i><b>C</b></i></sub>+0.68<i>σ</i><sub><i><b>C</b></i></sub>),[<i>μ</i><sub><i><b>C</b></i></sub>+0.68<i>σ</i><sub><i><b>C</b></i></sub>,+∞)的概率均近似等于0.25,根据这一规律,本文以像素块为单位,将每个像素处的边缘和纹理强度平均分为弱、较弱、较强、强4个等级,从而实现将像素(<i>x</i>,<i>y</i>)的深度从8 b变换为2 b:</p>
                </div>
                <div class="area_img" id="393">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201911016_39300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="394">其中，<image id="395" type="formula" href="images/JFYZ201911016_39500.jpg" display="inline" placement="inline"><alt></alt></image>表示块C中（x,y）处的梯度模长，C′（x,y）表示像素（x,y）经过变换后的2b深度表示．</p>
                </div>
                <div class="p1">
                    <p id="116">本文提出的基于梯度均值和标准差的2 b变换过程如图2所示:</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文提出的2 b变换流程图" src="Detail/GetImg?filename=images/JFYZ201911016_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文提出的2 b变换流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Flowchart of the proposed 2 b transform</p>

                </div>
                <div class="p1">
                    <p id="118">图3给出了分别采用低位截断方法<citation id="361" type="reference"><link href="329" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>、基于亮度均值和方差的2 b变换方法<citation id="362" type="reference"><link href="331" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>,以及本文方法处理Football序列和Foreman序列第2帧的结果.从图3不难发现,基于低位截断的变换方法损失了Football序列包含的复杂背景纹理(图3(b));虽然基于亮度均值和方差的2 b变换方法<citation id="363" type="reference"><link href="331" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>在一定程度上避免了位截断方法的不足,可是未充分考虑正态分布的特点,选用亮度均值<i>μ</i>、标准差<i>σ</i>及其线性组合<i>μ</i>-<i>σ</i>和<i>μ</i>+<i>σ</i>作为变换阈值,这将导致约有68%的像素会从8 b深度被降采样为00和01,产生较大面积的平滑区,如Football的运动员身体和Foreman的脸部区域中大量像素被转换为相同值,易使运动估计陷入局部最优,甚至失去对最优向量的判断能力;而本文方法无论在复杂的背景纹理区,还是在平滑的渐变区(如Foreman的脸部),均能保持适当的图像细节,进而形成能有效区分错误运动向量的特征.</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同的2 b变换方法的效果对比" src="Detail/GetImg?filename=images/JFYZ201911016_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同的2 b变换方法的效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Comparison among different 2 b transform results</p>

                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>3.2 2 b深度像素的匹配误差曲面的特点</b></h4>
                <div class="p1">
                    <p id="121">由于位深度变换过程难免丢失少量纹理细节,会出现2种情况:1)当一定区域内的像素均被变换为相同值时,像素值的变化率降低、自相关系数增大.这样,当待预测块在该区域内搜寻最佳匹配块时,匹配误差的变化趋于平缓.我们称这样的区域为“曲面平滑区域”.2)在2个曲面平滑区的交界线两侧,像素值被变换为不同值,像素值的变化率提高,而自相关系数减小.对2 b深度的像素而言,由于匹配误差的值域显著小于8 b深度像素,即使匹配误差增加1,也意味着25%的增幅,这相当于8 b误差增幅的32倍.因此,在交界区域中不同候选向量的运动补偿误差易产生较大变化.2 b匹配误差曲面的这种“区域内平滑、区域间锐化”的分布特点,会使其呈现更加明显的单调性和梯度变化.</p>
                </div>
                <div class="p1">
                    <p id="122">图4给出了Stefan序列第2帧内左上角坐标为(144,112)的块和Football序列第2帧内左上角坐标为(176,176)的块,分别进行基于8 b深度像素和基于本文2 b深度像素的整数精度全搜索后得到的匹配误差曲面,搜索窗口为33×33.对比可见:首先,8 b深度像素的匹配误差曲面(图4(a)(c))较之2 b深度像素的匹配误差曲面(图4(b)(d))具有更强的波动性,局部极值点也更多,易导致典型的快速搜索陷入局部最优.其次,在曲面平滑区域,8 b深度像素的匹配误差的变化幅度和频率均大于2 b深度像素的匹配误差;而在极值点的一定邻域以及2个局部极值区域的交界,8 b深度像素匹配误差的变化趋势却较平滑,其数值梯度和衰减速度明显小于2 b深度像素的匹配误差曲面.这不仅印证了上一段的理论分析,也充分说明2 b深度像素的运动估计陷入局部最优的概率更小,且能通过梯度下降策略以更快的速度向全局最优点收敛,尤其是当搜索初始点较为准确、位于全局极值点的单调区间时,从而有利于提高运动补偿精度和运动估计效率.</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 8 b全搜索与2 b全搜索的匹配误差曲面比较" src="Detail/GetImg?filename=images/JFYZ201911016_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 8 b全搜索与2 b全搜索的匹配误差曲面比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Comparison between matching error surfaces of 8 b pixel and 2 b pixel under full search</p>

                </div>
                <h3 id="124" name="124" class="anchor-tag"><b>4 低位深度的弹性运动模型</b></h3>
                <div class="p1">
                    <p id="125">传统高斯-牛顿法的每次迭代都需要计算待预测块的偏导数、黑塞矩阵、逆矩阵、矩阵乘法和运动补偿误差等,其计算复杂度达到了max{<i>O</i>(<i>p</i><sup>3</sup>),<i>O</i>(<i>p</i><sup>2</sup><i>B</i><sup>2</sup>)}.若能降低反复执行上述操作的运算量,则可进一步改善弹性运动估计/补偿的效率.同时,经过第3节的处理,视频帧的全部像素已由8 b深度降采样到2 b深度,若继续延用传统高斯-牛顿法中基于8 b整数的偏导、矩阵乘法等运算,则达不到通过精度下采样来提高计算效率的目的.故此,本文对匹配误差<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)及其1阶偏导数<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)也进行了位深度变换,利用异或运算取代乘法运算,提出了面向低位深度像素的弹性运动模型,从而加快弹性运动估计的速度.</p>
                </div>
                <div class="p1">
                    <p id="126">根据1阶偏导<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)的符号,文献<citation id="364" type="reference">[<a class="sup">23</a>]</citation>将其直接2值化为</p>
                </div>
                <div class="area_img" id="396">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201911016_39600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="129">其中,用bit “1”表示正数,用bit “0”表示非正数,<i>e</i>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)表示<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)的第<i>k</i>个分量.同理,采用同样的规则将匹配误差<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)进行位深度的变换,即:</p>
                </div>
                <div class="area_img" id="397">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201911016_39700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="132">此时,将经过2值化后的<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)和<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)代入式(8),并将式(8)中的乘法运算替换为异或运算来计算向量<i><b>b</b></i>.为了验证上述规则的有效性,表1给出了基于8 b运算的[<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)]<sup>T</sup>×<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)的乘法符号表,而表2所示则为低位深度的<mathml id="212"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover></math></mathml>′<sub><i>ij</i></sub>(<i><b>m</b></i>)和<mathml id="213"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>e</mi><mo>˜</mo></mover></math></mathml><sub><i>ij</i></sub>(<i><b>m</b></i>)经过1 b异或运算“⊕”的真值表.</p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表1 8 b乘法运算的符号表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Sign of 8 b Multiplication Operation</b></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td><br /><i>e</i><sub><i>ij</i></sub>(<b><i>m</i></b>)</td><td><i>e</i>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)</td><td><i>e</i>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)×<i>e</i><sub><i>ij</i></sub>(<b><i>m</i></b>)</td></tr><tr><td><br />-</td><td>-</td><td>+</td></tr><tr><td><br />-</td><td>+</td><td>-</td></tr><tr><td><br />+</td><td>-</td><td>-</td></tr><tr><td><br />+</td><td>+</td><td>+</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="134">
                    <p class="img_tit"><b>表2 1 b异或运算的真值表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Truth Table of 1 Bit-Wise XOR Operation</b></p>
                    <p class="img_note"></p>
                    <table id="134" border="1"><tr><td><br /><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>e</mi><mo>˜</mo></mover></math><sub><i>ij</i></sub>(<b><i>m</i></b>)</td><td><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>e</mi><mo>˜</mo></mover></math>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)</td><td><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>e</mi><mo>˜</mo></mover></math>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)⊕<math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>e</mi><mo>˜</mo></mover></math><sub><i>ij</i></sub>(<b><i>m</i></b>)</td></tr><tr><td><br />0</td><td>0</td><td>0</td></tr><tr><td><br />0</td><td>1</td><td>1</td></tr><tr><td><br />1</td><td>0</td><td>1</td></tr><tr><td><br />1</td><td>1</td><td>0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="135">对比表1和表2可以发现,8 b乘法运算的符号与1 b异或运算的真值并不一致.例如正数与负数的乘积为负数,也就是“1”与“0”的乘积应为“0”,而异或的结果却等于“1”.另一方面,高斯-牛顿法通过[<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)]<sup>T</sup>×<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)控制每次迭代的方向,若<mathml id="214"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">[</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>⊕</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow></math></mathml>,则由Δ<i><b>m</b></i>=<i><b>H</b></i><sup>-1</sup><i><b>b</b></i>可知,将导致迭代步长<mathml id="215"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi mathvariant="bold-italic">m</mi></mrow><mo>|</mo></mrow><mo>=</mo><mn>0</mn></mrow></math></mathml>,失去向全局最优解收敛的驱动力.这表明,采用文献<citation id="365" type="reference">[<a class="sup">23</a>]</citation>的方法将弹性模型进行2值化,仅能产生单一方向的迭代动力(也就是当[<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)]<sup>T</sup>×<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)=<b>1</b>时的情形),不利于保证解的精度和收敛速度.</p>
                </div>
                <div class="p1">
                    <p id="136">为了解决这个问题,本文通过将匹配误差进行2次互为相反数的2值化转换,提出了基于2 b深度的弹性运动模型,即:</p>
                </div>
                <div class="area_img" id="398">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201911016_39800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="141">其中,<i>I</i>′<sub><i>ij</i></sub>和<i>R</i>′<sub><i>ij</i></sub>表示当前帧和参考帧的2 b深度表示,<mathml id="216"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>+</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow></math></mathml>和<mathml id="217"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>-</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow></math></mathml>分别表示在弹性运动参数<i><b>m</b></i>下像素(<i>i</i>,<i>j</i>)处匹配误差的高位和低位.在此基础上,将高、低位分别与<mathml id="218"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover></math></mathml>′<sub><i>ij</i></sub>(<i><b>m</b></i>)进行异或运算,再将所得结果相减:</p>
                </div>
                <div class="p1">
                    <p id="142"><mathml id="219"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>+</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>-</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></mathml>.(16)</p>
                </div>
                <div class="p1">
                    <p id="143">表3给出了经过上述改进后,1 b异或运算和8 b乘法运算的对比结果.可见,[<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)]<sup>T</sup>×<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)与<mathml id="220"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>+</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>-</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></mathml>表现出一致的极性,并且<mathml id="221"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>+</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>-</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mo>±</mo><mn>1</mn></mrow></math></mathml>表明,上述基于2 b深度的弹性运动模型不仅避免了<mathml id="222"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">[</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>⊕</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow></math></mathml>时可能出现的不收敛现象,也使得求解过程能够朝着2个不同方向进行迭代,从而提高取得全局最优解的概率.鉴于这一原因,本文向量<i><b>b</b></i>的计算过程为</p>
                </div>
                <div class="p1">
                    <p id="144" class="code-formula">
                        <mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">b</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mover accent="true"><mi>e</mi><mo>˜</mo></mover></mstyle></mrow></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>+</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>-</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mover accent="true"><mi>e</mi><mo>˜</mo></mover></mstyle></mrow></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>-</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi mathvariant="bold-italic">e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表3 改进的异或运算真值表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Truth Table of Improved XOR Operation</b></p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td><i>e</i><sub><i>ij</i></sub>(<b><i>m</i></b>)</td><td><i>e</i>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)</td><td><i>e</i>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)×<i>e</i><sub><i>ij</i></sub>(<b><i>m</i></b>)</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>+</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>-</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow></math></td><td><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>e</mi><mo>˜</mo></mover></math>′<sub><i>ij</i></sub>(<i>m</i><sub><i>k</i></sub>)</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>+</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi>e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>-</mo><mo stretchy="false">(</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>-</mo></msubsup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>⊕</mo><msup><mover accent="true"><mi>e</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></td></tr><tr><td><br />-</td><td>-</td><td>+</td><td>1</td><td>0</td><td>0</td><td>(1⊕0)-(0⊕0)=+1</td></tr><tr><td><br />-</td><td>+</td><td>-</td><td>1</td><td>0</td><td>1</td><td>(1⊕1)-(0⊕1)=-1</td></tr><tr><td><br />+</td><td>-</td><td>-</td><td>0</td><td>1</td><td>0</td><td>(0⊕0)-(1⊕0)=-1</td></tr><tr><td><br />+</td><td>+</td><td>+</td><td>0</td><td>1</td><td>1</td><td>(0⊕1)-(1⊕1)=+1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="146" name="146" class="anchor-tag"><b>5 迭代步长的自适应计算</b></h3>
                <div class="p1">
                    <p id="147">在高斯-牛顿方法中,<i><b>b</b></i>用于确定每次迭代的方向,黑塞矩阵<i><b>H</b></i>的逆<i><b>H</b></i><sup>-1</sup>则用于确定每次迭代的步长.然而,计算<i><b>H</b></i><sup>-1</sup>需要大量的乘法运算,其时间复杂度为<i>O</i>(<i>p</i><sup>3</sup>);并且,1阶偏导<i><b>e</b></i>′<sub><i>ij</i></sub>(<i><b>m</b></i>)经过第4节的2 b转换后,<i><b>H</b></i><sup>-1</sup>所给出的步长亦不够精确,没有必要再通过<i><b>H</b></i><sup>-1</sup>计算迭代步长.所以,文献<citation id="366" type="reference">[<a class="sup">25</a>]</citation>采用固定步长<i>s</i>来近似<i><b>H</b></i><sup>-1</sup>,于是弹性运动向量的增量表示为</p>
                </div>
                <div class="p1">
                    <p id="148">Δ<i><b>m</b></i>=-<i>s</i>×sgn(<i><b>b</b></i>),(18)</p>
                </div>
                <div class="p1">
                    <p id="149">其中,sgn(·)表示符号函数.但是,这种做法无异于放弃了黑塞矩阵对高斯-牛顿迭代过程的控制.而文献<citation id="368" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">22</a>]</citation>的研究结论却表明,高斯-牛顿法对初始迭代步长较为敏感,文献<citation id="367" type="reference">[<a class="sup">25</a>]</citation>的这种固定初始步长的方式显然不利于迭代过程收敛到全局最优解.为了验证这一推论,我们选取Akiyo,Tempete,Football这3个运动特性和纹理复杂度各异的视频序列的前10帧,应用固定步长的2 b深度弹性模型进行了运动估计/补偿实验.图5给出了在不同的初始步长<i>s</i>下,3个序列经过15次迭代后所获得的平均运动补偿PSNR曲线.从图5可见,Akiyo序列的运动幅度很小、画面纹理细节简单,随着初始步长的缩小,该序列的运动补偿PSNR明显升高(图5(a)),但是即使初始步长缩小至1×10<sup>-6</sup>,仍未取得最高的PSNR;Tempete序列的运动幅度中等,可是纹理细节复杂,且包含摄像机的拉摄运动,其运动补偿的平均PSNR在初始步长为4×10<sup>-6</sup>时取得极值,然后随着初始步长的增大迅速下降(图5(b));Football序列既包含快速的前景运动和中等复杂度的纹理,又存在物体的局部形变,它在初始步长等于3×10<sup>-5</sup>时取得了运动补偿PSNR的极值(图5(c)),而此时,Akiyo的平均PSNR已比其最高值下降了4.74 dB.</p>
                </div>
                <div class="area_img" id="150">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同初始步长s下的运动补偿PSNR对比" src="Detail/GetImg?filename=images/JFYZ201911016_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同初始步长<i>s</i>下的运动补偿PSNR对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 The motion-compensated PSNR comparison 
 among with different initial step size <i>s</i></p>

                </div>
                <div class="p1">
                    <p id="151">对比这3个视频序列的实验结果可知,不同序列的最优初始步长相差几十倍.对于运动幅度较小、画面细节较多的视频,应为其选取一个较小的迭代步长;反之,对于运动速度较快、局部形变较多的视频,为其设定一个较大的迭代步长则更加合适.可见,文献<citation id="369" type="reference">[<a class="sup">25</a>]</citation>固定初始步长的方式不仅无法保证运动补偿的质量,而且在现实中亦很难做到折中选择.为此,本节采用一种自适应步长<i>s</i>来近似<i><b>H</b></i><sup>-1</sup>,下面讨论其计算方法.</p>
                </div>
                <div class="p1">
                    <p id="152">由式(6)可知,高斯-牛顿法的基本思路是在每次迭代中利用2次函数来逼近匹配误差<i>D</i>(<i><b>m</b></i>),并求解近似函数的极小点作为下一个迭代点,则第<i>k</i>+1次迭代的弹性运动向量<i><b>m</b></i><sup><i>k</i></sup><sup>+1</sup>有:</p>
                </div>
                <div class="p1">
                    <p id="153"><i><b>m</b></i><sup><i>k</i></sup><sup>+1</sup>=<i><b>m</b></i><sup><i>k</i></sup>+<i><b>H</b></i><sup>-1</sup><i><b>b</b></i>,(19)</p>
                </div>
                <div class="p1">
                    <p id="154">其中,<mathml id="223"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>.那么:</p>
                </div>
                <div class="p1">
                    <p id="155"><mathml id="224"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi></mrow></mfrac><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mn>2</mn></mstyle></mrow></mstyle><mo stretchy="false">[</mo><msup><mi mathvariant="bold-italic">e</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>e</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo><mo>=</mo><mo>-</mo><mn>2</mn><mi mathvariant="bold-italic">b</mi></mrow></math></mathml>,(20)</p>
                </div>
                <div class="area_img" id="399">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201911016_39900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="158">由于匹配误差<i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)在全局最优解附近“几乎”是白噪声<citation id="370" type="reference"><link href="333" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>,式(21)第2项[<i><b>e</b></i>″<sub><i>ij</i></sub>(<i><b>m</b></i>)]<sup>T</sup><i>e</i><sub><i>ij</i></sub>(<i><b>m</b></i>)的数学期望近似为<b>0</b>,就有:</p>
                </div>
                <div class="p1">
                    <p id="159"><mathml id="225"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>≈</mo><mn>2</mn><mi mathvariant="bold-italic">Η</mi></mrow></math></mathml>.(22)</p>
                </div>
                <div class="p1">
                    <p id="160">而由微分的1阶近似性质Δ<i>f</i>(<i>x</i>)≈<i>f</i>′(<i>x</i>)·Δ<i>x</i>,可知:</p>
                </div>
                <div class="p1">
                    <p id="161"><mathml id="226"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>≈</mo><mfrac><mrow><mfrac><mrow><mo>∂</mo><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mfrac><mo>-</mo><mfrac><mrow><mo>∂</mo><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>k</mi></msup></mrow></mfrac></mrow><mrow><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>k</mi></msup></mrow></mfrac></mrow></math></mathml>,(23)</p>
                </div>
                <div class="p1">
                    <p id="162">进一步,将式(20)代入式(23),得到:</p>
                </div>
                <div class="p1">
                    <p id="163"><mathml id="227"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">m</mi><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>≈</mo><mfrac><mrow><mn>2</mn><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mi>k</mi></msup><mo>-</mo><mn>2</mn><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><mrow><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi mathvariant="bold-italic">m</mi><msup><mrow></mrow><mi>k</mi></msup></mrow></mfrac><mo>=</mo><mo>-</mo><mn>2</mn><mtext>Δ</mtext><mi mathvariant="bold-italic">b</mi><mo>/</mo><mtext>Δ</mtext><mi mathvariant="bold-italic">m</mi></mrow></math></mathml>,(24)</p>
                </div>
                <div class="p1">
                    <p id="164">再由式(22)易知<i><b>H</b></i>≈-Δ<i><b>b</b></i>/Δ<i><b>m</b></i>,整理后即可得到自适应步长<i>s</i>:</p>
                </div>
                <div class="p1">
                    <p id="165"><mathml id="228"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Η</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>|</mo></mrow><mo>=</mo><mo>-</mo><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi mathvariant="bold-italic">m</mi></mrow><mo>|</mo></mrow><mo>×</mo><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi mathvariant="bold-italic">b</mi></mrow><mo>|</mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>.(25)</p>
                </div>
                <div class="p1">
                    <p id="166">式(25)表明:自适应步长<i>s</i>与运动向量的变化量Δ<i><b>m</b></i>成正比,而与匹配误差的变化量及其关于<i><b>m</b></i>的导数呈反比.对比图5的实验结果,Akiyo序列的运动幅度很小,其Δ<i><b>m</b></i>几乎为<b>0</b>,而由于播音员的头部和嘴部存在局部运动,第1次迭代后产生的匹配误差必然大于0,这就使得该序列的最优初始步长趋近于0;尽管Tempete序列存在中等幅度的运动(即Δ<i><b>m</b></i>&gt;<b>0</b>),可是复杂纹理细节势必产生较大的匹配误差,故此,由式(25)可推知Tempete序列的最优初始步长也相对较小;考虑到Football序列包含快速运动,其Δ<i><b>m</b></i>将明显超过Akiyo和Tempete,且纹理细节的复杂度一般,匹配误差变化量在预期上不会显著大于Tempete序列,于是Football序列的最优初始步长较大.综合上述分析,式(25)的结论与图5的实验结果一致.</p>
                </div>
                <div class="p1">
                    <p id="167">为了进一步降低式(25)所需要的计算量,本文采用取绝对值运算代替乘法和开平方运算来近似取模长运算:</p>
                </div>
                <div class="p1">
                    <p id="168"><mathml id="229"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi mathvariant="bold-italic">m</mi></mrow><mo>|</mo></mrow><mo>≈</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></math></mathml>,(26)</p>
                </div>
                <div class="p1">
                    <p id="169"><mathml id="230"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi mathvariant="bold-italic">b</mi></mrow><mo>|</mo></mrow><mo>≈</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mrow><mrow><mo>|</mo><mrow><mtext>Δ</mtext><mi>b</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></math></mathml>,(27)</p>
                </div>
                <div class="p1">
                    <p id="170">其中,Δ<i>m</i><sub><i>k</i></sub>,Δ<i>b</i><sub><i>k</i></sub>分别表示Δ<i><b>m</b></i>和Δ<i><b>b</b></i>的第<i>k</i>个分量.同时,本文仅利用式(25)～(27)确定初始迭代步长,而对于后续的迭代,为保证算法具有较稳定的收敛性,本文在步长值满足以下条件时将其减半<citation id="371" type="reference"><link href="323" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>:<i><b>b</b></i>的符号在连续3次迭代中改变3次,即在某个解的局部邻域内发生往返式的迭代.如第4节所述,本文的低位深度的弹性运动模型能朝着2个不同方向进行迭代,若发生折返式迭代,则表明算法很可能处于某个全局/局部最优解的单调区间内,且当前步长较大,导致每次迭代均越过该最优解,故应选取更小的步长向这个解进行逼近.</p>
                </div>
                <h3 id="171" name="171" class="anchor-tag"><b>6 2 b深度像素的弹性运动估计步骤</b></h3>
                <div class="p1">
                    <p id="172">在第5节算法的基础上,本节给出一种基于2 b深度像素的弹性运动估计方法,具体步骤如图6所示,其中,<i>x</i><sub><i>i</i></sub>,<i>y</i><sub><i>i</i></sub>表示<i><b>I</b></i>中某个像素的横、纵坐标,0≤<i>x</i><sub><i>i</i></sub>,<i>y</i><sub><i>i</i></sub>≤<i>B</i>-1;<i><b>m</b></i><sup>0</sup>表示只包含平移分量的初始运动向量,且<i><b>m</b></i><sup>0</sup>=(<i>m</i><sub>1</sub>,0,…,<i>m</i><sub><i>p</i></sub><sub>/2+1</sub>,0,…);<i>Th</i>表示预设的迭代次数阈值;<i>R</i>′(·)表示参考帧中位于坐标“·”处的2 b深度的像素值;8 b深度像素的菱形搜索和弹性运动估计的搜索窗口尺寸为<i>W</i>×<i>W</i>像素.</p>
                </div>
                <div class="area_img" id="173">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_173.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 本文提出的2 b弹性运动估计流程图" src="Detail/GetImg?filename=images/JFYZ201911016_173.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 本文提出的2 b弹性运动估计流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_173.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Flowchart of the proposed 2 b elastic 
 motion estimation</p>

                </div>
                <h3 id="174" name="174" class="anchor-tag"><b>7 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="175">为了验证本文算法的有效性,以通用中间格式(common intermediate format, CIF)、4CIF和高清格式的34个标准视频序列(见表4)的1～90f为例进行实验,并将结果与基于8 b深度像素的菱形运动估计<citation id="372" type="reference"><link href="335" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>(简称8 b-DS)、基于8 b深度像素的块平移全搜索(简称8 b-FS)、基于8 b深度像素的弹性运动估计<citation id="373" type="reference"><link href="305" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>(简称8 b-Elastic)、基于传统2 b深度像素的块平移全搜索算法<citation id="374" type="reference"><link href="331" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>(简称2 b-FS)以及未引进自适应初始步长的本文算法(简称2 b-Elastic-NAStep)进行比较.</p>
                </div>
                <div class="p1">
                    <p id="176">实验参数选取为:搜索窗口为33×33像素,宏块尺寸为<i>B</i>=16像素,这与文献<citation id="375" type="reference">[<a class="sup">16</a>,<a class="sup">29</a>,<a class="sup">31</a>]</citation>的参数取值相同,也是视频编码器的典型设置.为了在预测精度和收敛速度之间实现折中,令迭代次数阈值<i>Th</i>=5,7.2节还将对此进行深入讨论.同时,为公平起见,将传统8 b-Elastic的迭代次数也设置为5次.运动补偿质量采用PSNR进行评价.</p>
                </div>
                <div class="area_img" id="177">
                    <p class="img_tit"><b>表4 测试视频序列名称及其格式</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Test Video Sequences' Names and Their Formats</b></p>
                    <p class="img_note"></p>
                    <table id="177" border="1"><tr><td><br />Resolution</td><td> Sequence</td></tr><tr><td><br />352×288</td><td>Akiyo,Bowing,Coastguard,Football,Foreman,Hall,Highway,Husky,Ice,Intros_cif,Mobile,Mother_daug,Pamphlet,Paris,Sign_irene,Soccer,Stefan,Students,Tempete,Tennis,Vtc1nw,Waterfall</td></tr><tr><td><br />704×576</td><td>Crew,City,Harbour</td></tr><tr><td><br />832×480</td><td>BQmall,Flowervase</td></tr><tr><td><br />1280×720</td><td>sc_Robot,FourPeople,Johnny,KristenAndSara</td></tr><tr><td><br />960×540</td><td>BQTerrace,Cactus,ParkScene</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="178" name="178"><b>7.1 运动估计/补偿质量的比较</b></h4>
                <div class="p1">
                    <p id="179">表5罗列了各个测试序列的亮度分量采用不同运动估计算法所得到的平均PSNR.从表5可见,相对于传统的2 b深度像素的全搜索算法2 b-FS<citation id="376" type="reference"><link href="331" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>,未引进自适应初始步长的本文算法2 b-Elastic-NAStep将PSNR平均提高了1.15 dB,表明基于Prewitt算子的2 b变换和2 b深度像素的弹性运动模型能够进行更有效的运动估计/补偿.2 b-Elastic-NAStep算法的平均PSNR比传统的8 b深度弹性运动估计8 b-Elastic<citation id="377" type="reference"><link href="305" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提高了0.46 dB,其根本原因在于8 b像素的匹配误差曲面富含局部极值点,在缺少初始搜索的情况下易陷入局部最优,并且8 b匹配误差曲面的下降梯度为高斯-牛顿法提供的迭代驱动力不足,收敛速度较慢;而2 b-Elastic-NAStep算法则利用8 b-DS计算弹性运动向量的水平和竖直分量,将起始搜索点置入全局最优点的单调区间,再沿着梯度下降方向进行迭代,这表明起始搜索点对于提高弹性运动估计的精度有重要作用,该结论与文献<citation id="378" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">22</a>]</citation>的研究结果一致.同时,2 b-Elastic-NAStep算法的平均PSNR较之8 b深度像素的菱形运动估计8 b-DS高出0.90 dB,并且比8 b深度像素的块平移全搜索8 b-FS提高0.23 dB,说明本文提出的低位深度弹性运动模型在初始搜索的基础上取得了进一步的性能增益.在引进了自适应初始步长之后,本文算法的运动补偿PSNR比2 b-Elastic-NAStep又提高了0.92 dB,这表明通过自适应步长实现黑塞矩阵对迭代过程的控制,有助于弹性运动估计收敛到全局最优解,进而表现出与8 b深度像素的阻尼高斯-牛顿法相近的准确程度.</p>
                </div>
                <div class="p1">
                    <p id="180">图7给出了Akiyo,Husky,City,Flowervase序列的PSNR逐帧比较情况.其中,Akiyo序列仅含有局部慢速运动,且细节简单;Husky序列则与之相反,前景具有较大幅度的平移运动且纹理复杂性高;City序列含有摄像机的中速摇摄运动和丰富的细节信息;而Flowervase序列则包含摄像机的慢速拉摄运动和中等复杂性的纹理.如图7所示,尽管4个序列的运动类型、速度和纹理复杂度各有不同,本文算法的运动补偿质量均较为稳定,在绝大部分情况下都取得了最高的PSNR,而其他算法的运动估计精度却会随着视频特点的不同出现一定波动.</p>
                </div>
                <div class="area_img" id="181">
                    <p class="img_tit"><b>表5 运动补偿的PSNR 比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Motion-Compensated PSNR Comparison</b></p>
                    <p class="img_note"></p>
                    <table id="181" border="1"><tr><td><br />Sequence</td><td>8 b-FS</td><td>8 b-DS</td><td>8 b-Elastic</td><td>2 b-FS</td><td>2 b-Elastic-NAStep</td><td>Proposed</td></tr><tr><td><br />Akiyo</td><td>42.67</td><td>42.65</td><td>39.99</td><td>42.23</td><td>41.91</td><td>44.41</td></tr><tr><td><br />Bowing</td><td>42.39</td><td>40.78</td><td>38.57</td><td>39.65</td><td>40.40</td><td>42.88</td></tr><tr><td><br />Coastguard</td><td>29.71</td><td>29.19</td><td>30.93</td><td>29.30</td><td>30.64</td><td>30.97</td></tr><tr><td><br />Football</td><td>27.37</td><td>25.52</td><td>25.37</td><td>25.76</td><td>27.09</td><td>27.10</td></tr><tr><td><br />Foreman</td><td>33.52</td><td>32.47</td><td>30.25</td><td>31.97</td><td>33.43</td><td>34.26</td></tr><tr><td><br />Hall</td><td>34.48</td><td>34.37</td><td>34.92</td><td>33.37</td><td>34.74</td><td>36.14</td></tr><tr><td><br />Highway</td><td>36.08</td><td>34.63</td><td>30.63</td><td>33.97</td><td>35.88</td><td>36.42</td></tr><tr><td><br />Husky</td><td>19.70</td><td>19.17</td><td>19.83</td><td>19.46</td><td>20.93</td><td>20.95</td></tr><tr><td><br />Ice</td><td>30.99</td><td>30.11</td><td>29.47</td><td>29.10</td><td>31.84</td><td>32.08</td></tr><tr><td><br />Intros_cif</td><td>37.30</td><td>36.36</td><td>32.71</td><td>36.29</td><td>37.87</td><td>38.48</td></tr><tr><td><br />Mobile</td><td>23.96</td><td>23.58</td><td>27.02</td><td>23.61</td><td>25.11</td><td>25.34</td></tr><tr><td><br />Mother_daug</td><td>40.26</td><td>39.95</td><td>42.08</td><td>39.45</td><td>40.78</td><td>41.76</td></tr><tr><td><br />Pamphlet</td><td>43.12</td><td>41.87</td><td>41.85</td><td>40.88</td><td>38.83</td><td>43.86</td></tr><tr><td><br />Paris</td><td>30.70</td><td>30.50</td><td>32.38</td><td>30.17</td><td>29.47</td><td>32.27</td></tr><tr><td><br />Sign_irene</td><td>33.56</td><td>32.95</td><td>34.59</td><td>32.59</td><td>34.65</td><td>34.70</td></tr><tr><td><br />Soccer</td><td>29.61</td><td>27.79</td><td>28.42</td><td>28.32</td><td>29.67</td><td>29.81</td></tr><tr><td><br />Stefan</td><td>25.90</td><td>24.45</td><td>24.90</td><td>25.44</td><td>25.95</td><td>26.22</td></tr><tr><td><br />Students</td><td>39.49</td><td>39.40</td><td>41.09</td><td>38.79</td><td>38.93</td><td>41.16</td></tr><tr><td><br />Tempete</td><td>27.75</td><td>27.37</td><td>29.32</td><td>27.29</td><td>28.87</td><td>29.21</td></tr><tr><td><br />Tennis</td><td>28.91</td><td>27.16</td><td>28.21</td><td>27.95</td><td>28.74</td><td>29.05</td></tr><tr><td><br />Vtc1nw</td><td>44.70</td><td>44.70</td><td>42.08</td><td>44.01</td><td>43.77</td><td>46.46</td></tr><tr><td><br />Waterfall</td><td>35.53</td><td>35.52</td><td>39.43</td><td>35.41</td><td>36.64</td><td>37.28</td></tr><tr><td><br />Crew</td><td>32.36</td><td>31.64</td><td>32.17</td><td>30.93</td><td>33.48</td><td>33.53</td></tr><tr><td><br />City</td><td>30.86</td><td>29.46</td><td>28.77</td><td>30.29</td><td>31.06</td><td>31.24</td></tr><tr><td><br />Harbour</td><td>28.10</td><td>27.79</td><td>30.23</td><td>27.45</td><td>29.35</td><td>29.55</td></tr><tr><td><br />BQmall</td><td>29.63</td><td>28.22</td><td>28.59</td><td>28.71</td><td>29.56</td><td>30.14</td></tr><tr><td><br />Flowervase</td><td>37.42</td><td>37.34</td><td>36.24</td><td>35.71</td><td>37.66</td><td>39.10</td></tr><tr><td><br />sc_Robot</td><td>32.20</td><td>32.22</td><td>32.75</td><td>32.89</td><td>33.93</td><td>34.36</td></tr><tr><td><br />FourPeople</td><td>38.43</td><td>38.17</td><td>39.86</td><td>37.82</td><td>38.92</td><td>39.99</td></tr><tr><td><br />Johnny</td><td>38.83</td><td>38.61</td><td>39.71</td><td>38.08</td><td>39.71</td><td>40.37</td></tr><tr><td><br />KristenAndSara</td><td>39.38</td><td>39.16</td><td>41.01</td><td>38.71</td><td>39.47</td><td>40.93</td></tr><tr><td><br />BQTerrace</td><td>25.51</td><td>25.31</td><td>26.60</td><td>24.96</td><td>26.59</td><td>27.03</td></tr><tr><td><br />Cactus</td><td>29.53</td><td>28.95</td><td>30.98</td><td>28.57</td><td>30.52</td><td>30.84</td></tr><tr><td><br />ParkScene</td><td>29.98</td><td>29.57</td><td>31.14</td><td>29.43</td><td>31.08</td><td>31.18</td></tr><tr><td><br />Average</td><td>33.23</td><td>32.56</td><td>33.00</td><td>32.31</td><td>33.46</td><td>34.38</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="182">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_182.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 Akiyo,Husky,City,Flowervase的前90帧采用不同运动估计算法所得到的PSNR比较" src="Detail/GetImg?filename=images/JFYZ201911016_182.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 Akiyo,Husky,City,Flowervase的前90帧采用不同运动估计算法所得到的PSNR比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_182.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 PSNR comparison among different algorithms on the first 90 frames of Akiyo, Husky, City, and Flowervase</p>

                </div>
                <div class="p1">
                    <p id="183">需要指出,作为逆黑塞矩阵的1阶近似,本文的自适应步长对于前景运动慢、纹理细节简单或者含有慢速摇摄、拉摄运动的视频(如Akiyo,Johnny,Flowervase)尤为有效,而对于含有快速运动和复杂纹理的视频(如Husky和City),其性能增益则不够明显.究其原因在于,后者的匹配误差曲面非常复杂,导致每次迭代的最优步长之间存在较大差异,尤其当迭代过程从搜索起始点所在的单调区间进入其他单调区间时,初始步长的普适性难免会受到影响.这也是除了像素深度降采样这个原因以外,本文算法在Mobile,Waterfall,Harbour等序列上的运动补偿PSNR低于传统8 b-Elastic运动估计的根本缘故.当然,作为一种基于低位深度像素的快速运动估计算法,本文工作的基本目的是在计算量和运动估计精度之间尽量实现折中,而不是通过精确估计阻尼步长来取得最理想的补偿质量.从这个意义上讲,本文提出的低位深度的弹性模型及其初始步长的自适应计算能够满足较低计算负载下的弹性运动估计需要.</p>
                </div>
                <h4 class="anchor-tag" id="184" name="184"><b>7.2 收敛速度与迭代次数的讨论</b></h4>
                <div class="p1">
                    <p id="185">收敛速度是衡量弹性运动估计效率的指标之一.图8所示为Akiyo,Husky,City序列第2帧采用本文算法的前15次迭代结果.从图8中能够发现,对于运动幅度小、细节简单的Akiyo序列,本文算法在第1次迭代后就趋于收敛;对于运动幅度较大、纹理复杂的Husky序列,运动补偿的PSNR随着迭代次数的增加而不断升高,但是经过5次迭代就已达到最高PSNR值的99.97%;而对于含有摇摄运动且纹理丰富的City序列,本文算法在第8次迭代时取得了最高的运动补偿质量,之后出现PSNR的下降,不过在第5次迭代后已达到PSNR峰值的99.99%;由于Flowervase序列的情况与City类似,这里不再赘述.图8结果表明,一方面,本文算法在视频具有不同运动模式和空间分布特点的情况下,均能取得较快的收敛速度.另一方面,视频的运动幅度和模式,以及空间纹理复杂性对本文算法的收敛速度存在一定影响:当匹配误差曲面在全局/局部最优解附近呈现单峰分布时(如Akiyo),本文算法将快速收敛,这与3.2节所讨论的2 b匹配误差曲面具有“区域内平滑、区域间锐化”的分布特点一致,下降梯度能提供足够的迭代驱动力;反之,当迭代过程需越过不同的单峰区间时,可能引起运动补偿质量的波动甚至小幅下降.这种情况与7.1节末尾的讨论一致,源于本文为了节省计算量,仅求解1次自适应步长并且未对相邻2次迭代的均方误差进行比较(若设1个视频帧包含<i>N</i>个像素,则计算均方误差的时间复杂度为<i>O</i>(<i>Th</i>×<i>N</i>)).</p>
                </div>
                <div class="area_img" id="186">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201911016_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 Akiyo,Husky,City的第2帧的前15次迭代结果" src="Detail/GetImg?filename=images/JFYZ201911016_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 Akiyo,Husky,City的第2帧的前15次迭代结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201911016_186.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Result of the second frame of Akiyo, Husky, 
 and City during the first 15 iterations</p>

                </div>
                <div class="p1">
                    <p id="187">考虑到本文算法经过5次迭代即可获得超过最优补偿质量99%的PSNR,并且此时迭代过程在很大概率下仍然处于起始搜索点的单调区间内,自适应步长对<mathml id="231"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Η</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>|</mo></mrow></mrow></math></mathml>具有较高的逼近程度,我们在实验中将设置迭代次数阈值<i>Th</i>=5.同时,经过2～3次迭代后,本文算法就能够达到与8 b-FS相当的PSNR,这也表明本文基于Prewitt梯度算子的像素深度转换方法保持了视频帧的纹理特征,并未由于深度降采样导致运动估计精度的明显下降,有效避免了传统像素深度转换方法(如文献<citation id="379" type="reference">[<a class="sup">28</a>,<a class="sup">29</a>]</citation>)产生大面积平滑区时陷入局部最优的现象.</p>
                </div>
                <h4 class="anchor-tag" id="188" name="188"><b>7.3 计算复杂度分析</b></h4>
                <div class="p1">
                    <p id="189">设宏块尺寸为<i>B</i>×<i>B</i>像素,搜索窗口为<i>W</i>×<i>W</i>像素,则不同运动估计算法处理1个宏块的计算量为:</p>
                </div>
                <div class="p1">
                    <p id="190">1) 8 b-FS和2 b-FS的时间复杂度均为<i>O</i>(<i>B</i><sup>2</sup><i>W</i><sup>2</sup>).另外,2 b-FS在像素深度变换阶段还需<i>O</i>(<i>B</i><sup>2</sup>)的复杂度.</p>
                </div>
                <div class="p1">
                    <p id="191">2) 由文献<citation id="380" type="reference">[<a class="sup">31</a>,<a class="sup">32</a>]</citation>可知,8 b-DS的计算复杂度约为8 b-FS的7%,即<i>O</i>(0.07<i>B</i><sup>2</sup><i>W</i><sup>2</sup>).</p>
                </div>
                <div class="p1">
                    <p id="192">3) 用高斯-牛顿法求解8 b深度弹性运动模型的每次迭代需计算偏导数、黑塞矩阵、逆矩阵、矩阵乘法、双线性插值和当前的运动补偿误差,其渐近时间复杂度分别为<i>O</i>(<i>pB</i><sup>2</sup>),<i>O</i>(<i>p</i><sup>2</sup><i>B</i><sup>2</sup>),<i>O</i>(<i>p</i><sup>3</sup>),<i>O</i>(<i>pB</i><sup>2</sup>),<i>O</i>(<i>B</i><sup>2</sup>),<i>O</i>(<i>B</i><sup>2</sup>).</p>
                </div>
                <div class="p1">
                    <p id="193">4) 由于省去了黑塞矩阵及其逆矩阵的计算,本文算法的每次迭代过程只需求解偏导数、向量乘法、双线性插值和运动补偿误差,其渐近时间复杂度分别为<i>O</i>(<i>pB</i><sup>2</sup>),<i>O</i>(<i>pB</i><sup>2</sup>),<i>O</i>(<i>B</i><sup>2</sup>),<i>O</i>(<i>B</i><sup>2</sup>),基于菱形搜索的初始点预测还需约为<i>O</i>(0.07<i>B</i><sup>2</sup><i>W</i><sup>2</sup>)的计算复杂度.</p>
                </div>
                <div class="p1">
                    <p id="194">当搜索窗口<i>W</i>=33、块尺寸<i>B</i>=16、迭代次数阈值<i>Th</i>=5时,本文算法的时间复杂度约为8 b-FS算法和2 b-FS算法的15.26%、8 b-Elastic算法的39.58%,但是高于8 b-DS.若进一步将迭代次数<i>Th</i>减少到2～3次,本文算法则可在8 b-FS算法的10.31%～11.60%的时间复杂度内,获得与之相当的运动估计精度.</p>
                </div>
                <div class="p1">
                    <p id="195">具体地,表6给出了各种算法求解1个块的运动向量所需的平均操作次数,其中运动估计阶段的“Addition”操作包括8 b定点加法和浮点加法.从表6可见,本文方法的操作次数显著少于8 b-FS,2 b-FS和8 b-Elastic.尽管8 b加法、2 b加法、乘法、取绝对值、比较、位运算等各类操作所需的CPU周期数和计算代价存在明显差异,可是这些指标依赖于具体的硬件设计和指令集,已超出本文的讨论范围,所以在此不予进一步的定量比较,详细了解可参见文献<citation id="381" type="reference">[<a class="sup">28</a>]</citation>.不过,考虑到本文算法采用位操作和比较操作来求解偏导数、向量乘法和运动补偿误差,其计算开销将低于8 b像素的加法和乘法,且有利于实现多个像素的并行计算,其实际开销比渐近时间复杂度更低.</p>
                </div>
                <div class="area_img" id="196">
                    <p class="img_tit"><b>表6 不同运动估计算法对每个块的平均操作次数比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 6 Average Operation Number Comparison Among Various Motion Estimation Algorithms on Each Block</b></p>
                    <p class="img_note"></p>
                    <table id="196" border="1"><tr><td><br />Stage</td><td>Operation</td><td>8 b-FS</td><td>8 b-DS</td><td>8 b-Elastic</td><td>2 b-FS</td><td>Proposed</td></tr><tr><td rowspan="5"><br />Bit-depth<br />Conversion<br />Stage</td><td><br />Fix-Point Addition</td><td>0</td><td>0</td><td>0</td><td>1 076</td><td>1 715</td></tr><tr><td><br />Multiplication</td><td>0</td><td>0</td><td>0</td><td>264</td><td>263</td></tr><tr><td><br />Comparison</td><td>0</td><td>0</td><td>0</td><td>768</td><td>640</td></tr><tr><td><br />Absolute</td><td>0</td><td>0</td><td>0</td><td>0</td><td>512</td></tr><tr><td><br />Square</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td rowspan="6"><br />Motion<br />Estimation<br />Stage</td><td><br />Addition</td><td>557 568</td><td>41 093</td><td>119 890</td><td>0</td><td>41 269</td></tr><tr><td><br />2 b Addition</td><td>0</td><td>0</td><td>0</td><td>278 784</td><td>32 512</td></tr><tr><td><br />Absolute</td><td>278 784</td><td>20 546</td><td>0</td><td>0</td><td>20 562</td></tr><tr><td><br />Comparison</td><td>0</td><td>0</td><td>0</td><td>0</td><td>11 680</td></tr><tr><td><br />Multiplication</td><td>0</td><td>0</td><td>155 840</td><td>0</td><td>60</td></tr><tr><td><br />Bitwise Operation</td><td>0</td><td>0</td><td>0</td><td>836 352</td><td>20 480</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="197" name="197" class="anchor-tag"><b>8 结 论</b></h3>
                <div class="p1">
                    <p id="198">为进一步改善弹性运动估计的实时性,本文引进了基于Prewitt梯度算子和正态分布的像素深度变换,以及基于位操作和比较操作的矩阵乘法和偏导运算,推导出高斯-牛顿法的自适应初始步长的1阶逼近方法,从而提出了一种基于2 b深度像素的弹性运动估计.其优点在于尽可能地简化求解弹性运动模型的高斯-牛顿法,用异或运算替代乘法运算,且无需反复计算黑塞矩阵及其逆矩阵.实验结果表明,该算法的运动补偿质量和计算效率优于8 b深度像素的块平移全搜索算法、菱形搜索算法、传统弹性搜索算法,以及传统2 b深度像素的块平移全搜索算法.</p>
                </div>
                <div class="p1">
                    <p id="199">另外,本文算法仍存在若干问题可臻完善,如快速预测起始搜索点、根据匹配误差曲面的曲率变化来自适应地更新初始步长,以及设计能够高效执行本文算法的硬件电路等,我们将在今后的工作中进一步深入研究这些问题的解决思路.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="275">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201501004&amp;v=MjQ1OTBSc0Z5em5VTHZKTHl2U2RMRzRIOVRNcm85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Ma Siwei.History and recent development of AVS video coding standards[J].Journal of Computer Research and Development,2015,52(1):27- 37 (in Chinese)(马思伟.AVS视频编码标准技术回顾及最新进展[J].计算机研究与发展,2015,52(1):27- 37)
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                Sinangil M E,Sze V,Zhou Minhua,et al.Cost and coding efficient motion estimation design considerations for high efficiency video coding (HEVC) standard[J].IEEE Journal of Selected Topics in Signal Processing,2013,7(6):1017- 1028
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                Narroschke M,Swoboda R.Extending HEVC by an affine motion model[C] //Proc of the 30th PCS.Piscataway,NJ:IEEE,2013:321- 324
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_4" >
                                    <b>[4]</b>
                                Ahmmed A,Hannuksela M M,Gabbouj M.Fisheye video coding using elastic motion compensated reference frames[C] //Proc of the 23rd IEEE ICIP.Piscataway,NJ:IEEE,2016:2027- 2031
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                Liu Dong,Wu Feng.Advances and trends of video coding technologies[J].Communications of the CCF,2016,12(6):20- 23 (in Chinese)(刘东,吴枫.视频编码技术发展与趋势[J].中国计算机学会通讯,2016,12(6):20- 23)
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                Ahmmed A,Xu Rui,Naman A T,et al.Motion segmentation initialization strategies for bi-directional inter-frame prediction[C] //Proc of the 15th IEEE MMSP.Piscataway,NJ:IEEE,2013:58- 63
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200005014&amp;v=MTMxOTVuVUx2SklUZlRlN0c0SHRITXFvOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>Wu Feng,Gao Peng,Gao Wen.Motion estimation technologies based on mesh model[J].Acta Electronica Sinica,2000,28(5):47- 51 (in Chinese)(吴枫,高鹏,高文.基于网格模型的运动估计技术[J].电子学报,2000,28(5):47- 51)
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                Al-Regib G,Altunbasak Y,Mersereau R M.Hierarchical motion estimation with content-based meshes[J].IEEE Transactions on Circuits and System for Video Technology,2003,13(10):1000- 1005
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501985863&amp;v=MjY3NzltVUwzSUpGd1hiaE09TmlmT2ZiSzdIdEROcW85RWJlTUtCSG82b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Cui Suxia,Wang Yonghui,Fowler J E.Motion estimation and compensation in the redundant-wavelet domain using triangle meshes[J].Signal Processing:Image Communication,2006,21(7):586- 598
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                Huang Han,Woods J W,Zhao Yao,et al.Control-point representation and differential coding affine-motion compensation[J].IEEE Transactions on Circuits and Systems for Video Technology,2013,23(10):1651- 1660
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                Li Li,Li Houqiang,Liu Dong,et al.An efficient four-parameter affine motion model for video coding[J].IEEE Transactions on Circuits and Systems for Video Technology,2018,28(8):1934- 1947
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201108001&amp;v=MjY1NjdlWmVSc0Z5em5VTHZKUHlyZmJMRzRIOURNcDQ5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Zheng Jiali,Qin Tuanfa,Ni Guangnan.Adaptive global motion estimation method based on rate distortion optimization[J].Journal of Image and Graphics,2011,16(8):1346- 1352 (in Chinese)(郑嘉利,覃团发,倪光南.结合率失真优化的自适应全局运动估计方法[J].中国图象图形学报,2011,16(8):1346- 1352)
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                Po L M,Wong K M,Cheung K W,et al.Subsampled block-matching for zoom motion compensated prediction[J].IEEE Transactions on Circuits and Systems for Video Technology,2010,20(11):1625- 1637
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                Yuan Hui,Liu Ju,Sun Jiande,et al.Affine model based motion compensation prediction for zoom[J].IEEE Transactions on Multimedia,2012,14(4):1370- 1375
                            </a>
                        </p>
                        <p id="303">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                Kim H S,Lee J H,Kim C K,et al.Zoom motion estimation using block-based fast local area scaling[J].IEEE Transactions on Circuits and Systems for Video Technology,2012,22(9):1280- 1291
                            </a>
                        </p>
                        <p id="305">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                Muhit A A,Pickering M R,Frater M R,et al.Video coding using elastic motion model and larger blocks[J].IEEE Transactions on Circuits and Systems for Video Technology,2010,20(5):661- 672
                            </a>
                        </p>
                        <p id="307">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501263353&amp;v=MTg1MjQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUwzSUpGd1hiaE09TmlmT2ZiSzdIdEROcW85RVp1ME1EM2s2b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>Muhit A A,Pickering M R,Frater M R,et al.Video coding using fast geometry-adaptive partitioning and an elastic motion model[J].Journal of Visual Communication and Image Representation,2012,23(1):31- 41
                            </a>
                        </p>
                        <p id="309">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014223317.nh&amp;v=MDgzODRSTE9lWmVSc0Z5em5VTHZKVkYyNkdyRzZIZExOcUpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>Deng Binyou.Study on video compression based on elastic motion model[D].Xiamen:Xiamen University,2014 (in Chinese)(邓斌攸.基于弹性运动模型的视频压缩算法研究[D].厦门:厦门大学,2014)
                            </a>
                        </p>
                        <p id="311">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201611018&amp;v=MTEyMzNvOUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUx2Sk55ZlRiTEc0SDlmTnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Song Chuanming,Zhao Changwei,Liu Dan,et al.Elastic motion estimation of video using improved Gauss-Newton method[J].Journal of Software,2016,27(11):2946- 2960 (in Chinese)(宋传鸣,赵长伟,刘丹,等.采用改进高斯-牛顿法的视频弹性运动估计[J].软件学报,2016,27(11):2946- 2960)
                            </a>
                        </p>
                        <p id="313">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015637459.nh&amp;v=MDE0MTJPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5em5VTHZKVkYyNkc3VzdHZFhKcHBFYlBJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>Zhao Changwei.Research on motion estimation algorithm using elastic model[D].Dalian:Liaoning Normal University,2015 (in Chinese)(赵长伟.基于弹性模型的运动估计算法研究[D].大连:辽宁师范大学,2015)
                            </a>
                        </p>
                        <p id="315">
                            <a id="bibliography_21" >
                                    <b>[21]</b>
                                Huang Han.Research on inter/intra prediction and optimization techniques in HEVC[D].Beijing:Beijing Jiaotong University,2013 (in Chinese)(黄晗.HEVC帧间/帧内预测及优化技术研究[D].北京:北京交通大学,2013)
                            </a>
                        </p>
                        <p id="317">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201907019&amp;v=MDgxMTQ5RWJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5em5VTHZKTnlmVGJMRzRIOWpNcUk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>Song Chuanming,Min Xin,Yan Xiaohong,et al.Fast elastic motion estimation using improved Levenberg-Marquardt method[J/OL].Journal of Software,2019.[2019-02-09].http://www.jos.org.cn/1000-9825/5487.htm (in Chinese)(宋传鸣,闵新,闫小红,等.采用改进Levenberg-Marquardt法的快速弹性运动估计[J/OL].软件学报,2019.[2019-02-09].http://www.jos.org.cn/1000-9825/5487.htm)
                            </a>
                        </p>
                        <p id="319">
                            <a id="bibliography_23" >
                                    <b>[23]</b>
                                Haque M N,Biswas M,Pickering M R,et al.A low complexity algorithm for global motion parameter estimation targeting hardware implementation[C] //Proc of the 11th DICTA.Piscataway,NJ:IEEE,2009:1- 5
                            </a>
                        </p>
                        <p id="321">
                            <a id="bibliography_24" >
                                    <b>[24]</b>
                                Haque M N,Biswas M,Pickering M R,et al.An adaptive low-complexity global motion estimation algorithm[C] //Proc of the 27th PCS.Piscataway,NJ:IEEE,2010:598- 601
                            </a>
                        </p>
                        <p id="323">
                            <a id="bibliography_25" >
                                    <b>[25]</b>
                                Haque M N,Biswas M,Pickering M R,et al.A low-complexity image registration algorithm for global motion estimation[J].IEEE Transactions on Circuits and Systems for Video Technology,2012,22(3):426- 433
                            </a>
                        </p>
                        <p id="325">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600363711&amp;v=MjEzMzJaZVp1SHlqbVVMM0lKRndYYmhNPU5pZk9mYks4SHRETXFZOUZaKzBNQzMwNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b>Song Chuanming,Guo Yanwen,Wang Xianghai,et al.Fuzzy quantization based bit transform for low bit-resolution motion estimation[J].Signal Processing:Image Communication,2013,28(10):1435- 1447
                            </a>
                        </p>
                        <p id="327">
                            <a id="bibliography_27" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201307006&amp;v=MDI5NzJPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5em5VTHZKTVRYVGJMRzRIOUxNcUk5RllvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[27]</b>Song Chuanming,Guo Yanwen,Wang Xianghai,et al.Motion estimation algorithm using 2 bit-depth pixel and fuzzy quantization[J].Journal on Communications,2013,34(7):59- 70 (in Chinese)(宋传鸣,郭延文,王相海,等.基于模糊量化和2 bit深度像素的运动估计算法[J].通信学报,2013,34(7):59- 70)
                            </a>
                        </p>
                        <p id="329">
                            <a id="bibliography_28" >
                                    <b>[28]</b>
                                He Zhongli,Tsui C Y,Chan K K,et al.Low-power VLSI design for motion estimation using adaptive pixel truncation[J].IEEE Transactions on Circuits Systems for Video Technology,2000,10(8):669- 678
                            </a>
                        </p>
                        <p id="331">
                            <a id="bibliography_29" >
                                    <b>[29]</b>
                                Ertürk A,Ertürk S.Two-bit transform for binary block motion estimation[J].IEEE Transactions on Circuits and Systems for Video Technology,2005,15(7):938- 946
                            </a>
                        </p>
                        <p id="333">
                            <a id="bibliography_30" >
                                    <b>[30]</b>
                                Diniz P S R.Adaptive Filtering:Algorithm and Practical Implementation[M].New York:Springer US,2013
                            </a>
                        </p>
                        <p id="335">
                            <a id="bibliography_31" >
                                    <b>[31]</b>
                                Zhu Shan,Ma K K.A new diamond search algorithm for fast block-matching motion estimation[J].IEEE Transactions on Image Processing,2000,9(2):287- 290
                            </a>
                        </p>
                        <p id="337">
                            <a id="bibliography_32" >
                                    <b>[32]</b>
                                Li Renxiang,Zeng Bing,Liou M L.A new three-step search algorithm for block motion estimation[J].IEEE Transactions on Circuits and Systems for Video Technology,1994,4(4):438- 442
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201911016" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201911016&amp;v=MzA1OTh2Skx5dlNkTEc0SDlqTnJvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpuVUw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EZk56MHY3S0E0RkFXczJ5OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

