

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127157028582500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201909003%26RESULT%3d1%26SIGN%3d%252fEnRnk78qX41fOEtlyqsVdqx7rI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201909003&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201909003&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201909003&amp;v=MjAyODhIOWpNcG85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5L25WNzdLTHl2U2RMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#70" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="&lt;b&gt;2 算法实现&lt;/b&gt; "><b>2 算法实现</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="&lt;b&gt;2.1 问题定义&lt;/b&gt;"><b>2.1 问题定义</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;2.2 生成式对抗网络GAN&lt;/b&gt;"><b>2.2 生成式对抗网络GAN</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;2.3 结构化数据表生成模型TableGAN&lt;/b&gt;"><b>2.3 结构化数据表生成模型TableGAN</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#122" data-title="&lt;b&gt;3 实验与分析&lt;/b&gt; "><b>3 实验与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="&lt;b&gt;3.1 数据集&lt;/b&gt;"><b>3.1 数据集</b></a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;3.2 分类模型&lt;/b&gt;"><b>3.2 分类模型</b></a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;3.3 基准算法&lt;/b&gt;"><b>3.3 基准算法</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;3.4 实验结果分析&lt;/b&gt;"><b>3.4 实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#169" data-title="&lt;b&gt;4 总结与工作展望&lt;/b&gt; "><b>4 总结与工作展望</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="图1 模型训练过程中的预测准确率">图1 模型训练过程中的预测准确率</a></li>
                                                <li><a href="#65" data-title="图2 使用合成数据集训练分类模型的流程图">图2 使用合成数据集训练分类模型的流程图</a></li>
                                                <li><a href="#94" data-title="图3 TableGAN模型示意图">图3 TableGAN模型示意图</a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;表1 实验数据集统计信息&lt;/b&gt;"><b>表1 实验数据集统计信息</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;表2 关于SF Crime数据集的描述&lt;/b&gt;"><b>表2 关于SF Crime数据集的描述</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;表3 关于Poker Hand数据集的描述&lt;/b&gt;"><b>表3 关于Poker Hand数据集的描述</b></a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;表4 分类模型在17个不同版本的训练集下的所有结果列表&lt;/b&gt;"><b>表4 分类模型在17个不同版本的训练集下的所有结果列表</b></a></li>
                                                <li><a href="#153" data-title="图5 使用随机森林在数据集SF Crime上的性能对比">图5 使用随机森林在数据集SF Crime上的性能对比</a></li>
                                                <li><a href="#157" data-title="图4 使用MLP在数据集SF Crime上的性能对比">图4 使用MLP在数据集SF Crime上的性能对比</a></li>
                                                <li><a href="#158" data-title="图6 使用决策树在数据集SF Crime上的性能对比">图6 使用决策树在数据集SF Crime上的性能对比</a></li>
                                                <li><a href="#161" data-title="图7 使用MLP在数据集Poker Hand上的性能对比">图7 使用MLP在数据集Poker Hand上的性能对比</a></li>
                                                <li><a href="#165" data-title="图8 使用随机森林在数据集Poker Hand上的性能对比">图8 使用随机森林在数据集Poker Hand上的性能对比</a></li>
                                                <li><a href="#166" data-title="图9 使用决策树在数据集Poker Hand上的性能对比">图9 使用决策树在数据集Poker Hand上的性能对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="13">


                                    <a id="bibliography_1" title="Tay Y C,Dai B T,Wang D T,et al.UpSizeR:Synthetically scaling an empirical relational database[J].Information Systems,2013,38(8):1168- 1183" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600210944&amp;v=MDM0MjJnOW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUwzSUoxd1FheEE9TmlmT2ZiSzlIOVBPcVk5Rlp1b1BCWA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Tay Y C,Dai B T,Wang D T,et al.UpSizeR:Synthetically scaling an empirical relational database[J].Information Systems,2013,38(8):1168- 1183
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_2" title="Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier gans[J].arXiv preprint arXiv:1610.09585,2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Conditional image synthesis with auxiliary classifier gans">
                                        <b>[2]</b>
                                        Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier gans[J].arXiv preprint arXiv:1610.09585,2016
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_3" title="Hawkins D M.The problem of overfitting[J].Journal of Chemical Information and Computer Sciences,2004,44(1):1- 12" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The problem of overfitting">
                                        <b>[3]</b>
                                        Hawkins D M.The problem of overfitting[J].Journal of Chemical Information and Computer Sciences,2004,44(1):1- 12
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_4" title="Vincent P,Larochelle H,Bengio Y,et al.Extracting and composing robust features with denoising autoencoders[C] //Proc of the 25th Int Conf on Machine Learning.New York:ACM,2008:1096- 1103" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Extracting and composing robust features with denoising autoencoders">
                                        <b>[4]</b>
                                        Vincent P,Larochelle H,Bengio Y,et al.Extracting and composing robust features with denoising autoencoders[C] //Proc of the 25th Int Conf on Machine Learning.New York:ACM,2008:1096- 1103
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_5" title="Eslami S M A,Heess N,Williams C K I,et al.The shape Boltzmann machine:A strong model of object shape[J].International Journal of Computer Vision,2014,107(2):155- 176" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14032100000892&amp;v=MDM5NzBNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTDNJSjF3UWF4QT1OajdCYXJLOEh0TE9ybzlGWk9zUEJIVTdvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Eslami S M A,Heess N,Williams C K I,et al.The shape Boltzmann machine:A strong model of object shape[J].International Journal of Computer Vision,2014,107(2):155- 176
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_6" title="Kingma D P,Welling M.Auto-encoding variational Bayes[J].arXiv preprint arXiv:1312.6114,2013" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Auto-encoding variational Bayes">
                                        <b>[6]</b>
                                        Kingma D P,Welling M.Auto-encoding variational Bayes[J].arXiv preprint arXiv:1312.6114,2013
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_7" title="Mnih V,Susskind J M,Hinton G E.Modeling natural images using gated MRFs[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(9):2206- 2222" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modeling Natural Images Using Gated MRFs">
                                        <b>[7]</b>
                                        Mnih V,Susskind J M,Hinton G E.Modeling natural images using gated MRFs[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(9):2206- 2222
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_8" title="Goodfellow I,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2014:2672- 2680" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">
                                        <b>[8]</b>
                                        Goodfellow I,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2014:2672- 2680
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_9" title="Mirza M,Osindero S.Conditional generative adversarial nets[J].arXiv preprint arXiv:1411.1784,2014" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Conditional generative adversarial nets">
                                        <b>[9]</b>
                                        Mirza M,Osindero S.Conditional generative adversarial nets[J].arXiv preprint arXiv:1411.1784,2014
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_10" title="Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier gans[J].arXiv preprint arXiv:1610.09585,2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Conditional image synthesis with auxiliary classifier gans">
                                        <b>[10]</b>
                                        Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier gans[J].arXiv preprint arXiv:1610.09585,2016
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_11" title="Patki N,Wedge R,Veeramachaneni K.The synthetic data vault[C] //Proc of the 3rd IEEE Int Conf on Data Science and Advanced Analytics (DSAA).Piscataway,NJ:IEEE,2016:399- 410" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The synthetic data vault">
                                        <b>[11]</b>
                                        Patki N,Wedge R,Veeramachaneni K.The synthetic data vault[C] //Proc of the 3rd IEEE Int Conf on Data Science and Advanced Analytics (DSAA).Piscataway,NJ:IEEE,2016:399- 410
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_12" title="Tay Y.Data generation for application-specific benchmarking[C] //Proc of the 37th Int Conf on Very Large Data Bases (VLDB).New York:ACM,2011:1470- 1473" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Data generation for application-specific benchmarking">
                                        <b>[12]</b>
                                        Tay Y.Data generation for application-specific benchmarking[C] //Proc of the 37th Int Conf on Very Large Data Bases (VLDB).New York:ACM,2011:1470- 1473
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_13" title="Tran T,Pham T,Carneiro G,et al.A Bayesian data augmentation approach for learning deep models[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2017:2794- 2803" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Bayesian data augmentation approach for learning deep models">
                                        <b>[13]</b>
                                        Tran T,Pham T,Carneiro G,et al.A Bayesian data augmentation approach for learning deep models[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2017:2794- 2803
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_14" title="Krizhevsky A,Sutskever I,Hinton G E.Imagenet classification with deep convolutional neural networks[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2012:1097- 1105" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[14]</b>
                                        Krizhevsky A,Sutskever I,Hinton G E.Imagenet classification with deep convolutional neural networks[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2012:1097- 1105
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_15" title="Prechelt L.Automatic early stopping using cross validation:Quantifying the criteria[J].Neural Networks,1998,11(4):761- 767" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070811&amp;v=MjIwMjhheEE9TmlmT2ZiSzdIdERPckk5RlpPd1BCSDA0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTDNJSjF3UQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        Prechelt L.Automatic early stopping using cross validation:Quantifying the criteria[J].Neural Networks,1998,11(4):761- 767
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_16" title="Srivastava N,Hinton G,Krizhevsky A,et al.Dropout:A simple way to prevent neural networks from overfitting[J].The Journal of Machine Learning Research,2014,15(1):1929- 1958" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dropout:A simple way to prevent neural networks from overfitting">
                                        <b>[16]</b>
                                        Srivastava N,Hinton G,Krizhevsky A,et al.Dropout:A simple way to prevent neural networks from overfitting[J].The Journal of Machine Learning Research,2014,15(1):1929- 1958
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_17" title="Loughrey J,Cunningham P.Using early-stopping to avoid overfitting in wrapper-based feature selection employing stochastic search[R].Ireland:Trinity College Dublin,Department of Computer Science,2005" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using early-stopping to avoid overfitting in wrapper-based feature selection employing stochastic search">
                                        <b>[17]</b>
                                        Loughrey J,Cunningham P.Using early-stopping to avoid overfitting in wrapper-based feature selection employing stochastic search[R].Ireland:Trinity College Dublin,Department of Computer Science,2005
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_18" title="Nowozin S,Cseke B,Tomioka R.f-gan:Training generative neural samplers using variational divergence minimization[C] // Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2016:271- 279" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=F-gan:training generative neural samplers using variational divergence minimization">
                                        <b>[18]</b>
                                        Nowozin S,Cseke B,Tomioka R.f-gan:Training generative neural samplers using variational divergence minimization[C] // Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2016:271- 279
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_19" title="Husz&#225;r F.How (not) to train your generative model:Scheduled sampling,likelihood,adversary?[J].arXiv preprint arXiv:1511.05101,2015" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=How (not) to train your generative model:Scheduled sampling,likelihood,adversary?">
                                        <b>[19]</b>
                                        Husz&#225;r F.How (not) to train your generative model:Scheduled sampling,likelihood,adversary?[J].arXiv preprint arXiv:1511.05101,2015
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_20" title="Arjovsky M,Bottou L.Towards principled methods for training generative adversarial networks[J].arXiv preprint arXiv:1701.04862,2017" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards principled methods for training generative adversarial networks">
                                        <b>[20]</b>
                                        Arjovsky M,Bottou L.Towards principled methods for training generative adversarial networks[J].arXiv preprint arXiv:1701.04862,2017
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_21" title="Arjovsky M,Chintala S,Bottou L.Wasserstein gan[J].arXiv preprint arXiv:1701.07875,2017" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wasserstein gan">
                                        <b>[21]</b>
                                        Arjovsky M,Chintala S,Bottou L.Wasserstein gan[J].arXiv preprint arXiv:1701.07875,2017
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_22" title="Mukkamala M C,Hein M.Variants of RMSProp and adagrad with logarithmic regret bounds[J].arXiv preprint arXiv:1706.05507,2017" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Variants of RMSProp and adagrad with logarithmic regret bounds">
                                        <b>[22]</b>
                                        Mukkamala M C,Hein M.Variants of RMSProp and adagrad with logarithmic regret bounds[J].arXiv preprint arXiv:1706.05507,2017
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_23" title="Tieleman T,Hinton G.Divide the gradient by a running average of its recent magnitude[J].COURSERA:Neural Networks for Machine Learning,2012,4(2):26- 31" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Divide the gradient by a running average of its recent magnitude">
                                        <b>[23]</b>
                                        Tieleman T,Hinton G.Divide the gradient by a running average of its recent magnitude[J].COURSERA:Neural Networks for Machine Learning,2012,4(2):26- 31
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_24" title="Zhang Jiangwei,Tay Y C.Dscaler:Synthetically scaling a given relational database[C] //Proc of the 42nd Int Conf on Very Large Data Bases (VLDB).New York:ACM,2016:1671- 1682" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dscaler:Synthetically scaling a given relational database">
                                        <b>[24]</b>
                                        Zhang Jiangwei,Tay Y C.Dscaler:Synthetically scaling a given relational database[C] //Proc of the 42nd Int Conf on Very Large Data Bases (VLDB).New York:ACM,2016:1671- 1682
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(09),1832-1842 DOI:10.7544/issn1000-1239.2019.20180353            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于生成式对抗网络的结构化数据表生成模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AE%8B%E7%8F%82%E6%85%A7&amp;code=37987730&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宋珂慧</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%8E%B9&amp;code=08779868&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张莹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%B1%9F%E4%BC%9F&amp;code=42840450&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张江伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%A2%81%E6%99%93%E6%B4%81&amp;code=08109249&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">袁晓洁</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E5%BC%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0205377&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南开大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%96%B0%E5%8A%A0%E5%9D%A1%E5%9B%BD%E7%AB%8B%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0236701&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">新加坡国立大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在机器学习和数据库等领域,高质量数据集的合成一直以来是一个非常重要且充满挑战性的问题.其中,合成的高质量数据集可用来改善模型,尤其是深度学习模型的训练过程.一个健壮的模型训练过程需要大量已标注的数据集,获取这些数据集的一种方法是通过领域专家的手动标注,这种方法不仅代价大还容易出错,因此由模型自动合成高质量数据集的方法更为合理.近年来,由于计算机视觉领域的飞速发展,已经有不少致力于图像数据集合成的研究,但是这些模型不能直接应用在结构化数据表上,并且据调研,对这类数据的相关研究几乎没有.因此,提出了一个针对结构化数据表的生成模型TableGAN,该模型是生成式对抗网络(generative adversarial network, GAN)家族的一种变体,通过对抗训练的方式提高生成模型的性能.针对结构化数据的特征改变了传统GAN模型的内部结构,包括优化函数等,使其能够生成高质量的结构化数据用于改善模型的训练过程.通过在真实数据集上的大量实验表明了此模型的有效性,即在扩大后的数据集上训练模型的效果有明显提升.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">生成模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">生成式对抗网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *张莹,yingzhang@nankai.edu.cn;
                                </span>
                                <span>
                                    宋珂慧,songkehui@dbis.nankai.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61772289,U1836109);</span>
                    </p>
            </div>
                    <h1><b>A Generative Model for Synthesizing Structured Datasets Based on GAN</b></h1>
                    <h2>
                    <span>Song Kehui</span>
                    <span>Zhang Ying</span>
                    <span>Zhang Jiangwei</span>
                    <span>Yuan Xiaojie</span>
            </h2>
                    <h2>
                    <span>College of Computer Science, Nankai University</span>
                    <span>School of Computing, National University of Singapore</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Synthesizing high quality dataset has been a long-standing challenge in both machine learning and database community. One of the applications of high quality dataset synthesis is to improve the model training, especially deep learning models. A robust model training process requires a large annotated dataset. One way of acquiring a large annotated training set is via the domain experts' manual annotation, which is expensive and prone to mistakes. Therefore, as an alternative, automatic synthesis of high quality and similar dataset is much more plausible. Some efforts have been devoted for synthesizing image dataset due to the rapid development of computer vision. However, those models can not be applied to the structured data(numeric &amp; categorical table) directly. Moreover, little efforts have been payed to the numeric &amp; categorical table. Therefore, we propose TableGAN, the first generative model from GAN family, which improves the performance of the generative model with adversarial learning mechanism. TableGAN modifies the internal structure of traditional GAN targeting numeric &amp; categorical table, including the optimization function, to synthesize more high-quality training dataset samples for improving the effectiveness of the training models. Extensive experiments on real datasets show significant performance improvement for those models trained on the enlarged training datasets, and thus verify the effectiveness of our TableGAN.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=generative%20models&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">generative models;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=generative%20adversarial%20network(GAN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">generative adversarial network(GAN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">classification;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Song Kehui,born in 1994.PhD candidate. Her main research interests include database scaling,information retrieval and machine learning.&lt;image id="218" type="formula" href="images/JFYZ201909003_21800.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Zhang Ying,born in 1986.PhD,associate professor.Her main research interests include sentiment analysis,data mining, and information retrieval.&lt;image id="220" type="formula" href="images/JFYZ201909003_22000.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Zhang Jiangwei,born in 1990.PhD.His main research interests include database scaling,with particular focus on social network data.&lt;image id="222" type="formula" href="images/JFYZ201909003_22200.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Yuan Xiaojie,born in 1963.PhD,professor, PhD supervisor. Her main research interests include data management and data mining.&lt;image id="224" type="formula" href="images/JFYZ201909003_22400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-05-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61772289,U1836109);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="61">近年来,在机器学习和数据库等领域,高质量数据集的合成问题一直以来是一个非常重要且充满挑战性的问题<citation id="183" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>.合成的高质量数据集可用于很多场景,例如数据库性能基准测试(performance bench-marking)、降低数据挖掘成本以及改进模型训练过程等.其中,合成的高质量数据集可用来提升模型,尤其是深度学习模型的训练过程.</p>
                </div>
                <div class="p1">
                    <p id="62">在训练某个机器学习模型的过程中,当训练样本数量不足时,很容易出现过拟合<citation id="184" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>现象.过拟合现象往往由训练样本数量不足引起,导致模型中的复杂参数只能捕捉训练样本中十分具体的随机特征,导致一些细微的误差都会对其产生巨大影响,因此在训练的过程中会出现模型在验证集上表现变差的现象.图1展示了分类器多层感知机(multi-layer perception, MLP)在数据集“Poker Hand”上的预测准确率曲线,从图1两条曲线的走向可以看出,在迭代6次之后,在训练集上的准确率尽管稳步上升,但在验证集上的准确率已经开始下降,也就是出现了过拟合现象,2条曲线之间的区域大小反映了过拟合现象的严重程度.</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模型训练过程中的预测准确率" src="Detail/GetImg?filename=images/JFYZ201909003_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 模型训练过程中的预测准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 An example of model performance</p>

                </div>
                <div class="p1">
                    <p id="64">为了防止过拟合现象发生,需要将原有的训练集扩大.其中一种方法是领域专家手动标注更多的数据样本,但这既浪费人力又容易出错;另一种自动合成更多数据样本的方法更为可行.如图2所示,原始训练样本首先作为生成器(generator)的输入,生成器输出的合成训练样本和原始训练样本一起组成扩大后的训练集,最终将这个扩大后的训练集用于分类模型的训练.由于合成数据集质量较高且保留了原始数据样本中的重要特征,用扩大后的样本对分类模型进行训练的过程将更加稳定,并能够解决因训练样本不足引起的过拟合问题,提升了分类模型在验证集上的准确率.因此,设计一个性能良好的生成器是图2所示整个工作流程的重要环节.</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 使用合成数据集训练分类模型的流程图" src="Detail/GetImg?filename=images/JFYZ201909003_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 使用合成数据集训练分类模型的流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The workflow of training classifiers using 
 synthesized datasets</p>

                </div>
                <div class="p1">
                    <p id="66">近年来,有不少与生成模型相关的研究<citation id="189" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>,其中备受瞩目的是生成式对抗网络(generative adversarial network, GAN)<citation id="185" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>.生成式对抗网络是Goodfellow等人<citation id="186" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>在2014年提出的一种生成模型,并被广泛应用于对原始样本分布特征的无监督式学习.目前为止,有不少针对GAN的相关研究,并衍生出若干GAN模型的变种,如C-GAN<citation id="187" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和AC-GAN<citation id="188" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>等,都能够生成高质量的图片数据.</p>
                </div>
                <div class="p1">
                    <p id="67">关系数据库中不具有主外键约束的单表被称为结构化数据表.结构化数据表包含若干属性,每个属性有自己特有的分布,属性间也有或强或弱的相关性,例如身高和体重正相关,身高越高的个体,体重就越大.属性的取值具有无序性(与结构化数据表中每条记录所处的位置无关)、取值离散等特点,与图片数据不尽相同.因此,GAN及其若干变体都无法直接用于结构化数据表的生成.为了解决这个问题,本文主要提出了一个基于生成式对抗网络的结构化数据表生成模型,称为TableGAN.</p>
                </div>
                <div class="p1">
                    <p id="68">该模型为传统生成式对抗网络模型GAN的一种变体,由一个生成器(generator)模型<i>G</i>和一个判别器(discriminator)模型<i>D</i>组成.生成器<i>G</i>的目的是尽量学习原始数据的真实分布,生成让判别器甄别不出真伪的合成数据,而判别器<i>D</i>的目的是尽量提升自己甄别原始数据与合成数据的判别能力.2个模型在相互对抗优化的过程中,不断提升各自的生成能力与判别能力.最终,生成器能够生成符合原始数据分布特征的合成数据,和原始数据一起用于分类模型的训练,从而解决由于训练样本不足导致的过拟合问题.和其他传统生成式对抗网络不同的是,TableGAN修改了优化函数,保证了模型有一个稳定的训练过程,并且为了防止噪声对模型稳定性的影响,在生成器模型和判别器模型中都添加了L<sub>2</sub>正则化项,还增大了输入噪声的多样性,在一定程度上避免了模式崩溃(mode collapse)情况的发生.据我们所知,TableGAN模型是生成式对抗网络在结构化数据表生成领域的首次应用.</p>
                </div>
                <div class="p1">
                    <p id="69">为了证明TabelGAN的有效性,本文提供了在2个数据集上,针对3种分类器网络的一系列实验结果和相关分析.充分的实验表明TableGAN能够生成有助于提升分类器网络训练的数据样本.为了更好地展示TableGAN生成数据的效果,我们选择了一个在数据挖掘比赛网站Kaggle<citation id="239" type="note"><link href="229" rel="footnote" /><sup>①</sup></citation>上排名最靠前的分类模型,实验证明使用合成的数据集训练后,分类模型的准确率仍可以进一步提升.</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="71">数据合成在机器学习和数据库等领域有着十分重要的应用<citation id="194" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>.其中一个在机器学习领域的应用就是利用合成的数据来解决过拟合问题.过拟合问题在机器学习领域存在已久,是一个亟待解决的问题.近年来,有不少学者提出对这个问题的解决方案,包括合成更多的训练样本<citation id="190" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、交叉验证(cross-validation)<citation id="191" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、正则化(regularization)<citation id="192" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>和提前停止(early stopping)<citation id="193" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>等方法.其中,合成更多的训练样本是最常使用的方法之一.</p>
                </div>
                <div class="p1">
                    <p id="72">在计算机视觉领域,合成更多训练样本这一技术通常被称为数据增强(data augmentation).为了得到更多的训练样本,需要对原始训练图像进行简单的几何和外观方面的转换,包括对图片进行旋转、扭曲等,但是这些转换都基于一个很强的假设,即这些细微的物理转换都不会改变图片的类别标签.由于此假设没有相关的理论证明,这种通过物理转换来扩大训练集的方法具有一定的局限性.</p>
                </div>
                <div class="p1">
                    <p id="73">生成模型是近年来机器学习领域最有前景的方法之一,它通过学习并遵从给定数据集的概率分布来生成新的样本数据.其中变分自动编码器(variational auto-encoders, VAE)<citation id="195" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和生成式对抗网络(GAN)<citation id="196" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>是生成模型中众所周知的代表.</p>
                </div>
                <div class="p1">
                    <p id="74">VAE是一个概率图模型,由一个编码器(encoder)和一个解码器(decoder)构成,编码器将数据分布的高级特征映射到数据的低级表征(latent vector),解码器接受数据的低级表征,然后输出同样数据的高级表征.VAE的训练过程完全依赖于一个假设损失函数及KL散度,使得生成的数据尽可能去接近真实数据的分布.</p>
                </div>
                <div class="p1">
                    <p id="75">然而,GAN为我们提供了一个对目标函数更为灵活的定义,其中包括Jensen-Shannon<citation id="197" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、所有的<i>f</i>-divergences<citation id="198" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>以及一些其他距离度量的组合<citation id="199" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>.GAN由一个生成器<i>G</i>和一个判别器<i>D</i>组成,它们均由深度学习网络实现.生成器和判别器相互对抗进行训练,生成器尽可能生成与原始数据分布相近的数据集,使判别器无法将其与原始数据区分,而判别器则尽可能提升自己区分原始数据与合成数据的能力.经过一段时间的对抗训练后,生成器能够生成接近原始数据分布的样本,用于解决由于训练样本不足导致的过拟合问题.GAN被证明训练难度大且十分不稳定<citation id="200" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>,因此不少学者提出了GAN的若干变体,用于改进生成数据的质量.例如,C-GAN<citation id="201" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>将条件信息,即类标签,添加到生成器模型输入中,用于改进原始GAN模型.AC-GAN<citation id="202" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>中的判别器不仅要判别输入数据来自原始数据还是合成数据,还要判别输入数据的类别标签.本文提出了GAN模型的另一个变体TableGAN,用于生成高质量的结构化数据表,并将其用来训练分类模型以改善模型的训练过程.</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag"><b>2 算法实现</b></h3>
                <div class="p1">
                    <p id="77">本节主要介绍文中所提出算法的模型推导和理论分析,首先对模型训练过程发生的过拟合现象进行形式化定义和描述,然后回顾生成式对抗网络的基本原理,最后给出基于GAN的结构化数据表生成模型TableGAN中算法的相关理论分析,包括模型推导、算法伪代码等.</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78"><b>2.1 问题定义</b></h4>
                <div class="p1">
                    <p id="79">给定一个带标签的训练集<i>Y</i>={<i><b>y</b></i><sub><i>n</i></sub>}<sup><i>N</i></sup>,其中<i><b>y</b></i><sub><i>n</i></sub>=(<i><b>x</b></i><sub><i>n</i></sub>,<i>c</i><sub><i>n</i></sub>),<i>c</i><sub><i>n</i></sub>∈{1,2,…,<i>M</i>}是第<i>n</i>行数据的标签,<i><b>x</b></i><sub><i>n</i></sub>是除了标签之外的其他属性.训练一个神经网络的基本目标是,用给定训练集去估计模型中的所有参数:</p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">θ</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>max</mi></mrow></mstyle><mi mathvariant="bold-italic">θ</mi></munder><mspace width="0.25em" /><mrow><mi>log</mi></mrow><mtext> </mtext><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">)</mo></mrow></math></mathml>,      (1)</p>
                </div>
                <div class="p1">
                    <p id="81">结合贝叶斯公式:</p>
                </div>
                <div class="p1">
                    <p id="82"><i>p</i>(<i>θ</i>|<i><b>y</b></i>)=<i>p</i>(<i>θ</i>|<i><b>x</b></i>,<i>c</i>)∝<i>p</i>(<i>θ</i>)<i>p</i>(<i><b>x</b></i>|<i>θ</i>)<i>p</i>(<i>c</i>|<i><b>x</b></i>,<i>θ</i>).      (2)</p>
                </div>
                <div class="p1">
                    <p id="83">假设所有的训练样本均为条件独立,可以得到:</p>
                </div>
                <div class="p1">
                    <p id="84">log <i>p</i>(<i>θ</i>|<i><b>y</b></i>)≈log <i>p</i>(<i>θ</i>)+<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">(</mo></mstyle><mrow><mi>log</mi></mrow><mtext> </mtext><mi>p</mi></mrow></math></mathml>(<i><b>x</b></i><sub><i>n</i></sub>|<i>θ</i>)+log <i>p</i>(<i>c</i><sub><i>n</i></sub>|<i><b>x</b></i><sub><i>n</i></sub>,<i>θ</i>)),      (3)</p>
                </div>
                <div class="p1">
                    <p id="86">其中,<i>p</i>(<i>θ</i>)为模型所有参数的先验概率,<i>p</i>(<i><b>x</b></i><sub><i>n</i></sub>|<i>θ</i>)是对样本<i><b>x</b></i><sub><i>n</i></sub>的似然估计,<i>p</i>(<i>c</i><sub><i>n</i></sub>|<i><b>x</b></i><sub><i>n</i></sub>,<i>θ</i>)是对标签<i>c</i><sub><i>n</i></sub>在给定<i><b>x</b></i><sub><i>n</i></sub>和<i>θ</i>条件下的似然估计.</p>
                </div>
                <div class="p1">
                    <p id="87">在训练神经网络时,模型中所有参数通过梯度下降的方式找到最优解.然而,当训练样本<i>Y</i>数量不足时,往往会出现过拟合现象.也就是说,尽管模型在训练集上效果很好,但在验证集上效果却很差.因此,我们需要合成更多高质量的训练样本,这些新合成的样本需要保留原始训练样本的重要特征,使扩大后的样本能够更好地训练模型中的参数.本文提出了一个基于生成式对抗网络的结构化数据表生成模型——TableGAN,用来扩大原有的训练样本并保留原始样本中的重要特征,为后续神经网络的稳定训练提供良好保障.</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>2.2 生成式对抗网络GAN</b></h4>
                <div class="p1">
                    <p id="89">生成式对抗网络GAN是Goodfellow等人<citation id="203" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>在2014年提出的一种生成模型,目前已经成为人工智能学界一个热门的研究方向.GAN的基本思想源于博弈论中的二人零和博弈,即二人的利益之和为零,一方所得正好为另一方所失.因此,GAN由2个相互博弈的神经网络模型组成,一个叫生成器<i>G</i>,另一个叫判别器<i>D</i>.生成器<i>G</i>的目的是尽量学习原始数据的真实分布,生成让判别器甄别不出真伪的合成数据;而判别器<i>D</i>的目的是尽量提升自己甄别原始数据与合成数据的判别能力.2个模型在相互对抗优化的过程中,不断提升各自的生成能力与判别能力,这个学习优化过程就是寻找二者之间的一个纳什均衡.在训练优化一段时间之后,生成式对抗网络的生成器能够捕捉原始数据的真实分布,并生成一系列符合同一分布的合成数据样本.</p>
                </div>
                <div class="p1">
                    <p id="90">生成器为了捕捉原始数据<i><b>x</b></i>的真实分布<i>p</i><sub>g</sub>,使用一个映射函数(一般由深度神经网络实现),将一个已知的分布<i>p</i>(<i><b>z</b></i>),例如高斯分布,映射到另一个数据空间<i>G</i>(<i><b>z</b></i>,<i>θ</i><sub>g</sub>),其中<i><b>z</b></i>称之为噪声(noise),<i>θ</i><sub>g</sub>表示生成器模型中的所有参数.生成器的目标是尽量缩小<i>G</i>(<i><b>z</b></i>,<i>θ</i><sub>g</sub>)与真实数据分布<i>p</i><sub>data</sub>(<i><b>x</b></i>)之间的差异.对于判别器模型来说,通过输出0或1来表示判别器对输入数据真假的判别情况.当输入数据采样于原始数据<i>p</i><sub>data</sub>(<i><b>x</b></i>)时,判别器输出为1;而当输入数据采样于合成数据集<i>G</i>(<i><b>z</b></i>),也就是从生成器中输出的数据时,判别器输出为0.</p>
                </div>
                <div class="p1">
                    <p id="91">在GAN的训练过程中,生成器模型和判别器模型进行相互对抗来进行优化,因此对<i>G</i>和<i>D</i>进行交替式训练.对于<i>G</i>而言,需要最小化log(1-<i>D</i>(<i>G</i>(<i><b>z</b></i>))),也就是尽可能让<i>G</i>合成的数据集<i>G</i>(<i><b>z</b></i>)能够欺骗<i>D</i>,使得判别器<i>D</i>的输出<i>D</i>(<i>G</i>(<i><b>z</b></i>))接近1.然而对判别器<i>D</i>而言,需要增强自己判别真假数据的能力,即最大化log <i>D</i>(<i><b>x</b></i>)与log(1-<i>D</i>(<i>G</i>(<i><b>z</b></i>))),也就是当输入数据为真实数据<i><b>x</b></i>时,判别器的输出<i>D</i>(<i><b>x</b></i>)尽可能接近1,而当输入数据为合成数据<i>G</i>(<i><b>z</b></i>)时,判别器的输出<i>D</i>(<i>G</i>(<i><b>z</b></i>))尽可能接近0.因此,GAN的优化问题是一个极小-极大化问题,GAN的目标函数可以描述为</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>G</mi></munder><mspace width="0.25em" /><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mi>D</mi></munder><mspace width="0.25em" /><mi>V</mi><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>a</mtext><mtext>t</mtext><mtext>a</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mrow><mi>log</mi></mrow><mtext> </mtext><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>E</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">z</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mrow><mi>log</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="93" name="93"><b>2.3 结构化数据表生成模型TableGAN</b></h4>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 TableGAN模型示意图" src="Detail/GetImg?filename=images/JFYZ201909003_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 TableGAN模型示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 The structure of our TableGAN</p>

                </div>
                <div class="p1">
                    <p id="95">本节主要介绍基于GAN的结构化数据表生成模型TableGAN.图3给出了模型TableGAN的示意图,TableGAN由一个生成器<i>G</i>和一个判别器<i>D</i>组成,符合某种分布的噪声<i><b>z</b></i>与类标签<i><b>c</b></i>一起作为生成器<i>G</i>的输入,经过<i>G</i>的变换后生成合成数据样本<i>G</i>(<i><b>z</b></i>|<i><b>c</b></i>),随后与真实数据样本<i><b>x</b></i>一起作为判别器<i>D</i>的输入,判别器的最终输出又会进一步指导生成器网络的训练过程.</p>
                </div>
                <div class="p1">
                    <p id="96">生成器网络与判别器网络均由深度神经网络实现,生成器网络和判别器网络中的所有参数分别由<i>θ</i>与<i>γ</i>表示.2个网络相互对抗进行训练,目标函数为</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>G</mi></munder><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mi>D</mi></munder><mspace width="0.25em" /><mi>V</mi><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>a</mtext><mtext>t</mtext><mtext>a</mtext></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mrow><mi>log</mi></mrow><mtext> </mtext><mi>D</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>E</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">z</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mrow><mi>log</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">c</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">式(5)与传统GAN模型的目标函数对比而言,增加了类别标签<i><b>c</b></i>作为生成器的输入,即给生成器额外的信息指导其更好地生成数据.然而在训练的过程中,使用式(5)作为目标函数易出现生成器梯度消失现象,从而导致模型极难训练,文献<citation id="204" type="reference">[<a class="sup">21</a>]</citation>中有相关理论证明.因此,TableGAN模型使用Earth-Mover(EM)距离来衡量原始样本与合成样本之间的距离,即使2个分布没有重叠或重叠的部分非常少,依然能够反映2个分布的远近,EM距离定义为</p>
                </div>
                <div class="p1">
                    <p id="99"><mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><mo stretchy="false">(</mo><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>inf</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∼</mo><mi>Π</mi><mo stretchy="false">(</mo><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></munder><mi>E</mi><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><mo>,</mo><mi mathvariant="bold-italic">y</mi><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="bold-italic">γ</mi></mrow></msub><mo stretchy="false">[</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><mo>-</mo><mi mathvariant="bold-italic">y</mi></mrow><mo>|</mo></mrow><mo stretchy="false">]</mo></mrow></math></mathml>,      (6)</p>
                </div>
                <div class="p1">
                    <p id="100">其中<i>Π</i>(<i>P</i><sub>1</sub>,<i>P</i><sub>2</sub>)为<i>P</i><sub>1</sub>和<i>P</i><sub>2</sub>所有可能的联合分布,计算在此联合分布下样本对距离的期望,此期望的下界就是EM距离.因此,使用EM距离后的目标函数为</p>
                </div>
                <div class="area_img" id="101">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201909003_10100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="103">传统GAN模型在训练过程中往往会发生模式崩溃(mode collapse)的现象,这指的是模型只能捕捉并保留原始数据中很少的一部分特征,以致生成的数据样本十分单一.我们的TableGAN则针对这个问题,使用3个技巧来缓解模式崩溃的现象:1)增加生成器输入噪声<i><b>z</b></i>的多样性.对图片数据集来说,传统GAN模型生成器的输入噪声服从单峰的正态分布,而对于本文需要生成的结构化数据表来说,输入多峰分布的噪声能够增加合成数据的多样性;2)我们放弃基于动量的优化方法,例如Adam,而使用RMSProp<citation id="205" type="reference"><link href="55" rel="bibliography" /><link href="57" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>;3)在神经网络模型上增加L<sub>2</sub>正则化项,保证TableGAN训练过程中的稳定.</p>
                </div>
                <div class="p1">
                    <p id="104">TableGAN的训练过程如算法1所示,针对参数<i>θ</i>与<i>γ</i>,使用式(7)给出的目标函数来分别交替训练生成器网络与判别器网络,训练过程收敛后会得到:</p>
                </div>
                <div class="p1">
                    <p id="105"><mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mo>-</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">γ</mi></munder><mspace width="0.25em" /><mi>V</mi><mo stretchy="false">(</mo><mi>D</mi><mo>,</mo><mi>G</mi><mo stretchy="false">)</mo></mrow></math></mathml>.      (8)</p>
                </div>
                <div class="p1">
                    <p id="106">此时,判别器<i>D</i><sub><i>γ</i></sub><sub><sup>*</sup></sub>已经收敛,<i>θ</i><sup>*</sup>也已收敛于<i>V</i>(<i>D</i>,<i>G</i>)的最小值,模型已经训练至稳定状态.之后,我们使用模型中已训练好的生成器,生成更多的训练样本,用于分类模型的训练过程.</p>
                </div>
                <div class="p1">
                    <p id="107"><b>算法1</b>. TableGAN训练算法.</p>
                </div>
                <div class="p1">
                    <p id="108">输入:学习率(learning rate)<i>η</i>、剪切参数(clipping parameter)<i>d</i>、批大小(batch size)<i>m</i>、生成器每迭代1次时判别器迭代的次数<i>n</i><sub><i>d</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="109">输出:收敛后生成器网络和判别器网络的参数<i>θ</i>与<i>γ</i>.</p>
                </div>
                <div class="area_img" id="225">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201909003_22500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="122" name="122" class="anchor-tag"><b>3 实验与分析</b></h3>
                <div class="p1">
                    <p id="123">本节主要介绍相关实验设置,包括实验所使用的数据集、分类模型以及用于比较的基准算法,之后给出实验结果并对其进行分析与讨论.实验代码已更新至GitHub<citation id="240" type="note"><link href="231" rel="footnote" /><sup>①</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="124">针对每个数据集,我们采取3个实验步骤:</p>
                </div>
                <div class="p1">
                    <p id="125">1) 使用原始训练样本对分类模型进行训练,在测试集上得到分类模型预测准确率;</p>
                </div>
                <div class="p1">
                    <p id="126">2) 使用原始训练样本,对数据库领域结构化数据表扩展方法Dscaler、数据匿名化方法<i>k</i>-anonymity与<i>t</i>-closeness、生成式对抗网络C-GAN和我们的模型TableGAN进行训练,随后使用训练好的模型生成合成的数据集,与原始训练样本一起组成了扩大后的数据集;  3) 使用步骤2中扩大后的数据集进行训练,在测试集上得到分类模型的预测准确率,和步骤1中得到的准确率进行比较.</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127"><b>3.1 数据集</b></h4>
                <div class="p1">
                    <p id="128">本文使用2个公开的数据集用于实验.一个是数据挖掘比赛网站Kaggle上公开的数据集<citation id="241" type="note"><link href="233" rel="footnote" /><sup>①</sup></citation>,另一个是机器学习仓库UCI<citation id="242" type="note"><link href="235" rel="footnote" /><sup>②</sup></citation>上公开的数据集,表1提供了2个数据集的统计信息.</p>
                </div>
                <div class="area_img" id="129">
                    <p class="img_tit"><b>表1 实验数据集统计信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Summaries of the 2 Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="129" border="1"><tr><td><br />Dataset</td><td>Source</td><td>#Classes</td><td>#Samples</td></tr><tr><td><br />SF Crime</td><td>Kaggle</td><td>39</td><td>877 982</td></tr><tr><td><br />Poker Hand</td><td>UCI</td><td>10</td><td>1 025 010</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="130">1) SF Crime.本数据集收集了旧金山市近12年来的犯罪记录,共有9个不同的属性,其中属性“<i>Category</i>”为标签,共有39种不同的取值.分类模型需要根据犯罪事件发生的时间与地点来预测犯罪的种类.表2提供了此数据集的详细信息.</p>
                </div>
                <div class="area_img" id="131">
                    <p class="img_tit"><b>表2 关于SF Crime数据集的描述</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Summaries of the SF Crime Dataset</b></p>
                    <p class="img_note"></p>
                    <table id="131" border="1"><tr><td><br />Attribute</td><td>Description</td><td>Data Type</td></tr><tr><td><br /><i>Dates</i></td><td>Timestamp of the Crime Incident</td><td>Datetime</td></tr><tr><td><br /><i>Category</i></td><td>Category of the Crime Incident</td><td>Categorical</td></tr><tr><td><br /><i>Description</i></td><td>Detailed Description of the Crime Incident</td><td>Text</td></tr><tr><td><br /><i>DayOfWeek</i></td><td>Day of the Week</td><td>Number</td></tr><tr><td><br /><i>PdDistrict</i></td><td>Name of the Police Department District</td><td>Categorical</td></tr><tr><td><br /><i>Resolution</i></td><td>How the Crime Incident was Resolved</td><td>Categorical</td></tr><tr><td><br /><i>Address</i></td><td>Approximate Street Address of the <br />Crime Incident</td><td>Categorical</td></tr><tr><td><br /><i>X</i></td><td>Longitude</td><td>Number</td></tr><tr><td><br /><i>Y</i></td><td>Latitude</td><td>Number</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="132">2) Poker Hand.本数据集记录了从52张扑克牌中抽出5张扑克牌的大小与花色,共有11个不同的属性,其中属性“<i>Class</i>”为标签,共有10种不同的取值,包括“同花顺”、“同花”、“顺子”等.分类模型需要根据5张扑克牌的大小与花色来预测牌型.表3提供了此数据集的详细信息.</p>
                </div>
                <div class="area_img" id="133">
                    <p class="img_tit"><b>表3 关于Poker Hand数据集的描述</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Summaries of the Poker Hand Dataset</b></p>
                    <p class="img_note"></p>
                    <table id="133" border="1"><tr><td><br />Attribute</td><td>Description</td></tr><tr><td><br /><i>S</i><sub>1</sub></td><td>Suit of card # 1, ordinal (1- 4) representing<br />{Hearts, Spades, Diamonds, Clubs}</td></tr><tr><td><br /><i>C</i><sub>1</sub></td><td>Rank of card # 1, numerical (1- 13) <br />representing (Ace,2,3,…,Queen,King)</td></tr><tr><td><br />︙</td><td>︙</td></tr><tr><td><br /><i>S</i><sub>5</sub></td><td>Suit of card # 5</td></tr><tr><td><br /><i>C</i><sub>5</sub></td><td>Rank of card # 5</td></tr><tr><td><br /><i>Class</i></td><td>Class “Poker Hand”, ordinal (0- 9)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="134" name="134"><b>3.2 分类模型</b></h4>
                <div class="p1">
                    <p id="135">本文使用3个公开的分类模型,包括1个性能良好的多层感知机(MLP),以及2个经典的分类算法——随机森林(random forest, RF)和决策树(decision tree, DT).</p>
                </div>
                <div class="p1">
                    <p id="136">1) MLP.这是引言提到的在数据挖掘比赛网站Kaggle<citation id="243" type="note"><link href="237" rel="footnote" /><sup>③</sup></citation>上排名最靠前的分类模型,它是一个3层神经元感知器,在SF Crime数据集下,这个分类模型的性能在所有的公开算法中排名前1%.</p>
                </div>
                <div class="p1">
                    <p id="137">2) RF.随机森林是通过集成学习的思想将多棵树集成的一种算法,它的基本单元是决策树,而它的本质属于机器学习的一大分支——集成学习(ensemble learning)方法,其输出的类别由个别树输出的类别的众数而定.也就是说,对于一个输入样本,<i>N</i>棵树会有<i>N</i>个分类结果,而随机森林集成了所有的分类投票结果,将投票次数最多的类别指定为最终的输出.</p>
                </div>
                <div class="p1">
                    <p id="138">3) DT.决策树是一种基本的分类方法.决策树模型呈树形结构,表示基于特征对实例进行分类的过程.它可以认为是if-then规则的集合,也可以认为是定义在特征空间与类空间上的条件概率分布,具有可读性、效率高等优点.</p>
                </div>
                <div class="p1">
                    <p id="139">本文模型TableGAN由高层神经网络API——Keras来实现,基于TensorFlow后端.针对每个数据集,TableGAN根据<i>Epochs</i>和<i>D</i>_<i>iters</i>这2个参数的不同取值,生成17份不同的合成数据样本.其中,<i>Epochs</i>反映了模型的学习程度,如果训练时的<i>Epochs</i>过小,由于特征学习不够充分,生成的合成数据集不足以大幅提高分类模型的预测准确率,反之,如果<i>Epochs</i>过大,模型会学习数据中过于具体的特征,依旧会影响分类模型的预测准确率,本实验<i>Epochs</i>的取值在20～90之间.<i>D</i>_<i>iters</i>反映了模型中判别器相对于生成器的迭代次数,即每当生成器迭代1次时判别器迭代的次数.例如<i>D</i>_<i>iters</i>=5表明每当模型生成器训练1次时判别器训练5次.此参数表明维持生成器和判别器这2个模型训练程度的动态平衡具有十分重要的意义.</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140"><b>3.3 基准算法</b></h4>
                <div class="p1">
                    <p id="141">本文采用10折交叉验证的方式对提出的TableGAN算法和4个方法在2个数据集上进行了实验,并将结果进行了比较和分析.</p>
                </div>
                <div class="p1">
                    <p id="142">1) Without scaling up. 未采用任何生成模型,使用原始训练样本对分类模型进行训练.</p>
                </div>
                <div class="p1">
                    <p id="143">2) Dscaler<citation id="206" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>. 数据库领域较新的结构化数据扩展方法Dscaler,一般针对多张具有主外键关系的结构化数据表,旨在保留主外键间参照关系.而单个结构化数据表的扩展方法,只是简单在数据表中进行采样,以此合成新的数据集.</p>
                </div>
                <div class="p1">
                    <p id="144">3) Anonymization. 采用数据匿名化方法<i>k</i>-anonymity与<i>t</i>-closeness结合.参数<i>k</i>∈{2,10,100},<i>t</i>∈{0.001,0.1,0.5},表4的实验结果取这些参数下最高的准确率值.</p>
                </div>
                <div class="p1">
                    <p id="145">4) C-GAN<citation id="207" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>. C-GAN是传统生成式对抗网络的一种变体,通过增加额外信息来提升合成数据的质量.其在图片数据集MNIST上表现良好,能够根据标签生成高质量的图片.</p>
                </div>
                <div class="p1">
                    <p id="146">5) TableGAN为本文提出的算法.</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147"><b>3.4 实验结果分析</b></h4>
                <div class="p1">
                    <p id="148">本节通过比较使用扩大后的训练集与原始训练集对分类模型的训练情况来证明TableGAN的有效性.我们使用训练后的分类模型在验证集上的预测准确率来量化TableGAN合成数据的质量.表4呈现了在2个数据集上的所有实验结果.可以看出,TableGAN在大部分情况下都可以改进分类模型的训练情况,并且比Dscaler,Anonymization,C-GAN这3个模型表现要好.3.4.1和3.4.2节有对实验结果详细的对比分析,并根据<i>Epochs</i>和<i>D</i>_<i>iters</i>这2个参数的变化情况绘制了分类模型对应的预测结果图.</p>
                </div>
                <div class="area_img" id="149">
                                            <p class="img_tit">
                                                <b>表4 分类模型在17个不同版本的训练集下的所有结果列表</b>
                                                    <br />
                                                <b>Table 4 Quantitative Results on the 17 Versions of Training Data</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JFYZ201909003_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 分类模型在17个不同版本的训练集下的所有结果列表" src="Detail/GetImg?filename=images/JFYZ201909003_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="150"><b>Continued (Table 4</b>)</p>
                </div>
                <div class="area_img" id="151">
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="" src="Detail/GetImg?filename=images/JFYZ201909003_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>
                                <p class="img_note">Notes：“<image id="226" type="formula" href="images/JFYZ201909003_22600.jpg" display="inline" placement="inline"><alt></alt></image>”means the corresponding classifiers using the augmented training data produced by data anonymization algorithms(k-anonymity+t-closeness）；“<image id="227" type="formula" href="images/JFYZ201909003_22700.jpg" display="inline" placement="inline"><alt></alt></image>”means the classification results of data produced by Dscaler；“*”means the classification results of data produced by C-GAN；“<image id="228" type="formula" href="images/JFYZ201909003_22800.jpg" display="inline" placement="inline"><alt></alt></image>”means the classification results of data produced by our TableGAN.The best results have been highlighted in bold.</p>

                </div>
                <div class="area_img" id="153">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 使用随机森林在数据集SF Crime上的性能对比" src="Detail/GetImg?filename=images/JFYZ201909003_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 使用随机森林在数据集SF Crime上的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Performance comparison using Random Forest classifier on SF Crime dataset</p>

                </div>
                <h4 class="anchor-tag" id="154" name="154">3.4.1 SF Crime数据集上效果对比</h4>
                <div class="p1">
                    <p id="155">图4展示了在SF Crime数据集上应用分类模型MLP的实验结果.其中,TableGAN的性能一直优于C-GAN的性能,即使这个分类模型已经是在此数据集下性能排名前1%的分类器,TableGAN依旧可以通过扩大训练样本的方式,进一步提升分类模型的预测准确率.而数据隐私算法扩大后的数据集,由于隐藏数据中部分重要特征,训练分类模型的准确率还不如原始训练样本对分类模型进行训练的准确率.</p>
                </div>
                <div class="p1">
                    <p id="156">图5和图6分别展示了在分类模型随机森林和决策树下的实验结果.尽管这2个传统分类模型的学习能力不如MLP强,也就是过拟合现象不够显著,但TableGAN依旧能够提升分类模型的准确率,TableGAN的表现也优于C-GAN模型的表现.</p>
                </div>
                <div class="area_img" id="157">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_157.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 使用MLP在数据集SF Crime上的性能对比" src="Detail/GetImg?filename=images/JFYZ201909003_157.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 使用MLP在数据集SF Crime上的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_157.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Performance comparison using MLP classifier on SF Crime dataset</p>

                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 使用决策树在数据集SF Crime上的性能对比" src="Detail/GetImg?filename=images/JFYZ201909003_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 使用决策树在数据集SF Crime上的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Performance comparison using Decision Tree classifier on SF Crime dataset</p>

                </div>
                <div class="p1">
                    <p id="160">为更好地证明本文方法TableGAN在数据集SF Crime上的优越性,使用配对样本<i>t</i>检验.显著性检验表明,TableGAN在置信区间为0.95的情况下,性能优于其他所有算法.</p>
                </div>
                <div class="area_img" id="161">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 使用MLP在数据集Poker Hand上的性能对比" src="Detail/GetImg?filename=images/JFYZ201909003_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 使用MLP在数据集Poker Hand上的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Performance comparison using MLP classifier on Poker Hand dataset</p>

                </div>
                <h4 class="anchor-tag" id="162" name="162">3.4.2 Poker Hand数据集上效果对比</h4>
                <div class="p1">
                    <p id="163">图7展示了在Poker Hand数据集上应用分类模型MLP的实验结果.可以看出使用TableGAN扩大原始训练样本之后能够大幅提升分类模型的准确率,并且TableGAN比C-GAN有着更好的性能.当TableGAN训练30轮,且每当生成器训练一次后判别器被训练6次时,TableGAN提升分类模型的性能最显著,准确率由原来的54.71%提升至60.16%.通过观察分类模型训练过程中的loss曲线,使用TableGAN扩大训练样本在很大程度上缓解了过拟合的问题.</p>
                </div>
                <div class="p1">
                    <p id="164">图8和图9分别展示了在分类模型随机森林和决策树下的实验结果.使用TableGAN扩大训练样本后,能将分类模型随机森林的准确率由原来的56.08%提升至57.68%,并能将分类模型决策树的准确率由原来的47.86%提升至52.73%.从图8和图9可以看出TableGAN很大程度上提升了分类模型的预测准确率,并总比使用C-GAN的性能好.从图9可以看出,随着参数<i>Epochs</i>和<i>D</i>_<i>iters</i>的变化,分类模型的预测准确率变化不大(最上方的曲线较为平缓),也就是说,我们的模型TabelGAN即使没有谨慎选择参数,仍然可以生成高质量的合成数据集来改善分类模型的训练过程,反观C-GAN,参数的细微变化很大程度上影响了分类模型的准确率.</p>
                </div>
                <div class="area_img" id="165">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 使用随机森林在数据集Poker Hand上的性能对比" src="Detail/GetImg?filename=images/JFYZ201909003_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 使用随机森林在数据集Poker Hand上的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Performance comparison using Random Forest classifier on Poker Hand dataset</p>

                </div>
                <div class="area_img" id="166">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909003_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 使用决策树在数据集Poker Hand上的性能对比" src="Detail/GetImg?filename=images/JFYZ201909003_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 使用决策树在数据集Poker Hand上的性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909003_166.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Performance comparison using Decision Tree classifier on Poker Hand dataset</p>

                </div>
                <div class="p1">
                    <p id="167">为更好地证明本文模型TableGAN在数据集Poker Hand上的优越性,使用配对样本<i>t</i>检验.显著性检验表明,TableGAN在置信区间为0.95的情况下,性能优于其他所有算法.</p>
                </div>
                <div class="p1">
                    <p id="168">总之,通过实验可以看出我们的模型TableGAN在2个数据集上都能够生成高质量的合成数据,用于改善分类模型的训练过程,从而提升分类模型的预测准确率.</p>
                </div>
                <h3 id="169" name="169" class="anchor-tag"><b>4 总结与工作展望</b></h3>
                <div class="p1">
                    <p id="170">本文研究了结构化数据表的生成问题,提出一个基于生成式对抗网络的生成模型,生成符合原始数据样本分布的合成样本,以扩大训练样本的方式解决由于训练样本不足导致的分类模型过拟合问题.实验证明,本文提出的方法能够生成高质量的结构化数据表,进一步提高分类模型的准确率.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="13">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600210944&amp;v=MjE1NjJLOUg5UE9xWTlGWnVvUEJYZzlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMM0lKMXdRYXhBPU5pZk9mYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Tay Y C,Dai B T,Wang D T,et al.UpSizeR:Synthetically scaling an empirical relational database[J].Information Systems,2013,38(8):1168- 1183
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Conditional image synthesis with auxiliary classifier gans">

                                <b>[2]</b>Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier gans[J].arXiv preprint arXiv:1610.09585,2016
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The problem of overfitting">

                                <b>[3]</b>Hawkins D M.The problem of overfitting[J].Journal of Chemical Information and Computer Sciences,2004,44(1):1- 12
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Extracting and composing robust features with denoising autoencoders">

                                <b>[4]</b>Vincent P,Larochelle H,Bengio Y,et al.Extracting and composing robust features with denoising autoencoders[C] //Proc of the 25th Int Conf on Machine Learning.New York:ACM,2008:1096- 1103
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14032100000892&amp;v=MzEyOTBMT3JvOUZaT3NQQkhVN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUwzSUoxd1FheEE9Tmo3QmFySzhIdA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Eslami S M A,Heess N,Williams C K I,et al.The shape Boltzmann machine:A strong model of object shape[J].International Journal of Computer Vision,2014,107(2):155- 176
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Auto-encoding variational Bayes">

                                <b>[6]</b>Kingma D P,Welling M.Auto-encoding variational Bayes[J].arXiv preprint arXiv:1312.6114,2013
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modeling Natural Images Using Gated MRFs">

                                <b>[7]</b>Mnih V,Susskind J M,Hinton G E.Modeling natural images using gated MRFs[J].IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(9):2206- 2222
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">

                                <b>[8]</b>Goodfellow I,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2014:2672- 2680
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Conditional generative adversarial nets">

                                <b>[9]</b>Mirza M,Osindero S.Conditional generative adversarial nets[J].arXiv preprint arXiv:1411.1784,2014
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Conditional image synthesis with auxiliary classifier gans">

                                <b>[10]</b>Odena A,Olah C,Shlens J.Conditional image synthesis with auxiliary classifier gans[J].arXiv preprint arXiv:1610.09585,2016
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The synthetic data vault">

                                <b>[11]</b>Patki N,Wedge R,Veeramachaneni K.The synthetic data vault[C] //Proc of the 3rd IEEE Int Conf on Data Science and Advanced Analytics (DSAA).Piscataway,NJ:IEEE,2016:399- 410
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Data generation for application-specific benchmarking">

                                <b>[12]</b>Tay Y.Data generation for application-specific benchmarking[C] //Proc of the 37th Int Conf on Very Large Data Bases (VLDB).New York:ACM,2011:1470- 1473
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Bayesian data augmentation approach for learning deep models">

                                <b>[13]</b>Tran T,Pham T,Carneiro G,et al.A Bayesian data augmentation approach for learning deep models[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2017:2794- 2803
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[14]</b>Krizhevsky A,Sutskever I,Hinton G E.Imagenet classification with deep convolutional neural networks[C] //Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2012:1097- 1105
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070811&amp;v=MDk0MjJkR2VycVFUTW53WmVadUh5am1VTDNJSjF3UWF4QT1OaWZPZmJLN0h0RE9ySTlGWk93UEJIMDRvQk1UNlQ0UFFIL2lyUg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>Prechelt L.Automatic early stopping using cross validation:Quantifying the criteria[J].Neural Networks,1998,11(4):761- 767
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dropout:A simple way to prevent neural networks from overfitting">

                                <b>[16]</b>Srivastava N,Hinton G,Krizhevsky A,et al.Dropout:A simple way to prevent neural networks from overfitting[J].The Journal of Machine Learning Research,2014,15(1):1929- 1958
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using early-stopping to avoid overfitting in wrapper-based feature selection employing stochastic search">

                                <b>[17]</b>Loughrey J,Cunningham P.Using early-stopping to avoid overfitting in wrapper-based feature selection employing stochastic search[R].Ireland:Trinity College Dublin,Department of Computer Science,2005
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=F-gan:training generative neural samplers using variational divergence minimization">

                                <b>[18]</b>Nowozin S,Cseke B,Tomioka R.f-gan:Training generative neural samplers using variational divergence minimization[C] // Proc of Advances in Neural Information Processing Systems (NIPS).Cambridge,MA:MIT Press,2016:271- 279
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=How (not) to train your generative model:Scheduled sampling,likelihood,adversary?">

                                <b>[19]</b>Huszár F.How (not) to train your generative model:Scheduled sampling,likelihood,adversary?[J].arXiv preprint arXiv:1511.05101,2015
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards principled methods for training generative adversarial networks">

                                <b>[20]</b>Arjovsky M,Bottou L.Towards principled methods for training generative adversarial networks[J].arXiv preprint arXiv:1701.04862,2017
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wasserstein gan">

                                <b>[21]</b>Arjovsky M,Chintala S,Bottou L.Wasserstein gan[J].arXiv preprint arXiv:1701.07875,2017
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Variants of RMSProp and adagrad with logarithmic regret bounds">

                                <b>[22]</b>Mukkamala M C,Hein M.Variants of RMSProp and adagrad with logarithmic regret bounds[J].arXiv preprint arXiv:1706.05507,2017
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Divide the gradient by a running average of its recent magnitude">

                                <b>[23]</b>Tieleman T,Hinton G.Divide the gradient by a running average of its recent magnitude[J].COURSERA:Neural Networks for Machine Learning,2012,4(2):26- 31
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dscaler:Synthetically scaling a given relational database">

                                <b>[24]</b>Zhang Jiangwei,Tay Y C.Dscaler:Synthetically scaling a given relational database[C] //Proc of the 42nd Int Conf on Very Large Data Bases (VLDB).New York:ACM,2016:1671- 1682
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="229" href="javascript:void(0)">
                            <b>1</b> https://www.kaggle.com/c/sf-crime/discussion/15836
                        </span>
                    </p>
                    <p>
                        <span id="231" href="javascript:void(0)">
                            <b>2</b> https://github.com/cocoissong/TableGAN
                        </span>
                    </p>
                    <p>
                        <span id="233" href="javascript:void(0)">
                            <b>3</b> https://www.kaggle.com/c/sf-crime/data
                        </span>
                    </p>
                    <p>
                        <span id="235" href="javascript:void(0)">
                            <b>4</b> http://archive.ics.uci.edu/ml/datasets/Poker+Hand
                        </span>
                    </p>
                    <p>
                        <span id="237" href="javascript:void(0)">
                            <b>5</b> https://www.kaggle.com/c/sf-crime/discussion/15836
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201909003" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201909003&amp;v=MjAyODhIOWpNcG85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5L25WNzdLTHl2U2RMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlTSGF5bHg5eGpDNElNND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

