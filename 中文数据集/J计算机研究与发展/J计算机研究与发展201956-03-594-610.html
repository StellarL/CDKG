<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133237994502500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201903015%26RESULT%3d1%26SIGN%3dr%252bT19l%252bN9333d8%252fc9cqO8CRqZbE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201903015&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201903015&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201903015&amp;v=MDgxMzVxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N21XN3ZBTHl2U2RMRzRIOWpNckk5RVlZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#78" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="&lt;b&gt;1.1 基于搜索策略的Shapelets提取&lt;/b&gt;"><b>1.1 基于搜索策略的Shapelets提取</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;1.2 基于学习策略的Shapelets提取&lt;/b&gt;"><b>1.2 基于学习策略的Shapelets提取</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="&lt;b&gt;2 相关定义与符号表示&lt;/b&gt; "><b>2 相关定义与符号表示</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="&lt;b&gt;3 Shapelets提取&lt;/b&gt; "><b>3 Shapelets提取</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#122" data-title="&lt;b&gt;3.1 关键时序数据的选择&lt;/b&gt;"><b>3.1 关键时序数据的选择</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;3.2 候选矩阵&lt;/b&gt;"><b>3.2 候选矩阵</b></a></li>
                                                <li><a href="#199" data-title="&lt;b&gt;3.3 基于候选矩阵的Shapelets提取&lt;/b&gt;"><b>3.3 基于候选矩阵的Shapelets提取</b></a></li>
                                                <li><a href="#224" data-title="&lt;b&gt;3.4 算法分析&lt;/b&gt;"><b>3.4 算法分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#226" data-title="&lt;b&gt;4 时间序列空间变换&lt;/b&gt; "><b>4 时间序列空间变换</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#230" data-title="&lt;b&gt;5 实验与分析&lt;/b&gt; "><b>5 实验与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#232" data-title="&lt;b&gt;5.1 实验设置&lt;/b&gt;"><b>5.1 实验设置</b></a></li>
                                                <li><a href="#261" data-title="&lt;b&gt;5.2 提取关键时序数据对实验结果的影响&lt;/b&gt;"><b>5.2 提取关键时序数据对实验结果的影响</b></a></li>
                                                <li><a href="#266" data-title="&lt;b&gt;5.3 实验结果对比&lt;/b&gt;"><b>5.3 实验结果对比</b></a></li>
                                                <li><a href="#283" data-title="&lt;b&gt;5.4 算法可扩展性&lt;/b&gt;"><b>5.4 算法可扩展性</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#290" data-title="&lt;b&gt;6 结 论&lt;/b&gt; "><b>6 结 论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="图1 子序列&lt;b&gt;&lt;i&gt;S&lt;/i&gt;&lt;/b&gt;在&lt;b&gt;&lt;i&gt;T&lt;/i&gt;&lt;/b&gt;中的最优匹配示例">图1 子序列<b><i>S</i></b>在<b><i>T</i></b>中的最优匹配示例</a></li>
                                                <li><a href="#121" data-title="图2 本文方法的整体框架及流程">图2 本文方法的整体框架及流程</a></li>
                                                <li><a href="#176" data-title="图3 &lt;b&gt;&lt;i&gt;P&lt;/i&gt;&lt;/b&gt;&lt;sub&gt;&lt;i&gt;A A&lt;/i&gt;&lt;/sub&gt;更新过程">图3 <b><i>P</i></b><sub><i>A A</i></sub>更新过程</a></li>
                                                <li><a href="#203" data-title="图4 时序数据&lt;b&gt;&lt;i&gt;T&lt;/i&gt;&lt;/b&gt;和&lt;b&gt;&lt;i&gt;R&lt;/i&gt;&lt;/b&gt;的Shapelets提取过程">图4 时序数据<b><i>T</i></b>和<b><i>R</i></b>的Shapelets提取过程</a></li>
                                                <li><a href="#222" data-title="图5 Shapelets 提取过程">图5 Shapelets 提取过程</a></li>
                                                <li><a href="#223" data-title="图 6 时序数据的空间变换示意图">图 6 时序数据的空间变换示意图</a></li>
                                                <li><a href="#235" data-title="&lt;b&gt;表1 实验中所使用的数据集&lt;/b&gt;"><b>表1 实验中所使用的数据集</b></a></li>
                                                <li><a href="#248" data-title="图8 SJS算法和N-SJS算法的运行时间对比">图8 SJS算法和N-SJS算法的运行时间对比</a></li>
                                                <li><a href="#263" data-title="图1 SJS算法和N-SJS算法在表1数据集上的分类 准确率比较">图1 SJS算法和N-SJS算法在表1数据集上的分类 准确率比较</a></li>
                                                <li><a href="#271" data-title="&lt;b&gt;表2 不同方法在各个数据集上的测试准确率&lt;/b&gt; %"><b>表2 不同方法在各个数据集上的测试准确率</b> %</a></li>
                                                <li><a href="#273" data-title="图9 SJS和对比算法的关键差异图">图9 SJS和对比算法的关键差异图</a></li>
                                                <li><a href="#278" data-title="&lt;b&gt;表3 不同方法在各个数据集上的运行时间&lt;/b&gt;"><b>表3 不同方法在各个数据集上的运行时间</b></a></li>
                                                <li><a href="#286" data-title="图10 时序数据长度变化时的实验结果">图10 时序数据长度变化时的实验结果</a></li>
                                                <li><a href="#288" data-title="图11 训练集时序数据数量变化时的实验结果">图11 训练集时序数据数量变化时的实验结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="363">


                                    <a id="bibliography_1" title="Su Weixing, Zhu Yunlong, Liu Fang, et al. Outliers and change-points detection algorithm for time series[J]. Journal of Computer Research and Development, 2014, 51 (4) : 781- 788 (in Chinese) (苏卫星, 朱云龙, 刘芳, 等. 时间序列异常点及突变点的检测算法[J]. 计算机研究与发展, 2014, 51 (4) : 781- 788) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201404009&amp;v=MDUxNTQ3bVc3dkFMeXZTZExHNEg5WE1xNDlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Su Weixing, Zhu Yunlong, Liu Fang, et al. Outliers and change-points detection algorithm for time series[J]. Journal of Computer Research and Development, 2014, 51 (4) : 781- 788 (in Chinese) (苏卫星, 朱云龙, 刘芳, 等. 时间序列异常点及突变点的检测算法[J]. 计算机研究与发展, 2014, 51 (4) : 781- 788) 
                                    </a>
                                </li>
                                <li id="365">


                                    <a id="bibliography_2" title="Wu Honghua, Liu Guohua, Wang Wei. Similarity matching for uncertain time series[J]. Journal of Computer Research and Development, 2014, 51 (8) : 1802- 1810 (in Chinese) (吴红花, 刘国华, 王伟. 不确定时间序列的相似性匹配问题[J]. 计算机研究与发展, 2014, 51 (8) : 1802- 1810) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201408016&amp;v=MDg1MzZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeTdtVzd2QUx5dlNkTEc0SDlYTXA0OUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Wu Honghua, Liu Guohua, Wang Wei. Similarity matching for uncertain time series[J]. Journal of Computer Research and Development, 2014, 51 (8) : 1802- 1810 (in Chinese) (吴红花, 刘国华, 王伟. 不确定时间序列的相似性匹配问题[J]. 计算机研究与发展, 2014, 51 (8) : 1802- 1810) 
                                    </a>
                                </li>
                                <li id="367">


                                    <a id="bibliography_3" title="Esling P, Agon C.Time-series data mining[J]. ACM Computing Surveys (CSUR) , 2012, 45 (1) : 1- 34" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000011010&amp;v=MTY1MzN0ak5yNDlGWk9vT0RIMDVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKbDBjYmhvPU5pZklZN0s3SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Esling P, Agon C.Time-series data mining[J]. ACM Computing Surveys (CSUR) , 2012, 45 (1) : 1- 34
                                    </a>
                                </li>
                                <li id="369">


                                    <a id="bibliography_4" title="Ding Hui, Trajcevski G, Scheuermann P, et al. Querying and mining of time series data: Experimental comparison of representations and distance measures[J]. Proc of the VLDB Endowment, 2008, 1 (2) : 1542- 1552" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Querying and mining of time series data: experimental comparison of representations and distance measures">
                                        <b>[4]</b>
                                        Ding Hui, Trajcevski G, Scheuermann P, et al. Querying and mining of time series data: Experimental comparison of representations and distance measures[J]. Proc of the VLDB Endowment, 2008, 1 (2) : 1542- 1552
                                    </a>
                                </li>
                                <li id="371">


                                    <a id="bibliography_5" title="Lines J, Bagnall A.Time series classification with ensembles of elastic distance measures[J]. Data Mining and Knowledge Discovery, 2015, 29 (3) : 565- 592" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Time series classification with ensembles of elastic distance measures">
                                        <b>[5]</b>
                                        Lines J, Bagnall A.Time series classification with ensembles of elastic distance measures[J]. Data Mining and Knowledge Discovery, 2015, 29 (3) : 565- 592
                                    </a>
                                </li>
                                <li id="373">


                                    <a id="bibliography_6" title="Ratanamahatana C A, Keogh E.Three myths about dynamic time warping data mining[C] //Proc of the 5th SIAM Int Conf on Data Mining.Philadelphia, PA: SIAM, 2005: 506- 510" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Three myths about dynamic time warping">
                                        <b>[6]</b>
                                        Ratanamahatana C A, Keogh E.Three myths about dynamic time warping data mining[C] //Proc of the 5th SIAM Int Conf on Data Mining.Philadelphia, PA: SIAM, 2005: 506- 510
                                    </a>
                                </li>
                                <li id="375">


                                    <a id="bibliography_7" title="Chen Lei, &#214;zsu M T, Oria V.Robust and fast similarity search for moving object trajectories[C] //Proc of the 24th ACM SIGMOD Int Conf on Management of Data. New York: ACM, 2005: 491- 502" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust and fast similarity search for moving object trajectories">
                                        <b>[7]</b>
                                        Chen Lei, &#214;zsu M T, Oria V.Robust and fast similarity search for moving object trajectories[C] //Proc of the 24th ACM SIGMOD Int Conf on Management of Data. New York: ACM, 2005: 491- 502
                                    </a>
                                </li>
                                <li id="377">


                                    <a id="bibliography_8" title="Keogh E J, Pazzani M J.Derivative dynamic time warping[C] //Proc of the 1st SIAM Int Conf on Data Mining.Philadelphia, PA: SIAM, 2001: 1- 11" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Derivative dynamic time warping">
                                        <b>[8]</b>
                                        Keogh E J, Pazzani M J.Derivative dynamic time warping[C] //Proc of the 1st SIAM Int Conf on Data Mining.Philadelphia, PA: SIAM, 2001: 1- 11
                                    </a>
                                </li>
                                <li id="379">


                                    <a id="bibliography_9" title="Jeong Y S, Jeong M K, Omitaomu O A.Weighted dynamic time warping for time series classification[J]. Pattern Recognition, 2011, 44 (9) : 2231- 2240" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738155&amp;v=MTU2NjRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKbDBjYmhvPU5pZk9mYks3SHRETnFZOUZZK2dIRFhrOA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Jeong Y S, Jeong M K, Omitaomu O A.Weighted dynamic time warping for time series classification[J]. Pattern Recognition, 2011, 44 (9) : 2231- 2240
                                    </a>
                                </li>
                                <li id="381">


                                    <a id="bibliography_10" title="Marteau P F.Time warp edit distance with stiffness adjustment for time series matching[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) : 306- 318" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Time warp edit distance with stiffness adjustment for time series matching">
                                        <b>[10]</b>
                                        Marteau P F.Time warp edit distance with stiffness adjustment for time series matching[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) : 306- 318
                                    </a>
                                </li>
                                <li id="383">


                                    <a id="bibliography_11" title="Stefan A, Vassilis A, Gautam D.The move-split-merge metric for time series[J]. IEEE Transactions on Knowledge and Data Engineering, 2013, 25 (6) : 1425- 1438" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The move-split-merge metric for time series">
                                        <b>[11]</b>
                                        Stefan A, Vassilis A, Gautam D.The move-split-merge metric for time series[J]. IEEE Transactions on Knowledge and Data Engineering, 2013, 25 (6) : 1425- 1438
                                    </a>
                                </li>
                                <li id="385">


                                    <a id="bibliography_12" title="Batista G E, Wang Xiaoyue, Keogh E J.A complexity-invariant distance measure for time series[C] //Proc of the 11th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2011: 699- 710" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A complexity-invariant distance measure for time series">
                                        <b>[12]</b>
                                        Batista G E, Wang Xiaoyue, Keogh E J.A complexity-invariant distance measure for time series[C] //Proc of the 11th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2011: 699- 710
                                    </a>
                                </li>
                                <li id="387">


                                    <a id="bibliography_13" title="Ye Lexiang, Keogh E.Time series shapelets: A novel technique that allows accurate, interpretable and fast classification[J]. Data Mining and Knowledge Discovery, 2011, 22 (1) : 149- 182" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Time series shapelets: a novel technique that allows accurate, interpretable and fast classification">
                                        <b>[13]</b>
                                        Ye Lexiang, Keogh E.Time series shapelets: A novel technique that allows accurate, interpretable and fast classification[J]. Data Mining and Knowledge Discovery, 2011, 22 (1) : 149- 182
                                    </a>
                                </li>
                                <li id="389">


                                    <a id="bibliography_14" title="Mueen A, Keogh E, Young N. Logical-shapelets: An expressive primitive for time series classification[C] //Proc of the 17th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2011: 1154- 1162" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Logical-shapelets:an expressive primitive for time series classification">
                                        <b>[14]</b>
                                        Mueen A, Keogh E, Young N. Logical-shapelets: An expressive primitive for time series classification[C] //Proc of the 17th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2011: 1154- 1162
                                    </a>
                                </li>
                                <li id="391">


                                    <a id="bibliography_15" title="Lin J, Keogh E, Li Wei, et al. Experiencing SAX: A novel symbolic representation of time series[J]. Data Mining and Knowledge Discovery, 2007, 15 (2) : 107- 144" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002157770&amp;v=Mjc1NDM1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZTbmxWYnpBSkZZPU5qN0Jhck80SHRIT3JvcENZK3dQWTNr&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        Lin J, Keogh E, Li Wei, et al. Experiencing SAX: A novel symbolic representation of time series[J]. Data Mining and Knowledge Discovery, 2007, 15 (2) : 107- 144
                                    </a>
                                </li>
                                <li id="393">


                                    <a id="bibliography_16" title="Rakthanmanon T, Keogh E. Fast shapelets: A scalable algorithm for discovering time series shapelets[C] //Proc of the 13th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2013: 668- 676" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast shapelets:a scalable algorithm for discovering time series shapelets">
                                        <b>[16]</b>
                                        Rakthanmanon T, Keogh E. Fast shapelets: A scalable algorithm for discovering time series shapelets[C] //Proc of the 13th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2013: 668- 676
                                    </a>
                                </li>
                                <li id="395">


                                    <a id="bibliography_17" title="Hills J, Lines J, Baranauskas E, et al. Classification of time series by shapelet transformation[J]. Data Mining and Knowledge Discovery, 2014, 28 (4) : 851- 881" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14031700001088&amp;v=MDY3MDFSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsMGNiaG89Tmo3QmFySzhIdExOcUk5RlpPc09ESFF4b0JNVDZUNFBRSC9pcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        Hills J, Lines J, Baranauskas E, et al. Classification of time series by shapelet transformation[J]. Data Mining and Knowledge Discovery, 2014, 28 (4) : 851- 881
                                    </a>
                                </li>
                                <li id="397">


                                    <a id="bibliography_18" title="Lines J, Davis L M, Hills J, et al. A shapelet transform for time series classification[C] //Proc of the 18th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2012: 289- 297" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A shapelet transform for time series classification">
                                        <b>[18]</b>
                                        Lines J, Davis L M, Hills J, et al. A shapelet transform for time series classification[C] //Proc of the 18th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2012: 289- 297
                                    </a>
                                </li>
                                <li id="399">


                                    <a id="bibliography_19" title="Yeh C C M, Zhu Yan, Ulanova L, et al. Matrix profile I: All pairs similarity joins for time series: A unifying view that includes motifs, discords and shapelets[C] //Proc of the 16th Int Conf on Data Mining (ICDM) . Piscataway, NJ: IEEE, 2016: 1317- 1322" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Matrix profile I: All pairs similarity joins for time series: A unifying view that includes motifs, discords and shapelets">
                                        <b>[19]</b>
                                        Yeh C C M, Zhu Yan, Ulanova L, et al. Matrix profile I: All pairs similarity joins for time series: A unifying view that includes motifs, discords and shapelets[C] //Proc of the 16th Int Conf on Data Mining (ICDM) . Piscataway, NJ: IEEE, 2016: 1317- 1322
                                    </a>
                                </li>
                                <li id="401">


                                    <a id="bibliography_20" title="Yuan Jidong, Wang Zhihai, Han Meng, et al. A logical shapelets transform for time series classification[J]. Chinese Journal of Computers, 2015, 38 (7) : 1448- 1459 (in Chinese) (原继东, 王志海, 韩萌, 等. 基于逻辑shapelets转换的时间序列分类算法[J]. 计算机学报, 2015, 38 (7) : 1448- 1459) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201507011&amp;v=MTE3MDZHNEg5VE1xSTlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3bVc3dkFMejdCZHI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        Yuan Jidong, Wang Zhihai, Han Meng, et al. A logical shapelets transform for time series classification[J]. Chinese Journal of Computers, 2015, 38 (7) : 1448- 1459 (in Chinese) (原继东, 王志海, 韩萌, 等. 基于逻辑shapelets转换的时间序列分类算法[J]. 计算机学报, 2015, 38 (7) : 1448- 1459) 
                                    </a>
                                </li>
                                <li id="403">


                                    <a id="bibliography_21" title="Chang Kaiwei, Deka B, Hwu W M W, et al. Efficient pattern-based time series classification on GPU[C] //Proc of the 12th Int Conf on Data Mining (ICDM) . Piscataway, NJ: IEEE, 2012: 131- 140" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient PatternBased Time Series Classification on GPU">
                                        <b>[21]</b>
                                        Chang Kaiwei, Deka B, Hwu W M W, et al. Efficient pattern-based time series classification on GPU[C] //Proc of the 12th Int Conf on Data Mining (ICDM) . Piscataway, NJ: IEEE, 2012: 131- 140
                                    </a>
                                </li>
                                <li id="405">


                                    <a id="bibliography_22" title="Wistuba M, Grabocka J, Schmidt-Thieme L. Ultra-fast shapelets for time series classification[EB/OL]. 2015 [2015-03-17]. https://arxiv.org/abs/1503.05018" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ultra-fast shapelets for time series classification">
                                        <b>[22]</b>
                                        Wistuba M, Grabocka J, Schmidt-Thieme L. Ultra-fast shapelets for time series classification[EB/OL]. 2015 [2015-03-17]. https://arxiv.org/abs/1503.05018
                                    </a>
                                </li>
                                <li id="407">


                                    <a id="bibliography_23" title="Zhang Zhenguo, Zhang Haiwei, Wen Yanlong, et al. Accelerating time series shapelets discovery with key points [G] //LNCS 9932: Proc of the 12th Asia-Pacific Web Conf. Berlin: Springer, 2016: 330- 342" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accelerating time series shapelets discovery with key points">
                                        <b>[23]</b>
                                        Zhang Zhenguo, Zhang Haiwei, Wen Yanlong, et al. Accelerating time series shapelets discovery with key points [G] //LNCS 9932: Proc of the 12th Asia-Pacific Web Conf. Berlin: Springer, 2016: 330- 342
                                    </a>
                                </li>
                                <li id="409">


                                    <a id="bibliography_24" title="Grabocka J, Schilling N, Wistuba M, et al. Learning time-series shapelets[C] //Proc of the 20th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2014: 392- 401" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning timeseries shapelets">
                                        <b>[24]</b>
                                        Grabocka J, Schilling N, Wistuba M, et al. Learning time-series shapelets[C] //Proc of the 20th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2014: 392- 401
                                    </a>
                                </li>
                                <li id="411">


                                    <a id="bibliography_25" title="Hou Lu, Kwok J T, Zurada J M.Efficient learning of timeseries shapelets[C] //Proc of the 30th AAAI Conf on Artificial Intelligence. Menlo Park, CA: AAAI, 2016: 1209- 1215" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient learning of timeseries shapelets">
                                        <b>[25]</b>
                                        Hou Lu, Kwok J T, Zurada J M.Efficient learning of timeseries shapelets[C] //Proc of the 30th AAAI Conf on Artificial Intelligence. Menlo Park, CA: AAAI, 2016: 1209- 1215
                                    </a>
                                </li>
                                <li id="413">


                                    <a id="bibliography_26" title="Bagnall A, Lines J, Bostrom A, et al. The great time series classification bake off: A review and experimental evaluation of recent algorithmic advances[J]. Data Mining and Knowledge Discovery, 2017, 31 (3) : 606- 660" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The great time series classification bake off:a review and experimental evaluation of recent algorithmic advances">
                                        <b>[26]</b>
                                        Bagnall A, Lines J, Bostrom A, et al. The great time series classification bake off: A review and experimental evaluation of recent algorithmic advances[J]. Data Mining and Knowledge Discovery, 2017, 31 (3) : 606- 660
                                    </a>
                                </li>
                                <li id="415">


                                    <a id="bibliography_27" title="Rakthanmanon T, Campana B, Mueen A, et al. Searching and mining trillions of time series subsequences under dynamic time warping[C] //Proc of the 18th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2012: 262- 270" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Searching and Min-ing Trillions of Time Series Subsequences under Dynamic TimeWarping">
                                        <b>[27]</b>
                                        Rakthanmanon T, Campana B, Mueen A, et al. Searching and mining trillions of time series subsequences under dynamic time warping[C] //Proc of the 18th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2012: 262- 270
                                    </a>
                                </li>
                                <li id="417">


                                    <a id="bibliography_28" title="Begum N, Keogh E.Rare time series motif discovery from unbounded streams[J]. Proc of the VLDB Endowment, 2014, 8 (2) : 149- 160" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rare time series motif discovery from unbounded streams">
                                        <b>[28]</b>
                                        Begum N, Keogh E.Rare time series motif discovery from unbounded streams[J]. Proc of the VLDB Endowment, 2014, 8 (2) : 149- 160
                                    </a>
                                </li>
                                <li id="419">


                                    <a id="bibliography_29" title="Mueen A, Zhu Yan, Yeh M et al. The fastest similarity search algorithm for time series subsequences under Euclidean distance[EB/OL]. [2017-08-12]. http://www.cs.unm.edu/～mueen/FastestSimilaritySearch.html" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The fastest similarity search algorithm for time series subsequences under Euclidean distance">
                                        <b>[29]</b>
                                        Mueen A, Zhu Yan, Yeh M et al. The fastest similarity search algorithm for time series subsequences under Euclidean distance[EB/OL]. [2017-08-12]. http://www.cs.unm.edu/～mueen/FastestSimilaritySearch.html
                                    </a>
                                </li>
                                <li id="421">


                                    <a id="bibliography_30" title="Bagnall A, Davis L, Hills J, et al. Transformation based ensembles for time series classification[C] //Proc of the 12th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2012: 307- 318" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Transformation based ensembles for time series classification">
                                        <b>[30]</b>
                                        Bagnall A, Davis L, Hills J, et al. Transformation based ensembles for time series classification[C] //Proc of the 12th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2012: 307- 318
                                    </a>
                                </li>
                                <li id="423">


                                    <a id="bibliography_31" >
                                        <b>[31]</b>
                                    Demšar J. Statistical comparisons of classifiers over multiple data sets[J]. Journal of Machine Learning Research, 2006, 7 (1) : 1- 30</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(03),594-610 DOI:10.7544/issn1000-1239.2019.20170741            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于相似性连接的时间序列Shapelets提取</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%8C%AF%E5%9B%BD&amp;code=22077138&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张振国</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E8%B6%85&amp;code=08110651&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王超</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B8%A9%E5%BB%B6%E9%BE%99&amp;code=29192060&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">温延龙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%A2%81%E6%99%93%E6%B4%81&amp;code=08109249&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">袁晓洁</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%BB%B6%E8%BE%B9%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E7%B3%BB&amp;code=0019391&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">延边大学计算机科学与技术系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E5%BC%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0205377&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南开大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E5%BC%80%E5%A4%A7%E5%AD%A6%E7%BD%91%E7%BB%9C%E7%A9%BA%E9%97%B4%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南开大学网络空间安全学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在时间序列分类问题中, 以Shapelets特征为基础的分类算法具有很高的分类准确率和良好的可解释性, 因此, 高辨别能力Shapelets的提取已成为时间序列研究领域重要的研究热点之一.对于Shapelets提取的研究已取得了很多优秀的成果, 但仍存在一些问题, 主要是由于通过遍历所有子序列来获取Shapelets的方式非常耗时.尽管可以采取剪枝策略优化该过程, 但往往会损失分类准确率.为此, 提出一种基于相似性连接的Shapelets提取方法, 该方法舍弃逐一判断子序列分类能力的策略, 而是以子序列为单位, 通过相似性连接的思想构建时序数据间的相似性向量.对于不同类别的时序数据, 计算每一对时序数据间的差异向量, 进而得到表示时序数据集中不同类别间差异的候选矩阵, 然后根据候选矩阵的数值差异, 快速筛选出具有高分类能力的Shapelets集合.在真实数据集上的大量实验表明:相比于现有的Shapelets提取方法, 这种相似性连接方法所得到的Shapelets在分类任务中不仅具有很好的时间效率, 而且能保证高分类准确率.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时间序列;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Shapelets&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Shapelets;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%BF%9E%E6%8E%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相似性连接;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B7%AE%E5%BC%82%E5%90%91%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">差异向量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%80%99%E9%80%89%E7%9F%A9%E9%98%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">候选矩阵;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *袁晓洁, yuanxj@nankai.edu.cn;
                                </span>
                                <span>
                                    张振国, zhangzhenguo@dbis.nankai.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-09-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61772289);</span>
                                <span>吉林省教育厅“十三五”科学技术项目 (JJKH20191125KJ);</span>
                    </p>
            </div>
                    <h1><b>Time Series Shapelets Extraction via Similarity Join</b></h1>
                    <h2>
                    <span>Zhang Zhenguo</span>
                    <span>Wang Chao</span>
                    <span>Wen Yanlong</span>
                    <span>Yuan Xiaojie</span>
            </h2>
                    <h2>
                    <span>Department of Computer Science and Technology, Yanbian University</span>
                    <span>College of Computer Science, Nankai University</span>
                    <span>College of Cyber Science, Nankai University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>For time series classification, the classifier built by Shapelets has high classification accuracy and, meanwhile, the classification results are easily interpretable. Therefore, the extraction of discriminative Shapelets has attracted a lot of attention in the field of time series data mining. Research on Shapelets extraction has obtained promising achievement, but there are still some problems. The main reason is that the traversal of all time series subsequences to find the discriminative Shapelets is extraordinarily time consuming. Although some pruning techniques can be applied to accelerate the extraction process, they usually reduce the classification accuracy. In this paper, we propose a novel Shapelets extraction method based on similarity join, which abandons the idea of computing each subsequence's discriminative power. In the proposed method, each subsequence is considered as a basic computing unit and the similarity vector of two time series is obtained by the similarity join calculation of their subsequences. For the time series with different class label, we compute the difference vector of each time series pair and merge them into a candidate matrix which represents the differences between different time series class. Thus, we can easily obtain the eligible Shapelets from the candidate matrix. Extensive experimental results in real time series datasets show that, compared with the exist Shapelets extraction methods, the proposed method has high time efficiency while ensuring excellent classification accuracy.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=time%20series&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">time series;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Shapelets&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Shapelets;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=similarity%20join&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">similarity join;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=difference%20vector&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">difference vector;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=candidate%20matrix&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">candidate matrix;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Zhang Zhenguo, born in 1981.PhD.His main research interests include machine learning and data mining.<image id="359" type="formula" href="images/JFYZ201903015_35900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Chao, born in 1990.Master.His main research interests include information retrieval and data mining.<image id="360" type="formula" href="images/JFYZ201903015_36000.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wen Yanlong, born in 1979.PhD.Senior engineer.His main research interests include database, data mining and information retrieval.<image id="361" type="formula" href="images/JFYZ201903015_36100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Yuan Xiaojie, born in 1963.PhD.Professor, PhD supervisor.Her main research interests include data management and data mining.<image id="362" type="formula" href="images/JFYZ201903015_36200.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2017-09-29</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61772289);</span>
                                <span>the “13th Five-year” Science and Technology Project of the Jilin Provincial Education Department (JJKH20191125KJ);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="73">近年来, 对于时间序列数据 (time series, 简称时序数据) 的研究与分析受到越来越多的关注, 已成为数据挖掘领域的一个重要的研究课题<citation id="426" type="reference"><link href="363" rel="bibliography" /><link href="365" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>, 其原因在于时序数据广泛地存在于我们日常生活的诸多领域, 如医疗、金融、运动轨迹以及天文星系观测等<citation id="425" type="reference"><link href="367" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>.一般来说, 时序数据是由某一观测量随时间变化产生的, 每一数据值之间有严格的时间先后顺序, 这是时序数据区别于其他类型数据的本质特征.广义上, 任何具有严格先后顺序的数值构成的序列, 都可以称为时序数据.作为一项基础工作, 时序数据的分类是被研究最多的问题之一, 具有重要的应用价值, 如在心电图信号分析中, 对其进行分类能够快速鉴别信号的正常与异常, 有助于辅助医疗;在工业生产中, 对设备性能数据的采集与分类, 能够及时了解设备的运行状况.相比于其他数据的分类, 在提取时序数据特征, 构建分类器的过程中, 数据之间的先后顺序是必须要考虑的关键因素.因此, 以时序数据整体作为处理对象, 利用数据间相似性的最近邻分类器 (nearest neighbor classifier, NN) 被首先用于时序数据的分类问题<citation id="427" type="reference"><link href="369" rel="bibliography" /><link href="371" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="74">基于NN分类器的时序分类算法的核心在于如何计算时序数据间的相似性.由于噪音、采集时间上的对齐等因素, 时序数据在获取过程中可能会存在一些轻微的幅值偏移, 这就使得在计算时序数据间的相似性时, 相似性算法必须能够处理这种时间轴上的数据错位现象.有2种类型的相似性计算方式被广泛应用:1) 基于动态时间规整 (dynamic time warping, DTW) 的距离计算<citation id="428" type="reference"><link href="373" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>;2) 基于编辑距离 (edit distance) 的相似度计算<citation id="429" type="reference"><link href="375" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>.DTW及其相关改进算法, 如导数DTW (derivative DTW) <citation id="430" type="reference"><link href="377" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、权重DTW (weighted DTW) <citation id="431" type="reference"><link href="379" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 通过寻找一条有效的规整路径来最小化对应的时序数据点间的总距离并借此计算2条时序数据的相似性.DTW已被认为是时序数据相似性计算的基准<citation id="432" type="reference"><link href="371" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.同DTW一样, 编辑距离也通过寻找数据间的最佳匹配来计算相似度, 所不同的是, 基于编辑距离的方法, 如时间规整编辑 (time warp edit, TWE) <citation id="433" type="reference"><link href="381" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、移动-分裂-融合 (move-split-merge, MSM) <citation id="434" type="reference"><link href="383" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 允许数据间存在跨越和改变.这2种类型的时序数据相似性计算被称为弹性距离度量 (elastic distance measures) .在很长一段时间内, 使用这些弹性距离度量的简单NN算法在时序数据分类问题上占据主要地位且很难被超过<citation id="435" type="reference"><link href="385" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.然而, 由于NN算法需要存储和搜索整个时序数据集, 而这些弹性距离度量的计算又比较耗时 (通常情况下, 时间复杂度为<i>O</i> (<i>m</i><sup>2</sup>) , <i>m</i>为时序数据长度) , 这就导致在处理较大时序数据集时, 时间和空间的消耗都比较大, 限制了其应用.另一方面, 这种方法是将时序数据作为整体来考虑的, 然而更多的时候, 对于时序数据类别区分起关键作用的是局部信息而非全局信息, 同时, 局部信息更能体现出时序数据间的本质差异.</p>
                </div>
                <div class="p1">
                    <p id="75">为了解决上述2个问题, Ye等人<citation id="436" type="reference"><link href="387" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出使用子序列 (subsequence) 作为区分不同类别的依据, 并将具有高类别可区分的子序列称为Shapelets.相比于使用NN分类器的算法, Shapelets提供了良好的可解释性, 易于体现不同类别时序数据之间的关键差异.因此, Shapelets一经提出便受到研究者的关注.如何快速提取高质量的Shapelets已成为最近几年时序数据处理领域的一个热点问题.然而, 由于任意长度的时序子序列都可能是Shapelets, 而子序列数量庞大 (例如长度为60, 时序数量为600的数据集, 子序列数量达1.098×10<sup>6</sup>) , 所以逐一判断子序列的类别可分能力是一项非常耗时的工作.针对该问题, Ye等人<citation id="437" type="reference"><link href="387" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出使用剪枝策略加速子序列分类能力的判断.这些策略对于小数据集是可行的, 但对于大数据集仍难以处理.为了提高Shapelets提取效率, 许多使用加速技术的算法被提出, 如使用空间换时间的Logical Shapelets算法<citation id="438" type="reference"><link href="389" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、借助时序数据的离散化SAX (symbolic aggregate approximation) <citation id="439" type="reference"><link href="391" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation> 表示的Fast Shapelets算法<citation id="440" type="reference"><link href="393" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>等.这些方法虽然能够在一定程度上加速Shapelets的提取, 但仍需要大的时间消耗, 且会损失一定的预测准确率.除此之外, Hills等人<citation id="441" type="reference"><link href="395" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>更改子序列分类能力度量方法, 使用易于计算的Kruskal-Wallis度量和F-statistic作为衡量标准, 但加速效果并不明显, 并且降低了分类准确率.</p>
                </div>
                <div class="p1">
                    <p id="76">除了上述直接使用提取的Shapelets构建分类器外, Lines等人<citation id="442" type="reference"><link href="397" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出了一种使用Shapelets构建对应时序数据特征向量的方法, 可以使用当前比较成熟的分类器, 如SVM, 而不必拘束于Ye等人<citation id="443" type="reference"><link href="387" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>使用的决策树分类器.使用时序数据的特征向量表示, 一方面可以保证Shapelets的可解释特性, 另一方面可以充分利用成熟分类器的优点, 提高分类准确率.该方法的关键问题仍然是如何提取出高质量的Shapelets, 然而作者并没有改变辨别子序列分类能力的方式, 故其方法仍然非常耗时.</p>
                </div>
                <div class="p1">
                    <p id="77">为此, 本文在Yeh等人<citation id="444" type="reference"><link href="399" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>所提出的时间序列matrix profile基础上, 提出了一种基于相似性连接的时间序列数据Shapelets提取方法.该方法舍弃了现有工作中先生成子序列, 再对子序列进行区分能力判断的方案, 而是通过差异向量体现不同类别时序数据本身的差异, 利用相似性连接策略快速计算出隐含高分类能力Shapelets的候选矩阵, 然后通过对比候选矩阵中的数值差异, 筛选出Shapelets集合.以子序列为单位的时序数据间的相似性可以通过快速傅里叶变换计算得到, 大大减少了距离计算带来的时间消耗.在获得Shapelets集合之后, 利用这些Shapelets将原时序数据集转换成相应的特征向量表示, 使用SVM分类器完成分类工作.本文在多个领域的真实数据集上进行一系列实验, 对比了目前主要Shapelets提取算法.实验结果表明:本文提出的Shapelets提取算法具有很好的时间效率, 同时, 又能保证很高的分类准确率, 与其他算法相比具有更好的实用性.</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="79">目前的研究工作中对于Shapelets的提取思路主要有2种:基于搜索的策略<citation id="445" type="reference"><link href="387" rel="bibliography" /><link href="389" rel="bibliography" /><link href="393" rel="bibliography" /><link href="395" rel="bibliography" /><link href="401" rel="bibliography" /><link href="403" rel="bibliography" /><link href="405" rel="bibliography" /><link href="407" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>和基于学习的策略<citation id="446" type="reference"><link href="409" rel="bibliography" /><link href="411" rel="bibliography" /><sup>[<a class="sup">24</a>,<a class="sup">25</a>]</sup></citation>.</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80"><b>1.1 基于搜索策略的Shapelets提取</b></h4>
                <div class="p1">
                    <p id="81">在Shapelets提取最初的研究中, 其基本思路是考虑训练数据中的所有子序列, 然后使用信息增益 (information gain, IG) 来评估每一个子序列对于类别的区分能力, 通过循环获取当前训练数据中具有最优信息增益度量的子序列来构建决策树分类器, 实现时序数据的分类<citation id="447" type="reference"><link href="387" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.类似于信息增益度量, 一些新的度量方式, 如F-Statistic, Kruskall-Wallis等, 也被应用于衡量子序列的区分能力, 但从效果上来看, 信息增益要优于这些度量方式<citation id="448" type="reference"><link href="395" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="82">由于时序数据子序列数目众多, 逐一进行判断的brute-force算法需要大量的运行时间, 其时间复杂度为<i>O</i> (<i>n</i><sup>2</sup><i>m</i><sup>4</sup>) (<i>n</i>为训练集中时序数据的条数) , 因此, 相应的剪枝方法和加速技术是研究的重点.基于最小距离的提前终止计算和基于信息增益的熵剪枝是最早提出的策略<citation id="449" type="reference"><link href="387" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 这些策略虽然在一定程度上可以加速搜索过程, 但仍然十分耗时.Mueen等人<citation id="450" type="reference"><link href="389" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出以空间换时间的方法, 使用5个充分统计量使得在距离计算过程中可以部分重用之前的结果.另外, 使用新的度量方式 (信息增益上界) 来减少耗时的熵的计算.通过这些技术, 算法的时间复杂度被减少至<i>O</i> (<i>n</i><sup>2</sup><i>m</i><sup>3</sup>) .在文献<citation id="451" type="reference">[<a class="sup">14</a>]</citation>的基础上, 原继东等人<citation id="452" type="reference"><link href="401" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出利用Shapelets之间的逻辑组合关系来提高分类准确率, 但并没有提升Shapelets提取效率.为进一步压缩搜索空间, Rakthanmanon等人<citation id="453" type="reference"><link href="393" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>借助于时序数据符号化表示, 将时序数据离散化, 在低维空间中通过随机映射方法快速过滤掉类别区分能力低的子序列.对于筛选出的有可能成为Shapelets的子序列, 则继续使用信息增益加以判断.该方法能够大大减小搜索空间, 使得时间复杂度降低至<i>O</i> (<i>nm</i><sup>2</sup>) .</p>
                </div>
                <div class="p1">
                    <p id="83">除了使用加速技术改进算法外, 其他方式的策略也被用于加快Shapelets提取.Chang等人<citation id="454" type="reference"><link href="403" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>借助GPU运算对不同的子序列使用并行化方法来判断子序列分类能力.然而, 这一方面需要对距离计算方式做较大的修改, 另一方面, 其Shapelets的搜索时间非常依赖于硬件性能.Wistuba等人<citation id="455" type="reference"><link href="405" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>基于有区分能力的Shapelets应当在时序数据中经常出现的假设, 使用随机采样的方式构成Shapelets.这种策略确实可以减少运行时间, 但分类准确率相对较低.Zhang等人<citation id="456" type="reference"><link href="407" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>提出没有数值变化的子序列成为Shapelets的可能性很小, 只利用有数值变化的子序列构成Shapelets候选空间.这种方法大大减小搜索空间, 有很好的加速效果, 但本质上并没有改变算法时间复杂度.</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>1.2 基于学习策略的Shapelets提取</b></h4>
                <div class="p1">
                    <p id="85">与搜索整个子序列空间不同, 基于学习的策略试图寻找针对Shapelets提取的数学表示作为时序数据分类的目标函数, 通过优化算法从时序数据集中学习到Shapelets.以这种方式得到的Shapelets有可能不是时序数据中的子序列, 但确能将不同类别的时序更好地区分.Grabocka等人<citation id="457" type="reference"><link href="409" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>使用logistic回归分类模型构建Shapelets提取的目标函数, 称为LTS (learning time series) , 以随机梯度的方式不断地优化目标函数, 使损失将至最低, 进而构造出Shapelets.该方法得到的Shapelets往往不是某条时序数据中的子序列, 而是能够对数据进行划分的特征.目前, LTS仍然是在不使用集成策略前提下的分类效果最好的算法<citation id="458" type="reference"><link href="413" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>.但是这种策略的最大问题是时间和空间消耗都很大, 在硬件资源受限情况下无法得到分类结果.另一种基于学习的方法是由Hou等人<citation id="459" type="reference"><link href="411" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>提出的FLAG (fused lasso generalized eigenvector method) 算法, 与LTS直接优化产生Shapelets不同, FLAG通过构建目标函数来寻找具有好的分类能力的数据所在的位置信息, 然后提取这些位置上的子序列形成Shapelets.这种方法的优点是速度快, 但是分类准确率有一定的降低.</p>
                </div>
                <h3 id="86" name="86" class="anchor-tag"><b>2 相关定义与符号表示</b></h3>
                <div class="p1">
                    <p id="87"><b>定义1</b>. 时序数据.一条时序数据是一组实数值变量组成的向量, 表示为<b><i>T</i></b>= (<i>t</i><sub>1</sub>, <i>t</i><sub>2</sub>, …, <i>t</i><sub><i>m</i></sub>) , 其中<i>m</i>为时序数据的长度.</p>
                </div>
                <div class="p1">
                    <p id="88"><b>定义2</b>. 子序列.给定长度为<i>m</i>时序数据<b><i>T</i></b>, 子序列<b><i>S</i></b>是<b><i>T</i></b>中的一个连续片段, 记为<b><i>S</i></b>= (<i>t</i><sub><i>p</i></sub>, <i>t</i><sub><i>p</i>+1</sub>, …, <i>t</i><sub><i>p</i>+<i>l</i>-1</sub>) , 其中<i>p</i>为子序列在<b><i>T</i></b>中的起始位置, <i>l</i>为子序列长度, 1≤<i>p</i>≤<i>m</i>-<i>l</i>+1.</p>
                </div>
                <div class="p1">
                    <p id="89">长度为<i>m</i>的时序数据<b><i>T</i></b>中包含<i>m</i>-<i>l</i>+1条长度为<i>l</i>的子序列, 可以使用滑动窗口逐一取出.</p>
                </div>
                <div class="p1">
                    <p id="90"><b>定义3</b>. 全子序列集合.时序数据<b><i>T</i></b>的全子序列集合是指由长度为<i>l</i>的滑动窗口在<b><i>T</i></b>上生成的子序列集合, 记为<i>A</i>={<b><i>S</i></b><sub>1, <i>l</i></sub>, <b><i>S</i></b><sub>2, <i>l</i></sub>, …, <b><i>S</i></b><sub><i>m</i>-<i>l</i>+1, <i>l</i></sub>}.为了表示方便, 本文使用<b><i>A</i></b>[<i>i</i>]表示<b><i>S</i></b><sub><i>i</i>, <i>l</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="91">时序数据间的相似性通常是通过距离大小来度量的, 长度相等的2条时序数据<b><i>T</i></b>与<b><i>R</i></b>之间的距离</p>
                </div>
                <div class="p1">
                    <p id="92"><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Τ</mi><mo>, </mo><mi mathvariant="bold-italic">R</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>.      (1) </p>
                </div>
                <div class="p1">
                    <p id="94">式 (1) 只能度量长度相等的时序数据, 而本文主要的处理对象是子序列, 也就是在不等长情况下度量序列间的相似性, 为此, 需要定义子序列与时序数据间的距离表示.</p>
                </div>
                <div class="p1">
                    <p id="95"><b>定义4</b>. 子序列与时序数据的距离.给定时序数据<b><i>T</i></b> (全子序列集合为<i>A</i>) 及子序列<b><i>S</i></b>, 两者之间的距离定义为子序列<b><i>S</i></b>在<b><i>T</i></b>中最优匹配时的欧氏距离:</p>
                </div>
                <div class="p1">
                    <p id="96"><i>sd</i> (<b><i>T</i></b>, <b><i>S</i></b>) =min (<i>d</i> (<b><i>A</i></b><citation id="460" type="reference">[<a class="sup">1</a>]</citation>, <b><i>S</i></b>) , <i>d</i> (<b><i>A</i></b><citation id="461" type="reference">[<a class="sup">2</a>]</citation>, <b><i>S</i></b>) , …, <i>d</i> (<b><i>A</i></b>[<i>m</i>-<i>l</i>+1], <b><i>S</i></b>) ) .      (2) </p>
                </div>
                <div class="p1">
                    <p id="98">图1直观地描述了距离<i>sd</i> (<b><i>T</i></b>, <b><i>S</i></b>) 中最小值的含义.</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 子序列S在T中的最优匹配示例" src="Detail/GetImg?filename=images/JFYZ201903015_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 子序列<b><i>S</i></b>在<b><i>T</i></b>中的最优匹配示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Illustration of best matching in <b><i>T</i></b> for subsequence <b><i>S</i></b></p>

                </div>
                <div class="p1">
                    <p id="100">尽管式 (2) 易于理解, 但由于子序列数量庞大, 其计算需要大量的运行时间, Yeh等人<citation id="462" type="reference"><link href="399" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出借助均值、方差等充分统计量和点积运算来降低计算的复杂度, 即<b><i>S</i></b>与<b><i>T</i></b>中每一条子序列之间的计算为</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>, </mo><mi mathvariant="bold-italic">S</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mn>2</mn><mi>l</mi><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mi mathvariant="bold-italic">A</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>⋅</mo><mi mathvariant="bold-italic">S</mi><mo>-</mo><mi>l</mi><mi>μ</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">A</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow></msub><mi>μ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">S</mi></msub></mrow><mrow><mi>l</mi><mi>σ</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">A</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow></msub><mi>σ</mi><msub><mrow></mrow><mi mathvariant="bold-italic">S</mi></msub></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></msqrt><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">其中, <i>μ</i><sub><b><i>A</i></b>[<i>i</i>]</sub>, <i>μ</i><sub><b><i>S</i></b></sub>, <i>σ</i><sub><b><i>A</i></b>[<i>i</i>]</sub>, <i>σ</i><sub><b><i>S</i></b></sub>分别为子序列<b><i>A</i></b>[<i>i</i>], <b><i>S</i></b>的均值和方差.通常情况下, 对于每一条子序列, 均值和方差的计算时间复杂度为<i>O</i> (<i>l</i>) , 但可以通过存储<b><i>T</i></b>中数据值和数据值平方的累积和向量, 使得在每一次运算中都可以直接用来计算任意长度的子序列的均值和方差<citation id="463" type="reference"><link href="415" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>.这样, 在式 (3) 中, <b><i>A</i></b>[<i>i</i>]与<b><i>S</i></b>的点积运算就成为制约计算效率的关键因素, 3.2.1节将给出快速计算该点积操作的算法.</p>
                </div>
                <div class="p1">
                    <p id="103"><b>定义5</b>. 最近邻函数.给定2条时序数据的全子序列集合<i>A</i>和<i>B</i>, 对于任意一子序列对&lt;<b><i>A</i></b>[<i>i</i>], <b><i>B</i></b>[<i>j</i>]&gt;, 如果<b><i>A</i></b>[<i>i</i>]在<i>B</i>中的最优匹配是<b><i>B</i></b>[<i>j</i>], 则最近邻函数<i>θ</i>值为1, 否则为0, 即:</p>
                </div>
                <div class="area_img" id="104">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201903015_10400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="106">其中, <i>k</i>∈[1, <i>m</i>-<i>l</i>+1]且<i>k</i>≠<i>j</i>.使用最近邻函数, 可以得到2条时序数据的相似性连接向量.</p>
                </div>
                <div class="p1">
                    <p id="107"><b>定义6</b>. 相似性连接向量.给定2条时序数据的全子序列集合<i>A</i>和<i>B</i>, 对于<i>A</i>中的每一条子序列<b><i>A</i></b>[<i>i</i>], 使用最近邻函数在<i>B</i>中寻找其最优匹配<b><i>B</i></b>[<i>j</i>], 每一个匹配对之间的距离所构成的向量称为<i>A</i>与<i>B</i>之间的相似性连接向量, 记为<b><i>P</i></b><sub><i>A B</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="108">需要注意的是, <b><i>P</i></b><sub><i>A B</i></sub>是有序的, 在计算过程中严格按照第1条时序的全子序列集合<i>A</i>中子序列的先后顺序寻找在<i>B</i>中的最近邻, 也就是说<i>A</i>中的子序列一定会在<i>θ</i>=1的最优匹配对中出现, 而<i>B</i>中的子序列不一定全部在<i>θ</i>=1的匹配对中, 因此, <b><i>P</i></b><sub><i>A B</i></sub>并不是对称的, 即<b><i>P</i></b><sub><i>A B</i></sub>≠<b><i>P</i></b><sub><i>BA</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="109"><b>定义7</b>. 自相似性连接向量.在计算<b><i>P</i></b><sub><i>A B</i></sub>时, 若<i>B</i>=<i>A</i>, 这样构成的相似性连接向量称为自相似性连接向量, 记为<b><i>P</i></b><sub><i>A A</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="110"><b><i>P</i></b><sub><i>A A</i></sub>可看作表示一条时序数据的元数据.由于每一条子序列都来自该时序数据, 所以总能找到距离为0的最优匹配以及在最优匹配附近近似等于0的匹配子序列, 这样的匹配对于描述数据特性是没有意义的, 通常称之为平凡匹配 (trivial matching) <citation id="464" type="reference"><link href="417" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>.因此, 在计算过程中, 需要避免这样的匹配.2条时序数据之间的相似性可以通过<b><i>P</i></b><sub><i>A A</i></sub>和<b><i>P</i></b><sub><i>A B</i></sub>表现出来, 为此, 我们定义差异向量来描述时序数据之间的差异.</p>
                </div>
                <div class="p1">
                    <p id="111"><b>定义8</b>. 差异向量.对于2条不同时序数据的全子序<i>A</i>和<i>B</i>, 则两者的差异向量<b><i>Dif</i></b><b><i>f</i></b><sub><i>A B</i></sub>定义为以<i>A</i>为基准的相似性连接向量<b><i>P</i></b><sub><i>A B</i></sub>和<i>A</i>的自相似性连接向量<b><i>P</i></b><sub><i>A A</i></sub>之间差的绝对值, 形式化表示为:若</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>A</mi><mtext> </mtext><mi>B</mi></mrow></msub><mo>=</mo><mo stretchy="false"> (</mo><mi>d</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mi>A</mi><mtext> </mtext><mi>B</mi></mrow></msubsup><mo>, </mo><mi>d</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>A</mi><mtext> </mtext><mi>B</mi></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>d</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>A</mi><mtext> </mtext><mi>B</mi></mrow></msubsup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>A</mi><mtext> </mtext><mi>A</mi></mrow></msub><mo>=</mo><mo stretchy="false"> (</mo><mi>d</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mi>A</mi><mtext> </mtext><mi>A</mi></mrow></msubsup><mo>, </mo><mi>d</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>A</mi><mtext> </mtext><mi>A</mi></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>d</mi><msubsup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>A</mi><mtext> </mtext><mi>A</mi></mrow></msubsup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">则<b><i>Dif</i></b><b><i>f</i></b><sub><i>A B</i></sub>= (|<i>d</i><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mi>A</mi><mtext> </mtext><mi>B</mi></mrow></msubsup></mrow></math></mathml>-<i>d</i><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mi>A</mi><mtext> </mtext><mi>A</mi></mrow></msubsup></mrow></math></mathml>|, …, |<i>d</i><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>A</mi><mtext> </mtext><mi>B</mi></mrow></msubsup></mrow></math></mathml>-<i>d</i><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>A</mi><mtext> </mtext><mi>A</mi></mrow></msubsup></mrow></math></mathml>|) .</p>
                </div>
                <div class="p1">
                    <p id="118">在时序数据集中, 如果同一类的时序数据之间在<b><i>Dif</i></b><b><i>f</i></b><sub><i>A B</i></sub>的某些分量上值比较小, 而在不同类的数据上值比较大, 则可认为相应的子序列是具有较高的类别可分性, 是比较好的Shapelets.在第3节中, 将详细描述如何使用这些定义提取高质量的Shapelets.</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag"><b>3 Shapelets提取</b></h3>
                <div class="p1">
                    <p id="120">本文所提出的基于相似性连接的时序数据Shapelets提取主要由3部分构成:1) 数据的预处理过程, 主要完成对时序数据集的精简工作, 只保留对Shapelets提取起关键作用的训练数据以加速后续处理;2) 通过计算相似性连接向量、自相似性连接向量及差异向量来生成Shapelets候选矩阵, 然后从候选矩阵中提取相对应的子序列, 并对这些子序列进行合并操作实现Shapelets提取, 这是本文的核心;3) 完成时序数据的转换工作, 借助已提取的Shapelets将时序数据转换为由距离值构成的特征向量表示.对于时序数据的特征向量表示, 使用现有成熟的分类器, 如SVM, 完成分类工作.本文方法的整体框架及流程如图2所示:</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文方法的整体框架及流程" src="Detail/GetImg?filename=images/JFYZ201903015_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文方法的整体框架及流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The overall framework and whole process of the proposed method</p>

                </div>
                <h4 class="anchor-tag" id="122" name="122"><b>3.1 关键时序数据的选择</b></h4>
                <div class="p1">
                    <p id="123">在时序数据集中, 往往存在着一些高度相似的数据, 其全子序列集合也非常相近.由于使用相似性连接向量计算差异向量的过程相对复杂, 因此, 对原始时序数据集进行精简, 只选择相似度比较小的关键时序数据进行计算是十分必要的.Wistuba等人<citation id="465" type="reference"><link href="405" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>基于Shapelets在时序数据集中出现的频率高的假设所做的工作也验证了只选用关键时序数据提取高质量的Shapelets是可行的.</p>
                </div>
                <div class="p1">
                    <p id="124">由于在选择关键时序数据时不仅要求整体上有极大的相似度, 还需要子序列之间也要高度相似, 因此本文使用不具有任何偏移处理的欧氏距离 (式 (1) ) 计算时序数据间的相似程度.通常情况下, 同类别中存在高相似性的数据的可能性大, 而不同类之间, 时序数据的差异较大.基于此, 本文按类别分别进行关键时序数据的选择.对于每一类中的时序数据, 使用队列作为核心数据, 计算队首时序与其他时序的距离, 若距离小于预先设定的阈值, 则认为两者有高度相似性, 然后提取队首时序作为关键时序数据, 而与队首时序相似的时序就可以舍弃.具体算法如算法1所示:</p>
                </div>
                <div class="p1">
                    <p id="125"><b>算法1</b>. 关键时序选取算法.</p>
                </div>
                <div class="p1">
                    <p id="126">输入:时序数据集<i>dataSet</i>、相似度阈值<i>mthres</i>;</p>
                </div>
                <div class="p1">
                    <p id="127">输出:关键时序数据集 <i>nDataSet</i>.</p>
                </div>
                <div class="p1">
                    <p id="128">① <i>tempDataSet</i>=<i>partitionByClasses</i> (<i>dataSet</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="129">② <i>nDataSet</i>=[];</p>
                </div>
                <div class="p1">
                    <p id="130">③ for each <i>classData</i> in <i>tempDataSet</i></p>
                </div>
                <div class="p1">
                    <p id="131">/*每一类*/</p>
                </div>
                <div class="p1">
                    <p id="132">④ <i>queue</i>=<i>index</i> (<i>classData</i>) ; /*使用队列存储当前类时序的索引*/</p>
                </div>
                <div class="p1">
                    <p id="133">⑤ while <i>queue</i> is not empty</p>
                </div>
                <div class="p1">
                    <p id="134">⑥ <i>pos</i>=<i>distance</i> (<i>classData</i>, <i>queue</i>, <i>mthres</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="135">/*查找当前类别中与队首数据距离小于阈值的时序的位置*/</p>
                </div>
                <div class="p1">
                    <p id="136">⑦ <i>queue</i>=<i>remove</i> (<i>queue</i>, <i>pos</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="137">/*删除队列中<i>pos</i>位置的索引*/</p>
                </div>
                <div class="p1">
                    <p id="138">⑧ <i>nDataSet</i>=[<i>nDataSet</i>;<i>classData</i> (<i>queue</i><citation id="466" type="reference">[<a class="sup">1</a>]</citation>) ];</p>
                </div>
                <div class="p1">
                    <p id="139">⑨ end while</p>
                </div>
                <div class="p1">
                    <p id="140">⑩ end for</p>
                </div>
                <div class="p1">
                    <p id="141">算法1所消耗的运行时间是很少的.首先, 算法在选取关键时序数据时是以类别为单位的, 不同类的时序数据间不进行距离计算, 这使得参与相似度计算的时序数据条数大大减少.其次, 在每次迭代过程中, 算法在只保留1条关键时序数据的同时, 从队列中删除与之相似的数据, 减少了下次迭代过程中参与计算的时序数量.具体地说, 若时序数据集 (大小为<i>n</i>) 的第<i>i</i>类中含有<i>n</i><sub><i>i</i></sub>条时序, 则在最好情况下, 所有时序均相似, 每一条时序只参与一次距离计算 (<i>n</i><sub><i>i</i></sub>-1次) ;在最坏情况下, 所有时序均不相似, 需进行<i>n</i><sub><i>i</i></sub> (<i>n</i><sub><i>i</i></sub>-1) /2次距离计算, 故算法1在处理第<i>i</i>类时序数据时距离计算的次数介于<i>n</i><sub><i>i</i></sub>-1至<i>n</i><sub><i>i</i></sub> (<i>n</i><sub><i>i</i></sub>-1) /2之间.因此, 算法1的距离计算次数约为<i>n</i>～<i>n</i> (<i>n</i><sub><i>i</i></sub>-1) /2.通常情况下, <i>n</i><sub><i>i</i></sub>要比<i>n</i>小得多且数据集中存在大量的相似时序数据, 所以算法1具有很高的时间效率.</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142"><b>3.2 候选矩阵</b></h4>
                <div class="p1">
                    <p id="143">候选矩阵 (candidate matrix) 是本文基于相似性连接策略提取时序数据Shapelets的核心, 候选矩阵中隐含着可用于表示类别差异的Shapelets, 其值表示相连接的时序在相应子序列上的差异, 值越大, 对应子序列区分能力越强, 因此, 可从候选矩阵中快速定位并提取出高类别可分性的子序列.候选矩阵生成的时间消耗是影响算法整体效率的关键因素, 如何快速的生成候选矩阵是本文的重点研究内容.</p>
                </div>
                <div class="p1">
                    <p id="144">计算候选矩阵的关键是相似性连接, 而相似性连接属于全匹配问题, 即需要计算出时序数据全子序列集合中每一个子序列在其他集合中的最近邻子序列.候选矩阵的计算分为3个部分:1) 计算距离向量, 即子序列与时序数据全部子序列间的欧氏距离;2) 根据相似性连接策略计算两条时序数据全子序列集合间的最优匹配, 得到两者之间的相似性连接向量;3) 利用2条时序数据的相似性连接向量和其中1条时序数据的自相似性连接向量构造差异向量, 将由同一条时序数据的自相似性连接向量得到的差异向量合并, 即可组成候选矩阵.</p>
                </div>
                <h4 class="anchor-tag" id="145" name="145">3.2.1 距离向量的快速计算</h4>
                <div class="p1">
                    <p id="146">距离向量是某一子序列<i>S</i>与一条时序数据<i>T</i>全部子序列之间的欧氏距离构成的向量, 其核心是2个子序列距离的计算问题.然而, 由于子序列数量庞大, 逐个计算子序列间的距离会消耗大量的运行时间, 降低算法效率.为此, 本文根据Rakthanmanon等人<citation id="467" type="reference"><link href="415" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>提出的方法, 使用式 (3) 的计算方式, 实现子序列与时序数据全子序列集合之间距离的快速计算.式 (3) 中最关键部分是子序列之间内积的运算, Mueen等人<citation id="468" type="reference"><link href="419" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>已经证明, 借助快速傅里叶变换, 可以使得子序列与时序数据全部子序列之间的内积在1次计算中完成.距离向量的具体实现如下:</p>
                </div>
                <div class="p1">
                    <p id="147"><b>算法2</b>. 距离向量计算算法<i>distanceVector</i>.</p>
                </div>
                <div class="p1">
                    <p id="148">输入:时序数据<b><i>T</i></b>及长度<i>m</i>、子序列<b><i>S</i></b>及长度<i>l</i>;</p>
                </div>
                <div class="p1">
                    <p id="149">输出:<b><i>S</i></b>与<b><i>T</i></b>的距离向量<b><i>D</i></b>.</p>
                </div>
                <div class="p1">
                    <p id="150">① [<i>μ</i><sub><b><i>T</i></b></sub>, <i>μ</i><sub><b><i>S</i></b></sub>, <i>σ</i><sub><b><i>T</i></b></sub>, <i>σ</i><sub><b><i>S</i></b></sub>]=<i>meanStd</i> (<b><i>S</i></b>, <b><i>T</i></b>) ; /*根据文献0计算均值方差*/</p>
                </div>
                <div class="p1">
                    <p id="151">② <b><i>S</i></b>′=<i>reverse</i> (<b><i>S</i></b>) ; /*将<b><i>S</i></b>翻转*/</p>
                </div>
                <div class="p1">
                    <p id="152">③ <b><i>T</i></b><sub><i>a</i>=</sub><i>append</i> (<b><i>T</i></b>, <i>m</i>) ; /*对<b><i>T</i></b>扩充, 填<i>m</i>个0*/</p>
                </div>
                <div class="p1">
                    <p id="153">④ <b><i>S</i></b>′<sub><i>a</i></sub>=<i>append</i> (<b><i>S</i></b>′, 2<i>m</i>-<i>l</i>) ; /*与<b><i>T</i></b><sub><i>a</i></sub>等长*/</p>
                </div>
                <div class="p1">
                    <p id="154">⑤ <b><i>S</i></b>′<sub><i>af</i></sub>=FFT (<b><i>S</i></b>′<sub><i>a</i></sub>) ; /*快速傅里叶变换*/</p>
                </div>
                <div class="p1">
                    <p id="155">⑥ <b><i>T</i></b><sub><i>af</i></sub>=FFT (<b><i>T</i></b><sub><i>a</i></sub>) ;</p>
                </div>
                <div class="p1">
                    <p id="156">⑦ <b><i>ST</i></b><sub><i>t</i></sub>=MUL (<b><i>S</i></b>′<sub><i>af</i></sub>, <b><i>T</i></b><sub><i>af</i></sub>) ; /*逐元素相乘*/</p>
                </div>
                <div class="p1">
                    <p id="157">⑧ <b><i>ST</i></b>=<i>inverseFFT</i> (<b><i>ST</i></b><sub><i>t</i></sub>) ;</p>
                </div>
                <div class="p1">
                    <p id="158">⑨ <b><i>D</i></b>=<i>distance</i> (<i>l</i>, <b><i>ST</i></b>, <i>μ</i><sub><b><i>T</i></b></sub>, <i>μ</i><sub><b><i>S</i></b></sub>, <i>σ</i><sub><b><i>T</i></b></sub>, <i>σ</i><sub><b><i>S</i></b></sub>) . /*根据式 (3) 计算距离并组成距离向量*/</p>
                </div>
                <div class="p1">
                    <p id="159">算法行⑧得到的<b><i>ST</i></b>是子序列<b><i>S</i></b>与<b><i>T</i></b>中每一个子序列点积所构成的有序向量, 即<i>ST</i>[<i>i</i>]表示<b><i>S</i></b>与<b><i>T</i></b>中第<i>i</i>条子序列<b><i>A</i></b>[<i>i</i>]的点积.因此, 在使用式 (3) 计算距离向量 (行⑨) 时, 只需要从中取出相应的值, 而不用每次都计算内积.该算法的一个优势在于算法的时间复杂度与子序列长度无关, 这也就不存在最好情况与最坏情况的差异, 其主要时间消耗在于傅里叶变换 (<i>O</i> (<i>m</i> lb <i>m</i>) ) , 故算法的运行效率高.</p>
                </div>
                <h4 class="anchor-tag" id="160" name="160">3.2.2 提取相似性连接向量</h4>
                <div class="p1">
                    <p id="161">对于2条时序数据<b><i>T</i></b>, <b><i>R</i></b> (其全子序列集合分别为<i>A</i>, <i>B</i>) , 可以迭代使用算法2计算<i>A</i>中每一条子序列与<b><i>R</i></b>的距离向量.<b><i>T</i></b>和<b><i>R</i></b>的相似性连接向量<b><i>P</i></b><sub><i>A B</i></sub>就可以通过查找这些距离向量的最小值得到.在计算过程中, 本文采用在每次计算距离向量之后更新<b><i>P</i></b><sub><i>A B</i></sub>的方式, 逐步得到与<b><i>T</i></b>中每一条子序列最优匹配的<b><i>R</i></b>中的子序列, 记录其距离和位置, 具体算法如下:</p>
                </div>
                <div class="p1">
                    <p id="162"><b>算法3</b>. <b><i>P</i></b><sub><i>A B</i></sub>提取算法<i>similarityJoinVector</i>.</p>
                </div>
                <div class="p1">
                    <p id="163">输入:时序数据<b><i>T</i></b>, <b><i>R</i></b>及长度<i>m</i>、子序列长度<i>l</i>;</p>
                </div>
                <div class="p1">
                    <p id="164">输出:<b><i>P</i></b><sub><i>A B</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="165">① <i>B</i>=<i>allSubseqSet</i> (<b><i>R</i></b>) ;</p>
                </div>
                <div class="p1">
                    <p id="166">/*<b><i>R</i></b>的全子序列集合*/</p>
                </div>
                <div class="p1">
                    <p id="167">② initialize <b><i>P</i></b><sub><i>A B</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="168">③ <i>index</i>=1; /*<i>B</i>中子序列索引变量*/</p>
                </div>
                <div class="p1">
                    <p id="169">④ for each <b><i>S</i></b>∈<i>B</i></p>
                </div>
                <div class="p1">
                    <p id="170">⑤ <b><i>D</i></b>=<i>distanceVector</i> (<b><i>T</i></b>, <i>m</i>, <b><i>S</i></b>, <i>l</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="171">/*算法2*/</p>
                </div>
                <div class="p1">
                    <p id="172">⑥ <b><i>P</i></b><sub><i>A B</i></sub>=<i>updating</i> (<b><i>P</i></b><sub><i>A B</i></sub>, <b><i>D</i></b>, <i>index</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="173">/*逐元素更新距离值*/</p>
                </div>
                <div class="p1">
                    <p id="174">⑦ end for</p>
                </div>
                <div class="p1">
                    <p id="175">在算法3中, <b><i>P</i></b><sub><i>A B</i></sub>是以<b><i>T</i></b>为基准计算的, 每一次的迭代中, 算法都更新<b><i>T</i></b>相应位置上的距离值, 直至<i>B</i>中所有子序列计算完成.这种更新方式的好处是不必开辟内存空间去存储所有子序列对之间的距离, 减少了空间消耗.如果算法3的输入中<b><i>R</i></b>替换为<b><i>T</i></b>, 则算法得到的是<b><i>T</i></b>的自相似性连接向量<b><i>P</i></b><sub><i>A A</i></sub>, 但必须要处理平凡匹配导致的距离为0的问题.本文采用Yeh等人<citation id="469" type="reference"><link href="399" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>的处理方式, 直接跳过相关区域的计算, 且不更新<b><i>P</i></b><sub><i>A A</i></sub>中对应位置上的值.图3直观描述了算法3生成<b><i>P</i></b><sub><i>A A</i></sub>的过程.当<b><i>P</i></b><sub><i>A A</i></sub>初始化为Inf后, 按顺序计算每一条子序列与<b><i>T</i></b>的距离向量并更新<b><i>P</i></b><sub><i>A A</i></sub>, 为了方便展示, 本文只选取第<i>i</i>条和第<i>j</i>条子序列作为示例来更新 <b><i>P</i></b><sub><i>A A</i></sub>.在得到<b><i>A</i></b>[<i>i</i>]与<b><i>T</i></b>的距离向量 (以<b><i>D</i></b><sub><i>i</i></sub>表示) 之后, 按照逐元素取最小值的策略更新<b><i>P</i></b><sub><i>A A</i></sub>对应位置上的值 (图3中第1行和第2行) , 得到更新后的<b><i>P</i></b><sub><i>A A</i></sub>.当遇到平凡匹配的情况时, 即距离向量中值为0的情况, 则保留<b><i>P</i></b><sub><i>A A</i></sub>原来的值.对于<b><i>A</i></b>[<i>j</i>], 思路相同, 所不同的是生成的距离向量 (以<b><i>D</i></b><sub><i>j</i></sub>表示) 比较的对象是上次更新后的<b><i>P</i></b><sub><i>A A</i></sub> (图3中第3行和第4行) .</p>
                </div>
                <div class="area_img" id="176">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_176.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 PA A更新过程" src="Detail/GetImg?filename=images/JFYZ201903015_176.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 <b><i>P</i></b><sub><i>A A</i></sub>更新过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_176.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 The process of <b><i>P</i></b><sub><i>A A</i></sub> updating</p>

                </div>
                <h4 class="anchor-tag" id="177" name="177">3.2.3 候选矩阵生成</h4>
                <div class="p1">
                    <p id="178">由3.2.2节可知, <b><i>P</i></b><sub><i>A B</i></sub>是以子序列为单位描述两时序数据的, 其相似性可以通过<b><i>P</i></b><sub><i>A B</i></sub>与<b><i>P</i></b><sub><i>A A</i></sub>的差值来体现, 即差异向量<b><i>Dif</i></b><b><i>f</i></b><sub><i>A B</i></sub>.然而由于Shapelets是具有类别可分性的子序列, 体现的是类别差异, 因此, 需要考虑数据集中的全部时序数据, 将得到的差异向量进行综合分析, 为此, 本文将所得到的差异向量进行组合, 形成候选矩阵, 用于后续处理.</p>
                </div>
                <div class="p1">
                    <p id="179">一个关键的问题是并不是所有时序数据之间的差异向量对于提取Shapelets都是有用的.如果2条时序数据具有相同的类别标识, 其差异向量描述的是两者在数据生成过程中的差异, 并不是体现不同类别时序数据的本质区别.因此本文以类别为依据, 在计算差异向量时, 从不同类别中选取时序数据, 而同类别时序数据间不进行计算.若某一时序数据集中包含3个类别, 分别为Ⅰ, Ⅱ, Ⅲ类, 差异向量的计算过程为:从Ⅰ类中选出1条时序数据<b><i>T</i></b>, 以<b><i>T</i></b>为基准依次计算其与Ⅱ类和Ⅲ类中所有时序数据的差异向量.对<b><i>T</i></b>与每一类时序数据得到差异向量进行逐点求平均值, 得到平均差异向量, 将其合并到候选矩阵中, 之后对Ⅰ类中的其他数据进行相同的操作.然后再以Ⅱ类中时序数据为基准计算其与Ⅲ类中时序数据的平均差异向量.本质上, 平均差异向量从统计意义上表示了<b><i>T</i></b>与某一类别时序数据间的不同.候选矩阵生成的具体算法过程如下:</p>
                </div>
                <div class="p1">
                    <p id="180"><b>算法4</b>. 候选矩阵生成算法.</p>
                </div>
                <div class="p1">
                    <p id="181">输入:关键时序数据集<i>nDataSet</i>、子序列长度<i>l</i>;</p>
                </div>
                <div class="p1">
                    <p id="182">输出:候选矩阵<b><i>M</i></b>.</p>
                </div>
                <div class="p1">
                    <p id="183">① <i>tempDataSet</i>=<i>partitionByClasses</i> (<i>nDataSet</i>) ; /*按类别划分关键时序数据集*/</p>
                </div>
                <div class="p1">
                    <p id="184">② initialize <b><i>M</i></b>;/*初始化候选矩阵*/</p>
                </div>
                <div class="p1">
                    <p id="185">③ for each <i>currClass</i> in <i>tempDataSet</i></p>
                </div>
                <div class="p1">
                    <p id="186">④ for each <b><i>T</i></b>∈<i>currClass</i></p>
                </div>
                <div class="p1">
                    <p id="187">⑤ <b><i>P</i></b><sub><i>A A</i></sub>=<i>similarityJoinVector</i> (<b><i>T</i></b>, <b><i>T</i></b>, <i>l</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="188">⑥ initialize <b><i>Z</i></b>; /*初始化差异矩阵*/</p>
                </div>
                <div class="p1">
                    <p id="189">⑦ for each <i>otherclass</i> after <i>currClass</i></p>
                </div>
                <div class="p1">
                    <p id="190">⑧ for each <b><i>R</i></b>∈<i>otherclass</i></p>
                </div>
                <div class="p1">
                    <p id="191">⑨ <b><i>P</i></b><sub><i>A B</i></sub>=<i>similarityJoinVector</i> (<b><i>T</i></b>, <b><i>R</i></b>, <i>l</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="192">⑩ <b><i>Z</i></b>=[<b><i>Z</i></b>;abs (<b><i>P</i></b><sub><i>A B</i></sub>-<b><i>P</i></b><sub><i>A A</i></sub>) ];</p>
                </div>
                <div class="p1">
                    <p id="193"> (11) end for</p>
                </div>
                <div class="p1">
                    <p id="194"> (12) end for</p>
                </div>
                <div class="p1">
                    <p id="195"> (13) <b><i>M</i></b>=[<b><i>M</i></b>;<i>sum</i> (<b><i>Z</i></b>) /<b><i>Z</i></b>.<i>rows</i>];</p>
                </div>
                <div class="p1">
                    <p id="196"> (14) end for</p>
                </div>
                <div class="p1">
                    <p id="197"> (15) end for</p>
                </div>
                <div class="p1">
                    <p id="198">在候选矩阵生成过程中, 需要对数据集中所有的时序对计算<b><i>P</i></b><sub><i>A B</i></sub>和<b><i>P</i></b><sub><i>A A</i></sub>, 算法4本身的复杂度较高, 但由于本文在预处理阶段借助算法1大大减小了数据集规模, 仅使用关键时序数据用于计算, 因此, 在实验中不会消耗很多的运行时间.候选矩阵中的每一行代表着1条时序数据与另一类时序数据的平均差异, 使用平均值的目的在于剔除这一类时序数据之间的差异, 只使用共性的特征来提取Shapelets.</p>
                </div>
                <h4 class="anchor-tag" id="199" name="199"><b>3.3 基于候选矩阵的Shapelets提取</b></h4>
                <div class="p1">
                    <p id="200">从3.2节可知, 候选矩阵中的每一个值表示1条子序列与1类时序数据中最优匹配的差异, 其值的大小代表该子序列区分能力, 因此, Shapelets可以通过提取候选矩阵中较大的值对应的子序列得到.为了更形象地描述Shapelets提取过程, 本文首先以2条时序数据为例, 展示其相似性连接向量、自相似性连接向量及差异向量的计算过程, 提取出能够表示两者之间差异的子序列, 然后将其扩展到整个时序数据集上.在差异向量上选取可能成为Shapelets的子序列时, 阈值的选择对于Shapelets的数量有很大影响.阈值设置过大, 会导致仅有少数子序列构成Shapelets, 不能够全面体现时序间的差异;阈值过小, 则会使得大量可区分性不明显的子序列也被加入到Shapelets中, 这一方面会导致后续处理计算量的增加, 另一方面会对分类过程形成干扰.在实验中, 本文通过交叉验证的方式来确定合适的阈值.时序数据的Shapelets提取地过程如图4所示.</p>
                </div>
                <div class="p1">
                    <p id="201">2条示例时序数据<b><i>T</i></b>和<b><i>R</i></b>选自于UCR archives<sup>①</sup>的UWaveGestureLibraryAll时序数据集, 且属于不同的类别, 如图4 (a) 所示.假设<b><i>T</i></b>和<b><i>R</i></b>的全子序列集合分别为<i>A</i>和<i>B</i>, 则由算法2得到的<b><i>P</i></b><sub><i>A B</i></sub>与<b><i>P</i></b><sub><i>A A</i></sub>如图4 (b) 所示.从图4 (b) 中可以看出, <b><i>P</i></b><sub><i>A B</i></sub>与<b><i>P</i></b><sub><i>A A</i></sub>之间在某些位置上存在着明显的差异, 这些差异所对应的子序列就可以将<b><i>T</i></b>和<b><i>R</i></b>进行区分.图4 (c) 给出了两者的差异向量, 根据其值的大小可以很容易得到有区分能力的子序列所在的位置, 如图4 (c) 中的点<i>P</i>, 然后在原始时序数据<b><i>T</i></b>中即可将相应的子序列<b><i>A</i></b>[<i>P</i>]提取出来.在构成Shapelets时, 若子序列位置之间的距离小于子序列长度 (如图4 (c) 中以<i>P</i>和<i>Q</i>开始的子序列) , 本文将其合并形成Shapelets, 如图4 (d) 所示.</p>
                </div>
                <div class="p1">
                    <p id="202">如果由算法1所提取的关键时序数据集中只包含2类数据且每类中仅有1条时序数据, 按照图4的流程就是Shapelets提取的全过程, 差异向量<b><i>Dif</i></b><b><i>f</i></b><sub><i>A B</i></sub>即为候选矩阵.但在一般情况下, 数据集中会包含多类, 而每类中含有若干时序数据, 因此在提取Shapelets时, 需要逐行扫描候选矩阵, 在每一条时序上均提取子序列, 实现算法如下:</p>
                </div>
                <div class="area_img" id="203">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_203.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 时序数据T和R的Shapelets提取过程" src="Detail/GetImg?filename=images/JFYZ201903015_203.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 时序数据<b><i>T</i></b>和<b><i>R</i></b>的Shapelets提取过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_203.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 The process of Shapelets extraction between <b><i>T</i></b> and <b><i>R</i></b></p>

                </div>
                <div class="p1">
                    <p id="204"><b>算法5</b>. Shapelets提取算法.</p>
                </div>
                <div class="p1">
                    <p id="205">输入:候选矩阵<b><i>M</i></b>、子序列长度<i>l</i>、阈值<i>th</i>、时序数据集<i>DataSet</i>;</p>
                </div>
                <div class="p1">
                    <p id="206">输出:Shapelets集合<i>SL</i>.</p>
                </div>
                <div class="p1">
                    <p id="207">① initialize <i>SL</i>; /*初始化Shapelets集合*/</p>
                </div>
                <div class="p1">
                    <p id="208">② for each <i>row</i> in <b><i>M</i></b></p>
                </div>
                <div class="p1">
                    <p id="209">③ initialize <i>tempSL</i>;</p>
                </div>
                <div class="p1">
                    <p id="210">/*二元组 (位置, 子序列) */</p>
                </div>
                <div class="p1">
                    <p id="211">④ for <i>i</i>=1:<i>length</i> (<i>row</i>) </p>
                </div>
                <div class="p1">
                    <p id="212">⑤ if <i>row</i>[<i>i</i>]&gt;<i>th</i></p>
                </div>
                <div class="p1">
                    <p id="213">⑥ <i>subSequence</i>=<i>DataSet</i> (<i>row</i>, <i>i</i>:<i>i</i>+<i>l</i>-1) ; /*提取子序列*/</p>
                </div>
                <div class="p1">
                    <p id="214">⑦ <i>tempSL</i>=[<i>tempSL</i>;[<i>i</i>, <i>subSequence</i>]];</p>
                </div>
                <div class="p1">
                    <p id="215">⑧ end if</p>
                </div>
                <div class="p1">
                    <p id="216">⑨ end for</p>
                </div>
                <div class="p1">
                    <p id="217">⑩ <i>tSL</i>=<i>mergeSubsequence</i> (<i>tempSL</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="218">/*将有重合部分的子序列合并*/</p>
                </div>
                <div class="p1">
                    <p id="219"> (11) <i>SL</i>=[<i>SL</i>; <i>tSL</i>];</p>
                </div>
                <div class="p1">
                    <p id="220"> (12) end for</p>
                </div>
                <div class="p1">
                    <p id="221">算法5与图4所描述过程本质上是一样的, 唯一的区别在于候选矩阵值的计算方式有所不同.假设时序数据集中包含3类:Ⅰ, Ⅱ, Ⅲ类, 则多类情况下的Shapelets提取基本过程如图5所示.图5中第Ⅰ类所提取的Shapelets, 可以将Ⅰ类时序数据从数据集中区分开来, 但并不能将Ⅱ类和Ⅲ类的时序数据进行区分, 因此还需要以Ⅱ类时序数据为基准从Ⅱ类中提取Shapelets, 此时, Ⅰ类中的时序数据不再参与计算以减少时间消耗.</p>
                </div>
                <div class="area_img" id="222">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_222.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 Shapelets 提取过程" src="Detail/GetImg?filename=images/JFYZ201903015_222.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 Shapelets 提取过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_222.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 The process of shapelets extraction</p>

                </div>
                <div class="area_img" id="223">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_223.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图 6 时序数据的空间变换示意图" src="Detail/GetImg?filename=images/JFYZ201903015_223.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图 6 时序数据的空间变换示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_223.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 The space transformation of time series</p>

                </div>
                <h4 class="anchor-tag" id="224" name="224"><b>3.4 算法分析</b></h4>
                <div class="p1">
                    <p id="225">从算法2～5描述过程可以看出, 本文所提出的Shapelets提取算法以不同类别时序的差异为基本出发点, 从时序数据中提取能够区分不同类别的子序列是一种最直观的方式.与现有Shapelets提取算法不同的是本文直接从子序列的角度描述时序数据间的相似性, 其优势在于易于发现时序间差异所对应的子序列.研究的核心在于如何以子序列为基准快速地计算不同类别时序间的差异.本文通过2个方面来加速计算:1) 通过选取关键时序数据来减少后续参与计算的时序数量, 通过实验验证 (5.2节) 该步骤是合理和有效的;2) 借助傅里叶变换快速完成时序间的相似性连接向量和自相似性连接向量.本质上, 本文是通过两两比较来构成Shapelets集合的, 这样得到的每一条子序列至少能区分来自不同类别的2条时序, 由其构成的集合也能够很好的将不同类别的时序区分开来, 因此, 算法是合理可行的.</p>
                </div>
                <h3 id="226" name="226" class="anchor-tag"><b>4 时间序列空间变换</b></h3>
                <div class="p1">
                    <p id="227">在以Shapelets为特征的时序数据分类算法中, 决策树是使用最为广泛的分类器, 其优点是容易构造, 对分类结果有直观的解释, 但缺点也很明显.决策树以Shapelets为节点, 将数据集不断地进行划分, 直至每个子数据集不能再分或者达到某些终止条件.这会导致2方面的问题:如果只使用少数Shapelets构建浅层二叉树, 其分类准确率受到限制, 并且很多Shapelets具有非常相近的分类能力, 不恰当的选择也会导致分类准确率降低;而如果使用的Shapelets太多, 树的结构复杂, 又会导致运行时间加大.Bagnall等人<citation id="470" type="reference"><link href="421" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>指出将时序数据映射到特征易于被检测的空间是解决时序数据分类问题的一个好方法, 本文借鉴Lines等人<citation id="471" type="reference"><link href="397" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>的策略, 将时序数据映射到Shapelets所构成的空间, 形成原始时序数据的特征表示.</p>
                </div>
                <div class="p1">
                    <p id="228">图6描述了基于距离运算的空间转换的方法:假设提取的Shapelets数目为<i>k</i>, 对于每一条时序数据<b><i>T</i></b><sub><i>i</i></sub>, 依次计算其与<i>k</i>条Shapelets (<b><i>SL</i></b><sub>1</sub>, <b><i>SL</i></b><sub>2</sub>, …, <b><i>SL</i></b><sub><i>k</i></sub>) 之间的距离 (式 (2) ) , 将这些距离组合起来形成1个距离向量, 该距离向量即为原时序数据在Shapelets空间中的表示.这种表示一方面保持了Shapelets在时序数据分类问题中的优势, 因为向量中每一个值都是以Shapelets为单位得到的;另一方面, 向量中的每个值都蕴含着时序数据中数据的先后次序关系, 因此, 向量中各元素之间具有相互独立性, 可以使用现有成熟的分类器 (本文使用SVM) 进行分类.</p>
                </div>
                <h3 id="230" name="230" class="anchor-tag"><b>5 实验与分析</b></h3>
                <div class="p1">
                    <p id="231">本文通过对时序数据进行分类来验证所提出的Shapelets提取方法的有效性.本节将首先介绍相关的实验设置, 包括实验所使用的时序数据集、评价指标以及用于比较的Shapelets提取算法, 之后给出实验结果并进行分析和讨论.</p>
                </div>
                <h4 class="anchor-tag" id="232" name="232"><b>5.1 实验设置</b></h4>
                <h4 class="anchor-tag" id="233" name="233">5.1.1 数据集</h4>
                <div class="p1">
                    <p id="234">本文使用UCR archives和UEA时序数据集<sup>①</sup>中的26个数据集来评估方法的性能, 这些数据集是目前Shapelets相关研究中普遍使用的数据集<citation id="472" type="reference"><link href="393" rel="bibliography" /><link href="411" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">25</a>]</sup></citation>.数据来自于多个领域, 包括传感器数据、图像轮廓信息、人体心电图以及动作数据等, 数据集的基本信息如表1所示:</p>
                </div>
                <div class="area_img" id="235">
                    <p class="img_tit"><b>表1 实验中所使用的数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Datasets Used in the Experiments</b></p>
                    <p class="img_note"></p>
                    <table id="235" border="1"><tr><td><br />Datasets</td><td>#Train</td><td>#Test</td><td>Length</td><td>#Classes</td></tr><tr><td><br />Adiac</td><td>390</td><td>391</td><td>176</td><td>37</td></tr><tr><td><br />Beef</td><td>30</td><td>30</td><td>470</td><td>5</td></tr><tr><td><br />Chlorine.</td><td>467</td><td>3 840</td><td>166</td><td>3</td></tr><tr><td><br />Coffee</td><td>28</td><td>28</td><td>286</td><td>2</td></tr><tr><td><br />Diatom.</td><td>16</td><td>306</td><td>345</td><td>4</td></tr><tr><td><br />DP_Little</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />DP_Middle</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />DP_Thumb</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />ECGFiveDays</td><td>23</td><td>861</td><td>136</td><td>2</td></tr><tr><td><br />FaceFour</td><td>24</td><td>88</td><td>350</td><td>4</td></tr><tr><td><br />Gun_Point</td><td>50</td><td>150</td><td>150</td><td>2</td></tr><tr><td><br />ItalyPower.</td><td>67</td><td>1 029</td><td>24</td><td>2</td></tr><tr><td><br />Lighting7</td><td>70</td><td>73</td><td>319</td><td>7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="236"><b>Continued (Table 1</b>) </p>
                </div>
                <div class="area_img" id="237">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="237" border="1"><tr><td><br />Datasets</td><td>#Train</td><td>#Test</td><td>Length</td><td>#Classes</td></tr><tr><td><br />MedicalImages</td><td>381</td><td>760</td><td>99</td><td>10</td></tr><tr><td><br />MoteStrain</td><td>20</td><td>1 252</td><td>84</td><td>2</td></tr><tr><td><br />MP_little</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />MP_Middle</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />Otoliths</td><td>64</td><td>64</td><td>512</td><td>2</td></tr><tr><td><br />PP_little</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />PP_Middle</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />PP_Thumb</td><td>400</td><td>645</td><td>250</td><td>3</td></tr><tr><td><br />Sony</td><td>20</td><td>601</td><td>70</td><td>2</td></tr><tr><td><br />Symbols</td><td>25</td><td>995</td><td>398</td><td>6</td></tr><tr><td><br />SyntheticC</td><td>300</td><td>300</td><td>60</td><td>6</td></tr><tr><td><br />Trace</td><td>100</td><td>100</td><td>275</td><td>4</td></tr><tr><td><br />TwoLeadECG</td><td>23</td><td>1 139</td><td>82</td><td>2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="238">从表1可以看出, 所使用的数据集类型多样:从二分类到多分类, 且多分类问题较多, 最多可达37类 (Adiac) ;长度不一, 最短为24 (ItalyPower.) , 最长为512 (Otoliths) ;训练集和测试集的数据差异也比较大, 因此, 可以全面的度量算法的性能.为了便于性能比较, 本文采用默认的训练集和测试集划分, 实验中相关的参数均通过交叉验证的方式获得.</p>
                </div>
                <h4 class="anchor-tag" id="239" name="239">5.1.2 方法对比</h4>
                <div class="p1">
                    <p id="240">本文算法 (similarity join for Shapelets extraction, SJS) 与目前主要的7个Shapelets提取算法进行性能比较:</p>
                </div>
                <div class="p1">
                    <p id="241">1) 标准基于Shapelets时序数据分类算法使用不同的度量指标:信息增益 (IG) <citation id="473" type="reference"><link href="387" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、Kruskal-Wallis检验 (KW) <citation id="474" type="reference"><link href="395" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、F-统计量 (FS) <citation id="475" type="reference"><link href="395" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="242">2) FSH (fast-Shapelets) <citation id="476" type="reference"><link href="393" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>算法.将时序数据转换为离散的低维表示, 在低维空间中过滤掉大部分子序列以加速搜索的算法.</p>
                </div>
                <div class="p1">
                    <p id="243">3) LTS<citation id="477" type="reference"><link href="409" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>算法.使用梯度下降法从数据中学习出最优Shapelets和分类决策函数的算法.</p>
                </div>
                <div class="p1">
                    <p id="244">4) IGSVM<citation id="478" type="reference"><link href="397" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>算法.首次对时序数据进行空间变换的算法, 以信息增益作为Shapelets区分能力度量, 使用线性SVM作为分类器完成分类工作.</p>
                </div>
                <div class="p1">
                    <p id="245">5) FLAG<citation id="479" type="reference"><link href="411" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>算法.采用学习优化的策略, 使用广义特征向量的方法对时序数据进行降维, 进而提取相应子序列作为Shapelets的算法.</p>
                </div>
                <div class="p1">
                    <p id="246">上述对比算法的实现均由提出该方法的原作者提供, 其参数为作者推荐的设置.</p>
                </div>
                <h4 class="anchor-tag" id="247" name="247">5.1.3 评价指标</h4>
                <div class="area_img" id="248">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_248.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 SJS算法和N-SJS算法的运行时间对比" src="Detail/GetImg?filename=images/JFYZ201903015_248.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 SJS算法和N-SJS算法的运行时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_248.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Running time comparison of SJS and N-SJS algorithm</p>

                </div>
                <div class="p1">
                    <p id="249">对于分类问题, 分类准确率是评价算法性能最重要的标准, 但对于多种算法在多个数据集上的结果比较, 分类准确率难以直观地度量各个算法的性能, 因为在很多情况下, 某一算法在一数据集上效果很好, 但在另一数据集上, 分类结果可能较差.因此, 本文采用在机器学习领域广泛使用的无参数Friedman测试作为评价算法性能的标准.本质上, Friedman测试是基于分类准确率计算的.在获得<i>K</i>个算法在<i>N</i>个数据集上的分类结果后, 对每一个数据集上的<i>K</i>个算法进行排序, 分类准确率最高的算法标记为“1”, 次高标记为“2”, 以此类推, 分类效果最差的算法标记为“<i>K</i>”, 这样就可以得到<i>N</i>×<i>K</i>的排序矩阵<b><i>H</i></b>, 其中, <i>h</i><sub><i>i j</i></sub>表示第<i>i</i>个数据集上第<i>j</i>个算法的标记值.然后, 计算每个算法的平均标记值</p>
                </div>
                <div class="p1">
                    <p id="250"><mathml id="251"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>h</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>h</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mtext> </mtext><mi>j</mi></mrow></msub><mo>/</mo><mi>Ν</mi></mrow></math></mathml>.      (6) </p>
                </div>
                <div class="p1">
                    <p id="252">在零假设 (null hypothesis) 的情况下, 所有算法是等价的, 因而<mathml id="253"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>h</mi><mo>¯</mo></mover></math></mathml><sub><i>j</i></sub>应当相等, 所以当<i>N</i>和<i>K</i>足够大时 (一般<i>N</i>&gt;10, <i>K</i>&gt;5) , Friedman统计量:</p>
                </div>
                <div class="p1">
                    <p id="254"><i>χ</i><mathml id="255"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>F</mtext><mtext>r</mtext><mtext>i</mtext><mtext>e</mtext><mtext>d</mtext><mtext>m</mtext><mtext>a</mtext><mtext>n</mtext></mrow><mn>2</mn></msubsup><mo>=</mo><mfrac><mrow><mn>1</mn><mn>2</mn><mi>Ν</mi></mrow><mrow><mi>Κ</mi><mo stretchy="false"> (</mo><mi>Κ</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml><mathml id="256"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mover accent="true"><mi>h</mi><mo>¯</mo></mover></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mfrac><mrow><mi>Κ</mi><mo stretchy="false"> (</mo><mi>Κ</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mn>4</mn></mfrac></mrow><mo>]</mo></mrow></mrow></math></mathml>,      (7) </p>
                </div>
                <div class="p1">
                    <p id="257">可以用具有<i>K</i>-1个自由度的卡方分布近似.Demšar<citation id="480" type="reference"><link href="423" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>通过分析前人的工作得出卡方分布是相当保守的近似, 提出使用</p>
                </div>
                <div class="p1">
                    <p id="258"><mathml id="259"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mi>χ</mi><msubsup><mrow></mrow><mrow><mtext>F</mtext><mtext>r</mtext><mtext>i</mtext><mtext>e</mtext><mtext>d</mtext><mtext>m</mtext><mtext>a</mtext><mtext>n</mtext></mrow><mn>2</mn></msubsup></mrow><mrow><mi>Ν</mi><mo stretchy="false"> (</mo><mi>Κ</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>χ</mi><msubsup><mrow></mrow><mrow><mtext>F</mtext><mtext>r</mtext><mtext>i</mtext><mtext>e</mtext><mtext>d</mtext><mtext>m</mtext><mtext>a</mtext><mtext>n</mtext></mrow><mn>2</mn></msubsup></mrow></mfrac></mrow></math></mathml>,      (8) </p>
                </div>
                <div class="p1">
                    <p id="260">作为度量.当实验结果拒绝零假设时, Demša提出将所有算法按照<i>F</i>值分到不同的组, 使得同一组内的算法在分类准确率上没有显著差异.这样, 不同算法的性能差异可以通过包含平均次序和无明显差异算法组的关键差异图 (critical difference diagram) 表示.</p>
                </div>
                <h4 class="anchor-tag" id="261" name="261"><b>5.2 提取关键时序数据对实验结果的影响</b></h4>
                <div class="p1">
                    <p id="262">本节首先验证仅仅使用关键时序数据所提取的Shapelets对于分类结果的影响.图7显示了在表1数据集上使用算法1和不使用算法1的情况下, 所提取的Shapelets用于分类的结果对比, 其中, N-SJS表示使用全部时序数据时的算法, SJS算法表示仅使用关键时序数据的算法.横、纵轴均以分类准确率为单位.</p>
                </div>
                <div class="area_img" id="263">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_263.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SJS算法和N-SJS算法在表1数据集上的分类 准确率比较" src="Detail/GetImg?filename=images/JFYZ201903015_263.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SJS算法和N-SJS算法在表1数据集上的分类 准确率比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_263.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Classification accuracy comparison of SJS and  N-SJS algorithm for datasets in Table 1</p>

                </div>
                <div class="p1">
                    <p id="264">从表1数据集上的分类结果 (图7) 可以看出, 在绝大多数数据集上, SJS和N-SJS几乎没有区别, 即分类结果位于中间对角线附近, 说明通过算法1精简数据集后, 并没有减弱本文方法提取高质量Shapelets的能力.同时, 在部分数据集上, 准确率略有提升, 意味着冗余的Shapelets也可能导致分类器性能的下降.</p>
                </div>
                <div class="p1">
                    <p id="265">另一方面, 算法1的主要目的是减少参与计算的时序数据的数量, 加速Shapelets的提取, 图8是两者的运行时间对比图 (纵轴为对数坐标) .在绝大多数的数据集上, 使用算法1之后, 加速效果明显, 如在Adiac数据集上的运行时间比为23.6 s∶626.1 s, Chlorine.数据集上为7.7 s∶957.3 s.仅有4个数据集没有加速效果, 这是因为这些数据集的训练集本身非常小, 且数据之间差异比较大, 算法1将所有时序都作为关键数据.但这并没有影响本文算法的效率, 因为算法在这些数据集上使用全部时序数据的时间消耗非常小 (Coffee:3.5 s, ItalyPower:0.7 s, Sony:0.1 s, TwoLeadECG:0.4 s) .</p>
                </div>
                <h4 class="anchor-tag" id="266" name="266"><b>5.3 实验结果对比</b></h4>
                <div class="p1">
                    <p id="267">本节从分类准确率和运行时间2方面来验证本文算法SJS的性能.</p>
                </div>
                <h4 class="anchor-tag" id="268" name="268">5.3.1 分类准确率</h4>
                <div class="p1">
                    <p id="269">表2列出了本文算法与所有对比算法在各个数据集上的分类准确率.其中, 每个数据集上的最优算法以加粗的形式表示, 需要说明的是IG, KW, FS这3个方法在部分数据集上运行时间过长, 无法在合理的运行时间内结束 (超过24 h) , 标记为“*”.表2的最后一行表示各个算法在不同数据集上具有最好分类效果的次数.从该统计结果上来看, LTS具有一定的优势, 在13个数据集上取得最好的分类准确率, 本文算法SJS仅次于LTS, 在9个数据集上处于领先, 而标准的使用IG和KW作为度量标准的Shapelets算法效果最差.</p>
                </div>
                <div class="p1">
                    <p id="270">然而, 仅从算法在各个数据集上获胜的次数来评价算法性能是不全面的, 为此, 本文使用5.1.3节的方法来评价各个算法, 其结果如图9所示.从该关键差异图可以看出, 本文算法与最优的LTS算法差别很小 (2.54∶2.35) , 但与其他算法有比较明显的差别, 如其他算法中最好的FLAG算法其平均次序已到3.15.尽管IGSVM算法也在7个数据集上取得最好的准确率, 但在平均次序上, 与本文算法差距明显 (2.54∶3.58) .</p>
                </div>
                <div class="area_img" id="271">
                    <p class="img_tit"><b>表2 不同方法在各个数据集上的测试准确率</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Testing Accuracy of Different Methods on the Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="271" border="1"><tr><td><br />Datasets</td><td>IG</td><td>KW</td><td>FS</td><td>FSH</td><td>IGSVM</td><td>LTS</td><td>FLAG</td><td>SJS</td></tr><tr><td><br />Adiac</td><td>29.9</td><td>26.6</td><td>15.6</td><td>57.5</td><td>23.5</td><td>51.9</td><td><b>75.2</b></td><td>72.8</td></tr><tr><td><br />Beef</td><td>50</td><td>33.3</td><td>56.7</td><td>50</td><td>90</td><td>76.7</td><td>83.3</td><td><b>93.3</b></td></tr><tr><td><br />Chlorine.</td><td>58.8</td><td>52</td><td>53.5</td><td>58.8</td><td>57.1</td><td>73</td><td>76</td><td><b>87.3</b></td></tr><tr><td><br />Coffee</td><td>96.4</td><td>85.7</td><td><b>100</b></td><td>92.9</td><td><b>100</b></td><td><b>100</b></td><td><b>100</b></td><td><b>100</b></td></tr><tr><td><br />Diatom.</td><td>76.5</td><td>62.1</td><td>76.5</td><td>87.3</td><td>93.1</td><td>94.2</td><td>96.4</td><td>97.7</td></tr><tr><td><br />DP_Little</td><td>*</td><td>*</td><td>*</td><td>60.6</td><td>66.6</td><td><b>73.4</b></td><td>68.3</td><td>68.1</td></tr><tr><td><br />DP_Middle</td><td>*</td><td>*</td><td>*</td><td>58.8</td><td>69.5</td><td><b>74.1</b></td><td>71.3</td><td>71.5</td></tr><tr><td><br />DP_Thumb</td><td>*</td><td>*</td><td>*</td><td>63.4</td><td>69.6</td><td><b>75.2</b></td><td>70.5</td><td>71.5</td></tr><tr><td><br />ECGFiveDays</td><td>77.5</td><td>87.2</td><td>99</td><td>99.8</td><td>99</td><td><b>100</b></td><td>92</td><td>98.5</td></tr><tr><td><br />FaceFour</td><td>84</td><td>44.3</td><td>75</td><td>92</td><td><b>97.7</b></td><td>94.3</td><td>90.9</td><td><b>97.7</b></td></tr><tr><td><br />Gun_Point</td><td>89.3</td><td>94</td><td>95.3</td><td>94</td><td><b>100</b></td><td>99.6</td><td>96.7</td><td>98</td></tr><tr><td><br />ItalyPower</td><td>89.2</td><td>91</td><td>93.1</td><td>91</td><td>93.7</td><td><b>95.8</b></td><td>94.6</td><td><b>95.8</b></td></tr><tr><td><br />Lighting7</td><td>49.3</td><td>48</td><td>41.1</td><td>65.2</td><td>63</td><td><b>79</b></td><td>76.7</td><td>75.3</td></tr><tr><td><br />MedicalImages</td><td>48.8</td><td>47.1</td><td>50.8</td><td>64.7</td><td>52.2</td><td>71.3</td><td>71.4</td><td><b>74.8</b></td></tr><tr><td><br />MoteStrain</td><td>82.5</td><td>84</td><td>84</td><td>83.8</td><td>88.7</td><td><b>90</b></td><td>88.8</td><td>89.8</td></tr><tr><td><br />MP_little</td><td>*</td><td>*</td><td>*</td><td>56.9</td><td>70.7</td><td><b>74.3</b></td><td>69.3</td><td>71.8</td></tr><tr><td><br />MP_Middle</td><td>*</td><td>*</td><td>*</td><td>60.3</td><td>76.9</td><td><b>77.5</b></td><td>75</td><td>75.5</td></tr><tr><td><br />Otoliths</td><td>67.1</td><td>60.8</td><td>57.9</td><td>60.8</td><td>64.1</td><td>59.4</td><td>64.1</td><td><b>67.1</b></td></tr><tr><td><br />PP_little</td><td>*</td><td>*</td><td>*</td><td>57.6</td><td><b>72.1</b></td><td>71</td><td>67.1</td><td>69.1</td></tr><tr><td><br />PP_Middle</td><td>*</td><td>*</td><td>*</td><td>61.6</td><td><b>75.8</b></td><td>74.9</td><td>73.8</td><td>74.7</td></tr><tr><td><br />PP_Thumb</td><td>*</td><td>*</td><td>*</td><td>55.7</td><td><b>75.5</b></td><td>70.5</td><td>67.4</td><td>70.7</td></tr><tr><td><br />Sony</td><td>85.7</td><td>72.7</td><td><b>95.3</b></td><td>68.6</td><td>92.7</td><td>91</td><td>92.9</td><td>91.2</td></tr><tr><td><br />Symbols</td><td>78.4</td><td>55.7</td><td>80.1</td><td>92.4</td><td>84.6</td><td><b>94.5</b></td><td>87.5</td><td>92.6</td></tr><tr><td><br />SyntheticC</td><td>94.3</td><td>90</td><td>95.7</td><td>94.7</td><td>87.3</td><td>97.3</td><td><b>99.7</b></td><td><b>99.7</b></td></tr><tr><td><br />Trace</td><td>98</td><td>94</td><td><b>100</b></td><td><b>100</b></td><td>98</td><td><b>100</b></td><td>99</td><td>98</td></tr><tr><td><br />TwoLeadECG</td><td>85.1</td><td>76.4</td><td>97</td><td>92.5</td><td><b>100</b></td><td><b>100</b></td><td>99</td><td>87.6</td></tr><tr><td><br />#Win</td><td><b>0</b></td><td><b>0</b></td><td><b>3</b></td><td><b>1</b></td><td><b>7</b></td><td><b>13</b></td><td><b>3</b></td><td><b>9</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The results highlighted in bold denote that the method gets the highest accuracy for this dataset and the “*” represents the corresponding method cannot finish in 24 hours.</p>
                </div>
                <div class="area_img" id="273">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_273.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 SJS和对比算法的关键差异图" src="Detail/GetImg?filename=images/JFYZ201903015_273.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 SJS和对比算法的关键差异图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_273.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Critical difference diagram for SJS and  other baselines</p>

                </div>
                <div class="p1">
                    <p id="274">综合上述2方面的分析, 可以看出本文所提出的SJS算法具有很好的分类准确率, 要优于目前绝大多数Shapelets提取算法.除此之外, SJS的最大优势在于算法的稳定性, 在几乎全部的数据集上, SJS都保持很高准确率, 而LTS算法则有些波动, 如在Adiac和Otoliths数据集上, LTS准确率不足60%.更显著的是, 当类别数增多时, SJS优势明显, 如在37类的Adiac数据集和10类的MedicalImages数据集上, SJS都要优于LTS.</p>
                </div>
                <h4 class="anchor-tag" id="275" name="275">5.3.2 运行时间比较</h4>
                <div class="p1">
                    <p id="276">对于算法的评价, 除了准确率之外, 算法的运行时间也是一个重要的评价指标.对于实际应用, 如金融、医疗等数据的处理, 算法在可接受的时间内得到结果显得尤为重要.本文算法的核心在于时序数据间的相似性连接, 子序列与1条时序数据的距离计算借助快速傅里叶变换完成 (算法2) , 其算法复杂度为<i>O</i> (<i>m</i> lb <i>m</i>) (<i>m</i>为时序数据长度) , 因此, 计算2条时序数据相似性连接的时间复杂度为<i>O</i> ( (<i>m</i>-<i>l</i>+1) <i>m</i> lb <i>m</i>) , 即近似于<i>O</i> (<i>m</i><sup>2</sup> lb <i>m</i>) .对于时序数据集, 如果要处理所有时序数据对的相似性, 算法复杂度会很高, 但本文通过算法1提取每类中的关键数据, 且相似性连接计算只在不同类的时序数据间进行, 使得参与计算的时序条数大大减少, 降低了运行时间消耗.</p>
                </div>
                <div class="p1">
                    <p id="277">本文算法与其他对比算法的运行时间如表3所示 (所有结果均在使用Intel i7 CPU和16 GB内存的计算机上得到) , 括号中的数字表示算法运行时间在每一个数据集上的排序次序.同表2一样, 算法如果无法在合理的时间内完成, 标记为“*”, 且次序用“ (8) ”表示.为了方便对比, 本文按照式 (6) 计算每一算法的平均次序, 表3中的最后一行Average Rank给出了相应的结果.该统计结果表明:FLAG算法具有最好的时间效率 (平均次序为1.2) , SJS次之 (平均次序为2) , 标准使用IG作为度量的Shapelets提取算法的时间消耗最多.</p>
                </div>
                <div class="area_img" id="278">
                    <p class="img_tit"><b>表3 不同方法在各个数据集上的运行时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Running Time of Different Methods on the Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="278" border="1"><tr><td rowspan="2"><br />Datasets</td><td colspan="8"><br />Running Time/s (Rank) </td></tr><tr><td><br />IG</td><td>KW</td><td>FS</td><td>FSH</td><td>IGSVM</td><td>LTS</td><td>FLAG</td><td>SJS</td></tr><tr><td>Adiac</td><td>3 287 (7) </td><td>1 349 (5) </td><td>1 513 (6) </td><td>288 (3) </td><td>706 (4) </td><td>80 596 (8) </td><td>2.78 (1) </td><td>23.6 (2) </td></tr><tr><td><br />Beef</td><td>471 (6) </td><td>484 (7) </td><td>576 (8) </td><td>154 (3) </td><td>435 (5) </td><td>414 (4) </td><td>1.15 (1) </td><td>10.5 (2) </td></tr><tr><td><br />Chlorine.</td><td>9 751 (8) </td><td>3 213 (7) </td><td>3 050 (6) </td><td>617 (4) </td><td>1 181 (5) </td><td>556 (3) </td><td>6.88 (1) </td><td>7.7 (2) </td></tr><tr><td><br />Coffee</td><td>22.3 (7) </td><td>21.8 (5) </td><td>21.9 (6) </td><td>16.5 (4) </td><td>15.9 (3) </td><td>76 (8) </td><td>0.13 (1) </td><td>3.5 (2) </td></tr><tr><td><br />Diatom.</td><td>9.3 (5) </td><td>8.99 (3) </td><td>9.2 (4) </td><td>13.7 (7) </td><td>9.3 (5) </td><td>88 (8) </td><td>0.41 (1) </td><td>2.2 (2) </td></tr><tr><td><br />DP_Little</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>401 (3) </td><td>9516 (5) </td><td>1 608 (4) </td><td>1.81 (1) </td><td>4.5 (2) </td></tr><tr><td><br />DP_Middle</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>456 (3) </td><td>7 041 (4) </td><td>12 528 (5) </td><td>1.78 (1) </td><td>2.2 (2) </td></tr><tr><td><br />DP_Thumb</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>392 (3) </td><td>11 353 (5) </td><td>2 073 (4) </td><td>3.14 (1) </td><td>3.7 (2) </td></tr><tr><td><br />ECGFiveDays</td><td>19 (8) </td><td>18.4 (6) </td><td>18.6 (7) </td><td>4.6 (3) </td><td>11.7 (5) </td><td>9.1 (4) </td><td>0.08 (1) </td><td>0.8 (2) </td></tr><tr><td><br />FaceFour</td><td>1 021 (8) </td><td>1 012 (7) </td><td>1 010 (6) </td><td>75 (3) </td><td>410 (5) </td><td>116 (4) </td><td>0.26 (1) </td><td>4.9 (2) </td></tr><tr><td><br />Gun_Point</td><td>116.4 (7) </td><td>112 (6) </td><td>148.9 (8) </td><td>7.6 (3) </td><td>74.8 (5) </td><td>14.1 (4) </td><td>0.07 (1) </td><td>3.6 (2) </td></tr><tr><td><br />ItalyPower</td><td>0.38 (5) </td><td>0.22 (2) </td><td>0.22 (2) </td><td>0.5 (6) </td><td>0.22 (2) </td><td>7.3 (8) </td><td>0.03 (1) </td><td>0.7 (7) </td></tr><tr><td><br />Lighting7</td><td>3 442 (7) </td><td>3 438 (6) </td><td>3 584 (8) </td><td>307 (3) </td><td>1473 (5) </td><td>965 (4) </td><td>0.31 (1) </td><td>32.8 (2) </td></tr><tr><td><br />MedicalImages</td><td>4 347 (8) </td><td>2 625 (7) </td><td>2 616 (6) </td><td>164 (3) </td><td>1 547 (4) </td><td>2 199 (5) </td><td>1.69 (2) </td><td>1.1 (1) </td></tr><tr><td><br />MoteStrain</td><td>1.41 (7) </td><td>1.29 (4) </td><td>1.29 (4) </td><td>1.4 (6) </td><td>0.84 (3) </td><td>6 (8) </td><td>0.04 (1) </td><td>0.1 (2) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="279"><b>Continued (Table 3</b>) </p>
                </div>
                <div class="area_img" id="280">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="280" border="1"><tr><td rowspan="2"><br />Datasets</td><td colspan="8"><br />Running Time/s (Rank) </td></tr><tr><td><br />IG</td><td>KW</td><td>FS</td><td>FSH</td><td>IGSVM</td><td>LTS</td><td>FLAG</td><td>SJS</td></tr><tr><td>MP_little</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>460 (3) </td><td>7 394 (4) </td><td>10 779 (5) </td><td>2.95 (2) </td><td>0.5 (1) </td></tr><tr><td><br />MP_Middle</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>421 (3) </td><td>12 102 (5) </td><td>1 448 (4) </td><td>2.23 (2) </td><td>0.6 (1) </td></tr><tr><td><br />Otoliths</td><td>17 864 (7) </td><td>18 166 (8) </td><td>17 789 (6) </td><td>183 (3) </td><td>8 536 (5) </td><td>264 (4) </td><td>1.25 (1) </td><td>2.6 (2) </td></tr><tr><td><br />PP_little</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>393 (3) </td><td>8 142 (4) </td><td>9 899 (5) </td><td>3.91 (2) </td><td>2 (1) </td></tr><tr><td><br />PP_Middle</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>403 (3) </td><td>4 753 (4) </td><td>6 819 (5) </td><td>2.19 (2) </td><td>1.3 (1) </td></tr><tr><td><br />PP_Thumb</td><td>* (8) </td><td>* (8) </td><td>* (8) </td><td>416 (3) </td><td>8 209 (4) </td><td>13 675 (5) </td><td>4.2 (1) </td><td>7.2 (2) </td></tr><tr><td><br />Sony</td><td>1.17 (7) </td><td>1.02 (4) </td><td>1.02 (4) </td><td>1.1 (6) </td><td>0.75 (3) </td><td>25.4 (8) </td><td>0.04 (1) </td><td>0.1 (2) </td></tr><tr><td><br />Symbols</td><td>3 325 (7) </td><td>3 318 (6) </td><td>3 622 (8) </td><td>59.4 (3) </td><td>1 263 (5) </td><td>528 (4) </td><td>0.85 (1) </td><td>2.3 (2) </td></tr><tr><td><br />SyntheticC</td><td>291 (6) </td><td>164 (5) </td><td>161 (4) </td><td>39.4 (3) </td><td>922 (8) </td><td>293 (7) </td><td>0.26 (1) </td><td>0.7 (2) </td></tr><tr><td><br />Trace</td><td>11 542 (7) </td><td>11 622 (8) </td><td>11 411 (6) </td><td>98.7 (3) </td><td>4 838 (5) </td><td>394 (4) </td><td>0.35 (1) </td><td>2.5 (2) </td></tr><tr><td><br />TwoLeadECG</td><td>0.48 (6) </td><td>0.42 (4) </td><td>0.42 (4) </td><td>1.1 (7) </td><td>0.26 (2) </td><td>5.2 (8) </td><td>0.08 (1) </td><td>0.4 (3) </td></tr><tr><td>Average Rank</td><td><b>7.2</b></td><td><b>6.3</b></td><td><b>6.4</b></td><td><b>3.7</b></td><td><b>4.5</b></td><td><b>5.3</b></td><td><b>1.2</b></td><td><b>2.0</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The results highlighted in bold denote that the method gets the highest accuracy for this dataset and the “*” represents the corresponding method cannot finish in 24 hours.</p>
                </div>
                <div class="p1">
                    <p id="281">虽然运行时间的平均次序能够体现出算法的时间效率, 但没有体现具体运行时间差异的大小.从表3中可以看出, 尽管FLAG要优于SJS, 但在大部分数据集上, 两者几乎在同一个数量级范围内, 均在几秒甚至更短的时间内得出结果.相反, 其他算法则需要很长的时间, 特别是准确率最高的LTS算法, 稍大一点的数据集都需要几千甚至上万秒的时间消耗.</p>
                </div>
                <div class="p1">
                    <p id="282">本节的实验表明:LTS具有最好的分类效果, 但运行时间长, 尤其在类别数多时, 时间消耗大, 如在Adiac数据集上, 差不多需要24 h的时间;FLAG的时间效率最好, 但分类准确率不高, 而本文算法SJS不仅在分类准确率上接近LTS算法, 而且在运行时间上与最优的FLAG具有同等的数量级.因此, 综合分类准确率和运行时间2方面, SJS的实用性更好.</p>
                </div>
                <h4 class="anchor-tag" id="283" name="283"><b>5.4 算法可扩展性</b></h4>
                <div class="p1">
                    <p id="284">本文以UCR archives中的最大时序数据集之一StarLightCurves来验证算法的可扩展性.该数据集包含3类的“星光”数据, 共计9 236条, 其中Eclipsed Binaries有2 580条, Cepheids有1 329条, RR Lyrae Variables有5 236条.实验中采用默认的训练集和数据集划分.Shapelets的提取时间主要受2方面的影响:1) 时序的长度;2) 训练集的大小.本文从这两方面进行实验.由于对比算法IG, KW, FS, IGSVM在StarLightCurves数据集上的运行时间太长, 难以获得实验结果, 因此, 本文舍弃与这些算法的比较.</p>
                </div>
                <div class="p1">
                    <p id="285">首先验证时序长度的变化对于分类准确率和运行时间的影响, 具体设置为:固定训练集中时序的数量, 将时序的长度从100变化至1 024, 以100为间隔单元.实验中, LTS算法受限于时间和空间消耗, 在长度大于300时难以得到结果, 因而只有3个实验数据.实验结果如图10所示, 图10 (a) 是随着时序长度的增加, 各对比算法在测试集上分类准确率的变化, 图10 (b) 是对应运行时间的变化.从图10 (a) 中可以看出, 本文算法SJS受时序数据长度变化影响最小且相对稳定, 而其他算法在长度为100和200时, 分类准确率很低且在长度增大过程中分类结果有波动, 这说明, SJS在提取Shapelets过程中能够很好的发现当前处理的数据集中最具类别可分性的子序列.运行时间对比的结果与表3基本一致, 即FLAG具有最优的运行时间, SJS次之, 但长度在100～600之间时, SJS要优于FLAG, 这充分验证了SJS的主要时间消耗来自时序数据间的相似性连接.</p>
                </div>
                <div class="area_img" id="286">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_286.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 时序数据长度变化时的实验结果" src="Detail/GetImg?filename=images/JFYZ201903015_286.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 时序数据长度变化时的实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_286.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.10 Experimental results for varying the length  of time series</p>

                </div>
                <div class="area_img" id="288">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903015_288.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 训练集时序数据数量变化时的实验结果" src="Detail/GetImg?filename=images/JFYZ201903015_288.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 训练集时序数据数量变化时的实验结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903015_288.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.11 Experimental results for varying the number  of training time series</p>

                </div>
                <div class="p1">
                    <p id="289">其次, 固定时序数据的长度为1 024, 将训练集中时序数据数量从100增加至1 000, 使用默认的测试集.由于LTS算法无法在合理的运行时间内得到结果, 所以本实验中仅有SJS, FSH, FLAG这3个算法的结果, 如图11所示.与FSH和FLAG在训练集增大时, 分类准确率有起伏不同, SJS一直处于上升的趋势, 如图11 (a) , 说明当训练集增大时, FSH和FLAG所提取的Shapelets可能会不同, 而SJS则会在原有提取出的Shapelets基础上, 对新增加的训练集数据提取Shapelets, 进而提高分类准确率.这一特性对于优化算法的运行效率更为重要, 如图11 (b) 所示, 尽管在同等规模的数据集上FLAG要优于SJS (如图11 (b) 所示) , 但SJS在应对数据集变化时可以重用之前结果, 能够减少后续计算量, 如图11 (b) 中的SJS-R曲线, 因此, SJS有更好的增量扩展性.</p>
                </div>
                <h3 id="290" name="290" class="anchor-tag"><b>6 结 论</b></h3>
                <div class="p1">
                    <p id="291">本文针对时序数据中的Shapelets提取问题进行研究, 提出了基于相似性连接策略的Shapelets提取算法SJS.该方法以子序列为基本单元描述时序数据之间的相似性, 通过不同类别的时序数据之间的差异向量构建候选矩阵, 然后提取候选矩阵中大差异值对应的子序列构成Shapelets.在大量真实时序数据集上进行分类的实验表明, 本文方法所提取的Shapelets不仅能获得良好的分类准确率, 还具有很高的时间效率, 实用性强.同时, 可扩展性实验表明:在训练数据集增大时, 本文算法能够增量提取Shapelets, 可以减少大量重复计算.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="363">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201404009&amp;v=Mjg0NDJ2U2RMRzRIOVhNcTQ5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N21XN3ZBTHk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Su Weixing, Zhu Yunlong, Liu Fang, et al. Outliers and change-points detection algorithm for time series[J]. Journal of Computer Research and Development, 2014, 51 (4) : 781- 788 (in Chinese) (苏卫星, 朱云龙, 刘芳, 等. 时间序列异常点及突变点的检测算法[J]. 计算机研究与发展, 2014, 51 (4) : 781- 788) 
                            </a>
                        </p>
                        <p id="365">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201408016&amp;v=MjY5MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3bVc3dkFMeXZTZExHNEg5WE1wNDlFWW9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Wu Honghua, Liu Guohua, Wang Wei. Similarity matching for uncertain time series[J]. Journal of Computer Research and Development, 2014, 51 (8) : 1802- 1810 (in Chinese) (吴红花, 刘国华, 王伟. 不确定时间序列的相似性匹配问题[J]. 计算机研究与发展, 2014, 51 (8) : 1802- 1810) 
                            </a>
                        </p>
                        <p id="367">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000011010&amp;v=MjcyMDFpZklZN0s3SHRqTnI0OUZaT29PREgwNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsMGNiaG89Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Esling P, Agon C.Time-series data mining[J]. ACM Computing Surveys (CSUR) , 2012, 45 (1) : 1- 34
                            </a>
                        </p>
                        <p id="369">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Querying and mining of time series data: experimental comparison of representations and distance measures">

                                <b>[4]</b>Ding Hui, Trajcevski G, Scheuermann P, et al. Querying and mining of time series data: Experimental comparison of representations and distance measures[J]. Proc of the VLDB Endowment, 2008, 1 (2) : 1542- 1552
                            </a>
                        </p>
                        <p id="371">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Time series classification with ensembles of elastic distance measures">

                                <b>[5]</b>Lines J, Bagnall A.Time series classification with ensembles of elastic distance measures[J]. Data Mining and Knowledge Discovery, 2015, 29 (3) : 565- 592
                            </a>
                        </p>
                        <p id="373">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Three myths about dynamic time warping">

                                <b>[6]</b>Ratanamahatana C A, Keogh E.Three myths about dynamic time warping data mining[C] //Proc of the 5th SIAM Int Conf on Data Mining.Philadelphia, PA: SIAM, 2005: 506- 510
                            </a>
                        </p>
                        <p id="375">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust and fast similarity search for moving object trajectories">

                                <b>[7]</b>Chen Lei, Özsu M T, Oria V.Robust and fast similarity search for moving object trajectories[C] //Proc of the 24th ACM SIGMOD Int Conf on Management of Data. New York: ACM, 2005: 491- 502
                            </a>
                        </p>
                        <p id="377">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Derivative dynamic time warping">

                                <b>[8]</b>Keogh E J, Pazzani M J.Derivative dynamic time warping[C] //Proc of the 1st SIAM Int Conf on Data Mining.Philadelphia, PA: SIAM, 2001: 1- 11
                            </a>
                        </p>
                        <p id="379">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738155&amp;v=MjM4MjlUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSmwwY2Jobz1OaWZPZmJLN0h0RE5xWTlGWStnSERYazhvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Jeong Y S, Jeong M K, Omitaomu O A.Weighted dynamic time warping for time series classification[J]. Pattern Recognition, 2011, 44 (9) : 2231- 2240
                            </a>
                        </p>
                        <p id="381">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Time warp edit distance with stiffness adjustment for time series matching">

                                <b>[10]</b>Marteau P F.Time warp edit distance with stiffness adjustment for time series matching[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) : 306- 318
                            </a>
                        </p>
                        <p id="383">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The move-split-merge metric for time series">

                                <b>[11]</b>Stefan A, Vassilis A, Gautam D.The move-split-merge metric for time series[J]. IEEE Transactions on Knowledge and Data Engineering, 2013, 25 (6) : 1425- 1438
                            </a>
                        </p>
                        <p id="385">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A complexity-invariant distance measure for time series">

                                <b>[12]</b>Batista G E, Wang Xiaoyue, Keogh E J.A complexity-invariant distance measure for time series[C] //Proc of the 11th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2011: 699- 710
                            </a>
                        </p>
                        <p id="387">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Time series shapelets: a novel technique that allows accurate, interpretable and fast classification">

                                <b>[13]</b>Ye Lexiang, Keogh E.Time series shapelets: A novel technique that allows accurate, interpretable and fast classification[J]. Data Mining and Knowledge Discovery, 2011, 22 (1) : 149- 182
                            </a>
                        </p>
                        <p id="389">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Logical-shapelets:an expressive primitive for time series classification">

                                <b>[14]</b>Mueen A, Keogh E, Young N. Logical-shapelets: An expressive primitive for time series classification[C] //Proc of the 17th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2011: 1154- 1162
                            </a>
                        </p>
                        <p id="391">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002157770&amp;v=MDU3NjFqN0Jhck80SHRIT3JvcENZK3dQWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVmJ6QUpGWT1O&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>Lin J, Keogh E, Li Wei, et al. Experiencing SAX: A novel symbolic representation of time series[J]. Data Mining and Knowledge Discovery, 2007, 15 (2) : 107- 144
                            </a>
                        </p>
                        <p id="393">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast shapelets:a scalable algorithm for discovering time series shapelets">

                                <b>[16]</b>Rakthanmanon T, Keogh E. Fast shapelets: A scalable algorithm for discovering time series shapelets[C] //Proc of the 13th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2013: 668- 676
                            </a>
                        </p>
                        <p id="395">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14031700001088&amp;v=MDU1NjBIeWptVWI3SUpsMGNiaG89Tmo3QmFySzhIdExOcUk5RlpPc09ESFF4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>Hills J, Lines J, Baranauskas E, et al. Classification of time series by shapelet transformation[J]. Data Mining and Knowledge Discovery, 2014, 28 (4) : 851- 881
                            </a>
                        </p>
                        <p id="397">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A shapelet transform for time series classification">

                                <b>[18]</b>Lines J, Davis L M, Hills J, et al. A shapelet transform for time series classification[C] //Proc of the 18th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2012: 289- 297
                            </a>
                        </p>
                        <p id="399">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Matrix profile I: All pairs similarity joins for time series: A unifying view that includes motifs, discords and shapelets">

                                <b>[19]</b>Yeh C C M, Zhu Yan, Ulanova L, et al. Matrix profile I: All pairs similarity joins for time series: A unifying view that includes motifs, discords and shapelets[C] //Proc of the 16th Int Conf on Data Mining (ICDM) . Piscataway, NJ: IEEE, 2016: 1317- 1322
                            </a>
                        </p>
                        <p id="401">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201507011&amp;v=MTI4MTVxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N21XN3ZBTHo3QmRyRzRIOVRNcUk5RVpZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>Yuan Jidong, Wang Zhihai, Han Meng, et al. A logical shapelets transform for time series classification[J]. Chinese Journal of Computers, 2015, 38 (7) : 1448- 1459 (in Chinese) (原继东, 王志海, 韩萌, 等. 基于逻辑shapelets转换的时间序列分类算法[J]. 计算机学报, 2015, 38 (7) : 1448- 1459) 
                            </a>
                        </p>
                        <p id="403">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient PatternBased Time Series Classification on GPU">

                                <b>[21]</b>Chang Kaiwei, Deka B, Hwu W M W, et al. Efficient pattern-based time series classification on GPU[C] //Proc of the 12th Int Conf on Data Mining (ICDM) . Piscataway, NJ: IEEE, 2012: 131- 140
                            </a>
                        </p>
                        <p id="405">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ultra-fast shapelets for time series classification">

                                <b>[22]</b>Wistuba M, Grabocka J, Schmidt-Thieme L. Ultra-fast shapelets for time series classification[EB/OL]. 2015 [2015-03-17]. https://arxiv.org/abs/1503.05018
                            </a>
                        </p>
                        <p id="407">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accelerating time series shapelets discovery with key points">

                                <b>[23]</b>Zhang Zhenguo, Zhang Haiwei, Wen Yanlong, et al. Accelerating time series shapelets discovery with key points [G] //LNCS 9932: Proc of the 12th Asia-Pacific Web Conf. Berlin: Springer, 2016: 330- 342
                            </a>
                        </p>
                        <p id="409">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning timeseries shapelets">

                                <b>[24]</b>Grabocka J, Schilling N, Wistuba M, et al. Learning time-series shapelets[C] //Proc of the 20th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2014: 392- 401
                            </a>
                        </p>
                        <p id="411">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient learning of timeseries shapelets">

                                <b>[25]</b>Hou Lu, Kwok J T, Zurada J M.Efficient learning of timeseries shapelets[C] //Proc of the 30th AAAI Conf on Artificial Intelligence. Menlo Park, CA: AAAI, 2016: 1209- 1215
                            </a>
                        </p>
                        <p id="413">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The great time series classification bake off:a review and experimental evaluation of recent algorithmic advances">

                                <b>[26]</b>Bagnall A, Lines J, Bostrom A, et al. The great time series classification bake off: A review and experimental evaluation of recent algorithmic advances[J]. Data Mining and Knowledge Discovery, 2017, 31 (3) : 606- 660
                            </a>
                        </p>
                        <p id="415">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Searching and Min-ing Trillions of Time Series Subsequences under Dynamic TimeWarping">

                                <b>[27]</b>Rakthanmanon T, Campana B, Mueen A, et al. Searching and mining trillions of time series subsequences under dynamic time warping[C] //Proc of the 18th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2012: 262- 270
                            </a>
                        </p>
                        <p id="417">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rare time series motif discovery from unbounded streams">

                                <b>[28]</b>Begum N, Keogh E.Rare time series motif discovery from unbounded streams[J]. Proc of the VLDB Endowment, 2014, 8 (2) : 149- 160
                            </a>
                        </p>
                        <p id="419">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The fastest similarity search algorithm for time series subsequences under Euclidean distance">

                                <b>[29]</b>Mueen A, Zhu Yan, Yeh M et al. The fastest similarity search algorithm for time series subsequences under Euclidean distance[EB/OL]. [2017-08-12]. http://www.cs.unm.edu/～mueen/FastestSimilaritySearch.html
                            </a>
                        </p>
                        <p id="421">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Transformation based ensembles for time series classification">

                                <b>[30]</b>Bagnall A, Davis L, Hills J, et al. Transformation based ensembles for time series classification[C] //Proc of the 12th SIAM Int Conf on Data Mining. Philadelphia, PA: SIAM, 2012: 307- 318
                            </a>
                        </p>
                        <p id="423">
                            <a id="bibliography_31" >
                                    <b>[31]</b>
                                Demšar J. Statistical comparisons of classifiers over multiple data sets[J]. Journal of Machine Learning Research, 2006, 7 (1) : 1- 30
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="3" href="javascript:void(0)">
                            <b>1</b> http://www.cs.ucr.edu/～eamonn/time_series_data/
                        </span>
                    </p>
                    <p>
                        <span id="5" href="javascript:void(0)">
                            <b>2</b> http://www.uea.ac.uk/computing/machine-learning/shapelets/shapelet-data
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201903015" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201903015&amp;v=MDgxMzVxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N21XN3ZBTHl2U2RMRzRIOWpNckk5RVlZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
