

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127157317176250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201909004%26RESULT%3d1%26SIGN%3dAyVRR7VxFz21gbyhUAKdEPfxzn8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201909004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201909004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201909004&amp;v=MjA0MzdCdEdGckNVUkxPZVplUnNGeS9uVjczSUx5dlNkTEc0SDlqTXBvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#48" data-title="&lt;b&gt;1 相关研究工作&lt;/b&gt; "><b>1 相关研究工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;1.1 PU学习算法&lt;/b&gt;"><b>1.1 PU学习算法</b></a></li>
                                                <li><a href="#55" data-title="&lt;b&gt;1.2 GAN模型&lt;/b&gt;"><b>1.2 GAN模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;2 基于PU与生成对抗网络的模型&lt;/b&gt; "><b>2 基于PU与生成对抗网络的模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="&lt;b&gt;2.1 puGAN模型&lt;/b&gt;"><b>2.1 puGAN模型</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;2.2 理论分析&lt;/b&gt;"><b>2.2 理论分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#129" data-title="&lt;b&gt;3 实例分析&lt;/b&gt; "><b>3 实例分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#130" data-title="&lt;b&gt;3.1 数据集&lt;/b&gt;"><b>3.1 数据集</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;3.2 传统模型与puGAN模型对比&lt;/b&gt;"><b>3.2 传统模型与puGAN模型对比</b></a></li>
                                                <li><a href="#148" data-title="&lt;b&gt;3.3 3种GAN模型对比&lt;/b&gt;"><b>3.3 3种GAN模型对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#155" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="图1 GAN模型图">图1 GAN模型图</a></li>
                                                <li><a href="#70" data-title="图2 puGAN模型图">图2 puGAN模型图</a></li>
                                                <li><a href="#135" data-title="图3 正样本数据统计图">图3 正样本数据统计图</a></li>
                                                <li><a href="#143" data-title="图4 OC,SVM,NN和puGAN的ROC曲线对比图">图4 OC,SVM,NN和puGAN的ROC曲线对比图</a></li>
                                                <li><a href="#145" data-title="图5 OC,SVM,NN和puGAN训练误差和测试误差分析对比图">图5 OC,SVM,NN和puGAN训练误差和测试误差分析对比图</a></li>
                                                <li><a href="#152" data-title="图6 GAN1,GAN2和puGAN的ROC曲线图">图6 GAN1,GAN2和puGAN的ROC曲线图</a></li>
                                                <li><a href="#153" data-title="图7 GAN1,GAN2和puGAN训练误差和测试误差分析对比图">图7 GAN1,GAN2和puGAN训练误差和测试误差分析对比图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title="Gao Rong,Li Jing,Du Bo,et al.A synthetic recommendation model for point-of-interest on location-based social networks:Exploiting contextual information and review[J].Journal of Computer Research and Development,2016,53(4):752- 763 (in Chinese)(高榕,李晶,杜博,等.一种融合情景和评论信息的位置社交网络兴趣点推荐模型[J].计算机研究与发展,2016,53(4):752- 763)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201604004&amp;v=MDYzNzFNcTQ5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5L25WNzNMTHl2U2RMRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Gao Rong,Li Jing,Du Bo,et al.A synthetic recommendation model for point-of-interest on location-based social networks:Exploiting contextual information and review[J].Journal of Computer Research and Development,2016,53(4):752- 763 (in Chinese)(高榕,李晶,杜博,等.一种融合情景和评论信息的位置社交网络兴趣点推荐模型[J].计算机研究与发展,2016,53(4):752- 763)
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title="Chen Cheng,Yang Haiqin,Lyu M R,et al.Where you like to go next:Successive point-of-interest recommendation[C] //Proc of the 23rd Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2013:2605- 2611" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Where you like to go next:Successive point-of-interest recommendation">
                                        <b>[2]</b>
                                        Chen Cheng,Yang Haiqin,Lyu M R,et al.Where you like to go next:Successive point-of-interest recommendation[C] //Proc of the 23rd Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2013:2605- 2611
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title="Gao Huiji,Tang Jiliang,Hu Xia,et al.Content-aware point of interest recommendation on location-based social networks[C] //Proc of the 29th AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2015:1721- 1727" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Content-aware point of interest recommendation on location-based social networks">
                                        <b>[3]</b>
                                        Gao Huiji,Tang Jiliang,Hu Xia,et al.Content-aware point of interest recommendation on location-based social networks[C] //Proc of the 29th AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2015:1721- 1727
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title="Yin Hongzhi,Zhou Xiaofang,Cui Bin,et al.Adapting to user interest drift for POI recommendation[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2016,28(10):2566- 2581" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adapting to user interest drift for POI recommendation">
                                        <b>[4]</b>
                                        Yin Hongzhi,Zhou Xiaofang,Cui Bin,et al.Adapting to user interest drift for POI recommendation[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2016,28(10):2566- 2581
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title="Wen Yutian,Tian Xiaohua,Wang Xinbing,et al.Fundamental limits of RSS fingerprinting based indoor localization[C] //Proc of the IEEE Conf on Computer Communications.Piscataway,NJ:IEEE,2015:2479- 2487" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fundamental limits of RSS fingerprinting based indoor localization">
                                        <b>[5]</b>
                                        Wen Yutian,Tian Xiaohua,Wang Xinbing,et al.Fundamental limits of RSS fingerprinting based indoor localization[C] //Proc of the IEEE Conf on Computer Communications.Piscataway,NJ:IEEE,2015:2479- 2487
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title="Zhou Mu,Zhang Qiao,Xu Kunjie,et al.PRIMAL:Page rank-based indoor mapping and localization using gene-sequenced unlabeled WLAN received signal strength[J].Sensors,2015,15(10):24791- 24817" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PRIMAL:Page rank based indoor mapping and localization using gene sequenced unlabeled WLAN received signal strength">
                                        <b>[6]</b>
                                        Zhou Mu,Zhang Qiao,Xu Kunjie,et al.PRIMAL:Page rank-based indoor mapping and localization using gene-sequenced unlabeled WLAN received signal strength[J].Sensors,2015,15(10):24791- 24817
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title="Zhang Wei,Hua Xianghong,Yu Kegen,et al.Radius based domain clustering for WiFi indoor positioning[J].Sensor Review,2017,37(1):54- 60" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD9180E7E349065F745924E2D7829D546B&amp;v=MDEwNjVTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TnBodzdxN3dxcz1OajNhYXJxNUZ0RzVxUHBHWU9JUENubFB5QklXNHoxNVBYMldxeG8zY01hUlFienRDT052Rg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        Zhang Wei,Hua Xianghong,Yu Kegen,et al.Radius based domain clustering for WiFi indoor positioning[J].Sensor Review,2017,37(1):54- 60
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title="Matos P P D,Afonso A P,Carmo M B.Point of interest awareness using indoor positioning with a mobile phone[C/OL] //Proc of the 1st Int Conf on Pervasive and Embedded Computing and Communication Systems.2011 [2018-12-19].https://www.researchgate.net/publication/221156937_Point_of_Interest_Awareness_using_Indoor_Positioning_with_a_Mobile_Phone" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Point of interest awareness using indoor positioning with a mobile phone[C/OL]">
                                        <b>[8]</b>
                                        Matos P P D,Afonso A P,Carmo M B.Point of interest awareness using indoor positioning with a mobile phone[C/OL] //Proc of the 1st Int Conf on Pervasive and Embedded Computing and Communication Systems.2011 [2018-12-19].https://www.researchgate.net/publication/221156937_Point_of_Interest_Awareness_using_Indoor_Positioning_with_a_Mobile_Phone
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title="Moghtadaiee V,Dempster A G.WiFi fingerprinting signal strength error modeling for short distances[C] //Proc of the Int Conf on Indoor Positioning and Indoor Navigation.Piscataway,NJ:IEEE,2013:1- 6" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=WiFi fingerprinting signal strength error modeling for short distances">
                                        <b>[9]</b>
                                        Moghtadaiee V,Dempster A G.WiFi fingerprinting signal strength error modeling for short distances[C] //Proc of the Int Conf on Indoor Positioning and Indoor Navigation.Piscataway,NJ:IEEE,2013:1- 6
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title="Elkan C,Noto K.Learning classifiers from only positive and unlabeled data[C] //Proc of the 14th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM,2008:213- 220" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning classifiers from only positive and unlabeled data">
                                        <b>[10]</b>
                                        Elkan C,Noto K.Learning classifiers from only positive and unlabeled data[C] //Proc of the 14th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM,2008:213- 220
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title="Du Plessis M C,Niu Gang,Sugiyama M.Analysis of learning from positive and unlabeled data[C] //Proc of the 27th Int Conf on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014:703- 711" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analysis of learning from positive and unlabeled data">
                                        <b>[11]</b>
                                        Du Plessis M C,Niu Gang,Sugiyama M.Analysis of learning from positive and unlabeled data[C] //Proc of the 27th Int Conf on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014:703- 711
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title="Chapelle O,Lkopf B S,Zien A.Semi-Supervised Learning[M].Cambridge,MA:MIT Press,2006" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-Supervised Learning">
                                        <b>[12]</b>
                                        Chapelle O,Lkopf B S,Zien A.Semi-Supervised Learning[M].Cambridge,MA:MIT Press,2006
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title="Ren Yafeng,Ji Donghong,Zhang Hongbin,et al.Deceptive reviews detection based on positive and unlabeled learning[J].Journal of Computer Research and Development,2015,52(3):639- 648 (in Chinese)(任亚峰,姬东鸿,张红斌,等.基于PU学习算法的虚假评论识别研究[J].计算机研究与发展,2015,52(3):639- 648)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201503012&amp;v=MzAwNzVFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJzRnkvblY3M0xMeXZTZExHNEg5VE1ySTk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Ren Yafeng,Ji Donghong,Zhang Hongbin,et al.Deceptive reviews detection based on positive and unlabeled learning[J].Journal of Computer Research and Development,2015,52(3):639- 648 (in Chinese)(任亚峰,姬东鸿,张红斌,等.基于PU学习算法的虚假评论识别研究[J].计算机研究与发展,2015,52(3):639- 648)
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title="Goodfellow I J,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of the 27th Int Conf on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014:2672- 2680" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative Adversarial Nets">
                                        <b>[14]</b>
                                        Goodfellow I J,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of the 27th Int Conf on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014:2672- 2680
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title="Salimans T,Goodfellow I,Zaremba W,et al.Improved techniques for training gans[J].arXiv preprint,arXiv:1606.03498,2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved techniques for training gans">
                                        <b>[15]</b>
                                        Salimans T,Goodfellow I,Zaremba W,et al.Improved techniques for training gans[J].arXiv preprint,arXiv:1606.03498,2016
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title="Papernot N,Abadi M,Erlingsson U,et al.Semi-supervised knowledge transfer for deep learning from private training data[J].arXiv preprint,arXiv:1610.05755,2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-supervised knowledge transfer for deep learning from private training data">
                                        <b>[16]</b>
                                        Papernot N,Abadi M,Erlingsson U,et al.Semi-supervised knowledge transfer for deep learning from private training data[J].arXiv preprint,arXiv:1610.05755,2016
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title="Odena A.Semi-supervised learning with generative adversarial networks[J].arXiv preprint,arXiv:1606.01583,2016" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-supervised learning with generative adversarial networks">
                                        <b>[17]</b>
                                        Odena A.Semi-supervised learning with generative adversarial networks[J].arXiv preprint,arXiv:1606.01583,2016
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title="Arjovsky M,Chintala S,Bottou L.Wasserstein gan[J].arXiv preprint,arXiv:1701.07875,2017" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wasserstein gan">
                                        <b>[18]</b>
                                        Arjovsky M,Chintala S,Bottou L.Wasserstein gan[J].arXiv preprint,arXiv:1701.07875,2017
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title="Mordelet F,Vert J P.A bagging SVM to learn from positive and unlabeled examples[J].Pattern Recognition Letters,2010,37(1):201- 209" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122500448289&amp;v=MTM1MTRadUh5am1VTDNJSjF3UWFCRT1OaWZPZmJLOUg5UE9xbzlGWU84SERuUXdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Mordelet F,Vert J P.A bagging SVM to learn from positive and unlabeled examples[J].Pattern Recognition Letters,2010,37(1):201- 209
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title="Singh G,Sachan M.Multi-layer perceptron (MLP) neural network technique for offline handwritten gurmukhi character recognition[C] //Proc of the IEEE Int Conf on Computational Intelligence and Computing Research.Piscataway,NJ:IEEE,2015:1- 5" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-layer perceptron (MLP) neural network technique for offline handwritten gurmukhi character recognition">
                                        <b>[20]</b>
                                        Singh G,Sachan M.Multi-layer perceptron (MLP) neural network technique for offline handwritten gurmukhi character recognition[C] //Proc of the IEEE Int Conf on Computational Intelligence and Computing Research.Piscataway,NJ:IEEE,2015:1- 5
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(09),1843-1850 DOI:10.7544/issn1000-1239.2019.20180847            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于PU与生成对抗网络的POI定位算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%94%B0%E7%BB%A7%E4%BC%9F&amp;code=41973269&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">田继伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%8A%B2%E6%9D%BE&amp;code=11235738&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王劲松</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%9F%B3%E5%87%AF&amp;code=26413150&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">石凯</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A9%E6%B4%A5%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0028092&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">天津理工大学计算机科学与工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A9%E6%B4%A5%E5%B8%82%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E5%8F%8A%E8%BD%AF%E4%BB%B6%E6%96%B0%E6%8A%80%E6%9C%AF%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%A4%A9%E6%B4%A5%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">天津市智能计算及软件新技术重点实验室(天津理工大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%97%85%E6%AF%92%E9%98%B2%E6%B2%BB%E6%8A%80%E6%9C%AF%E5%9B%BD%E5%AE%B6%E5%B7%A5%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%A4%A9%E6%B4%A5%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机病毒防治技术国家工程实验室(天津理工大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着智能移动设备的快速普及,人们对基于位置的社交网络服务的依赖性越来越高.但是,由于数据采集成本昂贵以及现有数据采集技术的缺陷,基于小样本数据挖掘的兴趣点(point of interest, POI)定位已经成为了一种挑战.尽管已经有一些POI定位方面的研究,但是现有的方法不能解决正样本数据不足的问题.提出一种基于PU与生成对抗网络(positive and unlabeled generative adversarial network, puGAN)的模型,采用PU学习和生成对抗网络相结合的方式挖掘数据的隐藏特征,生成伪正样本弥补数据不足的问题,并校正无标签样本数据的分布,从而训练出有效的POI判别模型.通过分析ROC曲线以及训练误差和测试误差在迭代过程中的变化和关系来比较不同模型在实验场景下的效果.结果表明,puGAN模型可以有效解决数据样本不足的问题,进而提高POI定位的准确性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据挖掘;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B4%E8%B6%A3%E7%82%B9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">兴趣点;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%9A%E4%BD%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">定位;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=PU&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">PU;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">生成对抗网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *王劲松,jswang@tjut.edu.cn;
                                </span>
                                <span>
                                    田继伟,jiwei.tian@foxmail.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61272450);</span>
                                <span>天津市自然科学基金重点项目(18JCZDJC30700);</span>
                                <span>天津市科技计划项目(17ZXHLSY00060);</span>
                    </p>
            </div>
                    <h1><b>Positive and Unlabeled Generative Adversarial Network on POI Positioning</b></h1>
                    <h2>
                    <span>Tian Jiwei</span>
                    <span>Wang Jinsong</span>
                    <span>Shi Kai</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Engineering, Tianjin University of Technology</span>
                    <span>Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology (Tianjin University of Technology)</span>
                    <span>National Engineering Laboratory for Computer Virus Prevention and Control Technology (Tianjin University of Technology)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the rapid popularization of smart mobile devices, people rely more and more on location-based social networking service(LBSNS). Due to the high cost of data acquisition, point of interest(POI) positioning based on small data collection has become a big challenge. Recent research focuses on received signal strength(RSS) and simultaneous localization methods. Although there has been some research on POI positioning, the existing approaches do not discuss the problem of insufficient positive training samples. Based on the truthful positive data and a large amount of unlabeled data, a novel approach, called positive and unlabeled generative adversarial network(puGAN), is proposed. Firstly, we use positive and unlabeled method along with the generative adversarial network to effectively mine the hidden features of data. Secondly, based on the hidden features, we calibrate the positive data and unlabeled data, then treat them as the input of the discriminator. Finally, with the minimax of generator and discriminator, a POI-discriminator model is obtained. We evaluate the new method by analyzing ROC curve and the relationship between training error and testing error. The results of experiments show that the method we proposed can effectively solve the problem of insufficient positive samples and outperforms the traditional models of POI positioning, including one-class classifier, SVM and neural network.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20mining&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data mining;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=point%20of%20interest(POI)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">point of interest(POI);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=positioning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">positioning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=positive%20and%20unlabeled&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">positive and unlabeled;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=generative%20adversarial%20network(GAN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">generative adversarial network(GAN);</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Tian Jiwei,born in 1993.MSc candidate. Student member of CCF. Her main research interests include data mining, wireless network application.&lt;image id="190" type="formula" href="images/JFYZ201909004_19000.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Wang Jinsong, born in 1970. PhD, professor,PhD supervisor.Distinguished member of CCF. His main research interests include network and information security,computer network.&lt;image id="192" type="formula" href="images/JFYZ201909004_19200.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Shi Kai,born in 1981.PhD,associate professor,MSc supervisor.Member of CCF. His main research interests include network and information security.(shikai0229@163. com)&lt;image id="194" type="formula" href="images/JFYZ201909004_19400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-24</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China(61272450);</span>
                                <span>the Key Program of the Natural Science Foundation of Tianjin(18JCZDJC30700);</span>
                                <span>the Science and Technology Project of Tianjin(17ZXHLSY00060);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="43">随着互联网的蓬勃发展,个性化推荐技术已经成为学术界的研究热点之一.近年来,个性化推荐技术已经成功应用于多个领域,尤其是在广告推荐领域,它带来了巨大的商业价值.但是,个性化推荐技术的数据来源于人们在网络上产生的行为,这些网络行为往往是低成本的,由这些低成本的行为推荐来的广告虽然具有很大价值,但确有局限性.例如,经常在网络上浏览汽车的人虽然有很大可能性接受汽车类的广告推荐,但是相比之下,那些去4S店的人有更大可能性购买汽车,从而给商家带来真正的利润.考虑到推荐技术的这种局限性,对兴趣点(point of interest, POI)的定位和推荐技术就变得非常重要.另外,随着智能移动设备的快速普及,人们对基于位置的社交网络服务(location-based social networking service, LBSNS)的依赖性也越来越高.基于数据挖掘的POI定位和推荐技术已经成为一个重要课题.高榕等人<citation id="172" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>将POI、社交关联和评论信息融合起来,提出了一种GeoSoRev兴趣点推荐模型.Chen等人<citation id="173" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>研究了LBSNS中的连续个性化POI推荐问题,将时间关系融合到POI推荐中.Gao等人<citation id="174" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>将内容信息融合进了POI推荐系统中.Yin等人<citation id="175" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>考虑了用户在不同区域往往有不同的兴趣,研究了跨区域的POI推荐系统.但是,文献<citation id="176" type="reference">[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</citation>的POI推荐系统都无法离开POI定位技术的建设.</p>
                </div>
                <div class="p1">
                    <p id="44">目前,国内外许多研究已经利用无线网络来进行POI定位.其中,使用最多的方法是基于无线信号接收强度(received signal strength, RSS)的位置指纹技术<citation id="179" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>,该技术已经广泛应用于移动通信领域,且可以在任何具有WiFi发射设备的地方推广应用.但是由于用户隐私问题,有POI标记的数据难以收集.一般来说,采集来的数据可以分为2类:一类是占比很大的没有标记POI的数据;另一类是占比很小的标记了POI的数据,即正样本数据.这就造成了正样本数据不足的问题,极大地影响了POI定位的准确性.目前很少有研究致力于解决这一普遍存在的问题.Matos等人<citation id="177" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了一种模拟定位的方式去进行POI的识别.然而,这种识别系统的误差会随着系统计算量的增大而增加.此外,Moghtadaiee等人<citation id="178" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了一种短距离RSS误差模型来提高POI定位效果,但累积误差的问题仍然无法得到有效解决.</p>
                </div>
                <div class="p1">
                    <p id="45">本文基于现有数据,提出了一种基于PU与生成对抗网络(positive and unlabeled generative adversarial network, puGAN)的模型来进行POI的有效定位与识别.实验表明,本文提出的puGAN模型比传统的POI定位和分类模型具有更好的效果.本文工作的主要贡献有2个方面:</p>
                </div>
                <div class="p1">
                    <p id="46">1) 将PU(positive and unlabeled)学习<citation id="180" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>和生成对抗网络(generative adversarial network, GAN)模型相结合,并应用到POI定位算法中,以此解决数据样本不足的问题,从而提高POI定位的准确性;</p>
                </div>
                <div class="p1">
                    <p id="47">2) 理论证明了puGAN模型的普遍适用性.</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag"><b>1 相关研究工作</b></h3>
                <div class="p1">
                    <p id="49">到目前为止,大部分POI定位模型都有着数据采集不足的缺陷.有2种方式可以解决这个问题:一种方式是覆盖所有的采集点采集充足的数据,但这种方式往往伴随着巨大的人力、财力和时间成本,通常来说是不可接受的;另一种方式是基于少量正样本和大量无标签样本,使用PU学习方法.下面简单介绍PU学习算法.</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50"><b>1.1 PU学习算法</b></h4>
                <div class="p1">
                    <p id="51">PU学习作为半监督学习<citation id="181" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>的一个重要分支,逐渐成为了研究界的热点问题.PU算法对无标签样本的使用情况,可以概括成2个方面:</p>
                </div>
                <div class="p1">
                    <p id="52">1) 基础模型的研究.通过单类模型(one-class, OC)对正样本数据进行学习,但是这种方式通常会浪费较多的数据特征,从而导致模型欠拟合.或者使用SVM等二分类模型,它们虽然能够利用到所有的数据特征,但无法避免无标签样本噪声过大而可能导致的欠拟合问题.</p>
                </div>
                <div class="p1">
                    <p id="53">2) 基于高可信样本的挖掘.这种方法的核心是优先找到高可信的正样本或者负样本,从而基于此样本进行学习和分类.任亚峰等人<citation id="182" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>使用这种PU学习的方式,从大量无标签样本中识别出少量高可信的负样本,进行了识别虚假评论的研究.</p>
                </div>
                <div class="p1">
                    <p id="54">PU学习虽然能够利用少量正样本以及大量无标签样本进行学习,但是正样本和无标签样本的样本量相差巨大,影响了模型学习的准确性和快速性.本文在利用PU学习算法的同时引入了GAN模型,一方面生成伪正样本弥补正样本不足的缺陷,另一方面学习无标签样本的分布,提高分类模型的准确性.下面简单介绍GAN模型.</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55"><b>1.2 GAN模型</b></h4>
                <div class="p1">
                    <p id="56">2014年,Goodfellow等人<citation id="183" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出了GAN,并进行了一系列研究<citation id="185" type="reference"><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>,解决了如何使机器学习的训练成果向着理想方向前进的问题.Odena<citation id="184" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>首次将GAN模型与半监督学习相结合来提高生成器的质量.</p>
                </div>
                <div class="p1">
                    <p id="57">如图1所示,GAN模型针对正样本提出了生成器与判别器的概念.生成器通过不断学习真实样本数据的分布生成伪样本,从而尽可能欺骗判别器.而判别器则通过学习真实样本和伪样本的差异,尽可能区分出数据来源.</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909004_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 GAN模型图" src="Detail/GetImg?filename=images/JFYZ201909004_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 GAN模型图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909004_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 The illustration of GAN model</p>

                </div>
                <div class="p1">
                    <p id="59">生成器和判别器不断博弈的过程就是数据不断生成和分类的过程.实验证明,GAN模型在训练样本不足的情况下,能够有效学习出原有数据的分布特征.与此同时,模型的判别器也能够准确地区分出样本是来源于生成器还是来源于真实的训练数据集.</p>
                </div>
                <div class="p1">
                    <p id="60">另外,2017年,Arjovsky等人<citation id="186" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出了一种观点,即GAN中利用JS散度会导致纳什不均衡的问题,这会使模型训练不稳定.为了解决这个问题,他提出了WGAN模型,这种模型在提升稳定性与准确性上有很好的表现.本文提出的puGAN模型也使用了这一思想.</p>
                </div>
                <div class="p1">
                    <p id="61">不同于传统的GAN模型,本文不仅将GAN模型应用于POI定位中,而且在模型中分别对正样本和无标签样本都引入了生成器和判别器.</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>2 基于PU与生成对抗网络的模型</b></h3>
                <div class="p1">
                    <p id="63">本文将第1节的PU学习与生成对抗网络模型相结合,提出了基于PU与生成对抗网络的模型.下面将详细介绍puGAN模型的原理及理论分析.</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>2.1 puGAN模型</b></h4>
                <div class="p1">
                    <p id="65">在本文中,<i>X</i><sub>p</sub>,<i>X</i><sub>u</sub>分别表示正样本数据集和无标签样本数据集;<i>p</i><sub>p</sub>(<i>x</i>),<i>p</i><sub>n</sub>(<i>x</i>),<i>p</i><sub>u</sub>(<i>x</i>),<i>p</i>(<i>x</i>)分别表示正样本、负样本、无标签样本以及整个数据集合的分布;<i>G</i><sub>p</sub>,<i>G</i><sub>u</sub>分别表示puGAN模型中正样本生成器和无标签样本生成器;<i>D</i><sub>p</sub>,<i>D</i><sub>u</sub>分别表示正样本判别器和无标签样本判别器;<i>D</i><sub>pu</sub>表示正样本/无标签样本判别器.本文假设数据分布遵循的规则为</p>
                </div>
                <div class="p1">
                    <p id="66"><i>p</i>(<i>x</i>)=<i>p</i><sub>p</sub>(<i>x</i>)+<i>p</i><sub>n</sub>(<i>x</i>),</p>
                </div>
                <div class="p1">
                    <p id="67"><i>p</i><sub>u</sub>(<i>x</i>)=<i>θ</i><sub>p</sub><i>p</i><sub>p</sub>(<i>x</i>)+<i>θ</i><sub>n</sub><i>p</i><sub>n</sub>(<i>x</i>),</p>
                </div>
                <div class="p1">
                    <p id="68">其中<i>θ</i><sub>p</sub>,<i>θ</i><sub>n</sub>都是0～1之间的小数,并且满足<i>θ</i><sub>p</sub>+<i>θ</i><sub>n</sub>=1.</p>
                </div>
                <div class="p1">
                    <p id="69">基于上面的假设,本文设计了puGAN模型.如图2所示,描述了puGAN模型的训练过程.其中,判别器<i>D</i><sub>u</sub>通过对真实的无标签样本与无标签样本生成器<i>G</i><sub>u</sub>生成的数据进行判别分类,从而调整学习得到无标签样本数据的分布特征.同理,判别器<i>D</i><sub>p</sub>通过对正样本进行判别分类,训练得到正样本数据的分布特征.</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909004_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 puGAN模型图" src="Detail/GetImg?filename=images/JFYZ201909004_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 puGAN模型图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909004_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The illustration of puGAN model</p>

                </div>
                <div class="p1">
                    <p id="71">最终,puGAN模型的目标函数为</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>D</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">}</mo></mrow></munder><mi>V</mi><mo stretchy="false">(</mo><mi>G</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>α</mi><mtext> </mtext><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>D</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><mi>V</mi><msub><mrow></mrow><mrow><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mtext>p</mtext></msub></mrow></msub><mo stretchy="false">(</mo><mi>G</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>β</mi><mtext> </mtext><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>D</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><mi>V</mi><msub><mrow></mrow><mrow><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mtext>u</mtext></msub></mrow></msub><mo stretchy="false">(</mo><mi>G</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>γ</mi><mtext> </mtext><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><mi>V</mi><msub><mrow></mrow><mrow><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>u</mtext></mrow></msub></mrow></msub><mo stretchy="false">(</mo><mi>G</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中,<i>α</i>,<i>β</i>,<i>γ</i>均为大于0的参数.</p>
                </div>
                <div class="p1">
                    <p id="74">判别器希望提高自己的辨别能力,能够准确分辨出样本是来源于真实样本集还是来源于生成器生成.而生成器则不断提升自己的“伪造”技术,希望能够生成可以“以假乱真”的数据.根据零和博弈的原则,将目标函数进行推导,可以得到</p>
                </div>
                <div class="p1">
                    <p id="75"><i>V</i><sub><i>G</i></sub><sub>u,</sub><sub><i>D</i></sub><sub>u</sub>(<i>G</i>,<i>D</i>)=<i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>u(</sub><sub><i>x</i></sub><sub>)</sub>lg(<i>D</i><sub>u</sub>(<i>x</i>))+<i>E</i><sub><i>z</i></sub><sub>～</sub><sub><i>p</i></sub><sub>zu(</sub><sub><i>z</i></sub><sub>)</sub>lg(1-<i>D</i><sub>u</sub>(<i>G</i><sub>u</sub>(<i>z</i>))),      (2)</p>
                </div>
                <div class="p1">
                    <p id="77"><i>V</i><sub><i>G</i></sub><sub>p,</sub><sub><i>D</i></sub><sub>p</sub>(<i>G</i>,<i>D</i>)=<i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>p(</sub><sub><i>x</i></sub><sub>)</sub>lg(<i>D</i><sub>p</sub>(<i>x</i>))+<i>E</i><sub><i>z</i></sub><sub>～</sub><sub><i>p</i></sub><sub>zp(</sub><sub><i>z</i></sub><sub>)</sub>lg(1-<i>D</i><sub>p</sub>(<i>G</i><sub>p</sub>(<i>z</i>))),      (3)</p>
                </div>
                <div class="p1">
                    <p id="79"><i>V</i><sub><i>G</i></sub><sub>p,</sub><sub><i>G</i></sub><sub>u,</sub><sub><i>D</i></sub><sub>pu</sub>(<i>G</i>,<i>D</i>)=<i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>p(</sub><sub><i>x</i></sub><sub>)</sub>lg(<i>D</i><sub>pu</sub>(<i>G</i><sub>p</sub>(<i>x</i>)))+<i>E</i><sub><i>z</i></sub><sub>～</sub><sub><i>p</i></sub><sub>u(</sub><sub><i>z</i></sub><sub>)</sub>lg(1-<i>D</i><sub>pu</sub>(<i>G</i><sub>u</sub>(<i>z</i>))).      (4)</p>
                </div>
                <div class="p1">
                    <p id="81">在此训练过程中,正样本判别器<i>D</i><sub>p</sub>、无标签样本判别器<i>D</i><sub>u</sub>、正样本/无标签样本判别器<i>D</i><sub>pu</sub>、正样本生成器<i>G</i><sub>p</sub>和无标签样本生成器<i>G</i><sub>u</sub>均由深度神经网络训练得到.整个模型的训练过程如算法1所示.</p>
                </div>
                <div class="p1">
                    <p id="82"><b>算法1</b>. puGAN模型训练算法.</p>
                </div>
                <div class="p1">
                    <p id="83">输入:正样本数据集和无标签样本数据集;</p>
                </div>
                <div class="p1">
                    <p id="84">输出:正样本/无标签样本判别器模型.</p>
                </div>
                <div class="area_img" id="195">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201909004_19500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="195">
                                <img alt="" src="Detail/GetImg?filename=images/JFYZ201909004_19501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="107">在此训练过程中,噪声普遍存在于正样本和无标签样本数据中,因此,本文分别对正样本和无标签样本引入了生成器与判别器,从而调整并学习得到2个样本的分布特征.随后,使用无标签样本生成器和正样本生成器分别生成伪无标签样本和伪正样本数据,并根据此数据进行分类学习,最终得到了POI定位的分类模型.</p>
                </div>
                <h4 class="anchor-tag" id="108" name="108"><b>2.2 理论分析</b></h4>
                <div class="p1">
                    <p id="109"><b>命题1</b>. 对于给定的<i>G</i><sub>u</sub>与<i>G</i><sub>p</sub>,最优化的分类器<i>D</i><sup>*</sup><sub>u</sub>,<i>D</i><sup>*</sup><sub>p</sub>,<i>D</i><sup>*</sup><sub>pu</sub>为</p>
                </div>
                <div class="p1">
                    <p id="110"><mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msubsup><mrow></mrow><mtext>u</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>,      (5)</p>
                </div>
                <div class="p1">
                    <p id="111"><mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msubsup><mrow></mrow><mtext>p</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>,      (6)</p>
                </div>
                <div class="p1">
                    <p id="112"><mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msubsup><mrow></mrow><mrow><mtext>p</mtext><mtext>u</mtext></mrow><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mtext>ϕ</mtext><msub><mrow></mrow><mtext>u</mtext></msub><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mtext>ϕ</mtext><msub><mrow></mrow><mtext>p</mtext></msub><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>.      (7)</p>
                </div>
                <div class="p1">
                    <p id="113">证明. 对于任何一个给定的生成器,分类器<i>D</i><sub>u</sub>,<i>D</i><sub>p</sub>,<i>D</i><sub>pu</sub>的估值函数方程为</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>V</mi><mo stretchy="false">(</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>x</mi></msub><mi>p</mi></mrow></mstyle><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>lg</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>d</mtext><mi>x</mi><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>z</mi></msub><mi>p</mi></mrow></mstyle><msub><mrow></mrow><mi>z</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mi>lg</mi><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>d</mtext><mi>z</mi><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>V</mi><mo stretchy="false">(</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>x</mi></msub><mi>p</mi></mrow></mstyle><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>lg</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>d</mtext><mi>x</mi><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>z</mi></msub><mi>p</mi></mrow></mstyle><msub><mrow></mrow><mi>z</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mi>lg</mi><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>d</mtext><mi>z</mi><mo>,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>V</mi><mo stretchy="false">(</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>x</mi></msub><mi>p</mi></mrow></mstyle><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>lg</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>d</mtext><mi>x</mi><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><mrow><msub><mo>∫</mo><mi>z</mi></msub><mi>p</mi></mrow></mstyle><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mi>lg</mi><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext>d</mtext><mi>z</mi><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">通过合并最优估值函数,可以得到结论:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>C</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mo stretchy="false">{</mo><mi>D</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">}</mo></mrow></munder><mspace width="0.25em" /><mi>V</mi><mo stretchy="false">(</mo><mi>G</mi><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><mtext> </mtext><mo stretchy="false">[</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mo stretchy="false">(</mo><mi>D</mi><msubsup><mrow></mrow><mtext>u</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>z</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><msubsup><mrow></mrow><mtext>u</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>β</mi><mtext> </mtext><mo stretchy="false">[</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mo stretchy="false">(</mo><mi>D</mi><msubsup><mrow></mrow><mtext>p</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>z</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><msubsup><mrow></mrow><mtext>p</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>γ</mi><mtext> </mtext><mo stretchy="false">[</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mo stretchy="false">(</mo><mi>D</mi><msubsup><mrow></mrow><mtext>p</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>G</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>D</mi><msubsup><mrow></mrow><mtext>u</mtext><mo>*</mo></msubsup><mo stretchy="false">(</mo><mi>G</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>α</mi><mtext> </mtext><mo stretchy="false">[</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>z</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>β</mi><mtext> </mtext><mo stretchy="false">[</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>z</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>γ</mi><mtext> </mtext><mo stretchy="false">[</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mtext>u</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mi>lg</mi></mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>-</mo><mi>p</mi><msub><mrow></mrow><mtext>p</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>u</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>+</mo><mi>p</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>p</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">]</mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mtext>证</mtext><mtext>毕</mtext><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118"><b>定理1</b>. 当且仅当<i>p</i><sub>u</sub>=<i>p</i><sub>gu</sub>,<i>p</i><sub>p</sub>=<i>p</i><sub>gp</sub>,且2<i>p</i><sub>p</sub>=ϕ<sub>u</sub><i>p</i><sub>gu</sub>+ϕ<sub>p</sub><i>p</i><sub>gp</sub>时,目标函数可以达到全局最小值.</p>
                </div>
                <div class="p1">
                    <p id="119">证明. 当满足上述条件时,可以得到:</p>
                </div>
                <div class="p1">
                    <p id="120"><i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>u(</sub><sub><i>x</i></sub><sub>)</sub>[-lg 2]+<i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>zu(</sub><sub><i>x</i></sub><sub>)</sub>[-lg 2]=-lg 4,      (12)</p>
                </div>
                <div class="p1">
                    <p id="121"><i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>p(</sub><sub><i>x</i></sub><sub>)</sub>[-lg 2]+<i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>zp(</sub><sub><i>x</i></sub><sub>)</sub>[-lg 2]=-lg 4,      (13)</p>
                </div>
                <div class="p1">
                    <p id="122"><i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>zp(</sub><sub><i>x</i></sub><sub>)</sub>[-lg 2]+<i>E</i><sub><i>x</i></sub><sub>～</sub><sub><i>p</i></sub><sub>zu(</sub><sub><i>x</i></sub><sub>)</sub>[-lg 2]=-lg 4.      (14)</p>
                </div>
                <div class="p1">
                    <p id="123">将式(12)～(14)带入式(11),可以得到:</p>
                </div>
                <div class="p1">
                    <p id="124"><i>C</i>(<i>G</i>)=<i>α</i> [-lg 4+<i>JS</i>(<i>p</i><sub>p</sub>‖<i>p</i><sub>gp</sub>)]+<i>β</i> [-lg 4+<i>JS</i>(<i>p</i><sub>u</sub>‖<i>p</i><sub>gu</sub>)]+<i>γ</i> [-lg 4+<i>JS</i>(<i>p</i><sub>gp</sub>‖<i>p</i><sub>gu</sub>)],      (15)</p>
                </div>
                <div class="p1">
                    <p id="127">其中,<i>JS</i>为分布之前的JS散度.</p>
                </div>
                <div class="p1">
                    <p id="128">所以,当满足条件<i>p</i><sub>u</sub>=<i>p</i><sub>gu</sub>,<i>p</i><sub>p</sub>=<i>p</i><sub>gp</sub>且2<i>p</i><sub>p</sub>=ϕ<sub>u</sub><i>p</i><sub>gu</sub>+ϕ<sub>p</sub><i>p</i><sub>gp</sub>时,可以取得目标函数的全局最优值. </p>
                </div>
                <div class="p1">
                    <p id="196">证毕．</p>
                </div>
                <h3 id="129" name="129" class="anchor-tag"><b>3 实例分析</b></h3>
                <h4 class="anchor-tag" id="130" name="130"><b>3.1 数据集</b></h4>
                <div class="p1">
                    <p id="131">本文使用的是脱敏后某高校校园无线网络接入日志数据,日志提供了对设备信息加密后的唯一标识及扫描得到的WiFi信息列表.具体的WiFi数据格式为</p>
                </div>
                <div class="p1">
                    <p id="132">〈<i>id</i><sub>1</sub>,<i>sig</i><sub>1</sub>|<i>id</i><sub>2</sub>,<i>sig</i><sub>2</sub>|…|<i>id</i><sub><i>m</i></sub>,<i>sig</i><sub><i>m</i></sub>〉,</p>
                </div>
                <div class="p1">
                    <p id="133">其中,<i>id</i><sub><i>i</i></sub>表示第<i>i</i>个发射WiFi信号设备的标识,<i>sig</i><sub><i>i</i></sub>为第<i>i</i>个WiFi所对应的信号强度.</p>
                </div>
                <div class="p1">
                    <p id="134">数据集共包含176 449条数据,覆盖了210个WiFi接入点和150个POI.其中,正样本15 888条,无标签样本160 561条.本文将有连接行为的数据标记为该WiFi接入点的正样本数据,并与对应的POI进行关联,将与其他POI关联的正样本数据作为该POI的负样本数据,将无连接行为的数据作为无标签数据.通常来说,一个POI可能对应多个WiFi接入点,同时每个WiFi接入点对应着多条正样本和无标签样本数据.通过对数据集进行初步分析,可以知道正样本大约只有总数据量的9%,而剩余的91%均为无标签样本.本文又对正样本数据进行深入统计和分析,得到了它的统计规律如图3所示:</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909004_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 正样本数据统计图" src="Detail/GetImg?filename=images/JFYZ201909004_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 正样本数据统计图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909004_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 The statistics of positive samples</p>

                </div>
                <div class="p1">
                    <p id="136">从图3可以发现, 47%的WiFi接入点拥有的正样本数在10条以下,而正样本数量在300条以上的WiFi接入点仅仅占比9%.由此可见,过半的WiFi接入点的正样本缺失情况严重.此情况在一个POI具有多个WiFi接入点的时候尤为明显.</p>
                </div>
                <div class="p1">
                    <p id="137">在实验中,由于采集得到的负样本在物理空间中通常偏于一侧,为了避免训练结果出现偏差,本文使用正样本和负样本作为评估集,使用正样本和无标签样本作为训练集.</p>
                </div>
                <div class="p1">
                    <p id="138">在训练过程中,由于数据本身特征维度相对较高,在样本偏少的情况下,传统的分类模型通常会因训练不足而难以得到理想的样本分布情况.为了证明puGAN模型的有效性,本文进行了2组对比实验:第1组实验对比了OC、SVM<citation id="187" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、神经网络(neural network, NN)<citation id="188" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>以及puGAN这4种模型的效果;第2组实验对比了GAN模型在不同使用条件下的效果.下面将分别阐述这2组实验.</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139"><b>3.2 传统模型与puGAN模型对比</b></h4>
                <div class="p1">
                    <p id="140">实验通过调整模型不同的超参数进行交叉验证训练,得到了不同准确率下对应的数据召回率.根据此准确率和召回率,使用ROC曲线来对模型效果进行比较与分析.如图4所示是不同模型在实验数据集上的表现.</p>
                </div>
                <div class="p1">
                    <p id="141">图4中,横轴表示模型的召回率,纵轴表示模型的准确率,ROC面积越大表示模型效果越好.</p>
                </div>
                <div class="p1">
                    <p id="142">从图4可以看出,单类模型的ROC面积为0.761,在准确率为80%时召回率不足60%,效果明显低于其他的几类模型.SVM与神经网络(NN)模型在ROC曲线的评估上效果相当,当准确率为80%时召回率均为77%左右.而puGAN模型在准确率为80%时召回率达到了85%左右,对应的ROC面积也明显高于其他模型.</p>
                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909004_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 OC,SVM,NN和puGAN的ROC曲线对比图" src="Detail/GetImg?filename=images/JFYZ201909004_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 OC,SVM,NN和puGAN的ROC曲线对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909004_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Comparison of ROC curves among 
 OC, SVM, NN and puGAN</p>

                </div>
                <div class="p1">
                    <p id="144">此外,我们还观察了这4种模型的训练误差和测试误差随迭代次数增加的变化,这种变化反应模型的拟合情况,如图5所示:</p>
                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909004_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 OC,SVM,NN和puGAN训练误差和测试误差分析对比图" src="Detail/GetImg?filename=images/JFYZ201909004_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 OC,SVM,NN和puGAN训练误差和测试误差分析对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909004_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Training error and Testing error among OC, SVM, NN and puGAN</p>

                </div>
                <div class="p1">
                    <p id="146">由图5可知,单类模型明显存在着欠拟合的情况,经过多轮的迭代,训练误差始终维持在26%左右,整体效果较差.SVM和神经网络的表现明显优于单类模型,训练误差维持在21%左右.但随着迭代次数的增加,由于神经网络结构复杂,它的测试误差不断上升,出现了过拟合的情况.puGAN模型在训练初始阶段,收敛速度会略慢于SVM以及神经网络,但在最终效果却明显优于上述2类模型,且模型表现稳定,训练误差和测试误差均维持在15%左右.</p>
                </div>
                <div class="p1">
                    <p id="147">综上,由于单类模型在训练过程中只利用了正样本进行学习,而忽略了大量的无标签样本,所以整体实验效果均不佳.SVM与神经网络均使用了正样本和无标签样本进行二分类学习,SVM模型结构较神经网络简单,因此收敛速度较快,在准确率和召回率上二者差别不大.puGAN对正样本和无标签样本进行学习,生成伪正样本来弥补数据不足的问题,同时生成伪无标签样本来提高判别器对正样本的识别能力.因此,从ROC曲线以及模型拟合情况来看,puGAN的效果明显优于传统的机器学习模型.</p>
                </div>
                <h4 class="anchor-tag" id="148" name="148"><b>3.3 3种GAN模型对比</b></h4>
                <div class="p1">
                    <p id="149">第2组实验中,我们对比分析了puGAN模型与另外2种未校正模型在准确率、召回率以及训练误差、测试误差等指标上的表现情况.其中未校正的模型包括未对正样本建模(本文称GAN1)以及未对无标签样本建模(本文称GAN2)这2种情况.</p>
                </div>
                <div class="p1">
                    <p id="150">如图6所示,puGAN模型的ROC面积略高于GAN1和GAN2这2种未校正的模型.在这3种模型中,GAN1模型面积最小,其值只有0.835.该模型由于未能够对正样本进行分布上的学习,使得训练得到的模型在准确率以及召回率上的表现不佳,得到的分类面也偏于无标签样本数据一方.GAN2模型虽然也受到了训练样本不均匀的影响,但是在准确率和召回率上的表现却略好于GAN1模型,原因是GAN2模型对正样本进行了建模和重采样,使其受到的正样本数据不足的影响略低于GAN1模型.</p>
                </div>
                <div class="p1">
                    <p id="151">此外,我们也同样观察了上述3种模型训练误差和测试误差的变化,并对它们的拟合情况进行了分析.如图7所示为3种模型的训练误差以及测试误差随着迭代次数增加的变化情况.从图7中可以看出,GAN1模型在训练初期存在过拟合的情况,但随着迭代次数的增加,过拟合逐渐缓解,效果趋于稳定.GAN2模型在训练过程中整体效果较为稳定,但是误差较大,始终维持在20%以上.而puGAN模型最终训练误差和测试误均在15%左右且效果稳定.</p>
                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909004_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 GAN1,GAN2和puGAN的ROC曲线图" src="Detail/GetImg?filename=images/JFYZ201909004_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 GAN1,GAN2和puGAN的ROC曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909004_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Comparison of ROC curves among 
 GAN1, GAN2 and puGAN</p>

                </div>
                <div class="area_img" id="153">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201909004_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 GAN1,GAN2和puGAN训练误差和测试误差分析对比图" src="Detail/GetImg?filename=images/JFYZ201909004_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 GAN1,GAN2和puGAN训练误差和测试误差分析对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201909004_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Training error and Testing error among GAN1, GAN2 and puGAN</p>

                </div>
                <div class="p1">
                    <p id="154">综上所述,在GAN的3类模型中,puGAN模型在ROC面积以及稳定性上表现更为突出.</p>
                </div>
                <h3 id="155" name="155" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="156">本文讨论了puGAN模型在POI定位中的应用.实验表明,该模型通过对正样本和无标签样本进行建模和生成,提升了POI定位的准确率和召回率,从而有效解决了数据样本不足以及半监督学习中噪声过大的问题.</p>
                </div>
                <div class="p1">
                    <p id="157">实验还表明,该模型能够避免复杂模型所带来的过拟合问题,且具有更好的稳定性.此研究为现有的POI定位系统提供了新的指导意义.</p>
                </div>
                <div class="p1">
                    <p id="158">虽然puGAN模型在准确率、召回率和稳定性上表现优秀,但是却存在迭代速度较慢的缺点.在大数据的背景下,提升模型训练速度也早已成为了一个重要的课题.在今后的研究中,我们会改进训练过程中最优化的方法来提升模型训练的效率.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201604004&amp;v=MzA0NjBGckNVUkxPZVplUnNGeS9uVjczTEx5dlNkTEc0SDlmTXE0OUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Gao Rong,Li Jing,Du Bo,et al.A synthetic recommendation model for point-of-interest on location-based social networks:Exploiting contextual information and review[J].Journal of Computer Research and Development,2016,53(4):752- 763 (in Chinese)(高榕,李晶,杜博,等.一种融合情景和评论信息的位置社交网络兴趣点推荐模型[J].计算机研究与发展,2016,53(4):752- 763)
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Where you like to go next:Successive point-of-interest recommendation">

                                <b>[2]</b>Chen Cheng,Yang Haiqin,Lyu M R,et al.Where you like to go next:Successive point-of-interest recommendation[C] //Proc of the 23rd Int Joint Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2013:2605- 2611
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Content-aware point of interest recommendation on location-based social networks">

                                <b>[3]</b>Gao Huiji,Tang Jiliang,Hu Xia,et al.Content-aware point of interest recommendation on location-based social networks[C] //Proc of the 29th AAAI Conf on Artificial Intelligence.Menlo Park,CA:AAAI,2015:1721- 1727
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adapting to user interest drift for POI recommendation">

                                <b>[4]</b>Yin Hongzhi,Zhou Xiaofang,Cui Bin,et al.Adapting to user interest drift for POI recommendation[J].IEEE Transactions on Knowledge &amp; Data Engineering,2016,28(10):2566- 2581
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fundamental limits of RSS fingerprinting based indoor localization">

                                <b>[5]</b>Wen Yutian,Tian Xiaohua,Wang Xinbing,et al.Fundamental limits of RSS fingerprinting based indoor localization[C] //Proc of the IEEE Conf on Computer Communications.Piscataway,NJ:IEEE,2015:2479- 2487
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PRIMAL:Page rank based indoor mapping and localization using gene sequenced unlabeled WLAN received signal strength">

                                <b>[6]</b>Zhou Mu,Zhang Qiao,Xu Kunjie,et al.PRIMAL:Page rank-based indoor mapping and localization using gene-sequenced unlabeled WLAN received signal strength[J].Sensors,2015,15(10):24791- 24817
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD9180E7E349065F745924E2D7829D546B&amp;v=MTY5NTRJVzR6MTVQWDJXcXhvM2NNYVJRYnp0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TnBodzdxN3dxcz1OajNhYXJxNUZ0RzVxUHBHWU9JUENubFB5Qg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>Zhang Wei,Hua Xianghong,Yu Kegen,et al.Radius based domain clustering for WiFi indoor positioning[J].Sensor Review,2017,37(1):54- 60
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Point of interest awareness using indoor positioning with a mobile phone[C/OL]">

                                <b>[8]</b>Matos P P D,Afonso A P,Carmo M B.Point of interest awareness using indoor positioning with a mobile phone[C/OL] //Proc of the 1st Int Conf on Pervasive and Embedded Computing and Communication Systems.2011 [2018-12-19].https://www.researchgate.net/publication/221156937_Point_of_Interest_Awareness_using_Indoor_Positioning_with_a_Mobile_Phone
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=WiFi fingerprinting signal strength error modeling for short distances">

                                <b>[9]</b>Moghtadaiee V,Dempster A G.WiFi fingerprinting signal strength error modeling for short distances[C] //Proc of the Int Conf on Indoor Positioning and Indoor Navigation.Piscataway,NJ:IEEE,2013:1- 6
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning classifiers from only positive and unlabeled data">

                                <b>[10]</b>Elkan C,Noto K.Learning classifiers from only positive and unlabeled data[C] //Proc of the 14th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining.New York:ACM,2008:213- 220
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analysis of learning from positive and unlabeled data">

                                <b>[11]</b>Du Plessis M C,Niu Gang,Sugiyama M.Analysis of learning from positive and unlabeled data[C] //Proc of the 27th Int Conf on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014:703- 711
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-Supervised Learning">

                                <b>[12]</b>Chapelle O,Lkopf B S,Zien A.Semi-Supervised Learning[M].Cambridge,MA:MIT Press,2006
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201503012&amp;v=MTM0MjhaZVJzRnkvblY3M0xMeXZTZExHNEg5VE1ySTlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Ren Yafeng,Ji Donghong,Zhang Hongbin,et al.Deceptive reviews detection based on positive and unlabeled learning[J].Journal of Computer Research and Development,2015,52(3):639- 648 (in Chinese)(任亚峰,姬东鸿,张红斌,等.基于PU学习算法的虚假评论识别研究[J].计算机研究与发展,2015,52(3):639- 648)
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative Adversarial Nets">

                                <b>[14]</b>Goodfellow I J,Pouget-Abadie J,Mirza M,et al.Generative adversarial nets[C] //Proc of the 27th Int Conf on Neural Information Processing Systems.Cambridge,MA:MIT Press,2014:2672- 2680
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved techniques for training gans">

                                <b>[15]</b>Salimans T,Goodfellow I,Zaremba W,et al.Improved techniques for training gans[J].arXiv preprint,arXiv:1606.03498,2016
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-supervised knowledge transfer for deep learning from private training data">

                                <b>[16]</b>Papernot N,Abadi M,Erlingsson U,et al.Semi-supervised knowledge transfer for deep learning from private training data[J].arXiv preprint,arXiv:1610.05755,2016
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-supervised learning with generative adversarial networks">

                                <b>[17]</b>Odena A.Semi-supervised learning with generative adversarial networks[J].arXiv preprint,arXiv:1606.01583,2016
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wasserstein gan">

                                <b>[18]</b>Arjovsky M,Chintala S,Bottou L.Wasserstein gan[J].arXiv preprint,arXiv:1701.07875,2017
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122500448289&amp;v=MDE0MzBmT2ZiSzlIOVBPcW85RllPOEhEblF3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTDNJSjF3UWFCRT1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Mordelet F,Vert J P.A bagging SVM to learn from positive and unlabeled examples[J].Pattern Recognition Letters,2010,37(1):201- 209
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-layer perceptron (MLP) neural network technique for offline handwritten gurmukhi character recognition">

                                <b>[20]</b>Singh G,Sachan M.Multi-layer perceptron (MLP) neural network technique for offline handwritten gurmukhi character recognition[C] //Proc of the IEEE Int Conf on Computational Intelligence and Computing Research.Piscataway,NJ:IEEE,2015:1- 5
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201909004" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201909004&amp;v=MjA0MzdCdEdGckNVUkxPZVplUnNGeS9uVjczSUx5dlNkTEc0SDlqTXBvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9QejlMZ29raFZNcXpTKzl4VT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

