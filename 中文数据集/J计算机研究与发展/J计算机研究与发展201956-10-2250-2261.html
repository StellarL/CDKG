

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637127135504832500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201910020%26RESULT%3d1%26SIGN%3daUlWCiqm4BGOWu4s6G0ngX7qDH8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201910020&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201910020&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201910020&amp;v=MDAwNDFyQ1VSTE9lWmVSc0Z5emhXNy9KTHl2U2RMRzRIOWpOcjQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#87" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#90" data-title="&lt;b&gt;1.1 JPEG图像深度学习隐写分析处理过程&lt;/b&gt;"><b>1.1 JPEG图像深度学习隐写分析处理过程</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;1.2 深度学习隐写分析辅助信息产生方式&lt;/b&gt;"><b>1.2 深度学习隐写分析辅助信息产生方式</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#116" data-title="&lt;b&gt;2 JPEG图像隐写分析参照图像生成模型&lt;/b&gt; "><b>2 JPEG图像隐写分析参照图像生成模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#119" data-title="&lt;b&gt;2.1 JPEG图像隐写分析模型的关系&lt;/b&gt;"><b>2.1 JPEG图像隐写分析模型的关系</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;2.2 所提出参照图像生成模型结构&lt;/b&gt;"><b>2.2 所提出参照图像生成模型结构</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;2.3 所提出参照图像生成模型训练方式&lt;/b&gt;"><b>2.3 所提出参照图像生成模型训练方式</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;2.4 参照图像与隐写分析模型的结合方式&lt;/b&gt;"><b>2.4 参照图像与隐写分析模型的结合方式</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#149" data-title="&lt;b&gt;3 实验与分析&lt;/b&gt; "><b>3 实验与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#151" data-title="&lt;b&gt;3.1 数据集合&lt;/b&gt;"><b>3.1 数据集合</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;3.2 模型参数设置&lt;/b&gt;"><b>3.2 模型参数设置</b></a></li>
                                                <li><a href="#161" data-title="&lt;b&gt;3.3 模型训练策略与结合方式的选择&lt;/b&gt;"><b>3.3 模型训练策略与结合方式的选择</b></a></li>
                                                <li><a href="#167" data-title="&lt;b&gt;3.4 对比实验与结果分析&lt;/b&gt;"><b>3.4 对比实验与结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#181" data-title="&lt;b&gt;4 总  结&lt;/b&gt; "><b>4 总  结</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="图1 隐写与隐写分析">图1 隐写与隐写分析</a></li>
                                                <li><a href="#115" data-title="图2 一张图像及其对应的修改概率图">图2 一张图像及其对应的修改概率图</a></li>
                                                <li><a href="#122" data-title="图3 本文方法与隐写分析模型的关系">图3 本文方法与隐写分析模型的关系</a></li>
                                                <li><a href="#127" data-title="图4 JPEG图像隐写分析参照图像生成模型结构图">图4 JPEG图像隐写分析参照图像生成模型结构图</a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表1 参照图像生成模型的参数细节&lt;/b&gt;"><b>表1 参照图像生成模型的参数细节</b></a></li>
                                                <li><a href="#133" data-title="图5 Pre-training训练策略">图5 Pre-training训练策略</a></li>
                                                <li><a href="#142" data-title="图6 Together训练策略">图6 Together训练策略</a></li>
                                                <li><a href="#146" data-title="图7 参照图像输入方式">图7 参照图像输入方式</a></li>
                                                <li><a href="#153" data-title="图8 实验数据产生方式">图8 实验数据产生方式</a></li>
                                                <li><a href="#160" data-title="图9 对比实验数据集合构成">图9 对比实验数据集合构成</a></li>
                                                <li><a href="#164" data-title="&lt;b&gt;表2 不同训练策略、结合方式在验证数据集的检测效果&lt;/b&gt;"><b>表2 不同训练策略、结合方式在验证数据集的检测效果</b></a></li>
                                                <li><a href="#165" data-title="图10 训练策略、结合方式对验证结果的影响">图10 训练策略、结合方式对验证结果的影响</a></li>
                                                <li><a href="#170" data-title="图11 J-XuNet与Reference-J-XuNet对于J-UNIWARD隐写算法的检测准确率对比">图11 J-XuNet与Reference-J-XuNet对于J-UNIWARD隐写算法的检测准确率......</a></li>
                                                <li><a href="#171" data-title="图12 J-XuNet与Reference-J-XuNet对于JC-UED隐写算法的检测准确率对比">图12 J-XuNet与Reference-J-XuNet对于JC-UED隐写算法的检测准确率对比</a></li>
                                                <li><a href="#172" data-title="&lt;b&gt;表3 本文方法与对比算法对于不同隐写算法的检测结果&lt;/b&gt;"><b>表3 本文方法与对比算法对于不同隐写算法的检测结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title="Wang Lina,Zhang Huanguo,Ye Dengpan.Information Hiding Technology and Application[M].Wuhan:Wuhan University Press,2003 (in Chinese)(王丽娜,张焕国,叶登攀.信息隐藏技术与应用[M].武汉:武汉大学出版社,2003)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007307038269999&amp;v=MTg0NjduM3hFOWZidm5LcmlmWnU5dUZDdm5VN3ZNS0Y0VlZWMjdHYkM0R2RIUHA0MURiZUlHQlJNOHp4VVNtRGQ5U0g3&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Wang Lina,Zhang Huanguo,Ye Dengpan.Information Hiding Technology and Application[M].Wuhan:Wuhan University Press,2003 (in Chinese)(王丽娜,张焕国,叶登攀.信息隐藏技术与应用[M].武汉:武汉大学出版社,2003)
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title="Zhang Zhan,Liu Guangjie,Dai Yuewei,et al.A self-adaptive image steganography algorithm based on cover-coding and Markov model[J].Journal of Computer Research and Development,2012,49(8):1668- 1675 (in Chinese)(张湛,刘光杰,戴跃伟,等.基于隐写编码和Markov模型的自适应图像隐写算法[J].计算机研究与发展,2012,49(8):1668- 1675)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201208011&amp;v=MDYzMzR6cXFCdEdGckNVUkxPZVplUnNGeXpoVzcvSkx5dlNkTEc0SDlQTXA0OUVaWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Zhang Zhan,Liu Guangjie,Dai Yuewei,et al.A self-adaptive image steganography algorithm based on cover-coding and Markov model[J].Journal of Computer Research and Development,2012,49(8):1668- 1675 (in Chinese)(张湛,刘光杰,戴跃伟,等.基于隐写编码和Markov模型的自适应图像隐写算法[J].计算机研究与发展,2012,49(8):1668- 1675)
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title="Han Tao,Zhu Yuefei,Lin Sisi,et al.Modified matrix encoding based on the spatial distortion model and its improvement[J].Journal of Computer Research and Development,2014,51(7):1467- 1475 (in Chinese)(韩涛,祝跃飞,林斯思,等.基于空域失真模型的修正矩阵编码及其改进[J].计算机研究与发展,2014,51(7):1467- 1475)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201407010&amp;v=MjY1MDBGckNVUkxPZVplUnNGeXpoVzcvSkx5dlNkTEc0SDlYTXFJOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Han Tao,Zhu Yuefei,Lin Sisi,et al.Modified matrix encoding based on the spatial distortion model and its improvement[J].Journal of Computer Research and Development,2014,51(7):1467- 1475 (in Chinese)(韩涛,祝跃飞,林斯思,等.基于空域失真模型的修正矩阵编码及其改进[J].计算机研究与发展,2014,51(7):1467- 1475)
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title="Bao Zhenkun,Zhang Weiming,Cheng Sen,et al.&#177;1 Steganographic codes by applying syndrome-trellis codes to dynamic distortion model in pixel chain[J].Journal of Computer Research and Development,2014,51(8):1739- 1747 (in Chinese)(包震坤,张卫明,程森,等.基于像素链动态失真和校验格码的&#177;1隐写编码[J].计算机研究与发展,2014,51(8):1739- 1747)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201408010&amp;v=MTkxNjlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5emhXNy9KTHl2U2RMRzRIOVhNcDQ5RVpJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        Bao Zhenkun,Zhang Weiming,Cheng Sen,et al.&#177;1 Steganographic codes by applying syndrome-trellis codes to dynamic distortion model in pixel chain[J].Journal of Computer Research and Development,2014,51(8):1739- 1747 (in Chinese)(包震坤,张卫明,程森,等.基于像素链动态失真和校验格码的&#177;1隐写编码[J].计算机研究与发展,2014,51(8):1739- 1747)
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title="Zhao Xianfeng,Zhang Hong.Principles and Techniques of Seganography[M].Beijing:Science Press,2018 (in Chinese)(赵险峰,张弘.隐写学原理与技术[M].北京:科学出版社,2018)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030591173000&amp;v=MTU3MjRLcmlmWnU5dUZDdm5VN3ZNS0Y0VlhGcXpHYk83SHRURnJvNUNaK3NQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZu&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Zhao Xianfeng,Zhang Hong.Principles and Techniques of Seganography[M].Beijing:Science Press,2018 (in Chinese)(赵险峰,张弘.隐写学原理与技术[M].北京:科学出版社,2018)
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title="Filler T,Judas J,Fridrich J,et al.Minimizing additive distortion in steganography using syndrome-trellis codes[J].IEEE Transactions on Information Forensics and Security,2011,6(3):920- 935" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Minimizing Additive Distortion in Steganography Using Syndrome-Trellis Codes">
                                        <b>[6]</b>
                                        Filler T,Judas J,Fridrich J,et al.Minimizing additive distortion in steganography using syndrome-trellis codes[J].IEEE Transactions on Information Forensics and Security,2011,6(3):920- 935
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title="Pevn&#253; T,Filler T,Bas P.Using high-dimensional image models to perform highly undetectable steganography[G] // LNCS 6387:Proc of the 12th Int Conf on Information Hiding.Berlin:Springer,2010:161- 171" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using high-dimensional image models to perform highly undetectable steganography">
                                        <b>[7]</b>
                                        Pevn&#253; T,Filler T,Bas P.Using high-dimensional image models to perform highly undetectable steganography[G] // LNCS 6387:Proc of the 12th Int Conf on Information Hiding.Berlin:Springer,2010:161- 171
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title="Holub V,Fridrich J.Designing steganographic distortion using directional filters[C] //Proc of the 2012 IEEE Int Workshop on Information Forensics and Security.Piscataway,NJ:IEEE,2012:234- 239" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Designing Steganographic Distortion Using Directional Filters">
                                        <b>[8]</b>
                                        Holub V,Fridrich J.Designing steganographic distortion using directional filters[C] //Proc of the 2012 IEEE Int Workshop on Information Forensics and Security.Piscataway,NJ:IEEE,2012:234- 239
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title="Guo Linjie,Ni Jiangqun,Shi Yunqing.Uniform embedding for efficient JPEG steganography[J].IEEE Transactions on Information Forensics and Security,2014,9(5):814- 825" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Uniform embedding for efficient JPEG steganography">
                                        <b>[9]</b>
                                        Guo Linjie,Ni Jiangqun,Shi Yunqing.Uniform embedding for efficient JPEG steganography[J].IEEE Transactions on Information Forensics and Security,2014,9(5):814- 825
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title="Holub V,Fridrich J,Denemark T.Universal distortion function for steganography in an arbitrary domain[OL].[2019-06-01].https://doi.org/10.1186/1687-417X-2014-1" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Universal distortion function for steganography in an arbitrary domain[OL]">
                                        <b>[10]</b>
                                        Holub V,Fridrich J,Denemark T.Universal distortion function for steganography in an arbitrary domain[OL].[2019-06-01].https://doi.org/10.1186/1687-417X-2014-1
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title="Fridrich J,Kodovsky J.Multivariate Gaussian model for designing additive distortion for steganography[C] //Proc of the 2013 IEEE ICASSP.Piscataway,NJ:IEEE,2016:26- 31" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multivariate Gaussian model for designing additive distortion for steganography">
                                        <b>[11]</b>
                                        Fridrich J,Kodovsky J.Multivariate Gaussian model for designing additive distortion for steganography[C] //Proc of the 2013 IEEE ICASSP.Piscataway,NJ:IEEE,2016:26- 31
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title="Li Bin,Wang Ming,Huang Jiwu,et al.A new cost function for spatial image steganography[C] //Proc of the 2014 IEEE Int Conf on Image Processing (ICIP).Piscataway,NJ:IEEE,2014:4206- 4210" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new cost function for spatial image steganography">
                                        <b>[12]</b>
                                        Li Bin,Wang Ming,Huang Jiwu,et al.A new cost function for spatial image steganography[C] //Proc of the 2014 IEEE Int Conf on Image Processing (ICIP).Piscataway,NJ:IEEE,2014:4206- 4210
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title="Sedighi V,Cogranne R,Fridrich J.Content-adaptive steganography by minimizing statistical detectability[J].IEEE Transactions on Information Forensics and Security,2016,11(2):221- 234" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Content-adaptive steganography by minimizing statistical detectability">
                                        <b>[13]</b>
                                        Sedighi V,Cogranne R,Fridrich J.Content-adaptive steganography by minimizing statistical detectability[J].IEEE Transactions on Information Forensics and Security,2016,11(2):221- 234
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title="Wang Lina,Wang Kaige,Xu Yibo,et al.An evaluation of carrier security for image steganography based on residual co-occurrence probability[J].Journal of Computer Research and Development,2018,55(12):2664- 2673 (in Chinese)(王丽娜,王凯歌,徐一波,等.基于残差共生概率的隐写图像载体安全性评价[J].计算机研究与发展,2018,55(12):2664- 2673)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201812008&amp;v=MTE0NzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJzRnl6aFc3L0pMeXZTZExHNEg5bk5yWTlGYkk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Wang Lina,Wang Kaige,Xu Yibo,et al.An evaluation of carrier security for image steganography based on residual co-occurrence probability[J].Journal of Computer Research and Development,2018,55(12):2664- 2673 (in Chinese)(王丽娜,王凯歌,徐一波,等.基于残差共生概率的隐写图像载体安全性评价[J].计算机研究与发展,2018,55(12):2664- 2673)
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title="Pevny T,Bas P,Fridrich J.Steganalysis by subtractive pixel adjacency matrix[J].IEEE Transactions on Information Forensics and Security,2010,5(2):215- 224" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Steganalysis by Subtractive Pixel Adjacency Matrix">
                                        <b>[15]</b>
                                        Pevny T,Bas P,Fridrich J.Steganalysis by subtractive pixel adjacency matrix[J].IEEE Transactions on Information Forensics and Security,2010,5(2):215- 224
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title="Fridrich J,Kodovsky J.Rich models for steganalysis of digital images[J].IEEE Transactions on Information Forensics and Security,2012,7(3):868- 882" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rich Models for Steganalysis of Digital Images">
                                        <b>[16]</b>
                                        Fridrich J,Kodovsky J.Rich models for steganalysis of digital images[J].IEEE Transactions on Information Forensics and Security,2012,7(3):868- 882
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title="Holub V,Fridrich J.Random projections of residuals for digital image steganalysis[J].IEEE Transactions on Information Forensics and Security,2013,8(12):1996- 2006" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Random projections of residuals for digital image steganalysis">
                                        <b>[17]</b>
                                        Holub V,Fridrich J.Random projections of residuals for digital image steganalysis[J].IEEE Transactions on Information Forensics and Security,2013,8(12):1996- 2006
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title="Denemark T,Sedighi V,Holub V,et al.Selection-channel-aware rich model for steganalysis of digital images[C] //Proc of the 2014 IEEE Int Workshop on Information Forensics and Security (WIFS).Piscataway,NJ:IEEE,2014:48- 53" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Selection-channel-aware rich model for Steganalysis of digital images">
                                        <b>[18]</b>
                                        Denemark T,Sedighi V,Holub V,et al.Selection-channel-aware rich model for steganalysis of digital images[C] //Proc of the 2014 IEEE Int Workshop on Information Forensics and Security (WIFS).Piscataway,NJ:IEEE,2014:48- 53
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title="Tang Weixuan,Li Haodong,Luo Weiqi,et al.Adaptive steganalysis based on embedding probabilities of pixels[J].IEEE Transactions on Information Forensics and Security,2016,11(4):734- 745" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Steganalysis Based on Embedding Probabilities of Pixels">
                                        <b>[19]</b>
                                        Tang Weixuan,Li Haodong,Luo Weiqi,et al.Adaptive steganalysis based on embedding probabilities of pixels[J].IEEE Transactions on Information Forensics and Security,2016,11(4):734- 745
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title="Tan Shunquan,Li Bin.Stacked convolutional auto-encoders for steganalysis of digital images[C/L] //Proc of the 2014 Signal and Information Processing Association Annual Summit and Conf.Piscataway,NJ:IEEE,2014.[2019-06-01].https://ieeexplore.ieee.org/document/7041565" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked convolutional auto-encoders for steganalysis of digital images">
                                        <b>[20]</b>
                                        Tan Shunquan,Li Bin.Stacked convolutional auto-encoders for steganalysis of digital images[C/L] //Proc of the 2014 Signal and Information Processing Association Annual Summit and Conf.Piscataway,NJ:IEEE,2014.[2019-06-01].https://ieeexplore.ieee.org/document/7041565
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title="Qian Yinlong,Dong Jing,Wang Wei,et al.Deep learning for steganalysis via convolutional neural networks[G] //LNCS 9409:Proc of the 2015 SPIE Electronic Imaging.Berlin:Springer,2015" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning for steganalysis via convolutional neural networks">
                                        <b>[21]</b>
                                        Qian Yinlong,Dong Jing,Wang Wei,et al.Deep learning for steganalysis via convolutional neural networks[G] //LNCS 9409:Proc of the 2015 SPIE Electronic Imaging.Berlin:Springer,2015
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title="Xu Guanshuo,Wu Hanzhou,Shi Yunqing.Structural design of convolutional neural networks for steganalysis[J].IEEE Signal Processing Letters,2016,23(5):708- 712" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Structural Design of Convolutional Neural Networks for Steganalysis">
                                        <b>[22]</b>
                                        Xu Guanshuo,Wu Hanzhou,Shi Yunqing.Structural design of convolutional neural networks for steganalysis[J].IEEE Signal Processing Letters,2016,23(5):708- 712
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title="Yang Jianhua,Liu Kai,Kang Xiangui,et al.Steganalysis based on awareness of selection-channel and deep learning[C] // Proc of the 16th Int Workshop on Digital Forensics and Watermarking.Berlin:Springer,2017:263- 272" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Steganalysis based on awareness of selection-channel and deep learning">
                                        <b>[23]</b>
                                        Yang Jianhua,Liu Kai,Kang Xiangui,et al.Steganalysis based on awareness of selection-channel and deep learning[C] // Proc of the 16th Int Workshop on Digital Forensics and Watermarking.Berlin:Springer,2017:263- 272
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title="Ye Jian,Ni Jiangqun,Yi Yang.Deep learning hierarchical representations for image steganalysis[J].IEEE Transactions on Information Forensics and Security,2017,12(11):2545- 2557" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Learning Hierarchical Representations for Image Steganalysis">
                                        <b>[24]</b>
                                        Ye Jian,Ni Jiangqun,Yi Yang.Deep learning hierarchical representations for image steganalysis[J].IEEE Transactions on Information Forensics and Security,2017,12(11):2545- 2557
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title="Boroumand M,Chen M,Fridrich J,et al.Deep residual network for steganalysis of digital images[J].IEEE Transactions on Information Forensics and Security,2019,14(5):1181- 1193" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep residual network for steganalysis of digital images">
                                        <b>[25]</b>
                                        Boroumand M,Chen M,Fridrich J,et al.Deep residual network for steganalysis of digital images[J].IEEE Transactions on Information Forensics and Security,2019,14(5):1181- 1193
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title="Xu Guanshuo.Deep convolutional neural network to detect J-UNIWARD[C] //Proc of the 5th ACM Workshop on Information Hiding and Multimedia Security.New York:ACM,2017:67- 73" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep convolutional neural network to detect J-UNIWARD">
                                        <b>[26]</b>
                                        Xu Guanshuo.Deep convolutional neural network to detect J-UNIWARD[C] //Proc of the 5th ACM Workshop on Information Hiding and Multimedia Security.New York:ACM,2017:67- 73
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title="Chen Mo,Sedighi V,Boroumand M,et al.JPEG-phaseaware convolutional neural network for steganalysis of JPEG images[C] // Proc of the 5th ACM Workshop on Information Hiding and Multimedia Security.New York:ACM,2017,75- 84" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=JPEG-phase-aware convolutional neural network for steganalysis of JPEG images">
                                        <b>[27]</b>
                                        Chen Mo,Sedighi V,Boroumand M,et al.JPEG-phaseaware convolutional neural network for steganalysis of JPEG images[C] // Proc of the 5th ACM Workshop on Information Hiding and Multimedia Security.New York:ACM,2017,75- 84
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_28" title="Zeng Jishen,Tan Shunquan,Li Bin,et al.Large-scale JPEG image steganalysis using hybrid deep-learning framework[J].IEEE Transactions on Information Forensics and Security,2017,13(5):1200- 1214" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large-scale JPEG image steganalysis using hybrid deep-learning framework">
                                        <b>[28]</b>
                                        Zeng Jishen,Tan Shunquan,Li Bin,et al.Large-scale JPEG image steganalysis using hybrid deep-learning framework[J].IEEE Transactions on Information Forensics and Security,2017,13(5):1200- 1214
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_29" title="Yang Jianhua,Shi Yunqing,Wong E K,et al.JPEG steganalysis based on DenseNet[J].arXiv preprint arXiv:1711.09335,2017" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=JPEG steganalysis based on DenseNet">
                                        <b>[29]</b>
                                        Yang Jianhua,Shi Yunqing,Wong E K,et al.JPEG steganalysis based on DenseNet[J].arXiv preprint arXiv:1711.09335,2017
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_30" title="Huang Gao,Liu Zhuang,Maaten L V D,et al.Densely connected convolutional networks[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition (CVPR).Piscataway,NJ:IEEE,2017:2261- 2269" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Densely connected convolutional networks">
                                        <b>[30]</b>
                                        Huang Gao,Liu Zhuang,Maaten L V D,et al.Densely connected convolutional networks[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition (CVPR).Piscataway,NJ:IEEE,2017:2261- 2269
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_31" title="Ioffe S,Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C] //Proc of the 32nd Int Conf on Machine Leaning -Volume 37.New York:ACM,2015:448- 456" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">
                                        <b>[31]</b>
                                        Ioffe S,Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C] //Proc of the 32nd Int Conf on Machine Leaning -Volume 37.New York:ACM,2015:448- 456
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_32" title="Ronneberger O,Fischer P,Brox T,et al.U-Net:Convolutional networks for biomedical image segmentation[G] //LNCS 9351:Proc of MICCAI 2015.Berlin:Springer,2015:234- 241" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=U-Net:Convolutional Networks for Biomedical Image Segmentation">
                                        <b>[32]</b>
                                        Ronneberger O,Fischer P,Brox T,et al.U-Net:Convolutional networks for biomedical image segmentation[G] //LNCS 9351:Proc of MICCAI 2015.Berlin:Springer,2015:234- 241
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_33" title="Bas P,Filler T,Pevn&#253; T.“Break our steganographic system”:The ins and outs of organizing BOSS[G] //LNCS 9351:Proc of MICCAI 2015.Berlin:Springer,2015:234- 241" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Break our steganographic system&amp;quot;:The ins and outs of organizing BOSS">
                                        <b>[33]</b>
                                        Bas P,Filler T,Pevn&#253; T.“Break our steganographic system”:The ins and outs of organizing BOSS[G] //LNCS 9351:Proc of MICCAI 2015.Berlin:Springer,2015:234- 241
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_34" title="Kingma D P,Ba J.Adam:A method for stochastic optimization[J].arXiv preprint arXiv:1412.6980,2014&lt;image href=&quot;images/JFYZ201910020_071.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Ren Weixiang,born in 1987.PhD candidate.His main research interests include information hiding,machine learning and deep learning.&lt;image href=&quot;images/JFYZ201910020_072.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Zhai Liming,born in 1988.PhD candidate.His main research interests include stegano-graphy and steganalysis.(limingzhai@whu.edu.cn)&lt;image href=&quot;images/JFYZ201910020_073.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Wang Lina,born in 1964.PhD,professor.Member of CCF.Her main research interests include system security and steganalysis.&lt;image href=&quot;images/JFYZ201910020_074.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Jia Ju,born in 1990.PhD candidate.His main research interests include steganography and steganalysis." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization">
                                        <b>[34]</b>
                                        Kingma D P,Ba J.Adam:A method for stochastic optimization[J].arXiv preprint arXiv:1412.6980,2014&lt;image href=&quot;images/JFYZ201910020_071.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Ren Weixiang,born in 1987.PhD candidate.His main research interests include information hiding,machine learning and deep learning.&lt;image href=&quot;images/JFYZ201910020_072.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Zhai Liming,born in 1988.PhD candidate.His main research interests include stegano-graphy and steganalysis.(limingzhai@whu.edu.cn)&lt;image href=&quot;images/JFYZ201910020_073.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Wang Lina,born in 1964.PhD,professor.Member of CCF.Her main research interests include system security and steganalysis.&lt;image href=&quot;images/JFYZ201910020_074.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;Jia Ju,born in 1990.PhD candidate.His main research interests include steganography and steganalysis.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(10),2250-2261 DOI:10.7544/issn1000-1239.2019.20190386            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于卷积神经网络的JPEG图像隐写分析参照图像生成方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">任魏翔</a>
                                <a href="javascript:;">翟黎明</a>
                                <a href="javascript:;">王丽娜</a>
                                <a href="javascript:;">嘉炬</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A9%BA%E5%A4%A9%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E4%BF%A1%E8%AE%A1%E7%AE%97%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6)&amp;code=0009404&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">空天信息安全与可信计算教育部重点实验室(武汉大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6%E5%9B%BD%E5%AE%B6%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉大学国家网络安全学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于深度学习的JPEG数字图像隐写分析模型检测能力已超越基于人工设计特征隐写分析模型,但检测能力仍存在提升空间.以进一步提升JPEG隐写分析模型的检测能力为目标,借助深度学习方法,为基于深度学习的JPEG隐写分析模型提供辅助信息,从数据输入角度,探索进一步提升隐写分析模型检测能力的途径.基于卷积神经网络,构建隐写分析参照图像生成模型,对待检测图像进行变换,从而获得对应参照图像.之后,将待检测图像与对应参照图像作为隐写分析模型的输入数据,进一步挖掘待检测图像中存在的隐写分析相关信息.为验证所提出算法的有效性,进行针对JPEG自适应隐写算法的对比实验.实验结果表明:所设计的参照图像生成模型能够提升现有基于深度学习的隐写分析模型检测能力,提升效果最多可达6个百分点.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=JPEG%E9%9A%90%E5%86%99%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">JPEG隐写分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BE%85%E5%8A%A9%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辅助信息;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%82%E7%85%A7%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">参照图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=JPEG%E8%87%AA%E9%80%82%E5%BA%94%E9%9A%90%E5%86%99%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">JPEG自适应隐写算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    Ren Weixiang,born in 1987.PhD candidate.His main research interests includeinformation hiding,machine learning anddeep learning.renweixiang@whu.edu.cn&lt;image id="230" type="formula" href="images/JFYZ201910020_23000.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Zhai Liming,born in 1988.PhD candidate.His main research interests include stegano-graphy and steganalysis.(limingzhai@whu.edu.cn)&lt;image id="232" type="formula" href="images/JFYZ201910020_23200.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    *Wang Lina,born in 1964.PhD,professor.Member of CCF.Her main research interestsinclude system security and steganalysis.lnwang@whu.edu.cn&lt;image id="234" type="formula" href="images/JFYZ201910020_23400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    Jia Ju,born in 1990.PhD candidate.Hismain research interests include steganographyand steganalysis.&lt;image id="236" type="formula" href="images/JFYZ201910020_23600.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-11</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金重点项目(U1536204);国家自然科学基金项目(61876134,61872275);</span>
                                <span>NSFC-通用技术基础研究联合基金项目(U1836112);</span>
                    </p>
            </div>
                    <h1><b>Reference Image Generation Algorithm for JPEG Image Steganalysis Based on Convolutional Neural Network</b></h1>
                    <h2>
                    <span>Ren Weixiang</span>
                    <span>Zhai Liming</span>
                    <span>Wang Lina</span>
                    <span>Jia Ju</span>
            </h2>
                                    <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>As the opponent of image steganography, the image steganalysis is to detect the secret message in images concealed by steganography algorithms. Recently, state-of-the-art JPEG image steganalysis schemes are changing from complex handcrafted feature-based ones to deep learning-based ones. Although the deep learning steganalysis for detecting JPEG steganography achieves great advancement, there still exists room for improvement. As it is verified that side information could promote the steganography detection accuracy, we seek the method to further improve the accuracy of content-adaptive steganography detection in JPEG domain from the perspective of side information offering for the deep learning steganalysis scheme. The proposed method utilizes convolutional neural networks to generate reference images from the input data. And the reference image is treated as the side information for the deep learning-based JPEG image steganalysis model. The proposed method can be pre-trained or trained together with the steganalysis model. Experimental results on classic content-adaptive steganography algorithms in JPEG domain named J-UNIWARD and JC-UED verifies the proposed method could enhance the detection ability compared with the deep learning steganalysis model without the aid of the proposed method to a certain extent. The proposed method could boost the detection accuracy for deep learning-based JPEG steganalysis model by 6 percentage points at most.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=JPEG%20steganalysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">JPEG steganalysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=side%20information&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">side information;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=reference%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">reference image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolution%20neural%20network%20(CNN)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolution neural network (CNN);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=JPEG%20adaptive%20steganography&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">JPEG adaptive steganography;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-06-11</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the Key Program of the National Natural Science Foundation of China(U1536204) and the National Natural Science Foundation of China(61876134,61872275);</span>
                                <span>the United Basic Research Foundation of NSFC-General Technology(U1836112);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="75">随着信息技术的飞速发展,多媒体文件在网络中广泛传输,导致多媒体信息安全问题日益严重.信息隐藏的研究成果对解决多媒体信息安全问题具有重要作用.</p>
                </div>
                <div class="p1">
                    <p id="76">信息隐藏领域的研究可分为隐写(stegano-graphy)、隐写分析(steganalysis)两方面.如图1所示,隐写是将有意义的信息隐藏在另一个称为载体C(cover)的信息中得到隐蔽载体S(stego)的技术<citation id="192" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.隐写分析是隐写术的对抗技术,对可疑的载体信息进行攻击,达到检测、破坏、甚至提取秘密信息的技术<citation id="193" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 隐写与隐写分析" src="Detail/GetImg?filename=images/JFYZ201910020_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 隐写与隐写分析  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Steganography and steganalysis</p>

                </div>
                <div class="p1">
                    <p id="78">针对数字图像的隐写术通过对图像中的像素或者DCT系数等图像元素进行微量的修改,从而实现在图像中隐藏秘密信息的目的.然而隐写过程中对图像元素的修改操作会对图像元素值的统计分布造成一定的扰动.因此,当前数字图像隐写算法主要通过合理地选择对图像进行修改的位置<citation id="194" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,以及尽量减少所需修改的图像元素<citation id="198" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>来达到最小化隐写操作对原始图像所造成影响的目的.当前具有较高安全性的数字图像隐写算法主要为内容自适应隐写算法,该类算法能够有选择地对图像元素进行修改,以减小秘密信息嵌入过程对图像造成影响.该类算法设计过程可分为失真代价函数设计和隐写码的设计2部分.其中失真代价函数用于衡量秘密信息的嵌入过程中对原始图像载体元素的统计规律造成的影响.而隐写码是指在基本嵌入的基础上,为了减小隐写嵌入失真(distortion)(亦称代价)而进行的编码<citation id="195" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.在STC隐写码<citation id="196" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出后,面向数字图像的隐写算法的设计工作主要集中在失真代价函数的设计<citation id="199" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>.然而,隐写的安全性不仅取决于隐写算法、嵌入率等因素,而且在很大程度上收到隐写过程中载体图像自身属性的影响<citation id="197" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="79">当前通用图像隐写分析方法的相关研究可分为基于隐写分析特征的检测方法,以及基于深度学习的检测方法.前者通过构建能够描述图像载体统计规律或特性,并且对隐写嵌入操作敏感的隐写分析特征,结合机器学习方法对载体进行检测<citation id="200" type="reference"><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>.其中,隐写分析特征依据对图像载体.后者基于深度学习技术,构建用于执行隐写分析任务的深度学习模型,以实现隐写信号的端到端检测.目前,基于深度学习的隐写分析相关研究已成信息隐藏领域的热点研究问题,并取得了较好的成果<citation id="201" type="reference"><link href="41" rel="bibliography" /><link href="43" rel="bibliography" /><link href="45" rel="bibliography" /><link href="47" rel="bibliography" /><link href="49" rel="bibliography" /><link href="51" rel="bibliography" /><link href="53" rel="bibliography" /><link href="55" rel="bibliography" /><link href="57" rel="bibliography" /><link href="59" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>,<a class="sup">24</a>,<a class="sup">25</a>,<a class="sup">26</a>,<a class="sup">27</a>,<a class="sup">28</a>,<a class="sup">29</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="80">选择信道感知的隐写分析方法以提升针对自适应图像隐写算法检测效果为目标,利用自适应隐写算法对图像各元素修改的概率,将检测重点集中在更易被隐写算法修改的图像区域,从而提升针对自适应隐写算法的检测能力.其中,待检测图像各元素被特定自适应隐写算法修改的概率可视为隐写分析模型的辅助信息.当前选择信道感知的思想已运用于基于特征的隐写分析模型,以及基于深度学习的隐写分析模型.</p>
                </div>
                <div class="p1">
                    <p id="81">由于JPEG图像在互联网中的广泛应用,因此针对JPEG图像的研究具有较高的实际意义.当前基于深度学习的JPEG图像隐写分析的研究工作主要集中于负责隐写检测的深度学习模型的相关研究<citation id="202" type="reference"><link href="53" rel="bibliography" /><link href="55" rel="bibliography" /><link href="57" rel="bibliography" /><link href="59" rel="bibliography" /><sup>[<a class="sup">26</a>,<a class="sup">27</a>,<a class="sup">28</a>,<a class="sup">29</a>]</sup></citation>.基于深度学习隐写分析模型辅助信息的产生方式主要基于研究者专业经验进行设计<citation id="203" type="reference"><link href="47" rel="bibliography" /><link href="49" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>.本文借助深度学习方法,从隐写分析辅助信息产生方式的角度,探索提升针对JPEG图像的深度学习隐写分析模型检测效果的新途径.</p>
                </div>
                <div class="p1">
                    <p id="82">本文构建具有卷积层和反卷积层的16层卷积神经网络,对待检测图像进行变换,得到待检测图像所对应的参照图像,将参照图像和待检测图像一同作为JPEG图像隐写分析模型的输入数据,从而基于现有针对JPEG图像深度学习隐写分析模型,进一步提升JPEG图像深度学习隐写分析模型检测能力.</p>
                </div>
                <div class="p1">
                    <p id="83">本文的主要贡献有3个方面:</p>
                </div>
                <div class="p1">
                    <p id="84">1) 提出针对JPEG图像隐写分析的参照图像生成模型,为针对JPEG图像的深度学习隐写分析模型提供辅助信息,从辅助信息的角度探索提升深度学习隐写分析模型检测能力的途径;</p>
                </div>
                <div class="p1">
                    <p id="85">2) 隐写分析参照图像生成模型基于深度卷积神经网络,能够通过训练,学习有利于提升隐写检测能力的辅助信息生成方式;</p>
                </div>
                <div class="p1">
                    <p id="86">3) 针对多种嵌入率、隐写算法的对比实验结果表明,所提出的针对JPEG图像隐写分析的参照图像生成模型生成的参照图像能够提升针对JPEG图像的深度学习隐写分析模型的检测能力.</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="88">由于JPEG图像在互联网中的广泛使用,针对JPEG图像的隐写分析具有较高的研究价值.因此,基于深度学习的JPEG隐写分析方法也是隐写分析研究领域的热点问题.</p>
                </div>
                <div class="p1">
                    <p id="89">在深度学习隐写分析开始引起学者关注期间,Xu<citation id="204" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>,Chen等人<citation id="205" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>,Zeng等人<citation id="206" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>分别提出了针对JPEG图像的深度学习隐写分析模型.其中,Xu<citation id="207" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>构建了具有20层的深度卷积网络模型,该模型为减少信息丢失,不使用池化操作,并加入跳转链接(shortcut connection),以防止梯度消失现象发生.Chen等人<citation id="208" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>构建的深度学习模型包含64个卷积神经网络,其中每个神经网络与JPEG图像的1个相位相对应,从而实现了网络模型对JPEG图像不同相位数据的分离处理.Zeng等人<citation id="209" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>构建了1种针对JPEG隐写分析的混合卷积经网络模型.该模型首先利用25个DCT变换基对待检测图像进行预处理,之后对预处理结果进行多种不同的量化和截断处理,并将处理的结果分别作为不同深度卷积神经网络的输入.Yang等人<citation id="210" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>基于DenseNet<citation id="211" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>提出了针对JPEG图像的深度学习隐写分析模型.</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>1.1 JPEG图像深度学习隐写分析处理过程</b></h4>
                <div class="p1">
                    <p id="91">卷积神经网络(convolutional neural network, CNN)能够提取图像中相邻元素之间存在的相关性.因此,当前针对JPEG图像的深度学习隐写分析模型主要基于卷积神经网络,并将JPEG图像的解压(不取整)结果作为输入数据.除此之外,不同针对JPEG图像的深度学习隐写分析模型在卷积神经网络部分都采用了卷积层(convolutional layer)、批标准化(batch normalization)、ReLU(rectified linear unit)激活函数、平均池化(avarage pooling)等操作.</p>
                </div>
                <div class="p1">
                    <p id="92">卷积神经网络中的卷积层由多个卷积核构成,各卷积核的有卷积权重和偏置组成,卷积权重和偏置参与神经网络的训练.卷积层中的各卷积核分别利用卷积权重对输入数据进行卷积操作,并将结果与对应的偏置相加,之后将卷积核的处理结果进行合并,合并结果作为该卷积层的输出.具体处理过程:</p>
                </div>
                <div class="p1">
                    <p id="93"><i>output</i><sup><i>l</i></sup>=<i>output</i><sup><i>l</i></sup><sup>-1</sup>*<i><b>W</b></i><sub><i>l</i></sub>+<i><b>B</b></i><sub><i>l</i></sub>,(1)</p>
                </div>
                <div class="p1">
                    <p id="94">其中,<i>output</i><sup><i>l</i></sup>和<i>output</i><sup><i>l</i></sup><sup>-1</sup>分别为第<i>l</i>个卷积层的输出数据和输入数据;<i><b>W</b></i><sub><i>l</i></sub>为第<i>l</i>个卷积层的卷积核参数矩阵;*为卷积操作算子;<i><b>B</b></i><sub><i>l</i></sub>为第<i>l</i>个卷积层的偏置.</p>
                </div>
                <div class="p1">
                    <p id="95">为了提升深度学习隐写分析模型在训练过程中的收敛速度,采用批标准化(batch normalization, BN)层<citation id="212" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>,对卷积层输出的特征图进行标准化处理.BN层的处理过程:</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>X</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>,(2)</p>
                </div>
                <div class="p1">
                    <p id="97"><mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>u</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>,(3)</p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>X</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>u</mi></mrow><mrow><msqrt><mrow><mi>v</mi><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac></mrow></math></mathml>,(4)</p>
                </div>
                <div class="p1">
                    <p id="99"><mathml id="187"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>γ</mi><mo>*</mo><mover accent="true"><mi>X</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>β</mi></mrow></math></mathml>,(5)</p>
                </div>
                <div class="p1">
                    <p id="100">其中,<i>γ</i>和<i>β</i>为可训练参数,参与神经网络的训练;<i>ε</i>参数为大于0的常量;<mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>X</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>为当前批处理层的最小批量输入数据中的1个特征图.</p>
                </div>
                <div class="p1">
                    <p id="101">深度神经网络中的激活函数保证了深度学习隐写分析模型进行非线性特性的学习,而ReLU(rectified linear unit, ReLU)激活函数在深度学习模型中得到了广泛的应用.ReLU激活函数的具体处理过程为</p>
                </div>
                <div class="area_img" id="102">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201910020_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="104">其中,<i>x</i>为ReLU激活函数的输入;<i>f</i>(<i>x</i>)为其输出结果.</p>
                </div>
                <div class="p1">
                    <p id="105">平均池化属于1种下采样操作,对矩阵<i><b>X</b></i>进行平均池化操作具体过程:</p>
                </div>
                <div class="p1">
                    <p id="106"><mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><mi>v</mi><mi>g</mi><mo>_</mo><mi>p</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Κ</mi><mo>*</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo></mrow></math></mathml>,(7)</p>
                </div>
                <div class="p1">
                    <p id="107">其中,<i><b>X</b></i>为池化操作待处理的矩阵;池化操作的窗口大小为<i>n</i>×<i>n</i>;<i><b>K</b></i>为大小为<i>n</i>×<i>n</i>,并且元素全为1的矩阵,“*”为卷积操作算子.</p>
                </div>
                <div class="p1">
                    <p id="108">相对于最大池化等其他池化操作,能够保留隐写算法的嵌入操作在载体中引入的微弱扰动.因此,基于深度学习的隐写分析模型主要采用平均池化作为其池化操作.</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>1.2 深度学习隐写分析辅助信息产生方式</b></h4>
                <div class="p1">
                    <p id="110">为进一步提升针对JPEG图像的深度学习隐写分析模型检测能力,Yang等人<citation id="213" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>和Ye等人<citation id="214" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>提出的深度学习隐写分析模型在输入数据的基础上,附加以相应的辅助信息.当前基于深度学习的隐写分析模型的辅助信息主要来源于待检测图像各元素被自适应隐写算法修改的概率.</p>
                </div>
                <div class="p1">
                    <p id="111">如图2所示,图像中位于纹理复杂区域的元素对应的大于位于平滑区域元素的修改概率.以上现象表明自适应隐写算法更倾向于在图像中的纹理复杂区域进行嵌入操作.</p>
                </div>
                <div class="p1">
                    <p id="112">产生以上现象的原因为图像纹理复杂区域的元素值的统计分布相比于平滑区域更为复杂,隐写算法在这些统计规律复杂区域造成的扰动更加不易被觉察.因此,对隐写算法修改概率更高的区域进行更有侧重地检测,有利于提升隐写检测效果待检测图像的元素被自适应隐写算法修改概率可利用损失函数计算得到.具体计算方式为</p>
                </div>
                <div class="p1">
                    <p id="113"><mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>β</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mo>+</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mi>λ</mi><mtext> </mtext><mi>ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow></msup></mrow></mfrac></mrow></math></mathml>,(8)</p>
                </div>
                <div class="p1">
                    <p id="114">其中,<i>β</i><sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub>为位于图像位置(<i>i</i>,<i>j</i>)的元素被修改的概率值;<i>λ</i>为大于零的数值,具体数值由隐写相对嵌入率决定.</p>
                </div>
                <div class="area_img" id="115">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 一张图像及其对应的修改概率图" src="Detail/GetImg?filename=images/JFYZ201910020_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 一张图像及其对应的修改概率图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 An image and the corresponding embedding probability map</p>

                </div>
                <h3 id="116" name="116" class="anchor-tag"><b>2 JPEG图像隐写分析参照图像生成模型</b></h3>
                <div class="p1">
                    <p id="117">虽然利用图像各元素被修改的概率作为辅助信息,能够提升针对JPEG图像的深度学习隐写分析模型的检测能力,但当前基于深度学习隐写分析模型所使用辅助信息的产生方法有待进一步改进,隐写分析模型的输入数据中隐含的与隐写分析有关的信息有待进一步挖掘.</p>
                </div>
                <div class="p1">
                    <p id="118">本文从隐写分析辅助信息的角度,探索进一步提升深度学习隐写分析模型检测能力的途径,提出JPEG图像隐写分析参照图像生成模型,尝试更加深入的挖掘待检测图像中与隐写分析有关的信息.首先,基于U-NET<citation id="215" type="reference"><link href="65" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>构建具有跳转连接(skip connection)的深度卷积神经网络,对待检测图像进行处理,生成用于JPEG图像隐写分析的参照图像.之后,将生成的参照图像作为隐写分析的辅助信息,与隐写分析模型相结合.从而更加充分地挖掘待检测图像中与隐写有关的信息,在现有隐写分析模型的基础上,进一步提升深度学习隐写分析模型的检测能力的目的.</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119"><b>2.1 JPEG图像隐写分析模型的关系</b></h4>
                <div class="p1">
                    <p id="120">JPEG图像隐写分析参照图像生成模型将待检测图像进行处理和变换,以提升隐写分析模型的检测能力为目的,为针对JPEG图像的深度学习隐写分析模型提供辅助信息.</p>
                </div>
                <div class="p1">
                    <p id="121">如图3所示,JPEG图像隐写分析参照图像生成模型与隐写分析模型相互独立,以待检测图像为输入数据.而隐写分析模型的输入数据为待检测图像和JPEG图像隐写分析参照图像生成模型的输出数据.最终检测结果由隐写分析模型输出.</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 本文方法与隐写分析模型的关系" src="Detail/GetImg?filename=images/JFYZ201910020_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 本文方法与隐写分析模型的关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Relations between the proposed method and 
 steganalysis model</p>

                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>2.2 所提出参照图像生成模型结构</b></h4>
                <div class="p1">
                    <p id="124">JPEG图像隐写分析参照图像生成模型,由8个卷积层与8个反卷积层(deconvolution)组成,共16层.每个卷积层以及反卷积层的输出依次经过批标准化(BN)和LReLu(leaky ReLu, LReLU)激活函数的处理,分别记为CONV-BN-LReLU和deCONV-BN-LReLU.</p>
                </div>
                <div class="p1">
                    <p id="125">本文提出模型的反卷积层又称为转置卷积,记为deCONV.本文模型通过反卷积层实现上采样目的,将经由多个卷积层输出的抽象特征图进行进一步变换,最终得到与输入图像相同大小的参照图像.此外,为抑制梯度消失现象,在模型的卷积层与对称位置的反卷积层之间添加跳转连接(skip connection).</p>
                </div>
                <div class="p1">
                    <p id="126">具体网络结构如图4所示,包括2种类型的操作组合:<i>GT</i>1,<i>GT</i>2.网络各层结构的具体参数如表1所示,其中,列2和列3代表对应网络层的输入数据和输出数据尺寸.输入数据和输出数据尺寸参数格式为<i>a</i>×(<i>b</i>×<i>c</i>),<i>a</i>为数据的通道数,<i>b</i>为数据的高度,<i>c</i>为数据的宽度.卷积核尺寸列为对应网络层中卷积核的参数.卷积核的具体参数格式为<i>n</i>×(<i>h</i>×<i>w</i>)×<i>s</i>,<i>n</i>为卷积核的个数,<i>h</i>为卷积核的高度,<i>w</i>为卷积核的宽度,<i>s</i>为卷积操作的步长.Process列表示对应层包含的操作,ADD(·)为按位相加操作,“·”是与当前层相加的网络层标号.</p>
                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 JPEG图像隐写分析参照图像生成模型结构图" src="Detail/GetImg?filename=images/JFYZ201910020_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 JPEG图像隐写分析参照图像生成模型结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Structure of reference image generation network for JPEG image deep learning steganalysis model</p>

                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表1 参照图像生成模型的参数细节</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Configuration Details of Reference Image Generation Network</b></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td><br />Layer</td><td>Input Size<br /><i>a</i>×(<i>b</i>×<i>c</i>)</td><td>Output Size<br /><i>a</i>×(<i>b</i>×<i>c</i>)</td><td>Kernel Size<br /><i>n</i>×(<i>h</i>×<i>w</i>)×<i>s</i></td><td>Process</td></tr><tr><td><br /><i>L</i>1</td><td>1×(256×256)</td><td>16×(256×256)</td><td>16×(3×3)×1</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>2</td><td>16×(256×256)</td><td>32×(256×256)</td><td>32×(3×3)×1</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>3</td><td>32×(256×256)</td><td>64×(128×128)</td><td>64×(3×3)×2</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>4</td><td>64×(128×128)</td><td>64×(64×64)</td><td>64×(3×3)×2</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>5</td><td>64×(64×64)</td><td>128×(32×32)</td><td>128×(3×3)×2</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>6</td><td>128×(32×32)</td><td>128×(16×16)</td><td>128×(3×3)×2</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>7</td><td>128×(16×16)</td><td>128×(8×8)</td><td>128×(3×3)×2</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>8</td><td>128×(8×8)</td><td>128×(4×4)</td><td>128×(3×3)×2</td><td>CONV-BN-LReLu</td></tr><tr><td><br /><i>L</i>9</td><td>128×(4×4)</td><td>128×(8×8)</td><td>128×(5×5)×2</td><td>DECONV-BN-LReLu-ADD(<i>L</i>8)</td></tr><tr><td><br /><i>L</i>10</td><td>128×(8×8)</td><td>128×(16×16)</td><td>128×(5×5)×2</td><td>DECONV-BN-LReLu-ADD(<i>L</i>7)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="129"><b>Continued (Table 1</b>)</p>
                </div>
                <div class="area_img" id="130">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="130" border="1"><tr><td><br />Layer</td><td>Input Size<br /><i>a</i>×(<i>b</i>×<i>c</i>)</td><td>Output Size<br /><i>a</i>×(<i>b</i>×<i>c</i>)</td><td>Kernel Size<br /><i>n</i>×(<i>h</i>×<i>w</i>)×<i>s</i></td><td>Process</td></tr><tr><td><br /><i>L</i>11</td><td>128×(16×16)</td><td>128×(32×32)</td><td>128×(5×5)×2</td><td>DECONV-BN-LReLu-ADD(<i>L</i>6)</td></tr><tr><td><br /><i>L</i>12</td><td>128×(32×32)</td><td>64×(64×64)</td><td>64×(5×5)×2</td><td>DECONV-BN-LReLu-ADD(<i>L</i>5)</td></tr><tr><td><br /><i>L</i>13</td><td>64×(64×64)</td><td>64×(128×128)</td><td>64×(5×5)×2</td><td>DECONV-BN-LReLu-ADD(<i>L</i>4)</td></tr><tr><td><br /><i>L</i>14</td><td>64×(128×128)</td><td>32×(256×256)</td><td>32×(5×5)×2</td><td>DECONV-BN-LReLu-ADD(<i>L</i>3)</td></tr><tr><td><br /><i>L</i>15</td><td>32×(256×256)</td><td>16×(256×256)</td><td>16×(5×5)×1</td><td>DECONV-BN-LReLu-ADD(<i>L</i>2)</td></tr><tr><td><br /><i>L</i>16</td><td>16×(256×256)</td><td>1×(256×256)</td><td>1×(5×5)×1</td><td>DECONV-BN-LReLu-ADD(<i>L</i>1)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: <i>a</i> is the channel of the data, <i>b</i> is the height of the data and <i>c</i> is the width of the data. Besides, <i>n</i> is the number of the convolutional kernel, <i>h</i> is the height of the convolutional kernel, <i>w</i> is width of the convolutional kernel and <i>s</i> is the stride for the convolution.</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131"><b>2.3 所提出参照图像生成模型训练方式</b></h4>
                <div class="p1">
                    <p id="132">本文提出的隐写分析参照图像生成模型可采取2种训练策略:第1种训练策略为预训练策略,记为Pre-training;第2种训练策略为共同训练方式,记为Together.</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 Pre-training训练策略" src="Detail/GetImg?filename=images/JFYZ201910020_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 Pre-training训练策略  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Pre-training strategy</p>

                </div>
                <div class="p1">
                    <p id="134">第1种训练方式,即预训练方式.首先,对本文所提出参照图像生成模型进行预训练,预训练过程如图5所示.隐写分析参照图像生成模型预训练的损失函数为生成的参照图像与待检测图像对应的cover图像之间的相似程度,该损失函数的计算方法:</p>
                </div>
                <div class="p1">
                    <p id="135"><i>φ</i>(<i><b>I</b></i>)=<i><b>I</b></i>*<i><b>K</b></i>,(9)</p>
                </div>
                <div class="p1">
                    <p id="136"><i>φ</i>(<i><b>R</b></i>)=<i><b>R</b></i>*<i><b>K</b></i>,(10)</p>
                </div>
                <div class="p1">
                    <p id="137"><mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>Ο</mi><mi>S</mi><mi>S</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Μ</mi><mi>Ν</mi></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><mo stretchy="false">(</mo></mstyle><mi>φ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">)</mo><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>-</mo><mi>φ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">R</mi><mo stretchy="false">)</mo><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>,(11)</p>
                </div>
                <div class="p1">
                    <p id="138">其中,1≤<i>i</i>≤<i>M</i>,1≤<i>j</i>≤<i>N</i>;<i>M</i>,<i>N</i>为图像的宽度和长度;<i><b>I</b></i>为待检测图像对应的原始图像;<i><b>R</b></i>为本文提出的方法产生的隐写分析参照图像;<i><b>K</b></i>是预训练过程中使用的滤波器;<i>φ</i>(<i><b>I</b></i>)和<i>φ</i>(<i><b>R</b></i>)分别是对<i><b>I</b></i>和<i><b>R</b></i>进行滤波的结果;<i>φ</i>(<i><b>I</b></i>)<sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub>和<i>φ</i>(<i><b>R</b></i>)<sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub>分别为<i>φ</i>(<i><b>I</b></i>)和<i>φ</i>(<i><b>R</b></i>)位于(<i>i</i>,<i>j</i>)位置的元素值;<i>LOSS</i>为预训练的损失函数.</p>
                </div>
                <div class="p1">
                    <p id="139">首先采用YeNet<citation id="216" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>中所使用的Rich Model<citation id="217" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>中的30个高通滤波器<i><b>K</b></i>分别对生成图像<i><b>R</b></i>和输入图像所对应的cover图像<i><b>I</b></i>进行滤波操作;然后,计算以上2种图像的滤波结果<i>φ</i>(<i><b>I</b></i>)和<i>φ</i>(<i><b>R</b></i>)之间的均方误差,并将其作为参照图像<i><b>R</b></i>与待检测图像对应的cover图像<i><b>I</b></i>之间相似程度的度量和预训练的损失函数<i>LOSS</i>.</p>
                </div>
                <div class="p1">
                    <p id="140">预训练完成之后,将参照图像生成模型与隐写分析模型相结合,以提升隐写分析任务分类准确率为目标,进行训练.通过对参照图像生成模型进行预训练,保证参照图像与待检测图像所对应的cover图像在残差噪声上尽可能接近.</p>
                </div>
                <div class="p1">
                    <p id="141">第2种训练策略,属于1种共同训练方式,如图6所示,将参照图像生成模型与隐写分析模型作为1个整体,以提升隐写分析检测准确率为目标,进行共同训练.</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 Together训练策略" src="Detail/GetImg?filename=images/JFYZ201910020_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 Together训练策略  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 6 Together training strategy</p>

                </div>
                <h4 class="anchor-tag" id="143" name="143"><b>2.4 参照图像与隐写分析模型的结合方式</b></h4>
                <div class="p1">
                    <p id="144">JPEG图像隐写分析参照图像生成模型输出的参照图像将作为深度学习隐写分析模型的辅助信息,与待检测图像一同作为深度学习隐写分析模型的输入,以提升深度学习隐写分析模型的检测能力.</p>
                </div>
                <div class="p1">
                    <p id="145">本文所提出方法生成的参照图像可以按照2种方式与隐写分析模型进行结合,如图7所示.</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 参照图像输入方式" src="Detail/GetImg?filename=images/JFYZ201910020_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 参照图像输入方式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 7 Reference images input methods</p>

                </div>
                <div class="p1">
                    <p id="147">第1种结合方式,记为Combine方式,该种方式是将参照图像与对应的待检测图像沿着图像的<i>x</i>轴进行连接(concation)操作,合成结果为1个宽度为待检测待检测图像2倍的矩阵,并将该合成结果作为隐写分析模型的输入.</p>
                </div>
                <div class="p1">
                    <p id="148">第2种合结合方式,记为Channel方式,将参照图像和待检测图像沿<i>z</i>轴进行合并.分别作为隐写分析模型的输入数据,在隐写分析模型对2种数据进行相应处理,并将处理的结果进行合并.</p>
                </div>
                <h3 id="149" name="149" class="anchor-tag"><b>3 实验与分析</b></h3>
                <div class="p1">
                    <p id="150">为验证本文方法有效性,基于JPEG图像隐写分析参照图像生成模型和J-Xune<citation id="218" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>,构建隐写分析模型,并与J-Xunet的检测效果进行对比.本文使用Tensorflow深度学习框架实现提出的模型以及对比模型.本论文的数值计算得到了武汉大学超级计算中心的计算支持和帮助.</p>
                </div>
                <h4 class="anchor-tag" id="151" name="151"><b>3.1 数据集合</b></h4>
                <div class="p1">
                    <p id="152">本文实验采用的数据集合来源于BossBase v1.01<citation id="219" type="reference"><link href="67" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>中的10 000图像.如图8所示,本文在实验中将BossBase v1.01中每张512×512大小的图像从4个对角以及图像的中间部分截取的5张大小为256×256的图像,从而产生50 000张空域图像.之后对50 000张空域图像分别以质量因子为75和95,进行JPEG压缩,得到对应不同质量因子的JPEG图像,作为本文实验中涉及的cover图像.</p>
                </div>
                <div class="area_img" id="153">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 实验数据产生方式" src="Detail/GetImg?filename=images/JFYZ201910020_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 实验数据产生方式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 8 Generation of image samples in the experiments</p>

                </div>
                <div class="p1">
                    <p id="154">本文所涉及的对比实验的训练、验证、测试数据的stego图像由JC-UED<citation id="220" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和J-UNIWARD<citation id="221" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>和隐写算法分别以相对嵌入率0.1bpnzAC(bits per none zero AC),0.2bpnzAC,0.3bpnzAC,0.4bpnzAC,0.5bpnzAC对50 000张256×256大小的cover图像进行嵌入得到.</p>
                </div>
                <div class="p1">
                    <p id="155">对比实验的数据构成如图9所示,将BossBase v1.01中8 000张原始图像对应的40 000张256×256大小的cover图像以及对应的40 000张stego图像,共80 000张图像作为模型的训练数据集合;将BossBase v1.01中与训练测试集合不同的1 000张图像所对应的5 000张256×256大小cover图像以及对应的stego图像,共10 000张图像作为验证数据集合;将BossBase v1.01中其余1 000张图像对应的5 000张256×256大小图像及其对应的stego图像,共10 000张图像作为实验的测试数据集合.</p>
                </div>
                <div class="p1">
                    <p id="156">所构建的数据集合保证了本文提出的模型以及对比方法采用相同的训练、验证、测试数据集合,并且训练、验证、测试数据集合的原图像互不重复.</p>
                </div>
                <h4 class="anchor-tag" id="157" name="157"><b>3.2 模型参数设置</b></h4>
                <div class="p1">
                    <p id="158">本文所提出模型在训练过程中都采用Adam<citation id="222" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>优化算法进行目标函数的优化.其中,学习率初始值为0.001,学习率每5 000次训练衰减为原来的0.9.训练过程中,每个mini-batch包括16对cover和stego图像,即32张图像;每种模型训练的最大训练迭代次数为20万,即80个epoch.</p>
                </div>
                <div class="p1">
                    <p id="159">此外,本文实验所涉及的对比算法采用相同参数设置.</p>
                </div>
                <div class="area_img" id="160">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 对比实验数据集合构成" src="Detail/GetImg?filename=images/JFYZ201910020_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 对比实验数据集合构成  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_160.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 9 Data sets for the experiments</p>

                </div>
                <h4 class="anchor-tag" id="161" name="161"><b>3.3 模型训练策略与结合方式的选择</b></h4>
                <div class="p1">
                    <p id="162">为了确定JPEG图像隐写分析参照图像生成模型的训练策略,以及与深度学习隐写分析模型的结合方式,分别采用Together,Pre-training训练方式以及Combine和Channel结合方式进行包含1种情况的对比实验.</p>
                </div>
                <div class="p1">
                    <p id="163">该对比实验中,将本文所提出的隐写分析参照凸显生成模型与J-Xunet<citation id="223" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>隐写分析模型相结合.各种情况下模型的最大训练迭代次数为12.5万次,并选取最后5个epoch的验证结果的平均值作为最终的检测准确率.检测算法为J-UNIWARD<citation id="224" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>,相对嵌入率为0.4bpnzAC,JPEG图像载体为质量因子为75.分别采用2种模型结合方式,以及2种不同的训练策略,得到的4种模型在验证数据集合中的检测准确率如表2所示.其中,加粗数据为最高的准确率.模型在验证集合上的准确率在训练过程中的变化情况如图10所示.其中,横坐标为训练的epoch,纵坐标为各个epoch训练完成之后的测试准确率.</p>
                </div>
                <div class="area_img" id="164">
                    <p class="img_tit"><b>表2 不同训练策略、结合方式在验证数据集的检测效果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Detection Accuracy when Different Training Strategies and Combination Ways are Applied</b></p>
                    <p class="img_note">%</p>
                    <table id="164" border="1"><tr><td><br />Training Strategy</td><td>Combine</td><td>Channel</td></tr><tr><td><br />Together</td><td><b>83.45</b></td><td>49.30</td></tr><tr><td><br />Pre-training</td><td>78.75</td><td>80.16</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The bold numbers are the best performance in experiments.</p>
                </div>
                <div class="area_img" id="165">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 训练策略、结合方式对验证结果的影响" src="Detail/GetImg?filename=images/JFYZ201910020_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 训练策略、结合方式对验证结果的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_165.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 10 Effect of training strategies and combination
 ways on verification results</p>

                </div>
                <div class="p1">
                    <p id="166">实验结果表明:采用Combine方式将参照图像生成模型与隐写分析模型结合,能够获得具有更高检测准确率的模型.当本文方法与J-Xunet隐写分析模型采用Combine方式进行结合,并采用Together训练方式得到的隐写分析模型具有最高的检测准确率.因此,本文对比实验采用Combine方式将参照图像生成模型产生的参照图像与待检测图像结合,并采用Together训练方式进行训练.</p>
                </div>
                <h4 class="anchor-tag" id="167" name="167"><b>3.4 对比实验与结果分析</b></h4>
                <div class="p1">
                    <p id="168">本文提出的JPEG隐写分析参照图像生成模型与J-Xunet<citation id="225" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>深度学习隐写分析模型结合,从而为针对JPEG图像的深度学习隐写分析模型提供辅助信息,所构成的隐写分析模型记为Reference-J-Xunet.为验证本文提出方法的有效性,利用第3.1节中所构建的隐写分析数据集合,进行Reference-J-Xunet与J-XuNet<citation id="226" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>之间的隐写分析检测能力对比实验.</p>
                </div>
                <div class="p1">
                    <p id="169">每种深度学习隐写分析模型采用与3.2节中相同的参数设置.每种隐写分析模型训练完成之后,取训练过程中最后5个epoch所保存模型的测试结果的平均值作为最终检测准确率.除此之外,每种隐写分析模型各进行以上3次测试,并取3次测试准确率的平均结果作为最终的测试结果.具体测试结果如图11、图12以及表3所示.其中,图11和图12中的圆点表示本文提出方法针对不同载体质量因子、不同嵌入率,以及不同隐写算法嵌入的样本的隐写分析准确率,而正方形表示J-XuNet相应的隐写分析准确率.表3中,行2数据为待检测样本的相对嵌入率,单位为bpnzAC(bits per non-zero AC DCT coeﬃcient).此外,表3中的加粗数据为针对相同算法相同嵌入率情况下最高检测准确率.</p>
                </div>
                <div class="area_img" id="170">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 J-XuNet与Reference-J-XuNet对于J-UNIWARD隐写算法的检测准确率对比" src="Detail/GetImg?filename=images/JFYZ201910020_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 J-XuNet与Reference-J-XuNet对于J-UNIWARD隐写算法的检测准确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 11 Detection accuracy comparison between J-XuNet and Reference-J-XuNet for J-UNIWARD QF75 and QF95</p>

                </div>
                <div class="area_img" id="171">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201910020_171.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 J-XuNet与Reference-J-XuNet对于JC-UED隐写算法的检测准确率对比" src="Detail/GetImg?filename=images/JFYZ201910020_171.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 J-XuNet与Reference-J-XuNet对于JC-UED隐写算法的检测准确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201910020_171.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 12 Detection accuracy comparison between J-XuNet and Reference-J-XuNet for JC-UED</p>

                </div>
                <div class="area_img" id="172">
                    <p class="img_tit"><b>表3 本文方法与对比算法对于不同隐写算法的检测结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Detection Results of Proposed Method and Prior Art for J-UNIWARD and UED-JC</b></p>
                    <p class="img_note">%</p>
                    <table id="172" border="1"><tr><td rowspan="2"><br />Embedding<br />Method</td><td rowspan="2">Detecor</td><td colspan="5"><br />QF75</td><td colspan="5">QF95</td></tr><tr><td><br />0.1</td><td>0.2</td><td>0.3</td><td>0.4</td><td>0.5</td><td>0.1</td><td>0.2</td><td>0.3</td><td>0.4</td><td>0.5</td></tr><tr><td rowspan="2"><br />J-UNIWARD</td><td><br />Reference-J-Xunet</td><td><b>57.352</b></td><td><b>66.357</b></td><td><b>74.512</b></td><td><b>81.867</b></td><td><b>88.508</b></td><td><b>50.88</b></td><td><b>53.49</b></td><td><b>59.176</b></td><td><b>63.718</b></td><td><b>65.802</b></td></tr><tr><td><br />J-Xunet</td><td>54.438</td><td>62.246</td><td>72.026</td><td>76.205</td><td>81.572</td><td>50.52</td><td>52.838</td><td>56.544</td><td>59.089</td><td>64.024</td></tr><tr><td rowspan="2"><br />JC-UED</td><td><br />Reference-J-Xunet</td><td><b>76.966</b></td><td><b>86.024</b></td><td><b>90.916</b></td><td><b>92.472</b></td><td><b>95.486</b></td><td><b>56.296</b></td><td><b>64.762</b></td><td><b>72.478</b></td><td><b>77.378</b></td><td><b>81.236</b></td></tr><tr><td><br />J-Xunet</td><td>72.544</td><td>82.388</td><td>87.044</td><td>90.604</td><td>94.096</td><td>55.146</td><td>62.644</td><td>65.904</td><td>75.838</td><td>76.984</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note">Note: The bold numbers are the best performance in experiments.</p>
                </div>
                <div class="p1">
                    <p id="173">在载体质量因子为95时,相对嵌入率为0.1bpnzAC和0.2bpnzAC,隐写算法为J-UNIWARD的情况下,以及载体质量因子为95时,相对嵌入率为0.1bpnzAC,隐写算法为JC-UED的情况下,检测难度较大.为了保证模型在以上情况下的检测效果,本文对比实验采用调优策略进行以上情况下模型的训练.</p>
                </div>
                <div class="p1">
                    <p id="174">具体训练过程为:</p>
                </div>
                <div class="p1">
                    <p id="175">1) 采用载体质量因子为95,相对嵌入率为0.5bpnzAC的样本,对模型进行训练,共训练80个epoch.</p>
                </div>
                <div class="p1">
                    <p id="176">2) 利用当前情况下的样本,继续训练上一步训练过程中得到的模型,即对模型进行调优.调优过程的最大epoch数为80.</p>
                </div>
                <div class="p1">
                    <p id="177">在隐写样本的嵌入方法为J-UNIWARD<citation id="227" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>算法、载体图像质量因子为75、隐写样本的相对嵌入率分别为0.1bpnzAC,0.2bpnzAC,0.3bpnzAC,0.4bpnzAC,0.5bpnzAC的情况下,本文提出方法相对于对比方法的隐写分析准确率分别提升了2.914,4.111,2.486,5.662,6.936个百分点.而当载体图像具有较高质量因子,如质量因子为95时,隐写分析难度相对于低质量因子图像更大.因此,实验中载体质量因子为95时,隐写分析准确率相对于载体质量因子为75有所下降.但本文提出方法依然能够提升隐写分析模型的检测能力.在相对嵌入率为0.2bpnzAC,0.3bpnzAC,0.4bpnzAC,0.5bpnzAC的情况下,本文方法的隐写分析准确率相对于对比方法分别提升0.652,2.632,4.629,1.778个百分点.</p>
                </div>
                <div class="p1">
                    <p id="178">当隐写样本采用JC-UED<citation id="228" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>算法进行嵌入的情况下,本文提出方法同样能够提升深度学习隐写分析模型的检测能力.当载体图像的质量因子为75且相对嵌入率分别为0.1bpnzAC,0.2bpnzAC,0.3bpnzAC,0.4bpnzAC,0.5bpnzAC的情况下,本文方法隐写分析准确率相对于对比方法分别提升4.422,3.636,3.872,1.868,1.39个百分点.在载体质量因子为95且相对嵌入率分别为0.1bpnzAC,0.2bpnzAC,0.3bpnzAC,0.4bpnzAC,0.5bpnzAC的情况下,本文方法的隐写分析准确率相对于对比方法分别提升1.15,2.118,6.574,1.54,4.252个百分点.</p>
                </div>
                <div class="p1">
                    <p id="179">当载体图像质量因子为95、隐写样本相对嵌入率为0.1bpnzAC,隐写算法为J-UNIWARD时,对比试验在模型训练过程中采用了调优策略.虽然本文算法相对于对比方法略有提升,但是本文方法和对比方法的隐写检测准确率均接近50%.</p>
                </div>
                <div class="p1">
                    <p id="180">实验结果表明:本文方法能够为基于深度学习的JPEG图像隐写分析模型提供有利于提升检测能力的辅助信息,提升深度学习隐写分析模型的检测能力.但在载体图像具有较高质量因子、较低嵌入率情况下提升效果有待加强.</p>
                </div>
                <h3 id="181" name="181" class="anchor-tag"><b>4 总  结</b></h3>
                <div class="p1">
                    <p id="182">本文从隐写分析模型辅助信息的角度,探索进一步提升JPEG图像隐写分析模型检测能力的途径.构建了基于卷积神经网络的隐写分析参照图像生成模型为,以更加充分地挖掘待检测图像中与隐写分析有关的信息.本文提出方法对待检测图像进行变换,并与隐写分析模型一同参与训练,保证参照图像生成模型以提升隐写分析检测能力为目标,为隐写分析模型提供辅助信息.对比实验结果表明:本文提出模型,能够为针对JPEG图像的深度学习隐写分析模型提供有助于提升检测能力的辅助信息.但在载体为高质量因子JPEG图像,相对嵌入率较低的情况下,提升效果有待加强.</p>
                </div>
                <div class="p1">
                    <p id="183">在未来,将针对隐写分析检测对象的载体属性与深度学习隐写分析模型的特性,对JPEG图像隐写分析参照图像生成模型进行改进与优化,改善本文构建的模型在载体具有高质量因子,相对嵌入率较低情况下的检测能力,探索进一步提升针对JPEG图像的深度学习隐写分析模型检测能力的途径.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007307038269999&amp;v=MjkzNThpZlp1OXVGQ3ZuVTd2TUtGNFZWVjI3R2JDNEdkSFBwNDFEYmVJR0JSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bkty&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Wang Lina,Zhang Huanguo,Ye Dengpan.Information Hiding Technology and Application[M].Wuhan:Wuhan University Press,2003 (in Chinese)(王丽娜,张焕国,叶登攀.信息隐藏技术与应用[M].武汉:武汉大学出版社,2003)
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201208011&amp;v=MjY5NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpoVzcvSkx5dlNkTEc0SDlQTXA0OUVaWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Zhang Zhan,Liu Guangjie,Dai Yuewei,et al.A self-adaptive image steganography algorithm based on cover-coding and Markov model[J].Journal of Computer Research and Development,2012,49(8):1668- 1675 (in Chinese)(张湛,刘光杰,戴跃伟,等.基于隐写编码和Markov模型的自适应图像隐写算法[J].计算机研究与发展,2012,49(8):1668- 1675)
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201407010&amp;v=MjQ0NjRSTE9lWmVSc0Z5emhXNy9KTHl2U2RMRzRIOVhNcUk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Han Tao,Zhu Yuefei,Lin Sisi,et al.Modified matrix encoding based on the spatial distortion model and its improvement[J].Journal of Computer Research and Development,2014,51(7):1467- 1475 (in Chinese)(韩涛,祝跃飞,林斯思,等.基于空域失真模型的修正矩阵编码及其改进[J].计算机研究与发展,2014,51(7):1467- 1475)
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201408010&amp;v=MDU3MDVMRzRIOVhNcDQ5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSc0Z5emhXNy9KTHl2U2Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>Bao Zhenkun,Zhang Weiming,Cheng Sen,et al.±1 Steganographic codes by applying syndrome-trellis codes to dynamic distortion model in pixel chain[J].Journal of Computer Research and Development,2014,51(8):1739- 1747 (in Chinese)(包震坤,张卫明,程森,等.基于像素链动态失真和校验格码的±1隐写编码[J].计算机研究与发展,2014,51(8):1739- 1747)
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787030591173000&amp;v=MjgxNDV1OXVGQ3ZuVTd2TUtGNFZYRnF6R2JPN0h0VEZybzVDWitzUERCTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZa&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Zhao Xianfeng,Zhang Hong.Principles and Techniques of Seganography[M].Beijing:Science Press,2018 (in Chinese)(赵险峰,张弘.隐写学原理与技术[M].北京:科学出版社,2018)
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Minimizing Additive Distortion in Steganography Using Syndrome-Trellis Codes">

                                <b>[6]</b>Filler T,Judas J,Fridrich J,et al.Minimizing additive distortion in steganography using syndrome-trellis codes[J].IEEE Transactions on Information Forensics and Security,2011,6(3):920- 935
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using high-dimensional image models to perform highly undetectable steganography">

                                <b>[7]</b>Pevný T,Filler T,Bas P.Using high-dimensional image models to perform highly undetectable steganography[G] // LNCS 6387:Proc of the 12th Int Conf on Information Hiding.Berlin:Springer,2010:161- 171
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Designing Steganographic Distortion Using Directional Filters">

                                <b>[8]</b>Holub V,Fridrich J.Designing steganographic distortion using directional filters[C] //Proc of the 2012 IEEE Int Workshop on Information Forensics and Security.Piscataway,NJ:IEEE,2012:234- 239
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Uniform embedding for efficient JPEG steganography">

                                <b>[9]</b>Guo Linjie,Ni Jiangqun,Shi Yunqing.Uniform embedding for efficient JPEG steganography[J].IEEE Transactions on Information Forensics and Security,2014,9(5):814- 825
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Universal distortion function for steganography in an arbitrary domain[OL]">

                                <b>[10]</b>Holub V,Fridrich J,Denemark T.Universal distortion function for steganography in an arbitrary domain[OL].[2019-06-01].https://doi.org/10.1186/1687-417X-2014-1
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multivariate Gaussian model for designing additive distortion for steganography">

                                <b>[11]</b>Fridrich J,Kodovsky J.Multivariate Gaussian model for designing additive distortion for steganography[C] //Proc of the 2013 IEEE ICASSP.Piscataway,NJ:IEEE,2016:26- 31
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new cost function for spatial image steganography">

                                <b>[12]</b>Li Bin,Wang Ming,Huang Jiwu,et al.A new cost function for spatial image steganography[C] //Proc of the 2014 IEEE Int Conf on Image Processing (ICIP).Piscataway,NJ:IEEE,2014:4206- 4210
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Content-adaptive steganography by minimizing statistical detectability">

                                <b>[13]</b>Sedighi V,Cogranne R,Fridrich J.Content-adaptive steganography by minimizing statistical detectability[J].IEEE Transactions on Information Forensics and Security,2016,11(2):221- 234
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201812008&amp;v=MjMyODF5dlNkTEc0SDluTnJZOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUnNGeXpoVzcvSkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Wang Lina,Wang Kaige,Xu Yibo,et al.An evaluation of carrier security for image steganography based on residual co-occurrence probability[J].Journal of Computer Research and Development,2018,55(12):2664- 2673 (in Chinese)(王丽娜,王凯歌,徐一波,等.基于残差共生概率的隐写图像载体安全性评价[J].计算机研究与发展,2018,55(12):2664- 2673)
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Steganalysis by Subtractive Pixel Adjacency Matrix">

                                <b>[15]</b>Pevny T,Bas P,Fridrich J.Steganalysis by subtractive pixel adjacency matrix[J].IEEE Transactions on Information Forensics and Security,2010,5(2):215- 224
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rich Models for Steganalysis of Digital Images">

                                <b>[16]</b>Fridrich J,Kodovsky J.Rich models for steganalysis of digital images[J].IEEE Transactions on Information Forensics and Security,2012,7(3):868- 882
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Random projections of residuals for digital image steganalysis">

                                <b>[17]</b>Holub V,Fridrich J.Random projections of residuals for digital image steganalysis[J].IEEE Transactions on Information Forensics and Security,2013,8(12):1996- 2006
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Selection-channel-aware rich model for Steganalysis of digital images">

                                <b>[18]</b>Denemark T,Sedighi V,Holub V,et al.Selection-channel-aware rich model for steganalysis of digital images[C] //Proc of the 2014 IEEE Int Workshop on Information Forensics and Security (WIFS).Piscataway,NJ:IEEE,2014:48- 53
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Steganalysis Based on Embedding Probabilities of Pixels">

                                <b>[19]</b>Tang Weixuan,Li Haodong,Luo Weiqi,et al.Adaptive steganalysis based on embedding probabilities of pixels[J].IEEE Transactions on Information Forensics and Security,2016,11(4):734- 745
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked convolutional auto-encoders for steganalysis of digital images">

                                <b>[20]</b>Tan Shunquan,Li Bin.Stacked convolutional auto-encoders for steganalysis of digital images[C/L] //Proc of the 2014 Signal and Information Processing Association Annual Summit and Conf.Piscataway,NJ:IEEE,2014.[2019-06-01].https://ieeexplore.ieee.org/document/7041565
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning for steganalysis via convolutional neural networks">

                                <b>[21]</b>Qian Yinlong,Dong Jing,Wang Wei,et al.Deep learning for steganalysis via convolutional neural networks[G] //LNCS 9409:Proc of the 2015 SPIE Electronic Imaging.Berlin:Springer,2015
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Structural Design of Convolutional Neural Networks for Steganalysis">

                                <b>[22]</b>Xu Guanshuo,Wu Hanzhou,Shi Yunqing.Structural design of convolutional neural networks for steganalysis[J].IEEE Signal Processing Letters,2016,23(5):708- 712
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Steganalysis based on awareness of selection-channel and deep learning">

                                <b>[23]</b>Yang Jianhua,Liu Kai,Kang Xiangui,et al.Steganalysis based on awareness of selection-channel and deep learning[C] // Proc of the 16th Int Workshop on Digital Forensics and Watermarking.Berlin:Springer,2017:263- 272
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Learning Hierarchical Representations for Image Steganalysis">

                                <b>[24]</b>Ye Jian,Ni Jiangqun,Yi Yang.Deep learning hierarchical representations for image steganalysis[J].IEEE Transactions on Information Forensics and Security,2017,12(11):2545- 2557
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep residual network for steganalysis of digital images">

                                <b>[25]</b>Boroumand M,Chen M,Fridrich J,et al.Deep residual network for steganalysis of digital images[J].IEEE Transactions on Information Forensics and Security,2019,14(5):1181- 1193
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep convolutional neural network to detect J-UNIWARD">

                                <b>[26]</b>Xu Guanshuo.Deep convolutional neural network to detect J-UNIWARD[C] //Proc of the 5th ACM Workshop on Information Hiding and Multimedia Security.New York:ACM,2017:67- 73
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=JPEG-phase-aware convolutional neural network for steganalysis of JPEG images">

                                <b>[27]</b>Chen Mo,Sedighi V,Boroumand M,et al.JPEG-phaseaware convolutional neural network for steganalysis of JPEG images[C] // Proc of the 5th ACM Workshop on Information Hiding and Multimedia Security.New York:ACM,2017,75- 84
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large-scale JPEG image steganalysis using hybrid deep-learning framework">

                                <b>[28]</b>Zeng Jishen,Tan Shunquan,Li Bin,et al.Large-scale JPEG image steganalysis using hybrid deep-learning framework[J].IEEE Transactions on Information Forensics and Security,2017,13(5):1200- 1214
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=JPEG steganalysis based on DenseNet">

                                <b>[29]</b>Yang Jianhua,Shi Yunqing,Wong E K,et al.JPEG steganalysis based on DenseNet[J].arXiv preprint arXiv:1711.09335,2017
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Densely connected convolutional networks">

                                <b>[30]</b>Huang Gao,Liu Zhuang,Maaten L V D,et al.Densely connected convolutional networks[C] //Proc of the 2017 IEEE Conf on Computer Vision and Pattern Recognition (CVPR).Piscataway,NJ:IEEE,2017:2261- 2269
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">

                                <b>[31]</b>Ioffe S,Szegedy C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C] //Proc of the 32nd Int Conf on Machine Leaning -Volume 37.New York:ACM,2015:448- 456
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=U-Net:Convolutional Networks for Biomedical Image Segmentation">

                                <b>[32]</b>Ronneberger O,Fischer P,Brox T,et al.U-Net:Convolutional networks for biomedical image segmentation[G] //LNCS 9351:Proc of MICCAI 2015.Berlin:Springer,2015:234- 241
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Break our steganographic system&amp;quot;:The ins and outs of organizing BOSS">

                                <b>[33]</b>Bas P,Filler T,Pevný T.“Break our steganographic system”:The ins and outs of organizing BOSS[G] //LNCS 9351:Proc of MICCAI 2015.Berlin:Springer,2015:234- 241
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_34" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization">

                                <b>[34]</b>Kingma D P,Ba J.Adam:A method for stochastic optimization[J].arXiv preprint arXiv:1412.6980,2014<image href="images/JFYZ201910020_071.jpg" type="" display="inline" placement="inline"><alt></alt></image>Ren Weixiang,born in 1987.PhD candidate.His main research interests include information hiding,machine learning and deep learning.<image href="images/JFYZ201910020_072.jpg" type="" display="inline" placement="inline"><alt></alt></image>Zhai Liming,born in 1988.PhD candidate.His main research interests include stegano-graphy and steganalysis.(limingzhai@whu.edu.cn)<image href="images/JFYZ201910020_073.jpg" type="" display="inline" placement="inline"><alt></alt></image>Wang Lina,born in 1964.PhD,professor.Member of CCF.Her main research interests include system security and steganalysis.<image href="images/JFYZ201910020_074.jpg" type="" display="inline" placement="inline"><alt></alt></image>Jia Ju,born in 1990.PhD candidate.His main research interests include steganography and steganalysis.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201910020" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201910020&amp;v=MDAwNDFyQ1VSTE9lWmVSc0Z5emhXNy9KTHl2U2RMRzRIOWpOcjQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDZ3NE9EWlZSUU4yZ2VEdEtxcThmND0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

