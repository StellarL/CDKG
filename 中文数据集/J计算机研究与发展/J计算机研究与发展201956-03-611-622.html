<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133238025440000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201903016%26RESULT%3d1%26SIGN%3dqspASaIKtLH1EdWgbfLPrVVzn1Q%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201903016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201903016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201903016&amp;v=MDU4NDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3blVyN0lMeXZTZExHNEg5ak1ySTlFWW9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#67" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="&lt;b&gt;1.1 基于专业感知设备感知情绪&lt;/b&gt;"><b>1.1 基于专业感知设备感知情绪</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;1.2 基于社交网络感知情绪&lt;/b&gt;"><b>1.2 基于社交网络感知情绪</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;1.3 基于智能手机数据感知情绪&lt;/b&gt;"><b>1.3 基于智能手机数据感知情绪</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#77" data-title="&lt;b&gt;2 数据集介绍与问题定义&lt;/b&gt; "><b>2 数据集介绍与问题定义</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="&lt;b&gt;2.1 数据集介绍&lt;/b&gt;"><b>2.1 数据集介绍</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;2.2 问题定义&lt;/b&gt;"><b>2.2 问题定义</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="&lt;b&gt;3 方法概览&lt;/b&gt; "><b>3 方法概览</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#100" data-title="&lt;b&gt;4 核心方法&lt;/b&gt; "><b>4 核心方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#101" data-title="&lt;b&gt;4.1 特征抽取&lt;/b&gt;"><b>4.1 特征抽取</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;4.2 特征选择&lt;/b&gt;"><b>4.2 特征选择</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;4.3 模型训练与在线识别&lt;/b&gt;"><b>4.3 模型训练与在线识别</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#184" data-title="&lt;b&gt;5 实验验证&lt;/b&gt; "><b>5 实验验证</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#185" data-title="&lt;b&gt;5.1 实验数据&lt;/b&gt;"><b>5.1 实验数据</b></a></li>
                                                <li><a href="#188" data-title="&lt;b&gt;5.2 实验方法&lt;/b&gt;"><b>5.2 实验方法</b></a></li>
                                                <li><a href="#198" data-title="&lt;b&gt;5.3 实验结果&lt;/b&gt;"><b>5.3 实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#218" data-title="&lt;b&gt;6 总 结&lt;/b&gt; "><b>6 总 结</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="&lt;b&gt;表1 StudentLife感知数据&lt;/b&gt;"><b>表1 StudentLife感知数据</b></a></li>
                                                <li><a href="#98" data-title="图1 基于移动感知数据的心理压力检测框架">图1 基于移动感知数据的心理压力检测框架</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表2 基于POI的特征&lt;/b&gt;"><b>表2 基于POI的特征</b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;表3 活动信息相关特征&lt;/b&gt;"><b>表3 活动信息相关特征</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;表4 声音相关特征&lt;/b&gt;"><b>表4 声音相关特征</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;表5 蓝牙相关特征&lt;/b&gt;"><b>表5 蓝牙相关特征</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表6 用户睡眠信息&lt;/b&gt;"><b>表6 用户睡眠信息</b></a></li>
                                                <li><a href="#187" data-title="&lt;b&gt;表7 样本数量&lt;/b&gt;"><b>表7 样本数量</b></a></li>
                                                <li><a href="#206" data-title="图2 对比其他分类方法">图2 对比其他分类方法</a></li>
                                                <li><a href="#208" data-title="&lt;b&gt;表8 本篇论文方法效果&lt;/b&gt;"><b>表8 本篇论文方法效果</b></a></li>
                                                <li><a href="#212" data-title="图3 模型效果随特征数量的变化">图3 模型效果随特征数量的变化</a></li>
                                                <li><a href="#216" data-title="图4 模型评估指标随协同训练迭代轮数变化">图4 模型评估指标随协同训练迭代轮数变化</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="260">


                                    <a id="bibliography_1" title="America College Health Association. Fall 2015 reference group executive summary[EB/OL]. 2015 [2017-01-23]. https://www.acha.org/documents/ncha/NCHA-II_FALL_2017_REFERENCE_GROUP_EXECUTIVE_SUMMARY.pdf" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fall 2015 reference group executive summary">
                                        <b>[1]</b>
                                        America College Health Association. Fall 2015 reference group executive summary[EB/OL]. 2015 [2017-01-23]. https://www.acha.org/documents/ncha/NCHA-II_FALL_2017_REFERENCE_GROUP_EXECUTIVE_SUMMARY.pdf
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_2" title="Kirsten S. Statistics on college student stress[EB/OL]. 2015 [2017-01-23]. http://stress.lovetoknow.com/Statistics_on_College_Student_Stress" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Statistics on college student stress">
                                        <b>[2]</b>
                                        Kirsten S. Statistics on college student stress[EB/OL]. 2015 [2017-01-23]. http://stress.lovetoknow.com/Statistics_on_College_Student_Stress
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_3" title="Selye H. Stress in Health and Disease[M]. Oxford: Butterworth-Heinemann, 1974" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stress in Health and Disease">
                                        <b>[3]</b>
                                        Selye H. Stress in Health and Disease[M]. Oxford: Butterworth-Heinemann, 1974
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_4" title="Kahneman D, Tursky B, Shapiro D, et al. Pupillary, heart rate, and skin resistance changes during a mental task[J]. Journal of Experimental Psychology, 1969, 79 (1) : 164- 167" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pupillary, heart rate, and skin resistance changes during a mental task">
                                        <b>[4]</b>
                                        Kahneman D, Tursky B, Shapiro D, et al. Pupillary, heart rate, and skin resistance changes during a mental task[J]. Journal of Experimental Psychology, 1969, 79 (1) : 164- 167
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_5" title="Wang Rui, Chen Fanglin, Chen Zhenyu, et al. StudentLife: Assessing mental health, academic performance and behavioral trends of college students using smartphones[C] //Proc of the 2014 ACM Conf on Ubiquitous Computing. NewYork: ACM, 2014: 3- 14" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Student Life:assessing mental health,academic performance and behavioral trends of college students using smartphones">
                                        <b>[5]</b>
                                        Wang Rui, Chen Fanglin, Chen Zhenyu, et al. StudentLife: Assessing mental health, academic performance and behavioral trends of college students using smartphones[C] //Proc of the 2014 ACM Conf on Ubiquitous Computing. NewYork: ACM, 2014: 3- 14
                                    </a>
                                </li>
                                <li id="270">


                                    <a id="bibliography_6" title="Hetz C, Martinon F, Rodriguez D, et al. The unfolded protein response: Integrating stress signals through the stress sensor IRE1α[J]. Physiological Reviews, 2011, 91 (4) : 1219- 1243" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Unfolded Protein Response: Integrating Stress Signals Through the Stress Sensor IRE1{alpha}">
                                        <b>[6]</b>
                                        Hetz C, Martinon F, Rodriguez D, et al. The unfolded protein response: Integrating stress signals through the stress sensor IRE1α[J]. Physiological Reviews, 2011, 91 (4) : 1219- 1243
                                    </a>
                                </li>
                                <li id="272">


                                    <a id="bibliography_7" title="Healey J A, Picard R W. Detecting stress during real-world driving tasks using physiological sensors[J]. IEEE Transactions on Intelligent Transportation Systems, 2005, 6 (2) : 156- 166" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting stress during real-world driving tasks using physiological sensors">
                                        <b>[7]</b>
                                        Healey J A, Picard R W. Detecting stress during real-world driving tasks using physiological sensors[J]. IEEE Transactions on Intelligent Transportation Systems, 2005, 6 (2) : 156- 166
                                    </a>
                                </li>
                                <li id="274">


                                    <a id="bibliography_8" title="Mozos M, Sandulescu V, Andrews S. Stress detection using wearable physiological and sociometric sensors[J]. International Journal of Neural Systems, 2017, 27 (2) : 1- 17" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stress detection using wearable physiological and sociometric sensors">
                                        <b>[8]</b>
                                        Mozos M, Sandulescu V, Andrews S. Stress detection using wearable physiological and sociometric sensors[J]. International Journal of Neural Systems, 2017, 27 (2) : 1- 17
                                    </a>
                                </li>
                                <li id="276">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                    Lu Hong, Frauendorfer D, Rabbi M, et al. StressSense: Detecting stress in unconstrained acoustic environments using smartphones[C] //Proc of the 2012 ACM Conf on Ubiquitous Computing. New York: ACM, 2012: 351- 360</a>
                                </li>
                                <li id="278">


                                    <a id="bibliography_10" title="Lin Huijie, Jia Jia, Guo Quan, et al. Psychological stress detection from cross-media microblog data using deep sparse neural network[C] //Proc of the 2014 IEEE Int Conf on Multimedia and Expo. Piscataway, NJ: IEEE, 2014: 1- 6" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Psychological stress detection from cross-media microblog data using deep sparse neural network">
                                        <b>[10]</b>
                                        Lin Huijie, Jia Jia, Guo Quan, et al. Psychological stress detection from cross-media microblog data using deep sparse neural network[C] //Proc of the 2014 IEEE Int Conf on Multimedia and Expo. Piscataway, NJ: IEEE, 2014: 1- 6
                                    </a>
                                </li>
                                <li id="280">


                                    <a id="bibliography_11" title="Lin Huijie, Jia Jia, Guo Quan, et al. User-level psychological stress detection from social media using deep neural network[C] //Proc of the 22nd ACM Int Conf on Multimedia. New York: ACM, 2014: 507- 516" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=User-level psychological stress detection from social media using deep neural network">
                                        <b>[11]</b>
                                        Lin Huijie, Jia Jia, Guo Quan, et al. User-level psychological stress detection from social media using deep neural network[C] //Proc of the 22nd ACM Int Conf on Multimedia. New York: ACM, 2014: 507- 516
                                    </a>
                                </li>
                                <li id="282">


                                    <a id="bibliography_12" title="Xue Yuanyuan, Li Qi, Jin Li, et al. Detecting adolescent psychological pressures from micro-blog[G] //LNCS 8423: Proc of the 3rd Int Conf on Health Information Science. Berlin: Springer, 2014: 83- 94" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting adolescent psychological pressures form Micro-Blog">
                                        <b>[12]</b>
                                        Xue Yuanyuan, Li Qi, Jin Li, et al. Detecting adolescent psychological pressures from micro-blog[G] //LNCS 8423: Proc of the 3rd Int Conf on Health Information Science. Berlin: Springer, 2014: 83- 94
                                    </a>
                                </li>
                                <li id="284">


                                    <a id="bibliography_13" title="Jin Li, Xue Yuanyuan, Li Qi, et al. Integrating human mobility and social media for adolescent psychological stress detection[G] //LNCS 9643: Proc of the 21st Int Conf on Database Systems for Advanced Applications. Berlin: Springer, 2016: 367- 382" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Integrating human mobility and social media for adolescent psychological stress detection">
                                        <b>[13]</b>
                                        Jin Li, Xue Yuanyuan, Li Qi, et al. Integrating human mobility and social media for adolescent psychological stress detection[G] //LNCS 9643: Proc of the 21st Int Conf on Database Systems for Advanced Applications. Berlin: Springer, 2016: 367- 382
                                    </a>
                                </li>
                                <li id="286">


                                    <a id="bibliography_14" title="Chen Longbiao, Li Shijian, Pan Gang. Smartphone:Pervasive sensing and applications[J]. Chinese Journal of Computers, 2015, 38 (2) : 423- 438 (in Chinese) (陈龙彪, 李石坚, 潘纲. 智能手机:普适感知与应用[J]. 计算机学报, 2015, 38 (2) : 423- 438) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201502017&amp;v=MzI2MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N25VcjdJTHo3QmRyRzRIOVRNclk5RVk0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Chen Longbiao, Li Shijian, Pan Gang. Smartphone:Pervasive sensing and applications[J]. Chinese Journal of Computers, 2015, 38 (2) : 423- 438 (in Chinese) (陈龙彪, 李石坚, 潘纲. 智能手机:普适感知与应用[J]. 计算机学报, 2015, 38 (2) : 423- 438) 
                                    </a>
                                </li>
                                <li id="288">


                                    <a id="bibliography_15" title="Mehrotra A, Pejovic V, Vermeulen J, et al. My phone and me: Understanding people’s receptivity to mobile notifi-cations[C] //Proc of the 2016 CHI Conf on Human Factors in Computing Systems. New York: ACM, 2016: 1021- 1032" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=My phone and me: Understanding people&amp;#39;&amp;#39;s receptivity to mobile notifi-cations">
                                        <b>[15]</b>
                                        Mehrotra A, Pejovic V, Vermeulen J, et al. My phone and me: Understanding people’s receptivity to mobile notifi-cations[C] //Proc of the 2016 CHI Conf on Human Factors in Computing Systems. New York: ACM, 2016: 1021- 1032
                                    </a>
                                </li>
                                <li id="290">


                                    <a id="bibliography_16" title="Xiong Haoyi, Huang Yu, Barnes L E, et al. Sensus: A cross-platform, general-purpose system for mobile crowd-sensing in human-subject studies[C] //Proc of the 2016 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2016: 415- 426" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sensus: A cross-platform, general-purpose system for mobile crowd-sensing in human-subject studies">
                                        <b>[16]</b>
                                        Xiong Haoyi, Huang Yu, Barnes L E, et al. Sensus: A cross-platform, general-purpose system for mobile crowd-sensing in human-subject studies[C] //Proc of the 2016 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2016: 415- 426
                                    </a>
                                </li>
                                <li id="292">


                                    <a id="bibliography_17" title="Canzian L, Musolesi M. Trajectories of depression: Unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis[C] //Proc of the 2015 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2015: 1293- 1304" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Trajectories of depression:unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis">
                                        <b>[17]</b>
                                        Canzian L, Musolesi M. Trajectories of depression: Unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis[C] //Proc of the 2015 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2015: 1293- 1304
                                    </a>
                                </li>
                                <li id="294">


                                    <a id="bibliography_18" title="Lu Hong, Frauendorfer D, Rabbi M, et al. StressSense: Detecting stress in unconstrained acoustic environments using smartphones[C] //Proc of the 2012 ACM Conf on Ubiquitous Computing. New York: ACM, 2012: 351- 360" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=StressSense:Detecting Stress in Unconstrained Acoustic Environments using Smartphones">
                                        <b>[18]</b>
                                        Lu Hong, Frauendorfer D, Rabbi M, et al. StressSense: Detecting stress in unconstrained acoustic environments using smartphones[C] //Proc of the 2012 ACM Conf on Ubiquitous Computing. New York: ACM, 2012: 351- 360
                                    </a>
                                </li>
                                <li id="296">


                                    <a id="bibliography_19" title="Bogomolov A, Lepri B, Ferron M, et al. Daily stress recognition from mobile phone data, weather conditions and individual traits[C] //Proc of the 22nd ACM Int Conf on Multimedia. New York: ACM, 2014: 477- 486" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Daily stress recognition from mobile phone data, weather conditions and individual traits">
                                        <b>[19]</b>
                                        Bogomolov A, Lepri B, Ferron M, et al. Daily stress recognition from mobile phone data, weather conditions and individual traits[C] //Proc of the 22nd ACM Int Conf on Multimedia. New York: ACM, 2014: 477- 486
                                    </a>
                                </li>
                                <li id="298">


                                    <a id="bibliography_20" title="Wang Rui, Harari G, Hao Peilin, et al. SmartGPA: How smartphones can assess and predict academic performance of college students[C] //Proc of the 2015 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2015: 295- 306" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SmartGPA:How smartphones can assess and predict academic performance of college students">
                                        <b>[20]</b>
                                        Wang Rui, Harari G, Hao Peilin, et al. SmartGPA: How smartphones can assess and predict academic performance of college students[C] //Proc of the 2015 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2015: 295- 306
                                    </a>
                                </li>
                                <li id="300">


                                    <a id="bibliography_21" title="Shiffman S, Stone A, Hufford R. Ecological momentary assessment[J]. Annual Review of Clinical Psychology, 2008, 4: 1- 32" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SARD&amp;filename=SARD00000005539&amp;v=MTQ5ODk0OUFZZWdHWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVmIzSklWND1OaXpaYXJPNEh0SE1y&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        Shiffman S, Stone A, Hufford R. Ecological momentary assessment[J]. Annual Review of Clinical Psychology, 2008, 4: 1- 32
                                    </a>
                                </li>
                                <li id="302">


                                    <a id="bibliography_22" title="Lu Hong, Yang Jun, Liu Zhigang, et al. The Jigsaw continuous sensing engine for mobile phone applications[C] //Proc of the 8th ACM Conf on Embedded Networked Sensor Systems. New York: ACM, 2010: 71- 84" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Jigsaw Continuous Sensing Engine for Mobile Phone Applications">
                                        <b>[22]</b>
                                        Lu Hong, Yang Jun, Liu Zhigang, et al. The Jigsaw continuous sensing engine for mobile phone applications[C] //Proc of the 8th ACM Conf on Embedded Networked Sensor Systems. New York: ACM, 2010: 71- 84
                                    </a>
                                </li>
                                <li id="304">


                                    <a id="bibliography_23" title="Zheng Yu, Liu Furui, Hsieh P. U-air: When urban air quality inference meets big data[C] //Proc of the 19th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2013: 1436- 1444" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=U-air:When urban air quality inference meets big data">
                                        <b>[23]</b>
                                        Zheng Yu, Liu Furui, Hsieh P. U-air: When urban air quality inference meets big data[C] //Proc of the 19th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2013: 1436- 1444
                                    </a>
                                </li>
                                <li id="306">


                                    <a id="bibliography_24" title="Blum A, Mitchell T. Combining labeled and unlabeled data with co-training[C] //Proc of the 11th Annual Conf on Computational Learning Theory. New York: ACM, 1998: 92- 100" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining Labeled and Unlabeled Data with Co-Training">
                                        <b>[24]</b>
                                        Blum A, Mitchell T. Combining labeled and unlabeled data with co-training[C] //Proc of the 11th Annual Conf on Computational Learning Theory. New York: ACM, 1998: 92- 100
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(03),611-622 DOI:10.7544/issn1000-1239.2019.20170809            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于智能手机感知数据的心理压力评估方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%B8%B0&amp;code=23477297&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王丰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%BA%9A%E6%B2%99&amp;code=06263791&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王亚沙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%B1%9F%E6%B6%9B&amp;code=22611280&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王江涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%86%8A%E6%98%8A%E4%B8%80&amp;code=41425016&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">熊昊一</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E4%BF%8A%E5%B3%B0&amp;code=06277322&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵俊峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%A4%A7%E5%BA%86&amp;code=06276384&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张大庆</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%AB%98%E5%8F%AF%E4%BF%A1%E8%BD%AF%E4%BB%B6%E6%8A%80%E6%9C%AF%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6)&amp;code=0038515&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高可信软件技术教育部重点实验室(北京大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0220478&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京大学信息科学技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%92%8C%E4%BF%A1%E6%81%AF%E9%9B%86%E6%88%90%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=1515719&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机网络和信息集成教育部重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%9B%BD%E5%AE%B6%E5%B7%A5%E7%A8%8B%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京大学软件工程国家工程研究中心</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%AF%86%E8%8B%8F%E9%87%8C%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E7%B3%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">密苏里科技大学计算机科学系</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>较大的心理压力对大学生的心理和生理均会产生危害.心理压力往往在前期容易被人忽视, 从而导致严重的问题.因此, 如果能较早发现心理压力, 并进行合理干预, 有益于人的身心健康.传统心理压力检测方法以问卷调查和借助专业设备的评估为主, 但都存在成本较高, 且对被评估对象侵扰较大等不足.另一方面, 随着智能手机的快速普及, 通过手机中内置的位置、声音、加速度等多种传感器感知用户的行为习惯, 并基于感知数据评估用户心理压力成为一种低成本、低侵扰的心理压力评估手段.在此背景下, 针对基于智能手机感知数据分析, 对评估大学生心理压力的方法展开了研究, 从感知数据中提取合理的特征, 提出了一种更高效的心理压力评估方法.首先, 讨论了如何从原始的手机感知数据提取出合理的特征;其次, 介绍将心理压力评估转化为分类问题, 并使用半监督学习方法构造分类模型;最后, 在开放数据集StudentLife上对上述模型进行实验验证.实现结果表明:该方法在心理压力检测精确度和召回率等方面均优于基线方法.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BF%83%E7%90%86%E5%8E%8B%E5%8A%9B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">心理压力;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E5%A2%83%E6%84%9F%E7%9F%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情境感知;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征工程;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E5%8A%A8%E8%AF%84%E4%BC%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自动评估;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *王亚沙, wangyasha@pku.edu.cn;
                                </span>
                                <span>
                                    王丰, wangfeng2013@pku.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-10-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61772045);</span>
                    </p>
            </div>
                    <h1><b>Mental Stress Assessment Approach Based on Smartphone Sensing Data</b></h1>
                    <h2>
                    <span>Wang Feng</span>
                    <span>Wang Yasha</span>
                    <span>Wang Jiangtao</span>
                    <span>Xiong Haoyi</span>
                    <span>Zhao Junfeng</span>
                    <span>Zhang Daqing</span>
            </h2>
                    <h2>
                    <span>Key Laboratory of High Confidence Software Technologies (Peking University) , Ministry of Education</span>
                    <span>School of Electronics Engineering and Computer Science, Peking University</span>
                    <span>Key Laboratory of Computer Network and Information Integration (Southeast University) , Ministry of Education</span>
                    <span>National Research Center of Software Engineering, Peking University</span>
                    <span>Department of Computer Science, Missouri University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Mental stress is harmful on individuals' physical and mental well-being. It is often easy to be overlooked in the early stage, leading to serious problems. Therefore, it is crucial to detect stress before it evolves into severe problems. Traditional stress detection methods are based on either questionnaires or professional devices, which are time-consuming, costly and intrusive. With the popularity of smartphones with various embedded sensors, which can capture users' context data contains movement, sound, location and so on, it is an alternative way to access users' behavior by smartphones, which is less intrusive. This paper proposes an automatic and non-intrusive stress detection approach based on mobile sensing data captured by smartphones. By extracting reasonable features from the perceived data, a more efficient psychological stress assessment method is proposed. First, we generate lots of features represent users' behavior and explore the correlation between mobile sensing data and stress, then identify discriminative features. Second, we further develop a semi-supervised learning based stress detection model. Specifically, we use techniques such as co-training and random forest to deal with insufficient data. Finally, we evaluate our model based on the StudentLife dataset, and the experimental results verify the advantages of our approach over other baselines.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=mental%20stress&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">mental stress;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=context%20awareness&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">context awareness;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20engineering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature engineering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=automatic%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">automatic detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Wang Feng, born in 1995.Master candidate at the School of Electronic Engineering and Computer Science, Peking University, China.His main research interest is mobile crowd sensing.<image id="254" type="formula" href="images/JFYZ201903016_25400.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Yasha, born in 1975.Professor and PhD supervisor at Peking University.His main research interests include urban data analytics, ubiquitous computing, software reuse, and online software development environment.<image id="255" type="formula" href="images/JFYZ201903016_25500.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Wang Jiangtao, born in 1987.PhD.Assistant professor at Peking University.His main research interests include collaborative sensing, mobile computing, and ubiquitous computing.<image id="256" type="formula" href="images/JFYZ201903016_25600.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Xiong Haoyi, born in 1987.PhD.Assistant professor at the Department of Computer Science, Missouri University of Science and Technology, Rolla, MO, USA.His main research interests include ubiquitous data science, crowdsourcing, and applied optimization&amp;statistics.<image id="257" type="formula" href="images/JFYZ201903016_25700.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Zhao Junfeng, born in 1974.PhD.Associate professor at Peking University.Her research interests include software engineering, sofeware reuse, medical data analysis.<image id="258" type="formula" href="images/JFYZ201903016_25800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Zhang Daqing, born in 1965.PhD.Professor at Peking University, China, and Telecom SudParis, France.His main research interests include context-aware computing, urban computing, mobile computing.<image id="259" type="formula" href="images/JFYZ201903016_25900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2017-10-25</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61772045);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="57">在快节奏的生活中, 越来越多的人会受到心理压力的影响.美国大学健康协会 (America College Health Association) 在2015年秋季出具的心理学报告<citation id="308" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>中表明有57.7%的学生在过去的12个月中, 至少一次感受到“非常焦虑”.同时, 有研究表明人感受到的压力会显著影响心理和行为习惯, 当人们感受到巨大压力时, 往往会显得焦虑不安、失眠, 严重的可能会导致心理甚至生理疾病<citation id="309" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>.更有调查指出, 在中途辍学的大学学生中, 有64%是受到了精神方面的疾病的影响<citation id="310" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.这种由压力带来的心理疾病, 在初期难以被重视, 可能会发展成严重的问题, 进而对一个人造成巨大影响<citation id="311" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>.因此, 在心理压力转化成严重的心理问题之前及时检测心理压力对大学生心理健康方面有很重要的意义.</p>
                </div>
                <div class="p1">
                    <p id="58">近些年来, 心理压力的检测越来越受到重视.就如何合理检测人的心理压力, 心理学领域已经做出了很多的研究.最为传统的方法就是利用依据心理学理论制定的调查问卷, 由于其背后的理论支撑, 这种方法现在依然是使用最为广泛的调查方法.其次, 人的心理压力也可以通过专业的仪器进行监控, 比如人的皮肤电阻可以和某些心理指标建立联系<citation id="312" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 监控皮肤电阻即可完成对心理指标的检测, 且结果可信度较高.但是, 这些方法并不适用于日常的心理压力监控.无论是基于问卷还是专业仪器, 由于都需要用户提供额外的时间成本参与测试, 对用户造成了较大的侵扰, 导致参与积极性不高;因此, 我们希望找到一种自动的、低成本、低侵扰的方法来实现对用户的实时心理压力监控.与此同时, 智能手机已经成为了人们生活的必需品.为了满足人们生活中更多的需求, 手机中也加入了越来越多的感知设备 (比如加速度传感器、声传感器、光传感器等) .在日常生活中, 手机可以持续记录大量和人的日常生活相关的的感知数据, 包括运动信息、位置信息、手机使用信息等数据.</p>
                </div>
                <div class="p1">
                    <p id="59">与此同时, 有研究表明:人的心理压力状态会在人的行为习惯上得到反映, 比如在压力较大的状态下, 人们往往呈现出活动积极性降低、频繁使用手机、睡眠质量较低等状态<citation id="313" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>.手机提供的感知数据可以反映用户的行为习惯特征, 而用户的行为习惯可能和心理压力有某种联系, 因此可以尝试利用手机感知数据, 通过机器学习的方法探究手机感知数据和用户的心理状态之间的联系.</p>
                </div>
                <div class="p1">
                    <p id="60">建立两者之间的联系存在着2项技术挑战.</p>
                </div>
                <div class="p1">
                    <p id="61">1) 如何将基础的手机感知数据转变为有意义的分类特征.原始的手机感知数据以日志形式存在, 每一个时刻会生成相应的数据, 而对心理压力的评估需要综合某一段时间内的用户行为来进行判断, 因此需要将日志数据进行整合, 并提取特征.</p>
                </div>
                <div class="p1">
                    <p id="62">2) 如何解决带标记的训练数据不足的问题.在数据采集阶段, 智能手机可以低成本、持续采集各类数据并生成特征向量.然而, 每个特征向量所对应的标记数据需要用户主动标注, 无法大量获取, 导致带标记的训练数据稀少.因此, 如何在带标记的数据不足的情况下进行准确的模型训练是本文要解决的另一个技术挑战.</p>
                </div>
                <div class="p1">
                    <p id="63">本文针对上述挑战, 利用机器学习的手段, 提出了基于智能手机感知数据的心理压力评估方法.主要贡献包括3个方面:</p>
                </div>
                <div class="p1">
                    <p id="64">1) 对原始的手机感知数据进行分析, 提出了特征提取与筛选的方法, 基于这些特征生成用于训练分类模型的样本.通过特征抽取制定出一系列的方法, 将抽象的日志数据转化为了带有标记的样本数据, 通过对特征进行筛选得到真正对分类有用的特征, 减少了数据维度的冗余.</p>
                </div>
                <div class="p1">
                    <p id="65">2) 使用半监督学习模型应对训练数据不足的问题, 本文充分利用大量的没有标注的数据, 使用协同训练 (co-training) 对这些数据进行标注, 并迭代训练, 提高模型分类精度.</p>
                </div>
                <div class="p1">
                    <p id="66">3) 使用了现有的开放数据集 (Dartmouth StudentLife) <citation id="314" type="reference"><link href="268" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>进行验证, 结果证实了本文提出的方法可以对人的心理压力进行有效地监控, 且效果优于其他基线方法.</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag"><b>1 相关工作</b></h3>
                <h4 class="anchor-tag" id="68" name="68"><b>1.1 基于专业感知设备感知情绪</b></h4>
                <div class="p1">
                    <p id="69">由于人的心理变化必然会导致某些生理指标的变化, 因此很多研究致力于利用可穿戴设备对人的日常心理压力进行监控<citation id="315" type="reference"><link href="270" rel="bibliography" /><link href="272" rel="bibliography" /><link href="274" rel="bibliography" /><link href="276" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>.通常, 这些设备上集成了专门的传感器, 可以感知人的生理指标的变化, 例如皮肤的电阻、体温、心率、血压等.由于可以直接获取这些生理数据, 所以基于可穿戴设备进行的感知往往很有说服力, 但是代价是人们需要佩戴这些专业设备, 这就带来了成本较高, 对人打扰程度比较大的问题.而基于手机数据的心理压力感知可以将人从这些专业设备中解脱出来.</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70"><b>1.2 基于社交网络感知情绪</b></h4>
                <div class="p1">
                    <p id="71">随着互联网技术的不断发展, 社交网络也在迅猛发展.基于社交网络的和压力相关的研究也越来越多.Lin等人<citation id="316" type="reference"><link href="278" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>基于微博用户的数据, 利用深度稀疏神经网络对用户的心理压力程度作出判断;之后, Lin等人<citation id="317" type="reference"><link href="280" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>基于微博数据, 使用卷积神经网络检测用户压力;在青少年方面, Xue等人<citation id="318" type="reference"><link href="282" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>从青少年的推特消息出发, 提取了一系列特征, 利用分类器来了解青少年的潜在压力类别和压力水平;Jin等人<citation id="319" type="reference"><link href="284" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了一种基于协同训练的方法, 结合微博和轨迹信息来完成对青少年的压力检测.</p>
                </div>
                <div class="p1">
                    <p id="72">这些基于社交网络的工作通过对人们在社交网络上的行为和发布的内容, 利用自然语言处理以及深度学习可以自动并且在对用户低侵扰的情况下进行心理压力的评估.然而, 这些工作也有一定的局限性, 那就是这些方法只能聚焦于那些频繁使用社交网络的用户, 对于不常使用社交网络的用户, 由于缺乏训练数据较难对其进行心理压力的预测.同时, 由于人们并不会一直使用社交网络, 因此无法通过社交网络数据对一个用户进行不间断的监控, 这些问题也是基于手机感知数据的工作所重视的地方.基于社交网络对用户的心理压力进行评估的方法可以和本文工作形成互补.</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>1.3 基于智能手机数据感知情绪</b></h4>
                <div class="p1">
                    <p id="74">近些年来智能手机不断进步, 为了适应各种使用场景, 提供了更强大的功能, 传感器种类越来越多, 精度也越来越高, 它们记录了用户使用手机的习惯, 提供了大量有价值的数据, 陈龙彪等人<citation id="320" type="reference"><link href="286" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>对智能手机在普适计算领域的应用展开过深入探究.因此也有了越来越多的基于智能手机的感知数据开展的研究, 尤其在情感分析领域.这些工作大致上可以分为2种类型:1) 探究智能手机数据和用户情绪的相关性;2) 训练模型利用智能手机感知数据对用户情绪进行预测.</p>
                </div>
                <div class="p1">
                    <p id="75">在第1类的工作中, Wang等人<citation id="321" type="reference"><link href="288" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>利用Student-Life数据集, 从中提取了多维特征, 利用线性回归的方法, 分析了用户在学期中的行为习惯和用户在学期中的心理压力, 沮丧程度等多种心理指标的关系;Mehrotra等人<citation id="322" type="reference"><link href="288" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>利用用户日常生活中的手机通信数据, 应用使用习惯等提取了一系列特征, 通过线性回归的方法, 分析了多维特征和用户情绪沮丧程度的相关性;Xiong等人<citation id="323" type="reference"><link href="290" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>利用大学生的GPS和POI数据, 利用线性回归的方法, 分析了不同的行为习惯和用户社交焦虑的相关性.这些工作对本文的特征提取工作有着很大的指导意义, 缺陷是这些工作并没有完成预测模型, 本文在这些工作的启发下完成, 并构建了模型对用户心理压力进行预测.</p>
                </div>
                <div class="p1">
                    <p id="76">在第2类工作中, Canzian等人<citation id="324" type="reference"><link href="292" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>通过GPS数据实现了对用户的沮丧程度 (depression) 进行预测, (他们) 从用户的GPS数据中提取多维度的特征, 从PHQ-9问卷中得到用户的沮丧程度, 利用线性回归的方法, 建立了特征和用户的沮丧情绪之间的联系, 并使用SVM构建预测模型, 达到了80%的准确率.该工作的主要问题在于, 其致力于研究用户一段时间内的沮丧程度, 想要达到较好的预测效果, 则需要较长时间的GPS数据 (通常是2周左右) , 无法对用户短时期的心理状态 (以1天为时间窗口) 进行实时评估.同时, 该工作的事实依据选用的是问卷调查结果, 问卷只在实验结束时进行了一次, 所以其无法对用户的实时心理状态进行刻画.Lu等人<citation id="325" type="reference"><link href="294" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>通过手机感知的声音数据, 可以对用户在不同场合的紧张程度进行实时预测, 该方法中用户需要佩戴2部手机采集声音信息, 并利用声学的相关方法提取了一系列特征.使用专业的手环获取用户的真实紧张状态, 最后利用高斯混合模型 (GMM) 对这两者得到的数据建立联系, 实时预测用户紧张程度, 并讨论了如何利用通用模型得到可以更好适配单独用户的个性化模型, 最后个性化模型达到了约80%的准确率.这个工作虽然能够实时且精确地预测用户的紧张程度, 可是其数据采集设备对用户的打扰程度较高, 不适用于日常生活中对用户进行心理压力的检测.Bogomolov等人<citation id="326" type="reference"><link href="296" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>在使用手机收集到的通信数据 (包括手机通话数据和短信数据) 之外, 还使用了天气数据和用户的心理学问卷信息, 利用决策树构建模型, 在预测用户是否有压力的二分类问题中, 取得了72%的准确率.但是, 和本文工作相比, 有2个不同:1) 这个工作中也要求用户完成心理学问卷, 并且结果反映心理学问卷对预测准确度有很大的贡献, 而当只使用收集数据的时候, 模型很难达到较高的精度, 但心理学问卷需要耗费用户的大量时间, 且对用户的打扰程度较大, 本文工作不需要用户去额外填写这些问卷, 同时也达到了可以接受的模型精确度;2) 这个工作中没有考虑如何利用未标记数据, 而在本论文中, 本文通过协同训练使用了大量的没有标记的数据用于训练, 可以有效提高模型的预测精度.</p>
                </div>
                <h3 id="77" name="77" class="anchor-tag"><b>2 数据集介绍与问题定义</b></h3>
                <h4 class="anchor-tag" id="78" name="78"><b>2.1 数据集介绍</b></h4>
                <div class="p1">
                    <p id="79">为了训练模型, 本文使用了开放数据集Student-Life<citation id="327" type="reference"><link href="268" rel="bibliography" /><link href="298" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">20</a>]</sup></citation>.StudentLife数据集是Dartmouth学院的研究团队于2013年在StudentLife Study中获取的数据集.在研究中, 学生被要求使用安装有Student-Life程序的手机, 手机在后台记录了一系列信息.这次研究一共收集了49个学生连续10周的感知数据.这些数据大致分为4个类别:传感器数据、EMA (ecological momentary assessment) 数据、问卷调查数据、学业数据.</p>
                </div>
                <div class="p1">
                    <p id="80">本文使用了StudentLife数据集中的传感器数据和EMA数据, 其中, 传感器数据包含了所有利用手机传感器得到的数据, 描述了人在使用手机的过程中活动信息、环境信息、手机使用习惯信息等.EMA数据是即时的生理状态评估, 用户在使用软件时会不定期收到简单的问题, 用户对自己的心理状态做出评估后, 实时反馈给服务器<citation id="328" type="reference"><link href="300" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>.</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>2.2 问题定义</b></h4>
                <div class="p1">
                    <p id="82">本文目标是利用手机的感知数据建立模型预测用户的心理压力, 即通过机器学习算法训练一个分类器用来完成分类问题.因此需要明确如何形成用以训练的样本数据.</p>
                </div>
                <div class="p1">
                    <p id="83">训练数据使用StudentLife数据集中的传感器数据, 原始的文件一共分为10个类别, 如表1所示.在试验中, 利用这些数据一共生成了49个学生的2 167个有标记样本数据, 样本生成的方法在第4节会进行详细介绍.</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit"><b>表1 StudentLife感知数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 StudentLife Sensing Data</b></p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td><br />Type Number</td><td>Type</td><td>Description</td></tr><tr><td><br />1</td><td>Activity</td><td>User activity status</td></tr><tr><td><br />2</td><td>Audio</td><td>Audio status around user</td></tr><tr><td><br />3</td><td>Conversation</td><td>Conversation info of user</td></tr><tr><td><br />4</td><td>Bluetooth</td><td>Bluetooth scan log</td></tr><tr><td><br />5</td><td>Dark</td><td>Duration of phone in dark</td></tr><tr><td><br />6</td><td>GPS</td><td>GPS log</td></tr><tr><td><br />7</td><td>Phonecharge</td><td>Duration of phone charge</td></tr><tr><td><br />8</td><td>Phonelock</td><td>Duration of phone lock</td></tr><tr><td><br />9</td><td>WiFi</td><td>WiFi log</td></tr><tr><td><br />10</td><td>WiFi location</td><td>WiFi AP location</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="85">不同于以往的工作使用心理学问卷得到的结论作为样本数据的标注, 为了追求预测的实时性, 需要使用用户实时反馈的心理状态评估, 这里利用了EMA数据.</p>
                </div>
                <div class="p1">
                    <p id="86">在EMA数据中, 真正需要关心的是用户反馈的心理压力数据, EMA问卷中关于心理压力的问题是 (figure) , 用户有5个选项可供选择, 分别是:</p>
                </div>
                <div class="p1">
                    <p id="87">1) 有一点压力 (a little stressed) ;</p>
                </div>
                <div class="p1">
                    <p id="88">2) 确定有压力 (definitely stressed) ;</p>
                </div>
                <div class="p1">
                    <p id="89">3) 压力很大 (stressed out) ;</p>
                </div>
                <div class="p1">
                    <p id="90">4) 感觉较好 (felling good) ;</p>
                </div>
                <div class="p1">
                    <p id="91">5) 感觉好极了 (felling great) .</p>
                </div>
                <div class="p1">
                    <p id="92">为了使类目之间的显著性更大, 综合以往的工作<citation id="329" type="reference"><link href="296" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>, 本文将这5类进行融合, 将1) ～3) 合并为有压力, 将4) 5) 合并为无压力.从而这个分类问题变为二分类问题.2类的物理意义也更加明确.</p>
                </div>
                <div class="p1">
                    <p id="93">问题定义:通过感知数据集<i>D</i>, 从<i>D</i>中提取出特征集合<i>F</i>={<i>f</i><sub>1</sub>, <i>f</i><sub>2</sub>, …, <i>f</i><sub><i>n</i></sub>}, 从数据集<i>D</i>中, 按照特征抽取规则得到样本矩阵<b><i>X</i></b><sub><i>m</i>×<i>n</i></sub> (<i>m</i>行, 每一行是一个样本) , 从EMA数据中获取标注集<i>y</i><sub><i>m</i></sub> (<i>y</i><sub><i>i</i></sub>对应样本矩阵第<i>i</i>行的标注) , 利用<b><i>X</i></b><sub><i>m</i>×<i>n</i></sub>和<i>y</i><sub><i>m</i></sub>训练得到二分类分类器<i>C</i>, 使得<i>C</i>能够在给定输入后完成二分类任务.</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag"><b>3 方法概览</b></h3>
                <div class="p1">
                    <p id="95">本文所设计的方法框架图如图1所示, 方法共包括在线预测部分和离线训练部分:</p>
                </div>
                <div class="p1">
                    <p id="96">1) 离线训练部分.将原始数据进行特征提取、特征筛选, 得到数据样本, 包括有标记样本和未标记样本, 然后利用协同训练得到分类模型.</p>
                </div>
                <div class="p1">
                    <p id="97">2) 在线预测部分.从数据源获取传感器数据, 对数据进行特征提取, 通过接口调用预测模型, 可以实时完成对用户心理压力的评估.</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903016_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于移动感知数据的心理压力检测框架" src="Detail/GetImg?filename=images/JFYZ201903016_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于移动感知数据的心理压力检测框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903016_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Mental stress assessment framework</p>

                </div>
                <div class="p1">
                    <p id="99">整体的工作流程如下.首先, 在用户日常使用过程中, 手机会不断收集感知数据, 然后这些感知数据会被传输到服务器上, 通过特征抽取的方法, 从中提取出一系列有意义的特征, 继而通过特征筛选的方法保留有利于分类的特征, 将日志数据会被转化为样本数据.在生成有标记样本的同时, 也会利用相似的方法得到大量的未标记样本, 这些样本将被用于协同训练, 从而提升分类模型的分类效果, 本文构建的协同训练分类器基于随机森林分类器.分类器的训练工作都是离线完成, 从而用户可以在线调用已经完成的分类器, 实现对用户的心理压力的实时预测的工作.</p>
                </div>
                <h3 id="100" name="100" class="anchor-tag"><b>4 核心方法</b></h3>
                <h4 class="anchor-tag" id="101" name="101"><b>4.1 特征抽取</b></h4>
                <div class="p1">
                    <p id="102">特征抽取的工作是为了将日志文件转变为可用于分类的样本数据.</p>
                </div>
                <div class="p1">
                    <p id="103">首先需要引入时间窗口的概念, 目的是将批量的日志数据转化为一个样本.对于每一个样本, 只使用这个样本对应的时间窗口内的传感器数据进行特征提取, 生成样本, 并打上对应的标记.</p>
                </div>
                <div class="p1">
                    <p id="104">本文选择了24 h作为时间窗口, 对于一个EMA数据, 选取用户反馈该结果的时刻之前的24 h的感知数据用以生成对应这个EMA结果标记的样本.选定时间窗口为24 h有3个原因:1) 人每天的行为是有规律性的, 很多指标不会剧烈变化, 这样会更有利于控制变量, 进行样本间的对比, 选取其他的时长作为时间窗口, 便失去了这个保障;2) 以24 h为时间窗口可以采样到更多有意义的信息, 比如用户的睡眠信息, 用户的睡眠情况和用户的心理状态息息相关, 以24 h为时间窗口可以很自然地采样到这个数据;3) 以EMA数据作为样本的标注, 根据每一条用户反馈的EMA数据生成一个样本, 在该数据集中, EMA数据的频率接近每个用户每天1次, 那么按照天来生成样本, 更符合实际操作中的物理含义.</p>
                </div>
                <div class="p1">
                    <p id="105">在特征抽取的过程中, 需要对特征进行细化.例如描述用户周围人数的特征.用户在白天周围人数较多和在晚上周围人数较多实际上对应着不同的含义.这是因为用户在白天活动较多, 接触到的人也比较多, 而晚上一般都会回到宿舍, 周围接触到的人比较固定, 数量较少.而如果一个用户晚上接触到的人也比较多, 那么可能会说明这个用户在参加某种活动, 这种发现是有意义的, 而如果以天为单位去度量这一特征, 则无法得出这个结论.这说明对特征进行细化可以得到更多信息.在特征抽取的过程中, 本文使用了2种特征细化方法, 分别是按照时间细化和按照POI (point of interest) 细化.</p>
                </div>
                <div class="p1">
                    <p id="106">1) 按照时间细化.将时间分成白天 (8:00—18:00) 和夜间 (18:00—8:00) , 在之后的特征提取中, 会把每一种维度结合时间进行细化考虑.</p>
                </div>
                <div class="p1">
                    <p id="107">2) 按照POI细化.POI描述了用户所处的位置, 和时间类似, 用户的表现按照POI进行划分也可以得到更多的信息.</p>
                </div>
                <div class="p1">
                    <p id="108">同时, 将特征分为2个类别, 绝对特征和相对特征.绝对特征只描述当前时间窗口内的数据, 而相对特征则由当前时间窗口的数据和用户的历史数据对比得到.</p>
                </div>
                <div class="p1">
                    <p id="109">本节将详细阐述针对不同数据集提取的特征以及提取这些特征的指导思想.</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110">4.1.1 绝对特征<i>F</i><sub><i>a</i></sub></h4>
                <h4 class="anchor-tag" id="111" name="111">4.1.1.1 POI相关特征</h4>
                <div class="p1">
                    <p id="112">Jin等人<citation id="330" type="reference"><link href="292" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>的工作是基于用户的轨迹对用户的心理焦虑程度进行预测, 提取了POI相关的特征, 并证明了用户访问不同POI的频率和用户的心理焦虑程度是有一定的相关性的.本文从该角度出发, 基于StudentLife数据集的WiFi location数据, 获取用户POI信息.</p>
                </div>
                <div class="p1">
                    <p id="113">WiFi location数据是手机的WiFi模块的扫描结果, 每1～2 min会记录下一次扫描结果, 出于对隐私的保护, 数据只给出了接入点的位置信息 (接入点和学校内POI的关系) .本文将POI分为3类:1) 教学区, 包括教学楼、实验室、图书馆.2) 宿舍区, 包括学生公寓、宾馆.3) 饮食康健区, 包括食堂、健身房、艺术馆.进而得到每个用户在每个时间所处的POI类别, 这为通过POI信息细化特征提供了帮助, 正如通过时间细化是把时间分为了白天和夜间, 对各个指标按这2个时间段分别计算;通过POI细化则是把位置分成教学区、宿舍区、饮食康健区, 对不同的区域进行计算.</p>
                </div>
                <div class="p1">
                    <p id="114">与此同时, 我们希望利用一个指标反映用户每天在各类POI花费的时间.这类信息可以反映一个用户每天活动的行为习惯, 比如热爱学习的用户每天会花费更多时间在教学区, 而较宅的用户在宿舍区的时间更多, 热爱健身的人可能在饮食康健区停留更久.基于该思想的指导统计了每名用户在时间窗口内的POI数据, 由于采样的频率基本恒定, 每一类POI的条目数量正比于用户在每一类POI停留的时间.</p>
                </div>
                <div class="p1">
                    <p id="115">除了考虑用户在某种类型POI所处的时间长短, 这3种类型的数据构成了一个分布, 本文引入了熵来表达这个分布的特征.对于一个多类分布<i>X</i>, 定义熵为</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mi>lg</mi></mrow><mo stretchy="false"> (</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">结合上文, 形成的基于POI的特征如表2所示:</p>
                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表2 基于POI的特征</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 POI Based Features</b></p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td><br />Feature Number</td><td>Meaning</td></tr><tr><td><br />1</td><td>POI number in teaching area, daytime</td></tr><tr><td><br />2</td><td>POI number in accommodation area, daytime</td></tr><tr><td><br />3</td><td>POI number in eating and heathy area, daytime</td></tr><tr><td><br />4</td><td>POI number in teaching area, nighttime</td></tr><tr><td><br />5</td><td>POI number in accommodation area, nighttime</td></tr><tr><td><br />6</td><td>POI number in eating and healthy area, nighttime</td></tr><tr><td><br />7</td><td>Entropy of POI number distribution, daytime</td></tr><tr><td><br />8</td><td>Entropy of POI number distribution, nighttime</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="119" name="119">1) 活动信息相关特征</h4>
                <div class="p1">
                    <p id="120">POI信息可以在一定程度上反映用户的活动情况, 但其粒度较大.StudentLife数据集中通过利用加速度传感器收集到的数据, 使用物理运动分类器<citation id="331" type="reference"><link href="302" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>对原始数据进行分类, 得到用户在某个时刻的运动状态:静止 (stationary) 、走 (walking) 或跑 (running) , 还有一类标签是未知.为了得到更加精细的数据, 本文利用了这类数据.传感器采样的频率是恒定的, 所以在一个时间窗口内, 用户的某一类标签数目的多少就对应了用户处在这种运动状态下的时间长短.本文对时间窗口内每一类的标签数量进行统计, 并计算熵, 同时考虑按照时间进行细化, 得到特征如表3所示:</p>
                </div>
                <div class="area_img" id="121">
                    <p class="img_tit"><b>表3 活动信息相关特征</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Activity Features</b></p>
                    <p class="img_note"></p>
                    <table id="121" border="1"><tr><td><br />Feature Number</td><td>Meaning</td></tr><tr><td><br />1</td><td>Number of Stationary, daytime</td></tr><tr><td><br />2</td><td>Number of Stationary, nighttime</td></tr><tr><td><br />3</td><td>Number of Walking, daytime</td></tr><tr><td><br />4</td><td>Number of Walking, nighttime</td></tr><tr><td><br />5</td><td>Number of Running, daytime</td></tr><tr><td><br />6</td><td>Number of Running, nighttime</td></tr><tr><td><br />7</td><td>Entropy of label distribution, daytime</td></tr><tr><td><br />8</td><td>Entropy of label distribution, nighttime</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="122">除此之外, 可以反映用户活动信息的还有GPS信息.GPS传感器采样以10 min为间隔, 对用户的经纬度信息进行采样, 在Jin等人<citation id="332" type="reference"><link href="292" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>的工作中, 研究者们探究了用户的移动距离对用户的心理焦虑程度的影响, 本文利用GPS信息计算出用户在时间窗口内的白天移动距离和夜间移动距离, 移动距离为相邻的采样点间的距离的累加, 2经纬度点间的距离计算方式为</p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula">
                        <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>, </mo><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>R</mi><mo>×</mo><msqrt><mrow><mrow><mo> (</mo><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>cos</mi><msup><mrow></mrow><mn>2</mn></msup><mrow><mo> (</mo><mrow><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow><mo>×</mo><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>) </mo></mrow></mrow></msqrt><mo>, </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="124">其中 (<i>x</i>, <i>y</i>) 为一个数据点的经纬度.</p>
                </div>
                <h4 class="anchor-tag" id="125" name="125">2) 声音相关特征</h4>
                <div class="p1">
                    <p id="126">从Lu等人<citation id="333" type="reference"><link href="284" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>的工作中已经得知, 用户所处的环境的声音信息可以用来预测用户的紧张程度, 这说明声音信息和用户的心理指标是紧密相关的.利用手机的感知数据可以获取用户所处环境的声音信息.StudentLife数据集利用声音分类器和对话分类器获取了一系列的声音相关信息:其中一个用以感知手机所处环境是否有声音, 另一个用以感知这个声音是否是人声.这些信息包括用户每一时刻所处环境的声音类型:安静 (silence) 、噪音 (noise) 、人声 (voice) .对于这一类的数据, 采用类似于处理用户活动信息的方法, 结合时间细化, 统计了用户白天或者夜间3类标签的数量, 即用户处在相应空间的时长.同时也计算了熵用以描述此分布.</p>
                </div>
                <div class="p1">
                    <p id="127">数据集中还包含了用户所处空间的对话信息, 结合心理学角度发现, 用户的心理压力程度会影响其是否乐于交流, 本文据此统计了用户在不同的时间段以及不同的类别POI所进行的对话次数和时长, 声音相关的特征维度如表4所示.</p>
                </div>
                <h4 class="anchor-tag" id="128" name="128">3) 社交相关特征</h4>
                <div class="p1">
                    <p id="129">有研究表明:当用户处于较为压抑的状态下时, 往往表现得更加自闭, 不愿与人交流.因此, 可以提取特征来刻画用户的社交信息.区别于以往的工作, 研究者可以通过用户的电话短信数据获取用户的社交相关的信息.手机感知数据中不包含相关信息, 但可以使用蓝牙扫描数据近似刻画社交信息.手机会定期进行扫描, 并记录下扫描到的蓝牙设备.基于我们的认知, 可以被扫描到的蓝牙设备大多数为智能手机、电脑等设备.对于孤僻的用户而言, 不会倾向于去人流密集的地方, 蓝牙扫描记录的设备数量也就越少;相反, 对积极外向的用户而言, 热衷于参加各种活动, 那么记录中设备数量也就会越多.据此, 本文统计了用户在不同时间段, 在不同POI, 蓝牙扫描到的设备数量, 以此来描述用户所处环境的热闹程度, 也一定程度上反映了用户的社交习惯.具体的特征如表5所示.</p>
                </div>
                <div class="area_img" id="130">
                    <p class="img_tit"><b>表4 声音相关特征</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Conversation Features</b></p>
                    <p class="img_note"></p>
                    <table id="130" border="1"><tr><td><br />Feature Number</td><td>Meaning</td></tr><tr><td><br />1</td><td>Number of Silence, daytime</td></tr><tr><td><br />2</td><td>Number of Silence, nighttime</td></tr><tr><td><br />3</td><td>Number of Voice, daytime</td></tr><tr><td><br />4</td><td>Number of Voice, nighttime</td></tr><tr><td><br />5</td><td>Number of Noise, daytime</td></tr><tr><td><br />6</td><td>Number of Noise, nighttime</td></tr><tr><td><br />7</td><td>Entropy of label distribution, daytime</td></tr><tr><td><br />8</td><td>Entropy of label distribution, nighttime</td></tr><tr><td><br />9</td><td>Number of dialog, daytime</td></tr><tr><td><br />10</td><td>Total time of dialog, daytime</td></tr><tr><td><br />11</td><td>Number of dialog, nighttime</td></tr><tr><td><br />12</td><td>Total time of dialog, nighttime</td></tr><tr><td><br />13</td><td>Number of dialog, teaching area</td></tr><tr><td><br />14</td><td>Total time of dialog, teaching area</td></tr><tr><td><br />15</td><td>Number of dialog, accommodation area</td></tr><tr><td><br />16</td><td>Total time of dialog, accommodation area</td></tr><tr><td><br />17</td><td>Number of dialog, eating and health area</td></tr><tr><td><br />18</td><td>Total time of dialog, eating and health area</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="131">
                    <p class="img_tit"><b>表5 蓝牙相关特征</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Bluetooth Features</b></p>
                    <p class="img_note"></p>
                    <table id="131" border="1"><tr><td><br />Feature Number</td><td>Meaning</td></tr><tr><td><br />1</td><td>Number of scanned device, daytime</td></tr><tr><td><br />2</td><td>Number of scanned device, nighttime</td></tr><tr><td><br />3</td><td>Number of scanned device, teaching area</td></tr><tr><td><br />4</td><td>Number of scanned device, accommodation area</td></tr><tr><td><br />5</td><td>Number of scanned device, eating and health area</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="132" name="132">4) 用户睡眠信息</h4>
                <div class="p1">
                    <p id="133">基于心理学的预知知识, 当用户处在一定的心理压力下时, 会引起焦虑、睡眠质量差等生理反应, 因此, 为了预测用户的心理压力, 因此为睡眠质量是很重要的一个特征, 刻画出用户的睡眠时长以及入睡时间, 可以为分类提供帮助.</p>
                </div>
                <div class="p1">
                    <p id="134">本文基于手机锁屏的记录, 获取用户的睡眠习惯.每一条记录了一次手机锁屏到开启的起止时间 (超过1 h才会被记录) , 在探究过程中发现, 每24 h都会出现一个较长的记录, 且该记录都处在深夜, 即该记录对应了用户夜间的休息 (用户在休息的时候不会使用手机, 因此会留下一段长度相当于睡眠时长的记录) .本文使用用户这条记录的开始时间作为用户入睡时间, 构造了用户的睡眠时长以及入睡时间的特征, 如表6所示:</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表6 用户睡眠信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 6 Sleeping Features</b></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br />Feature Number</td><td>Meaning</td></tr><tr><td><br />1</td><td>Sleeping time</td></tr><tr><td><br />2</td><td>Length of sleeping duration</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="136" name="136">4.1.2 相对特征<i>F</i><sub><i>b</i></sub></h4>
                <div class="p1">
                    <p id="137">绝对特征在描述问题的时候依然有局限性:某些用户性格比较孤僻, 数据显示他接触到的人会一直较少, 有的用户相对外向, 其接触到的人较多.因此, 对于某一个指标的特定值, 对一些用户来说较高, 而对另一些用户是较少的, 相同的值对应了相反的变化, 因此本文利用将用户的数据和自身的历史数据进行纵向对比的方法来刻画这种现象.</p>
                </div>
                <div class="p1">
                    <p id="138">用于对比的基准是均值.由于时间窗口是24 h, 数据一共包括了49名学生超过70 d的感知数据.因此对这49名学生的70 d数据分别按照4.1节提到的特征抽取生成样本, 再对样本求取平均值, 可以得到均值样本 (在前面特征抽取部分提到的维度中, 并非所有维度都有对比意义, 比如熵的对比值就没有物理意义, 这种值不会进行对比) .</p>
                </div>
                <div class="p1">
                    <p id="139">之后, 对所有可生成相对特征的维度<i>i</i>, 计算其相对特征<i>r</i><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="140"><i>r</i><sub><i>i</i></sub>= (<i>v</i><sub><i>i</i></sub>-<i>avg</i><sub><i>i</i></sub>) /<i>avg</i><sub><i>i</i></sub>, </p>
                </div>
                <div class="p1">
                    <p id="141">将得到的 <i>r</i><sub><i>i</i></sub>作为新的特征维度加入原本的特征向量, 对之前得到的样本矩阵的每一行进行处理, 得到增加了相对特征的样本矩阵.</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142"><b>4.2 特征选择</b></h4>
                <div class="p1">
                    <p id="143">按照上面的方法, 一共提取了83个维度的特征, 但是由于特征都是手工提取, 一定会存在很多特征与用户心理压力程度在数学上相关性不足.因此, 对特征进行降维是有必要的.</p>
                </div>
                <div class="p1">
                    <p id="144">为了特征的可解释性, 本文没有采用PCA一类的方法进行降维, 因此特征筛选问题等价于选取最优子集, 而最优子集问题是NP难的, 从而问题变为利用近似方法选取一个子集, 能使分类器达到尽量优的效果, 且可以在多项式时间内求解.结合验证过程中使用的随机森林分类器, 本文提出了一种基于基尼不纯度的降维方式.</p>
                </div>
                <div class="p1">
                    <p id="145">基尼不纯度是用来衡量数据集纯净程度的统计量, 在决策树中使用广泛.对决策树而言, 随着树的节点不断分裂, 目标希望叶子节点中的数据点尽可能属于同一类别, 即希望节点样本的“纯度”越来越高.决策树选择节点的划分方式的时候可以依据基尼不纯度来选择特征维度<citation id="334" type="reference"><link href="304" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>.这里有2个概念:基尼不纯度和基尼指数, 其中基尼不纯度描述了一个数据集的纯净度, 而基尼指数则描述了数据集在划分过程中基尼不纯度的变化.</p>
                </div>
                <div class="p1">
                    <p id="146">对于数据集<i>D</i>来说, 设维度集为<i>F</i>={<i>f</i><sub>1</sub>, <i>f</i><sub>2</sub>, …, <i>f</i><sub><i>n</i></sub>}, 那么基尼不纯度可以用<i>I</i><sub><i>G</i></sub> (<i>D</i>) 来表示:</p>
                </div>
                <div class="p1">
                    <p id="147"><mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>G</mi></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>Κ</mi><mo stretchy="false">|</mo></mrow></munderover><mi>p</mi></mstyle><msubsup><mrow></mrow><mi>k</mi><mn>2</mn></msubsup></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="149">其中, <mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mrow><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo></mrow></mfrac><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="151">当对<i>D</i>按照某一个数据维度进行划分的时候, 会得到这个基尼不纯度的变化, 也就是基尼指数, 当按照<i>f</i><sub><i>i</i></sub>进行划分的时候, 基尼指数为</p>
                </div>
                <div class="p1">
                    <p id="152">Δ<i>I</i> (<i>D</i>, <i>f</i><sub><i>i</i></sub>) =<i>I</i><sub><i>G</i></sub> (<i>D</i>) × (<i>p</i><sub><i>l</i></sub><i>I</i><sub><i>G</i></sub> (<i>D</i><sub><i>l</i></sub>) +<i>p</i><sub><i>r</i></sub><i>I</i><sub><i>G</i></sub> (<i>D</i><sub><i>r</i></sub>) ) .</p>
                </div>
                <div class="p1">
                    <p id="153">在决策树选取特征划分时, 会选择划分后基尼不纯度变化最大的特征维度<i>f</i><sub><i>i</i></sub>进行划分, 即:</p>
                </div>
                <div class="p1">
                    <p id="154"><i>f</i><sub>*</sub>=arg max <i>f</i><sub><i>i</i>∈<i>A</i></sub>Δ<i>I</i> (<i>D</i>, <i>f</i><sub><i>i</i></sub>) .</p>
                </div>
                <div class="p1">
                    <p id="155">基尼不纯度变化越大, 说明按照这个维度划分后得到的数据的纯度越高, 特征筛选时, 应尽量保留这些数据维度.基于这个思想:本文所有特征计算基尼指数, 将特征按照基尼指数倒排, 按照排序增量选取特征, 继而训练分类器评估, 筛选结果在第6节中展示.</p>
                </div>
                <h4 class="anchor-tag" id="156" name="156"><b>4.3 模型训练与在线识别</b></h4>
                <h4 class="anchor-tag" id="157" name="157">4.3.1 分类器选择</h4>
                <div class="p1">
                    <p id="158">由于数据集中有标记的样本数量较少, 在分类器的选取上, 为了避免数据较少引起的分类器过拟合问题, 采取了可以有效规避过拟合问题的随机森林 (random forest) 来作为本文使用的分类器.</p>
                </div>
                <div class="p1">
                    <p id="159">随机森林是一个包含若干决策树的分类器, 其输出的类别由个别树输出的类别的众数而定.而森林中的每一棵决策树只利用一部分特征进行分类, 每一棵决策树使用的样本也是从原始样本集合中通过Bootstrap自举方法生成.</p>
                </div>
                <h4 class="anchor-tag" id="160" name="160">4.3.2 协同训练</h4>
                <div class="p1">
                    <p id="161">协同训练 (co-training) 是一种半监督模型, 在有标记的数据量较少的情况下, 可以使用大量的未标记数据进行训练, 以提升分类器的精度<citation id="335" type="reference"><link href="306" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>.协同训练需要从2个不同的“视角”去分析数据, 它要求数据集合有2个不同的特征集合, 且两者是相互独立的, 任意一组数据集合可以训练出预测类别的分类器.协同训练通过结合着2个从不同视角出发的分类器, 构建出更准确的分类模型.</p>
                </div>
                <div class="p1">
                    <p id="162">本文采用了2类特征抽取方法, 分别得到从原始数据中直接抽取到的绝对特征和基于个人历史数据的相对特征, 这2类特征在数学上也是相互独立的.对2类特征分别构建分类器, 利用协同训练可以得到2个分类器, 具体算法见算法 1:</p>
                </div>
                <div class="p1">
                    <p id="163"><b>算法1</b>. Co-training.</p>
                </div>
                <div class="p1">
                    <p id="164">输入:有标记数据集<i>D</i><sub>labeled</sub>、无标记数据集<i>D</i><sub>unlabeled</sub>、迭代轮数<i>θ</i>、每轮选择的样本数<i>n</i>;</p>
                </div>
                <div class="p1">
                    <p id="165">输出:分类器<i>h</i><sub>1</sub>, <i>h</i><sub>2</sub>.</p>
                </div>
                <div class="p1">
                    <p id="166">① 将<i>D</i><sub>labeled</sub>在2个不同的不相关的特征组合 <i>f</i><sub>1</sub>, <i>f</i><sub>2</sub>上进行投影, 分别得到投影后的数据集<i>D</i><sub><i>f</i><sub>1</sub></sub>, <i>D</i><sub><i>f</i><sub>2</sub></sub>;</p>
                </div>
                <div class="p1">
                    <p id="167">② 利用<i>D</i><sub><i>f</i><sub>1</sub></sub>训练出分类器<i>h</i><sub>1</sub>, 利用<i>D</i><sub><i>f</i><sub>2</sub></sub>训练出分类器<i>h</i><sub>2</sub>;</p>
                </div>
                <div class="p1">
                    <p id="168">③ 对每一个<i>D</i><sub>unlabeled</sub>中的未标记数据, 利用<i>h</i><sub>1</sub>标注, 选择置信度最大的<i>n</i>个样本, 加入<i>D</i><sub>labeled</sub>;</p>
                </div>
                <div class="p1">
                    <p id="169">④ 对每一个<i>D</i><sub>unlabeled</sub>中的未标记数据, 利用<i>h</i><sub>1</sub>标注, 选择置信度最大的<i>n</i>个样本, 加入<i>D</i><sub>labeled</sub>;</p>
                </div>
                <div class="p1">
                    <p id="170">⑤ <i>θ</i>=<i>θ</i>-1;</p>
                </div>
                <div class="p1">
                    <p id="171">⑥ if <i>θ</i>&lt;0‖<i>D</i><sub>unlabeled</sub>=∅</p>
                </div>
                <div class="p1">
                    <p id="172">⑦ Return <i>h</i><sub>1</sub>, <i>h</i><sub>2</sub>;</p>
                </div>
                <div class="p1">
                    <p id="173">⑧ else</p>
                </div>
                <div class="p1">
                    <p id="174">⑨ 返回算法步骤①继续执行;</p>
                </div>
                <div class="p1">
                    <p id="175">⑩ endif</p>
                </div>
                <div class="p1">
                    <p id="176">在每一轮迭代中, 从未标记样本集中选取随机森林分类器给出的置信度较高的<i>n</i>个样本加入训练样本集, 直到未标记样本集为空.最终可以得到2个随机森林分类器:<i>h</i><sub>1</sub>和<i>h</i><sub>2</sub>.</p>
                </div>
                <h4 class="anchor-tag" id="177" name="177">4.3.3 在线评估</h4>
                <div class="p1">
                    <p id="178">通过协同训练可以得到2个基于不同特征维度的分类器<i>h</i><sub>1</sub>, <i>h</i><sub>2</sub>, 在预测过程中, 需要综合2个分类器给出的结果做出评估.</p>
                </div>
                <div class="p1">
                    <p id="179">2个分类器都是基于随机森林得到的.随机森林是由很多单独的决策树组合得到的复合分类模型, 随机森林的结果是由单独的决策树输出的类别的众数决定.对二分类{<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>}问题来说, 设一个包含<i>m</i>棵决策树的随机森林, 给出分类结果为的决策树分别为<i>n</i><sub><i>i</i></sub>棵, 那么随机森林认为样本属于<i>c</i><sub><i>i</i></sub>的概率为</p>
                </div>
                <div class="p1">
                    <p id="180" class="code-formula">
                        <mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msup><mrow></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup><mo>=</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="181">在预测过程中, 利用如下的公式得到2个分类器综合的分类结果, 选取概率较大的一个类目作为分类结果:</p>
                </div>
                <div class="p1">
                    <p id="182" class="code-formula">
                        <mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><mo>=</mo><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>C</mi></mrow></munder><mo stretchy="false"> (</mo><mi>p</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msubsup><mo>×</mo><mi>p</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msubsup><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="183">模型的训练过程是离线完成的, 识别可以在线完成, 对给定的用户数据进行特征提取, 特征选择之后得到样本, 就可以进行在线分类.</p>
                </div>
                <h3 id="184" name="184" class="anchor-tag"><b>5 实验验证</b></h3>
                <h4 class="anchor-tag" id="185" name="185"><b>5.1 实验数据</b></h4>
                <div class="p1">
                    <p id="186">实验数据采用达特茅斯学院的StudentLife数据集, 包括49名学生超过10周的传感器数据和EMA反馈数据.对数据集采用前文提出的特征提取和特征筛选方法, 生成了有标注数据和未标注数据, 数量信息如表7所示:</p>
                </div>
                <div class="area_img" id="187">
                    <p class="img_tit"><b>表7 样本数量</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 7 Number of Sample</b></p>
                    <p class="img_note"></p>
                    <table id="187" border="1"><tr><td><br />Data Type</td><td>Stressed</td><td>Not Stressed</td><td>Total</td></tr><tr><td><br />Labeled Sample</td><td>1 587</td><td>580</td><td>2 167</td></tr><tr><td><br />Unlabeled Sample</td><td></td><td></td><td>9 800</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="188" name="188"><b>5.2 实验方法</b></h4>
                <div class="p1">
                    <p id="189">本文在样本集合上使用不同的方法构建模型, 并评估模型的效果.在验证过程中, 对数据采用10折的交叉验证, 将数据随机分成10份, 其中9份用于训练得到分类模型, 最后1份用作验证.本文使用3种评价指标, 分别是精确率 (precision, <i>Pr</i>) 、召回率 (recall, <i>Re</i>) 、<i>F</i>值 (F-measure, <i>F</i><sub>1</sub>) .</p>
                </div>
                <h4 class="anchor-tag" id="190" name="190">1) <i>Pr</i>:</h4>
                <div class="p1">
                    <p id="191">是正确被分到某一类的样本数量占所有被分类器标为该类的样本数量的比例;</p>
                </div>
                <h4 class="anchor-tag" id="192" name="192">2) <i>Re</i>:</h4>
                <div class="p1">
                    <p id="193">是正确被分到某一类的样本数量占实际这一类的样本数量的比例;</p>
                </div>
                <h4 class="anchor-tag" id="194" name="194">3) <i>F</i><sub>1</sub>:</h4>
                <div class="p1">
                    <p id="195">是综合精准率和召回率的一个指标, 在认为二者权重相等的时候, 是取二者的调和平均, 也就是<i>F</i><sub>1</sub>值:</p>
                </div>
                <div class="p1">
                    <p id="196" class="code-formula">
                        <mathml id="196"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mi>Ρ</mi><mi>r</mi><mo>×</mo><mi>R</mi><mi>e</mi></mrow><mrow><mi>Ρ</mi><mi>r</mi><mo>+</mo><mi>R</mi><mi>e</mi></mrow></mfrac><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="197">本文对模型进行了3个角度的评估, 和基线方法进行对比, 对特征筛选的效果进行评估, 对协同训练的效果进行评估.</p>
                </div>
                <h4 class="anchor-tag" id="198" name="198"><b>5.3 实验结果</b></h4>
                <h4 class="anchor-tag" id="199" name="199">5.3.1 和基线方法进行对比</h4>
                <div class="p1">
                    <p id="200">本文提出了基于随机森林的协同训练模型, 在本节中, 将此方法和基线方法进行对比, 作为对比的基线方法包括:</p>
                </div>
                <div class="p1">
                    <p id="201">1) 决策树 (decision tree) ;</p>
                </div>
                <div class="p1">
                    <p id="202">2) 支持向量机 (SVM) ;</p>
                </div>
                <div class="p1">
                    <p id="203">3) <i>K</i>近邻 (<i>K</i>NN) ;</p>
                </div>
                <div class="p1">
                    <p id="204">4) 逻辑斯蒂回归 (logistic regression) .</p>
                </div>
                <div class="p1">
                    <p id="205">对比的实验结果如图2所示:</p>
                </div>
                <div class="area_img" id="206">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903016_206.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 对比其他分类方法" src="Detail/GetImg?filename=images/JFYZ201903016_206.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 对比其他分类方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903016_206.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Compare to other classifier</p>

                </div>
                <div class="p1">
                    <p id="207">可以看出本文方法在<i>Pr</i>, <i>Re</i>, <i>F</i><sub>1</sub>上的表现都要好于直接使用这些分类器.这得益于协同训练的方法利用了大量的无标记数据, 以及随机森林分类器在一定程度上克服了数据样本数量少容易带来的过拟合问题, 本文方法在3种指标上的值如表8所示:</p>
                </div>
                <div class="area_img" id="208">
                    <p class="img_tit"><b>表8 本篇论文方法效果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 8 Performance of Our Function</b></p>
                    <p class="img_note"></p>
                    <table id="208" border="1"><tr><td><br />Metrics</td><td>Our Function</td></tr><tr><td><br /><i>Pr</i></td><td>0.804</td></tr><tr><td><br /><i>Re</i></td><td>0.755</td></tr><tr><td><br /><i>F</i><sub>1</sub></td><td>0.770</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="209" name="209">5.3.2 对特征筛选的评估</h4>
                <div class="p1">
                    <p id="210">基于手工提取的特征具有一定的冗余性, 本文采用基于基尼不纯度的特征筛选方法.对每一个特征, 计算基尼不纯度的变化, 并依此倒排.然后从中不断添加特征进行模型训练, 并进行评估, 得到如图3的曲线.</p>
                </div>
                <div class="p1">
                    <p id="211">其中<i>x</i>轴表示训练使用到的特征数量, <i>y</i>轴表示每轮迭代后模型的各项评估指标.从图3中可以看出, 随着添加的特征数目不断增加, 各项评估指标的值首先呈上升趋势, 然后趋于平稳.说明在添加了一定量的特征之后, 分类器的效果趋于稳定, 那么就不需要继续添加新的特征了.按照这个方法, 最终选取了前26个特征用于最后的分类器训练.</p>
                </div>
                <div class="area_img" id="212">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903016_212.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 模型效果随特征数量的变化" src="Detail/GetImg?filename=images/JFYZ201903016_212.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 模型效果随特征数量的变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903016_212.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Performance with number of selected feature</p>

                </div>
                <h4 class="anchor-tag" id="213" name="213">5.3.3 对协同训练的评估</h4>
                <div class="p1">
                    <p id="214">本文采用协同训练对未标记的数据进行标记并用于迭代训练.利用有标记的数据训练出2个基本的随机森林分类器, 再用2个分类器对无标记数据进行预测, 选取预测置信度较高的样本进入有标记样本集合, 然后基于新的训练数据集合训练出2个随机森林分类器, 并对2个分类器的综合分类结果进行评估, 再不断迭代, 直到分类效果趋于稳定.据此得到了图4所示.</p>
                </div>
                <div class="p1">
                    <p id="215">其中<i>x</i>轴为迭代的轮数, <i>y</i>轴为分类器的评价指标值.可以看出, 随着逐渐加入分类器标注的样本数据, 分类器的效果先是逐渐提高, 继而曲线趋于平稳, 说明分类器效果达到稳定, 此后再加入样本不再能使分类器效果有显著提升.</p>
                </div>
                <div class="area_img" id="216">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903016_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 模型评估指标随协同训练迭代轮数变化" src="Detail/GetImg?filename=images/JFYZ201903016_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 模型评估指标随协同训练迭代轮数变化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903016_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Performance with number of iteration round</p>

                </div>
                <div class="p1">
                    <p id="217">从实验中可以看出随着协同训练的不断迭代, 训练模型的效果得到了很好的优化.因此在缺少大量有标记数据的情况下, 使用半监督训练可以有效利用无标记数据, 从而改善原本分类器的效果.</p>
                </div>
                <h3 id="218" name="218" class="anchor-tag"><b>6 总 结</b></h3>
                <div class="p1">
                    <p id="219">本文分析了心理压力对人的身心的重要性, 并针对以往的评估人的心理压力的方法, 提出了基于手机感知数据的自动心理压力感知方法, 在对用户低侵扰的情况下实现对用户的心理压力的评估.针对手机获取到的日志数据, 本文提出了一系列的特征抽取方法, 将原始的日志数据转化为可用于分类的样本数据.基于基尼不纯度提出了特征筛选方法, 在多项式时间内筛选出对分类有利的特征.然后提出了基于随机森林的协同训练模型, 实现了通过手机感知数据对用户的心理压力进行感知的任务 (<i>Pr</i>=80.4%, <i>Re</i>=75.5%, <i>F</i><sub>1</sub>=77.0%) , 效果好于基线方法.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="260">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fall 2015 reference group executive summary">

                                <b>[1]</b>America College Health Association. Fall 2015 reference group executive summary[EB/OL]. 2015 [2017-01-23]. https://www.acha.org/documents/ncha/NCHA-II_FALL_2017_REFERENCE_GROUP_EXECUTIVE_SUMMARY.pdf
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Statistics on college student stress">

                                <b>[2]</b>Kirsten S. Statistics on college student stress[EB/OL]. 2015 [2017-01-23]. http://stress.lovetoknow.com/Statistics_on_College_Student_Stress
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stress in Health and Disease">

                                <b>[3]</b>Selye H. Stress in Health and Disease[M]. Oxford: Butterworth-Heinemann, 1974
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pupillary, heart rate, and skin resistance changes during a mental task">

                                <b>[4]</b>Kahneman D, Tursky B, Shapiro D, et al. Pupillary, heart rate, and skin resistance changes during a mental task[J]. Journal of Experimental Psychology, 1969, 79 (1) : 164- 167
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Student Life:assessing mental health,academic performance and behavioral trends of college students using smartphones">

                                <b>[5]</b>Wang Rui, Chen Fanglin, Chen Zhenyu, et al. StudentLife: Assessing mental health, academic performance and behavioral trends of college students using smartphones[C] //Proc of the 2014 ACM Conf on Ubiquitous Computing. NewYork: ACM, 2014: 3- 14
                            </a>
                        </p>
                        <p id="270">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Unfolded Protein Response: Integrating Stress Signals Through the Stress Sensor IRE1{alpha}">

                                <b>[6]</b>Hetz C, Martinon F, Rodriguez D, et al. The unfolded protein response: Integrating stress signals through the stress sensor IRE1α[J]. Physiological Reviews, 2011, 91 (4) : 1219- 1243
                            </a>
                        </p>
                        <p id="272">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting stress during real-world driving tasks using physiological sensors">

                                <b>[7]</b>Healey J A, Picard R W. Detecting stress during real-world driving tasks using physiological sensors[J]. IEEE Transactions on Intelligent Transportation Systems, 2005, 6 (2) : 156- 166
                            </a>
                        </p>
                        <p id="274">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stress detection using wearable physiological and sociometric sensors">

                                <b>[8]</b>Mozos M, Sandulescu V, Andrews S. Stress detection using wearable physiological and sociometric sensors[J]. International Journal of Neural Systems, 2017, 27 (2) : 1- 17
                            </a>
                        </p>
                        <p id="276">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                Lu Hong, Frauendorfer D, Rabbi M, et al. StressSense: Detecting stress in unconstrained acoustic environments using smartphones[C] //Proc of the 2012 ACM Conf on Ubiquitous Computing. New York: ACM, 2012: 351- 360
                            </a>
                        </p>
                        <p id="278">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Psychological stress detection from cross-media microblog data using deep sparse neural network">

                                <b>[10]</b>Lin Huijie, Jia Jia, Guo Quan, et al. Psychological stress detection from cross-media microblog data using deep sparse neural network[C] //Proc of the 2014 IEEE Int Conf on Multimedia and Expo. Piscataway, NJ: IEEE, 2014: 1- 6
                            </a>
                        </p>
                        <p id="280">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=User-level psychological stress detection from social media using deep neural network">

                                <b>[11]</b>Lin Huijie, Jia Jia, Guo Quan, et al. User-level psychological stress detection from social media using deep neural network[C] //Proc of the 22nd ACM Int Conf on Multimedia. New York: ACM, 2014: 507- 516
                            </a>
                        </p>
                        <p id="282">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting adolescent psychological pressures form Micro-Blog">

                                <b>[12]</b>Xue Yuanyuan, Li Qi, Jin Li, et al. Detecting adolescent psychological pressures from micro-blog[G] //LNCS 8423: Proc of the 3rd Int Conf on Health Information Science. Berlin: Springer, 2014: 83- 94
                            </a>
                        </p>
                        <p id="284">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Integrating human mobility and social media for adolescent psychological stress detection">

                                <b>[13]</b>Jin Li, Xue Yuanyuan, Li Qi, et al. Integrating human mobility and social media for adolescent psychological stress detection[G] //LNCS 9643: Proc of the 21st Int Conf on Database Systems for Advanced Applications. Berlin: Springer, 2016: 367- 382
                            </a>
                        </p>
                        <p id="286">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201502017&amp;v=MzI3MDI3QmRyRzRIOVRNclk5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N25VcjdMTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Chen Longbiao, Li Shijian, Pan Gang. Smartphone:Pervasive sensing and applications[J]. Chinese Journal of Computers, 2015, 38 (2) : 423- 438 (in Chinese) (陈龙彪, 李石坚, 潘纲. 智能手机:普适感知与应用[J]. 计算机学报, 2015, 38 (2) : 423- 438) 
                            </a>
                        </p>
                        <p id="288">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=My phone and me: Understanding people&amp;#39;&amp;#39;s receptivity to mobile notifi-cations">

                                <b>[15]</b>Mehrotra A, Pejovic V, Vermeulen J, et al. My phone and me: Understanding people’s receptivity to mobile notifi-cations[C] //Proc of the 2016 CHI Conf on Human Factors in Computing Systems. New York: ACM, 2016: 1021- 1032
                            </a>
                        </p>
                        <p id="290">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sensus: A cross-platform, general-purpose system for mobile crowd-sensing in human-subject studies">

                                <b>[16]</b>Xiong Haoyi, Huang Yu, Barnes L E, et al. Sensus: A cross-platform, general-purpose system for mobile crowd-sensing in human-subject studies[C] //Proc of the 2016 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2016: 415- 426
                            </a>
                        </p>
                        <p id="292">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Trajectories of depression:unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis">

                                <b>[17]</b>Canzian L, Musolesi M. Trajectories of depression: Unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis[C] //Proc of the 2015 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2015: 1293- 1304
                            </a>
                        </p>
                        <p id="294">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=StressSense:Detecting Stress in Unconstrained Acoustic Environments using Smartphones">

                                <b>[18]</b>Lu Hong, Frauendorfer D, Rabbi M, et al. StressSense: Detecting stress in unconstrained acoustic environments using smartphones[C] //Proc of the 2012 ACM Conf on Ubiquitous Computing. New York: ACM, 2012: 351- 360
                            </a>
                        </p>
                        <p id="296">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Daily stress recognition from mobile phone data, weather conditions and individual traits">

                                <b>[19]</b>Bogomolov A, Lepri B, Ferron M, et al. Daily stress recognition from mobile phone data, weather conditions and individual traits[C] //Proc of the 22nd ACM Int Conf on Multimedia. New York: ACM, 2014: 477- 486
                            </a>
                        </p>
                        <p id="298">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SmartGPA:How smartphones can assess and predict academic performance of college students">

                                <b>[20]</b>Wang Rui, Harari G, Hao Peilin, et al. SmartGPA: How smartphones can assess and predict academic performance of college students[C] //Proc of the 2015 ACM Int Joint Conf on Pervasive and Ubiquitous Computing. New York: ACM, 2015: 295- 306
                            </a>
                        </p>
                        <p id="300">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SARD&amp;filename=SARD00000005539&amp;v=MDMxOTVKSVYwPU5pelphck80SHRITXI0OUFZZWdHWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVmIz&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>Shiffman S, Stone A, Hufford R. Ecological momentary assessment[J]. Annual Review of Clinical Psychology, 2008, 4: 1- 32
                            </a>
                        </p>
                        <p id="302">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Jigsaw Continuous Sensing Engine for Mobile Phone Applications">

                                <b>[22]</b>Lu Hong, Yang Jun, Liu Zhigang, et al. The Jigsaw continuous sensing engine for mobile phone applications[C] //Proc of the 8th ACM Conf on Embedded Networked Sensor Systems. New York: ACM, 2010: 71- 84
                            </a>
                        </p>
                        <p id="304">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=U-air:When urban air quality inference meets big data">

                                <b>[23]</b>Zheng Yu, Liu Furui, Hsieh P. U-air: When urban air quality inference meets big data[C] //Proc of the 19th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2013: 1436- 1444
                            </a>
                        </p>
                        <p id="306">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining Labeled and Unlabeled Data with Co-Training">

                                <b>[24]</b>Blum A, Mitchell T. Combining labeled and unlabeled data with co-training[C] //Proc of the 11th Annual Conf on Computational Learning Theory. New York: ACM, 1998: 92- 100
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201903016" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201903016&amp;v=MDU4NDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3blVyN0lMeXZTZExHNEg5ak1ySTlFWW9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
