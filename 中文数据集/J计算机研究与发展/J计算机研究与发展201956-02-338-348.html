<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133243544658750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201902010%26RESULT%3d1%26SIGN%3dly3zx0vzpGqQ50YMhNTA2%252ftiKpg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201902010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201902010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201902010&amp;v=MTQzMDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N25XNy9LTHl2U2RMRzRIOWpNclk5RVpJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#278" data-title="&lt;b&gt;1&lt;/b&gt;&lt;b&gt;相关研究工作&lt;/b&gt; "><b>1</b><b>相关研究工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#288" data-title="&lt;b&gt;2&lt;/b&gt;&lt;b&gt;点云分割与点云簇局部特征提取&lt;/b&gt; "><b>2</b><b>点云分割与点云簇局部特征提取</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#290" data-title="&lt;b&gt;2.1&lt;/b&gt;&lt;b&gt;大地平面移除&lt;/b&gt;"><b>2.1</b><b>大地平面移除</b></a></li>
                                                <li><a href="#294" data-title="&lt;b&gt;2.2&lt;/b&gt;&lt;b&gt;点云分割&lt;/b&gt;"><b>2.2</b><b>点云分割</b></a></li>
                                                <li><a href="#301" data-title="&lt;b&gt;2.3&lt;/b&gt;&lt;b&gt;点云簇局部特征提取&lt;/b&gt;"><b>2.3</b><b>点云簇局部特征提取</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#303" data-title="&lt;b&gt;3&lt;/b&gt;&lt;b&gt;&lt;i&gt;K&lt;/i&gt;-公共子图检测&lt;/b&gt; "><b>3</b><b><i>K</i>-公共子图检测</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#305" data-title="&lt;b&gt;3.1&lt;/b&gt;&lt;b&gt;建&lt;/b&gt;&lt;b&gt;图&lt;/b&gt;"><b>3.1</b><b>建</b><b>图</b></a></li>
                                                <li><a href="#307" data-title="&lt;b&gt;3.2&lt;/b&gt;&lt;b&gt;&lt;i&gt;K&lt;/i&gt;-公共子图检测&lt;/b&gt;"><b>3.2</b><b><i>K</i>-公共子图检测</b></a></li>
                                                <li><a href="#339" data-title="&lt;b&gt;3.3&lt;/b&gt;&lt;b&gt;&lt;i&gt;K&lt;/i&gt;-公共子图检测近似算法&lt;/b&gt;"><b>3.3</b><b><i>K</i>-公共子图检测近似算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#345" data-title="&lt;b&gt;4&lt;/b&gt;&lt;b&gt;实验与结果&lt;/b&gt; "><b>4</b><b>实验与结果</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#364" data-title="&lt;b&gt;5&lt;/b&gt;&lt;b&gt;总&lt;/b&gt;&lt;b&gt;结&lt;/b&gt; "><b>5</b><b>总</b><b>结</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#268" data-title="图1 SegGraph算法流程">图1 SegGraph算法流程</a></li>
                                                <li><a href="#291" data-title="图2 KITTI 06 序列的第 2 组点云移除大地平面前后的可视化">图2 KITTI 06 序列的第 2 组点云移除大地平面前后的可视化</a></li>
                                                <li><a href="#300" data-title="图3 KITTI 06序列第2组点云分割所得点云簇集的可视化">图3 KITTI 06序列第2组点云分割所得点云簇集的可视化</a></li>
                                                <li><a href="#316" data-title="图4 KITTI 06 序列第 2 组和第 836 组点云分割所得点云簇集的可视化 (局部图) ">图4 KITTI 06 序列第 2 组和第 836 组点云分割所得点云簇集的可视化 (局部图) </a></li>
                                                <li><a href="#348" data-title="图5 KITTI 00, 05, 06, 07序列的位姿信息">图5 KITTI 00, 05, 06, 07序列的位姿信息</a></li>
                                                <li><a href="#356" data-title="&lt;b&gt;表1&lt;/b&gt;&lt;b&gt;取不同&lt;i&gt;K&lt;/i&gt;值时SegGraph在KITTI 06序列上的准确度&lt;/b&gt;"><b>表1</b><b>取不同<i>K</i>值时SegGraph在KITTI 06序列上的准确度</b></a></li>
                                                <li><a href="#358" data-title="&lt;b&gt;表2&lt;/b&gt;&lt;b&gt;SegGraph在KITTI 00, 05, 06, 07序列上的准确度&lt;/b&gt;"><b>表2</b><b>SegGraph在KITTI 00, 05, 06, 07序列上的准确度</b></a></li>
                                                <li><a href="#361" data-title="&lt;b&gt;表3&lt;/b&gt;&lt;b&gt;SegGraph在KITTI 06序列上的运行时间&lt;/b&gt;"><b>表3</b><b>SegGraph在KITTI 06序列上的运行时间</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="408">


                                    <a id="bibliography_1" title="Thrun S, Leonard J J.Simultaneous localization and mapping[M]Springer Handbook of Robotics.Berlin:Springer, 2008:871-889" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simultaneous localization and mapping">
                                        <b>[1]</b>
                                        Thrun S, Leonard J J.Simultaneous localization and mapping[M]Springer Handbook of Robotics.Berlin:Springer, 2008:871-889
                                    </a>
                                </li>
                                <li id="410">


                                    <a id="bibliography_2" title="Williams B, Cummins M, Neira J, et al.A comparison of loop closing techniques in monocular SLAM[J].Robotics and Autonomous Systems, 2009, 57 (12) :1188-1197" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501998989&amp;v=MDc2MTZOaWZPZmJLN0h0RE5xbzlFYmVJSEJYUXdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKbHdjYWhBPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Williams B, Cummins M, Neira J, et al.A comparison of loop closing techniques in monocular SLAM[J].Robotics and Autonomous Systems, 2009, 57 (12) :1188-1197
                                    </a>
                                </li>
                                <li id="412">


                                    <a id="bibliography_3" title="Cadena C, Carlone L, Carrillo H, et al.Past, present, and future of simultaneous localization and mapping:Towards the robust-perception age[J].IEEE Robotics and Automation Society, 2016, 32 (16) :1309-1332" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Past,present,and future of simultaneous localization and mapping:Towards the robust-perception age">
                                        <b>[3]</b>
                                        Cadena C, Carlone L, Carrillo H, et al.Past, present, and future of simultaneous localization and mapping:Towards the robust-perception age[J].IEEE Robotics and Automation Society, 2016, 32 (16) :1309-1332
                                    </a>
                                </li>
                                <li id="414">


                                    <a id="bibliography_4" title="Ehrlich H, Rarey M.Maximum common subgraph isomorphism algorithms and their applications in molecular science:A review[J].Wiley Interdisciplinary Reviews Computational Molecular Science, 2011, 1 (1) :68-79" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Maximum common subgraph isomorphism algorithms and their applications in molecular science: a review">
                                        <b>[4]</b>
                                        Ehrlich H, Rarey M.Maximum common subgraph isomorphism algorithms and their applications in molecular science:A review[J].Wiley Interdisciplinary Reviews Computational Molecular Science, 2011, 1 (1) :68-79
                                    </a>
                                </li>
                                <li id="416">


                                    <a id="bibliography_5" title="Besl P J, McKay N D.A method for registration of 3-Dshapes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1992, 14 (2) :239-256" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A method for registration of 3D shapes">
                                        <b>[5]</b>
                                        Besl P J, McKay N D.A method for registration of 3-Dshapes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1992, 14 (2) :239-256
                                    </a>
                                </li>
                                <li id="418">


                                    <a id="bibliography_6" title="Segal A, Haehnel D, Thrun S.Generalized-ICP[C]Robotics Science and Systems V.Cambridge, MA:MITPress, 2009:120-130" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generalized-ICP">
                                        <b>[6]</b>
                                        Segal A, Haehnel D, Thrun S.Generalized-ICP[C]Robotics Science and Systems V.Cambridge, MA:MITPress, 2009:120-130
                                    </a>
                                </li>
                                <li id="420">


                                    <a id="bibliography_7" title="Aiger D, Mitra N J, Cohen-Or D.4-points congruent sets for robust pairwise surface registration[J].ACM Transactions on Graphics, 2008, 27 (3) :85-86" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098653&amp;v=MTg5MzVQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsd2NhaEE9TmlmSVk3SzdIdGpOcjQ5RlpPSUhDbms2b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        Aiger D, Mitra N J, Cohen-Or D.4-points congruent sets for robust pairwise surface registration[J].ACM Transactions on Graphics, 2008, 27 (3) :85-86
                                    </a>
                                </li>
                                <li id="422">


                                    <a id="bibliography_8" title="Mellado N, Aiger D, Niloy J, et al.Super 4PCS fast global pointcloud registration via smart indexing[J].Computer Graphics Forum, 2014, 33 (5) :205-215" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD14082500000128&amp;v=MTc0NTFRVE1ud1plWnVIeWptVWI3SUpsd2NhaEE9TmlmY2FySzhIdG5PcW85RlpPc1BEWDR4b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Mellado N, Aiger D, Niloy J, et al.Super 4PCS fast global pointcloud registration via smart indexing[J].Computer Graphics Forum, 2014, 33 (5) :205-215
                                    </a>
                                </li>
                                <li id="424">


                                    <a id="bibliography_9" title="Bosse M, Zlot R.Place recognition using keypoint voting in large 3Dlidar datasets[C]Proc of the 30th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2013:2677-2684" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Place recognition using keypoint voting in large 3Dlidar datasets">
                                        <b>[9]</b>
                                        Bosse M, Zlot R.Place recognition using keypoint voting in large 3Dlidar datasets[C]Proc of the 30th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2013:2677-2684
                                    </a>
                                </li>
                                <li id="426">


                                    <a id="bibliography_10" title="Gawel A, Cieslewski T, Dub&#233;R, et al.Structure-based vision-laser matching[C]Proc of the 28th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2016:182-188" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Structure-based vision-laser matching">
                                        <b>[10]</b>
                                        Gawel A, Cieslewski T, Dub&#233;R, et al.Structure-based vision-laser matching[C]Proc of the 28th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2016:182-188
                                    </a>
                                </li>
                                <li id="428">


                                    <a id="bibliography_11" title="Zhuang Yan, Jiang Nan, Hu Huosheng, et al.3D-laserbased scene measurement and place recognition for mobile robots in dynamic indoor environments[J].IEEE Transactions on Instrumentation and Measurement, 2013, 66 (2) :438-450" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3-D-Laser-Based Scene Measurement and Place Recognition for Mobile Robots in Dynamic Indoor Environments">
                                        <b>[11]</b>
                                        Zhuang Yan, Jiang Nan, Hu Huosheng, et al.3D-laserbased scene measurement and place recognition for mobile robots in dynamic indoor environments[J].IEEE Transactions on Instrumentation and Measurement, 2013, 66 (2) :438-450
                                    </a>
                                </li>
                                <li id="430">


                                    <a id="bibliography_12" title="Rusu R B, Blodow N, Beetz M.Fast point feature histograms (FPFH) for 3Dregistration[C]Proc of the26th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2009:3212-3217" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast point feature histograms (FPFH) for 3-D registration">
                                        <b>[12]</b>
                                        Rusu R B, Blodow N, Beetz M.Fast point feature histograms (FPFH) for 3Dregistration[C]Proc of the26th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2009:3212-3217
                                    </a>
                                </li>
                                <li id="432">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                    Rusu R B, Bradski G, Thibaux R, et al.Fast 3Drecognition and pose using the viewpoint feature histogram[C]Proc of the 22nd IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2010:2155-2162</a>
                                </li>
                                <li id="434">


                                    <a id="bibliography_14" title="Aldoma A, Vincze M, Blodow N, et al.CAD-model recognition and 6DOF pose estimation using 3Dcues[C]Proc of the 13th IEEE Int Conf on Computer Vision Workshops.Piscataway, NJ:IEEE, 2011:585-592" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CAD-model recognition and 6DOF pose estimation using 3Dcues">
                                        <b>[14]</b>
                                        Aldoma A, Vincze M, Blodow N, et al.CAD-model recognition and 6DOF pose estimation using 3Dcues[C]Proc of the 13th IEEE Int Conf on Computer Vision Workshops.Piscataway, NJ:IEEE, 2011:585-592
                                    </a>
                                </li>
                                <li id="436">


                                    <a id="bibliography_15" title="Rohling T, Mack J, Schulz D.A fast histogram based similarity measure for detecting loop closures in 3-D lidar data[C]Proc of the 27th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2015:736-741" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A fast histogram based similarity measure for detecting loop closures in 3-D lidar data">
                                        <b>[15]</b>
                                        Rohling T, Mack J, Schulz D.A fast histogram based similarity measure for detecting loop closures in 3-D lidar data[C]Proc of the 27th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2015:736-741
                                    </a>
                                </li>
                                <li id="438">


                                    <a id="bibliography_16" title="Granstr9m K, Sch9n T B, Nieto J I, et al.Learning to close loops from range data[J].International Journal of Robotics Research, 2011, 30 (14) :1728-1754" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning to close loops from range data">
                                        <b>[16]</b>
                                        Granstr9m K, Sch9n T B, Nieto J I, et al.Learning to close loops from range data[J].International Journal of Robotics Research, 2011, 30 (14) :1728-1754
                                    </a>
                                </li>
                                <li id="440">


                                    <a id="bibliography_17" title="Xiang Haodong.Research on loop closing based on threedimensional laser point cloud in indoor environment[D].Wuhan:Wuhan University, 2017 (in Chinese) (项皓东.基于室内三维激光点云的闭环检测方法研究[D].武汉:武汉大学, 2017) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017195744.nh&amp;v=MjA2MDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N25XNy9LVkYyNkdiS3hHOWJJcTVFYlBJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        Xiang Haodong.Research on loop closing based on threedimensional laser point cloud in indoor environment[D].Wuhan:Wuhan University, 2017 (in Chinese) (项皓东.基于室内三维激光点云的闭环检测方法研究[D].武汉:武汉大学, 2017) 
                                    </a>
                                </li>
                                <li id="442">


                                    <a id="bibliography_18" title="Magnusson M, Andreasson H, N&#252;chter A, et al.Automatic appearance-based loop detection from three dimensional laser data using the normal distributions transform[J].Journal of Field Robotics, 2009, 26 (11/12) :892-914" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic appearance-based loop detection from three-dimensional laser data using the normal distributions transform">
                                        <b>[18]</b>
                                        Magnusson M, Andreasson H, N&#252;chter A, et al.Automatic appearance-based loop detection from three dimensional laser data using the normal distributions transform[J].Journal of Field Robotics, 2009, 26 (11/12) :892-914
                                    </a>
                                </li>
                                <li id="444">


                                    <a id="bibliography_19" title="He Li, Wang Xiaolong, Zhang Hong.M2DP:A novel 3Dpoint cloud descriptor and its application in loop closure detection[C]Proc of the 28th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2016:231-237" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=M2DP:A novel 3Dpoint cloud descriptor and its application in loop closure detection">
                                        <b>[19]</b>
                                        He Li, Wang Xiaolong, Zhang Hong.M2DP:A novel 3Dpoint cloud descriptor and its application in loop closure detection[C]Proc of the 28th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2016:231-237
                                    </a>
                                </li>
                                <li id="446">


                                    <a id="bibliography_20" title="Fernandez-Moral E, Mayol-Cuevas W, Arevalo V, et al.Fast place recognition with plane-based maps[C]Proc of the 30th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2013:2719-2724" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast place recognition with plane-based maps">
                                        <b>[20]</b>
                                        Fernandez-Moral E, Mayol-Cuevas W, Arevalo V, et al.Fast place recognition with plane-based maps[C]Proc of the 30th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2013:2719-2724
                                    </a>
                                </li>
                                <li id="448">


                                    <a id="bibliography_21" title="Dub&#233;R, Dugas D, Stumm E, et al.SegMatch:Segment based place recognition in 3Dpoint clouds[C]Proc of the34th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2017:5266-5272" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SegMatch:Segment based place recognition in 3Dpoint clouds">
                                        <b>[21]</b>
                                        Dub&#233;R, Dugas D, Stumm E, et al.SegMatch:Segment based place recognition in 3Dpoint clouds[C]Proc of the34th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2017:5266-5272
                                    </a>
                                </li>
                                <li id="450">


                                    <a id="bibliography_22" title="Douillard B, Underwood J, Kuntz N, et al.On the segmentation of 3D LIDAR point clouds[C]Proc of the28th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2011:2798-2805" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the segmentation of 3D LIDAR point clouds">
                                        <b>[22]</b>
                                        Douillard B, Underwood J, Kuntz N, et al.On the segmentation of 3D LIDAR point clouds[C]Proc of the28th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2011:2798-2805
                                    </a>
                                </li>
                                <li id="452">


                                    <a id="bibliography_23" title="Gollub M G, Dub&#233;R, Sommer H, et al.A partitioned approach for efficient graph-based place recognition[EB/OL].2017[2018-05-14].http:ppniv17.irccyn.ec-nantes.fr/session5/Gollub/paper.pdf" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A partitioned approach for efficient graph-based place recognition">
                                        <b>[23]</b>
                                        Gollub M G, Dub&#233;R, Sommer H, et al.A partitioned approach for efficient graph-based place recognition[EB/OL].2017[2018-05-14].http:ppniv17.irccyn.ec-nantes.fr/session5/Gollub/paper.pdf
                                    </a>
                                </li>
                                <li id="454">


                                    <a id="bibliography_24" title="Rusu R B, Blodow N, Marton Z C, et al.Close-range scene segmentation and reconstruction of 3Dpoint cloud maps for mobile manipulation in domestic environments[C]Proc of the 21st IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2009:1-6" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Close-range scene segmentation and reconstruction of 3Dpoint cloud maps for mobile manipulation in domestic environments">
                                        <b>[24]</b>
                                        Rusu R B, Blodow N, Marton Z C, et al.Close-range scene segmentation and reconstruction of 3Dpoint cloud maps for mobile manipulation in domestic environments[C]Proc of the 21st IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2009:1-6
                                    </a>
                                </li>
                                <li id="456">


                                    <a id="bibliography_25" title="Rabbania T, Heuvelb F A, Vosselmanc G.Segmentation of point clouds using smoothness constraint[J].International Society for Photogrammetry and Remote Sensing, 2006, 36 (5) :248-253" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmentation of point clouds using smoothness constraint">
                                        <b>[25]</b>
                                        Rabbania T, Heuvelb F A, Vosselmanc G.Segmentation of point clouds using smoothness constraint[J].International Society for Photogrammetry and Remote Sensing, 2006, 36 (5) :248-253
                                    </a>
                                </li>
                                <li id="458">


                                    <a id="bibliography_26" title="Rusu R B, Cousins S, Garage W.3Dis here:Point cloud library (PCL) [C]Proc of the 28th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2011:1-4" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D is here: Point cloud library (PCL)">
                                        <b>[26]</b>
                                        Rusu R B, Cousins S, Garage W.3Dis here:Point cloud library (PCL) [C]Proc of the 28th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2011:1-4
                                    </a>
                                </li>
                                <li id="460">


                                    <a id="bibliography_27" >
                                        <b>[27]</b>
                                    Geiger A, Lenz P, Stiller C, et al.Vision meets robotics:The KITTI dataset[J].International Journal of Robotics Research, 2013, 32 (11) :1231-1237</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(02),338-348 DOI:10.7544/issn1000-1239.2019.20180092            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>SegGraph:室外场景三维点云闭环检测算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BB%96%E7%91%9E%E6%9D%B0&amp;code=41253834&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">廖瑞杰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E7%BB%8D%E5%8F%91&amp;code=37019513&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨绍发</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%9F%E6%96%87%E9%9C%9E&amp;code=41253836&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孟文霞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%91%A3%E6%98%A5%E6%A2%85&amp;code=41253838&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">董春梅</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%BD%AF%E4%BB%B6%E7%A0%94%E7%A9%B6%E6%89%80)&amp;code=0046920&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机科学国家重点实验室(中国科学院软件研究所)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%BD%AF%E4%BB%B6%E7%A0%94%E7%A9%B6%E6%89%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院软件研究所</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>提出适用于配有三维激光雷达的自主移动机器人在室外场景进行同时定位与地图创建 (simul-taneous localization and mapping, SLAM) 的一种闭环检测算法, 命名为SegGraph.作为SLAM的关键模块, 闭环检测的任务是判断机器人当前位置是否与已到过的某一位置邻近.SegGraph包含3步:1) 对在不同时刻得到的2组点云分别移除大地平面后采用区域增长方法分割为若干个点云簇;2) 以点云簇为顶点, 以点云簇图心间距离为边权值, 分别构建带权值的完全图;3) 判定所得的2个完全图是否含有足够大的公共子图.SegGraph的主要创新点是在寻找公共子图时以边权值 (即点云簇间距离) 为主要匹配依据.这是因为点云数据中的噪声会导致在邻近地点获得的不同点云经分割后得出差别很大的点云簇集, 不同点云中相应的点云簇也便无法匹配.然而相应点云簇间距离却受分割过程影响不大.主要贡献包括研发高效的判定2个点云簇图是否有足够大的公共子图的近似算法, 实现完整的SegGraph算法, 及以被广泛使用的公开数据集KITTI (Karlsruhe Institute of Technology and Toyota Technological Institute) 评估SegGraph的准确度及运行效率.实验结果显示SegGraph具有良好的准确度及运行效率.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%90%8C%E6%97%B6%E5%AE%9A%E4%BD%8D%E4%B8%8E%E5%9C%B0%E5%9B%BE%E5%88%9B%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同时定位与地图创建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%97%AD%E7%8E%AF%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">闭环检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%AC%E5%85%B1%E5%AD%90%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">公共子图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%E7%82%B9%E4%BA%91&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D点云;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=KITTI%E6%95%B0%E6%8D%AE%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">KITTI数据集;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    廖瑞杰 liaorj@ios.ac.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-01-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家“九七三”重点基础研究发展计划基金项目 (2014CB340700);</span>
                    </p>
            </div>
                    <h1><b>SegGraph: An Algorithm for Loop-Closure Detection in Outdoor Scenes Using 3D Point Clouds</b></h1>
                    <h2>
                    <span>Liao Ruijie</span>
                    <span>Yang Shaofa</span>
                    <span>Meng Wenxia</span>
                    <span>Dong Chunmei</span>
            </h2>
                    <h2>
                    <span>State Key Laboratory of Computer Science (Institute of Software, Chinese Academy of Sciences)</span>
                    <span>University of Chinese Academy of Sciences</span>
                    <span>Institute of Software, Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>We present SegGraph, a new algorithm for loop-closure detection (LCD) for autonomous robots equipped with three-dimensional laser scanners in outdoor scenes such as urban streets. LCD is to check whether the robot has passed a place near where it visited at some point before, and is a key component of a robot's simultaneous localization and mapping system. Our SegGraph algorithm consists of three steps: 1) partition each of the two input point clouds into point clusters corre-sponding to smooth surfaces, while discarding the ground planes; 2) construct complete weighted graphs from the cluster sets where weights correspond to distances between surface centroids; 3) check if these two graphs contain a sufficiently large common subgraph. The key novelty of SegGraph is that in matching common subgraphs, we mainly compare the distances between corresponding pairs of surface clusters. The rationale is that, due to noise in point cloud data and imperfection of segmentation techniques, different point clouds obtained from nearby places may often be partitioned into drastically different surface segments. However, distances between centroids of these segments tend to be stable across different point clouds. We develope an efficient heuristic randomized algorithm for finding common subgraphs, implement a full LCD algorithm and evaluate it on the publicly available KITTI dataset, which is one of the most widely used. Experimental results demonstrate that our LCD algorithm achieves good accuracy and efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=simultaneous%20localization%20and%20mapping%20(SLAM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">simultaneous localization and mapping (SLAM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=loop-closure%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">loop-closure detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=common%20subgraphs&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">common subgraphs;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%20point%20cloud&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D point cloud;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=KITTI%20dataset&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">KITTI dataset;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Liao Ruijie, born in 1991.Master candidate.His main research intersts are in discrete algorithms for robotics, including localization and mapping.<image id="401" type="formula" href="images/JFYZ201902010_40100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Yang Shaofa, born in 1978.Associate professor.His main research intersts are in discrete algorithms for robotics, including localization, mapping and multirobot coordination. (yangsf@ios.ac.cn) <image id="403" type="formula" href="images/JFYZ201902010_40300.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Meng Wenxia, born in 1993.Master candidate.Her main research intersts are in design and analysis of algorithms. (wenxia@nfs.iscas.ac.cn) <image id="405" type="formula" href="images/JFYZ201902010_40500.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Dong Chunmei, born in 1993.Master candidate.Her main research intersts are in design and analysis of algorithms, and techniques for software design. (dongcm@ios.ac.cn) <image id="407" type="formula" href="images/JFYZ201902010_40700.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-01-29</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Basic Research Program of China (973 Program) (2014CB340700);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="266">随着机器人技术的快速发展, 移动机器人正在逐步走向完全自主化, 而同时定位与地图创建 (sim-ultaneous localization and mapping, SLAM) 是机器人能否真正实现完全自主化的关键技术之一<sup><a class="sup">[1]</a></sup>.SLAM是指机器人在未知环境中从某个未知位置开始移动, 根据运动传感器 (如里程计等) 获得的信息及环境传感器 (如相机、激光雷达等) 获得的场景信息, 在移动过程中同时自主近似计算出当前位置、姿态、运动轨迹并渐进地构建环境地图.每一步的近似计算和渐进建图都因运动传感器的信息偏差而产生误差, 误差会不断累积.闭环检测 (loop-closure detection) <sup><a class="sup">[2]</a></sup>是避免误差过多累积的关键模块.闭环检测的任务是根据环境传感器信息判断当前机器人位置是否与之前某时刻位置邻近, 以抵消运动传感器的累积误差.机器人在差距较大的不同时刻所经过的2个距离较近的不同位置合称为1个闭环.闭环检测的准确度和效率对SLAM均很关键.如实际闭环被正确检出, 则可大幅减少相应2个时刻位姿等信息估计的误差, 并进而校正全局相关时刻位姿和地图信息的误差.如对在实际相距较远位置所得的2组点云误判为闭环, 则可能导致全局位姿和地图信息的近似计算出现较大偏差, 甚至导致约束信息不一致而不可解.SLAM的未来发展趋势是应能支持机器人在大范围场景长时间自主移动<sup><a class="sup">[3]</a></sup>.在这些应用场景中, 闭环检测尤其关键, 难度也更大.</p>
                </div>
                <div class="p1">
                    <p id="267">闭环检测研究依应用场景大致可分为室内场景和室外场景2类, 依所用环境传感器可大致分为基于视觉传感器 (如双目相机) 所得图像数据和基于三维激光雷达所得点云数据两大类.本文专注于基于三维激光雷达的室外场景闭环检测.深度相机能同时获得关联的图像及点云数据, 但其只适用于室内场景, 而且其所得点云深度信息精度远小于激光雷达.在室外场景中, 由于视觉传感器所得图像对光照、天气等的影响甚为敏感, 而三维激光雷达通过激光对环境进行高分辨率扫描获得环境中各点在雷达坐标系中的位置信息, 其所得信息不受光照、天气等影响, 而且精度远高于从视觉传感器图像所估计出来的位置几何信息.故室外场景闭环检测当前研究更倾向于基于三维激光雷达所得点云数据.</p>
                </div>
                <div class="area_img" id="268">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902010_268.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SegGraph算法流程" src="Detail/GetImg?filename=images/JFYZ201902010_268.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SegGraph算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902010_268.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 Flow of algorithm SegGraph</p>

                </div>
                <div class="p1">
                    <p id="269">基于三维激光雷达所得点云的闭环检测本质是将2组点云进行比较, 以判断它们是否有较高相似度.在SLAM过程中, 将当前时刻所得的1组点云分别与过去某时间段内选取的若干组点云一一进行闭环检测, 将判断为闭环的2组点云认为是在相邻近位置所得, 并将由此2组点云邻近而产生的全局约束融入到全局的定位与建图计算中.本文提出适用于室外场景基于三维激光雷达所得点云数据的新的闭环检测算法, 命名为SegGraph.对作为输入的2组点云<i>A</i>和<i>B</i>, SegGraph的流程如图1所示, 主要分为点云分割、点云簇图构建、点云簇特征提取、<i>K</i>-公共子图检测四大模块.</p>
                </div>
                <div class="p1">
                    <p id="270">1) SegGraph对点云<i>A</i>和<i>B</i>分别分割成多个点云簇, 分割前先对点云作预处理移除大地平面.大地平面通常是场景中最大的平面及对点云相似度判定最没有参考价值的平面, 并且该平面连接了大部分的小平面如建筑物的外墙、汽车表面等, 移除大地平面能避免其对点云分割准确度的影响.</p>
                </div>
                <div class="p1">
                    <p id="271">2) 以<i>A</i>中点云簇为顶点、以点云簇图心间距离为边权值构建完全的带权无向图<i>G</i><sub><i>A</i></sub>, 使用同样的方法对<i>B</i>构建完全图<i>G</i><sub><i>B</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="272">3) 判断<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>是否存在有<i>K</i>个顶点的公共子图, 其中<i>K</i>是设定的参数.在匹配<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>的子图时, 我们以边权值 (即点云簇图心间距离) 为主要匹配依据.这是因为点云数据中的噪声及点云分割方法的不完美会导致从邻近地点得到的2组点云被分割成差别很大的点云簇集, 尤其是同一物体表面可能会表现为面积差别很大的点云簇.然而点云簇图心间距离则相对稳定, 这在第3节中有详细例子说明.另一方面, 为提高子图匹配效率, 我们分别对<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>中点云簇提取其具有代表性的局部特征, 以用于对匹配过程进行剪枝操作和优化, 这些特征包括图心、法向量等.</p>
                </div>
                <div class="p1">
                    <p id="273"><i>K</i>-公共子图的判定是很著名的NP-hard问题<sup><a class="sup">[4]</a></sup>.我们提出了一个近似算法, 基本思路如下:在初始化阶段, 分别从<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>中选取匹配的边, 并组成匹配的2-公共子图.假如选择不唯一, 则从符合要求的边对中随机选取.在递归阶段, 假设当前已找到<i>G</i><sub><i>A</i></sub>的ℓ-子图<i>H</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>的ℓ-子图<i>H</i><sub><i>B</i></sub>, 使得<i>H</i><sub><i>A</i></sub>与<i>H</i><sub><i>B</i></sub>匹配, 其中ℓ&lt;<i>K</i>.则从<i>G</i><sub><i>A</i></sub>中选在<i>H</i><sub><i>A</i></sub>外的1个顶点<i>v</i><sub><i>A</i></sub>, 从<i>G</i><sub><i>B</i></sub>中选在<i>H</i><sub><i>B</i></sub>外的1个顶点<i>v</i><sub><i>B</i></sub>, 使得由<i>H</i><sub><i>A</i></sub>与<i>v</i><sub><i>A</i></sub>组成的 (ℓ+1) -子图与由<i>H</i><sub><i>B</i></sub>与<i>v</i><sub><i>B</i></sub>组成的 (ℓ+1) -子图相匹配.如顶点对 (<i>v</i><sub><i>A</i></sub>, <i>v</i><sub><i>B</i></sub>) 的选择不唯一, 则从符合要求的顶点对中随机选取, 如此直到找到匹配的<i>K</i>-公共子图.如在上述过程中找不到符合要求的顶点对, 则近似地认为<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>不存在匹配的<i>K</i>-公共子图.</p>
                </div>
                <div class="p1">
                    <p id="274">本文主要贡献有3个方面:</p>
                </div>
                <div class="p1">
                    <p id="275">1) 提出以边匹配为主要依据的基于<i>K</i>-公共子图判定的室外场景三维点云闭环检测算法SegGraph, 提出解决其中核心问题——<i>K</i>-公共子图判定的近似算法.</p>
                </div>
                <div class="p1">
                    <p id="276">2) 基于C++语言和开源的第三方点云库 (point cloud library, PCL) <citation id="493" type="note"><link href="202" rel="footnote" /><sup>①</sup></citation>实现完整的SegGraph算法, 代码在GitHub上发布<citation id="494" type="note"><link href="204" rel="footnote" /><sup>②</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="277">3) 以广被采用的KITTI (Karlsruhe Institute of Technology and Toyota Technological Institute) 城市街景数据集<citation id="495" type="note"><link href="206" rel="footnote" /><sup>③</sup></citation>评估SegGraph, 实验结果显示SegGraph有良好的准确度和运行效率.</p>
                </div>
                <h3 id="278" name="278" class="anchor-tag"><b>1</b><b>相关研究工作</b></h3>
                <div class="p1">
                    <p id="279">基于激光雷达所得三维点云的室外场景闭环检测是近年来的研究热点, 仍为一大挑战.主要有3个难点:1) 单组点云含点个数数量庞大 (如KITTI数据集中单组点云约含12万个点) , 点在空间分布不均匀, 疏密不一;2) 点云中各点数据噪声很大, 这是目前激光雷达测量技术的不完美所致;3) 激光雷达只能测量不被阻挡的物体表面的点的空间位置, 对被阻挡的表面无法取得数据, 这就可能导致在相邻很近但视角不同而得的2组点云可能差别很大.闭环检测的本质是判别2组点云是否有较高的相似度, 从已有研究工作看主要有2类方法.</p>
                </div>
                <div class="p1">
                    <p id="280">第1类方法是2组点云点对点的直接匹配.在这类方法中最著名并被广泛采用的是最近邻迭代算法 (iterative closest point, ICP) <sup><a class="sup">[5]</a></sup>和它的改进算法<sup><a class="sup">[6]</a></sup>.假设从里程计信息或其他方式已取得2组点云的大致几何转换对应关系, ICP算法利用迭代一步步近似计算出误差越来越小的2组点云的几何转换对应关系.ICP算法的局限性是需要已有大致精确的几何转换对应关系.点对点直接匹配方法还有适用范围更广并且不需要先验信息的4点 (4-points congruent sets, 4PCS) 算法<sup><a class="sup">[7]</a></sup>和它们的改进算法, 如超级4点 (super-4PCS) 算法<sup><a class="sup">[8]</a></sup>等.因单组点云含点个数庞大, 点对点直接匹配计算效率并不高.另外, 此方法对个别点测量误差较为敏感, 容易因局部部分点误差而导致全局匹配的大偏差.</p>
                </div>
                <div class="p1">
                    <p id="281">第2类方法是基于描述子的点云匹配.首先为2组点云各计算出1个较简约的描述子, 然后通过比较描述子来衡量2组点云的相似度.与点对点直接匹配方法相比, 基于描述子的方法计算量相对较小, 受局部点测量误差影响也相对较小.描述子的计算方法主要基于3个方面:1) 基于场景点云的局部特征;2) 基于场景点云的全局特征;3) 基于对场景点云进行分割所得的平面集或者物体集.</p>
                </div>
                <div class="p1">
                    <p id="282">基于点云局部特征的描述子算法大多是从点云中选取关键点并从这些关键点抽取局部特征形成特征向量.Bosse和Zlot<sup><a class="sup">[9]</a></sup>通过构建1个投票矩阵计算每点经其最近的若干个邻近点投票所得权值, 再基于这些权值选取关键点建立描述子, 称为三维Gestalt描述子.Gawel和Cieslewski<sup><a class="sup">[10]</a></sup>也用了类似的方法.Zhuang和Jiang<sup><a class="sup">[11]</a></sup>则将点云的局部点集转换成方位图像, 并从这些图像中计算出SURF (speed up robust features) 描述子.Rusu等人<sup><a class="sup">[12]</a></sup>采用较经典的快速点特征直方图 (fast point feature histograms, FPFH) 构建描述子.受FPFH描述子构建方法的启发, 又产生了视点特征直方图 (viewpoint feature histogram, VFH) <sup><a class="sup">[13]</a></sup>描述子和CVFH (clustered viewpoint feature histogram) <sup><a class="sup">[14]</a></sup>描述子等.</p>
                </div>
                <div class="p1">
                    <p id="283">基于全局特征的描述子计算主要是提取点云的若干全局特征并加以组合构成全局描述子.Rohling等人<sup><a class="sup">[15]</a></sup>首先将点云中的点按高度值分成若干层, 然后为每层计算出一维的直方图, 最后将这些直方图组合起来构成全局描述子.2组点云的全局描述子以它们之间的Wasserstein距离来衡量相似度.Granström等人<sup><a class="sup">[16]</a></sup>提取出点云中具有旋转不变性的全局特征并将其组合构成全局描述子, 这些具有旋转不变性的特征包括体积、法向量、距离直方图等.描述子的匹配用机器学习中用于分类的AdaBoost算法来完成, 项皓东<sup><a class="sup">[17]</a></sup>继续了该方法的研究, 在一些细节方面做出了相关改进, 同样是把机器学习中的相关算法和传统方法相结合.Magnusson等人<sup><a class="sup">[18]</a></sup>首先将点云按三维网格划分为多个子集, 然后计算每个子集中局部点云的形状属性 (如球形、线状或平面等) , 最后将每个子集的形状属性描述组合构成点云的全局描述子.He等人<sup><a class="sup">[19]</a></sup>首先计算点云在多个预先选定的二维平面上的投影并对每个投影构建1个向量, 然后将从各投影所得向量组合成1个全局矩阵, 最后以对全局矩阵进行奇异值分解所得的左、右奇异向量构成全局描述子.各投影向量描述的计算方法是将平面分成许多小块并计算各小块里面所包含的点的个数.</p>
                </div>
                <div class="p1">
                    <p id="284">基于点云分割所得平面和物体构建描述子是近年来较新的思路, 其能兼顾到点云中的局部特征和全局特征.Fernandez-Moral 等人<sup><a class="sup">[20]</a></sup>研究基于RGB深度相机所得点云数据的室内场景闭环检测, 其方法首先从2组点云中分别检测出属于某个平面的若干点子集, 再对2组点云的平面进行匹配, 寻找相匹配的构成场景某一局部的2组平面子集.该方法只适用于有较多含平面表面物体的室内场景, 并依赖RGB图像选取场景某一局部, 并不适用于室外场景激光雷达所得三维点云的闭环检测.</p>
                </div>
                <div class="p1">
                    <p id="285">Dubé等人<sup><a class="sup">[21]</a></sup>提出命名为SegMatch的基于三维点云分割的室外场景闭环检测算法.SegMatch首先利用欧基里德点云分割算法<sup><a class="sup">[22]</a></sup>将2组点云各分成多个点云簇, 再利用基于机器学习中用于分类的随机森林算法对这2组点云的点云簇进行匹配.Gollub和Dubé等人<sup><a class="sup">[23]</a></sup>在SegMatch基础上作了改进, 首先将2组点云<i>A</i>, <i>B</i>各分成多个点云簇, 然后基于能相匹配的点云簇对构建1个 (不带权) 无向图<i>G</i>, 最后以检测<i>G</i>中是否含有足够大的团来判定<i>A</i>, <i>B</i>是否有较高相似度.图<i>G</i>的每个顶点为1个点云簇对 (<i>C</i><sub><i>A</i></sub>, <i>C</i><sub><i>B</i></sub>) , 其中<i>C</i><sub><i>A</i></sub>为<i>A</i>中的1个点云簇, <i>C</i><sub><i>B</i></sub>为<i>B</i>中的1个点云簇, <i>C</i><sub><i>A</i></sub>与<i>C</i><sub><i>B</i></sub>的各项特征包括图心、面积等能够相匹配.对图<i>G</i>中的2顶点<i>v</i>= (<i>C</i><sub><i>A</i></sub>, <i>C</i><sub><i>B</i></sub>) , <i>v</i>′= (<i>C</i>′<sub><i>A</i></sub>, <i>C</i>′<sub><i>B</i></sub>) , 若<i>C</i><sub><i>A</i></sub>到<i>C</i>′<sub><i>A</i></sub>距离与<i>C</i><sub><i>B</i></sub>到<i>C</i>′<sub><i>B</i></sub>距离相匹配, 则构建边 (<i>v</i>, <i>v</i>′) , 否则不构建边 (<i>v</i>, <i>v</i>′) .</p>
                </div>
                <div class="p1">
                    <p id="286">我们的方法SegGraph受SegMatch及其改进方法的启发, 并克服了这2个方法的不足.SegMatch在将2组点云所得的点云簇集进行匹配时, 忽略了点云簇间距离的信息, 故对闭环检测准确率影响很大.而改进它的方法中, 2组点云的点云簇要首先进行匹配, 但在真实的室外场景中, 受限于点云分割算法的辨识能力及点云数据中的噪声干扰, 从相邻很近地点所得的点云簇很难形成一对一的匹配.</p>
                </div>
                <div class="p1">
                    <p id="287">SegGraph首先采用受噪声点干扰程度更小的区域增长分割算法将2组点云<i>A</i>和<i>B</i>各分割成多个点云簇, 该方法分割出来的每个点云簇近似于1个光滑的表面, 并保留了点云中的关键局部特征.假定<i>A</i>和<i>B</i>具有较高的相似度, 即使<i>A</i>和<i>B</i>中有很多点云簇难以形成一对一的匹配对, 但点云簇间距离是较为稳定的信息, 因此, 我们以<i>A</i>和<i>B</i>中的点云簇为顶点构建1个带边权值的完全图<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>, 其中边的权值是点云簇图心间的距离.然后我们再以边匹配为主, 检测<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>是否含1个足够大的 (带权) 公共子图.在公共子图检测中, 我们将点云簇在分割中较稳定的局部特征如图心、法向量等作为辅助判定依据, 以提高公共子图的检测效率.在第4节中的实验结果显示了SegGraph能够取得良好的准确度和运行效率.</p>
                </div>
                <h3 id="288" name="288" class="anchor-tag"><b>2</b><b>点云分割与点云簇局部特征提取</b></h3>
                <div class="p1">
                    <p id="289">本节将详细介绍 SegGraph算法的第1步——点云分割, 即将2组输入点云分别经移除大地平面后分割成多个点云簇.为了提高SegGraph中<i>K</i>-公共子图判定的效率, 我们还将从每个点云簇中提取其具有代表性的局部特征, 包括图心、法向量、点云数量等.</p>
                </div>
                <h4 class="anchor-tag" id="290" name="290"><b>2.1</b><b>大地平面移除</b></h4>
                <div class="area_img" id="291">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902010_291.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 KITTI 06 序列的第 2 组点云移除大地平面前后的可视化" src="Detail/GetImg?filename=images/JFYZ201902010_291.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 KITTI 06 序列的第 2 组点云移除大地平面前后的可视化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902010_291.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 Visualization of before and after ground plane  removal for point cloud 2, sequence 06 KITTI</p>

                </div>
                <div class="p1">
                    <p id="292">SegGraph专注于处理室外场景的点云数据, 大多数此类场景如城市街景等均有1个较显著的大地平面.通常大地平面是场景中面积最大的平面, 也是对场景相似度比较最没有参考价值的平面.故先将大地平面移除可以大大减少场景相似度比较的计算量.</p>
                </div>
                <div class="p1">
                    <p id="293">SegGraph采用一致性分割算法 (SAC segmen-tation) <sup><a class="sup">[24]</a></sup>来移除点云中的大地平面.一致性分割算法的功能是从点云中提取与指定目标模型相对应的点云子集, 如平面、球体、圆柱等.SegGraph用该算法提取出点云中最大的1个平面, 认为其是大地平面, 并将其移除.图2显示了KITTI数据集 06序列第2组三维点云数据的可视化图像和将该组点云移除大地平面后的可视化图像.</p>
                </div>
                <h4 class="anchor-tag" id="294" name="294"><b>2.2</b><b>点云分割</b></h4>
                <div class="p1">
                    <p id="295">SegGraph采用区域增长算法<sup><a class="sup">[25]</a></sup>对移除大地平面后的点云数据进行分割.其算法包含3个步骤:</p>
                </div>
                <div class="p1">
                    <p id="296">1) 计算曲率.对点云中每个点<i>p</i>, 以与<i>p</i>在1个很小的指定范围内的邻近点子集信息计算<i>p</i>的曲率.</p>
                </div>
                <div class="p1">
                    <p id="297">2) 选取初始种子点集.以点云中曲率小于指定阈值的点构成初始种子点集.</p>
                </div>
                <div class="p1">
                    <p id="298">3) 区域增长.从种子点集中取出1个点<i>p</i>, 将以<i>p</i>为基础点构建1个可以近似认为是平滑表面的点云簇, 该点云簇包含与<i>p</i>距离在一定范围内且与<i>p</i>的法向量夹角小于指定阈值的所有点.</p>
                </div>
                <div class="p1">
                    <p id="299">点云数据经移除大地平面和分割后, 将形成1个点云簇集, 每个点云簇可以近似地视为场景中某个平滑表面的一部分.图3显示了从KITTI数据集06序列第2组点云所得点云簇集合的可视化图像, 其中, 同一个点云簇内的点以相同颜色显示, 相邻的点云簇用不同的颜色显示.</p>
                </div>
                <div class="area_img" id="300">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902010_300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 KITTI 06序列第2组点云分割所得点云簇集的可视化" src="Detail/GetImg?filename=images/JFYZ201902010_300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 KITTI 06序列第2组点云分割所得点云簇集的可视化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902010_300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Visualization of point clusters resulting from  segmentizing point cloud 2, sequence 06, KITTI</p>

                </div>
                <h4 class="anchor-tag" id="301" name="301"><b>2.3</b><b>点云簇局部特征提取</b></h4>
                <div class="p1">
                    <p id="302">为提高SegGraph后续<i>K</i>-公共子图检测的效率, 我们对点云分割所得点云簇提取关键的局部特征.对每个点云簇, 我们计算出图心、法向量、曲率、点的个数等信息.这些信息将辅助SegGraph后续<i>K</i>-公共子图检测进一步优化.</p>
                </div>
                <h3 id="303" name="303" class="anchor-tag"><b>3</b><b><i>K</i>-公共子图检测</b></h3>
                <div class="p1">
                    <p id="304">SegGraph的第2步是就2组点云<i>A</i>和<i>B</i>分割所得的点云簇构建带权值的完全图<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>, 并以检测<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>是否含有<i>K</i>-公共子图来判定<i>A</i>和<i>B</i>的相似度.从点云簇提取的特征将作为辅助匹配信息以提高<i>K</i>-公共子图检测的效率.本节将详述SegGraph中建图与<i>K</i>-公共子图检测算法.</p>
                </div>
                <h4 class="anchor-tag" id="305" name="305"><b>3.1</b><b>建</b><b>图</b></h4>
                <div class="p1">
                    <p id="306">对2组输入点云<i>A</i>和<i>B</i>, 我们分别构建无向完全图<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>, 其中<i>G</i><sub><i>A</i></sub>的顶点集是第2节操作对<i>A</i>移除大地平面并分割后所得的点云簇集<i>V</i><sub><i>A</i></sub>, 即每个点云簇<i>v</i><sub><i>A</i></sub>构成<i>G</i><sub><i>A</i></sub>的1个顶点.对<i>G</i><sub><i>A</i></sub>中任意2个不同顶点<i>v</i><sub><i>A</i></sub>和<i>v</i>′<sub><i>A</i></sub>, 我们构建边 (<i>v</i><sub><i>A</i></sub>, <i>v</i>′<sub><i>A</i></sub>) , 并标识权值<i>w</i> (<i>v</i><sub><i>A</i></sub>, <i>v</i>′<sub><i>A</i></sub>) , 其中<i>w</i> (<i>v</i><sub><i>A</i></sub>, <i>v</i>′<sub><i>A</i></sub>) 是<i>v</i><sub><i>A</i></sub>图心到<i>v</i>′<sub><i>A</i></sub>图心的欧基里德距离, 图<i>G</i><sub><i>B</i></sub>的构建同理.</p>
                </div>
                <h4 class="anchor-tag" id="307" name="307"><b>3.2</b><b><i>K</i>-公共子图检测</b></h4>
                <div class="p1">
                    <p id="308">我们将判定2组点云<i>A</i>和<i>B</i>是否相似转化为检测<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>是否含有<i>K</i>-公共子图, 其中<i>K</i>是预先设定的整数.我们称<i>G</i><sub><i>A</i></sub>和<i>G</i><sub><i>B</i></sub>含有<i>K</i>-公共子图当且仅当存在<i>U</i><sub><i>A</i></sub>⊆<i>V</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>⊆<i>V</i><sub><i>B</i></sub>, |<i>U</i><sub><i>A</i></sub>|=<i>K</i>=|<i>U</i><sub><i>B</i></sub>|, 而且以<i>U</i><sub><i>A</i></sub>为顶点集的子图<i>H</i><sub><i>A</i></sub>与以<i>U</i><sub><i>B</i></sub>为顶点集的子图<i>H</i><sub><i>B</i></sub>能相匹配, 其中<i>H</i><sub><i>A</i></sub>和<i>H</i><sub><i>B</i></sub>为完全图.更确切地说, 存在从<i>U</i><sub><i>A</i></sub>到<i>U</i><sub><i>B</i></sub>的一一对应的映射<i>f</i>, 满足:</p>
                </div>
                <div class="p1">
                    <p id="309">1) 对<i>U</i><sub><i>A</i></sub>中任意2个不同的顶点<i>u</i><sub><i>A</i></sub>和<i>u</i>′<sub><i>A</i></sub>, 其权值<i>w</i> (<i>u</i><sub><i>A</i></sub>, <i>u</i>′<sub><i>A</i></sub>) 与<i>w</i> (<i>f</i> (<i>u</i><sub><i>A</i></sub>) , <i>f</i> (<i>u</i>′<sub><i>A</i></sub>) ) 相差在指定的阈值内.</p>
                </div>
                <div class="p1">
                    <p id="310">2) 对<i>U</i><sub><i>A</i></sub>中任意顶点<i>u</i><sub><i>A</i></sub>, <i>u</i><sub><i>A</i></sub>所代表的点云簇的图心、法向量等特征与<i>f</i> (<i>u</i><sub><i>A</i></sub>) 所代表的点云簇的相应特征的差值在指定阈值内.</p>
                </div>
                <div class="p1">
                    <p id="311">第1节提到的SegMatch及其改进方法均基于上述的假设, 即依据点云簇的形状、面积及其他局部特征能使2组点云<i>A</i>和<i>B</i>分割所得的大多数点云簇能够形成唯一匹配, 即<i>A</i>中大多数点云簇<i>v</i><sub><i>A</i></sub>能在<i>V</i><sub><i>B</i></sub>中找到唯一1个<i>v</i><sub><i>B</i></sub>, 使得<i>v</i><sub><i>A</i></sub>与<i>v</i><sub><i>B</i></sub>的形状、面积及其他局部特征匹配.而这个假设在实际场景所得点云数据的分割中是很难满足的.主要原因有3点:</p>
                </div>
                <div class="p1">
                    <p id="312">1) 激光雷达测量的误差会使三维点云数据含有一定的噪声, 并且激光雷达所获取的点云中点的分布并不均匀, 且疏密不一.</p>
                </div>
                <div class="p1">
                    <p id="313">2) 激光雷达只能扫描未被阻挡的物体表面, 视点与视角的轻微变化及场景中瞬间出现的动态物体如车辆等均会使点云数据产生较大的偏差.</p>
                </div>
                <div class="p1">
                    <p id="314">3) 点云分割算法有局限, 无论是SegMatch中采用的欧基里德分割算法, 还是本文采用的区域增长分割算法, 均不能完美地使分割出来的点云簇与场景中的实际物体表面一一对应, 其他点云分割算法也无法避免此问题.</p>
                </div>
                <div class="p1">
                    <p id="315">因而, 我们将点云簇间距离作为点云相似度比较的主要依据.图4展示了KITTI数据集06序列第2组点云和第836组点云在分割后所得点云簇集的可视化图像.</p>
                </div>
                <div class="area_img" id="316">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902010_316.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 KITTI 06 序列第 2 组和第 836 组点云分割所得点云簇集的可视化 (局部图)" src="Detail/GetImg?filename=images/JFYZ201902010_316.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 KITTI 06 序列第 2 组和第 836 组点云分割所得点云簇集的可视化 (局部图)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902010_316.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Visualization of point clusters after segmentizing  point clouds 2 and 836, sequence 06, KITTI (portion) </p>

                </div>
                <div class="p1">
                    <p id="317">在图4的2组点云局部图中, 同个点云簇内的点以相同颜色显示, 邻近的点云簇之间用不同的颜色显示, 根据KITTI提供的位姿信息, 这2组点云获取地点 (即三维激光雷达所处位置) 相差仅为0.265 m, 可以将2组点云近似看作是对同一个场景的扫描, 图4中<i>X</i>与<i>Y</i>为同一个位置分割出来的2个点云簇, 但其面积差别很大, <i>X</i>′与<i>Y</i>′也是类似的情况, 但<i>X</i>图心与<i>X</i>′图心间距 <i>XX</i>′和<i>Y</i>图心与<i>Y</i>′图心间距<i>YY</i>′相差却不大, 可作为2组点云相似度比较的主要依据.另一方面, <i>X</i>与<i>Y</i>, <i>X</i>′与<i>Y</i>′的图心、法向量等信息基本一致, 可以作为辅助信息提高点云相似度比较的效率.</p>
                </div>
                <div class="p1">
                    <p id="318"><i>K</i>-公共子图检测是NP-hard问题.我们提出一种穷尽搜索算法来求解.</p>
                </div>
                <div class="p1">
                    <p id="319"><b>算法1</b>. <i>K</i>-公共子图穷尽搜索算法.</p>
                </div>
                <div class="p1">
                    <p id="320">输入:完全图<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>, 整数<i>K</i>, 以<i>V</i><sub><i>A</i></sub>, <i>V</i><sub><i>B</i></sub>分别记<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>的顶点集, 以<i>w</i> (<i>v</i>, <i>v</i>′) 记<i>G</i><sub><i>A</i></sub>或<i>G</i><sub><i>B</i></sub>中边 (<i>v</i>, <i>v</i>′) 的权值;</p>
                </div>
                <div class="p1">
                    <p id="321">输出:布尔值, 即<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>是否含<i>K</i>-公共子图.</p>
                </div>
                <div class="p1">
                    <p id="322">1) 预处理.为<i>G</i><sub><i>A</i></sub>中每条边<i>e</i><sub><i>A</i></sub>计算<i>G</i><sub><i>B</i></sub>中与之匹配的边的集合<i>Match</i><sub><i>e</i><sub><i>A</i></sub></sub>.<i>Match</i><sub><i>e</i><sub><i>A</i></sub></sub>含<i>G</i><sub><i>B</i></sub>所有满足下列条件的边<i>e</i><sub><i>B</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="323">① <i>w</i> (<i>e</i><sub><i>A</i></sub>) 与<i>w</i> (<i>e</i><sub><i>B</i></sub>) 相差小于指定阈值;</p>
                </div>
                <div class="p1">
                    <p id="324">② 令<i>e</i><sub><i>A</i></sub>= (<i>v</i><sub><i>A</i></sub>, <i>v</i>′<sub><i>A</i></sub>) , <i>e</i><sub><i>B</i></sub>= (<i>v</i><sub><i>B</i></sub>, <i>v</i>′<sub><i>B</i></sub>) , 则点云簇<i>v</i><sub><i>A</i></sub>的图心、法向量等与<i>v</i><sub><i>B</i></sub>相差小于指定阈值, <i>v</i>′<sub><i>A</i></sub>与<i>v</i>′<sub><i>B</i></sub>亦然.</p>
                </div>
                <div class="p1">
                    <p id="325">对<i>G</i><sub><i>A</i></sub>中每条边<i>e</i><sub><i>A</i></sub>, <i>Match</i><sub><i>e</i><sub><i>A</i></sub></sub>可能是空集, 可能含有<i>G</i><sub><i>B</i></sub>中的1条边, 也可能含有<i>G</i><sub><i>B</i></sub>中的多条边.</p>
                </div>
                <div class="p1">
                    <p id="326">2) 初始化.令<i>U</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>为空集, ℓ=0, <i>f</i><sub><i>AB</i></sub>为空映射.在<i>K</i>-公共子图搜索过程中, <i>U</i><sub><i>A</i></sub>是<i>G</i><sub><i>A</i></sub>顶点集的子集, <i>U</i><sub><i>B</i></sub>是<i>G</i><sub><i>B</i></sub>顶点集的子集, <i>f</i><sub><i>AB</i></sub>是从<i>U</i><sub><i>A</i></sub>到<i>U</i><sub><i>B</i></sub>的一一映射.<i>U</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>, <i>f</i><sub><i>AB</i></sub>联合代表已构建的含ℓ个顶点的公共子图, 其中|<i>U</i><sub><i>A</i></sub>|=ℓ=|<i>U</i><sub><i>B</i></sub>|, ℓ≤<i>K</i>.</p>
                </div>
                <div class="p1">
                    <p id="327">3) 公共子图搜索.调用算法2搜索公共子图, <i>DetectSubGraph</i> (<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>, <i>K</i>, <i>U</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>, <i>f</i><sub><i>AB</i></sub>, ℓ) .</p>
                </div>
                <div class="p1">
                    <p id="328"><b>算法2</b>. <i>DetectSubGraph</i>公共子图搜索算法.</p>
                </div>
                <div class="p1">
                    <p id="329">输入:<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>, <i>K</i>, <i>U</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>, <i>f</i><sub><i>AB</i></sub>, ℓ, 其中<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>, <i>K</i>同算法1中, <i>U</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>, <i>f</i><sub><i>AB</i></sub>联合构成<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>的有ℓ个顶点的公共子图, 且ℓ≤<i>K</i>;</p>
                </div>
                <div class="p1">
                    <p id="330">输出:布尔值, 即<i>U</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>, <i>f</i><sub><i>AB</i></sub>是否能扩展为<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>的<i>K</i>-公共子图.</p>
                </div>
                <div class="p1">
                    <p id="331">1) 如果ℓ=<i>K</i>, 则返回真并退出.</p>
                </div>
                <div class="p1">
                    <p id="332">2) 枚举所有满足下列条件的顶点对 (<i>v</i><sub><i>A</i></sub>, <i>v</i><sub><i>B</i></sub>) , 记为<i>CVP</i> (candidate vertex pairs) .</p>
                </div>
                <div class="p1">
                    <p id="333">① <i>v</i><sub><i>A</i></sub>是<i>G</i><sub><i>A</i></sub>中在<i>U</i><sub><i>A</i></sub>外的顶点, <i>v</i><sub><i>B</i></sub>是<i>G</i><sub><i>B</i></sub>中在<i>U</i><sub><i>B</i></sub>外的顶点.</p>
                </div>
                <div class="p1">
                    <p id="334">② 对<i>U</i><sub><i>A</i></sub>中任意顶点<i>u</i><sub><i>A</i></sub>, 边 (<i>v</i><sub><i>B</i></sub>, <i>f</i><sub><i>AB</i></sub> (<i>u</i><sub><i>A</i></sub>) ) 应属于边<i>e</i><sub><i>A</i></sub>的匹配集合<i>Match</i><sub><i>e</i><sub><i>A</i></sub></sub>, 其中边<i>e</i><sub><i>A</i></sub>= (<i>v</i><sub><i>A</i></sub>, <i>u</i><sub><i>A</i></sub>) .</p>
                </div>
                <div class="p1">
                    <p id="335">3) 依次对<i>CVP</i>的顶点对 (<i>v</i><sub><i>A</i></sub>, <i>v</i><sub><i>B</i></sub>) 执行下列操作.</p>
                </div>
                <div class="p1">
                    <p id="336">① 递归调用<i>DetectSubGraph</i> (<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>, <i>K</i>, <i>U</i><sub><i>A</i></sub>∪{<i>v</i><sub><i>A</i></sub>}<i>U</i><sub><i>B</i></sub>∪{<i>v</i><sub><i>B</i></sub>}, <i>f</i><sub><i>AB</i></sub>∪{ (<i>v</i><sub><i>A</i></sub>, <i>v</i><sub><i>B</i></sub>) }, ℓ+1) .</p>
                </div>
                <div class="p1">
                    <p id="337">② 如果返回值为真, 则返回真并退出算法.</p>
                </div>
                <div class="p1">
                    <p id="338">4) 若至此, 则说明<i>CVP</i>中不存在顶点对能与<i>U</i><sub><i>A</i></sub>, <i>U</i><sub><i>B</i></sub>, <i>f</i><sub><i>AB</i></sub>联合扩展为<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>的<i>K</i>-公共子图, 故搜索失败, 返回假并退出算法.</p>
                </div>
                <h4 class="anchor-tag" id="339" name="339"><b>3.3</b><b><i>K</i>-公共子图检测近似算法</b></h4>
                <div class="p1">
                    <p id="340">对实际移动机器人定位与建图应用, 我们提出更高效的<i>K</i>-公共子图检测的随机搜索算法.随机搜索算法与穷尽搜索算法架构相同, 只需将<i>DetectSubGraph</i>算法的步骤3) 和步骤4) 替换为下列步骤:</p>
                </div>
                <div class="p1">
                    <p id="341">随机从<i>CVP</i>中选取1个顶点对 (<i>v</i><sub><i>A</i></sub>, <i>v</i><sub><i>B</i></sub>) , 然后执行以下步骤.</p>
                </div>
                <div class="p1">
                    <p id="342">① 递归调用<i>DetectSubGraph</i> (<i>G</i><sub><i>A</i></sub>, <i>G</i><sub><i>B</i></sub>, <i>K</i>, <i>U</i><sub><i>A</i></sub>∪{<i>v</i><sub><i>A</i></sub>}<i>U</i><sub><i>B</i></sub>∪{<i>v</i><sub><i>B</i></sub>}, <i>f</i><sub><i>AB</i></sub>∪{ (<i>v</i><sub><i>A</i></sub>, <i>v</i><sub><i>B</i></sub>) }, ℓ+1) .</p>
                </div>
                <div class="p1">
                    <p id="343">② 如果返回值为真, 则返回真并退出算法;如果返回值为假, 则返回假并退出算法.</p>
                </div>
                <div class="p1">
                    <p id="344">很显然, 穷尽搜索的最坏复杂度是指数级的, 随机搜索的复杂度则是多项式级的.我们在KITTI数据集的实验表明基于 <i>K</i>-公共子图随机搜索算法的闭环检测与基于<i>K</i>-公共子图穷尽搜索算法的闭环检测这两者的准确度差别不大, 但是在时间耗损上, 随机搜索算法具有巨大的优势.</p>
                </div>
                <h3 id="345" name="345" class="anchor-tag"><b>4</b><b>实验与结果</b></h3>
                <div class="p1">
                    <p id="346">本文所详述的完整的SegGraph算法均以C++实现 (KITTI数据预处理部分利用了Python语言和KITTI官方提供的Python第三方库实现) .我们采用开源的PCL库<sup><a class="sup">[26]</a></sup>来实现算法模块的部分功能和可视化操作等.程序运行在1个图形工作站上, 其CPU为英特尔双核i7-2600, 主频3.4 GHz, 内存4 GB, 操作系统64位Windows 7.我们选取KITTI三维点云数据集<sup><a class="sup">[27]</a></sup>中适合用于闭环检测算法评估的00, 05, 06, 07序列数据进行实验.这4个序列的三维点云数据是以车载三维激光雷达在真实城市街道中扫描获得.KITTI官方提供由高精度GPS/IMU导航系统测得的准确激光雷达位姿信息, 以供闭环检测算法评估之用.这4个序列中各组点云的位姿信息用MatLab软件可视化所得轨迹如图5所示.</p>
                </div>
                <div class="p1">
                    <p id="347">图5中轨迹上每个点代表1组点云 (即1次扫描) 的位置.激光雷达的运动是从黄色的点开始, 由黄绿蓝渐变的方向移动, 到达蓝色的点终止.KITTI的00, 05, 06, 07序列分别含4 541, 2 761, 1 101, 1 101组点云.每组点云由激光雷达在某个位置扫描而得, 约有12万个点.我们以数据集提供的位姿信息作为评估闭环检测算法准确度的依据.每个序列的各组点云是依次在运行轨迹上的位置扫描所得, 所以对扫描次序间隔不大的2组点云, 其对机器人定位与建图依里程计信息估计的误差并不大, 不需再从环境信息加以校正.因而我们在实验中只选取部分扫描次序间隔大于50的点云对作为闭环检测实验的样本, 即对我们选取的每个点云对样本 (<i>A</i>, <i>B</i>) , <i>A</i>和<i>B</i>属于同一个序列, 若<i>A</i>是第<i>i</i><sub><i>A</i></sub>次扫描所得, <i>B</i>是第<i>i</i><sub><i>B</i></sub>次扫描所得, 则|<i>i</i><sub><i>A</i></sub>-<i>i</i><sub><i>B</i></sub>|&gt;50.</p>
                </div>
                <div class="area_img" id="348">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201902010_348.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 KITTI 00, 05, 06, 07序列的位姿信息" src="Detail/GetImg?filename=images/JFYZ201902010_348.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 KITTI 00, 05, 06, 07序列的位姿信息  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201902010_348.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 Pose information of KITTI sequences 00, 05, 06, 07</p>

                </div>
                <div class="p1">
                    <p id="349">对每个点云对样本 (<i>A</i>, <i>B</i>) , 设<i>A</i>和<i>B</i>分别是激光雷达位于全局三维坐标系中位置<i>p</i><sub><i>A</i></sub>和<i>p</i><sub><i>B</i></sub>处获得, 若<i>p</i><sub><i>A</i></sub>, <i>p</i><sub><i>B</i></sub>相距 (欧基里德距离) 小于3 m, 则认为<i>A</i>, <i>B</i>构成闭环, 称 (<i>A</i>, <i>B</i>) 为1个正样本;若<i>p</i><sub><i>A</i></sub>, <i>p</i><sub><i>B</i></sub>相距大于或等于3 m, 则认为<i>A</i>, <i>B</i>不构成闭环, 称 (<i>A</i>, <i>B</i>) 为1个负样本.</p>
                </div>
                <div class="p1">
                    <p id="350">按上述实验设定, 我们计算出KITTI 00序列共有7 403个正样本, 由于负样本数量太多 (由图5可知, 激光雷达车重复经过的点占比很少) , 我们只从00序列中负样本中随机选取10 274个, 即对00序列, 共采用17 677个样本进行闭环检测算法评估.同理, 对05, 06, 07序列, 我们选择所有的正样本并随机选取部分负样本进行实验, 具体来说, 05序列共采用4 827个正样本和10 274个负样本, 06序列1 577个正样本和10 794个负样本, 07序列1 858个正样本和11 242个负样本.</p>
                </div>
                <div class="p1">
                    <p id="351">我们依惯例<sup><a class="sup">[16]</a></sup>以检测率<i>D</i> (detection rate) , 丢失率<i>MD</i> (missed detection rate) , 误报率<i>FA</i> (false alarm rate) 三个指标来衡量闭环检测的准确度.令<i>P</i>表示实验中正样本总数, <i>N</i>表示实验中负样本总数.用<i>TP</i>表示实验中被闭环检测算法判定为闭环而实际为闭环的样本数量, 用<i>FN</i>表示被算法判定为非闭环而实际为闭环的样本数量, 用<i>FP</i>表示被算法判定为闭环而实际为非闭环的样本数量, 则3个指标的计算公式为</p>
                </div>
                <div class="p1">
                    <p id="352" class="code-formula">
                        <mathml id="352"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mi>Ρ</mi></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mi>D</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>Ν</mi></mrow><mi>Ρ</mi></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi>F</mi><mi>A</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>Ρ</mi></mrow><mi>Ν</mi></mfrac><mo>, </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="353">其中, <i>D</i>+<i>MD</i>=1.</p>
                </div>
                <div class="p1">
                    <p id="354">好的闭环检测算法应做到使检测率很高, 丢失率偏低, 而误报率极低, 这是因为在机器人即时定位与建图应用中, 闭环通常是在机器人轨迹中成段连续出现的, 见图5中黄色点和蓝色点的重叠部分.具体地说, 如果存在第<i>i</i>组点云 (由第<i>i</i>次扫描所得) 与第<i>j</i>组点云形成闭环 (<i>i</i>&lt;<i>j</i>) , 则有整数<i>m</i>, 使得对<i>m</i>′=1, 2, …, <i>m</i>, 第<i>i</i>+<i>m</i>′组点云与第<i>j</i>+<i>m</i>′组点云形成闭环.故少量闭环漏检对定位与建图精确度造成影响不大.但是误报的闭环则会使定位与建图出现大偏差, 甚至出现毁灭性的影响.</p>
                </div>
                <div class="p1">
                    <p id="355">每个序列参数<i>K</i>的设定是对该序列分别以<i>K</i>=7, 8, 9, 10, 11, 12运行并综合选取准确度最优的对应<i>K</i>值, 原则是误报率应极低而检测率较高.总的来说, 单组点云分割后所建的图顶点数约为40, <i>K</i>的设定要适当.若<i>K</i>取得太小, 则容易将许多稍有相似但实际上不是闭环的点云对误判为闭环;若<i>K</i>取得太大, 则因点云数据噪声影响容易将许多实际为闭环的点云对误判为非闭环, 并且导致<i>K</i>-公共子图判定的运行时间过大.表1列出了KITTI 06序列在<i>K</i>取不同值时的实验结果:</p>
                </div>
                <div class="area_img" id="356">
                    <p class="img_tit"><b>表1</b><b>取不同<i>K</i>值时SegGraph在KITTI 06序列上的准确度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1</b><b>Accuracy of SegGraph on KITTI Sequence 06 for Different Values of <i>K</i></b></p>
                    <p class="img_note"></p>
                    <table id="356" border="1"><tr><td><br /><i>K</i></td><td><i>D</i>/%</td><td><i>MD</i>/%</td><td><i>FA</i>/%</td></tr><tr><td><br />7</td><td>98.29</td><td>1.71</td><td>10.79</td></tr><tr><td><br />8</td><td>97.34</td><td>2.67</td><td>6.32</td></tr><tr><td><br />9</td><td>95.37</td><td>4.63</td><td>3.29</td></tr><tr><td><br />10</td><td>94.23</td><td>5.77</td><td>0.26</td></tr><tr><td><br />11</td><td>91.50</td><td>8.50</td><td>0.06</td></tr><tr><td><br />12</td><td>87.63</td><td>12.37</td><td>0.00</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="357">从表1可以看出, 当<i>K</i>=10时, SegGraph在KITTI 06序列上的误报率只有0.26%, 而检测率仍高达94.23%, 所以对这个序列我们将参数<i>K</i>设定为10.其他序列参数<i>K</i>的设定与06序列同理.我们最终的实验结果见表2:</p>
                </div>
                <div class="area_img" id="358">
                    <p class="img_tit"><b>表2</b><b>SegGraph在KITTI 00, 05, 06, 07序列上的准确度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2</b><b>Accuracy of SegGraph on KITTI Sequences 00, 05, 06, 07</b></p>
                    <p class="img_note"></p>
                    <table id="358" border="1"><tr><td><br />Sequences</td><td><i>D</i>/%</td><td><i>MD</i>/%</td><td><i>FA</i>/%</td><td><i>K</i></td></tr><tr><td><br />00</td><td>91.46</td><td>8.54</td><td>3.69</td><td>8</td></tr><tr><td><br />05</td><td>92.85</td><td>7.15</td><td>3.16</td><td>7</td></tr><tr><td><br />06</td><td>94.23</td><td>5.77</td><td>0.26</td><td>10</td></tr><tr><td><br />07</td><td>91.54</td><td>8.49</td><td>8.74</td><td>12</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="359">实验表明我们提出的SegGraph闭环检测算法在KITTI 4个序列中都取得了理想的检测率和较低的丢失率.在误报率方面, 06序列的效果最为明显, 仅为0.26%;00, 05序列误报率都能控制在3%左右;07序列的误报率偏高, 达到了8.74%, 由图5的位姿信息可看出, 07序列和其他序列最大的不同在于07序列中激光雷达车几乎没有重复走过同一段路线, 即图5中颜色几乎没有重合的部分, 所以导致了闭环信息较少, 同时07序列中有2段相距很远但结构与外观都非常相似的街道, 这就导致了算法将这些不是闭环的样本误判为闭环, 该序列在其他闭环检测算法的实验中<sup><a class="sup">[19]</a></sup>效果也不理想.</p>
                </div>
                <div class="p1">
                    <p id="360">我们还测量了SegGraph的运行时间, 对单个点云对, SegGraph运行分两大部分:第1部分是点云分割和点云簇局部特征提取时间;第2部分是<i>K</i>-公共子图检测.由于正样本与负样本在第2部分所花时间差距甚大, 我们对正负样本在第2部分所花时间分开测量.表3给出了KITTI 06序列的运行时间统计 (单位为s) , 其中<i>t</i><sub>min</sub>和<i>t</i><sub>max</sub>分别表示单个点云对的最小耗时和最大耗时, <i>t</i><sub>avg</sub>表示所有点云对的平均耗时.其他序列的运行时间与06序列类似.</p>
                </div>
                <div class="area_img" id="361">
                    <p class="img_tit"><b>表3</b><b>SegGraph在KITTI 06序列上的运行时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3</b><b>Running Time of SegGraph on KITTI Sequence 06</b></p>
                    <p class="img_note">s</p>
                    <table id="361" border="1"><tr><td rowspan="2"><br />Running Time</td><td rowspan="2">Part 1</td><td colspan="2"><br />Part 2</td></tr><tr><td><br />Pos</td><td>Neg</td></tr><tr><td><br /><i>t</i><sub>min</sub></td><td>19.846</td><td>0.879</td><td>0.126</td></tr><tr><td><br /><i>t</i><sub>max</sub></td><td>39.415</td><td>1.132</td><td>0.283</td></tr><tr><td><br /><i>t</i><sub>avg</sub></td><td>22.183</td><td>0.975</td><td>0.254</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="362">从表3可以看出, SegGraph第2部分时间中, 正样本的检测时间大约是负样本检测时间的4倍, 这是由于在正样本中, 边匹配成功的较多, 相应迭代的次数就更多, 所以花费的时间就更长.从总体时间上看, 第1部分占据了大部分时间, 这是因为在该过程中, 使用了区域增长算法来进行点云分割, 该算法需要求出点云中每个点的曲率和法向量, 这个步骤需要消耗大量的时间.相比于其他适用于城市街道的点云分割算法如欧基里德分割算法, 虽然区域增长算法在时间上不占优势, 但是欧基里德算法分割的结果为无规则状的点云簇, 而我们所采用的区域增长分割算法分割出来的点云簇则非常接近光滑的平面, 这使得<i>K</i>-公共子图检测中基于点云簇局部特征优化更加简洁和高效.同时, 区域增长分割算法相对欧基里德分割算法来说更为精确且鲁棒性更好, 前者基于曲率的变化增长, 后者根据距离的远近聚类<sup><a class="sup">[22]</a></sup>, 假如存在一些雷达扫描不可避免的噪声点, 很有可能本应属于2个点云簇的局部点云被欧基里德算法聚为了同一类, 这是因为噪声点干扰了算法中对距离的判定.而区域增长分割算法受噪声点干扰的程度远没有欧基里德分割算法大.</p>
                </div>
                <div class="p1">
                    <p id="363">区域增长分割算法中的主要耗时在于求点云中每个点的曲率和法向量.每个点的曲率和法向量只需从其邻近若干点的几何信息计算得出<sup><a class="sup">[25]</a></sup>, 因而对点云中各个点, 其曲率及法向量的计算可以并行执行.如果将这部分计算在多核或GPU平台上实现, 将能大大降低区域增长分割算法的运行时间.这将是我们下一步的工作.</p>
                </div>
                <h3 id="364" name="364" class="anchor-tag"><b>5</b><b>总</b><b>结</b></h3>
                <div class="p1">
                    <p id="365">本文提出适用于室外场景三维点云数据的闭环检测算法SegGraph.算法主要有3个步骤:1) 对输入的2组点云分别移除大地平面后采用区域增长算法分割为点云簇集, 并提取每个点云簇的局部特征;2) 分别以点云簇集为顶点集, 以点云簇间距离为边的权值, 构建无向完全图;3) 通过检测它们是否含<i>K</i>-公共子图来判定2组输入点云是否有较高的相似度, 其中<i>K</i>是根据实际情况可以调整的参数.我们提出了检测<i>K</i>-公共子图的高效随机搜索近似算法.在公开数据集KITTI的4个序列上的实验表明SegGraph有良好的准确度和运行效率.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="408">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simultaneous localization and mapping">

                                <b>[1]</b>Thrun S, Leonard J J.Simultaneous localization and mapping[M]Springer Handbook of Robotics.Berlin:Springer, 2008:871-889
                            </a>
                        </p>
                        <p id="410">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501998989&amp;v=MDUyNDlvOUViZUlIQlhRd29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsd2NhaGM9TmlmT2ZiSzdIdEROcQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Williams B, Cummins M, Neira J, et al.A comparison of loop closing techniques in monocular SLAM[J].Robotics and Autonomous Systems, 2009, 57 (12) :1188-1197
                            </a>
                        </p>
                        <p id="412">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Past,present,and future of simultaneous localization and mapping:Towards the robust-perception age">

                                <b>[3]</b>Cadena C, Carlone L, Carrillo H, et al.Past, present, and future of simultaneous localization and mapping:Towards the robust-perception age[J].IEEE Robotics and Automation Society, 2016, 32 (16) :1309-1332
                            </a>
                        </p>
                        <p id="414">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Maximum common subgraph isomorphism algorithms and their applications in molecular science: a review">

                                <b>[4]</b>Ehrlich H, Rarey M.Maximum common subgraph isomorphism algorithms and their applications in molecular science:A review[J].Wiley Interdisciplinary Reviews Computational Molecular Science, 2011, 1 (1) :68-79
                            </a>
                        </p>
                        <p id="416">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A method for registration of 3D shapes">

                                <b>[5]</b>Besl P J, McKay N D.A method for registration of 3-Dshapes[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1992, 14 (2) :239-256
                            </a>
                        </p>
                        <p id="418">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generalized-ICP">

                                <b>[6]</b>Segal A, Haehnel D, Thrun S.Generalized-ICP[C]Robotics Science and Systems V.Cambridge, MA:MITPress, 2009:120-130
                            </a>
                        </p>
                        <p id="420">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098653&amp;v=MTY1MTljYWhjPU5pZklZN0s3SHRqTnI0OUZaT0lIQ25rNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsdw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>Aiger D, Mitra N J, Cohen-Or D.4-points congruent sets for robust pairwise surface registration[J].ACM Transactions on Graphics, 2008, 27 (3) :85-86
                            </a>
                        </p>
                        <p id="422">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD14082500000128&amp;v=MzE1NTZhcks4SHRuT3FvOUZaT3NQRFg0eG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsd2NhaGM9TmlmYw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Mellado N, Aiger D, Niloy J, et al.Super 4PCS fast global pointcloud registration via smart indexing[J].Computer Graphics Forum, 2014, 33 (5) :205-215
                            </a>
                        </p>
                        <p id="424">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Place recognition using keypoint voting in large 3Dlidar datasets">

                                <b>[9]</b>Bosse M, Zlot R.Place recognition using keypoint voting in large 3Dlidar datasets[C]Proc of the 30th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2013:2677-2684
                            </a>
                        </p>
                        <p id="426">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Structure-based vision-laser matching">

                                <b>[10]</b>Gawel A, Cieslewski T, DubéR, et al.Structure-based vision-laser matching[C]Proc of the 28th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2016:182-188
                            </a>
                        </p>
                        <p id="428">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3-D-Laser-Based Scene Measurement and Place Recognition for Mobile Robots in Dynamic Indoor Environments">

                                <b>[11]</b>Zhuang Yan, Jiang Nan, Hu Huosheng, et al.3D-laserbased scene measurement and place recognition for mobile robots in dynamic indoor environments[J].IEEE Transactions on Instrumentation and Measurement, 2013, 66 (2) :438-450
                            </a>
                        </p>
                        <p id="430">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast point feature histograms (FPFH) for 3-D registration">

                                <b>[12]</b>Rusu R B, Blodow N, Beetz M.Fast point feature histograms (FPFH) for 3Dregistration[C]Proc of the26th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2009:3212-3217
                            </a>
                        </p>
                        <p id="432">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                Rusu R B, Bradski G, Thibaux R, et al.Fast 3Drecognition and pose using the viewpoint feature histogram[C]Proc of the 22nd IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2010:2155-2162
                            </a>
                        </p>
                        <p id="434">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CAD-model recognition and 6DOF pose estimation using 3Dcues">

                                <b>[14]</b>Aldoma A, Vincze M, Blodow N, et al.CAD-model recognition and 6DOF pose estimation using 3Dcues[C]Proc of the 13th IEEE Int Conf on Computer Vision Workshops.Piscataway, NJ:IEEE, 2011:585-592
                            </a>
                        </p>
                        <p id="436">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A fast histogram based similarity measure for detecting loop closures in 3-D lidar data">

                                <b>[15]</b>Rohling T, Mack J, Schulz D.A fast histogram based similarity measure for detecting loop closures in 3-D lidar data[C]Proc of the 27th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2015:736-741
                            </a>
                        </p>
                        <p id="438">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning to close loops from range data">

                                <b>[16]</b>Granstr9m K, Sch9n T B, Nieto J I, et al.Learning to close loops from range data[J].International Journal of Robotics Research, 2011, 30 (14) :1728-1754
                            </a>
                        </p>
                        <p id="440">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017195744.nh&amp;v=MjI3OTgvTlZGMjZHYkt4RzliSXE1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeTduVzc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>Xiang Haodong.Research on loop closing based on threedimensional laser point cloud in indoor environment[D].Wuhan:Wuhan University, 2017 (in Chinese) (项皓东.基于室内三维激光点云的闭环检测方法研究[D].武汉:武汉大学, 2017) 
                            </a>
                        </p>
                        <p id="442">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic appearance-based loop detection from three-dimensional laser data using the normal distributions transform">

                                <b>[18]</b>Magnusson M, Andreasson H, Nüchter A, et al.Automatic appearance-based loop detection from three dimensional laser data using the normal distributions transform[J].Journal of Field Robotics, 2009, 26 (11/12) :892-914
                            </a>
                        </p>
                        <p id="444">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=M2DP:A novel 3Dpoint cloud descriptor and its application in loop closure detection">

                                <b>[19]</b>He Li, Wang Xiaolong, Zhang Hong.M2DP:A novel 3Dpoint cloud descriptor and its application in loop closure detection[C]Proc of the 28th IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2016:231-237
                            </a>
                        </p>
                        <p id="446">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast place recognition with plane-based maps">

                                <b>[20]</b>Fernandez-Moral E, Mayol-Cuevas W, Arevalo V, et al.Fast place recognition with plane-based maps[C]Proc of the 30th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2013:2719-2724
                            </a>
                        </p>
                        <p id="448">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SegMatch:Segment based place recognition in 3Dpoint clouds">

                                <b>[21]</b>DubéR, Dugas D, Stumm E, et al.SegMatch:Segment based place recognition in 3Dpoint clouds[C]Proc of the34th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2017:5266-5272
                            </a>
                        </p>
                        <p id="450">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the segmentation of 3D LIDAR point clouds">

                                <b>[22]</b>Douillard B, Underwood J, Kuntz N, et al.On the segmentation of 3D LIDAR point clouds[C]Proc of the28th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2011:2798-2805
                            </a>
                        </p>
                        <p id="452">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A partitioned approach for efficient graph-based place recognition">

                                <b>[23]</b>Gollub M G, DubéR, Sommer H, et al.A partitioned approach for efficient graph-based place recognition[EB/OL].2017[2018-05-14].http:ppniv17.irccyn.ec-nantes.fr/session5/Gollub/paper.pdf
                            </a>
                        </p>
                        <p id="454">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Close-range scene segmentation and reconstruction of 3Dpoint cloud maps for mobile manipulation in domestic environments">

                                <b>[24]</b>Rusu R B, Blodow N, Marton Z C, et al.Close-range scene segmentation and reconstruction of 3Dpoint cloud maps for mobile manipulation in domestic environments[C]Proc of the 21st IEEE/RSJ Int Conf on Intelligent Robots and Systems.Piscataway, NJ:IEEE, 2009:1-6
                            </a>
                        </p>
                        <p id="456">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmentation of point clouds using smoothness constraint">

                                <b>[25]</b>Rabbania T, Heuvelb F A, Vosselmanc G.Segmentation of point clouds using smoothness constraint[J].International Society for Photogrammetry and Remote Sensing, 2006, 36 (5) :248-253
                            </a>
                        </p>
                        <p id="458">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D is here: Point cloud library (PCL)">

                                <b>[26]</b>Rusu R B, Cousins S, Garage W.3Dis here:Point cloud library (PCL) [C]Proc of the 28th IEEE Int Conf on Robotics and Automation.Piscataway, NJ:IEEE, 2011:1-4
                            </a>
                        </p>
                        <p id="460">
                            <a id="bibliography_27" >
                                    <b>[27]</b>
                                Geiger A, Lenz P, Stiller C, et al.Vision meets robotics:The KITTI dataset[J].International Journal of Robotics Research, 2013, 32 (11) :1231-1237
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="202" href="javascript:void(0)">
                            <b>1</b> http://pointclouds.org
                        </span>
                    </p>
                    <p>
                        <span id="204" href="javascript:void(0)">
                            <b>2</b> https://github.com/Jarily/SegGraph
                        </span>
                    </p>
                    <p>
                        <span id="206" href="javascript:void(0)">
                            <b>3</b> http://www.cvlibs.net/datasets/kitti/eval_odometry.php
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201902010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201902010&amp;v=MTQzMDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N25XNy9LTHl2U2RMRzRIOWpNclk5RVpJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
