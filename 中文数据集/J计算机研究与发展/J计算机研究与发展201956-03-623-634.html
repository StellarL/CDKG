<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133238050908750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJFYZ201903017%26RESULT%3d1%26SIGN%3dSS6nzcVmehsBUKJJobNtBm5%252bzRk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201903017&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JFYZ201903017&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201903017&amp;v=MzExMTVxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N25VcjdOTHl2U2RMRzRIOWpNckk5RVk0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#74" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#84" data-title="&lt;b&gt;2 基本知识&lt;/b&gt; "><b>2 基本知识</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#86" data-title="&lt;b&gt;2.1 基本定义&lt;/b&gt;"><b>2.1 基本定义</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#102" data-title="&lt;b&gt;3 层次粒度表示的属性图链接预测模型&lt;/b&gt; "><b>3 层次粒度表示的属性图链接预测模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#103" data-title="&lt;b&gt;3.1 问题描述&lt;/b&gt;"><b>3.1 问题描述</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;3.2 层次粒度表示的属性图链接预测模型&lt;/b&gt;"><b>3.2 层次粒度表示的属性图链接预测模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#186" data-title="&lt;b&gt;4 模型参数学习&lt;/b&gt; "><b>4 模型参数学习</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#236" data-title="&lt;b&gt;5 层次粒度表示模型的链接预测&lt;/b&gt; "><b>5 层次粒度表示模型的链接预测</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#238" data-title="&lt;b&gt;5.1 协同预测&lt;/b&gt;"><b>5.1 协同预测</b></a></li>
                                                <li><a href="#249" data-title="&lt;b&gt;5.2 预测算法&lt;/b&gt;"><b>5.2 预测算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#259" data-title="&lt;b&gt;6 实验与结果&lt;/b&gt; "><b>6 实验与结果</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#261" data-title="&lt;b&gt;6.1 数据集&lt;/b&gt;"><b>6.1 数据集</b></a></li>
                                                <li><a href="#267" data-title="&lt;b&gt;6.2 对比标准&lt;/b&gt;"><b>6.2 对比标准</b></a></li>
                                                <li><a href="#272" data-title="&lt;b&gt;6.3 案例分析&lt;/b&gt;"><b>6.3 案例分析</b></a></li>
                                                <li><a href="#296" data-title="&lt;b&gt;6.4 其他数据集上的结果&lt;/b&gt;"><b>6.4 其他数据集上的结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#301" data-title="&lt;b&gt;7 结 论&lt;/b&gt; "><b>7 结 论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="图1 一个示例链接网络">图1 一个示例链接网络</a></li>
                                                <li><a href="#89" data-title="图2 层次粒度表示的属性图链接预测模型框架图">图2 层次粒度表示的属性图链接预测模型框架图</a></li>
                                                <li><a href="#265" data-title="&lt;b&gt;表1 示例数据集结点的属性信息&lt;/b&gt;"><b>表1 示例数据集结点的属性信息</b></a></li>
                                                <li><a href="#266" data-title="&lt;b&gt;表2 数据集基本统计信息&lt;/b&gt;"><b>表2 数据集基本统计信息</b></a></li>
                                                <li><a href="#275" data-title="图5 HGRLPM模型链接预测结果">图5 HGRLPM模型链接预测结果</a></li>
                                                <li><a href="#276" data-title="图3 HGRLPM模型在示例数据集上的训练收敛过程">图3 HGRLPM模型在示例数据集上的训练收敛过程</a></li>
                                                <li><a href="#278" data-title="图4 HGRLPM得到的社区重要度与结点-社区关系">图4 HGRLPM得到的社区重要度与结点-社区关系</a></li>
                                                <li><a href="#281" data-title="&lt;b&gt;表3 HGRLPM预测的所有结点对链接概率&lt;/b&gt;"><b>表3 HGRLPM预测的所有结点对链接概率</b></a></li>
                                                <li><a href="#294" data-title="&lt;b&gt;表4 示例数据集的性能对比&lt;/b&gt;"><b>表4 示例数据集的性能对比</b></a></li>
                                                <li><a href="#298" data-title="&lt;b&gt;表5 AmazonFail的性能对比&lt;/b&gt;"><b>表5 AmazonFail的性能对比</b></a></li>
                                                <li><a href="#299" data-title="&lt;b&gt;表6 Lazega的性能对比&lt;/b&gt;"><b>表6 Lazega的性能对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="342">


                                    <a id="bibliography_1" title="L&#252; Linyuan, Zhou Tao. Link prediction in complex networks: A survey[J]. Physica A: Statistical Mechanics &amp;amp; Its Applications, 2011, 390 (6) : 1150- 1170" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100530194&amp;v=MDQ2MzlGWWVnUERYVTlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKbHdWYXhjPU5pZk9mYks3SHRET3JvOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        L&#252; Linyuan, Zhou Tao. Link prediction in complex networks: A survey[J]. Physica A: Statistical Mechanics &amp;amp; Its Applications, 2011, 390 (6) : 1150- 1170
                                    </a>
                                </li>
                                <li id="344">


                                    <a id="bibliography_2" title="Zhao Shu, Liu Xiaoman, Duan Zhen, et al. A survey on social ties mining[J]. Chinese Journal of Computers, 2017, 40 (3) : 535- 555 (in Chinese) (赵姝, 刘晓曼, 段震, 等. 社交关系挖掘研究综述[J]. 计算机学报, 2017, 40 (3) : 535- 555) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201703001&amp;v=Mjk2NThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3blVyN05MejdCZHJHNEg5Yk1ySTlGWlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Zhao Shu, Liu Xiaoman, Duan Zhen, et al. A survey on social ties mining[J]. Chinese Journal of Computers, 2017, 40 (3) : 535- 555 (in Chinese) (赵姝, 刘晓曼, 段震, 等. 社交关系挖掘研究综述[J]. 计算机学报, 2017, 40 (3) : 535- 555) 
                                    </a>
                                </li>
                                <li id="346">


                                    <a id="bibliography_3" title="Libennowell D, Kleinberg J. The link prediciton problem for social networks[J]. Journal of the Association for Information Science &amp;amp; Technology, 2007, 58 (7) : 1019- 1031" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The link-prediction problem for social networks">
                                        <b>[3]</b>
                                        Libennowell D, Kleinberg J. The link prediciton problem for social networks[J]. Journal of the Association for Information Science &amp;amp; Technology, 2007, 58 (7) : 1019- 1031
                                    </a>
                                </li>
                                <li id="348">


                                    <a id="bibliography_4" title="Kim M, Leskovec J. Multiplicative attribute graph model of real world networks[C] //Proc of the Int Workshop on Algorithms and Models for the Web-Graph. Berlin: Springer, 2010: 62- 73" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiplicative attribute graph model of real world networks">
                                        <b>[4]</b>
                                        Kim M, Leskovec J. Multiplicative attribute graph model of real world networks[C] //Proc of the Int Workshop on Algorithms and Models for the Web-Graph. Berlin: Springer, 2010: 62- 73
                                    </a>
                                </li>
                                <li id="350">


                                    <a id="bibliography_5" title="Newman M E J. Clustering and preferential attachment in growing networks[J]. Physical Review E-Statistical, Nonlinear and Soft Matter Physics, 2001, 64 (2) : 025102" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering and preferential attachment in growing networks">
                                        <b>[5]</b>
                                        Newman M E J. Clustering and preferential attachment in growing networks[J]. Physical Review E-Statistical, Nonlinear and Soft Matter Physics, 2001, 64 (2) : 025102
                                    </a>
                                </li>
                                <li id="352">


                                    <a id="bibliography_6" title="Jaccard P. Etude de la distribution florale dans une portion des Alpes et du Jura[J]. Bulletin De La Societe Vaudoise Des Sciences Naturelles, 1901, 37 (142) : 547- 579" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Etude comparative de la distribution florale dans une portion des Alpes et des Jura">
                                        <b>[6]</b>
                                        Jaccard P. Etude de la distribution florale dans une portion des Alpes et du Jura[J]. Bulletin De La Societe Vaudoise Des Sciences Naturelles, 1901, 37 (142) : 547- 579
                                    </a>
                                </li>
                                <li id="354">


                                    <a id="bibliography_7" title="Salton G, Mcgill M J. Introduction to Modern Information Retrieval[M]. New York: McGraw-Hill, 1983: 305- 306" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Introduction to Modern Information Retrieval">
                                        <b>[7]</b>
                                        Salton G, Mcgill M J. Introduction to Modern Information Retrieval[M]. New York: McGraw-Hill, 1983: 305- 306
                                    </a>
                                </li>
                                <li id="356">


                                    <a id="bibliography_8" title="Zhou Tao, L&#252; Linyuan, Zhang Yicheng. Predicting missing links via local information[J]. European Physical Journal B, 2009, 71 (4) : 623- 630" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003593437&amp;v=MjI3MDRidWR0RlNubFZiM0pJVnM9Tmo3QmFyTzRIdEhQcW9aR1lPZ0lZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3Fl&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Zhou Tao, L&#252; Linyuan, Zhang Yicheng. Predicting missing links via local information[J]. European Physical Journal B, 2009, 71 (4) : 623- 630
                                    </a>
                                </li>
                                <li id="358">


                                    <a id="bibliography_9" title="Adamic L A, Adar E. Friends and neighbors on the Web[J]. Social Networks, 2003, 25 (3) : 211- 230" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100484987&amp;v=MDk5MzBmT2ZiSzdIdERPcm85RllPTUxCWFErb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSmx3VmF4Yz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Adamic L A, Adar E. Friends and neighbors on the Web[J]. Social Networks, 2003, 25 (3) : 211- 230
                                    </a>
                                </li>
                                <li id="360">


                                    <a id="bibliography_10" title="Clauset A, Moore C, Newman M E. Hierarchical structure and the prediction of missing links in networks[J]. Nature, 2008, 453 (7191) : 98- 101" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical structure and the prediction of missing links in networks">
                                        <b>[10]</b>
                                        Clauset A, Moore C, Newman M E. Hierarchical structure and the prediction of missing links in networks[J]. Nature, 2008, 453 (7191) : 98- 101
                                    </a>
                                </li>
                                <li id="362">


                                    <a id="bibliography_11" title="Friedman N, Getoor L, Koller D, et al. Learning probabilistic relational models[C] //Proc of the 16th Int Joint Conf on Artificial Intelligence. San Francisco: Morgan Kaufmann, 1999: 1300- 1309" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning Probabilistic Relational Models">
                                        <b>[11]</b>
                                        Friedman N, Getoor L, Koller D, et al. Learning probabilistic relational models[C] //Proc of the 16th Int Joint Conf on Artificial Intelligence. San Francisco: Morgan Kaufmann, 1999: 1300- 1309
                                    </a>
                                </li>
                                <li id="364">


                                    <a id="bibliography_12" title="Taskar B, Wong M F, Abbeel P, et al. Link prediction in relational data[C] //Proc of the 16th Int Conf on Neural Information Processing Systems. Cambridge: MIT Press, 2003: 659- 666" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Link Prediction in Relational Data,&amp;quot;">
                                        <b>[12]</b>
                                        Taskar B, Wong M F, Abbeel P, et al. Link prediction in relational data[C] //Proc of the 16th Int Conf on Neural Information Processing Systems. Cambridge: MIT Press, 2003: 659- 666
                                    </a>
                                </li>
                                <li id="366">


                                    <a id="bibliography_13" title="Neville J, Jensen D. Relational dependency networks[J]. Journal of Machine Learning Research, 2007, 8 (2) : 653- 692" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relational dependency networks">
                                        <b>[13]</b>
                                        Neville J, Jensen D. Relational dependency networks[J]. Journal of Machine Learning Research, 2007, 8 (2) : 653- 692
                                    </a>
                                </li>
                                <li id="368">


                                    <a id="bibliography_14" title="Liu Zhen, Zhang Qianming, L&#252; Linyuan, et al. Link prediction in complex networks: A local naive bayes model[J]. Europhysics Letters, 2011, 96 (4) : 8007" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPD00000092103&amp;v=MTM5NzdCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVmIzSklWcz1OaVRiYXJPNEh0SE1yNFpIWmVzTVkzazV6&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Liu Zhen, Zhang Qianming, L&#252; Linyuan, et al. Link prediction in complex networks: A local naive bayes model[J]. Europhysics Letters, 2011, 96 (4) : 8007
                                    </a>
                                </li>
                                <li id="370">


                                    <a id="bibliography_15" title="Wang Chao, Satuluri V, Parthasarathy S. Local probabilistic models for link prediction[C] //Proc of the 7th IEEE Int Conf on Data Mining. Los Alamitos, CA: IEEE Computer Society, 2007: 322- 331" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local probabilistic models for link prediction">
                                        <b>[15]</b>
                                        Wang Chao, Satuluri V, Parthasarathy S. Local probabilistic models for link prediction[C] //Proc of the 7th IEEE Int Conf on Data Mining. Los Alamitos, CA: IEEE Computer Society, 2007: 322- 331
                                    </a>
                                </li>
                                <li id="372">


                                    <a id="bibliography_16" title="Menon A K, Elkan C. Link prediction via matrix factorization[C] //Proc of the 2011 European Conf on Machine Learning and Knowledge Discovery in Databases. Berlin: Springer, 2011: 437- 452" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Link Prediction via Matrix Factorization">
                                        <b>[16]</b>
                                        Menon A K, Elkan C. Link prediction via matrix factorization[C] //Proc of the 2011 European Conf on Machine Learning and Knowledge Discovery in Databases. Berlin: Springer, 2011: 437- 452
                                    </a>
                                </li>
                                <li id="374">


                                    <a id="bibliography_17" title="Dunlavy D M, Kolda T G, Acar E. Temporal link prediction using matrix and tensor factorizations[J]. ACM Transactions on Knowledge Discovery from Data, 2011, 5 (2) : 10:1- 10:27" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000093225&amp;v=MDIzMDZ3VmF4Yz1OaWZJWTdLN0h0ak5yNDlGWk9JTURuNDhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0lKbA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                        Dunlavy D M, Kolda T G, Acar E. Temporal link prediction using matrix and tensor factorizations[J]. ACM Transactions on Knowledge Discovery from Data, 2011, 5 (2) : 10:1- 10:27
                                    </a>
                                </li>
                                <li id="376">


                                    <a id="bibliography_18" title="Fan Xuhui, Xu Yida, Cao Longbing, et al. Learning nonparametric relational models by conjugately incorporating node information in a network[J]. IEEE Transactions on Cybernetics, 2017, 47 (3) : 589- 599" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning nonparametric relational models by conjugately incorporating node information in a network">
                                        <b>[18]</b>
                                        Fan Xuhui, Xu Yida, Cao Longbing, et al. Learning nonparametric relational models by conjugately incorporating node information in a network[J]. IEEE Transactions on Cybernetics, 2017, 47 (3) : 589- 599
                                    </a>
                                </li>
                                <li id="378">


                                    <a id="bibliography_19" title="Miller K T, Griffiths T L, Jordan M I. Nonparametric latent feature models for link prediction[C] //Proc of the 22nd Int Conf on Neural Information Processing Systems. Vancouver: Curran Associates, 2009: 1276- 1284" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonparametric latent feature models for link prediction">
                                        <b>[19]</b>
                                        Miller K T, Griffiths T L, Jordan M I. Nonparametric latent feature models for link prediction[C] //Proc of the 22nd Int Conf on Neural Information Processing Systems. Vancouver: Curran Associates, 2009: 1276- 1284
                                    </a>
                                </li>
                                <li id="380">


                                    <a id="bibliography_20" title="Wang Xin, Wang Ying, Zuo Wanli. Exploring interactional opinions and status theory for predicting links in signed network[J]. Journal of Computer Research and Development, 2016, 53 (4) : 764- 775 (in Chinese) (王鑫, 王英, 左万利. 基于交互意见和地位理论的符号网络链接预测模型[J]. 计算机研究与发展, 2016, 53 (4) :764- 775) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201604005&amp;v=MzE2NzN5N25VcjdOTHl2U2RMRzRIOWZNcTQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                        Wang Xin, Wang Ying, Zuo Wanli. Exploring interactional opinions and status theory for predicting links in signed network[J]. Journal of Computer Research and Development, 2016, 53 (4) : 764- 775 (in Chinese) (王鑫, 王英, 左万利. 基于交互意见和地位理论的符号网络链接预测模型[J]. 计算机研究与发展, 2016, 53 (4) :764- 775) 
                                    </a>
                                </li>
                                <li id="382">


                                    <a id="bibliography_21" title="Liu Ye, Zhu Weiheng, Pan Yan, et al. Multiple sources fusion for link prediction via low-rank and sparse matrix decomposition[J]. Journal of Computer Research and Development, 2015, 52 (2) : 423- 436 (in Chinese) (刘冶, 朱蔚恒, 潘炎, 等. 基于低秩和稀疏矩阵分解的多源融合链接预测算法[J]. 计算机研究与发展, 2015, 52 (2) : 423- 436) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201502016&amp;v=MjIzODZHNEg5VE1yWTlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3blVyN05MeXZTZEw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        Liu Ye, Zhu Weiheng, Pan Yan, et al. Multiple sources fusion for link prediction via low-rank and sparse matrix decomposition[J]. Journal of Computer Research and Development, 2015, 52 (2) : 423- 436 (in Chinese) (刘冶, 朱蔚恒, 潘炎, 等. 基于低秩和稀疏矩阵分解的多源融合链接预测算法[J]. 计算机研究与发展, 2015, 52 (2) : 423- 436) 
                                    </a>
                                </li>
                                <li id="384">


                                    <a id="bibliography_22" title="Zhang Zehua, Miao Duoqian, Qian Jin. Detecting overlapping communities with heuristic expansion mehtod based on rough neighborhood[J]. Chinese Journal of Computers, 2013, 36 (10) : 2078- 2086 ( in Chinese) (张泽华, 苗夺谦, 钱进. 邻域粗糙化的启发式重叠社区扩张方法[J]. 计算机学报, 2013, 36 (10) : 2078- 2086) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201310013&amp;v=MDUwMjFyQ1VSTE9lWmVWdkZ5N25VcjdOTHo3QmRyRzRIOUxOcjQ5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        Zhang Zehua, Miao Duoqian, Qian Jin. Detecting overlapping communities with heuristic expansion mehtod based on rough neighborhood[J]. Chinese Journal of Computers, 2013, 36 (10) : 2078- 2086 ( in Chinese) (张泽华, 苗夺谦, 钱进. 邻域粗糙化的启发式重叠社区扩张方法[J]. 计算机学报, 2013, 36 (10) : 2078- 2086) 
                                    </a>
                                </li>
                                <li id="386">


                                    <a id="bibliography_23" title="Yao Yiyu. Interpreting concept learning in cognitive informatics and granular computing[J]. IEEE Transactions on Systems Man &amp;amp; Cybernetics , Part B (Cybernetics) , 2009, 39 (4) : 855- 866" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interpreting concept learning in cognitive informatics and granular computing">
                                        <b>[23]</b>
                                        Yao Yiyu. Interpreting concept learning in cognitive informatics and granular computing[J]. IEEE Transactions on Systems Man &amp;amp; Cybernetics , Part B (Cybernetics) , 2009, 39 (4) : 855- 866
                                    </a>
                                </li>
                                <li id="388">


                                    <a id="bibliography_24" title="Yao Yiyu, Zhao Liquan. A measurement theory view on the granularity of partitions[J]. Information Sciences, 2012, 213 (2012) : 1- 13" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601416145&amp;v=Mjg3NDVlWnVIeWptVWI3SUpsd1ZheGM9TmlmT2ZiSzdIdEROcVk5RVlPb0pEWGc4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                        Yao Yiyu, Zhao Liquan. A measurement theory view on the granularity of partitions[J]. Information Sciences, 2012, 213 (2012) : 1- 13
                                    </a>
                                </li>
                                <li id="390">


                                    <a id="bibliography_25" title="Breiger R L. The duality of persons and groups[J]. Social Forces, 1974, 53 (2) :181- 190" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The duality of persons and groups">
                                        <b>[25]</b>
                                        Breiger R L. The duality of persons and groups[J]. Social Forces, 1974, 53 (2) :181- 190
                                    </a>
                                </li>
                                <li id="392">


                                    <a id="bibliography_26" title="Yang Jaewon, Leskovec J. Overlapping community detection at scale: A nonnegative matrix factorization approach[C] //Proc of the 6th ACM Int Conf on Web Search &amp;amp; Data Mining. New York: ACM, 2013: 587- 596" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Overlapping community detection at scale: A nonnegative matrix factorization approach">
                                        <b>[26]</b>
                                        Yang Jaewon, Leskovec J. Overlapping community detection at scale: A nonnegative matrix factorization approach[C] //Proc of the 6th ACM Int Conf on Web Search &amp;amp; Data Mining. New York: ACM, 2013: 587- 596
                                    </a>
                                </li>
                                <li id="394">


                                    <a id="bibliography_27" title="Hsieh C J, Dhillon I S. Fast coordinate descent methods with variable selection for non-negative matrix factorization[C] //Proc of the 17th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2011: 1064- 1072" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast Coordinate Descent Methods with Variable Selectionfor Non-negative Matrix Factorization">
                                        <b>[27]</b>
                                        Hsieh C J, Dhillon I S. Fast coordinate descent methods with variable selection for non-negative matrix factorization[C] //Proc of the 17th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2011: 1064- 1072
                                    </a>
                                </li>
                                <li id="396">


                                    <a id="bibliography_28" title="Sanchez P I, Muller E, Laforet F, et al. Statistical selection of congruent subspaces for mining attributed graphs[C] //Proc of the 13th IEEE Int Conf on Data Mining. Piscataway, NJ: IEEE, 2013: 647- 656" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Statistical selection of congruent subspaces for mining attributed graphs">
                                        <b>[28]</b>
                                        Sanchez P I, Muller E, Laforet F, et al. Statistical selection of congruent subspaces for mining attributed graphs[C] //Proc of the 13th IEEE Int Conf on Data Mining. Piscataway, NJ: IEEE, 2013: 647- 656
                                    </a>
                                </li>
                                <li id="398">


                                    <a id="bibliography_29" title="Snijders T A B, Pattison P E, Robins G L, et al. New specifications for exponential random graph models[J]. Sociological Methodology, 2010, 36 (1) : 99- 153" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001282341&amp;v=MjY5MjRSN3FlYnVkdEZTbmxWYjNKSVZzPU5pZmNhck80SHRITnJZZEhaKzhPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[29]</b>
                                        Snijders T A B, Pattison P E, Robins G L, et al. New specifications for exponential random graph models[J]. Sociological Methodology, 2010, 36 (1) : 99- 153
                                    </a>
                                </li>
                                <li id="400">


                                    <a id="bibliography_30" title="Xiong Bingyan, Wang Guoyin, Deng Weibin. Under-sampling method based on sample weight for imbalanced data[J]. Journal of Computer Research and Development, 2016, 53 (11) : 2613- 2622 (in Chinese) (熊冰妍, 王国胤, 邓维斌. 基于样本权重的不平衡数据欠抽样方法[J]. 计算机研究与发展, 2016, 53 (11) : 2613- 2622) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201611017&amp;v=MTkwNzJGeTduVXI3Tkx5dlNkTEc0SDlmTnJvOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[30]</b>
                                        Xiong Bingyan, Wang Guoyin, Deng Weibin. Under-sampling method based on sample weight for imbalanced data[J]. Journal of Computer Research and Development, 2016, 53 (11) : 2613- 2622 (in Chinese) (熊冰妍, 王国胤, 邓维斌. 基于样本权重的不平衡数据欠抽样方法[J]. 计算机研究与发展, 2016, 53 (11) : 2613- 2622) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JFYZ" target="_blank">计算机研究与发展</a>
                2019,56(03),623-634 DOI:10.7544/issn1000-1239.2019.20170961            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于层次信息粒表示的属性图链接预测模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BD%97%E6%99%9F&amp;code=10867310&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">罗晟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%97%E5%A4%BA%E8%B0%A6&amp;code=08963093&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苗夺谦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%BF%97%E9%A3%9E&amp;code=10097252&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张志飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%BF%9C%E5%81%A5&amp;code=33484682&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张远健</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E5%A3%B0%E4%B8%B9&amp;code=41425017&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡声丹</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E7%B3%BB&amp;code=0118734&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同济大学计算机科学与技术系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%9C%8D%E5%8A%A1%E8%AE%A1%E7%AE%97%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6)&amp;code=0069758&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">嵌入式系统与服务计算教育部重点实验室(同济大学)</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%BD%AF%E4%BB%B6%E6%96%B0%E6%8A%80%E6%9C%AF%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4(%E5%8D%97%E4%BA%AC%E5%A4%A7%E5%AD%A6)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">计算机软件新技术国家重点实验室(南京大学)</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着具有结点属性信息的网络图数据的增加, 结点属性及结点链接关系越来越复杂, 这对复杂网络的链接预测任务带来了一系列的挑战.这些不同来源的原始数据之间存在着不一致性, 即结点的属性诱导的潜在链接关系与网络拓扑结构观测到的链接边之间存在着不一致的情况, 这一现象将直接影响结点对之间的链接预测准确性与精确性.为了有效处理多源数据的不一致性, 融合异构数据的差异, 借助粒计算思想, 通过对原始数据的多粒度表示, 将原始数据在不同层次的粒度进行信息表示建模.最终依据这些数据的粒度表示, 寻找最优的粒层结构, 并最大化地消除数据内在的不一致性.首先, 定义了数据的粒度不同层次表示及粒层关系;其次, 对所观测到的链接数据, 构建对数似然统计模型, 并综合不同粒度层数据特点对模型进行修正;最后, 使用多源数据训练统计模型, 将学习好的模型用于预测结点对之间的链接概率.实验表明:与现有链接预测模型相比, 多源数据经过粒度表示极大地平衡了多源数据的不一致性, 有效提升了链接预测任务的准确性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B2%92%E5%BA%A6%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">粒度表示学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B2%92%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">粒计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%9E%E6%80%A7%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">属性图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%93%BE%E6%8E%A5%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">链接预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据融合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *苗夺谦, dqmiao@tongji.edu.cn;
                                </span>
                                <span>
                                    罗晟, tjluosheng@gmail.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2017-12-14</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61673301, 61502259);</span>
                                <span>南京大学计算机软件新技术国家重点实验室开放课题 (KFKT2017B22);</span>
                    </p>
            </div>
                    <h1><b>A Link Prediction Model Based on Hierarchical Information Granular Representation for Attributed Graphs</b></h1>
                    <h2>
                    <span>Luo Sheng</span>
                    <span>Miao Duoqian</span>
                    <span>Zhang Zhifei</span>
                    <span>Zhang Yuanjian</span>
                    <span>Hu Shengdan</span>
            </h2>
                    <h2>
                    <span>Department of Computer Science and Technology, Tongji University</span>
                    <span>Key Laboratory of Embedded System and Service Computing (Tongji University) , Ministry of Education</span>
                    <span>State Key Laboratory for Novel Software Technology (Nanjing University)</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the accumulation of the network graph data coupled with node attributes, the relations between node attributes and node linkages become more and more complex, which brings a lot of challenges to the task of the link prediction in complex network. The main reason is the inconsistency existing in the different source data, that is, the relations between the latent linkages which are implied by the node attributes and the observed linkages from network topological structure, respectively. This phenomenon directly affects the correctness and accuracy of link predictions. In order to effectively deal with multi-source data inconsistency and fuse the heterogeneous data, with the idea of granular computing and data multi-layer granular representation, we model the original data at different levels of granular representation. According to the data granular representation, we ultimately eliminate data inherent inconsistencies by finding the optimal granular structure. In this paper, we firstly define the data granular representation and the relation between different level granular; Then, we construct a log-likelihood model of the data, and place a lot of constraints decided by the granular relations to regularize the model; At last, we use the trained model to perform the link probability between nodes. Experiments show that, multi-source data can ultimately reduce the inconsistency by granular representation, and the statistic model regulated by these granular relations outperforms the state-of-the-art methods, and effectively improves the accuracy of the link prediction in the attributed graph.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=granular%20representation%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">granular representation learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=granular%20computing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">granular computing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=attributed%20graph&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">attributed graph;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=link%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">link prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data fusion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    Luo Sheng, born in 1982.PhD candidate in Tongji University.Student member of CCF.His main research interests include granular computing, machine learning.<image id="337" type="formula" href="images/JFYZ201903017_33700.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Miao Duoqian, born in 1964.PhD, professor, PhD supervisor in Tongji University.Distinguished member of CCF.His main research interests include rough sets, granular computing and machine learning.<image id="338" type="formula" href="images/JFYZ201903017_33800.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Zhang Zhifei, born in 1986.PhD and lecturer in Tongji University.Member of CCF.His main research interests include natural language processing and machine learning.<image id="339" type="formula" href="images/JFYZ201903017_33900.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Zhang Yuanjian, born in 1990.PhDcandidate in Tongji University.Student member of CCF.His main research interests include rough sets, granular computing and machine learning.<image id="340" type="formula" href="images/JFYZ201903017_34000.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                                <span>
                                    Hu Shengdan, born in 1982.PhD candidate in Tongji University.Student member of CCF.Her main research interests include rough sets and machine learning.<image id="341" type="formula" href="images/JFYZ201903017_34100.jpg" display="inline" placement="inline"><alt></alt></image>;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2017-12-14</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by the National Natural Science Foundation of China (61673301, 61573255);</span>
                                <span>the Open Research Funds of State Key Laboratory for Novel Software Technology (Nanjing University) (KFKT2017B22);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="70">随着信息技术的快速发展, 越来越多的网络应用将人们紧密地联系在一起, 形成了人与人之间的一个链接网络.现有大量的复杂网络分析相关的研究工作发表在统计物理、统计学、计算机科学和应用数学等领域<citation id="404" type="reference"><link href="342" rel="bibliography" /><link href="344" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>.复杂网络分析早已成为国内外学者研究的热点问题.链接预测正是复杂网络分析的一个基础性工作, 具有重要的地位.早期的链接预测<citation id="402" type="reference"><link href="346" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>分析方法的出发点是建立在数据的网络拓扑图之上, 这类方法较为直观, 易于解释.除了网络拓扑结构数据之外, 结点还具有属性信息, 这类复杂网络一般称之为属性图<citation id="403" type="reference"><link href="348" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>.一个常见的链接网络如图1所示:</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903017_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 一个示例链接网络" src="Detail/GetImg?filename=images/JFYZ201903017_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 一个示例链接网络  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903017_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 A toy example of the link network</p>

                </div>
                <div class="p1">
                    <p id="72">然而, 伴随着计算机的存储能力和计算能力的快速增长, 以及进入Web 2.0时代之后, 人们参与数据发布的积极性高涨, 以至于现在的复杂网络数据的规模越来越庞大.同时, 网络结点属性的丰富程度也越来越高.复杂网络数据的来源及质量得到了巨大的提升.数据的快速增长导致人们获取的数据亦呈现大数据特点, 即体量巨大 (volume) 、类型多样 (variety) 、产生速度快 (velocity) 、易变性 (variability) 以及真实性 (veracity) <citation id="432" type="note"><link href="430" rel="footnote" /><sup>①</sup></citation>等特征.这些数据特性对现有智能学习系统带来了巨大的挑战, 特别是数据的易变性, 也就是数据的不一致性, 对现有数据挖掘与分析工作提出了新的要求.</p>
                </div>
                <div class="p1">
                    <p id="73">本文从数据的不一致性出发, 分析现有多源异构的复杂网络不同数据, 以及由此引发的信息过载所带来的数据差异性问题;同时采用粒计算范式, 克服原有计算模式的单一粒度视角, 建立异构多源数据的层次粒度表示.不一致问题带来的挑战, 其背后的主要原因是异构数据之间存在的信息间隔 (infor-mation gap) .为此, 本文提出数据的层次粒度表示用于处理信息间隔问题.数据的层次粒度表示的主要工作是设计一个基于拓扑结构图的统计模型;同时, 以结点属性表为基础构建统计模型的先验知识.最后将这些异构的浅层模型表示的数据提升至更为抽象的高层信息粒, 以期望在高层信息粒层, 加以一定的约束条件, 多源数据能够达到数据一致.该链接预测模型的动机在于, 试图在多层粒度空间上寻找链接预测问题的最优解.</p>
                </div>
                <h3 id="74" name="74" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="75">本节主要介绍与链接预测主题相关的研究背景以及研究现状.</p>
                </div>
                <div class="p1">
                    <p id="76">现有大量链接预测相关的研究, 其中最简单和直观的方法以结点的相似性为基础.这类方法通过计算结点之间的相似性的评分来构造结点之间存在链接关系的可能性.常见的相似性计算方法有公共邻居 (common neighbors, CN) <citation id="405" type="reference"><link href="350" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、杰卡得系数 (Jaccard index, JI) <citation id="406" type="reference"><link href="352" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、索尔顿系数 (Salton index, SI) <citation id="407" type="reference"><link href="354" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、资源分配系数 (resource allocation index, RAI) <citation id="408" type="reference"><link href="356" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>和adamic-adar系数 (adamic-adar index, AAI) <citation id="409" type="reference"><link href="358" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>等.这类方法主要使用拓扑结构上的邻居或路径等特征来计算结点对之间的相似程度.很明显, 这类方法的主要缺陷是缺乏考虑结点属性以及扩展性不足.</p>
                </div>
                <div class="p1">
                    <p id="77">另一类方法聚焦在最大化观测结构的似然, 建构图的生成模型.然后, 使用数据学习后的最优模型预测未知结点对之间的链接概率.Clauset等人<citation id="410" type="reference"><link href="360" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出了一种从拓扑网络结构推断潜在层次组织结构的生成技术, 并将该模型用于缺失链接的预测.也有一些研究工作, 使用概率相关模型 (probabilstic relational models, PRM) <citation id="411" type="reference"><link href="362" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>描述关系数据集 (rela-tional dataset, RD) 的属性联合分布、优化分布, 并将其用于结点对的链接关系预测.相似的工作还有Relational Markov Networks<citation id="412" type="reference"><link href="364" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, Relational Depen-dency Networks<citation id="413" type="reference"><link href="366" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, Local Naïve Bayes Model<citation id="414" type="reference"><link href="368" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>等.还有一类链接预测方法则是基于机器学习技术<citation id="415" type="reference"><link href="370" rel="bibliography" /><link href="372" rel="bibliography" /><link href="374" rel="bibliography" /><link href="376" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="78">此外, 对于链接预测问题, 每个社区对于结点的链接关系建立过程同样具有重要作用<citation id="416" type="reference"><link href="378" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>.例如对于一个中国的社交网络链接预测问题来说, 大部分结点都属于中国这个社区;同时这些结点属于或不属于网球、游泳、足球等社区.很明显, 中国社区对于建立结点链接关系问题而言, 影响程度小于网球社区、游泳社区、足球社区等社区.也就是说社区在结点对建立链接关系的过程中所处的地位及作用是不同的.相关的工作还有:王鑫等人<citation id="417" type="reference"><link href="380" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>研究了交互意见和地位理论与链接关系的强相关性, 提出了一种基于符号网络的链接预测模型;刘冶等人<citation id="418" type="reference"><link href="382" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>研究了主数据源与附加数据源的特性, 并提出了一种基于低秩和稀疏分解的多源融合链接预测算法;张泽华等人<citation id="419" type="reference"><link href="384" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>将粗糙集理论引入图挖掘领域, 提出了网络社区的领域粗糙化扩张方法等等.值得注意的是, 现有的这些方法, 要么忽略了结点属性, 要么拓扑网络数据与结点属性之间存在的潜在交互性, 要么忽略了社区在结点对建立链接关系过程中的不同作用.</p>
                </div>
                <div class="p1">
                    <p id="79">为了处理以上问题, 本文首先对于各个来源的数据进行粒度表示学习.具体来说, 对于拓扑结点图数据, 使用一种概率生成模型对图数据进行抽象表示 (作用相当于提升数据信息粒层) ;对于结点属性表, 使用聚类方法对数据进行抽象表示 (提升数据信息粒层) .同时, 对数据抽象后产生的高层数据信息粒加以一定条件的约束, 以期在粒度表示的条件下, 达到数据的一致, 从而优化层次粒度表示模型, 最终优化结点对链接关系预测的效果.</p>
                </div>
                <div class="p1">
                    <p id="80">本文的贡献可以概括为3点:</p>
                </div>
                <div class="p1">
                    <p id="81">1) 提出了一种关于拓扑结构图数据的概率生成模型.这个模型充分考虑潜在社区贡献度因子, 又考虑结点与社区之间的结点-隶属关系.</p>
                </div>
                <div class="p1">
                    <p id="82">2) 提出了一种基于数据层次信息粒表示的问题求解方法.该方法将原始多源异构数据抽象为不同层次结构下的信息粒, 并考虑将不一致问题消除在这种层次信息粒表示的数据结构中.</p>
                </div>
                <div class="p1">
                    <p id="83">3) 提出了基于粒度视角的链接预测方法, 根据粒度计算范式, 学习最优的层次粒表示模型, 并将此模型用于表示缺失及观测链接关系的生成概率.实验表明这一方法相较现有方法, 有较为显著的性能提升.</p>
                </div>
                <h3 id="84" name="84" class="anchor-tag"><b>2 基本知识</b></h3>
                <div class="p1">
                    <p id="85">本节主要介绍数据的粒度表示以及信息粒在复杂网络链接预测模型中降低数据不一致性的重要作用.粒计算是人们处理日常事务的一般性思维模式.人们在计算现实世界问题时, 通常是从多个角度, 多个层次的观点看待问题, 而不会局限于某一些局部特征, 这一方法论也被称之为粒计算<citation id="420" type="reference"><link href="386" rel="bibliography" /><link href="388" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>.</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>2.1 基本定义</b></h4>
                <div class="p1">
                    <p id="87">在处理复杂网络数据时, 根据粒计算理论, 本文将网络结构中观测到的网络拓扑结构数据与结点的属性数据 (特征、标签等) 归结为原始信息粒.在原始信息粒的基础上, 又可以构造当前信息粒的一种抽象表示 (如图像处理过程中边缘是像素的一种抽象表示) , 形成高层信息粒, 假如当前信息粒层不适合问题求解, 可以在此基础上, 继续构造上一层信息粒, 直至当前信息粒有利于问题求得最优解.由此, 便形成了数据的层次粒度结构表示.</p>
                </div>
                <div class="p1">
                    <p id="88">下面给出相关的定义.</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903017_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 层次粒度表示的属性图链接预测模型框架图" src="Detail/GetImg?filename=images/JFYZ201903017_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 层次粒度表示的属性图链接预测模型框架图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903017_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 2 The framework of the HGRLPM</p>

                </div>
                <div class="p1">
                    <p id="90"><b>定义1</b>. 属性图.任意给定一个网络拓扑图<i>G</i> (<i>V</i>, <i>E</i>) , 其中网络拓扑图结点集<i>V</i>={<i>v</i><sub><i>i</i></sub>}, <i>i</i>=1, 2, …, <i>N</i>, <i>N</i>为网络拓扑图的结点总数, 链接边集<i>E</i>={<i>e</i><sub><i>i j</i></sub>|∀<i>i</i>, <i>j</i>≤<i>N</i>}为<i>V</i>上的一个二元关系, 且有</p>
                </div>
                <div class="area_img" id="91">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201903017_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="93">一般地, 若网络拓扑图<i>G</i> (<i>V</i>, <i>E</i>) 的结点具有属性信息, 则这一类型的网络拓扑图也称之为属性图, 记为<i>G</i> (<i>V</i>, <i>E</i>, <i>F</i>) , 其中<i>F</i>为结点属性表.</p>
                </div>
                <div class="p1">
                    <p id="94"><b>定义2</b>. 结点属性表. 属性图<i>G</i> (<i>V</i>, <i>E</i>, <i>F</i>) 中任意结点<i>u</i>∈<i>V</i>, 除了具有与外部结点的链接关系外, 还具有描述其各个侧面的特征<i>f</i><sub><i>i</i></sub>组成的属性集{<i>f</i><sub><i>i</i></sub>}<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>m</mi></msubsup></mrow></math></mathml>.结点与特征之间具有如下映射关系:</p>
                </div>
                <div class="p1">
                    <p id="96"><i>f</i><sub><i>i</i></sub>:<i>u</i>→<i>v</i><sup><i>f</i><sub><i>i</i></sub></sup>; ∀<i>u</i>∈<i>V</i>, <i>f</i><sub><i>i</i></sub>∈{<i>f</i><sub><i>i</i></sub>}<mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>m</mi></msubsup></mrow></math></mathml>, <i>v</i><sup><i>f</i><sub><i>i</i></sub></sup>∈<i>V</i><sup><i>f</i><sub><i>i</i></sub></sup>,      (2) </p>
                </div>
                <div class="p1">
                    <p id="98">其中, <i>v</i><sup><i>f</i><sub><i>i</i></sub></sup>为结点<i>v</i>在特征<i>f</i><sub><i>i</i></sub>映射值域<i>V</i><sup><i>f</i><sub><i>i</i></sub></sup>的一个具体属性值.具有属性值的网络图结点可以表示为属性值向量<b><i>v</i></b><sup><i>f</i></sup>= (<i>v</i><sup><i>f</i><sub>1</sub></sup>, <i>v</i><sup><i>f</i><sub>2</sub></sup>, …, <i>v</i><sup><i>f</i><sub><i>m</i></sub></sup>) , 所有结点属性向量集合为结点属性表, 记为<i>F</i>.</p>
                </div>
                <div class="p1">
                    <p id="99"><b>定义3</b>. 网络社区.任意给定一个网络拓扑图<i>G</i> (<i>V</i>, <i>E</i>) , 其中的网络结点根据一定的划分规则潜在地属于某个类簇中心, 即<i>v</i>∈<i>C</i><sub><i>i</i></sub>, <i>i</i>∈{1, 2, …, <i>k</i>} (<i>k</i>为类簇总数) .在复杂网络分析上下文环境中, 类簇中心也称之为网络社区.</p>
                </div>
                <div class="p1">
                    <p id="100">特别地, 由网络拓扑数据得到的网络社区也称之为拓扑网络社区, 记为{<i>C</i><sub><i>i</i></sub>}, <i>i</i>∈{1, 2, …, <i>k</i>}.</p>
                </div>
                <div class="p1">
                    <p id="101">同理, 给定结点的属性表, 那么根据结点的属性相似度, 潜在的存在着一个由所有结点组成的聚类族 (属性表诱导的网络社区) , 记为{<i>Q</i><sub><i>i</i></sub>}, <i>i</i>∈{1, 2, …, <i>k</i>}, 这类网络社区称之为属性网络社区.若结点可以同时属于多个网络社区, 那么由这些结点所形成的社区之间, 会存在结点的重叠, 即2个或以上社区存在公共结点, 这种类型的社区也称之为重叠社区.</p>
                </div>
                <h3 id="102" name="102" class="anchor-tag"><b>3 层次粒度表示的属性图链接预测模型</b></h3>
                <h4 class="anchor-tag" id="103" name="103"><b>3.1 问题描述</b></h4>
                <div class="p1">
                    <p id="104">在介绍模型之前, 首先将所研究的问题做个简单的描述.一般地, 假设给定属性图<i>G</i> (<i>V</i>, <i>E</i>, <i>F</i>) , 则链接预测问题的主要任务是根据观测到的现有结点间的链接关系集{<i>e</i><sub><i>i j</i></sub>|∀<i>e</i><sub><i>i j</i></sub>∈<i>E</i>∧<i>e</i><sub><i>i j</i></sub>&gt;0}与结点属性表<i>F</i>, 试图建立任意结点对之间链接关系的似然估计.</p>
                </div>
                <div class="p1">
                    <p id="105">如图2所示, 在系统处理的原始数据中, 拓扑结构图观测到的链接边与结点属性相似度诱导的潜在链接边存在不一致的情况, 即:</p>
                </div>
                <div class="p1">
                    <p id="106">1) 拓扑结构图中结点对没有观测到链接关系, 而属性表提供的结点相似度暗示着这对结点存在一条隐式链接;</p>
                </div>
                <div class="p1">
                    <p id="107">2) 根据结点属性表计算出结点对相似度较低, 表示存在链接关系的可能性较低, 而拓扑结构图却观测到了结点对之间存在链接.</p>
                </div>
                <div class="p1">
                    <p id="108">如果将所有对象映射至高层信息粒, 即拓扑网络社区与属性网络社区, 则可以在这种层次粒度结构的表示下, 通过粒度转换融合异构数据, 最大化地消除低层信息粒的不一致.信息粒度表示的粒层数量依赖于问题的规模及领域特点.</p>
                </div>
                <div class="p1">
                    <p id="109">现有的属性图链接预测模型都忽略了这种潜在的数据不一致导致的冲突问题.基于此, 不同于现有链接预测模型, 本文提出层次粒度表示链接预测模型 (hierarchical granular representation link prediction model, HGRLPM) 将从数据的层次粒度表示出发, 通过提升数据的粒度层次, 消除低层次粒度的不一致性, 最大化地融合异构的数据源, 降低链接预测的不确定性, 提升链接预测的准确性与精确性.下面引入基于层次信息粒表示的属性图链接预测模型.</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>3.2 层次粒度表示的属性图链接预测模型</b></h4>
                <div class="p1">
                    <p id="111">本文的模型主要基于Breiger等人<citation id="421" type="reference"><link href="390" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>与Jaewon等人<citation id="422" type="reference"><link href="392" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>的工作, 即每个结点依据不同的隶属度包含在不同的网络社区 (每个结点与每个社区潜在地都具有包含关系, 区别在于隶属度不同) .如果任意2个结点所属的公共社区越多, 那么它们将会以更高的概率建立链接关系.</p>
                </div>
                <div class="p1">
                    <p id="112">同时, 我们也注意到每一个网络社区在结点对建立链接关系中的重要程度是不同的.换句话说, 每个社区对每个结点对建立链接的贡献度是不一致的.</p>
                </div>
                <div class="p1">
                    <p id="113">最后, 由于结点的属性表获取代价昂贵, 所以研究数据对象以网络拓扑结构图为主体, 而属性表诱导的结点社区隶属关系作为拓扑网络结构统计模型对应随机变量的先验分布.</p>
                </div>
                <div class="p1">
                    <p id="114"><b>定义4</b>. 结点-隶属关系矩阵.<b><i>B</i></b>为一个非负矩阵, 表示结点-隶属关系.<b><i>B</i></b>的维度为|<i>C</i>|×|<i>V</i>|.每一个矩阵元素<b><i>B</i></b><sub><i>c u</i></sub>用于表示结点<i>u</i> (∀<i>u</i>∈<i>V</i>) 与网络社区<i>c</i> (<i>c</i>∈{<i>C</i><sub><i>i</i></sub>}<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>≜{<i>C</i><sub>1</sub>, <i>C</i><sub>2</sub>, …, <i>C</i><sub><i>k</i></sub>}) 之间的隶属程度, <i>k</i>为网络社区总数.</p>
                </div>
                <div class="p1">
                    <p id="116"><b>引理1</b>. 层次粒度表示链接预测模型 (HGRLPM) 通过相应的产生概率<i>p</i> (<i>u</i>, <i>v</i>) 建立任意结点链接边 (<i>u</i>, <i>v</i>) , ∀<i>u</i>, <i>v</i>∈<i>V</i>, 生成拓扑结构图<i>G</i> (<i>V</i>, <i>E</i>) , 且</p>
                </div>
                <div class="p1">
                    <p id="117"><i>p</i> (<i>u</i>, <i>v</i>) =1-exp (-<b><i>s</i></b><sup>T</sup> (<b><i>B</i></b><sub><i>u</i></sub>⊙<b><i>B</i></b><sub><i>v</i></sub>) ) ,      (3) </p>
                </div>
                <div class="p1">
                    <p id="118">其中, <i>s</i><sub><i>c</i></sub>是一个表示网络社区<i>c</i>的贡献度的随机变量, 向量<b><i>s</i></b>= (<i>s</i><sub>1</sub>, <i>s</i><sub>2</sub>, …, <i>s</i><sub><i>k</i></sub>) ;<b><i>B</i></b><sub><i>u</i></sub>, <b><i>B</i></b><sub><i>v</i></sub>分别是结点<i>u</i>, <i>v</i>的结点-隶属向量, 代表结点-隶属矩阵的一列;“⊙”为逐元素乘法.</p>
                </div>
                <div class="p1">
                    <p id="119">证明. 式 (3) 隐含的表示拓扑网络图中每一对结点都具有一个潜在的交互.本文假设任意一对结点 (<i>u</i>, <i>v</i>) 在任意网络社区<i>c</i>产生一个非负的交互作用<i>T</i><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>u</mi><mtext> </mtext><mi>v</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>c</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>, 且服从均值为<i>s</i><sub><i>c</i></sub><i>B</i><sub><i>c u</i></sub><i>B</i><sub><i>c v</i></sub>的泊松分布, 即</p>
                </div>
                <div class="p1">
                    <p id="121"><i>T</i><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>u</mi><mtext> </mtext><mi>v</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>c</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>～<i>Poi</i> (<i>s</i><sub><i>c</i></sub><i>B</i><sub><i>c u</i></sub><i>B</i><sub><i>c v</i></sub>) ,      (4) </p>
                </div>
                <div class="p1">
                    <p id="123">其中, <i>Poi</i> (·) 为泊松分布.根据泊松分布的性质, 可知, 网络社区对结点对 (<i>u</i>, <i>v</i>) 的相互作用总量<i>T</i><sub><i>u v</i></sub>为</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msub><mrow></mrow><mrow><mi>u</mi><mtext> </mtext><mi>v</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>c</mi><mo>∈</mo><mo stretchy="false">{</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></munder><mi>Τ</mi></mstyle><msubsup><mrow></mrow><mrow><mi>u</mi><mtext> </mtext><mi>v</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>c</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>~</mo><mi>Ρ</mi><mi>o</mi><mi>i</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">可以得到链接概率<i>p</i> (<i>u</i>, <i>v</i>) =<i>P</i> (<i>T</i><sub><i>u v</i></sub>&gt;0) , 即</p>
                </div>
                <div class="p1">
                    <p id="126"><i>P</i> (<i>T</i><sub><i>u v</i></sub>&gt;0) =1-<i>P</i> (<i>T</i><sub><i>u v</i></sub>=0) =1-exp (-<b><i>s</i></b><sup>T</sup> (<b><i>B</i></b><sub><i>u</i></sub>⊙<b><i>B</i></b><sub><i>v</i></sub>) ) .      (6) </p>
                </div>
                <div class="p1">
                    <p id="128">证毕.</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">3.2.1 拓扑结构图对数似然</h4>
                <div class="p1">
                    <p id="130">假设给定潜在因子矩阵, 即结点-隶属关系矩阵<b><i>B</i></b>与网络社区贡献度因子向量<b><i>s</i></b>, 拓扑结构图<i>G</i>生成模型的似然概率记为L (<b><i>B</i></b>, <b><i>s</i></b>) , 那么有:</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>L</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo><mo>=</mo><mi>ln</mi><mtext> </mtext><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>G</mi><mrow><mo stretchy="false">|</mo><mrow><mi mathvariant="bold-italic">B</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi></mrow><mo stretchy="false">) </mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>E</mi></mrow></munder><mtext>l</mtext></mstyle><mtext>n</mtext><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>-</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>∉</mo><mi>E</mi></mrow></munder><mi mathvariant="bold-italic">s</mi></mstyle><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">) </mo><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="132">在没有考虑结点属性表的情况下, 通过求解以下问题就可以得到最优模型, 即</p>
                </div>
                <div class="p1">
                    <p id="133"><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mo>*</mo></msup><mo>, </mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>max</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">B</mi><mo>⪰</mo><mn>0</mn><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>⪰</mo><mn>0</mn></mrow></munder><mspace width="0.25em" /><mtext>L</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo></mrow></math></mathml>.      (8) </p>
                </div>
                <div class="p1">
                    <p id="135">然而, 在这种情况下, 模型没有考虑结点属性以及拓结构图数据与属性数据之间潜在的不一致性.一般地, 在建构一个全面、鲁棒的链接预测模型时, 不仅需要考虑集成异构数据, 同时也需要考虑消除异构数据的不一致性.</p>
                </div>
                <h4 class="anchor-tag" id="136" name="136">3.2.2 结点-隶属关系先验</h4>
                <div class="p1">
                    <p id="137">当我们考虑结点的属性信息时, 这表示根据某种相似度测度可以将所有的结点按照它们之间的亲疏程度, 划分为<i>k</i>个聚类簇.这里为了保持数据整体上是一致的, 假设拓扑结构以及属性信息各自产生的数据概括是相同的, 即拓扑图产生的类簇与属性图产生的类簇个数是相等的.在本文中, 属性表产生的结点与聚类簇的隶属程度记为</p>
                </div>
                <div class="p1">
                    <p id="138"><i>D</i><sub><i>c u</i></sub> (∀<i>u</i>∈<i>V</i>, <i>c</i>∈{<i>Q</i><sub><i>i</i></sub>}<mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>≜{<i>Q</i><sub>1</sub>, <i>Q</i><sub>2</sub>, …, <i>Q</i><sub><i>k</i></sub>}) , </p>
                </div>
                <div class="p1">
                    <p id="140">并将此信息作为拓扑结构图的结点-隶属关系矩阵的一个先验信息.</p>
                </div>
                <div class="p1">
                    <p id="141">下面是矩阵<b><i>D</i></b>的产生过程.首先, 我们使用某种相似度测度M (·, ·) 计算结点相似度, 并以此测度为基础, 使用某种聚类算法对结点属性表进行聚类.这将产生一个原有结点集的一个划分;其次, 计算每个结点<i>u</i>与所有聚类簇中心{<i>c</i>|<i>c</i>∈{<i>Q</i><sub><i>i</i></sub>}<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>}的相似度, 即</p>
                </div>
                <div class="p1">
                    <p id="143"><i>D</i><sub><i>c u</i></sub>=M (<i>u</i>, <i>c</i>) , ∀<i>u</i>∈<i>V</i>, <i>c</i>∈{<i>Q</i><sub><i>i</i></sub>}<mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>,      ( (9) </p>
                </div>
                <div class="p1">
                    <p id="145">M (·, ·) 一般使用欧氏距离, 也可以根据数据特点选择余弦距离、马氏距离等.</p>
                </div>
                <h4 class="anchor-tag" id="146" name="146">3.2.3 社区贡献度先验</h4>
                <div class="p1">
                    <p id="147">我们假设每一个网络社区在结点对建立链接的过程中的贡献度是不同的.例如当我们在分析中国的社交网络链接问题时, 如果所有结点所属的社区都为中国, 那么这个社区对于链接预测任务而言, 贡献度是可以忽略的;而根据某种爱好划分的社区, 如音乐、体操、乒乓球等社区对于结点间的链接关系建立具有很强的驱动力.</p>
                </div>
                <div class="p1">
                    <p id="148">显然, 网络社区的重要性可以从当前社区的链接数在全体网络链接所占的比例观察出来.这也是为什么使用拓扑结构图的链接密度作为社区贡献度的先验, 即</p>
                </div>
                <div class="p1">
                    <p id="149"><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mfrac><mrow><mi>φ</mi><mo stretchy="false"> (</mo><mi>c</mi><mo stretchy="false">) </mo></mrow><mrow><mi>φ</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mspace width="0.25em" /><mo>∀</mo><mi>c</mi><mo>∈</mo><mo stretchy="false">{</mo><mi>Q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>,      (10) </p>
                </div>
                <div class="p1">
                    <p id="151">其中, 函数<i>φ</i> (·) 用于计算结点集所具有的链接边的个数.</p>
                </div>
                <h4 class="anchor-tag" id="152" name="152">3.2.4 结点-隶属关系重要度</h4>
                <div class="p1">
                    <p id="153">由于社区的贡献度不一样, 所以结点-隶属关系成员的重要程度也不一样.在系统建模时, 应当考虑结点-隶属关系成员的重要度.在本文中, 结点-隶属关系重要度为</p>
                </div>
                <div class="p1">
                    <p id="154"><i>W</i><sub><i>i j</i></sub>=<i>π μ</i><sub><i>j</i></sub>,      (11) </p>
                </div>
                <div class="p1">
                    <p id="155">其中, <i>i</i>∈{1, 2, …, |<i>V</i>|}, <i>j</i>∈{1, 2, …, <i>k</i>}, <i>π</i>为自定义常数.<i>W</i><sub><i>i j</i></sub>表示当前结点与社区中心的隶属关系的重要度与社区在结点建立链接关系时的重要度成正比关系.</p>
                </div>
                <h4 class="anchor-tag" id="156" name="156">3.2.5 层次粒度表示</h4>
                <div class="p1">
                    <p id="157">在获得先验信息{{<i>Q</i><sub><i>i</i></sub>}<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>, <i>μ</i>, <b><i>D</i></b>}与拓扑网络结构图<i>G</i> (<i>V</i>, <i>E</i>) 之后, 我们可以获得数据的层次粒度表示.</p>
                </div>
                <div class="p1">
                    <p id="159"><b>定义5</b>. 原始信息粒、高层信息粒.一般地, 信息系统所采集的经过简单数据清洗后得到的数据被认为是信息系统输入的原始数据.原始数据称之为原始信息粒, 记为<i>IG</i><sup>L</sup>.对原始数据依据某种规则抽象之后形成原有数据的一个概括描述, 即高层信息粒, 记为<i>IG</i><sup>H</sup>.</p>
                </div>
                <div class="p1">
                    <p id="160"><b>定义6</b>. 层次信息粒化表示.原始信息粒和高层信息粒, 以及由这些不同层次信息粒形成的层次结构, 称之为数据的层次粒化表示, 记为<i>R</i><sup>HI</sup>.本文将属性图<i>G</i> (<i>V</i>, <i>E</i>, <i>F</i>) 归属于原始信息粒<i>IG</i><sup>L</sup>, 拓扑网络社区{<i>C</i><sub><i>i</i></sub>}<mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>与属性网络社区{<i>Q</i><sub><i>i</i></sub>}<mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>归属于高层信息粒<i>IG</i><sup>H</sup>, 即</p>
                </div>
                <div class="area_img" id="163">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201903017_16300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="165">由此, <i>R</i><sup>HI</sup>={<i>IG</i><sup>L</sup>, <i>IG</i><sup>H</sup>|<b><i>B</i></b>, <b><i>D</i></b>, <b><i>W</i></b>, <b><i>s</i></b>, <i>μ</i>}为原始数据的层次粒度表示, 其中, {<b><i>B</i></b>, <b><i>D</i></b>, <b><i>W</i></b>, <b><i>s</i></b>, <i>μ</i>}为层次粒度表示的参数集.</p>
                </div>
                <div class="p1">
                    <p id="166">在层次粒度表示<i>R</i><sup>HI</sup>的结构基础上, 根据粒计算范式, 我们知道在原始信息粒、结点的拓扑结构与结点的属性是结点的各个侧面的信息, 会产生差异, 也就是不一致性, 参考图2.而在高层信息粒, 也就是拓扑网络社区{<i>C</i><sub><i>i</i></sub>}<mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>与属性网络社区{<i>Q</i><sub><i>i</i></sub>}<mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>, 作为原始信息粒的一个较为抽象的全貌, 其差异性要小于原始信息粒.模型的框架图在图2中描述.为了消除不一致性提高结点链接预测质量, 我们需要达到3个目标:</p>
                </div>
                <div class="p1">
                    <p id="169">1) 最小化高层信息粒<i>IG</i><sup>H</sup>={{<i>C</i><sub><i>i</i></sub>}<mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>, {<i>Q</i><sub><i>i</i></sub>}<mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>}的差异, 也就是矩阵<b><i>B</i></b>与<b><i>D</i></b>的差异应该最小化.</p>
                </div>
                <div class="p1">
                    <p id="172">2) 属性表诱导的社区重要度与拓扑结构图生成过程中的社区的重要度的差异也应最小化.</p>
                </div>
                <div class="p1">
                    <p id="173">3) 根据最大似然估计法, 我们需要最大化拓扑结构图的对数似然.</p>
                </div>
                <div class="p1">
                    <p id="174">因此, 本文提出层次粒度表示链接预测模型, 即</p>
                </div>
                <div class="p1">
                    <p id="175" class="code-formula">
                        <mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">B</mi><mo>⪰</mo><mn>0</mn><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>⪰</mo><mn>0</mn></mrow></munder><mtext>L</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi>ψ</mi><mo stretchy="false"> (</mo><mo stretchy="false">{</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup><mo>, </mo><mo stretchy="false">{</mo><mi>Q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn><mo>, </mo></mtd></mtr><mtr><mtd><mi>η</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><mo>, </mo><mi mathvariant="bold-italic">μ</mi><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="176">其中, <i>ψ</i> (·, ·) 为高层信息粒<i>IG</i><sup>H</sup>成员粒之间距离度量函数, <i>η</i> (·, ·) 为<b><i>s</i></b>与<i>μ</i>的距离度量, 用于测量2个输入变量的相似程度.矩阵<b><i>B</i></b>和<b><i>D</i></b>为构建高层信息粒层的参数.</p>
                </div>
                <div class="p1">
                    <p id="177">在本文中, 选取<mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>⊙</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mrow></math></mathml>作为高层粒的信息距离度量函数<mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><mo stretchy="false"> (</mo><mo stretchy="false">{</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup><mo>, </mo><mo stretchy="false">{</mo><mi>Q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup><mo stretchy="false">) </mo><mo>, </mo><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow><msub><mrow></mrow><mtext>F</mtext></msub></mrow></math></mathml>为Frobenius范数, <i>W</i><sub><i>i j</i></sub>为权值, 表示当前结点-隶属关系差分在不同社区的重要度.同时, 选择<mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><mo stretchy="false"> (</mo><mo>⋅</mo><mo>, </mo><mo>⋅</mo><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">s</mi><mo>-</mo><mi mathvariant="bold-italic">μ</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>, 其中<mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow></math></mathml>为向量的2范数.由此, 式 (13) 转化为</p>
                </div>
                <div class="p1">
                    <p id="182" class="code-formula">
                        <mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">B</mi><mo>⪰</mo><mn>0</mn><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>⪰</mo><mn>0</mn></mrow></munder><mtext>L</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>⊙</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>=</mo><mn>0</mn><mo>, </mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">s</mi><mo>-</mo><mi mathvariant="bold-italic">μ</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>=</mo><mn>0</mn><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="183">根据拉格朗日乘子法, 可以将式 (14) 转化为以下优化问题:</p>
                </div>
                <div class="p1">
                    <p id="184" class="code-formula">
                        <mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">B</mi><mo>⪰</mo><mn>0</mn><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo>⪰</mo><mn>0</mn></mrow></munder><mo>-</mo><mtext>L</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo><mo>+</mo><mfrac><mi>α</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>⊙</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mi>β</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">s</mi><mo>-</mo><mi mathvariant="bold-italic">μ</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="185">为方便计算, 将式 (15) 的目标函数记为ℓ (<b><i>B</i></b>, <b><i>s</i></b>) .</p>
                </div>
                <h3 id="186" name="186" class="anchor-tag"><b>4 模型参数学习</b></h3>
                <div class="p1">
                    <p id="187">模型所有需要学习的参数为矩阵<b><i>B</i></b>与向量<b><i>s</i></b>, 记为<i>Θ</i>={<b><i>B</i></b>, <b><i>s</i></b>}.对于式 (15) 这个优化问题, 当固定参数<b><i>s</i></b>与其他的<b><i>B</i></b><sub><i>v</i></sub> (∀<i>v</i>∈<i>V</i>∧<i>v</i>≠<i>u</i>) 时, 我们发现ℓ (<b><i>B</i></b>, <b><i>s</i></b>) 是<b><i>B</i></b><sub><i>u</i></sub> (∀<i>u</i>∈<i>V</i>) 的凸函数 (convex function) .同理, ℓ (<b><i>B</i></b>, <b><i>s</i></b>) 是<b><i>s</i></b>的凸函数.因此, 选择块座标梯度下降算法<citation id="423" type="reference"><link href="394" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation> (block coordinate gradient descent algorithm, BCGDA) 来得到模型参数的最优解.</p>
                </div>
                <div class="p1">
                    <p id="188">原式 (13) 可以分解为</p>
                </div>
                <div class="p1">
                    <p id="189"><mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>u</mi><mo>*</mo></msubsup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub></mrow></munder><mspace width="0.25em" /><mi>ℓ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>, </mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mrow><mo>-</mo><mi>u</mi></mrow><mo>+</mo></msubsup><mo>, </mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mo>+</mo></msup><mo stretchy="false">) </mo><mo>, </mo><mo>∀</mo><mi>u</mi><mo>∈</mo><mi>V</mi></mrow></math></mathml>,      (16) </p>
                </div>
                <div class="p1">
                    <p id="191">与</p>
                </div>
                <div class="p1">
                    <p id="192"><mathml id="193"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">s</mi></munder><mspace width="0.25em" /><mi>ℓ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mo>+</mo></msup><mo>, </mo><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo></mrow></math></mathml>,      (17) </p>
                </div>
                <div class="p1">
                    <p id="194">其中, <b><i>B</i></b><sub><i>u</i></sub>为列向量, 表示<b><i>B</i></b>的第<i>u</i>列.<b><i>B</i></b><sup>+</sup>, <b><i>s</i></b><sup>+</sup>分别表示矩阵<b><i>B</i></b>或向量<b><i>s</i></b>的值是固定的, 在当前优化过程中.<b><i>B</i></b><sup>+</sup><sub>-<i>u</i></sub>表示的是除了<b><i>B</i></b><sub><i>u</i></sub>, 其他的列都是固定的.</p>
                </div>
                <div class="p1">
                    <p id="195">式 (16) 的目标函数为</p>
                </div>
                <div class="p1">
                    <p id="196" class="code-formula">
                        <mathml id="196"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ℓ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>, </mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mrow><mo>-</mo><mi>u</mi></mrow><mo>+</mo></msubsup><mo>, </mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mo>+</mo></msup><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>v</mi><mo>∈</mo><mtext>Ν</mtext><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false">) </mo></mrow></munder><mtext>l</mtext></mstyle><mtext>n</mtext><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mrow><mo>+</mo><mtext>Τ</mtext></mrow></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>v</mi><mo>∉</mo><mtext>Ν</mtext><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false">) </mo></mrow></munder><mi mathvariant="bold-italic">s</mi></mstyle><msup><mrow></mrow><mrow><mo>+</mo><mtext>Τ</mtext></mrow></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo>+</mo><mfrac><mi>α</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>-</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mi>β</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mo>+</mo></msup><mo>-</mo><mi mathvariant="bold-italic">μ</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="197">其中, N (<i>u</i>) 为结点<i>u</i>在拓扑结构图中具有链接关系的结点集, <b><i>B</i></b><sup>+</sup><sub><i>v</i></sub>为<b><i>B</i></b><sup>+</sup>的第<i>v</i>列.</p>
                </div>
                <div class="p1">
                    <p id="198">式 (17) 的目标函数为</p>
                </div>
                <div class="p1">
                    <p id="199" class="code-formula">
                        <mathml id="199"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ℓ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mo>+</mo></msup><mo>, </mo><mi>s</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>E</mi></mrow></munder><mtext>l</mtext></mstyle><mtext>n</mtext><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>∉</mo><mi>E</mi></mrow></munder><mi mathvariant="bold-italic">s</mi></mstyle><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo>+</mo><mfrac><mi>α</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>⊙</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mo>+</mo></msup><mo>-</mo><mi mathvariant="bold-italic">D</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mi>β</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">s</mi><mo>-</mo><mi mathvariant="bold-italic">μ</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="200">BCGDA将迭代地按某一个顺序, 循环地优化式 (14) 和式 (15) .BCGDA的一个最基本的要求是必须计算式 (16) 和式 (17) 的梯度.</p>
                </div>
                <div class="p1">
                    <p id="201">下面, 给出每个目标函数各自相对应的梯度, 它们分别为</p>
                </div>
                <div class="p1">
                    <p id="202" class="code-formula">
                        <mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>ℓ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub></mrow></mfrac><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>v</mi><mo>∈</mo><mtext>Ν</mtext><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false">) </mo></mrow></munder><mrow><mfrac><mrow><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mrow><mo>+</mo><mtext>Τ</mtext></mrow></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mn>1</mn><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mrow><mo>+</mo><mtext>Τ</mtext></mrow></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mo>+</mo></msup><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>v</mi><mo>∉</mo><mtext>Ν</mtext><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mo>+</mo></msup><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>α</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>u</mi></msub><mo>-</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="203">与</p>
                </div>
                <div class="p1">
                    <p id="204" class="code-formula">
                        <mathml id="204"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>ℓ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">s</mi></mrow></mfrac><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>E</mi></mrow></munder><mrow><mfrac><mrow><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mn>1</mn><mo>-</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi mathvariant="bold-italic">s</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>∉</mo><mi>E</mi></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">s</mi><mo>⊙</mo><mi mathvariant="bold-italic">B</mi><msubsup><mrow></mrow><mi>v</mi><mo>+</mo></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>β</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">s</mi><mo>-</mo><mi mathvariant="bold-italic">μ</mi><mo stretchy="false">) </mo><mo>.</mo><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="205">下面给出本文提出的层次粒度表示链接预测模型 (HGRLPM) 的参数学习算法.</p>
                </div>
                <div class="p1">
                    <p id="206"><b>算法1</b>. HGRLPM参数学习算法.</p>
                </div>
                <div class="p1">
                    <p id="207">输入:精度<i>ε</i><sup>tol</sup>、属性图<i>G</i> (<i>V</i>, <i>E</i>, <i>F</i>) 、社区数<i>k</i>、学习率<i>γ</i>、重要度系数<i>π</i>、最大迭代次数<i>MAXITER</i>;</p>
                </div>
                <div class="p1">
                    <p id="208">输出:结点-隶属关系矩阵<b><i>B</i></b>、社区贡献度<b><i>s</i></b>.</p>
                </div>
                <div class="p1">
                    <p id="209">① 根据属性表<i>F</i>, 使用<i>K</i>-means聚类算法, 计算<i>k</i>个聚类中心{<i>Q</i><sub><i>i</i></sub>}<mathml id="210"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup></mrow></math></mathml>;</p>
                </div>
                <div class="p1">
                    <p id="211">② for <i>u</i>=1, 2, …, |<i>V</i>| do</p>
                </div>
                <div class="p1">
                    <p id="212">③ for <i>c</i>=1, 2, …, <i>k</i> do</p>
                </div>
                <div class="p1">
                    <p id="213">④ <i>D</i><sub><i>c u</i></sub>←式 (9) ;</p>
                </div>
                <div class="p1">
                    <p id="214">⑤ end for</p>
                </div>
                <div class="p1">
                    <p id="215">⑥ end for</p>
                </div>
                <div class="p1">
                    <p id="216">⑦ for <i>c</i>=1, 2, …, <i>k</i> do</p>
                </div>
                <div class="p1">
                    <p id="217">⑧ <i>μ</i><sub><i>c</i></sub>←式 (10) ;</p>
                </div>
                <div class="p1">
                    <p id="218">⑨ end for</p>
                </div>
                <div class="p1">
                    <p id="219">⑩ for <i>u</i>=1, 2, …, |<i>V</i>| do</p>
                </div>
                <div class="p1">
                    <p id="220"> (11) for <i>c</i>=1, 2, …, <i>k</i> do</p>
                </div>
                <div class="p1">
                    <p id="221"> (12) <i>W</i><sub><i>c u</i></sub>←式 (11) ;</p>
                </div>
                <div class="p1">
                    <p id="222"> (13) end for</p>
                </div>
                <div class="p1">
                    <p id="223"> (14) end for</p>
                </div>
                <div class="p1">
                    <p id="224"> (15) 初使化<b><i>B</i></b>, <b><i>s</i></b>;<i>t</i>←1;计算<i>r</i><sup> (<i>t</i>) </sup>←式 (13) ;</p>
                </div>
                <div class="p1">
                    <p id="225"> (16) while <i>t</i>&lt;<i>MAXITER</i> do</p>
                </div>
                <div class="p1">
                    <p id="226"> (17) for <i>u</i>=1, 2, …, |<i>V</i>| do</p>
                </div>
                <div class="p1">
                    <p id="227"> (18) <b><i>B</i></b><sub><i>u</i></sub>←<i>γ</i>×式 (18) ;</p>
                </div>
                <div class="p1">
                    <p id="228"> (19) end for</p>
                </div>
                <div class="p1">
                    <p id="229"> (20) <b><i>s</i></b>←<i>γ</i>×式 (19) ;<i>t</i>←<i>t</i>+1;</p>
                </div>
                <div class="p1">
                    <p id="230"> (21) 计算<i>r</i><sup> (<i>t</i>+1) </sup>←式 (13) ;</p>
                </div>
                <div class="p1">
                    <p id="231"> (22) if |<i>r</i><sup> (<i>t</i>+1) </sup>-<i>r</i><sup> (<i>t</i>) </sup>|&lt;<i>ε</i><sup>tol</sup></p>
                </div>
                <div class="p1">
                    <p id="232"> (23) break;</p>
                </div>
                <div class="p1">
                    <p id="233"> (24) end if</p>
                </div>
                <div class="p1">
                    <p id="234"> (25) end while</p>
                </div>
                <div class="p1">
                    <p id="235"> (26) 返回<b><i>B</i></b>, <b><i>s</i></b>.</p>
                </div>
                <h3 id="236" name="236" class="anchor-tag"><b>5 层次粒度表示模型的链接预测</b></h3>
                <div class="p1">
                    <p id="237">经过数据训练后, 获得当前数据的一个层次粒度表示<i>R</i><sup>HI</sup>={<i>IG</i><sup>L</sup>, <i>IG</i><sup>H</sup>|<b><i>B</i></b><sup>*</sup>, <b><i>D</i></b><sup>*</sup>, <b><i>s</i></b><sup>*</sup>, <i>μ</i><sup>*</sup>}, 其中<b><i>B</i></b><sup>*</sup>, <b><i>D</i></b><sup>*</sup>, <b><i>s</i></b><sup>*</sup>, <i>μ</i><sup>*</sup>是从数据中学习的参数最优值.模型HGRLPM将在学习好的层次粒表示<i>R</i><sup>HI</sup>基础上, 执行链接预测任务.为此我们设计了以下预测模型.</p>
                </div>
                <h4 class="anchor-tag" id="238" name="238"><b>5.1 协同预测</b></h4>
                <div class="p1">
                    <p id="239">给定层次粒度表示<i>R</i><sup>HI</sup>, 以及查询结点 (<i>u</i>, <i>v</i>) , 对于信息缺失的结点<i>u</i>, 根据<i>u</i>的属性信息, 寻找与<i>u</i>最相似的<i>n</i>个结点, 并以这些结点的潜在结点-隶属向量的期望作为潜变量<b><i>B</i></b><sub><i>u</i></sub>的值, 称之为预测向量, 记为<mathml id="240"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>¯</mo></mover></math></mathml><sub><i>u</i></sub>, 即</p>
                </div>
                <div class="p1">
                    <p id="241"><mathml id="242"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo>≜</mo></mrow></math></mathml><mathml id="243"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>t</mi><mo>∈</mo><mi>n</mi><mi>n</mi><mi>b</mi><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false">) </mo></mrow></munder><mi mathvariant="bold-italic">B</mi></mstyle><msubsup><mrow></mrow><mi>t</mi><mo>*</mo></msubsup></mrow></math></mathml>,      (22) </p>
                </div>
                <div class="p1">
                    <p id="244">其中, <i>nnb</i> (<i>u</i>) 为结点<i>u</i>最相似的<i>n</i>个结点集合.若<i>v</i>也是信息缺失, 那么执行与结点<i>u</i>相同的处理过程.</p>
                </div>
                <div class="p1">
                    <p id="245">在此基础上, 结点对 (<i>u</i>, <i>v</i>) 建立链接关系的协同预测概率<i>p</i> (<i>u</i>, <i>v</i>) , 即</p>
                </div>
                <div class="p1">
                    <p id="246"><mathml id="247"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">s</mi><mo>^</mo></mover><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo>⊙</mo><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>.      (23) </p>
                </div>
                <div class="p1">
                    <p id="248">特别地, 当<i>n</i>=1时, 这种协同预测策略称之为基础预测.</p>
                </div>
                <h4 class="anchor-tag" id="249" name="249"><b>5.2 预测算法</b></h4>
                <div class="p1">
                    <p id="250">下面给出基于层次粒度表示协同链接预测算法的详细步骤:</p>
                </div>
                <div class="p1">
                    <p id="251"><b>算法2</b>. 协同链接预测算法.</p>
                </div>
                <div class="p1">
                    <p id="252">输入:层次粒度表示<i>R</i><sup>HI</sup>、预测结点对 (<i>u</i>, <i>v</i>) 、协同数<i>n</i>;</p>
                </div>
                <div class="p1">
                    <p id="253">输出:结点对链接概率<i>p</i> (<i>u</i>, <i>v</i>) .</p>
                </div>
                <div class="p1">
                    <p id="254">① 根据属性表<i>F</i>, 协同数<i>n</i>, 计算结点对 (<i>u</i>, <i>v</i>) 的期望预测向量:<mathml id="255"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>¯</mo></mover></math></mathml><sub><i>u</i></sub>← 式 (22) , <mathml id="256"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">B</mi><mo>¯</mo></mover></math></mathml><sub><i>v</i></sub>← 式 (22) ;</p>
                </div>
                <div class="p1">
                    <p id="257">② 计算链接概率:<i>p</i> (<i>u</i>, <i>v</i>) ← 式 (23) ;</p>
                </div>
                <div class="p1">
                    <p id="258">③ 输出<i>p</i> (<i>u</i>, <i>v</i>) .</p>
                </div>
                <h3 id="259" name="259" class="anchor-tag"><b>6 实验与结果</b></h3>
                <div class="p1">
                    <p id="260">在本节中, 我们设计了关于引言部分介绍的示例数据集, 以及2个真实数据数据集AmazonFail<citation id="424" type="reference"><link href="396" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>和Lazega<citation id="425" type="reference"><link href="398" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>的实验.同时, 我们对比了HGRLPM与其他的算法的预测性能, 实验结果显示HGRLPM模型相对于其他的方法具有较强的优越性.</p>
                </div>
                <h4 class="anchor-tag" id="261" name="261"><b>6.1 数据集</b></h4>
                <div class="p1">
                    <p id="262">示例数据集的拓扑结构图已在引言部分介绍过了, 表1给出了示例数据的结点属性值, 表2给出了所有数据集的一些基本统计信息.</p>
                </div>
                <div class="p1">
                    <p id="263">AmazonFail数据集是从Amazon网站所收集的.该数据集总共有1 418个结点, 每一个都代表Amazon网站出售的一件产品.3 695条链接边建立了这些结点之间的相关关系.此外, 这个数据集还提供了产品的属性以及标签信息.标签信息用于标记用户对该产品的不满意度.</p>
                </div>
                <div class="p1">
                    <p id="264">Lazega数据集是一个公司法律事务所关于公司法合伙关系的属性图.它包括该公司的71名律师 (合伙人和同事) 之间的网络关系.这个数据集常用于社区网络分析, 例如有限团结、横向控制、质量控制、知识共享、权力平衡、监管等等.</p>
                </div>
                <div class="area_img" id="265">
                    <p class="img_tit"><b>表1 示例数据集结点的属性信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 The Attribute Information of the Toy Dataset</b></p>
                    <p class="img_note"></p>
                    <table id="265" border="1"><tr><td><br />Node</td><td>Age</td><td>Math</td><td>English</td><td>Art</td><td>Physics</td></tr><tr><td><br />Node<sub>1</sub></td><td>13</td><td>70</td><td>71</td><td>88</td><td>95</td></tr><tr><td><br />Node<sub>2</sub></td><td>14</td><td>81</td><td>88</td><td>93</td><td>85</td></tr><tr><td><br />Node<sub>3</sub></td><td>14</td><td>75</td><td>89</td><td>87</td><td>79</td></tr><tr><td><br />Node<sub>4</sub></td><td>14</td><td>86</td><td>85</td><td>95</td><td>81</td></tr><tr><td><br />Node<sub>5</sub></td><td>13</td><td>95</td><td>86</td><td>90</td><td>92</td></tr><tr><td><br />Node<sub>6</sub></td><td>14</td><td>89</td><td>91</td><td>92</td><td>88</td></tr><tr><td><br />Node<sub>7</sub></td><td>13</td><td>87</td><td>89</td><td>88</td><td>83</td></tr><tr><td><br />Node<sub>8</sub></td><td>15</td><td>70</td><td>72</td><td>90</td><td>81</td></tr><tr><td><br />Node<sub>9</sub></td><td>14</td><td>71</td><td>73</td><td>70</td><td>87</td></tr><tr><td><br />Node<sub>10</sub></td><td>14</td><td>92</td><td>88</td><td>90</td><td>93</td></tr><tr><td><br />Node<sub>11</sub></td><td>13</td><td>70</td><td>75</td><td>81</td><td>71</td></tr><tr><td><br />Node<sub>12</sub></td><td>14</td><td>69</td><td>89</td><td>87</td><td>84</td></tr><tr><td><br />Node<sub>13</sub></td><td>14</td><td>65</td><td>70</td><td>90</td><td>69</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="266">
                    <p class="img_tit"><b>表2 数据集基本统计信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Basic Statistics of Datasets</b></p>
                    <p class="img_note"></p>
                    <table id="266" border="1"><tr><td><br />Dataset</td><td>Nodes</td><td>Edges</td><td>Attributes</td></tr><tr><td><br />Toy</td><td>13</td><td>17</td><td>5</td></tr><tr><td><br />AmazonFail</td><td>1 418</td><td>3 695</td><td>28</td></tr><tr><td><br />Lazega</td><td>71</td><td>650</td><td>8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="267" name="267"><b>6.2 对比标准</b></h4>
                <div class="p1">
                    <p id="268">对于模型输出的链接概率, 设置一个阈值<i>ε</i>, 如果<i>p</i> (<i>u</i>, <i>v</i>) &gt;<i>ε</i>, 那么认为结点对 (<i>u</i>, <i>v</i>) 存在一条边, 即<i>E</i> (<i>u</i>, <i>v</i>) =1, 反之为0.那么, 使用3个指标来对比算法的性能:</p>
                </div>
                <div class="area_img" id="269">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JFYZ201903017_26900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="271">其中, <i>TP</i> (true positive) 为正确正例, <i>TN</i> (true negative) 为正确负例, <i>FP</i> (false positive) 为错误正例, <i>FN</i> (false negative) 为错误负例.</p>
                </div>
                <h4 class="anchor-tag" id="272" name="272"><b>6.3 案例分析</b></h4>
                <div class="p1">
                    <p id="273">在本节将详细分析算法在示例数据集上的性能, 以及与其他算法的对比.对比的算法为第1部分介绍的杰卡得系数 (JI) 和资源分配系数 (resource allocation index, RA) 和LHNI (Leicht Holme Newman index) 系数.</p>
                </div>
                <div class="p1">
                    <p id="274">由上述示例数据集的背景知识, 假设社区数量<i>k</i>=3, 学习率<i>γ</i>=0.001, 正则项系数<i>α</i>=0.03, <i>β</i>=0.005, 在这些参数设定条件下, 算法经过50次迭代后目标函数逐渐稳定, 最终在第59次迭代后收敛于6 020.49.具体的收敛过程如图3所示:</p>
                </div>
                <div class="area_img" id="275">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903017_275.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 HGRLPM模型链接预测结果" src="Detail/GetImg?filename=images/JFYZ201903017_275.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 HGRLPM模型链接预测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903017_275.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 5 The link prediction result of the HGRLPM model</p>

                </div>
                <div class="area_img" id="276">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903017_276.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 HGRLPM模型在示例数据集上的训练收敛过程" src="Detail/GetImg?filename=images/JFYZ201903017_276.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 HGRLPM模型在示例数据集上的训练收敛过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903017_276.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 The convergence of the HGRLPM model  training processes with the Toy dataset</p>

                </div>
                <div class="p1">
                    <p id="277">训练过程结束后, 我们得到了用于表示模型HGRLPM的最优参数值<b><i>B</i></b><sup>*</sup>, <b><i>s</i></b><sup>*</sup>.图4给出了<b><i>B</i></b><sup>*</sup>和<b><i>s</i></b><sup>*</sup>的参数值分布.从图4我们可以发现每个社区参与建立结点对之间的链接关系的贡献度<b><i>s</i></b><sup>*</sup>是不同的, 社区1的贡献度最小, 社区2的贡献度最大, 社区3的贡献介于社区1和社区2之间.同时, 社区贡献度<b><i>s</i></b><sup>*</sup>还影响着结点与社区之间的隶属关系<b><i>B</i></b><sup>*</sup>.模型HGRLPM的最优参数值也代表着:属性表导出的结点与类簇的隶属关系<b><i>D</i></b>与拓扑结构图产生的<b><i>B</i></b>在<b><i>B</i></b><sup>*</sup>时差异最小.这也表明通过最优化技术, 低层信息粒的不一致性在高层信息粒得到了最大化的消除.</p>
                </div>
                <div class="area_img" id="278">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JFYZ201903017_278.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 HGRLPM得到的社区重要度与结点-社区关系" src="Detail/GetImg?filename=images/JFYZ201903017_278.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 HGRLPM得到的社区重要度与结点-社区关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JFYZ201903017_278.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 The community weights and node-community  affiliation relations learnt by the HGRLPM</p>

                </div>
                <div class="p1">
                    <p id="279">通过数据训练得到最优模型HGRLPM后, 我们根据链接预测算法, 对属性图的所有结点, 预测其链接的生成概率.图5显示了模型HGRLPM预测的属性图中的示例训练集观测到的所有链接生成概率, 以及潜在链接 (生成概率大于50%的边) 的生成概率.在图5中, 虚线代表为错误正例, 实线为正确正例, 链接边的数字为建立链接的概率.</p>
                </div>
                <div class="p1">
                    <p id="280">另外, 表3给出了所有的结点对的链接边 (观测到的以及未观测到的结点链接关系) 预测概率.</p>
                </div>
                <div class="area_img" id="281">
                    <p class="img_tit"><b>表3 HGRLPM预测的所有结点对链接概率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 All of the Link Probability Predicted by the HGRLPM for the Node Pairs</b></p>
                    <p class="img_note"></p>
                    <table id="281" border="1"><tr><td><br />Nodes</td><td>Node<sub>1</sub></td><td>Node<sub>2</sub></td><td>Node<sub>3</sub></td><td>Node<sub>4</sub></td><td>Node<sub>5</sub></td><td>Node<sub>6</sub></td><td>Node<sub>7</sub></td><td>Node<sub>8</sub></td><td>Node<sub>9</sub></td><td>Node<sub>10</sub></td><td>Node<sub>11</sub></td><td>Node<sub>12</sub></td><td>Node<sub>13</sub></td></tr><tr><td><br />Node<sub>1</sub></td><td>0.00</td><td>0.12</td><td>0.26</td><td>0.11</td><td>0.09</td><td>0.10</td><td>0.09</td><td>0.25</td><td>0.53</td><td>0.01</td><td>0.56</td><td>0.02</td><td>0.55</td></tr><tr><td><br />Node<sub>2</sub></td><td>0.12</td><td>0.00</td><td>0.11</td><td>0.38</td><td>0.36</td><td>0.38</td><td>0.36</td><td>0.13</td><td>0.27</td><td>0.37</td><td>0.28</td><td>0.10</td><td>0.25</td></tr><tr><td><br />Node<sub>3</sub></td><td>0.26</td><td>0.11</td><td>0.00</td><td>0.06</td><td>0.03</td><td>0.01</td><td>0.02</td><td>0.15</td><td>0.29</td><td>0.00</td><td>0.30</td><td>0.01</td><td>0.30</td></tr><tr><td><br />Node<sub>4</sub></td><td>0.11</td><td>0.38</td><td>0.06</td><td>0.00</td><td>0.61</td><td>0.59</td><td>0.63</td><td>0.07</td><td>0.16</td><td>0.58</td><td>0.15</td><td>0.17</td><td>0.16</td></tr><tr><td><br />Node<sub>5</sub></td><td>0.09</td><td>0.36</td><td>0.03</td><td>0.61</td><td>0.00</td><td>0.63</td><td>0.01</td><td>0.02</td><td>0.05</td><td>0.64</td><td>0.05</td><td>0.21</td><td>0.03</td></tr><tr><td><br />Node<sub>6</sub></td><td>0.10</td><td>0.38</td><td>0.01</td><td>0.59</td><td>0.63</td><td>0.00</td><td>0.65</td><td>0.01</td><td>0.01</td><td>0.62</td><td>0.01</td><td>0.17</td><td>0.03</td></tr><tr><td><br />Node<sub>7</sub></td><td>0.09</td><td>0.36</td><td>0.02</td><td>0.63</td><td>0.01</td><td>0.65</td><td>0.00</td><td>0.01</td><td>0.00</td><td>0.68</td><td>0.00</td><td>0.16</td><td>0.04</td></tr><tr><td><br />Node<sub>8</sub></td><td>0.25</td><td>0.13</td><td>0.15</td><td>0.07</td><td>0.02</td><td>0.01</td><td>0.01</td><td>0.00</td><td>0.51</td><td>0.03</td><td>0.57</td><td>0.00</td><td>0.38</td></tr><tr><td><br />Node<sub>9</sub></td><td>0.53</td><td>0.27</td><td>0.29</td><td>0.16</td><td>0.05</td><td>0.01</td><td>0.00</td><td>0.51</td><td>0.00</td><td>0.00</td><td>0.63</td><td>0.00</td><td>0.63</td></tr><tr><td><br />Node<sub>10</sub></td><td>0.01</td><td>0.37</td><td>0.00</td><td>0.58</td><td>0.64</td><td>0.62</td><td>0.68</td><td>0.03</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.23</td><td>0.01</td></tr><tr><td><br />Node<sub>11</sub></td><td>0.56</td><td>0.28</td><td>0.30</td><td>0.15</td><td>0.05</td><td>0.01</td><td>0.00</td><td>0.57</td><td>0.63</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.65</td></tr><tr><td><br />Node<sub>12</sub></td><td>0.02</td><td>0.10</td><td>0.01</td><td>0.17</td><td>0.21</td><td>0.17</td><td>0.16</td><td>0.00</td><td>0.00</td><td>0.23</td><td>0.00</td><td>0.00</td><td>0.01</td></tr><tr><td><br />Node<sub>13</sub></td><td>0.55</td><td>0.25</td><td>0.30</td><td>0.16</td><td>0.03</td><td>0.03</td><td>0.04</td><td>0.38</td><td>0.63</td><td>0.01</td><td>0.65</td><td>0.01</td><td>0.00</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="282">从表3可以看出, 图5中有4条边划分为错误的负例, 即{ (Node<sub>4</sub>, Node<sub>13</sub>) :0.16, (Node<sub>2</sub>, Node<sub>4</sub>) :0.38, (Node<sub>2</sub>, Node<sub>3</sub>) :0.11, (Node<sub>2</sub>, Node<sub>12</sub>) :0.10};同时, 有3条未能观测到的边划分为正例, 即错误的正例{ (Node<sub>1</sub>, Node<sub>9</sub>) :0.53, (Node<sub>4</sub>, Node<sub>6</sub>) :0.59, (Node<sub>4</sub>, Node<sub>10</sub>) :0.58}.可以得到以下评价分:</p>
                </div>
                <div class="p1">
                    <p id="283" class="code-formula">
                        <mathml id="283"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mn>1</mn><mn>4</mn></mrow><mrow><mn>1</mn><mn>4</mn><mo>+</mo><mn>3</mn></mrow></mfrac><mo>=</mo><mn>8</mn><mn>2</mn><mo>.</mo><mn>3</mn><mn>5</mn><mi>%</mi><mo>, </mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mn>1</mn><mn>4</mn></mrow><mrow><mn>1</mn><mn>4</mn><mo>+</mo><mn>4</mn></mrow></mfrac><mo>=</mo><mn>7</mn><mn>7</mn><mo>.</mo><mn>7</mn><mn>8</mn><mi>%</mi><mo>, </mo></mtd></mtr><mtr><mtd><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mn>1</mn><mn>4</mn><mo>+</mo><mn>5</mn><mn>7</mn></mrow><mrow><mn>7</mn><mn>8</mn></mrow></mfrac><mo>=</mo><mn>9</mn><mn>1</mn><mo>.</mo><mn>0</mn><mn>2</mn><mi>%</mi><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="284">为了验证算法的性能, 我们将原有的拓扑相似索引JI<citation id="426" type="reference"><link href="352" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, RA<citation id="427" type="reference"><link href="356" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, LHNI<citation id="428" type="reference"><link href="356" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>进行扩展, 使之能够同时利用拓扑和属性表信息.然后与HGRLPM进行对比.具体扩展如下:</p>
                </div>
                <div class="p1">
                    <p id="285">1) 计算JI, RA, LHNI的相似度;</p>
                </div>
                <div class="p1">
                    <p id="286">2) 计算属性表中结点对的修正余弦相似度 (adjust cosine similarity, ACOS) , 即</p>
                </div>
                <div class="p1">
                    <p id="287"><mathml id="288"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msup><mrow></mrow><mrow><mtext>A</mtext><mtext>C</mtext><mtext>Ο</mtext><mtext>S</mtext></mrow></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>¯</mo></mover><mo stretchy="false">) </mo><mo>⋅</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>¯</mo></mover><mo stretchy="false">) </mo></mrow><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>¯</mo></mover></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub><mo>×</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>¯</mo></mover></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow></math></mathml>.      (25) </p>
                </div>
                <div class="p1">
                    <p id="289">3) 融合2个相似度, 以JI索引为例, 融合ACOS与JI, 即</p>
                </div>
                <div class="p1">
                    <p id="290"><i>δ</i><sup>JIA</sup> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>) =<i>θ</i>×<i>δ</i><sup>JI</sup> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>) + (1-<i>θ</i>) ×<i>δ</i><sup>ACOS</sup> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>) ,      (26) </p>
                </div>
                <div class="p1">
                    <p id="292">其中, <b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>为属性表中的任意结点的特征向量, <i>θ</i>为权值参数, 可以设置属性表与拓扑结构图的重要性.扩展后的3个算法分别记为JIA, RAA, LHNIA.</p>
                </div>
                <div class="p1">
                    <p id="293">我们使用3个扩展算法和相同的对比标准, 在示例数据集上可以得到表4的实验结果:</p>
                </div>
                <div class="area_img" id="294">
                    <p class="img_tit"><b>表4 示例数据集的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Performance Comparison of Toy</b></p>
                    <p class="img_note"></p>
                    <table id="294" border="1"><tr><td><br />Algorithms</td><td><i>Precison</i></td><td><i>Recall</i></td><td><i>Accuracy</i></td></tr><tr><td><br />HGRLPM</td><td>0.823 5</td><td>0.777 8</td><td>0.910 2</td></tr><tr><td><br />JIA</td><td>0.422 2</td><td>0.448 5</td><td>0.759 0</td></tr><tr><td><br />RAA</td><td>0.88 9</td><td>0.188 1</td><td>0.743 6</td></tr><tr><td><br />LHNIA</td><td>0.311 1</td><td>0.335 3</td><td>0.759 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="295">表4的3个方法 (JIA, RAA, LHNIA) 的结果为<i>θ</i>取值0.3:0.05:0.7的9次计算结果的均值.这3个方法的<i>Precision</i>, <i>Recall</i>, <i>Accuracy</i>的方差分别为 (JIA:0.224 3, 0.092 4, 0.026 3) , (RAA:0.115 2, 0.194 6, 0.012 8) 和 (LHNIA:0.295 5, 0.227 4, 0.019 0) .实验结果表明:无论是<i>Accuracy</i>还是<i>Precision</i>以及<i>Recall</i>指标, HGRLPM模型预测的结果对比JIA, RAA, LHNIA有着显著的提升.而且, 当<i>θ</i>的值发生变化时, 算法的性能波动较大, 这主要体现在方差的变化.原因在于JIA, RAA, LHNIA等算法是建立在原始信息上的单粒度表示之上, 拓扑结构图与属性表的原始信息融合容易出现偏差, 异构数据源的冲突较为明显.这也证明了在原始信息粒上直接处理信息融合是具有挑战性的问题.HGRLPM充分挖掘了潜在社区变量的分布, 以及社区作用的不平衡, 在多层信息粒的表示下, 将数据的不一致性上升到高层信息粒, 可以最大化地消除原始信息粒上较难处理的融合问题.这一对比结果映证了我们的假设, 也显示了HGRLPM的优越性.</p>
                </div>
                <h4 class="anchor-tag" id="296" name="296"><b>6.4 其他数据集上的结果</b></h4>
                <div class="p1">
                    <p id="297">采取与示例数据一致的评价标准, 表5和表6分别显示了在数据集AmazonFail和Lazega数据集上的算法性能.</p>
                </div>
                <div class="area_img" id="298">
                    <p class="img_tit"><b>表5 AmazonFail的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Performance Comparison of AmazonFail</b></p>
                    <p class="img_note"></p>
                    <table id="298" border="1"><tr><td><br />Algorithms</td><td><i>Precison</i></td><td><i>Recall</i></td><td><i>Accuracy</i></td></tr><tr><td><br />HGRLPM</td><td>0.235 1</td><td>0.339 2</td><td>0.846 2</td></tr><tr><td><br />JIA</td><td>0.555 0</td><td>0.205 6</td><td>0.995 7</td></tr><tr><td><br />RAA</td><td>0.000 0</td><td>0.000 0</td><td>0.996 1</td></tr><tr><td><br />LHNIA</td><td>0.000 0</td><td>0.000 0</td><td>0.996 1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="299">
                    <p class="img_tit"><b>表6 Lazega的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 6 Performance Comparison of Lazega</b></p>
                    <p class="img_note"></p>
                    <table id="299" border="1"><tr><td><br />Algorithms</td><td><i>Precison</i></td><td><i>Recall</i></td><td><i>Accuracy</i></td></tr><tr><td><br />HGRLPM</td><td>0.409 1</td><td>0.641 2</td><td>0.815 7</td></tr><tr><td><br />JIA</td><td>0.185 0</td><td>0.582 2</td><td>0.739 9</td></tr><tr><td><br />RAA</td><td>0.000 0</td><td>0.000 0</td><td>0.738 4</td></tr><tr><td><br />LHNIA</td><td>0.000 0</td><td>0.000 0</td><td>0.738 4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="300">虽然HGRLPM能够取得比JIA, RAA, LHNIA要好的<i>Precison</i>和 <i>Recall</i>成绩, 但<i>Accuracy</i>却提升不是很显著, 甚至在AmazonFail数据集上, <i>Accuracy</i>指标在还有较大的差距离, 主要原因在于拓扑图数据的结点链接的稀疏性.当数据集规模不大时稀疏性不会对算法性能产生很严重的影响, 然而当数据集规模扩大到一定程度时, 稀疏性将严重影响预测的准确性.这一现象也称之为类别不平衡问题<citation id="429" type="reference"><link href="400" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>.最直观的影响在于正例淹没在负例的海洋.对于<i>Precision</i>和<i>Recall</i>为0, 这说明RAA和LHNIA在数据集AmazonFail和Lazega上所有的判例都为负, 不能识别正例, 这也证实了底层原始数据源的不一致性.同时, 这也说明了当数据规模扩大时, HGRLPM应该在建模时对数据的稀疏性这一数据因子加以考虑.</p>
                </div>
                <h3 id="301" name="301" class="anchor-tag"><b>7 结 论</b></h3>
                <div class="p1">
                    <p id="302">本文提出了一种融合异构数据 (网络拓扑图与结点属性表) 的层次粒度表示模型, 根据粒计算理论, 对于低层信息粒中的数据不一致性, 通过提升粒层的方法, 在高层信息粒最大化的消除异构数据的不一致性.该方法的最大优势在于它能捕捉数据潜在的层次粒度结构, 同时也最大化的捕捉了数据的语义.实验结果表明, 层次信息粒表示的链模型是有效的, 对比其他方法有较大优势.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="342">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100530194&amp;v=MDYyNzA5RlllZ1BEWFU5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdJSmx3VmF4Yz1OaWZPZmJLN0h0RE9ybw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Lü Linyuan, Zhou Tao. Link prediction in complex networks: A survey[J]. Physica A: Statistical Mechanics &amp; Its Applications, 2011, 390 (6) : 1150- 1170
                            </a>
                        </p>
                        <p id="344">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201703001&amp;v=MDU4Mjk5Yk1ySTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3blVyN05MejdCZHJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Zhao Shu, Liu Xiaoman, Duan Zhen, et al. A survey on social ties mining[J]. Chinese Journal of Computers, 2017, 40 (3) : 535- 555 (in Chinese) (赵姝, 刘晓曼, 段震, 等. 社交关系挖掘研究综述[J]. 计算机学报, 2017, 40 (3) : 535- 555) 
                            </a>
                        </p>
                        <p id="346">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The link-prediction problem for social networks">

                                <b>[3]</b>Libennowell D, Kleinberg J. The link prediciton problem for social networks[J]. Journal of the Association for Information Science &amp; Technology, 2007, 58 (7) : 1019- 1031
                            </a>
                        </p>
                        <p id="348">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiplicative attribute graph model of real world networks">

                                <b>[4]</b>Kim M, Leskovec J. Multiplicative attribute graph model of real world networks[C] //Proc of the Int Workshop on Algorithms and Models for the Web-Graph. Berlin: Springer, 2010: 62- 73
                            </a>
                        </p>
                        <p id="350">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering and preferential attachment in growing networks">

                                <b>[5]</b>Newman M E J. Clustering and preferential attachment in growing networks[J]. Physical Review E-Statistical, Nonlinear and Soft Matter Physics, 2001, 64 (2) : 025102
                            </a>
                        </p>
                        <p id="352">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Etude comparative de la distribution florale dans une portion des Alpes et des Jura">

                                <b>[6]</b>Jaccard P. Etude de la distribution florale dans une portion des Alpes et du Jura[J]. Bulletin De La Societe Vaudoise Des Sciences Naturelles, 1901, 37 (142) : 547- 579
                            </a>
                        </p>
                        <p id="354">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Introduction to Modern Information Retrieval">

                                <b>[7]</b>Salton G, Mcgill M J. Introduction to Modern Information Retrieval[M]. New York: McGraw-Hill, 1983: 305- 306
                            </a>
                        </p>
                        <p id="356">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003593437&amp;v=MjY3NzdCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVmIzSklWcz1OajdCYXJPNEh0SFBxb1pHWU9nSVkzazV6&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Zhou Tao, Lü Linyuan, Zhang Yicheng. Predicting missing links via local information[J]. European Physical Journal B, 2009, 71 (4) : 623- 630
                            </a>
                        </p>
                        <p id="358">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100484987&amp;v=MTU1NzNpZk9mYks3SHRET3JvOUZZT01MQlhRK29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsd1ZheGM9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Adamic L A, Adar E. Friends and neighbors on the Web[J]. Social Networks, 2003, 25 (3) : 211- 230
                            </a>
                        </p>
                        <p id="360">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical structure and the prediction of missing links in networks">

                                <b>[10]</b>Clauset A, Moore C, Newman M E. Hierarchical structure and the prediction of missing links in networks[J]. Nature, 2008, 453 (7191) : 98- 101
                            </a>
                        </p>
                        <p id="362">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning Probabilistic Relational Models">

                                <b>[11]</b>Friedman N, Getoor L, Koller D, et al. Learning probabilistic relational models[C] //Proc of the 16th Int Joint Conf on Artificial Intelligence. San Francisco: Morgan Kaufmann, 1999: 1300- 1309
                            </a>
                        </p>
                        <p id="364">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Link Prediction in Relational Data,&amp;quot;">

                                <b>[12]</b>Taskar B, Wong M F, Abbeel P, et al. Link prediction in relational data[C] //Proc of the 16th Int Conf on Neural Information Processing Systems. Cambridge: MIT Press, 2003: 659- 666
                            </a>
                        </p>
                        <p id="366">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relational dependency networks">

                                <b>[13]</b>Neville J, Jensen D. Relational dependency networks[J]. Journal of Machine Learning Research, 2007, 8 (2) : 653- 692
                            </a>
                        </p>
                        <p id="368">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPD00000092103&amp;v=MDUwOTdNSDdSN3FlYnVkdEZTbmxWYjNKSVZzPU5pVGJhck80SHRITXI0WkhaZXNNWTNrNXpCZGg0ajk5U1hxUnJ4b3hj&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Liu Zhen, Zhang Qianming, Lü Linyuan, et al. Link prediction in complex networks: A local naive bayes model[J]. Europhysics Letters, 2011, 96 (4) : 8007
                            </a>
                        </p>
                        <p id="370">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local probabilistic models for link prediction">

                                <b>[15]</b>Wang Chao, Satuluri V, Parthasarathy S. Local probabilistic models for link prediction[C] //Proc of the 7th IEEE Int Conf on Data Mining. Los Alamitos, CA: IEEE Computer Society, 2007: 322- 331
                            </a>
                        </p>
                        <p id="372">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Link Prediction via Matrix Factorization">

                                <b>[16]</b>Menon A K, Elkan C. Link prediction via matrix factorization[C] //Proc of the 2011 European Conf on Machine Learning and Knowledge Discovery in Databases. Berlin: Springer, 2011: 437- 452
                            </a>
                        </p>
                        <p id="374">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000093225&amp;v=MTY1MTJVYjdJSmx3VmF4Yz1OaWZJWTdLN0h0ak5yNDlGWk9JTURuNDhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b>Dunlavy D M, Kolda T G, Acar E. Temporal link prediction using matrix and tensor factorizations[J]. ACM Transactions on Knowledge Discovery from Data, 2011, 5 (2) : 10:1- 10:27
                            </a>
                        </p>
                        <p id="376">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning nonparametric relational models by conjugately incorporating node information in a network">

                                <b>[18]</b>Fan Xuhui, Xu Yida, Cao Longbing, et al. Learning nonparametric relational models by conjugately incorporating node information in a network[J]. IEEE Transactions on Cybernetics, 2017, 47 (3) : 589- 599
                            </a>
                        </p>
                        <p id="378">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonparametric latent feature models for link prediction">

                                <b>[19]</b>Miller K T, Griffiths T L, Jordan M I. Nonparametric latent feature models for link prediction[C] //Proc of the 22nd Int Conf on Neural Information Processing Systems. Vancouver: Curran Associates, 2009: 1276- 1284
                            </a>
                        </p>
                        <p id="380">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201604005&amp;v=MjM5ODZPZVplVnZGeTduVXI3Tkx5dlNkTEc0SDlmTXE0OUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b>Wang Xin, Wang Ying, Zuo Wanli. Exploring interactional opinions and status theory for predicting links in signed network[J]. Journal of Computer Research and Development, 2016, 53 (4) : 764- 775 (in Chinese) (王鑫, 王英, 左万利. 基于交互意见和地位理论的符号网络链接预测模型[J]. 计算机研究与发展, 2016, 53 (4) :764- 775) 
                            </a>
                        </p>
                        <p id="382">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201502016&amp;v=MTMyOTA1NE8zenFxQnRHRnJDVVJMT2VaZVZ2Rnk3blVyN05MeXZTZExHNEg5VE1yWTlFWW9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>Liu Ye, Zhu Weiheng, Pan Yan, et al. Multiple sources fusion for link prediction via low-rank and sparse matrix decomposition[J]. Journal of Computer Research and Development, 2015, 52 (2) : 423- 436 (in Chinese) (刘冶, 朱蔚恒, 潘炎, 等. 基于低秩和稀疏矩阵分解的多源融合链接预测算法[J]. 计算机研究与发展, 2015, 52 (2) : 423- 436) 
                            </a>
                        </p>
                        <p id="384">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201310013&amp;v=MDkxNjFyQ1VSTE9lWmVWdkZ5N25VcjdOTHo3QmRyRzRIOUxOcjQ5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>Zhang Zehua, Miao Duoqian, Qian Jin. Detecting overlapping communities with heuristic expansion mehtod based on rough neighborhood[J]. Chinese Journal of Computers, 2013, 36 (10) : 2078- 2086 ( in Chinese) (张泽华, 苗夺谦, 钱进. 邻域粗糙化的启发式重叠社区扩张方法[J]. 计算机学报, 2013, 36 (10) : 2078- 2086) 
                            </a>
                        </p>
                        <p id="386">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interpreting concept learning in cognitive informatics and granular computing">

                                <b>[23]</b>Yao Yiyu. Interpreting concept learning in cognitive informatics and granular computing[J]. IEEE Transactions on Systems Man &amp; Cybernetics , Part B (Cybernetics) , 2009, 39 (4) : 855- 866
                            </a>
                        </p>
                        <p id="388">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011601416145&amp;v=MTg2MzZmYks3SHRETnFZOUVZT29KRFhnOG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3SUpsd1ZheGM9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b>Yao Yiyu, Zhao Liquan. A measurement theory view on the granularity of partitions[J]. Information Sciences, 2012, 213 (2012) : 1- 13
                            </a>
                        </p>
                        <p id="390">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The duality of persons and groups">

                                <b>[25]</b>Breiger R L. The duality of persons and groups[J]. Social Forces, 1974, 53 (2) :181- 190
                            </a>
                        </p>
                        <p id="392">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Overlapping community detection at scale: A nonnegative matrix factorization approach">

                                <b>[26]</b>Yang Jaewon, Leskovec J. Overlapping community detection at scale: A nonnegative matrix factorization approach[C] //Proc of the 6th ACM Int Conf on Web Search &amp; Data Mining. New York: ACM, 2013: 587- 596
                            </a>
                        </p>
                        <p id="394">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast Coordinate Descent Methods with Variable Selectionfor Non-negative Matrix Factorization">

                                <b>[27]</b>Hsieh C J, Dhillon I S. Fast coordinate descent methods with variable selection for non-negative matrix factorization[C] //Proc of the 17th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining. New York: ACM, 2011: 1064- 1072
                            </a>
                        </p>
                        <p id="396">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Statistical selection of congruent subspaces for mining attributed graphs">

                                <b>[28]</b>Sanchez P I, Muller E, Laforet F, et al. Statistical selection of congruent subspaces for mining attributed graphs[C] //Proc of the 13th IEEE Int Conf on Data Mining. Piscataway, NJ: IEEE, 2013: 647- 656
                            </a>
                        </p>
                        <p id="398">
                            <a id="bibliography_29" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001282341&amp;v=MjIzNTVPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU25sVmIzSklWcz1OaWZjYXJPNEh0SE5yWWRIWis4&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[29]</b>Snijders T A B, Pattison P E, Robins G L, et al. New specifications for exponential random graph models[J]. Sociological Methodology, 2010, 36 (1) : 99- 153
                            </a>
                        </p>
                        <p id="400">
                            <a id="bibliography_30" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201611017&amp;v=MjQ3NjdlWmVWdkZ5N25VcjdOTHl2U2RMRzRIOWZOcm85RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[30]</b>Xiong Bingyan, Wang Guoyin, Deng Weibin. Under-sampling method based on sample weight for imbalanced data[J]. Journal of Computer Research and Development, 2016, 53 (11) : 2613- 2622 (in Chinese) (熊冰妍, 王国胤, 邓维斌. 基于样本权重的不平衡数据欠抽样方法[J]. 计算机研究与发展, 2016, 53 (11) : 2613- 2622) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="430" href="javascript:void(0)">
                            <b>1</b> https://en.wikipedia.org/wiki/Big_data
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JFYZ201903017" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201903017&amp;v=MzExMTVxcUJ0R0ZyQ1VSTE9lWmVWdkZ5N25VcjdOTHl2U2RMRzRIOWpNckk5RVk0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR01QWmh5WWp6SmI1Z2pYeEdIOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
