<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140732139037500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJDGC201903003%26RESULT%3d1%26SIGN%3dxE34SbKlGZffWkbMwGQojbGGFRs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JDGC201903003&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JDGC201903003&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDGC201903003&amp;v=MjcxODViRzRIOWpNckk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGdVci9JTHluTWI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="0 引 言 ">0 引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="1 算法框架 ">1 算法框架</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="2 样本集的建立 ">2 样本集的建立</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="3 &lt;i&gt;PX&lt;/i&gt;-&lt;i&gt;LBP&lt;/i&gt;特征提取算子 ">3 <i>PX</i>-<i>LBP</i>特征提取算子</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="3.1 经典&lt;i&gt;LBP&lt;/i&gt;算子">3.1 经典<i>LBP</i>算子</a></li>
                                                <li><a href="#78" data-title="3.2 &lt;i&gt;PX&lt;/i&gt;-&lt;i&gt;LBP&lt;/i&gt;算子">3.2 <i>PX</i>-<i>LBP</i>算子</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="4 随机森林分类器 ">4 随机森林分类器</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#111" data-title="5 装配过程的识别与监测 ">5 装配过程的识别与监测</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#113" data-title="5.1 装配体零件的识别">5.1 装配体零件的识别</a></li>
                                                <li><a href="#115" data-title="5.2 装配过程监测">5.2 装配过程监测</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#125" data-title="6 实验及结果分析 ">6 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#132" data-title="6.1 相关参数的确定">6.1 相关参数的确定</a></li>
                                                <li><a href="#139" data-title="6.2 识别效率">6.2 识别效率</a></li>
                                                <li><a href="#143" data-title="6.3 装配体各零件像素识别">6.3 装配体各零件像素识别</a></li>
                                                <li><a href="#148" data-title="6.4 装配过程的监测">6.4 装配过程的监测</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#162" data-title="7 结束语 ">7 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="图1 算法框架">图1 算法框架</a></li>
                                                <li><a href="#128" data-title="图2 减速器各零件的颜色标记">图2 减速器各零件的颜色标记</a></li>
                                                <li><a href="#136" data-title="图3 部分参数的确定">图3 部分参数的确定</a></li>
                                                <li><a href="#141" data-title="&lt;b&gt;表1 识别单张图片所用时间&lt;/b&gt;"><b>表1 识别单张图片所用时间</b></a></li>
                                                <li><a href="#147" data-title="图4 分类器对各零件的像素识别率">图4 分类器对各零件的像素识别率</a></li>
                                                <li><a href="#150" data-title="图5 深度图像 (左) 和像素预测图像 (右) ">图5 深度图像 (左) 和像素预测图像 (右) </a></li>
                                                <li><a href="#152" data-title="图6 正确装配像素预测图像 (左) 和待测像素预测图像 (右) ">图6 正确装配像素预测图像 (左) 和待测像素预测图像 (右) </a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表2&lt;/b&gt; P&lt;sub&gt;&lt;b&gt;7&lt;/b&gt;&lt;/sub&gt;&lt;b&gt;件漏装的比对数据&lt;/b&gt;"><b>表2</b> P<sub><b>7</b></sub><b>件漏装的比对数据</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;表3&lt;/b&gt; P&lt;sub&gt;&lt;b&gt;3&lt;/b&gt;&lt;/sub&gt;&lt;b&gt;件漏装的比对数据&lt;/b&gt;"><b>表3</b> P<sub><b>3</b></sub><b>件漏装的比对数据</b></a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表4&lt;/b&gt; P&lt;sub&gt;&lt;b&gt;0&lt;/b&gt;&lt;/sub&gt;&lt;b&gt;件错位的比对数据&lt;/b&gt;"><b>表4</b> P<sub><b>0</b></sub><b>件错位的比对数据</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="186">


                                    <a id="bibliography_1" title=" CAO W, JIANG P Y, LU P, et al. Real-time data-driven monitoring in job-shop floor based on radio frequency identification [J]. The International Journal of Advanced Manufacturing Technology, 2017, 92 (5-8) :2099-2120." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time data-driven monitoring in job-shop floor based on radio frequency identification">
                                        <b>[1]</b>
                                         CAO W, JIANG P Y, LU P, et al. Real-time data-driven monitoring in job-shop floor based on radio frequency identification [J]. The International Journal of Advanced Manufacturing Technology, 2017, 92 (5-8) :2099-2120.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_2" title=" YIN C H, WANG W, ZHAO G, et al. Research on rapid layout method of RFID devices for aircraft assembly monitoring [C]. Proceedings of 2016 6th International Conference on Information Technology for Manufacturing Systems, Prague:IEEE, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Research on rapid layout method of RFID devices for aircraft assembly monitoring">
                                        <b>[2]</b>
                                         YIN C H, WANG W, ZHAO G, et al. Research on rapid layout method of RFID devices for aircraft assembly monitoring [C]. Proceedings of 2016 6th International Conference on Information Technology for Manufacturing Systems, Prague:IEEE, 2016.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_3" title=" 周铨.一种过盈压装装配工序的过程监测系统[J].机电产品开发与创新, 2018, 31 (3) :84-86." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDCP201803030&amp;v=MjE1MjFyQ1VSN3FmWnVabkZpRGdVci9JTHluSWZyRzRIOW5Nckk5R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         周铨.一种过盈压装装配工序的过程监测系统[J].机电产品开发与创新, 2018, 31 (3) :84-86.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_4" title=" 陈培, 申红明, 张会猛, 等.基于ARM的线缆生产监控系统的设计[J].现代电子技术, 2017, 40 (8) :65-72." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201708020&amp;v=MTI2MzVxcUJ0R0ZyQ1VSN3FmWnVabkZpRGdVci9JUFNuUFpMRzRIOWJNcDQ5SFpJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         陈培, 申红明, 张会猛, 等.基于ARM的线缆生产监控系统的设计[J].现代电子技术, 2017, 40 (8) :65-72.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_5" title=" 汪嘉杰, 王磊, 范秀敏, 等.基于视觉的航天电连接器的智能识别与装配引导[J], 计算机集成制造系统, 2017, 23 (11) :2423-2430." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJJ201711011&amp;v=MjI4MzE0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURnVXIvSUx6N0JaTEc0SDliTnJvOUVaWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         汪嘉杰, 王磊, 范秀敏, 等.基于视觉的航天电连接器的智能识别与装配引导[J], 计算机集成制造系统, 2017, 23 (11) :2423-2430.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_6" title=" OJALA T, PIETIKAINEN M, HARWOOD D. A comparative study of texture measures with classification based on featured distribu-tions [J]. Pattern Recognition, 1996, 29 (1) :51-59." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600742093&amp;v=MTI2MTVpclJkR2VycVFUTW53WmVadEZpbmxVcmJKS0ZzVmFoST1OaWZPZmJLN0h0RE5xWTlGWSs4TkRIVTZvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         OJALA T, PIETIKAINEN M, HARWOOD D. A comparative study of texture measures with classification based on featured distribu-tions [J]. Pattern Recognition, 1996, 29 (1) :51-59.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     OJALA T, PIETIKAINEN M, MEMBER S, et al. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) :971-987.</a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_8" title=" LIAO S, ZHU X, LEI Z, et al. Learning multi-scale block local binary patterns for face recognition[J]. Lecture Notes in Computer Science, 2007 (4642) :828-837." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning multi-scale block local binary patterns for face recognition">
                                        <b>[8]</b>
                                         LIAO S, ZHU X, LEI Z, et al. Learning multi-scale block local binary patterns for face recognition[J]. Lecture Notes in Computer Science, 2007 (4642) :828-837.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_9" title=" HEIKKILA M, PIETIKAINEN M, SCHMID C. Description of interestrions with local binary patterns[J]. Pattern Recognition, 2009, 42 (3) :425-436." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Description of interest regions with local binary patterns">
                                        <b>[9]</b>
                                         HEIKKILA M, PIETIKAINEN M, SCHMID C. Description of interestrions with local binary patterns[J]. Pattern Recognition, 2009, 42 (3) :425-436.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_10" title=" MATURANA D, MERY D, SOTO A. Learning discriminative local binary patterns for face recognition[C]. IEEE international conference on automatic face and gesture recognition, Santa Barbona:IEEE, 2011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning Discriminative Local Binary Patterns for Face Recognition">
                                        <b>[10]</b>
                                         MATURANA D, MERY D, SOTO A. Learning discriminative local binary patterns for face recognition[C]. IEEE international conference on automatic face and gesture recognition, Santa Barbona:IEEE, 2011.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_11" title=" HUSSAIN S U, NAPOLEON T, JURIE F . Face recognition using local quantized patterns[C]. British machine vision conference, Guildford: IEEE, 2012." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual recognition using local quantized patterns">
                                        <b>[11]</b>
                                         HUSSAIN S U, NAPOLEON T, JURIE F . Face recognition using local quantized patterns[C]. British machine vision conference, Guildford: IEEE, 2012.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_12" title=" 冀中, 聂林红.基于抗噪声局部二值模式的纹理图像分类[J].计算机研究与发展, 2016, 53 (5) :1128-1135." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201605018&amp;v=MjAwMTh0R0ZyQ1VSN3FmWnVabkZpRGdVci9JTHl2U2RMRzRIOWZNcW85RWJJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         冀中, 聂林红.基于抗噪声局部二值模式的纹理图像分类[J].计算机研究与发展, 2016, 53 (5) :1128-1135.
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_13" title=" 胡敏, 腾文娣, 王晓华, 等.融合局部纹理和形状的人脸表情识别[J].电子与信息学报, 2018, 40 (6) :1338-1344." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201806010&amp;v=MDMwODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGdVci9JSVRmU2RyRzRIOW5NcVk5RVpJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         胡敏, 腾文娣, 王晓华, 等.融合局部纹理和形状的人脸表情识别[J].电子与信息学报, 2018, 40 (6) :1338-1344.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_14" title=" SHOTTON J, FITZGIBBON A, COOK M, et al. Real-time human pose recognition in parts from single depth images[J]. Computer Vision &amp;amp; Pattern Recognition, 2011, 56 (1) :1297-1304." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time human pose recognition in parts from single depth images">
                                        <b>[14]</b>
                                         SHOTTON J, FITZGIBBON A, COOK M, et al. Real-time human pose recognition in parts from single depth images[J]. Computer Vision &amp;amp; Pattern Recognition, 2011, 56 (1) :1297-1304.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_15" title=" 田野, 项世军.基于LBP和多层DCT的人脸活体检测算法[J].计算机研究展, 2018, 55 (3) :1128-1135." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201803017&amp;v=MTg0ODNTZExHNEg5bk1ySTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEZ1VyL0lMeXY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         田野, 项世军.基于LBP和多层DCT的人脸活体检测算法[J].计算机研究展, 2018, 55 (3) :1128-1135.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_16" title=" 李光梅, 苟岩岩, 刘果玲, 等.易拉罐空罐缺陷智能轻测系统的设计[J].包装与食品机械, 2017 (6) :33-36." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BZSJ201706008&amp;v=MjI2MTgvSUp6ZllaTEc0SDliTXFZOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURnVXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         李光梅, 苟岩岩, 刘果玲, 等.易拉罐空罐缺陷智能轻测系统的设计[J].包装与食品机械, 2017 (6) :33-36.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_17" title=" 刘继忠, 吴文虎, 程乘, 等.基于像素滤波和中值滤波的深度图像修复方法[J].光电子.激光, 2018, 29 (5) :539-544." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201805012&amp;v=MTA0NjR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEZ1VyL0lJaW5SWkxHNEg5bk1xbzlFWm9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         刘继忠, 吴文虎, 程乘, 等.基于像素滤波和中值滤波的深度图像修复方法[J].光电子.激光, 2018, 29 (5) :539-544.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_18" title=" XU J, DING X Q, WANG S J, et al. Background subtraction based on combination of texture, color and intensity[J]. ICSP: 2008 9&lt;sup&gt;th&lt;/sup&gt; International Conference on Signal Processing, 2008 (1) :1400-1405." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Background subtraction based on a combination of texture,color and intensity">
                                        <b>[18]</b>
                                         XU J, DING X Q, WANG S J, et al. Background subtraction based on combination of texture, color and intensity[J]. ICSP: 2008 9&lt;sup&gt;th&lt;/sup&gt; International Conference on Signal Processing, 2008 (1) :1400-1405.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_19" title=" BREIMAN L. Randomized decision forests[J]. Machine Learning, 2001, 45 (1) :5-32." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Randomized decision forests">
                                        <b>[19]</b>
                                         BREIMAN L. Randomized decision forests[J]. Machine Learning, 2001, 45 (1) :5-32.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_20" title=" BREIMAN L, FRIEDMAN J H, OLSHEN R A, et al. Classification and regression trees (CART) [J]. Biomtrics, 1984, 40 (3) :358." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification and regression trees (CART)">
                                        <b>[20]</b>
                                         BREIMAN L, FRIEDMAN J H, OLSHEN R A, et al. Classification and regression trees (CART) [J]. Biomtrics, 1984, 40 (3) :358.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-03-21 16:37</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JDGC" target="_blank">机电工程</a>
                2019,36(03),236-243 DOI:10.3969/j.issn.1001-4551.2019.03.002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于PX-LBP和像素分类的装配体零件识别研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%94%B0%E4%B8%AD%E5%8F%AF&amp;code=37260840&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">田中可</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%88%90%E5%86%9B&amp;code=22453420&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈成军</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E4%B8%9C%E5%B9%B4&amp;code=36427469&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李东年</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%AD%A3%E6%97%AD&amp;code=41308062&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵正旭</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%9D%92%E5%B2%9B%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E6%9C%BA%E6%A2%B0%E4%B8%8E%E6%B1%BD%E8%BD%A6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0040284&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">青岛理工大学机械与汽车工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对机械产品装配维修诱导中零件和装配体的识别、监测问题, 对装配体零件识别及装配监测进行了研究, 对LBP算子进行了改进, 提出了一种基于像素局部二值模式 (PX-LBP) 和像素分类的装配体零件识别及装配监测方法。首先将LBP算子与像素分类融合, 提出了PX-LBP算子;然后对深度图像进行了PX-LBP特征提取, 生成了训练集和测试集;最后训练随机森林分类器, 并利用训练好的随机森林分类器实现了对测试集深度图像的像素分类, 生成了像素预测图像, 通过像素预测图像与标记图像对比实现了装配体零件的识别及装配过程的监测。研究结果表明:该方法对于模型深度图像的像素识别率可达到98.81%, 对于真实装配体深度图像的像素识别率也可达到77.51%;该方法兼具了一定的实时性与鲁棒性, 可用在装配维修诱导、装配监测和自动化装配邻域中。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9B%B6%E4%BB%B6%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">零件识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A3%85%E9%85%8D%E7%9B%91%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">装配监测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%83%8F%E7%B4%A0%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BC%E6%A8%A1%E5%BC%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">像素局部二值模式;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%83%8F%E7%B4%A0%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">像素分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%88%86%E7%B1%BB%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机森林分类器;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    田中可 (1989-) , 男, 山东菏泽人, 硕士研究生, 主要从事零件识别及装配监测方面的研究。E-mail:1321990585@qq.com;
                                </span>
                                <span>
                                    *陈成军, 男, 教授, 硕士生导师。E-mail:chenchengjun79@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (51475251, 51705273);</span>
                                <span>山东省重点研发计划资助项目 (2017GGX203003);</span>
                    </p>
            </div>
                    <h1><b>Recognition of assembly parts based on PX-LBP and pixel classification</b></h1>
                    <h2>
                    <span>TIAN Zhong-ke</span>
                    <span>CHEN Cheng-jun</span>
                    <span>LI Dong-nian</span>
                    <span>ZHAO Zheng-xu</span>
            </h2>
                    <h2>
                    <span>School of Mechanical & Automotive Engineering, Qingdao University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at issue of parts recognition and assembly monitoring in assembly maintenance and guidance of mechanical products, a part recognition and assembly monitoring method based on Pixel Local Binary Pattern (PX-LBP) was proposed. Firstly, the classical LBP operator was merged with the pixel classification to propose an improved LBP operator, which is named PX-LBP operator. Secondly, PX-LBP features of the depth images were extracted. And training set and test set were obtained. Finally, the randomized decision forests classifier was trained. Then the pixel classification of the depth image of the test set was executed to get the pixel prediction image of depth images. The recognition of assembly parts was realized by comparing the RGB values of pixel prediction image and the corresponding color label image. The assembly process monitoring was realized by analyzing the number and position of pixels in pixel prediction image of each assembly part to determine the assembly error. Experiment results show that the method proposed in this paper has high accuracy, real-time and robust ability, and can be used in fields of assembly maintenance guiding, assembly monitoring and automatic assembly.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=part%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">part recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=assembly%20monitoring&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">assembly monitoring;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=depth%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">depth image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=pixel%20local%20binary%20pattern&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">pixel local binary pattern;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=pixel%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">pixel classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=randomized%20decision%20forests%20classifier&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">randomized decision forests classifier;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-09</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">0 引 言</h3>
                <div class="p1">
                    <p id="44">大型复杂机械装备涉及的装配知识较多, 装配过程中工人难免会出现装配错误, 因此, 需要一种智能化的装配监测系统, 智能识别装配体各零件并监测装配过程。</p>
                </div>
                <div class="p1">
                    <p id="45">目前, 监测已广泛应用于生产中, 特别是产品装配领域, 如CAO等<citation id="226" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>提出了基于射频识别的车间实时数据驱动监测技术;YIN等<citation id="227" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>提出了一种面向飞机装配过程监测的RFID布局方法, 满足了飞机装配过程的监测要求;周铨<citation id="228" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>针对过盈装配过程中的质量控制和数据采集问题, 提出了过盈压装装配工序的过程监测系统;陈培等<citation id="229" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>设计了基于ARM的线缆智能生产监控系统, 满足了线缆生产自动化控制中的监测要求;汪嘉杰等<citation id="230" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出的基于视觉的航天电连接器智能识别与装配引导方法, 实现了航天电连接器的装配监测。以上成果针对具体产品的装配需求, 实现了装配过程中的监测功能, 但对机械产品装配维修诱导中零件和装配体的识别、监测问题相关研究较少。</p>
                </div>
                <div class="p1">
                    <p id="46">OJALA等<citation id="231" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>在1996年提出LBP算子, 是一种有效的纹理特征提取算法, 后经过了扩展LBP算子和旋转不变性LBP算子<citation id="232" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、MB-LBP<citation id="233" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、CS-LBP<citation id="234" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、DLBP<citation id="235" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、LQP<citation id="236" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、CELBP<sup>NT</sup><citation id="237" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>以及CS-LSBP<citation id="238" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>等多次改进。虽然改进后的LBP算子已有了很大提高, 但以上改进大多针对纹理分析和人脸识别领域, 使用的图像多为灰度图像, 识别单元多为整幅图像, 即每幅图像产生1组特征值向量。</p>
                </div>
                <div class="p1">
                    <p id="47">针对装配体零件识别与监测问题, 受SHOTTON等人<citation id="239" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>将深度差分特征与像素分类相融合及田野等人<citation id="240" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>将LBP与多层DCT相融合的启发, 本文将提出把PX-LBP与像素分类相融合的方法。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">1 算法框架</h3>
                <div class="p1">
                    <p id="49">基于PX-LBP和像素分类的零件识别及装配监测算法的整体框架如图1所示。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JDGC201903003_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 算法框架" src="Detail/GetImg?filename=images/JDGC201903003_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JDGC201903003_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="51">具体步骤为:首先获取深度图像包括模型的合成深度图像和装配体的真实深度图像, 并利用PX-LBP算子对深度图像进行特征提取, 使用模型的合成深度图像建立训练集和合成测试集, 使用装配体的真实深度图像建立真实测试集;然后建立随机森林分类器, 通过带有颜色标签的训练集训练随机森林分类器, 确定各相关参数;最后, 用随机森林分类器对装配体深度图像进行像素分类, 获取像素预测图像, 通过分析、比对像素预测图像识别装配体中的各零件并监测装配过程。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">2 样本集的建立</h3>
                <div class="p1">
                    <p id="53">建立样本集主要包括合成模型深度图像和采集真实装配体深度图像。在合成模型深度图像时, 本文首先建立三维装配体模型, 用不同的颜色对模型中的不同零件进行标记<citation id="241" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>;然后, 利用OSG三维渲染功能以图形渲染方式生成所需模型的深度图像及对应的标签图像;最后, 选择不同视角下的深度图像及标签图像建立样本集。在采集真实装配体深度图像时, 利用Kinect 2.0采集真实装配体的深度图像, 并对所采集的深度图像进行预处理, 主要包括空洞填充和平滑处理。</p>
                </div>
                <div class="p1">
                    <p id="54">空洞是指原始深度图像中深度值无效的区域。空洞填充是指修复原始深度图像的空洞区域。由于黑洞的灰度值为0, 而白洞的灰度值为205, 受刘继忠等<citation id="242" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>对深度图像修复处理的启发, 本文进行空洞填充, 即:</p>
                </div>
                <div class="area_img" id="55">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JDGC201903003_05500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="57">式中:<i>S</i> (<i>x</i>, <i>y</i>) —经过空洞填充处理后的灰度值;<i>Ω</i>—像素点 (<i>x</i>, <i>y</i>) 的一个方形邻域;<i>M</i><sub><i>Ω</i></sub>—邻域<i>Ω</i>中非0深度值的众数 (频率最高的深度值) ;<i>D</i> (<i>x</i>, <i>y</i>) —原始灰度值;<i>N</i><sub><i>Ω</i></sub> (<i>x</i>, <i>y</i>) —邻域<i>Ω</i>中非205像素点数。</p>
                </div>
                <div class="p1">
                    <p id="58">最后, 本研究用中值滤波对空洞填充后的深度图像进行平滑处理, 用以去除噪音。</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag">3 <i>PX</i>-<i>LBP</i>特征提取算子</h3>
                <h4 class="anchor-tag" id="60" name="60">3.1 经典<i>LBP</i>算子</h4>
                <div class="p1">
                    <p id="61">LBP算子定义:以中心像素点的灰度值为阈值, 将其周围8个像素点的灰度值分别与中心像素点的灰度值进行比较, 若小于中心像素点的灰度值, 则该像素位置被标记为0, 否则标记为1;然后, 将阈值化后的二进制数值转化为十进制数, 即对应位置分别乘以1, 2, 4……2<sup><i>n</i>-1</sup> (<i>n</i>∈<b><i>N</i></b>) , 然后求和作为该中心像素点的LBP特征值, 具体计算如下:</p>
                </div>
                <div class="area_img" id="62">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JDGC201903003_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="64">式中:<i>p</i><sub><i>c</i></sub>—该领域中心像素的灰度值;<i>N</i>—采样点数;<i>p</i><sub><i>i</i></sub> (<i>i</i>=0, …, <i>N</i>-1) —<i>N</i>个采样像素点的灰度值。</p>
                </div>
                <div class="p1">
                    <p id="65">后来, OJALA等又将上述LBP的方形邻域换成圆形邻域, 提出了扩展的LBP算子, 同时提出了旋转不变的LBP算子, 分别如下:</p>
                </div>
                <div class="area_img" id="66">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JDGC201903003_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="68">式中:<i>R</i>—圆形邻域的半径;<i>p</i><sub><i>c</i></sub>—邻域中心像素的灰度值;<i>p</i><sub><i>i</i></sub> (<i>i</i>=0, …, <i>N</i>-1) —<i>N</i>个采样像素点的灰度值;<i>N</i>—采样点数。</p>
                </div>
                <div class="p1">
                    <p id="69">LBP<sub><i>N</i>, <i>R</i></sub>=min (<i>ROR</i> (LBP<sub><i>N</i>, <i>R</i></sub>, <i>i</i>) ) , <i>i</i>=0, 1, …, <i>N</i>-1      (4) </p>
                </div>
                <div class="p1">
                    <p id="70">式中:<i>ROR</i> (<i>x</i>, <i>i</i>) —旋转函数, 表示将<i>x</i>循环右移<i>i</i> (<i>i</i>&lt;<i>p</i>) 位。</p>
                </div>
                <div class="p1">
                    <p id="71">MB-LBP算子把邻域像素点扩展到邻域像素矩形区域, 以矩形区域所有像素点灰度值的平均值作为阈值, 用像素块之间的平均灰度值比较代替传统LBP算子像素点之间灰度值的比较。</p>
                </div>
                <div class="p1">
                    <p id="72">近期, 胡敏等将LBP与CS-LBP相结合, 提出了CS-LSBP, 一定程度上既考虑了各邻域像素点灰度值之间的关系, 又考虑了中心像素点与其邻域像素点灰度值之间的对比关系, 即:</p>
                </div>
                <div class="p1">
                    <p id="73"><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>C</mtext><mtext>S</mtext><mo>-</mo><mtext>L</mtext><mtext>S</mtext><mtext>B</mtext><mtext>Ρ</mtext><msub><mrow></mrow><mrow><mi>Ν</mi><mo>, </mo><mi>R</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo>/</mo><mn>2</mn><mo stretchy="false">) </mo><mo>-</mo><mn>1</mn></mrow></munderover><mrow></mrow></mstyle><mi>X</mi><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>p</mi><msub><mrow></mrow><mi>c</mi></msub><mo>, </mo><mi>p</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mo stretchy="false"> (</mo><mi>Ν</mi><mo>/</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msub><mo stretchy="false">) </mo><mn>2</mn><msup><mrow></mrow><mi>i</mi></msup></mrow></math></mathml>      (5) </p>
                </div>
                <div class="area_img" id="75">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JDGC201903003_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="77">式中:<i>x</i>—采样像素点<i>p</i><sub><i>i</i></sub>所对应的灰度值;<i>y</i>—中心像素点<i>p</i><sub><i>c</i></sub>所对应的灰度值;<i>z</i>—采样像素点<i>p</i><sub><i>i</i>+ (<i>N</i>/2) </sub>所对应的灰度值。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">3.2 <i>PX</i>-<i>LBP</i>算子</h4>
                <div class="p1">
                    <p id="79">上述LBP特征提取算子识别单元多为整幅图像, 即每幅图像产生1组特征值向量, 存在无法识别深度图像内各组成元素的不足, 因此本文引入了像素分类。为使经典LBP算子适用于像素分类的需要, 本文提出了PX-LBP算子, 主要从以下几个方面对经典LBP算子进行了改进:</p>
                </div>
                <div class="p1">
                    <p id="80"> (1) 将同一邻域所产生LBP特征值的数量由原来的1个增加到了<i>K</i>个。增加方法是通过将起始像素点等角度偏移<i>K</i>-1次, 对应的偏移角度<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mtext>π</mtext></mrow><mrow><mi>Ν</mi><mo>*</mo><mi>Κ</mi></mrow></mfrac></mrow></math></mathml> (其中, <i>N</i>—采样点数) 。</p>
                </div>
                <div class="p1">
                    <p id="82">PX-LBP<sup><i>K</i>=<i>k</i></sup>的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="83">PX-LBP<sup><i>K</i>=<i>k</i></sup> (<i>P</i><sub><i>c</i></sub>) ={LBP<sub>1</sub> (<i>P</i><sub><i>c</i></sub>) , LBP<sub>2</sub> (<i>P</i><sub><i>c</i></sub>) , …, LBP<sub><i>k</i>-1</sub> (<i>P</i><sub><i>c</i></sub>) , LBP<sub><i>k</i></sub> (<i>P</i><sub><i>c</i></sub>) }      (7) </p>
                </div>
                <div class="p1">
                    <p id="85">式中:<i>K</i>—同一邻域内, 通过起始点的偏移所产生的LBP特征值的数量;<i>P</i><sub><i>c</i></sub>—中心像素点的灰度值;<b>LBP</b><sub>1</sub> (<b><i>P</i></b><sub><b><i>c</i></b></sub>) , <b>LBP</b><sub>2</sub> (<b><i>P</i></b><sub><b><i>c</i></b></sub>) , …, <b>LBP</b><sub><b><i>k</i></b></sub> (<b><i>P</i></b><sub><b><i>c</i></b></sub>) —同一邻域中不同偏移角度下的LBP特征值向量。</p>
                </div>
                <div class="p1">
                    <p id="86">改进后的LBP算子的起始像素点每多偏移一次, 就会多产生一个LBP特征值, 邻域所选点也会变的更加密集;在一定范围内, 所产生的特征向量对该邻域信息覆盖的全面性也会更高。</p>
                </div>
                <div class="p1">
                    <p id="87"> (2) 将同一中心像素点的圆形邻域数由原来的一个增加到了<i>m</i>个, 即每个中心像素点产生了<i>m</i>个同心圆邻域, 各同心圆邻域之间的半径分别为:<i>R</i><sub>1</sub>=<i>q</i>, <i>R</i><sub>2</sub>=<i>q</i><sup>2</sup>, ……, <i>R</i><sub><i>m</i></sub>=<i>q</i><sup><i>m</i></sup>。另外, 又由于邻域像素点<i>p</i><sub><i>i</i></sub>距离中心像素点<i>p</i><sub><i>c</i></sub>越远, 它对描述<i>p</i><sub><i>c</i></sub>贡献的信息量越小, 因此, 本文对<b>PX-LBP</b><sup><b><i>K</i>=<i>k</i>, <i>M</i>=<i>m</i></b></sup>进行了加权, 加权系数为:<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>R</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo stretchy="false"> (</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="89">PX-LBP<sup><i>K</i>=<i>k</i>, <i>M</i>=<i>m</i></sup>的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext><msup><mrow></mrow><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi><mo>, </mo><mi>Μ</mi><mo>=</mo><mi>m</mi></mrow></msup><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mfrac><mn>1</mn><mi>q</mi></mfrac><mo>*</mo><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext><msubsup><mrow></mrow><mn>1</mn><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mrow></mrow></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mi>q</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>*</mo><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext><msubsup><mrow></mrow><mn>2</mn><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mo>⋯</mo><mo>⋯</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mi>q</mi><msup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow></mfrac><mo>*</mo><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext><msubsup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mrow><mrow><mfrac><mn>1</mn><mrow><mi>q</mi><msup><mrow></mrow><mi>m</mi></msup></mrow></mfrac><mo>*</mo><mrow><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext><msubsup><mrow></mrow><mi>m</mi><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo></mrow></mrow><mo>}</mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">式中:<i>M</i>—同一中心像素点的圆形邻域数;PX-LBP<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi></mrow></msubsup></mrow></math></mathml> (<i>P</i><sub><i>c</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="93">PX-LBP<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi></mrow></msubsup></mrow></math></mathml> (<i>P</i><sub><i>c</i></sub>) , ……, PX-LBP<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mrow><mi>Κ</mi><mo>=</mo><mi>k</mi></mrow></msubsup></mrow></math></mathml> (<i>P</i><sub><i>c</i></sub>) —同一中心像素点下, 不同邻域所产生的各组LBP特征值向量。</p>
                </div>
                <div class="p1">
                    <p id="96">改进后的LBP算子每增加一个邻域, 所产生的LBP特征值向量就多一组, 覆盖的范围也会增大;在一定范围内, 所产生的特征向量对该邻域信息覆盖的全面性也会提高。</p>
                </div>
                <div class="p1">
                    <p id="97"> (3) 与CS-LSBP<sub><i>N</i>, <i>R</i></sub>算子相比, PX-LBP算子除继承CS-LSBP<sub><i>N</i>, <i>R</i></sub>外又加入了LBP<sup>+</sup><sub><i>N</i>, <i>R</i></sub>和LBP<sup>-</sup><sub><i>N</i>, <i>R</i></sub><citation id="243" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 即:</p>
                </div>
                <div class="p1">
                    <p id="98">PX-LBP=LBP<sub><i>K</i></sub>={LBP<sup>+</sup><sub><i>N</i>, <i>R</i></sub>, LBP<sup>-</sup><sub><i>N</i>, <i>R</i></sub>, CS-LSBP<sub><i>N</i>, <i>R</i></sub>}      (9) </p>
                </div>
                <div class="p1">
                    <p id="99">其中, LBP<sup>+</sup><sub><i>N</i>, <i>R</i></sub>和LBP<sup>-</sup><sub><i>N</i>, <i>R</i></sub>的计算公式如下:</p>
                </div>
                <div class="area_img" id="185">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JDGC201903003_18500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="104">另外, 为了增加算法的鲁棒性, 本文对PX-LBP进行了归一化处理, 即:</p>
                </div>
                <div class="p1">
                    <p id="105"><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext></mrow><mrow><mrow><mo>/</mo><mo>/</mo></mrow><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext><mrow><mo>/</mo><mo>/</mo></mrow></mrow></mfrac><mo>→</mo><mtext>Ρ</mtext><mtext>X</mtext><mo>-</mo><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="107">改进后的<i>LBP</i>算子解决了<i>CS</i>-<i>LSBP</i><sub>N, R</sub>算子无法区分相邻像素点与中心像素点是相等还是大于的情况。当<i>LBP</i><sup>+</sup><sub>N, R</sub>=0, <i>LBP</i><sup>-</sup><sub>N, R</sub>=0时, 表示邻域像素点与中心像素点相同;当<i>LBP</i><sup>+</sup><sub>N, R</sub>=1, <i>LBP</i><sup>-</sup><sub>N, R</sub>=0时, 表示邻域像素点大于中心像素点;当<i>LBP</i><sup>+</sup><sub>N, R</sub>=0, <i>LBP</i><sup>-</sup><sub>N, R</sub>=1时, 表示邻域像素点小于中心像素点。</p>
                </div>
                <div class="p1">
                    <p id="108">由式 (7-9) 组合, 可得到一个3*k*m维的特征向量, 也就是特征向量<i>PX</i>-<i>LBP</i><sup>K=k, M=m</sup>。与经典<i>LBP</i>算子相比, <i>PX</i>-<i>LBP</i>算子所得特征向量维数更多, 对中心像素点的邻域特征覆盖也更全面, 为准确的像素分类提供了基础。</p>
                </div>
                <h3 id="109" name="109" class="anchor-tag">4 随机森林分类器</h3>
                <div class="p1">
                    <p id="110">随机森林<citation id="244" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>]</citation>分类器是由多个决策树分类器组成的强分类器, 有效避免了决策树分类器常出现的过拟合现象。本文利用OpenCV机器学习库MLL中的随机森林相关算法类构建了随机森林分类器, 用于对深度图像中各像素点进行分类。过程如下:首先构建随机森林分类器, 将特征提取所得训练集导入分类器中进行训练;然后利用训练好的分类器对待测深度图像的像素点进行分类;最后, 输出分类结果为获取像素预测图提供数据。</p>
                </div>
                <h3 id="111" name="111" class="anchor-tag">5 装配过程的识别与监测</h3>
                <div class="p1">
                    <p id="112">本文方法主要用于装配体零件识别和装配过程监测, 装配体各零件的识别是完成装配监测的基础。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113">5.1 装配体零件的识别</h4>
                <div class="p1">
                    <p id="114">在合成模型深度图像时, 本文用不同的颜色标记不同的零件, 并记录各零件对应的RGB值;然后, 用模型深度图像训练随机森林分类器, 使用训练好的分类器对待测深度图像进行像素分类, 得到对应的像素预测图像;最后, 通过分析像素预测图像内各零件的RGB值并与标记图像的RGB值做比对, 实现对装配体各零件进行识别的目的。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">5.2 装配过程监测</h4>
                <div class="p1">
                    <p id="116">在机械设备装配中, 装配体的位置被固定或存在有限的几种位置状态, 因此可采用像素预测图像比对的方法进行装配过程监测, 具体如下:</p>
                </div>
                <div class="p1">
                    <p id="117">将深度相机固定, 采集正确装配下装配体的深度图像, 并进行特征提取及像素分类, 获取正确装配像素预测图像<i>a</i>。在装配工艺监测中, 采集装配体的深度图像, 同样进行特征提取及像素分类, 以获取对应像素预测图像<i>b</i>。比对像素预测图像<i>b</i>与像素预测图像<i>a</i>每一个像素点, 分别计算出像素预测图像<i>b</i>中各零件相对于像素预测图像<i>a</i>的像素重合率<i>q</i><sub><i>z</i></sub>和像素减少率<i>q</i><sub><i>n</i></sub>, 像素重合率<i>q</i><sub><i>z</i></sub>和像素减少率<i>q</i><sub><i>n</i></sub>的具体定义分别如下:</p>
                </div>
                <div class="p1">
                    <p id="118"><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mi>z</mi></msub><mo>=</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>c</mi></msub></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>z</mi></msub></mrow></mfrac></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="120">式中:<i>n</i><sub><i>c</i></sub>—零件<i>P</i><sub><i>n</i></sub>分别在像素预测图像<i>a</i>和像素预测图像<i>b</i>中坐标重合的像素点数;<i>n</i><sub><i>z</i></sub>—零件<i>P</i><sub><i>n</i></sub>在像素预测图像<i>a</i>中所含总像素点数。</p>
                </div>
                <div class="p1">
                    <p id="121"><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>a</mi></msub><mo>-</mo><mi>n</mi><msub><mrow></mrow><mi>b</mi></msub></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>a</mi></msub></mrow></mfrac></mrow></math></mathml>      (14) </p>
                </div>
                <div class="p1">
                    <p id="123">式中:<i>n</i><sub><i>a</i></sub>, <i>n</i><sub><i>b</i></sub>—零件<i>P</i><sub><i>n</i></sub>分别在像素预测图像<i>a</i>和像素预测图像<i>b</i>中所含像素点数。</p>
                </div>
                <div class="p1">
                    <p id="124">像素重合率<i>q</i><sub><i>z</i></sub>用于判断装配过程是否出错, 像素减少率<i>q</i><sub><i>n</i></sub>用于判断装配过程出错的类型。具体如下:当某零件的<i>q</i><sub><i>z</i></sub>远小于1而<i>q</i><sub><i>n</i></sub>远大于0时, 即该零件的像素点重合率较低且像素点数差距较大, 基本可判断该零件漏装;当某零件<i>q</i><sub><i>z</i></sub>远小于1而<i>q</i><sub><i>n</i></sub>的绝对值接近于0时, 即该零件的像素点重合率较低, 但像素点数变化不大, 可判断该零件错位。</p>
                </div>
                <h3 id="125" name="125" class="anchor-tag">6 实验及结果分析</h3>
                <div class="p1">
                    <p id="126">本文以双级圆柱圆锥减速器为例进行装配监测实验。使用SolidWorks进行了建模, 在Mutigen Creator软件中标记零件颜色。</p>
                </div>
                <div class="p1">
                    <p id="127">各零件被标记颜色的RGB值如图2所示。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JDGC201903003_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 减速器各零件的颜色标记" src="Detail/GetImg?filename=images/JDGC201903003_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 减速器各零件的颜色标记  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JDGC201903003_12800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="131">实验环境配置如下:计算机: Intel® Xeon (R) CPU E5-2630 V4 @ 2.20GHz x 20, 64G内存, UBUNTU 16.04 LTS系统;深度图像获取传感器为Kinect2.0;编译环境: GCC编译器。</p>
                </div>
                <h4 class="anchor-tag" id="132" name="132">6.1 相关参数的确定</h4>
                <div class="p1">
                    <p id="133">由于算法所涉及的参数较多, 本文仅介绍部分关键参数的确定过程, 如:同一邻域起始像素点数<i>K</i>, 同一中心像素点的圆形邻域数<i>m</i>和圆形邻域半径之间的公比<i>q</i>。</p>
                </div>
                <div class="p1">
                    <p id="134">在实验中, 训练集使用290张模型的合成深度图像, 测试集分为两类:10张模型的合成深度图像组成的合成测试集, 10张实物的真实深度图像组成的真实测试集。像素点采集方式:训练集采用横纵坐标均匀采集像素点的方式, 测试集则采用随机选点的方式, 每个深度图像中随机选取2 000个像素点进行特征提取。</p>
                </div>
                <div class="p1">
                    <p id="135">实验数据如图3所示。</p>
                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JDGC201903003_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 部分参数的确定" src="Detail/GetImg?filename=images/JDGC201903003_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 部分参数的确定  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JDGC201903003_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="137">由图3 (a) 可得:随着起始像素点数<i>K</i>的增大, 像素分类准确率先快速增大, 在2后开始增长缓慢, 尽管后面的准确率还在缓慢上升, 但考虑到<i>K</i>值对识别效率影响较大, 因此本文确定同一邻域内起始像素点数<i>K</i>为2。由图3 (b) 可得:随着单个中心像素点圆形邻域个数<i>m</i>的增大, 像素分类准确率先快速上升, 大约在22处后开始浮动, 因此本文确定<i>m</i>值为22。由图3 (c) 可得:随着圆形邻域半径公比<i>q</i>的增大, 像素分类准确率先快速上升, 大约在4.0处后开始浮动, 因此确定<i>m</i>的值为4.0。</p>
                </div>
                <div class="p1">
                    <p id="138">其他主要参数确定如下:邻域<i>Ω</i>的边长确定为2, 邻域采集点数<i>P</i>确定为16, 训练图片张数确定为290, 在随机森林中, 树的最大深度设置为23, 最小样本数设置为5, 树的最大数量设置为50, 准确率设置为0.006 <i>f</i>, 终止判断条件设置为以树的数目或准确率为终止条件。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139">6.2 识别效率</h4>
                <div class="p1">
                    <p id="140">由于装配过程监测有实时性要求, 即算法的识别效率将直接影响整个装配过程的时间和成本, 故本文方法所需时间主要集中于特征提取及像素分类两部分。本文设计了两组实验, 实验中训练集和测试集与6.1完全相同, 记录平均识别时间, 结果如表1所示。</p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit"><b>表1 识别单张图片所用时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="141" border="1"><tr><td><br /></td><td>合成测试集/ms</td><td>真实测试集/ms</td></tr><tr><td><br />特征提取</td><td>18 796</td><td>22 301</td></tr><tr><td><br />像素分类</td><td>298</td><td>277</td></tr><tr><td><br />总时间</td><td>19 094</td><td>22 578</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="142">由表1可得:在深度图像像素点采集方式为逐点采集的情况下, 每张模型深度图像从采集到完成识别大约需要19 s, 每张真实装配体深度图像从采集到完成识别大约需要22 s。单纯从表1中的单张图片识别时间上看, 该方法实时性不高, 但在实际应用中, 对于一些简单的装配体深度图像, 可适当减少像素点的采集量, 从而缩短特征提取时间。</p>
                </div>
                <h4 class="anchor-tag" id="143" name="143">6.3 装配体各零件像素识别</h4>
                <div class="p1">
                    <p id="144">为了获取该方法对装配体各零件的像素识别率, 本文设计了两组实验, 实验中训练集和测试集同6.1完全相同, 实验结果如图4所示 (横坐标的零件标号具体意义可参考图2) 。</p>
                </div>
                <div class="p1">
                    <p id="145">由图4可得:本文对于合成测试集的平均像素识别率可达到98.81%, 而对于真实测试集, 由于Kinect深度图像采集精度的影响, 平均像素识别率为77.51%, 少数小件由于被遮挡、像素较少的缘故像素识别率略低。</p>
                </div>
                <div class="p1">
                    <p id="146">经分类器分类后的深度图像及对应的像素预测图像如图5所示。</p>
                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JDGC201903003_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 分类器对各零件的像素识别率" src="Detail/GetImg?filename=images/JDGC201903003_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 分类器对各零件的像素识别率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JDGC201903003_147.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="148" name="148">6.4 装配过程的监测</h4>
                <div class="p1">
                    <p id="149">本文方法通过对比正确装配体的像素预测图像与待测装配体的像素预测图像, 图像如图6所示。</p>
                </div>
                <div class="area_img" id="150">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JDGC201903003_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 深度图像 (左) 和像素预测图像 (右)" src="Detail/GetImg?filename=images/JDGC201903003_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 深度图像 (左) 和像素预测图像 (右)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JDGC201903003_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="151">计算两者的像素重合率<i>q</i><sub><i>z</i></sub>和像素减少率<i>q</i><sub><i>n</i></sub>, 可以推断待测装配体的装配情况, 下面以图6为例详细分析这一过程。</p>
                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JDGC201903003_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 正确装配像素预测图像 (左) 和待测像素预测图像 (右)" src="Detail/GetImg?filename=images/JDGC201903003_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 正确装配像素预测图像 (左) 和待测像素预测图像 (右)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JDGC201903003_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="153">案例一:待测深度图像为模型的合成深度图, 待测深度图中P<sub>7</sub>件漏装。经特征提取及像素分类后获得像素预测图像如图6 (<i>a</i>) 所示:左为正确装配的像素预测图像, 右为出现P<sub>7</sub>件漏装的像素预测图像。根据式 (13, 14) 分别计算两者的像素重合率q<sub>z</sub>和像素减少率q<sub>n</sub>, 结果如表2所示。</p>
                </div>
                <div class="p1">
                    <p id="154">分析表2的比对数据:首先分析各件的像素重合率, P<sub>7</sub>件重合率较低, 可推断该件可能存在装配错误;然后, 分析各件的像素减少率, P<sub>7</sub>件的像素减少率偏高;因此基本可判断P<sub>7</sub>件出现了漏装现象。</p>
                </div>
                <div class="p1">
                    <p id="155">案例二:待测深度图像为实物的真实深度图, 待测深度图像中P<sub>3</sub>件漏装。经特征提取及像素分类后获得像素预测图像如图6 (<i>b</i>) 所示:左为正确装配的像素预测图像, 右为出现P<sub>3</sub>件漏装的像素预测图像。同上, 分别计算两者的像素重合率q<sub>z</sub>和像素减少率q<sub>n</sub>, 结果如表3所示。</p>
                </div>
                <div class="area_img" id="156">
                    <p class="img_tit"><b>表2</b> P<sub><b>7</b></sub><b>件漏装的比对数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="156" border="1"><tr><td><br />零件标号</td><td>像素重合率q<sub>z</sub>/ (%) </td><td>像素减少率q<sub>n</sub>/ (%) </td></tr><tr><td><br />P<sub>0</sub></td><td>99.74</td><td>0.013</td></tr><tr><td><br />P<sub>1</sub></td><td>100</td><td>-0.006</td></tr><tr><td><br />P<sub>2</sub></td><td>100</td><td>-0.022</td></tr><tr><td><br />P<sub>3</sub></td><td>100</td><td>0</td></tr><tr><td><br />P<sub>4</sub></td><td>100</td><td>-0.005</td></tr><tr><td><br />P<sub>5</sub></td><td>100</td><td>0</td></tr><tr><td><br />P<sub>6</sub></td><td>99.79</td><td>-0.042</td></tr><tr><td><br />P<sub>7</sub></td><td>15.67</td><td>0.843</td></tr><tr><td><br />P<sub>8</sub></td><td>100</td><td>-0.018</td></tr><tr><td><br />P<sub>9</sub></td><td>96.99</td><td>-0.052</td></tr><tr><td><br />P<sub>10</sub></td><td>100</td><td>-0.153</td></tr><tr><td><br />P<sub>11</sub></td><td>100</td><td>-0.008</td></tr><tr><td><br />P<sub>12</sub></td><td>100</td><td>0</td></tr><tr><td><br />P<sub>13</sub></td><td>100</td><td>-0.004</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="157">
                    <p class="img_tit"><b>表3</b> P<sub><b>3</b></sub><b>件漏装的比对数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="157" border="1"><tr><td><br />零件标号</td><td>像素重合率q<sub>z</sub>/ (%) </td><td>像素减少率q<sub>n</sub>/ (%) </td></tr><tr><td><br />P<sub>0</sub></td><td>81.58</td><td>-0.081</td></tr><tr><td><br />P<sub>1</sub></td><td>99.32</td><td>-0.118</td></tr><tr><td><br />P<sub>2</sub></td><td>100</td><td>0.033</td></tr><tr><td><br />P<sub>3</sub></td><td>23.88</td><td>0.758</td></tr><tr><td><br />P<sub>4</sub></td><td>94.63</td><td>0.083</td></tr><tr><td><br />P<sub>5</sub></td><td>80.19</td><td>0.217</td></tr><tr><td><br />P<sub>6</sub></td><td>93.01</td><td>0.079</td></tr><tr><td><br />P<sub>7</sub></td><td>66.90</td><td>0.028</td></tr><tr><td><br />P<sub>8</sub></td><td>98.09</td><td>-0.157</td></tr><tr><td><br />P<sub>9</sub></td><td>98.90</td><td>-0.241</td></tr><tr><td><br />P<sub>10</sub></td><td>99.28</td><td>-0.057</td></tr><tr><td><br />P<sub>11</sub></td><td>99.43</td><td>-0.063</td></tr><tr><td><br />P<sub>12</sub></td><td>73.25</td><td>0.102</td></tr><tr><td><br />P<sub>13</sub></td><td>97.74</td><td>-0.167</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="158">分析表3的比对数据:首先分析各件的像素重合率, P<sub>3</sub>件重合率较低, 可推断该件可能存在装配错误;然后, 分析各件的像素减少率, P<sub>3</sub>件的像素减少率偏高;因此基本可判断P<sub>3</sub>件出现了漏装现象。</p>
                </div>
                <div class="p1">
                    <p id="159">案例三:待测深度图像为模型的合成深度图, 待测深度图像中P<sub>0</sub>件装配错位。经特征提取及像素分类获得像素预测图像如图6 (<i>c</i>) 所示:左为正确装配的像素预测图像, 右为出现P<sub>0</sub>件错位的像素预测图像。同上, 分别计算两者的像素重合率q<sub>z</sub>和像素减少率q<sub>n</sub>, 结果如表4所示。</p>
                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表4</b> P<sub><b>0</b></sub><b>件错位的比对数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td><br />零件标号</td><td>像素重合率q<sub>z</sub>/ (%) </td><td>像素减少率q<sub>n</sub>/ (%) </td></tr><tr><td><br />P<sub>0</sub></td><td>72.21</td><td>0.144 4</td></tr><tr><td><br />P<sub>1</sub></td><td>99.82</td><td>-0.005</td></tr><tr><td><br />P<sub>2</sub></td><td>100</td><td>-0.021</td></tr><tr><td><br />P<sub>3</sub></td><td>99.55</td><td>0</td></tr><tr><td><br />P<sub>4</sub></td><td>100</td><td>0</td></tr><tr><td><br />P<sub>5</sub></td><td>80.19</td><td>0.033</td></tr><tr><td><br />P<sub>6</sub></td><td>99.38</td><td>0.004</td></tr><tr><td><br />P<sub>7</sub></td><td>99.52</td><td>0</td></tr><tr><td><br />P<sub>8</sub></td><td>98.74</td><td>0.010</td></tr><tr><td><br />P<sub>9</sub></td><td>100</td><td>0</td></tr><tr><td><br />P<sub>10</sub></td><td>100</td><td>0.005</td></tr><tr><td><br />P<sub>11</sub></td><td>97.67</td><td>0</td></tr><tr><td><br />P<sub>12</sub></td><td>93.72</td><td>0.099</td></tr><tr><td><br />P<sub>13</sub></td><td>99.61</td><td>0.001</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="161">分析表4的比对数据:首先分析各件的像素重合率, P<sub>0</sub>件重合率相对偏低, 可推断该件可能存在装配错误;然后, 分析各件的像素减少率, P<sub>0</sub>件的像素减少率与其他件相比虽然偏高, 但差距不大;因此可判断P<sub>0</sub>件出现了错位现象。</p>
                </div>
                <h3 id="162" name="162" class="anchor-tag">7 结束语</h3>
                <div class="p1">
                    <p id="163">针对机械产品装配维修诱导中零件和装配体的识别、监测问题, 本文提出了基于PX-LBP和像素分类的装配体零件识别方法;将LBP算法应用于像素分类, 提出了PX-LBP特征提取算子, 使LBP算子更好地与像素分类相融合。</p>
                </div>
                <div class="p1">
                    <p id="164">本文提出的装配体零件识别方法对于模型深度图像的像素识别率达到98.81%, 对于真实装配体深度图像的像素识别率达到77.51%。本文利用像素分类获取像素预测图, 通过对比像素预测图, 完成了装配体各零件的识别及装配过程的监测。</p>
                </div>
                <div class="p1">
                    <p id="165">基于PX-LBP和像素分类的装配体零件识别方法对其他领域的物体识别同样具有一定的参考价值。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="186">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time data-driven monitoring in job-shop floor based on radio frequency identification">

                                <b>[1]</b> CAO W, JIANG P Y, LU P, et al. Real-time data-driven monitoring in job-shop floor based on radio frequency identification [J]. The International Journal of Advanced Manufacturing Technology, 2017, 92 (5-8) :2099-2120.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Research on rapid layout method of RFID devices for aircraft assembly monitoring">

                                <b>[2]</b> YIN C H, WANG W, ZHAO G, et al. Research on rapid layout method of RFID devices for aircraft assembly monitoring [C]. Proceedings of 2016 6th International Conference on Information Technology for Manufacturing Systems, Prague:IEEE, 2016.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDCP201803030&amp;v=MDE5MzNJOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURnVXIvSUx5bklmckc0SDluTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 周铨.一种过盈压装装配工序的过程监测系统[J].机电产品开发与创新, 2018, 31 (3) :84-86.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201708020&amp;v=MTY2OTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGdVci9JUFNuUFpMRzRIOWJNcDQ5SFo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 陈培, 申红明, 张会猛, 等.基于ARM的线缆生产监控系统的设计[J].现代电子技术, 2017, 40 (8) :65-72.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJJ201711011&amp;v=MzI3MTVFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEZ1VyL0lMejdCWkxHNEg5Yk5ybzk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 汪嘉杰, 王磊, 范秀敏, 等.基于视觉的航天电连接器的智能识别与装配引导[J], 计算机集成制造系统, 2017, 23 (11) :2423-2430.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600742093&amp;v=MzE1NTdiSzdIdEROcVk5RlkrOE5ESFU2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJKS0ZzVmFoST1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> OJALA T, PIETIKAINEN M, HARWOOD D. A comparative study of texture measures with classification based on featured distribu-tions [J]. Pattern Recognition, 1996, 29 (1) :51-59.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 OJALA T, PIETIKAINEN M, MEMBER S, et al. Multiresolution gray-scale and rotation invariant texture classification with local binary patterns [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) :971-987.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning multi-scale block local binary patterns for face recognition">

                                <b>[8]</b> LIAO S, ZHU X, LEI Z, et al. Learning multi-scale block local binary patterns for face recognition[J]. Lecture Notes in Computer Science, 2007 (4642) :828-837.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Description of interest regions with local binary patterns">

                                <b>[9]</b> HEIKKILA M, PIETIKAINEN M, SCHMID C. Description of interestrions with local binary patterns[J]. Pattern Recognition, 2009, 42 (3) :425-436.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning Discriminative Local Binary Patterns for Face Recognition">

                                <b>[10]</b> MATURANA D, MERY D, SOTO A. Learning discriminative local binary patterns for face recognition[C]. IEEE international conference on automatic face and gesture recognition, Santa Barbona:IEEE, 2011.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual recognition using local quantized patterns">

                                <b>[11]</b> HUSSAIN S U, NAPOLEON T, JURIE F . Face recognition using local quantized patterns[C]. British machine vision conference, Guildford: IEEE, 2012.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201605018&amp;v=MTM2OTBmTXFvOUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURnVXIvSUx5dlNkTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 冀中, 聂林红.基于抗噪声局部二值模式的纹理图像分类[J].计算机研究与发展, 2016, 53 (5) :1128-1135.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201806010&amp;v=MTkwNDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGdVci9JSVRmU2RyRzRIOW5NcVk5RVpJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 胡敏, 腾文娣, 王晓华, 等.融合局部纹理和形状的人脸表情识别[J].电子与信息学报, 2018, 40 (6) :1338-1344.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time human pose recognition in parts from single depth images">

                                <b>[14]</b> SHOTTON J, FITZGIBBON A, COOK M, et al. Real-time human pose recognition in parts from single depth images[J]. Computer Vision &amp; Pattern Recognition, 2011, 56 (1) :1297-1304.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201803017&amp;v=MDk0MjF5dlNkTEc0SDluTXJJOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURnVXIvSUw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 田野, 项世军.基于LBP和多层DCT的人脸活体检测算法[J].计算机研究展, 2018, 55 (3) :1128-1135.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BZSJ201706008&amp;v=MjQzNDFyQ1VSN3FmWnVabkZpRGdVci9JSnpmWVpMRzRIOWJNcVk5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 李光梅, 苟岩岩, 刘果玲, 等.易拉罐空罐缺陷智能轻测系统的设计[J].包装与食品机械, 2017 (6) :33-36.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201805012&amp;v=MjE2OTlHRnJDVVI3cWZadVpuRmlEZ1VyL0lJaW5SWkxHNEg5bk1xbzlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 刘继忠, 吴文虎, 程乘, 等.基于像素滤波和中值滤波的深度图像修复方法[J].光电子.激光, 2018, 29 (5) :539-544.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Background subtraction based on a combination of texture,color and intensity">

                                <b>[18]</b> XU J, DING X Q, WANG S J, et al. Background subtraction based on combination of texture, color and intensity[J]. ICSP: 2008 9<sup>th</sup> International Conference on Signal Processing, 2008 (1) :1400-1405.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Randomized decision forests">

                                <b>[19]</b> BREIMAN L. Randomized decision forests[J]. Machine Learning, 2001, 45 (1) :5-32.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification and regression trees (CART)">

                                <b>[20]</b> BREIMAN L, FRIEDMAN J H, OLSHEN R A, et al. Classification and regression trees (CART) [J]. Biomtrics, 1984, 40 (3) :358.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JDGC201903003" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDGC201903003&amp;v=MjcxODViRzRIOWpNckk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGdVci9JTHluTWI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM1V1I1M3JjbjUxV3Mxa3FjaFBuRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
