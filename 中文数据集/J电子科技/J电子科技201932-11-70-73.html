

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139165039951250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZKK201911015%26RESULT%3d1%26SIGN%3dDPvS0i6gAnbzEwgVWSQoTXSzDCs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201911015&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201911015&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201911015&amp;v=MjM4NjFyQ1VSN3FmWnVacEZ5M2tXcnpOSVRmQVpiRzRIOWpOcm85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;1 算法模型&lt;/b&gt; "><b>1 算法模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#33" data-title="&lt;b&gt;1.1 一维数据聚类&lt;/b&gt;"><b>1.1 一维数据聚类</b></a></li>
                                                <li><a href="#46" data-title="&lt;b&gt;1.2 高维数据聚类&lt;/b&gt;"><b>1.2 高维数据聚类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="&lt;b&gt;2 试验分析&lt;/b&gt; "><b>2 试验分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="&lt;b&gt;2.1 试验数据集&lt;/b&gt;"><b>2.1 试验数据集</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;2.2&lt;/b&gt; TC-Mean shift&lt;b&gt;聚类算法性能分析&lt;/b&gt;"><b>2.2</b> TC-Mean shift<b>聚类算法性能分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#67" data-title="&lt;b&gt;3 结束语&lt;/b&gt; "><b>3 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="图1 测试数据集图">图1 测试数据集图</a></li>
                                                <li><a href="#61" data-title="图2 测试数据集效果图 ">图2 测试数据集效果图 </a></li>
                                                <li><a href="#63" data-title="图3 不同半径测试一维聚类的准确度变化图">图3 不同半径测试一维聚类的准确度变化图</a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同半径算法准确度表&lt;/b&gt;"><b>表</b>1 <b>不同半径算法准确度表</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 隋心怡,王瑞刚,张鸿翔.一种改进的K-均值聚类算法[J].计算机与数字工程,2018,46(4):682-685.Sui Xinyi,Wang Ruigang,Zhang Hongxiang.An improved K-means clustering algorithm[J].Computer and Digital Engineering,2018,46(4):682-685." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201804011&amp;v=MzA5NDNVUjdxZlp1WnBGeTNrV3J6Tkx6N1lhYkc0SDluTXE0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         隋心怡,王瑞刚,张鸿翔.一种改进的K-均值聚类算法[J].计算机与数字工程,2018,46(4):682-685.Sui Xinyi,Wang Ruigang,Zhang Hongxiang.An improved K-means clustering algorithm[J].Computer and Digital Engineering,2018,46(4):682-685.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 费贤举,李虹,田国忠.基于特征加权理论的数据聚类算法[J].沈阳工业大学学报(自然科学版),2018(1):77-81.Fei Xianju,Li Hong,Tian Guozhong.Data clustering algorithm based on feature weighting theory[J].Journal of Shenyang University of Technology(Natural Science Edition),2018(1):77-81." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201801014&amp;v=MjEzMzE0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrV3J6Tk5qVE1kN0c0SDluTXJvOUVZSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         费贤举,李虹,田国忠.基于特征加权理论的数据聚类算法[J].沈阳工业大学学报(自然科学版),2018(1):77-81.Fei Xianju,Li Hong,Tian Guozhong.Data clustering algorithm based on feature weighting theory[J].Journal of Shenyang University of Technology(Natural Science Edition),2018(1):77-81.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 田帅,陈谊.基于子空间聚类的高维数据可视分析方法综述[J].计算机工程与应用,2018,54(13):25-32.Tian Shuai,Chen Yi.Summary of visual analysis of high-dimensional data based on subspace clustering[J].Computer Engineering and Applications,2018,54 (13):25-32." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813003&amp;v=MjU2NzlOTHo3TWFiRzRIOW5Ockk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5M2tXcno=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         田帅,陈谊.基于子空间聚类的高维数据可视分析方法综述[J].计算机工程与应用,2018,54(13):25-32.Tian Shuai,Chen Yi.Summary of visual analysis of high-dimensional data based on subspace clustering[J].Computer Engineering and Applications,2018,54 (13):25-32.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Liu S,Dan M,Wang B,et al.Visualizing high-dimensional data:advances in the past decade[J].IEEE Transactions on Visualization &amp;amp; Computer Graphics,2017,23(3):1245-1249." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visualizing high-dimensional data: Advan-ces in the past decade">
                                        <b>[4]</b>
                                         Liu S,Dan M,Wang B,et al.Visualizing high-dimensional data:advances in the past decade[J].IEEE Transactions on Visualization &amp;amp; Computer Graphics,2017,23(3):1245-1249.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Ultsch A,L&#246;tsch J.Machine-learned cluster identification in high-dimensional data[J].Journal of Biomedical Informatics,2017,66(5):95-104." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES0BBE8E1C35DE1FC7CBC3CC6D8928FC0B&amp;v=MDU2OThtMnc2MD1OaWZPZmJQS2JLVEUybzQyWis1N2VYMVB2QkZnbUV4K093emsyQm84ZTdyaU5ycnRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0OWh3Yg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Ultsch A,L&#246;tsch J.Machine-learned cluster identification in high-dimensional data[J].Journal of Biomedical Informatics,2017,66(5):95-104.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 徐雪丽,赵学靖.稀疏谱聚类算法在高维数据上的应用[J].中国科学技术大学学报,2017,47(4):311-319.Xu Xueli,Zhao Xuejing.Application of sparse spectral clustering algorithm to high-dimensional data[J].Journal of China University of Science and Technology,2017,47(4):311-319." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKJD201704005&amp;v=MTYzNTlHRnJDVVI3cWZadVpwRnkza1dyek5QeWJCYXJHNEg5Yk1xNDlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         徐雪丽,赵学靖.稀疏谱聚类算法在高维数据上的应用[J].中国科学技术大学学报,2017,47(4):311-319.Xu Xueli,Zhao Xuejing.Application of sparse spectral clustering algorithm to high-dimensional data[J].Journal of China University of Science and Technology,2017,47(4):311-319.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 陈海辉,周向东,施伯乐.基于稀疏正则化的高维数据可视化分析技术[J].计算机应用与软件,2017,34(6):22-26.Chen Haihui,Zhou Xiangdong,Shi Baile.High-dimensional data visualization analysis technology based on sparse regularization[J].Computer Applications and Software,2017,34(6):22-26." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201706005&amp;v=MzEyMTJxWTlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkza1dyek5MelRaWkxHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         陈海辉,周向东,施伯乐.基于稀疏正则化的高维数据可视化分析技术[J].计算机应用与软件,2017,34(6):22-26.Chen Haihui,Zhou Xiangdong,Shi Baile.High-dimensional data visualization analysis technology based on sparse regularization[J].Computer Applications and Software,2017,34(6):22-26.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 唐颖军,黄淑英,杨勇,等.图像高维数据的K-means自适应聚类算法[J].小型微型计算机系统,2016,37(8):1854-1856.Tang Yingjun,Huang Shuying,Yang Yong,et al.K-means adaptive clustering algorithm for high-dimensional image data[J].Minicomputer System,2016,37(8):1854-1856." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201608047&amp;v=MDE3MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5M2tXcnpOUFRYY2RyRzRIOWZNcDQ5Qlk0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         唐颖军,黄淑英,杨勇,等.图像高维数据的K-means自适应聚类算法[J].小型微型计算机系统,2016,37(8):1854-1856.Tang Yingjun,Huang Shuying,Yang Yong,et al.K-means adaptive clustering algorithm for high-dimensional image data[J].Minicomputer System,2016,37(8):1854-1856.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 韩素青,贾茹.基于稀疏约束非负矩阵分解的K-means聚类算法[J].数据采集与处理,2017,32(6):1216-1222.Han Suqing,Jia Ru.K-means clustering algorithm based on sparse constrained nonnegative matrix factorization[J].Data Acquisition and Processing,2017,32(6):1216-1222." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201706017&amp;v=MjA2OTh6Tk5pZklaTEc0SDliTXFZOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrV3I=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         韩素青,贾茹.基于稀疏约束非负矩阵分解的K-means聚类算法[J].数据采集与处理,2017,32(6):1216-1222.Han Suqing,Jia Ru.K-means clustering algorithm based on sparse constrained nonnegative matrix factorization[J].Data Acquisition and Processing,2017,32(6):1216-1222.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 王召月,陈丽芳.基于Mean-shift全局立体匹配方法[J].计算机工程与科学,2017(7):88-92.Wang Zhaoyue,Chen Lifang.Global stereo matching method based on Mean-shift[J].Computer Engineering and Science,2017(7):88-92." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201707020&amp;v=MzIyOThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkza1dyek5MejdCWmJHNEg5Yk1xSTlIWkk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         王召月,陈丽芳.基于Mean-shift全局立体匹配方法[J].计算机工程与科学,2017(7):88-92.Wang Zhaoyue,Chen Lifang.Global stereo matching method based on Mean-shift[J].Computer Engineering and Science,2017(7):88-92.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 刘靖,赵逢禹.高维数据降维技术及研究进展[J].电子科技,2018(3):50-53.Liu Jing,Zhao Fengyu.High-dimensional data dimension reduction technology and research progress[J].Electronic Science and Technology,2018,31(3):50-53." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201803011&amp;v=MzE1NDl1WnBGeTNrV3J6TklUZkFaYkc0SDluTXJJOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         刘靖,赵逢禹.高维数据降维技术及研究进展[J].电子科技,2018(3):50-53.Liu Jing,Zhao Fengyu.High-dimensional data dimension reduction technology and research progress[J].Electronic Science and Technology,2018,31(3):50-53.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Dyer E L,Sankaranarayanan A C,Baraniuk R G.Greedy feature selection for subspace clustering[J].Journal of Machine Learning Research,2013,14(9):2487-2517." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Greedy feature selection for subspace clustering">
                                        <b>[12]</b>
                                         Dyer E L,Sankaranarayanan A C,Baraniuk R G.Greedy feature selection for subspace clustering[J].Journal of Machine Learning Research,2013,14(9):2487-2517.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Modha D S,Spangler W S.Feature weighting in K-means clustering[J].Machine Learning,2003,52(3):217-237." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340677&amp;v=MTUyNzhxZForWnVGaS9sVnI3Qkkxcz1OajdCYXJPNEh0SE5ySXRGWXV3SVkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Modha D S,Spangler W S.Feature weighting in K-means clustering[J].Machine Learning,2003,52(3):217-237.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZKK" target="_blank">电子科技</a>
                2019,32(11),70-73 DOI:10.16180/j.cnki.issn1007-7820.2019.11.014            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种结合贪心选择和特征加权的高维数据聚类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%91%E5%BF%97%E5%8D%8E&amp;code=36080020&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">向志华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B5%E4%BA%9A%E4%B8%BD&amp;code=39042483&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邵亚丽</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E7%90%86%E5%B7%A5%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=1699052&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东理工学院信息技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为解决传统聚类算法无法对高维数据聚类的问题,文中提出了一种结合贪心选择和特征加权的TC-Mean shift高维数据聚类算法。通过对一维数据进行聚类,获得一维数据的聚类结果,再通过加权添加维度聚类,最终获得所有维度数据的聚类,实现对高维数据的聚类。测试结果表明,该算法能够准确地对稀疏的高维数据样本进行聚类,能够处理各种维度的数据,具有良好的实际应用价值。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B4%AA%E5%BF%83%E7%AD%96%E7%95%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贪心策略;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E5%8A%A0%E6%9D%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征加权;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E7%BB%B4%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高维数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Mean%20shift&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Mean shift;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    向志华(1982-),女,讲师。研究方向:机器学习与数据挖掘。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-00-00</p>

                    <p>

                            <b>基金：</b>
                                                        <span>广东省教育厅科技项目(201713720010);</span>
                    </p>
            </div>
                    <h1><b>A High Dimensional Data Clustering Algorithm Combining Greedy Selection and Feature Weighting</b></h1>
                    <h2>
                    <span>XIANG Zhihua</span>
                    <span>SHAO Yali</span>
            </h2>
                    <h2>
                    <span>School of Information Technology,Guangdong Polytechnic College</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to solve the problem that traditional clustering algorithms can not cluster high-dimensional data, a high-dimensional data clustering algorithm combining greedy selection and feature weighting was proposed. By clustering one-dimensional feature data, the clustering results of one-dimensional data were obtained first, and then all dimension data were clustered by adding dimension clustering weights to achieve clustering of high-dimensional data. The results showed that the algorithm can accurately cluster sparse high-dimensional data samples and meet the needs of high-dimensional data clustering processing, and had good practical application value.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=greedy%20strategy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">greedy strategy;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20weighting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature weighting;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=high-dimensional%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">high-dimensional data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Mean%20shift&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Mean shift;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-00-00</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Science and Technology Project of Guangdong Education Department(20171372010);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="29">聚类算法作为数据处理的关键技术之一,广泛应用于人工智能、数据挖掘等领域<citation id="70" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。聚类是指将数据集合,根据相似度聚合成多个簇的过程<citation id="71" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。高维数据聚类是基于高维度的聚类算法,其与传统的聚类算法最主要的区别在于其处理的数据维度高<citation id="72" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。随着大数据时代的到来,数据库规模和复杂性越来越高,如各种类型的商业交易数据、网页数据、基因组数据、词库数据、天文数据及多媒体数据等的维度可以高达成百上千维<citation id="73" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="30">高维数据具有稀疏性,簇类只存在部分属性构成的子空间中,其数据集从全维空间讲根不存在簇类<citation id="78" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。传统的聚类算法如K-Means聚类算法<citation id="79" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>、Mean shift聚类算法<citation id="74" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>等,在高维数据中的效果不理想。当前的高维数据聚类算法主要是通过对数据降维来降低高维数据稀疏性,但降维之后的数据依然存在数据稀疏或数据信息缺失的问题<citation id="75" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。针对高维数据稀疏性的特点,本文借鉴贪心选择<citation id="76" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和特征加权<citation id="77" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>的思想,用传统聚类算法聚类一维数据,通过加权逐步加入其他维度聚类并删减合并,实现高维数据聚类。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>1 算法模型</b></h3>
                <div class="p1">
                    <p id="32">在TC-Mean shift高维数据聚类算法中,借鉴贪心选择的策略,通过传统聚类算法计算每一维度的聚类结果,再通过特征加权对各维度聚类结果进行整理,实现对高维数据的聚类。</p>
                </div>
                <h4 class="anchor-tag" id="33" name="33"><b>1.1 一维数据聚类</b></h4>
                <div class="p1">
                    <p id="34">在传统聚类算法中,Mean shift聚类算法不需要先确定簇的数量,也不易受均值影响。采用Mean shift聚类算法先对任一维数据进行聚类,获得单一维度的聚类结果。</p>
                </div>
                <div class="p1">
                    <p id="35">Mean shift聚类算法的主要思想是通过计算漂移向量朝着密度增大的方向漂移,直至寻找到簇中心点,本文需要对其稍作修改以适应一维数据的聚类。</p>
                </div>
                <div class="p1">
                    <p id="36">在高维数据中任意提取一维数据,一维数据有<i>n</i>个样本点,<i>i</i>=1,…,<i>n</i>。在其中任选一点<i>x</i>,则维的Mean shift向量通过式(1)计算得到</p>
                </div>
                <div class="p1">
                    <p id="37"><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi>r</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>Κ</mi></mfrac><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></msub><mo stretchy="false">(</mo></mstyle><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="38">其中,<i>x</i>表示一维线段的质心,<i>x</i><sub><i>i</i></sub>表示点<i>i</i>,<i>k</i>表示在这<i>n</i>个样本点中有<i>k</i>个点落入<i>S</i><sub><i>k</i></sub>区域中,<i>M</i><sub><i>r</i></sub>表示漂移向量。</p>
                </div>
                <div class="p1">
                    <p id="39"><i>S</i><sub><i>k</i></sub>是一个半径为r的一维线段区域,满足以下关系的<i>y</i>点的集合;<i>r</i>表示半径,如式(2)所示。</p>
                </div>
                <div class="p1">
                    <p id="40"><i>S</i><sub><i>r</i></sub> (<i>x</i>)={<i>y</i>:(<i>x</i>-<i>x</i><sub><i>i</i></sub> )*(<i>x</i>-<i>x</i><sub><i>i</i></sub> )&lt;<i>r</i><sup>2</sup>}       (2)</p>
                </div>
                <div class="p1">
                    <p id="41">一维Mean shift聚类算法与二维Mean shift聚类算法是一样对质心进行更新,如式(3)所示。</p>
                </div>
                <div class="p1">
                    <p id="42"><i>x</i>=<i>x</i>+<i>M</i><sub><i>r</i></sub>      (3)</p>
                </div>
                <div class="p1">
                    <p id="43">修改后的Mean shift聚类算法流程如下:</p>
                </div>
                <div class="p1">
                    <p id="44">(1)选择线段中<i>x</i>为线段中心,做一个长为2<i>r</i>的线段,落在线段内的所有点<i>x</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="45">(2)计算漂移向量,若<i>M</i><sub><i>r</i></sub>&lt;<i>ε</i>,迭代中止,开始下一个未标记点的漂移;若<i>M</i><sub><i>r</i></sub>&gt;<i>ε</i>,则利用式(3)计算新的质心<i>x</i>,返回步骤(1)。其中,<i>ε</i>表示人工设定的最小漂移距离。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46"><b>1.2 高维数据聚类</b></h4>
                <div class="p1">
                    <p id="47">在Mean shift聚类算法对一维数据进行聚类后,通过添加维度数据继续聚类,从而获得良好的聚类效果。多维数据不能简单相加或者相乘,在高维数据中存在相对数据不明显的维度数据,因而采用特征加权的思想对高维数据中各维度聚类结果进行加权聚类。</p>
                </div>
                <div class="p1">
                    <p id="48">算法流程如下:</p>
                </div>
                <div class="p1">
                    <p id="49">(1)一维聚类:对任意一个未聚类的一维数据进行Mean shift聚类,获得聚类结果;</p>
                </div>
                <div class="p1">
                    <p id="50">(2)多维数据聚类结果合并:根据上一步骤所得的聚类结果与之前的聚类结果进行重聚类。TC-Mean shift的重聚类:两次聚类结果分别为<i>m</i>类和<i>n</i>类,则定义重聚类的类别为<i>m</i>×<i>n</i>类。统计每一类的数量,大于阈值则保留类;小于阈值则认为是噪点,根据两个维度权重合并类;</p>
                </div>
                <div class="p1">
                    <p id="51">(3)重复以上两个步骤直至高维数据各个维度均完成聚类。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag"><b>2 试验分析</b></h3>
                <h4 class="anchor-tag" id="53" name="53"><b>2.1 试验数据集</b></h4>
                <div class="p1">
                    <p id="54">为了直观地测试TC-Mean shift聚类算法性能,采用随机高斯分布生成了两种不同的二维数据集,如图1和图2所示。本文将在这两种数据上验证算法是否能够实现可靠聚类及聚类的性能。</p>
                </div>
                <div class="p1">
                    <p id="55">如图1(a)所示,数据集1是一个明显的3簇数据。在第一维的数据明显,第二维的数据高度重合且区分度较低,维度2数据在聚类中拥有价值低。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911015_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 测试数据集图" src="Detail/GetImg?filename=images/DZKK201911015_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 测试数据集图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911015_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1. Test dataset diagram</p>
                                <p class="img_note"> (a)数据集1 (b)数据集2</p>
                                <p class="img_note">(a) Dataset 1(b) Dataset 2</p>

                </div>
                <div class="p1">
                    <p id="57">如图1(b)所示,数据集2是一个明显的3簇数据,在第一维和第二维的数据明显,但任一维度数据单独均不能较好地区分成3簇。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58"><b>2.2</b> TC-Mean shift<b>聚类算法性能分析</b></h4>
                <div class="p1">
                    <p id="59">修改后的Mean shift聚类算法主要对一维数据进行聚类。新算法在数据集1和2中进行测试,测试结果如图2所示。数据集1的聚类分析,在TC-Mean shift聚类算法中对维度1的数据进行聚类,聚类结果如图2(a)所示。聚类算法聚成了3簇,基本实现聚类。但在边界中因为只有一维信息,对边界点的聚类上存在错误。对维度2的数据进行聚类,聚类结果如图2(b)所示。维度2的数据信息含量少且价值低,并未区分不同类别。在对各个维度聚类信息整合后实现的聚类效果如图2(c)所示,算法基本完成聚类。</p>
                </div>
                <div class="p1">
                    <p id="60">数据集2的聚类分析,算法同样对维度1的数据进行聚类,聚类结果如图2(d)所示,聚类算法聚成了2簇。从图中显示,算法在维度1上的聚类效果良好,能够有效将单一维度数据进行聚类。对维度2的数据进行聚类,聚类结果如图2(e)所示。在对各个维度聚类信息整合后实现的聚类效果如图2(f)所示,算法聚类效果良好。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911015_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 测试数据集效果图" src="Detail/GetImg?filename=images/DZKK201911015_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 测试数据集效果图   <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911015_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2. Test dataset rendering </p>
                                <p class="img_note">(a)数据维度1测试效果 (b) 数据维度2测试效果 (c)特征加权测试效果 (d) 数据维度1测试效果 
(e) 数据维度2测试效果 (f) 特征加权测试效果</p>
                                <p class="img_note">(a) Dimension 1 rendering (b) Dimension 2 rendering (c) Feature weighted rendering 
(d) Dimension 1 rendering (e) Dimension 2 rendering (f) Feature weighted rendering</p>

                </div>
                <div class="p1">
                    <p id="62">Mean shift算法是通过多个滑动窗口来更新均值,靠近密度大的区域。分别选择不同的滑动窗口半径对算法进行测试,试验不同的半径对算法的影响。如图3所示,在两个数据集的不同维度下,算法的准确度在半径&lt;0.5时随半径增大而提高。当半径&gt;0.5时,各维度聚类结果趋向于稳定。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911015_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同半径测试一维聚类的准确度变化图" src="Detail/GetImg?filename=images/DZKK201911015_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同半径测试一维聚类的准确度变化图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911015_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3. Accuracy change map of one-dimensional 
clustering with different radii</p>

                </div>
                <div class="p1">
                    <p id="64">其中数据集1维度1的准确度能达到约95%,维度2的准确度最高只有33%。经分析数据集1维度1的数据明显,可以较好的区分3个簇,且聚类结果较好。但维度2数据相互交错难以区分,聚类效果差。数据集2的两个维度准确度最高均为66%。经分析,单一维度信息量缺失,不足以单独完成聚类,66%的准确度是正常现象,表明在单一维度的聚类效果良好。</p>
                </div>
                <div class="area_img" id="65">
                    <p class="img_tit"><b>表</b>1 <b>不同半径算法准确度表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1. Accuracy table of different radius</p>
                    <p class="img_note"></p>
                    <table id="65" border="1"><tr><td><br />半径</td><td>数据集1准确率/%</td><td>数据集2准确率/%</td></tr><tr><td><br />0.5</td><td>70.6</td><td>74.5</td></tr><tr><td><br />0.6</td><td>90.6</td><td>99.3</td></tr><tr><td><br />0.7</td><td>94.5</td><td>90.5</td></tr><tr><td><br />0.8</td><td>94.1</td><td>98.8</td></tr><tr><td><br />0.9</td><td>92.5</td><td>100.0</td></tr><tr><td><br />1.0</td><td>94.6</td><td>100.0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="66">对各个维度特征加权进行计算,测试TC-Mean shift聚类算法的准确度。半径&lt;0.5的单维度聚类效果差,不再做加权聚类分析。如表1所示,对各维度进行加权分析后,数据集1准确度达到了94.6%,数据集2准确度最高可达100%。半径在一定范围内,对算法准确度影响小。</p>
                </div>
                <h3 id="67" name="67" class="anchor-tag"><b>3 结束语</b></h3>
                <div class="p1">
                    <p id="68">本文结合贪心选择和特征加权的模糊聚类算法,提出了TC-Mean shift高维数据聚类算法。该算法通过对单维度数据进行聚类,取得单维度的聚类结果,再通过特征加权适应高维数据,使其具备了对高维数据聚类的能力。结果表明,在应对稀疏的高维数据,该算法能够以较高的准确度实现对数据样本的聚类分析,且该算法可应对各种维度的数据。然而算法在应对复杂交错的数据上仍存有一定不足,将在后续工作中做出改进。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201804011&amp;v=MTYyMDRhYkc0SDluTXE0OUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrV3J6Tkx6N1k=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 隋心怡,王瑞刚,张鸿翔.一种改进的K-均值聚类算法[J].计算机与数字工程,2018,46(4):682-685.Sui Xinyi,Wang Ruigang,Zhang Hongxiang.An improved K-means clustering algorithm[J].Computer and Digital Engineering,2018,46(4):682-685.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201801014&amp;v=MjUwMzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkza1dyek5OalRNZDdHNEg5bk1ybzlFWUk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 费贤举,李虹,田国忠.基于特征加权理论的数据聚类算法[J].沈阳工业大学学报(自然科学版),2018(1):77-81.Fei Xianju,Li Hong,Tian Guozhong.Data clustering algorithm based on feature weighting theory[J].Journal of Shenyang University of Technology(Natural Science Edition),2018(1):77-81.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201813003&amp;v=MTU3ODBMejdNYWJHNEg5bk5ySTlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkza1dyek4=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 田帅,陈谊.基于子空间聚类的高维数据可视分析方法综述[J].计算机工程与应用,2018,54(13):25-32.Tian Shuai,Chen Yi.Summary of visual analysis of high-dimensional data based on subspace clustering[J].Computer Engineering and Applications,2018,54 (13):25-32.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visualizing high-dimensional data: Advan-ces in the past decade">

                                <b>[4]</b> Liu S,Dan M,Wang B,et al.Visualizing high-dimensional data:advances in the past decade[J].IEEE Transactions on Visualization &amp; Computer Graphics,2017,23(3):1245-1249.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES0BBE8E1C35DE1FC7CBC3CC6D8928FC0B&amp;v=MTU4MDdCckxVMDV0OWh3Ym0ydzYwPU5pZk9mYlBLYktURTJvNDJaKzU3ZVgxUHZCRmdtRXgrT3d6azJCbzhlN3JpTnJydENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Ultsch A,Lötsch J.Machine-learned cluster identification in high-dimensional data[J].Journal of Biomedical Informatics,2017,66(5):95-104.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKJD201704005&amp;v=MTA2MzFNcTQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5M2tXcnpOUHliQmFyRzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 徐雪丽,赵学靖.稀疏谱聚类算法在高维数据上的应用[J].中国科学技术大学学报,2017,47(4):311-319.Xu Xueli,Zhao Xuejing.Application of sparse spectral clustering algorithm to high-dimensional data[J].Journal of China University of Science and Technology,2017,47(4):311-319.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201706005&amp;v=Mjc5MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrV3J6Tkx6VFpaTEc0SDliTXFZOUZZWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 陈海辉,周向东,施伯乐.基于稀疏正则化的高维数据可视化分析技术[J].计算机应用与软件,2017,34(6):22-26.Chen Haihui,Zhou Xiangdong,Shi Baile.High-dimensional data visualization analysis technology based on sparse regularization[J].Computer Applications and Software,2017,34(6):22-26.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201608047&amp;v=Mjc2OTE0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrV3J6TlBUWGNkckc0SDlmTXA0OUJZNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 唐颖军,黄淑英,杨勇,等.图像高维数据的K-means自适应聚类算法[J].小型微型计算机系统,2016,37(8):1854-1856.Tang Yingjun,Huang Shuying,Yang Yong,et al.K-means adaptive clustering algorithm for high-dimensional image data[J].Minicomputer System,2016,37(8):1854-1856.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJCJ201706017&amp;v=MTM5MTFwRnkza1dyek5OaWZJWkxHNEg5Yk1xWTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 韩素青,贾茹.基于稀疏约束非负矩阵分解的K-means聚类算法[J].数据采集与处理,2017,32(6):1216-1222.Han Suqing,Jia Ru.K-means clustering algorithm based on sparse constrained nonnegative matrix factorization[J].Data Acquisition and Processing,2017,32(6):1216-1222.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201707020&amp;v=MjEzNzQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5M2tXcnpOTHo3QlpiRzRIOWJNcUk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 王召月,陈丽芳.基于Mean-shift全局立体匹配方法[J].计算机工程与科学,2017(7):88-92.Wang Zhaoyue,Chen Lifang.Global stereo matching method based on Mean-shift[J].Computer Engineering and Science,2017(7):88-92.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201803011&amp;v=MjEyOTh6TklUZkFaYkc0SDluTXJJOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrV3I=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 刘靖,赵逢禹.高维数据降维技术及研究进展[J].电子科技,2018(3):50-53.Liu Jing,Zhao Fengyu.High-dimensional data dimension reduction technology and research progress[J].Electronic Science and Technology,2018,31(3):50-53.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Greedy feature selection for subspace clustering">

                                <b>[12]</b> Dyer E L,Sankaranarayanan A C,Baraniuk R G.Greedy feature selection for subspace clustering[J].Journal of Machine Learning Research,2013,14(9):2487-2517.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340677&amp;v=MTIyOTd0SE5ySXRGWXV3SVkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1RmkvbFZyN0JJMXM9Tmo3QmFyTzRI&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Modha D S,Spangler W S.Feature weighting in K-means clustering[J].Machine Learning,2003,52(3):217-237.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZKK201911015" />
        <input id="dpi" type="hidden" value="299" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201911015&amp;v=MjM4NjFyQ1VSN3FmWnVacEZ5M2tXcnpOSVRmQVpiRzRIOWpOcm85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

