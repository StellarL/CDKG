

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139861279638750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZKK201905010%26RESULT%3d1%26SIGN%3d5zpCO7ZhUHyUluChyYx084v%252f4Mo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201905010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201905010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201905010&amp;v=MDA1MDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURtV3JyQUlUZkFaYkc0SDlqTXFvOUVaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#38" data-title="&lt;b&gt;1&lt;/b&gt; 相关研究 "><b>1</b> 相关研究</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;2&lt;/b&gt; 视频关键帧及其特征提取 "><b>2</b> 视频关键帧及其特征提取</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="&lt;b&gt;2.1&lt;/b&gt; 灰度序列特征"><b>2.1</b> 灰度序列特征</a></li>
                                                <li><a href="#52" data-title="&lt;b&gt;2.2&lt;/b&gt; CCV特征"><b>2.2</b> CCV特征</a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;2.3&lt;/b&gt; SIFT局部特征"><b>2.3</b> SIFT局部特征</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;3&lt;/b&gt; 检索匹配 "><b>3</b> 检索匹配</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="&lt;b&gt;3.1&lt;/b&gt; 多特征融合"><b>3.1</b> 多特征融合</a></li>
                                                <li><a href="#68" data-title="&lt;b&gt;3.2&lt;/b&gt; 检索匹配"><b>3.2</b> 检索匹配</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#77" data-title="&lt;b&gt;4&lt;/b&gt; 实验数据与分析 "><b>4</b> 实验数据与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="&lt;b&gt;4.&lt;/b&gt;1 实验结果与分析"><b>4.</b>1 实验结果与分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="&lt;b&gt;5&lt;/b&gt; 结束语 "><b>5</b> 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="图1 视频检测流程图">图1 视频检测流程图</a></li>
                                                <li><a href="#45" data-title="图2 灰度序列特征图">图2 灰度序列特征图</a></li>
                                                <li><a href="#50" data-title="图3 灰度序列特征流程图">图3 灰度序列特征流程图</a></li>
                                                <li><a href="#57" data-title="图4 CCV特征流程图">图4 CCV特征流程图</a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;图像块的分布关系表&lt;/b&gt;"><b>表</b>1 <b>图像块的分布关系表</b></a></li>
                                                <li><a href="#70" data-title="图5 基于滑动窗口的视频检索图">图5 基于滑动窗口的视频检索图</a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;表&lt;/b&gt;2 MAP&lt;b&gt;值和时间的比较&lt;/b&gt;"><b>表</b>2 MAP<b>值和时间的比较</b></a></li>
                                                <li><a href="#83" data-title="图6 24个查询视频平均PR曲线">图6 24个查询视频平均PR曲线</a></li>
                                                <li><a href="#86" data-title="图7 SIG_CH方法">图7 SIG_CH方法</a></li>
                                                <li><a href="#87" data-title="图8 本文方法">图8 本文方法</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" Kashino K, Kurozumi T, Murase H.A quick search method for audio and video signals based on histogram pruning[J].IEEE Transactions on Multimedia, 2003, 5 (3) :348-357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A quick search method for audio and video signals based on histogram pruning">
                                        <b>[1]</b>
                                         Kashino K, Kurozumi T, Murase H.A quick search method for audio and video signals based on histogram pruning[J].IEEE Transactions on Multimedia, 2003, 5 (3) :348-357.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" Ozkan S, Esen E, Akar G B.Enhanced spatio-temporal video copy detection by combining trajectory and spatial consistency[C].Paris:IEEE International Conference on Image Processing, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhanced spatio-temporal video copy detection by combining trajectory and spatial consistency">
                                        <b>[2]</b>
                                         Ozkan S, Esen E, Akar G B.Enhanced spatio-temporal video copy detection by combining trajectory and spatial consistency[C].Paris:IEEE International Conference on Image Processing, 2014.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" Ren D, Zhuo L, Long H, et al.MPEG-2 video copy detection method based on sparse representation of spatial and temporal features[C].Taipei:IEEE Second International Conference on Multimedia Big Data, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MPEG-2 video copy detection method based on sparse representation of spatial and temporal features">
                                        <b>[3]</b>
                                         Ren D, Zhuo L, Long H, et al.MPEG-2 video copy detection method based on sparse representation of spatial and temporal features[C].Taipei:IEEE Second International Conference on Multimedia Big Data, 2016.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" 黄少年, 赵跃龙, 邱建雄.一种基于镜头的视频场景检测方法[J].计算机工程与应用, 2006, 42 (19) :170-173.Huang Shaonian, Zhao Yuelong, Qiu Jianxiong.A method of video scence detection based on shots[J].Computer Engineering and Applications, 2006, 42 (19) :170-173." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG200619052&amp;v=MDU4MDZxZlp1Wm9GaURtV3JyQUx6N01hYkc0SHRmTnBvOUFab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         黄少年, 赵跃龙, 邱建雄.一种基于镜头的视频场景检测方法[J].计算机工程与应用, 2006, 42 (19) :170-173.Huang Shaonian, Zhao Yuelong, Qiu Jianxiong.A method of video scence detection based on shots[J].Computer Engineering and Applications, 2006, 42 (19) :170-173.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" Lin H D, Qiang Y U.Design and Implementation of an network video surveillance system based on H264[J].Journal of Xihua University, 2014, 171 (6) :1029-1045." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCGX201402006&amp;v=MjQ0ODVyRzRIOVhNclk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG1XcnJBTmk3TWQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Lin H D, Qiang Y U.Design and Implementation of an network video surveillance system based on H264[J].Journal of Xihua University, 2014, 171 (6) :1029-1045.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" Shiue Y C, Lo S H, Tian Y C, et al.The study of salient object and BoF with SIFT for image retrieval[M].Bangkok:Frontier Computing, 2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The study of salient object and BoF with SIFT for image retrieval">
                                        <b>[6]</b>
                                         Shiue Y C, Lo S H, Tian Y C, et al.The study of salient object and BoF with SIFT for image retrieval[M].Bangkok:Frontier Computing, 2018.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" Wu X, Hauptmann A G, Ngo C W.Practical elimination of near-duplicates from web video search[C].Augsburg:ACM International Conference on Multimedia, 2007." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Practical elimination of near- duplicates from web video search">
                                        <b>[7]</b>
                                         Wu X, Hauptmann A G, Ngo C W.Practical elimination of near-duplicates from web video search[C].Augsburg:ACM International Conference on Multimedia, 2007.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" Chou C L, Chen H T, Lee S Y.Pattern-based near-duplicate video retrieval and localization on web-scale videos[J].IEEE Transactions on Multimedia, 2015, 17 (3) :382-395." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pattern-based near-duplicate video retrieval and localization on Web-scale videos">
                                        <b>[8]</b>
                                         Chou C L, Chen H T, Lee S Y.Pattern-based near-duplicate video retrieval and localization on web-scale videos[J].IEEE Transactions on Multimedia, 2015, 17 (3) :382-395.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" 王盼盼, 李玉惠.基于特征融合和L-M算法的车辆重识别方法[J].电子科技, 2018, 31 (4) :12-15.Wang Panpan, Li Yuhui.Vehicle re-identification method based on feature fusion and L-M algorithm[J].Electronic Science and Technology, 2018, 31 (4) :12-15." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201804005&amp;v=MTIyNzE0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURtV3JyQUlUZkFaYkc0SDluTXE0OUZZWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         王盼盼, 李玉惠.基于特征融合和L-M算法的车辆重识别方法[J].电子科技, 2018, 31 (4) :12-15.Wang Panpan, Li Yuhui.Vehicle re-identification method based on feature fusion and L-M algorithm[J].Electronic Science and Technology, 2018, 31 (4) :12-15.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" 韩永刚, 赵巍凯.基于单目视觉的行人检测研究[J].电子科技, 2014, 27 (8) :22-25.Han Yonggang, Zhao Weikai.Algorithm for pedestrian detection based on monocular vision[J].Electronic Science and Technology, 2014, 27 (8) :22-25." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201408008&amp;v=MTU0MDl1Wm9GaURtV3JyQUlUZkFaYkc0SDlYTXA0OUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         韩永刚, 赵巍凯.基于单目视觉的行人检测研究[J].电子科技, 2014, 27 (8) :22-25.Han Yonggang, Zhao Weikai.Algorithm for pedestrian detection based on monocular vision[J].Electronic Science and Technology, 2014, 27 (8) :22-25.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" 陈进, 陈思, 王一帆, 等.基于ARM的联合收割机远程视频监视系统[J].电子科技, 2016, 29 (2) :85-88.Chen Jin, Chen Si, Wang Yifan, et al.ARM9-based remote video monitoring system for combine harvester[J], Electronic Science and Technology, 2016, 29 (2) :85-88." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201602024&amp;v=MjU1OTMzenFxQnRHRnJDVVI3cWZadVpvRmlEbVdyckFJVGZBWmJHNEg5Zk1yWTlIWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         陈进, 陈思, 王一帆, 等.基于ARM的联合收割机远程视频监视系统[J].电子科技, 2016, 29 (2) :85-88.Chen Jin, Chen Si, Wang Yifan, et al.ARM9-based remote video monitoring system for combine harvester[J], Electronic Science and Technology, 2016, 29 (2) :85-88.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" 李阳.局部时空特征及部件的视频人体动作识别方法研究[D].重庆:重庆大学, 2015.Li Yang.Research based on local spatiotemporal features and parts for human action recognition from videos[D].Chongqing:Chongqing University, 2015." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1015971009.nh&amp;v=MzE1MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG1XcnJBVkYyNkc3cS9IOUhNcHBFYlBJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         李阳.局部时空特征及部件的视频人体动作识别方法研究[D].重庆:重庆大学, 2015.Li Yang.Research based on local spatiotemporal features and parts for human action recognition from videos[D].Chongqing:Chongqing University, 2015.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" 李龙.视频中人体行为识别的研究[D].南京:南京邮电大学, 2016.Li Long.A study on human action recognition in video[D].Nanjing:Nanjing University of Posts and Telecommunications, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016294156.nh&amp;v=MjgwNDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURtV3JyQVZGMjZHTEd4R3RESnFaRWJQSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         李龙.视频中人体行为识别的研究[D].南京:南京邮电大学, 2016.Li Long.A study on human action recognition in video[D].Nanjing:Nanjing University of Posts and Telecommunications, 2016.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" Gu X, Zhang D, Zhang Y, et al.A video copy detection algorithm combining local feature&#39;s robustness and global feature&#39;s speed[C].Vancouver:IEEE International Conference on Acoustics, Speech and Signal Processing, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A video copy detection algorithm combining local feature&amp;#39;&amp;#39;s robustness and global feature&amp;#39;&amp;#39;s speed">
                                        <b>[14]</b>
                                         Gu X, Zhang D, Zhang Y, et al.A video copy detection algorithm combining local feature&#39;s robustness and global feature&#39;s speed[C].Vancouver:IEEE International Conference on Acoustics, Speech and Signal Processing, 2013.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" Jiang Y G, Jiang Y, Wang J.VCDB:A Large-scale database for partial copy detection in videos[M].Amsterdam:Springer International Publishing, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VCDB:A Large-scale database for partial copy detection in videos">
                                        <b>[15]</b>
                                         Jiang Y G, Jiang Y, Wang J.VCDB:A Large-scale database for partial copy detection in videos[M].Amsterdam:Springer International Publishing, 2014.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" Mohamed S T.Shots temporal prediction rules for high-dimensional data of semantic video retrieval[J].American Journal of Applied Sciences, 2018, 15 (1) :60-69." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Shots temporal prediction rules for high-dimensional data of semantic video retrieval">
                                        <b>[16]</b>
                                         Mohamed S T.Shots temporal prediction rules for high-dimensional data of semantic video retrieval[J].American Journal of Applied Sciences, 2018, 15 (1) :60-69.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" 张护望, 林浒, 王诗宇, 等.一种基于改进SIFT算法的轨道板图像匹配方法[J].组合机床与自动化加工技术, 2018 (3) :1-3.Zhang Huwang, Lin hu, Wang Shiyu, et al.Method of rail board image matching based on improved SIFT algorithm[J].Modular Machine Tool &amp;amp; Automatic Manufacturing Technique, 2018 (3) :1-3." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHJC201803001&amp;v=MDEwODViRzRIOW5Nckk5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG1XcnJBUHlYQmI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         张护望, 林浒, 王诗宇, 等.一种基于改进SIFT算法的轨道板图像匹配方法[J].组合机床与自动化加工技术, 2018 (3) :1-3.Zhang Huwang, Lin hu, Wang Shiyu, et al.Method of rail board image matching based on improved SIFT algorithm[J].Modular Machine Tool &amp;amp; Automatic Manufacturing Technique, 2018 (3) :1-3.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZKK" target="_blank">电子科技</a>
                2019,32(05),44-48+54 DOI:10.16180/j.cnki.issn1007-7820.2019.05.009            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于多特征融合的视频检索算法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">侯严明</a>
                                <a href="javascript:;">李菲菲</a>
                                <a href="javascript:;">陈虬</a>
                </h2>
                    <h2>

                    <span>上海理工大学光电信息与计算机工程学院</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着视频等多媒体数据呈指数式迅猛增长, 高效快速的视频检索算法引起越来越多的重视。传统的图像特征如颜色直方图以及尺度不变特征变换等对视频拷贝检测中检索速度以及检测精度等问题无法达到很好的效果, 因此文中提出一种多特征融合的视频检索方法。该方法利用前后两帧的时空特征进行基于滑动窗口的时间对齐算法, 以达到减少检索的范围和提高检索速度的目的。该算法对关键帧进行灰度序列特征、颜色相关图特征以及SIFT局部特征提取, 然后融合全局特征和局部特征两者的优势, 从而提高检测精度。实验结果表明, 该方法可达到较好的视频检索精度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E9%A2%91%E6%A3%80%E7%B4%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视频检索;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">滑动窗口;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多特征融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%9C%E8%89%B2%E8%87%AA%E7%9B%B8%E7%9B%B8%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜色自相相图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E7%A9%BA%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时空特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E9%94%AE%E5%B8%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关键帧;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    侯严明 (1993-) , 男, 硕士研究生。研究方向:计算机视觉与模式识别。;
                                </span>
                                <span>
                                    李菲菲 (1970-) , 女, 博士, 教授。研究方向:多媒体信息处理、图像处理与模式识别、信息检索等。;
                                </span>
                                <span>
                                    陈虬 (1972-) , 男, 博士, 教授。研究方向:图像处理与模式识别、计算机视觉、信息检索等。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-17</p>

                    <p>

                            <b>基金：</b>
                                                        <span>上海市高校特聘教授 (东方学者) 岗位计划 (ES2015XX);</span>
                    </p>
            </div>
                    <h1><b>Video Retrieval Algorithm Based on Multiple Feature Fusion</b></h1>
                    <h2>
                    <span>HOU Yanming</span>
                    <span>LI Feifei</span>
                    <span>CHEN Qiu</span>
            </h2>
                    <h2>
                    <span>School of Optical Electrical and Computer Engineering, University of Shanghai for Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to the exponential growth of video data on the World Wide Web, efficient and fast video retrieval algorithm has attracted a lot of attentions. Because the traditional video image features, such as color histogram and scale invariant feature transform could not obtain promising results on the retrieval speed and detection precision in video copy detection, a video retrieval algorithm using multiple feature fusion was proposed in this paper. Using the temporal and spatial characteristics of the two frames before and after, the time alignment algorithm based on sliding window was applied to reduce the retrieval range and improve retrieval speed. In order to improve the detection precision, this algorithm performed the global feature, the color correlation graph, and the local feature extraction of the SIFT, and then combined the advantages of both global and local features. Experimental results showed that the proposed method could achieve better performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=video%20retrieval&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">video retrieval;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sliding%20window&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sliding window;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=multiple%20feature%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">multiple feature fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20correlogram&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color correlogram;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=temporal%20and%20spatial%20characteristics&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">temporal and spatial characteristics;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=key%20frame&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">key frame;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-05-17</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>The Program for Professor of Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher Learning (ES2015XX);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="36">当今社会, 人们生活中的方方面面都和电子产品有很深的联系。同时, 越来越多的信息通过图像和视频来进行传递。虽然信息全球化的不断扩展给我们带了很多方便, 但是也因为信息大爆炸使得处理这些大数据的时间不足。而由于移动互联网时代快速发展, 在很多视频分享平台中出现了大量的重复或者近似的视频, 不仅影响了用户体验, 而且侵犯了原创视频的知识产权。因此, 如何在保证高检测精度的前提下实现快速视频检索成为了一项重要的研究课题。</p>
                </div>
                <div class="p1">
                    <p id="37">在实际生活中, 视频相似性变换具有多样性与不确定性。但这些视频主要由原始视频经过光学变换或时间变换等方式转换产生。视频变换方式包括编码格式、比特率、颜色亮度、插入LOGO、添加字幕以及添加不相关帧等等变化。许多方法对各种变换都有一定的效果, 但不同变化之间存在着一定差异。据此, 本文提出一种基于多特征融合的视频检索方法。该算法中的多特征分别是OM (Ordinal Measure) 特征、CCV (Color Correlogram Vector) 特征以及SIFT (Scale Invariant Feature Transform) 局部特征, 可使检索系统在灰度空间、颜色还有局部特征上有很好的抗性, 从而在保证检索精度的同时实现快速检索的目的。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag"><b>1</b> 相关研究</h3>
                <div class="p1">
                    <p id="39">基于内容的视频检索技术的基本框架主要包含提取关键帧、特征提取、建立索引、特征匹配和时间对齐等。如图1所示, 本文在多特征融合检索中对多特征融合技术采用后期融合技术, 在检索技术中采用前后两帧同时检索, 以便充分利用视频中时空信息。文中同时采用窗口跳跃技术<citation id="90" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>来提高检索速度。而对于局部特征SIFT, 在采用基于视觉词袋 (Bag of Words) <citation id="91" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>的方法通过K-means聚类的方法统计视频关键帧库中出现所有的特征, 将相邻的特征归为一类, 并将聚类中心作为词袋。利用视觉词袋量化SIFT特征, 采用词频来表示图像。除此之外, 还有一些简单降维的方法, 即直接从头到尾提取特征向量中的每间隔10位的平均值组成新的特征向量, 以便达到加快检索速度的效果。</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 视频检测流程图" src="Detail/GetImg?filename=images/DZKK201905010_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 视频检测流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1. Flow chart of video retrieval</p>

                </div>
                <h3 id="41" name="41" class="anchor-tag"><b>2</b> 视频关键帧及其特征提取</h3>
                <div class="p1">
                    <p id="42">视频是由一系列的静态图像序列组成的, 按照图像序列包含的内容层次来划分, 从低到高依次是帧 (Frame) 、镜头 (Shot) 、场景 (Scene) 和视频 (Video) 。提取视频关键帧技术一般是基于镜头的关键帧提取方法, 而无论是利用视频帧图像的信息熵<citation id="92" type="reference"><link href="6" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>还是直方图<citation id="93" type="reference"><link href="8" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 在视频帧提取上都会出模糊镜头边界和视频镜头过短引起视频内容的缺失。于是本文提出利用FFMPEG<citation id="94" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>中的库函数来提取视频流中的关键帧的方法。视频是基于MPEG2规则编码的, 其中视频帧的模式是IBBPBBPBBPBB, 其中I帧就是关键帧, 大约每400 ms出现一次关键帧。此方法不仅可以更好地保留视频信息, 还提高了视频提取关键帧的速度。</p>
                </div>
                <h4 class="anchor-tag" id="43" name="43"><b>2.1</b> 灰度序列特征</h4>
                <div class="p1">
                    <p id="44">灰度序列特征 (OM) 是一种具有排序性质的全局特征。在其提取过程中首先将视频帧图像分割成个<i>n</i>×<i>n</i>相等的图像块, 文中<i>n</i>取3, 如图2 (a) 所示。然后如图2 (b) 所示依次计算各图像块的灰度平均值。紧接着如图2 (c) 所示将每块命名为G<sub><i>ij</i></sub>的序号, <i>i</i>代表每行的序号, <i>j</i>代表每一列的序列。</p>
                </div>
                <div class="area_img" id="45">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 灰度序列特征图" src="Detail/GetImg?filename=images/DZKK201905010_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 灰度序列特征图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_045.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2. Ordinal measure feature pattern</p>

                </div>
                <div class="p1">
                    <p id="46">如果只是采用依次按照每列从头到尾排列组成的方式提取特征向量, 会减少图像信息从而导致检索精度减小。于是本文在空间灰度序列上做了一些改善。首先计算周围各个图像块中像素平均值<i>G</i><sub><i>ij</i></sub>, 然后以<i>G</i><sub>22</sub>为中心进行比较, 图像的二值序列<b><i>B</i></b>的计算过程如下列计算式所述</p>
                </div>
                <div class="area_img" id="47">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201905010_04700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="49">最后, 按照图3 (b) 和2 (c) 所示将图像块分别从<i>G</i><sub>22</sub>和<i>G</i><sub>11</sub>开始, 重新排序得到8位的二值特征序列<b><i>B</i></b>为00100000, 如图3 (d) 所示。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 灰度序列特征流程图" src="Detail/GetImg?filename=images/DZKK201905010_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 灰度序列特征流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3. Ordinal measure feature flow chart</p>

                </div>
                <div class="p1">
                    <p id="51">为了充分利用视频中的时空信息, 在提取本帧图像空间灰度特征向量的基础上, OM特征加上了之后连续两帧图像空间灰度特征的前4位, 即图3 (c) 的图像块向量。因为一般图像的主要信息集中在图像的中间位置, 所以在时间信息上提取图3 (c) 中的特征向量不仅减少了特征向量多余的维度, 而且保留更多特征的信息量。由此可以得到灰度序列特征是16维。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52"><b>2.2</b> CCV特征</h4>
                <div class="p1">
                    <p id="53">颜色相关图 (Color Correlogram) 是图像颜色分布的另外一种表达式。这种特征不但刻画了某一种颜色的像素数量占整个图像的比例, 还反映了不同颜色对之间的空间相关性。但是考虑到任何颜色之间的相关性, 颜色相关图会变得非常的庞大和复杂。于是文中在颜色相关图的基础上提出一点改善的方法。</p>
                </div>
                <div class="p1">
                    <p id="54">首先将RGB图像平均分割成<i>n</i>×<i>n</i>个相等的图像块, 如图4所示 (<i>n</i>=4) , 然后分别计算每个像素块中3个通道的平均值, 即<i>C</i><sub><i>r</i></sub> (红色) , <i>C</i><sub><i>g</i></sub> (绿色) , <i>C</i><sub><i>b</i></sub> (蓝色) 。</p>
                </div>
                <div class="p1">
                    <p id="55">然后根据表1所示将图像块由图4 (a) 变成图4 (b) 。</p>
                </div>
                <div class="p1">
                    <p id="56">最后根据四通道连接方式计算相同数值分布个数, 选取个数最大值的图像区域块, 获得局部相同数值的最大数量, 之后按图像块中数值从大到小排列得到特征向量<b><i>T</i></b>, 如图4 (c) 所示。</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 CCV特征流程图" src="Detail/GetImg?filename=images/DZKK201905010_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 CCV特征流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4. CCV feature flow chart</p>

                </div>
                <div class="area_img" id="58">
                    <p class="img_tit"><b>表</b>1 <b>图像块的分布关系表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1. Distribution relation table of image block</p>
                    <p class="img_note"></p>
                    <table id="58" border="1"><tr><td><br />图像块</td><td>三通道关系</td></tr><tr><td><br />1</td><td><i>C</i><sub><i>r</i></sub>&gt;<i>C</i><sub><i>g</i></sub>&gt;<i>C</i><sub><i>b</i></sub></td></tr><tr><td><br />2</td><td><i>C</i><sub><i>r</i></sub>&gt;<i>C</i><sub><i>b</i></sub>&gt;<i>C</i><sub><i>g</i></sub></td></tr><tr><td><br />3</td><td><i>C</i><sub><i>g</i></sub>&gt;<i>C</i><sub><i>b</i></sub>&gt;<i>C</i><sub><i>r</i></sub></td></tr><tr><td><br />4</td><td><i>C</i><sub><i>g</i></sub>&gt;<i>C</i><sub><i>r</i></sub>&gt;<i>C</i><sub><i>b</i></sub></td></tr><tr><td><br />5</td><td><i>C</i><sub><i>b</i></sub>&gt;<i>C</i><sub><i>g</i></sub>&gt;<i>C</i><sub><i>r</i></sub></td></tr><tr><td><br />6</td><td><i>C</i><sub><i>b</i></sub>&gt;<i>C</i><sub><i>r</i></sub>&gt;<i>C</i><sub><i>g</i></sub></td></tr><tr><td><br />7</td><td><i>C</i><sub><i>r</i></sub>&gt;<i>C</i><sub><i>g</i></sub>=<i>C</i><sub><i>b</i></sub></td></tr><tr><td><br />8</td><td><i>C</i><sub><i>g</i></sub>&gt;<i>C</i><sub><i>r</i></sub>=<i>C</i><sub><i>b</i></sub></td></tr><tr><td><br />9</td><td><i>C</i><sub><i>b</i></sub>&gt;<i>C</i><sub><i>g</i></sub>=<i>C</i><sub><i>r</i></sub></td></tr><tr><td><br />0</td><td>其他</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>2.3</b> SIFT局部特征</h4>
                <div class="p1">
                    <p id="60">SIFT特征是为了使视频检索算法在视频帧图像受到旋转、缩放、平移以及噪声和光照等干扰下拥有良好的抗性。由文献<citation id="95" type="reference">[<a class="sup">6</a>]</citation>可知, SIFT特征提取步骤为:建立尺度空间、关键点定位和关键点描述。</p>
                </div>
                <div class="p1">
                    <p id="61">由于SIFT特征的维度比较大, 于是采用词袋模型进行降维, 从而加快视频检索速度。词袋模型最初在文本分类中使用, 可将文档表示为特征向量。同理使用词典模型, 首先对图像数据集中计算出的SIFT特征点使用K-means方法来聚类;然后在计算完SIFT特征点的聚类结果后, 把每一个SIFT描述符划分到一个特定的簇中;接着每一张图片都可以用<i>k</i>维的向量表示, 即用包含<i>k</i>个SIFT词的词典表示。文中<i>k</i>取500, 则SIFT特征向量为500维, 最后通过选取平均值降维到25维。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>3</b> 检索匹配</h3>
                <div class="p1">
                    <p id="63">文中通过查询视频关键帧以及参考视频关键帧的空间灰度序特征、颜色相关分布信息以及局部SIFT特征分别进行余弦距离比较得到各自的相似度, 即<i>S</i><sub>1</sub>、<i>S</i><sub>2</sub>、<i>S</i><sub>3</sub>。然后通过投票模型进行多特征融合, 最终得到两个视频关键帧的相似度<i>S</i>。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>3.1</b> 多特征融合</h4>
                <div class="p1">
                    <p id="65">两视频关键帧相似度通过投票模型计算获得, 计算式为</p>
                </div>
                <div class="p1">
                    <p id="66"><i>S</i> (<i>F</i><sub><i>q</i></sub>, <i>F</i><sub><i>r</i></sub>) =<i>w</i><sub>1</sub>×<i>S</i><sub>1</sub>+<i>w</i><sub>2</sub>×<i>S</i><sub>2</sub>+<i>w</i><sub>3</sub>×<i>S</i><sub>3</sub>      (2) </p>
                </div>
                <div class="p1">
                    <p id="67">其中, <i>w</i><sub>1</sub>、<i>w</i><sub>2</sub>、<i>w</i><sub>3</sub>分别是OM、CCV和SIFT特征的权重, <i>F</i><sub><i>q</i></sub>和<i>F</i><sub><i>r</i></sub>分别代表查询视频关键帧和参考视频关键帧。经过大量的实验显示<i>w</i><sub>1</sub>、<i>w</i><sub>2</sub>、<i>w</i><sub>3</sub>数值分别为0.4、0.4和0.2。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"><b>3.2</b> 检索匹配</h4>
                <div class="p1">
                    <p id="69">本文将视频的相似度匹配检索转化成关键帧序列的相似度计算比较。文中的检索算法基于滑动窗口原理来查找相似帧片段, 从而得到相似视频, 具体原理如图5所示。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于滑动窗口的视频检索图" src="Detail/GetImg?filename=images/DZKK201905010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 基于滑动窗口的视频检索图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5. Video retrieval graph based on sliding window</p>

                </div>
                <div class="p1">
                    <p id="71">图5中, 滑动窗口的视频帧序列中查询视频<i>a</i>、<i>b</i>、<i>c</i>帧分别和参考视频中的1、2、3帧进行相似度计算, 得到视频相似度<i>S</i> (<i>a</i>, 1) 、<i>S</i> (<i>b</i>, 2) 、<i>S</i> (<i>c</i>, 3) , 所取得的最大值就是此时间窗口的相似度<i>S</i><sub><i>w</i></sub>, <i>w</i>代表窗口的移动次数。两视频<i>V</i><sub><i>q</i></sub>和<i>V</i><sub><i>r</i></sub>的相似度<i>S</i><sub><i>v</i></sub>计算如下式所示</p>
                </div>
                <div class="p1">
                    <p id="72"><i>S</i><sub><i>v</i></sub> (<i>V</i><sub><i>q</i></sub>, <i>V</i><sub><i>r</i></sub>) =min (<i>S</i><sub><i>w</i></sub>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="73">式中, <i>v</i>代表查询视频数量。为了使检索速度更快, 本文使用窗口跳跃技术, 如式 (4) 所示, 当<i>S</i><sub><i>w</i></sub>小于阈值<i>θ</i> 时, 向前跳跃<i>k</i><sub><i>w</i></sub>帧数。</p>
                </div>
                <div class="area_img" id="74">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201905010_07400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="76">其中, D为滑动窗口中帧数, 文中取θ为0.4。</p>
                </div>
                <h3 id="77" name="77" class="anchor-tag"><b>4</b> 实验数据与分析</h3>
                <div class="p1">
                    <p id="78">算法实验均在戴尔工作站 (型号:Precision Tower 7910, Precision Tower 7910, 2.4 GHz, 16 GB内存) 及Ubuntu 16.04操作系统下用C++语言编程实现, 并采用OpenCV2.4.10和FFmpeg标准库。数据集选取自CC_WEB_VIDEO<citation id="96" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>数据集。数据集是24个热门检索词在YouTube, Google Video和Yahoo! Video上的检索结果, 总共拥有12 790个视频, 平均冗余视频的数量占检索结果的27%, 在某些特定的查询中, 冗余数量高达93%。</p>
                </div>
                <div class="p1">
                    <p id="79">在数据集中, 一个检索词的视频主要存在两种差异: (1) 格式上的差异, 如编码格式多种多样、帧率大小不一、比特率以及分辨率都有不同型号; (2) 内容上的差异, 如光学变化 (颜色、亮度) 、编辑操作 (添加字幕) 和内容改变 (添加相关的帧) 。本文中进行的视频检索实验采用的CC_WEB_VIDEO数据集不仅在真实性和复杂性都有很好体现。在实验结果分析时, 采用准确率召回率 (P-R) 曲线、平均精度 (MAP) 以及检索时间来评估实验结果。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80"><b>4.</b>1 实验结果与分析</h4>
                <div class="p1">
                    <p id="81">为了验证新算法的有效性, 本文算法不仅和SIG_CH<citation id="97" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>做了对比, 还和一些主流传统的特征进行方法做了对比, 例如HOG、SIFT以及ORB (Oriented FAST and Rotated BRIEF) <citation id="98" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>特征等。本文从MAP值和P-R曲线进行实验算法的比较, 结果如图6～图8以及表4所示。</p>
                </div>
                <div class="area_img" id="82">
                    <p class="img_tit"><b>表</b>2 MAP<b>值和时间的比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2. Comparison of MAP and time</p>
                    <p class="img_note"></p>
                    <table id="82" border="1"><tr><td><br />方法</td><td>MAP/%</td><td>时间/s</td></tr><tr><td><br />PPT<sup>[8]</sup></td><td>0.958</td><td>3 500</td></tr><tr><td><br />SIG_CH</td><td>0.892</td><td>-</td></tr><tr><td><br />CCV</td><td>0.757</td><td>22.45</td></tr><tr><td><br />CCV+OM</td><td>0.934</td><td>33.96</td></tr><tr><td><br />CCV+OM+ORB</td><td>0.943</td><td>73.45</td></tr><tr><td><br />CCV+OM+SIFT</td><td>0.952</td><td>64.13</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 24个查询视频平均PR曲线" src="Detail/GetImg?filename=images/DZKK201905010_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 24个查询视频平均PR曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 6. Averaged P-R graphs across 24 query video</p>

                </div>
                <div class="p1">
                    <p id="84">从图6以及表2可以看出采用的多特征融合是通过实验一步步结合图像特征在实验数据的效果获得的。另外, 针对不同相似视频的变化特点, 合理提出在颜色分布 (CCV) , 灰度空间序列 (OM) 以及局部特征点梯度方向大小 (SIFT) 上的图像特征。通过上述实验, 在颜色分布上添加上具有时空特性的灰度序列极大提高了视频的检索准确度。这是因为颜色分布特征虽然对图像的空间结构特征有很好的表现, 但是在灰度特征上以及图像块之间的顺序结构上并没有明显的效果。因此提出的颜色分布加上灰度空间序列对实验结果的精度有一定程度的提高。在加入ORB特征和SIFT之后弥补了特征提取在局部梯度方向大小以及角点之类的兴趣点的缺失。虽然结果有所提高, 但是实验数据库中视频很少受到旋转的干扰, 更多的是拍照镜头的远近对视频大小尺寸的影响。因此具有尺度不变性的SIFT比具有旋转不变性的ORB在视频检索的MAP效果更好。</p>
                </div>
                <div class="p1">
                    <p id="85">从表2中可以看出, 本文采用的多特征融合检索方法在精准度上比SIG_CH有所提高, 而在精确度相差不大的情况下比PPT算法更节省时间。图7和图8可以看出本文提出的方法在查询视频18和视频22上比SIG_CH实验结果的效果更加显著。这是因为18查询数据中多数视频是灰度画面以及插入了一些多余的帧, 而22查询视频动作幅度和画面色彩变化较快。因此SIG_CH中提出的颜色直方图算法以及检索方法没有在这两种视频上呈现很好的效果。而本文采用的多特征融合可在颜色、灰度序列还有局部特征等多方面检测相似拷贝视频, 对视频所带的干扰有很好抗性。另外, 本文所使用的特征降维和窗口跳跃性检索可以加快检索速度。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 SIG_CH方法" src="Detail/GetImg?filename=images/DZKK201905010_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 SIG_CH方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 7. SIG_CH method</p>

                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905010_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 本文方法" src="Detail/GetImg?filename=images/DZKK201905010_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 本文方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905010_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 8. The proposed method</p>

                </div>
                <h3 id="88" name="88" class="anchor-tag"><b>5</b> 结束语</h3>
                <div class="p1">
                    <p id="89">文中对所提出的基于多特征融合的视频检索技术分为3个部分进行了描述:首先对视频关键帧及其特征进行提取, 然后对关键帧特征序列进行相似度计算并匹配检索出相似视频。虽然实验算法提出的颜色分布、图像块序列分布以及局部特征在保证高的召回率和准确率的前提下, 在检索时间内获得了较大的提高, 但是随着深度学习在特征表示能力方面进一步发展, 未来基于深度学习的视频检索方法将成为主要的研究方向, 例如RNN/LSTM对视频片段建模是否有良好的性能以及更适合于视频检索的深度网络结构均有待进一步的研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A quick search method for audio and video signals based on histogram pruning">

                                <b>[1]</b> Kashino K, Kurozumi T, Murase H.A quick search method for audio and video signals based on histogram pruning[J].IEEE Transactions on Multimedia, 2003, 5 (3) :348-357.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhanced spatio-temporal video copy detection by combining trajectory and spatial consistency">

                                <b>[2]</b> Ozkan S, Esen E, Akar G B.Enhanced spatio-temporal video copy detection by combining trajectory and spatial consistency[C].Paris:IEEE International Conference on Image Processing, 2014.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MPEG-2 video copy detection method based on sparse representation of spatial and temporal features">

                                <b>[3]</b> Ren D, Zhuo L, Long H, et al.MPEG-2 video copy detection method based on sparse representation of spatial and temporal features[C].Taipei:IEEE Second International Conference on Multimedia Big Data, 2016.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG200619052&amp;v=MzAwMjg2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURtV3JyQUx6N01hYkc0SHRmTnBvOUFab1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 黄少年, 赵跃龙, 邱建雄.一种基于镜头的视频场景检测方法[J].计算机工程与应用, 2006, 42 (19) :170-173.Huang Shaonian, Zhao Yuelong, Qiu Jianxiong.A method of video scence detection based on shots[J].Computer Engineering and Applications, 2006, 42 (19) :170-173.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCGX201402006&amp;v=MTc5MzBab0ZpRG1XcnJBTmk3TWRyRzRIOVhNclk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Lin H D, Qiang Y U.Design and Implementation of an network video surveillance system based on H264[J].Journal of Xihua University, 2014, 171 (6) :1029-1045.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The study of salient object and BoF with SIFT for image retrieval">

                                <b>[6]</b> Shiue Y C, Lo S H, Tian Y C, et al.The study of salient object and BoF with SIFT for image retrieval[M].Bangkok:Frontier Computing, 2018.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Practical elimination of near- duplicates from web video search">

                                <b>[7]</b> Wu X, Hauptmann A G, Ngo C W.Practical elimination of near-duplicates from web video search[C].Augsburg:ACM International Conference on Multimedia, 2007.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pattern-based near-duplicate video retrieval and localization on Web-scale videos">

                                <b>[8]</b> Chou C L, Chen H T, Lee S Y.Pattern-based near-duplicate video retrieval and localization on web-scale videos[J].IEEE Transactions on Multimedia, 2015, 17 (3) :382-395.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201804005&amp;v=MjQxOTFNcTQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG1XcnJBSVRmQVpiRzRIOW4=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 王盼盼, 李玉惠.基于特征融合和L-M算法的车辆重识别方法[J].电子科技, 2018, 31 (4) :12-15.Wang Panpan, Li Yuhui.Vehicle re-identification method based on feature fusion and L-M algorithm[J].Electronic Science and Technology, 2018, 31 (4) :12-15.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201408008&amp;v=MjA5MzBab0ZpRG1XcnJBSVRmQVpiRzRIOVhNcDQ5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 韩永刚, 赵巍凯.基于单目视觉的行人检测研究[J].电子科技, 2014, 27 (8) :22-25.Han Yonggang, Zhao Weikai.Algorithm for pedestrian detection based on monocular vision[J].Electronic Science and Technology, 2014, 27 (8) :22-25.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201602024&amp;v=Mjc2NTJGaURtV3JyQUlUZkFaYkc0SDlmTXJZOUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 陈进, 陈思, 王一帆, 等.基于ARM的联合收割机远程视频监视系统[J].电子科技, 2016, 29 (2) :85-88.Chen Jin, Chen Si, Wang Yifan, et al.ARM9-based remote video monitoring system for combine harvester[J], Electronic Science and Technology, 2016, 29 (2) :85-88.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1015971009.nh&amp;v=MDA4NDZxL0g5SE1wcEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEbVdyckFWRjI2Rzc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 李阳.局部时空特征及部件的视频人体动作识别方法研究[D].重庆:重庆大学, 2015.Li Yang.Research based on local spatiotemporal features and parts for human action recognition from videos[D].Chongqing:Chongqing University, 2015.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016294156.nh&amp;v=MDEyMDBWRjI2R0xHeEd0REpxWkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEbVdyckE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 李龙.视频中人体行为识别的研究[D].南京:南京邮电大学, 2016.Li Long.A study on human action recognition in video[D].Nanjing:Nanjing University of Posts and Telecommunications, 2016.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A video copy detection algorithm combining local feature&amp;#39;&amp;#39;s robustness and global feature&amp;#39;&amp;#39;s speed">

                                <b>[14]</b> Gu X, Zhang D, Zhang Y, et al.A video copy detection algorithm combining local feature's robustness and global feature's speed[C].Vancouver:IEEE International Conference on Acoustics, Speech and Signal Processing, 2013.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VCDB:A Large-scale database for partial copy detection in videos">

                                <b>[15]</b> Jiang Y G, Jiang Y, Wang J.VCDB:A Large-scale database for partial copy detection in videos[M].Amsterdam:Springer International Publishing, 2014.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Shots temporal prediction rules for high-dimensional data of semantic video retrieval">

                                <b>[16]</b> Mohamed S T.Shots temporal prediction rules for high-dimensional data of semantic video retrieval[J].American Journal of Applied Sciences, 2018, 15 (1) :60-69.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHJC201803001&amp;v=MzIzNzZxQnRHRnJDVVI3cWZadVpvRmlEbVdyckFQeVhCYmJHNEg5bk1ySTlGWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 张护望, 林浒, 王诗宇, 等.一种基于改进SIFT算法的轨道板图像匹配方法[J].组合机床与自动化加工技术, 2018 (3) :1-3.Zhang Huwang, Lin hu, Wang Shiyu, et al.Method of rail board image matching based on improved SIFT algorithm[J].Modular Machine Tool &amp; Automatic Manufacturing Technique, 2018 (3) :1-3.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZKK201905010" />
        <input id="dpi" type="hidden" value="399" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201905010&amp;v=MDA1MDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURtV3JyQUlUZkFaYkc0SDlqTXFvOUVaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

