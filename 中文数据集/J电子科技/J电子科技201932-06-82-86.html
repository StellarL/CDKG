

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139249630420000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZKK201906018%26RESULT%3d1%26SIGN%3d4%252bsZPZALnJUf1WvAoxp5f8ZL5sk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201906018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201906018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201906018&amp;v=MTMxNzlHRnJDVVI3cWZadVpwRnkvbVc3ektJVGZBWmJHNEg5ak1xWTlFYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#36" data-title="&lt;b&gt;1&lt;/b&gt; 深度学习 "><b>1</b> 深度学习</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="&lt;b&gt;1.1&lt;/b&gt; 卷积神经网络"><b>1.1</b> 卷积神经网络</a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;1.2&lt;/b&gt; SIAMESE网络"><b>1.2</b> SIAMESE网络</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="&lt;b&gt;2&lt;/b&gt; 脸部标志检测 "><b>2</b> 脸部标志检测</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="&lt;b&gt;2.1&lt;/b&gt; 模型分析"><b>2.1</b> 模型分析</a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;2.2&lt;/b&gt; 模型建立"><b>2.2</b> 模型建立</a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;2.3&lt;/b&gt; 训练"><b>2.3</b> 训练</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#86" data-title="&lt;b&gt;3&lt;/b&gt; 人脸识别 "><b>3</b> 人脸识别</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="&lt;b&gt;3.1&lt;/b&gt; 模型分析"><b>3.1</b> 模型分析</a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;3.2&lt;/b&gt; 模型建立"><b>3.2</b> 模型建立</a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;3.3&lt;/b&gt; 训练"><b>3.3</b> 训练</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="&lt;b&gt;4&lt;/b&gt; 实验测试 "><b>4</b> 实验测试</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#120" data-title="&lt;b&gt;4.1&lt;/b&gt; 脸部标志检测结果"><b>4.1</b> 脸部标志检测结果</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;4.2&lt;/b&gt; 人脸识别结果"><b>4.2</b> 人脸识别结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#129" data-title="&lt;b&gt;5&lt;/b&gt; 结束语 "><b>5</b> 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="图1 Siamese 网络">图1 Siamese 网络</a></li>
                                                <li><a href="#74" data-title="图2 随机图像与脸部标志检测结果">图2 随机图像与脸部标志检测结果</a></li>
                                                <li><a href="#82" data-title="图3 逐层训练法">图3 逐层训练法</a></li>
                                                <li><a href="#97" data-title="图4 分层训练方法">图4 分层训练方法</a></li>
                                                <li><a href="#122" data-title="图5 面部标志检测的平均误差">图5 面部标志检测的平均误差</a></li>
                                                <li><a href="#123" data-title="图6 面部标志检测的部分结果">图6 面部标志检测的部分结果</a></li>
                                                <li><a href="#127" data-title="图7 AT&amp;amp;T ORL上人脸识别结果">图7 AT&amp;T ORL上人脸识别结果</a></li>
                                                <li><a href="#128" data-title="图8 LFW上人脸识别结果">图8 LFW上人脸识别结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="144">


                                    <a id="bibliography_1" title=" 曾建凡.多角度人脸检测与识别方法研究[J].电子设计工程, 2017, 25 (11) :41-44.Zeng Jianfan.Research on multi-angle face detection and recognition[J].Electronic Design Engineering, 2017, 25 (11) :41-44." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201711010&amp;v=MDkxMTJGeS9tVzd6S0lqclBkTEc0SDliTnJvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         曾建凡.多角度人脸检测与识别方法研究[J].电子设计工程, 2017, 25 (11) :41-44.Zeng Jianfan.Research on multi-angle face detection and recognition[J].Electronic Design Engineering, 2017, 25 (11) :41-44.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_2" title=" Chen L F, Liao H Y M, Ko M T, et al.A new LDA-based face recognition system which can solve the small sample size problem[J].Pattern Recognition, 2000, 33 (10) :1713-1726." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600741248&amp;v=MjgwMzMrOE9Ebmd4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmpJSjEwY2FSQT1OaWZPZmJLN0h0RE5xWTlGWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Chen L F, Liao H Y M, Ko M T, et al.A new LDA-based face recognition system which can solve the small sample size problem[J].Pattern Recognition, 2000, 33 (10) :1713-1726.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_3" title=" Zhang W, Shan S, Gao W, et al.Local gabor binary pattern histogram sequence (LGBPHS) :a novel non-statistical model for face representation and recognition[C].Boston:Tenth IEEE International Conference on Computer Vision, IEEE, 2005." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local Gabor Binary Pattern Histogram Sequence (LGBPHS): a Novel Non-Statistical Model for Face Representation and Recognition">
                                        <b>[3]</b>
                                         Zhang W, Shan S, Gao W, et al.Local gabor binary pattern histogram sequence (LGBPHS) :a novel non-statistical model for face representation and recognition[C].Boston:Tenth IEEE International Conference on Computer Vision, IEEE, 2005.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_4" title=" Ahonen T, Hadid A, Pietikainen M.Face description with local binary patterns:application to face recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (12) :2037-2041." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face Description with Local Binary Patterns: Application to Face Recognition">
                                        <b>[4]</b>
                                         Ahonen T, Hadid A, Pietikainen M.Face description with local binary patterns:application to face recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (12) :2037-2041.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_5" title=" 刘悦婷, 阎爱玲.一种基于 ISFLA-SVM 的人脸识别算法[J].自动化与仪器仪表, 2016 (3) :210-213.Liu Yueting, Yan Ailing.A face recognition algorithm based on ISFLA-SVM[J].Automation and Instrumentation, 2016 (3) :210-213." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDYY201603086&amp;v=MjM5OTJGeS9tVzd6S1B5blNkN0c0SDlmTXJJOU5Zb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         刘悦婷, 阎爱玲.一种基于 ISFLA-SVM 的人脸识别算法[J].自动化与仪器仪表, 2016 (3) :210-213.Liu Yueting, Yan Ailing.A face recognition algorithm based on ISFLA-SVM[J].Automation and Instrumentation, 2016 (3) :210-213.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_6" title=" Zhou E, Fan H, Cao Z, et al.Extensive facial landmark localization with coarse-to-fine convolutional network cascade[C].Charlotte:IEEE International Conference on Computer Vision Workshops, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Extensive facial landmark localization with coarse-to-fine convolutional network cascade">
                                        <b>[6]</b>
                                         Zhou E, Fan H, Cao Z, et al.Extensive facial landmark localization with coarse-to-fine convolutional network cascade[C].Charlotte:IEEE International Conference on Computer Vision Workshops, 2013.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_7" title=" Lu C, Tang X.Surpassing human-level face verification performance on LFW with GaussianFace[J].Computer Science, 2014 (7) :3811-3819." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Surpassing Human-Level Face Verifica-tion Performance on LFW with Gaussian Face">
                                        <b>[7]</b>
                                         Lu C, Tang X.Surpassing human-level face verification performance on LFW with GaussianFace[J].Computer Science, 2014 (7) :3811-3819.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_8" title=" Huang G B, Lee H, Learned-Miller E.Learning hierarchical representations for face verification with convolutional deep belief networks[C].Cleveland:IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, 2012." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning hierarchical representations for face verification with convolutional deep belief networks">
                                        <b>[8]</b>
                                         Huang G B, Lee H, Learned-Miller E.Learning hierarchical representations for face verification with convolutional deep belief networks[C].Cleveland:IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, 2012.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_9" title=" Ouyang W, Wang X.Joint deep learning for pedestrian detection[C].Beijing:IEEE International Conference on Computer Vision, IEEE, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint Deep Learning for Pedestrian Detection">
                                        <b>[9]</b>
                                         Ouyang W, Wang X.Joint deep learning for pedestrian detection[C].Beijing:IEEE International Conference on Computer Vision, IEEE, 2014.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_10" title=" Liu M, Shan S, Wang R, et al.Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition[C].Albuquerque:IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition">
                                        <b>[10]</b>
                                         Liu M, Shan S, Wang R, et al.Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition[C].Albuquerque:IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, 2014.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_11" title=" 冯建洋, 谌海云.基于人工神经网络的人脸识别研究[J].自动化与仪器仪表, 2017 (5) :24-26.Feng Jianyang, Chen Haiyun.Research on face recognition based on artificial neural network[J].Automation and Instruments, 2017 (5) :24-26." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDYY201705009&amp;v=MDMzNzQ5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5L21XN3pLUHluU2Q3RzRIOWJNcW8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         冯建洋, 谌海云.基于人工神经网络的人脸识别研究[J].自动化与仪器仪表, 2017 (5) :24-26.Feng Jianyang, Chen Haiyun.Research on face recognition based on artificial neural network[J].Automation and Instruments, 2017 (5) :24-26.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_12" title=" 甘航萍, 王力, 何庆, 等.基于凸轮权重距离局部保持投影算法的人脸识别[J].电子科技, 2017, 30 (8) :6-8.Gan Hangping, Wang Li, He Qing, et al.Face recognition based on cam weighted distance local preservation projection algorithms[J].Electronic Science and Technology, 2017, 30 (8) :6-8." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201708003&amp;v=MDAxNzFwRnkvbVc3ektJVGZBWmJHNEg5Yk1wNDlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         甘航萍, 王力, 何庆, 等.基于凸轮权重距离局部保持投影算法的人脸识别[J].电子科技, 2017, 30 (8) :6-8.Gan Hangping, Wang Li, He Qing, et al.Face recognition based on cam weighted distance local preservation projection algorithms[J].Electronic Science and Technology, 2017, 30 (8) :6-8.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_13" title=" Sun Y, Wang X, Tang X.Deep learning face representation from predicting 10, 000 classes[C].Virginia:Computer Vision and Pattern Recognition, IEEE, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Learning Face Representation from Predicting 10,000 Classes">
                                        <b>[13]</b>
                                         Sun Y, Wang X, Tang X.Deep learning face representation from predicting 10, 000 classes[C].Virginia:Computer Vision and Pattern Recognition, IEEE, 2014.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_14" title=" 侯小毛, 徐仁伯.云环境中考虑隐私保护的人脸图像识别[J].沈阳工业大学学报, 2018 (2) :99-104.Hou Xiaomao, Xu Renbo.Face image recognition considering privacy protection in cloud environment[J].Journal of Shenyang University of Technology, 2018 (2) :99-104." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201802021&amp;v=MjMwNDZHNEg5bk1yWTlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvbVc3ektOalRNZDc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         侯小毛, 徐仁伯.云环境中考虑隐私保护的人脸图像识别[J].沈阳工业大学学报, 2018 (2) :99-104.Hou Xiaomao, Xu Renbo.Face image recognition considering privacy protection in cloud environment[J].Journal of Shenyang University of Technology, 2018 (2) :99-104.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_15" title=" 廖延娜, 马超.基于稀疏表示的人脸识别系统设计与实现[J].电子设计工程, 2016, 24 (17) :153-155.Liao Yanna, Ma Chao.Design and implementation of face recognition system based on sparse representation[J].Electronic Design Engineering, 2016, 24 (17) :153-155." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201617047&amp;v=MTc5Njg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9tVzd6S0lqclBkTEc0SDlmTnFJOUJZNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         廖延娜, 马超.基于稀疏表示的人脸识别系统设计与实现[J].电子设计工程, 2016, 24 (17) :153-155.Liao Yanna, Ma Chao.Design and implementation of face recognition system based on sparse representation[J].Electronic Design Engineering, 2016, 24 (17) :153-155.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZKK" target="_blank">电子科技</a>
                2019,32(06),82-86 DOI:10.16180/j.cnki.issn1007-7820.2019.06.017            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于深度学习的人脸识别方法研究</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E5%B0%91%E8%81%AA&amp;code=43139012&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡少聪</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E6%98%8E%E5%BE%B7%E5%AD%A6%E9%99%A2&amp;code=1749628&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北工业大学明德学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>作为非接触式生物识别方法之一, 人脸识别在诸多情况下被广泛使用。然而, 传统的人脸识别方法由于识别准确度低以及在多个场合的应用受到限制, 已不能满足目前的需求。文中提出了采用深度学习的方法来实现脸部标志检测和无限制人脸识别。为解决人脸标志检测问题, 使用一种深层卷积神经网络的逐层训练方法, 以帮助卷积神经网络进行收敛, 并提出了一种避免过拟合的样本变换方法;为了解决人脸识别问题, 文中提出了一种SIAMESE卷积神经网络, 其在不同部位和尺度上进行训练。实验测试显示, ORL和人脸识别算法的精度分别达到了91%和81%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%84%B8%E9%83%A8%E6%A0%87%E5%BF%97%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">脸部标志检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%A0%E9%99%90%E5%88%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">无限制人脸识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SIAMESE%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SIAMESE网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    胡少聪 (1996-) , 男, 本科。研究方向:通信工程。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-06-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>陕西省自然科学基金 (2016JQ6024);</span>
                    </p>
            </div>
                    <h1><b>Research on Face Recognition Based on Deep Learning</b></h1>
                    <h2>
                    <span>HU Shaocong</span>
            </h2>
                    <h2>
                    <span>Mingde College, Northwest Polytechnic University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>As one of the contactless biometric methods, face recognition is widely used in many situations. However, the traditional face recognition method can not meet the current demand because of its low recognition accuracy and limited application in many occasions. In this paper, we proposed a deep learning method to achieve facial marker detection and unrestricted face recognition. In order to solved the problem of face marker detection, this paper proposed a layer-by-layer training method for deep convolutional neural networks to help convolutional neural network convergence, and proposes a sample transformation method to avoided overfitting;In order to solve the face recognition problem, this paper proposed a SIAMESE convolutional neural network, which was trained on different parts and scales. Experimental tests showed that the accuracy of ORL and face recognition algorithms reached 91% and 81%, respectively.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=facial%20Landmark%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">facial Landmark detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=unrestricted%20face%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">unrestricted face recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SIAMESE%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SIAMESE network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-06-18</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Natural Science Foundation of Shaanxi (2016JQ6024);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="32">随着计算机科学技术的发展, 人脸识别已被广泛应用于日常生活和环境, 且需求也在不断增长。提取和组合图像的语义信息需要有效的模式识别算法, 传统的人脸识别算法, 如PCA<citation id="174" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、LDA<citation id="175" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、GABOR<citation id="176" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、LBP<citation id="177" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等, 在精度和特征提取方面均存在一定的不足。完整的人脸识别系统包括人脸检测和人脸识别模式两部分, 脸部的生物学特征具有总体结构相似性与个体差异<citation id="178" type="reference"><link href="152" rel="bibliography" /><link href="154" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>。因此, 有必要通过人脸检测过程来提取人脸的结构特征, 并将人脸与背景图案分开, 并对分离出的人脸进行识别。这是一个提取规范化人脸图像的过程, 然后进行对比和识别, 目的是从图像中区分出人脸的身份。</p>
                </div>
                <div class="p1">
                    <p id="33">人脸识别的发展主要分为3个阶段, 从上世纪50年代到80年代, 人脸识别经历了第一阶段。此时人脸识别被认为是一般的模式识别问题, 其主流技术主要基于面部几何。在上世纪90年代, 经历了第二阶段。在该时期, 人脸识别技术飞速发展, 出现了众多经典的方法, 如Eigen Face、Fisher Face和弹性图匹配等, 主流技术基于人脸性能建模<citation id="179" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。从90年代至今, 是人脸识别技术的第三阶段。人脸识别进入深入发展阶段后, 研究人员开始专注于人脸识别的实际情况。</p>
                </div>
                <div class="p1">
                    <p id="34">在人类探索的过程中, 神经网络是一种生物启发的数学模型。这是一个适应性系统, 可以通过学习程序进行操作。2层BP网络对Mnist特征库的识别准确率较高 (98%) , 但其收敛速度较慢, 通常需要数百次才能收敛以获得满意的结果, 且易于收敛到局部最优解<citation id="180" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="35">为了解决上述问题, 本文提出了卷积神经网络作为基本模型来实现快速收敛、信号噪声抑制和高精度的特征点定位, 该模型也适用于面部标志检测。由于卷积神经网络的训练需要大量的样本<citation id="181" type="reference"><link href="160" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 为了避免过拟合, 本文提出样本变换方法。由于需要多输入, 文中将卷积神经网络和SIAMESE网络进行了组合, 以对不同部位及尺度的人脸进行训练并连接人脸表征, 从而实现一对一的人脸识别。</p>
                </div>
                <h3 id="36" name="36" class="anchor-tag"><b>1</b> 深度学习</h3>
                <div class="p1">
                    <p id="37">近年来, 随着机器学习的发展, 深度学习作为一种新的研究方向引起了人工智能领域的广泛关注<citation id="182" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。深度学习是一种能够有效训练深度神经网络的机器学习算法, 可以用于高层次的数据抽象建模。2012年12月29日, 纽约时报首页报道, 深度学习使机器能够进行人类活动, 如观看、倾听和思考。同时为模式识别提供可能性, 并促进人工智能的发展<citation id="183" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。2013年, MIT技术评论将深度学习列为全球十大技术突破之一。</p>
                </div>
                <div class="p1">
                    <p id="38">2017年随着深度学习的快速发展, 工业界和学术界均在深入学习中致力于身心。谷歌、Facebook、百度、阿里巴巴和一系列大公司声称人工智能将成为其下一个战略重点。而Google、Facebook、百度、微软、亚马逊和其他公司, 则已经开辟了自己的深度学习框架。深度学习<citation id="184" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>通过具有多隐含层和大量训练数据的机器学习模型, 可以学习更多有用的特征, 并提高分类与预测的准确性。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39"><b>1.1</b> 卷积神经网络</h4>
                <div class="p1">
                    <p id="40">卷积神经网络的出现较好地解决了神经网络的一些缺点, 如计算量大、运算结果过度拟合、缺乏局部特征等。通过其感受视野、共享权重和时域或空间域样本, 保持结果的位移、缩放和失真不变性<citation id="185" type="reference"><link href="168" rel="bibliography" /><link href="170" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="41">卷积神经网络可以通过卷积层和池化层在卷积神经网络中显着降低维数, 然后输出到全连接层。</p>
                </div>
                <div class="p1">
                    <p id="42">对于卷积层, 共享权重和非共享权重分别如式 (1) 和式 (2) 所示。</p>
                </div>
                <div class="p1">
                    <p id="43"><i>C</i><mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>=</p>
                </div>
                <div class="p1">
                    <p id="45"><i>g</i> (∑<mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>z</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msubsup></mrow></math></mathml>∑<mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>y</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></msubsup></mrow></math></mathml>∑<mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>h</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></msubsup></mrow></math></mathml><i>I</i><mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>+</mo><mi>y</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>c</mi><msubsup><mrow></mrow><mi>k</mi><mi>t</mi></msubsup></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>*<i>F</i><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>z</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>+<i>B</i><sub><i>k</i></sub>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="51"><i>C</i><mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>=</p>
                </div>
                <div class="p1">
                    <p id="53"><i>g</i> (∑<mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>z</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>c</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi>k</mi></mrow></msubsup></mrow></math></mathml>∑<mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>y</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></msubsup></mrow></math></mathml>∑<mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>h</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></msubsup></mrow></math></mathml><i>I</i><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>+</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo>+</mo><mi>y</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>c</mi><msubsup><mrow></mrow><mi>k</mi><mi>t</mi></msubsup><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">) </mo></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>*<i>F</i><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>+<i>B</i><sub><i>k</i></sub>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="59">池化层为</p>
                </div>
                <div class="p1">
                    <p id="60"><i>I</i><mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>=<i>f</i><sub>0&lt;<i>x</i>≤<i>d</i>, 0&lt;<i>y</i>≤<i>d</i></sub> (<i>C</i><mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>*</mo><mi>s</mi><mo>+</mo><mi>x</mi><mo>, </mo><mo stretchy="false"> (</mo><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>*</mo><mi>s</mi><mo>+</mo><mi>y</mi><mo>, </mo><mi>k</mi></mrow><mi>t</mi></msubsup></mrow></math></mathml>)      (3) </p>
                </div>
                <div class="p1">
                    <p id="63">其中, <i>c</i><sub><i>s</i></sub>为卷积层中第<i>k</i>个单元与最后一层的连接。<i>w</i><sub><i>c</i></sub>为一个卷积层单元的宽度, <i>h</i><sub><i>c</i></sub>为卷积层单元的高度, <i>t</i>为卷积层的数量。<i>c</i><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>t</mi></msubsup></mrow></math></mathml>为卷积层中最后一层的第<i>k</i>个单元的编号;<i>I</i>为这一层的输入, <i>F</i>是卷积核, <i>B</i>是偏置值。函数<i>g</i>和<i>f</i>的具体形式将在使用时引入。</p>
                </div>
                <h4 class="anchor-tag" id="65" name="65"><b>1.2</b> SIAMESE网络</h4>
                <div class="p1">
                    <p id="66">根据目前的卷积神经网络, 其只能支持如<i>y</i>=<i>f</i> (<i>X</i>) 的函数。其中, <i>X</i>是解决问题的向量, <i>y</i>是该模块的输出, 该模块不适合分类或类型未知的情况。因此, 文中使用基于卷积神经网络的Siamese网络。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Siamese 网络" src="Detail/GetImg?filename=images/DZKK201906018_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Siamese 网络  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_067.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1. Siamese network</p>

                </div>
                <div class="p1">
                    <p id="68">图1是Siamese网络的原理图, 其支持<i>y</i>=<i>f</i> (<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>) 模块。<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>是实际问题的向量, <i>y</i>是其的相似概率。使用Siamese网络模块, 可以解决多样本输入和分类的问题。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag"><b>2</b> 脸部标志检测</h3>
                <h4 class="anchor-tag" id="70" name="70"><b>2.1</b> 模型分析</h4>
                <div class="p1">
                    <p id="71">本文主要研究了光学相机在自然光条件下, 二维人脸图像之间的一对一识别问题。为了消除脸部表情、拍摄环境、图片大小等干扰, 本文采用眼睛、眉毛、鼻子、嘴巴等脸部标志检测, 以减少干扰<citation id="188" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation><sup>-16]</sup>。</p>
                </div>
                <div class="p1">
                    <p id="72">为了便于处理和提高准确性、泛化能力, 本文将脸部标志检测分为两步: (1) 定位人脸; (2) 脸部标志检测。</p>
                </div>
                <div class="p1">
                    <p id="73">脸部标志检测的核心问题是考虑两个约束问题:纹理约束和形状约束。脸部的肌理约束是指脸部的某些部位, 如眼睛、鼻子、嘴巴等, 其是通过局部像素表现出来的, 而脸部形状约束是这些脸部部分的拓扑结构。卷积层可以利用这些局部纹理特征重新训练一些噪声信号, 非共享层可充分利用训练样本中的拓扑信息。图2显示出了在随机图像上使用的内部面部标志检测算法的结果, 其结果稳定, 且能够检测出类似人脸的纹理。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 随机图像与脸部标志检测结果" src="Detail/GetImg?filename=images/DZKK201906018_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 随机图像与脸部标志检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2. Random image and face sign detection results</p>

                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.2</b> 模型建立</h4>
                <div class="p1">
                    <p id="76">这里使用的卷积神经网络的公式是用式 (1) ～式 (3) 实现的, 人脸识别的函数<i>g</i>和<i>f</i>为</p>
                </div>
                <div class="p1">
                    <p id="77"><i>g</i> (<i>x</i>) =|tan<i>h</i> (<i>x</i>) |      (4) </p>
                </div>
                <div class="p1">
                    <p id="78"><i>f</i> (<i>x</i>) =max (<i>x</i>)      (5) </p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>2.3</b> 训练</h4>
                <div class="p1">
                    <p id="80">文中使用的样本部分来自LFW, 以及中国科学院研制的CAS-PEAL-R1。本文通过人为地校准了特征点, 并获得了约6 400个样本。其中包含各种条件, 例如戴眼镜、太阳镜、帽子、脸型或不同种族的面孔。同时, 将6 400个样本映射到12 800个样本。</p>
                </div>
                <div class="p1">
                    <p id="81">如图3所示, 分层训练分为两个卷积神经网络。每个网络均有一个监督训练, 且在调整了图层的权重之后, 不再更新权重。分层次训练可以避免由于网络层数过多而导致的底层网络难以有效更新的情况, 使网络融合更好。此外, 由于计算量的减少, 从而加快了网络的收敛速度。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 逐层训练法" src="Detail/GetImg?filename=images/DZKK201906018_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 逐层训练法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3. Layer by layer training method</p>

                </div>
                <div class="p1">
                    <p id="83">为了提高训练机对有限样本的泛化能力, 减少训练过程中出现的过拟合问题。本文针对两种网络的不同特点, 在随机梯度下降训练过程中进行样本变换。</p>
                </div>
                <div class="p1">
                    <p id="84">第一级网络-人脸定位被用来缩小网络二级计算范围, 提高泛化能力。因此, 对第一级训练样本进行诸如旋转、缩放、偏移等操作, 可以使网络更好地泛化这些问题。</p>
                </div>
                <div class="p1">
                    <p id="85">第二级网络-脸部标志检测用于减少因光照、碎片、面部表情等引起的无效纹理约束及无效形状约束的噪声。因此, 对于样本的第二级, 文中可以改变亮度、阴影模拟来训练形状约束。以阴影模拟为例, 将图像中某个区域的像素值固定为随机值, 以模拟光照或遮挡的影响。</p>
                </div>
                <h3 id="86" name="86" class="anchor-tag"><b>3</b> 人脸识别</h3>
                <h4 class="anchor-tag" id="87" name="87"><b>3.1</b> 模型分析</h4>
                <div class="p1">
                    <p id="88">本文采用SIAMESE卷积神经网络集群构造人脸图像的不同部分, 如眼睛、鼻子、嘴等, 提取特征向量并将其连接成一个特征向量来表示人脸图像。</p>
                </div>
                <div class="p1">
                    <p id="89">这里SIAMESE网络中的分类器是一组深度卷积神经网络, 该方法的特点是直接从图像的不同部分和尺度使用机器学习模型提取特征, 然后直接用于识别。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>3.2</b> 模型建立</h4>
                <div class="p1">
                    <p id="91">这里使用的卷积神经网络的公式是用式 (1) ～式 (3) 实现的, 人脸识别的函数<i>g</i>和<i>f</i>为</p>
                </div>
                <div class="p1">
                    <p id="92"><i>g</i> (<i>x</i>) =lg (1+<i>e</i><sup><i>x</i></sup>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="93"><i>f</i> (<i>x</i>) =max (<i>x</i>)      (7) </p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>3.3</b> 训练</h4>
                <div class="p1">
                    <p id="95">样本主要来源于面部标志检测的结果, 并从LFW和CASPEAL-R1中选取了近8 000个样本。采用逐层训练法, 每个训练层的人脸区域为: (1) 用第一层卷积神经网络训练眼睛、鼻子和嘴周围的关键人脸区域; (2) 训练关键人脸; (3) 用卷积神经网络的第三层训练基于全脸的临界人脸区域。</p>
                </div>
                <div class="p1">
                    <p id="96">SIAMESE网络的训练采用基于梯度的反馈算法和随机梯度下降。因深层网络, 文中可以使用与第2节相同的方法 (逐层训练方法) 。图4显示了分层训练方法的结构图。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 分层训练方法" src="Detail/GetImg?filename=images/DZKK201906018_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 分层训练方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4. Hierarchical training method</p>

                </div>
                <div class="p1">
                    <p id="98">训练通过两个步骤实现:前馈和反馈。前馈为</p>
                </div>
                <div class="p1">
                    <p id="99"><i>L</i> (<i>s</i><sup>1</sup>, <i>s</i><sup>2</sup>, <i>s</i><sup>3</sup>, …, <i>s</i><sup><i>M</i></sup>|<i>h</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></mathml>, <i>h</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></mathml>, …, <i>h</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>Μ</mi></msubsup></mrow></math></mathml>, <i>h</i><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>Μ</mi></msubsup></mrow></math></mathml>, <i>α</i>|) =</p>
                </div>
                <div class="p1">
                    <p id="104">-∑<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></msubsup></mrow></math></mathml> (<i>s</i><sup><i>m</i></sup>log (<i>g</i> (<i>h</i><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>m</mi></msubsup></mrow></math></mathml>, <i>h</i><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>m</mi></msubsup></mrow></math></mathml>, <i>α</i>) ) ) +</p>
                </div>
                <div class="p1">
                    <p id="108"> (1-<i>s</i><sup><i>m</i></sup>) log (1-<i>g</i> (<i>h</i><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>m</mi></msubsup></mrow></math></mathml>, <i>h</i><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>m</mi></msubsup></mrow></math></mathml>, <i>α</i>) )      (8) </p>
                </div>
                <div class="p1">
                    <p id="111">训练集由<i>M</i>对输入示例和相应的相似性标签<i>s</i><sup><i>m</i></sup>组成, <i>h</i><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>m</mi></msubsup></mrow></math></mathml>是第<i>m</i>个输入示例的第一个样本, <i>h</i><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>m</mi></msubsup></mrow></math></mathml>是第<i>m</i>个输入示例的第二个样本;<i>α</i>是学习期间优化的正系数, <i>g</i> (<i>x</i>) 是SIAMESE网络的成本函数。</p>
                </div>
                <div class="p1">
                    <p id="114">反馈为</p>
                </div>
                <div class="area_img" id="115">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201906018_11500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="117">其中, w是<i>SIAMESE</i>网络之前训练机的参数, g<sup>m</sup>是第m个样本的输出。</p>
                </div>
                <div class="p1">
                    <p id="118">使用此函数的优点是, 尽可能使同一样本具有相似的输出。同时, 使不同样本中的输出具有较大的间隙, 且结果将在0和1之间归一化以显示相似的概率。</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag"><b>4</b> 实验测试</h3>
                <h4 class="anchor-tag" id="120" name="120"><b>4.1</b> 脸部标志检测结果</h4>
                <div class="p1">
                    <p id="121">AT&amp;T ORL:在AT&amp;T ORL人脸数据库中, 脸部样本之间的旋转和照明变化相当较小, 形象比其他人更清晰, 平均误差和样本误差之间没有显着差异, 所以过度拟合没有发生。AT&amp;T ORL的脸部标志检测的平均误差, 如图5所示。AT&amp;T ORL的脸部标志检测的部分结果, 如图6所示。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 面部标志检测的平均误差" src="Detail/GetImg?filename=images/DZKK201906018_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 面部标志检测的平均误差  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5. Average error of face mark detection</p>

                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 面部标志检测的部分结果" src="Detail/GetImg?filename=images/DZKK201906018_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 面部标志检测的部分结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 6. Partial results of facial marking detection</p>

                </div>
                <h4 class="anchor-tag" id="124" name="124"><b>4.2</b> 人脸识别结果</h4>
                <div class="p1">
                    <p id="125">AT&amp;T ORL:在该人脸数据库中, 样本的变化较小, 但图像的分辨率相对较低, 只有92×92左右。在测试过程中, 图像尺寸可达146×146。然而, 训练集中图像的实际分辨率通常大于146×146。因此, 结果仍有待改进。AT&amp;T ORL的人脸识别结果, 如图7所示。</p>
                </div>
                <div class="p1">
                    <p id="126">LFW:LFW中的图像具有最多的表情和最大的脸部旋转角度。由于本文主要研究了正面人脸识别, 故LFW在人脸数据库中表现最差并非偶然。在LFW上的人脸识别结果, 如图8所示。</p>
                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 AT&amp;T ORL上人脸识别结果" src="Detail/GetImg?filename=images/DZKK201906018_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 AT&amp;T ORL上人脸识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 7. Face recognition results on AT&amp;T ORL</p>

                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201906018_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 LFW上人脸识别结果" src="Detail/GetImg?filename=images/DZKK201906018_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 LFW上人脸识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201906018_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 8. Face recognition results on LFW</p>

                </div>
                <h3 id="129" name="129" class="anchor-tag"><b>5</b> 结束语</h3>
                <div class="p1">
                    <p id="130">为解决传统人脸识别方法识别准确度低以及在多个场合的应用受到限制的缺点, 本文提出了基于深度学习的人脸识别方法。研究了卷积神经网络的深度学习, 通过逐层训练方法和样本变换方法, 使其收敛更快、避免过拟合。SIAMESE卷积神经网络模型, 有效地解决了多输入和未知类型分类的问题。通过对ORL和LFW进行重复测试, 文中在脸部标志检测和人脸识别中实现了高精度。由于时间和样本的限制, 该方法的培训过程仍需进一步改进。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="144">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201711010&amp;v=MDc2NjFyQ1VSN3FmWnVacEZ5L21XN3pLSWpyUGRMRzRIOWJOcm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 曾建凡.多角度人脸检测与识别方法研究[J].电子设计工程, 2017, 25 (11) :41-44.Zeng Jianfan.Research on multi-angle face detection and recognition[J].Electronic Design Engineering, 2017, 25 (11) :41-44.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600741248&amp;v=Mjk0OTRadEZpbmxVcmpJSjEwY2FSQT1OaWZPZmJLN0h0RE5xWTlGWSs4T0RuZ3hvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Chen L F, Liao H Y M, Ko M T, et al.A new LDA-based face recognition system which can solve the small sample size problem[J].Pattern Recognition, 2000, 33 (10) :1713-1726.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local Gabor Binary Pattern Histogram Sequence (LGBPHS): a Novel Non-Statistical Model for Face Representation and Recognition">

                                <b>[3]</b> Zhang W, Shan S, Gao W, et al.Local gabor binary pattern histogram sequence (LGBPHS) :a novel non-statistical model for face representation and recognition[C].Boston:Tenth IEEE International Conference on Computer Vision, IEEE, 2005.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face Description with Local Binary Patterns: Application to Face Recognition">

                                <b>[4]</b> Ahonen T, Hadid A, Pietikainen M.Face description with local binary patterns:application to face recognition[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (12) :2037-2041.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDYY201603086&amp;v=MDI2MzQvbVc3ektQeW5TZDdHNEg5Zk1ySTlOWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 刘悦婷, 阎爱玲.一种基于 ISFLA-SVM 的人脸识别算法[J].自动化与仪器仪表, 2016 (3) :210-213.Liu Yueting, Yan Ailing.A face recognition algorithm based on ISFLA-SVM[J].Automation and Instrumentation, 2016 (3) :210-213.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Extensive facial landmark localization with coarse-to-fine convolutional network cascade">

                                <b>[6]</b> Zhou E, Fan H, Cao Z, et al.Extensive facial landmark localization with coarse-to-fine convolutional network cascade[C].Charlotte:IEEE International Conference on Computer Vision Workshops, 2013.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Surpassing Human-Level Face Verifica-tion Performance on LFW with Gaussian Face">

                                <b>[7]</b> Lu C, Tang X.Surpassing human-level face verification performance on LFW with GaussianFace[J].Computer Science, 2014 (7) :3811-3819.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning hierarchical representations for face verification with convolutional deep belief networks">

                                <b>[8]</b> Huang G B, Lee H, Learned-Miller E.Learning hierarchical representations for face verification with convolutional deep belief networks[C].Cleveland:IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, 2012.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint Deep Learning for Pedestrian Detection">

                                <b>[9]</b> Ouyang W, Wang X.Joint deep learning for pedestrian detection[C].Beijing:IEEE International Conference on Computer Vision, IEEE, 2014.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition">

                                <b>[10]</b> Liu M, Shan S, Wang R, et al.Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition[C].Albuquerque:IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, 2014.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDYY201705009&amp;v=MTUwOTE0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9tVzd6S1B5blNkN0c0SDliTXFvOUZiWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 冯建洋, 谌海云.基于人工神经网络的人脸识别研究[J].自动化与仪器仪表, 2017 (5) :24-26.Feng Jianyang, Chen Haiyun.Research on face recognition based on artificial neural network[J].Automation and Instruments, 2017 (5) :24-26.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201708003&amp;v=MjIzMzM0OUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeS9tVzd6S0lUZkFaYkc0SDliTXA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 甘航萍, 王力, 何庆, 等.基于凸轮权重距离局部保持投影算法的人脸识别[J].电子科技, 2017, 30 (8) :6-8.Gan Hangping, Wang Li, He Qing, et al.Face recognition based on cam weighted distance local preservation projection algorithms[J].Electronic Science and Technology, 2017, 30 (8) :6-8.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Learning Face Representation from Predicting 10,000 Classes">

                                <b>[13]</b> Sun Y, Wang X, Tang X.Deep learning face representation from predicting 10, 000 classes[C].Virginia:Computer Vision and Pattern Recognition, IEEE, 2014.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201802021&amp;v=MDE5ODBOalRNZDdHNEg5bk1yWTlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkvbVc3eks=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 侯小毛, 徐仁伯.云环境中考虑隐私保护的人脸图像识别[J].沈阳工业大学学报, 2018 (2) :99-104.Hou Xiaomao, Xu Renbo.Face image recognition considering privacy protection in cloud environment[J].Journal of Shenyang University of Technology, 2018 (2) :99-104.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201617047&amp;v=MzAxMDRSN3FmWnVacEZ5L21XN3pLSWpyUGRMRzRIOWZOcUk5Qlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 廖延娜, 马超.基于稀疏表示的人脸识别系统设计与实现[J].电子设计工程, 2016, 24 (17) :153-155.Liao Yanna, Ma Chao.Design and implementation of face recognition system based on sparse representation[J].Electronic Design Engineering, 2016, 24 (17) :153-155.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZKK201906018" />
        <input id="dpi" type="hidden" value="399" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201906018&amp;v=MTMxNzlHRnJDVVI3cWZadVpwRnkvbVc3ektJVGZBWmJHNEg5ak1xWTlFYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEkxbmYxYzdzR0dyZ1pjdDhmMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

