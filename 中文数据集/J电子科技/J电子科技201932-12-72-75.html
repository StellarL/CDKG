

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139158423857500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZKK201912016%26RESULT%3d1%26SIGN%3dpnk%252fMGOuprmhCfdbkdFo4S5UApc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201912016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201912016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201912016&amp;v=MTQwMDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXJoVmJ6TElUZkFaYkc0SDlqTnJZOUVZb1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#24" data-title="&lt;b&gt;1&lt;/b&gt; 工作流程 "><b>1</b> 工作流程</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;2&lt;/b&gt; 相机标定 "><b>2</b> 相机标定</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="&lt;b&gt;3&lt;/b&gt; 定位原理 "><b>3</b> 定位原理</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;3.1&lt;/b&gt; 图像识别"><b>3.1</b> 图像识别</a></li>
                                                <li><a href="#46" data-title="&lt;b&gt;3.2&lt;/b&gt; 图像预处理"><b>3.2</b> 图像预处理</a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;3.3&lt;/b&gt; 工件定位"><b>3.3</b> 工件定位</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#64" data-title="&lt;b&gt;4&lt;/b&gt; 定位实验 "><b>4</b> 定位实验</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="&lt;b&gt;5&lt;/b&gt; 结束语 "><b>5</b> 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#26" data-title="图1 工件抓取系统流程图">图1 工件抓取系统流程图</a></li>
                                                <li><a href="#29" data-title="图2 单镜头相机的成像模型">图2 单镜头相机的成像模型</a></li>
                                                <li><a href="#41" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;相机标定参数结果&lt;/b&gt;"><b>表</b>1 <b>相机标定参数结果</b></a></li>
                                                <li><a href="#53" data-title="图3 基于CAD模型的工件姿态定位算法流程">图3 基于CAD模型的工件姿态定位算法流程</a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;基于&lt;/b&gt;CAD&lt;b&gt;模型的工件定位实验数据&lt;/b&gt;"><b>表</b>2 <b>基于</b>CAD<b>模型的工件定位实验数据</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;基于先验性关系的工件定位实验数据&lt;/b&gt;"><b>表</b>3 <b>基于先验性关系的工件定位实验数据</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" 张振.基于单目视觉的工件位姿识别与抓取系统[D].杭州:中国计量大学,2016.Zhang Zheng.Workpiece pose recognition and grasping system based on monocular vision [D].Hangzhou:China University of Metrology,2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016287146.nh&amp;v=MDU3MzVxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmhWYnpLVkYyNkdMR3dHZERJcVpFYlBJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         张振.基于单目视觉的工件位姿识别与抓取系统[D].杭州:中国计量大学,2016.Zhang Zheng.Workpiece pose recognition and grasping system based on monocular vision [D].Hangzhou:China University of Metrology,2016.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" 严卫生,高智,杨小龙,等.面向AUV自主回收的单目视觉定位算法[J].电子设计工程,2014(22):174-176.Yan Weisheng,Gao Zhi,Yang Xiaolong,et al.Monocular vision localization algorithm for AUV self-recovery[J].Electronic Design Engineering,2014(22):174-176." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201422054&amp;v=MDAwMDBJanJQZExHNEg5WE9yWTlBWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyaFZieks=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         严卫生,高智,杨小龙,等.面向AUV自主回收的单目视觉定位算法[J].电子设计工程,2014(22):174-176.Yan Weisheng,Gao Zhi,Yang Xiaolong,et al.Monocular vision localization algorithm for AUV self-recovery[J].Electronic Design Engineering,2014(22):174-176.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" 朱统帅,徐维荣,莫锦秋.基于单目立体视觉的顶层工件定位方法[J].机械设计与研究,2017(4):49-52,57.Zhu Tongshuai,Xu Weirong,Mo Jinqiu.Top-level workpiece location method based on monocular stereo vision[J].Mechanical Design and Research,2017(4):49-52,57." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYY201704014&amp;v=MTc1MDFyQ1VSN3FmWnVacEZ5cmhWYnpLTHo3U2Q3RzRIOWJNcTQ5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         朱统帅,徐维荣,莫锦秋.基于单目立体视觉的顶层工件定位方法[J].机械设计与研究,2017(4):49-52,57.Zhu Tongshuai,Xu Weirong,Mo Jinqiu.Top-level workpiece location method based on monocular stereo vision[J].Mechanical Design and Research,2017(4):49-52,57.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" 张驰,廖华丽,周军.基于单目视觉的工业机器人智能抓取系统设计[J].机电工程,2018,35(3):283-287.Zhang Chi,Liao Huahua,Zhou Jun.Design of intelligent grasping system for industrial robots based on monocular vision[J].Mechatronics Engineering,2018,35(3):283-287." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDGC201803014&amp;v=MjUxNDZHNEg5bk1ySTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyaFZiektMeW5NYmI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         张驰,廖华丽,周军.基于单目视觉的工业机器人智能抓取系统设计[J].机电工程,2018,35(3):283-287.Zhang Chi,Liao Huahua,Zhou Jun.Design of intelligent grasping system for industrial robots based on monocular vision[J].Mechatronics Engineering,2018,35(3):283-287.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" 陈宗海,洪洋,王纪凯,等.基于循环卷积神经网络的单目视觉里程计[J].机器人,2019,41(2):147-155.Chen Zonghai,Hong Yang,Wang Jikai,et al.Monocular visual odometer based on cyclic convolution neural network[J].Robot,2019,41(2):147-155." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201902002&amp;v=MTU0NzVoVmJ6S0x6elpmTEc0SDlqTXJZOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         陈宗海,洪洋,王纪凯,等.基于循环卷积神经网络的单目视觉里程计[J].机器人,2019,41(2):147-155.Chen Zonghai,Hong Yang,Wang Jikai,et al.Monocular visual odometer based on cyclic convolution neural network[J].Robot,2019,41(2):147-155.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" 程亚军,任小洪,蔡绍堂,等.基于级联神经网络的单目视觉目标定位[J].自动化与仪器仪表,2018(5):14-17,23.Cheng Yajun,Ren Xiaohong,Cai Shaotang,et al.Monocular vision target location based on cascaded neural network[J].Automation and Instrumentation,2018(5):14-17,23." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=ZDYY201805004&amp;v=Mjk3Njk5bk1xbzlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyaFZiektQeW5TZDdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         程亚军,任小洪,蔡绍堂,等.基于级联神经网络的单目视觉目标定位[J].自动化与仪器仪表,2018(5):14-17,23.Cheng Yajun,Ren Xiaohong,Cai Shaotang,et al.Monocular vision target location based on cascaded neural network[J].Automation and Instrumentation,2018(5):14-17,23.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" 李星云,李众立,廖晓波.基于单目视觉的工业机器人定位系统的设计[J].机床与液压,2015,43(9):35-38.Li Xingyun,Li Zhongli,Liao Xiaobo.Design of industrial robot positioning system based on monocular vision[J].Machine Tool and Hydraulic,2015,43(9):35-38." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JCYY201509010&amp;v=MDQ5ODI3U2Q3RzRIOVRNcG85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmhWYnpLTHk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         李星云,李众立,廖晓波.基于单目视觉的工业机器人定位系统的设计[J].机床与液压,2015,43(9):35-38.Li Xingyun,Li Zhongli,Liao Xiaobo.Design of industrial robot positioning system based on monocular vision[J].Machine Tool and Hydraulic,2015,43(9):35-38.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" 汤月娟,徐晶,司书哲,等.一种基于NAO机器人的单目视觉目标定位方法[J].长春理工大学学报(自然科学版),2014(5):95-98.Tang Yuejuan,Xu Jing,Si Shuzhe,et al.A monocular vision target location method based on NAO robot[J].Journal of Changchun University of Technology(Natural Science Edition),2014(5):95-98." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGJM201405026&amp;v=MjEzMzJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmhWYnpLSmlyQlk3RzRIOVhNcW85SFlvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         汤月娟,徐晶,司书哲,等.一种基于NAO机器人的单目视觉目标定位方法[J].长春理工大学学报(自然科学版),2014(5):95-98.Tang Yuejuan,Xu Jing,Si Shuzhe,et al.A monocular vision target location method based on NAO robot[J].Journal of Changchun University of Technology(Natural Science Edition),2014(5):95-98.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" 翟敬梅,董鹏飞,张铁.基于视觉引导的工业机器人定位抓取系统设计[J].机械设计与研究,2014(5):45-49.Zhai Jingmei,Dong Pengfei,Zhang Tie.Design of industrial robot positioning and grasping system based on vision guidance[J].Mechanical Design and Research,2014(5):45-49." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYY201405018&amp;v=MTAwMzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyaFZiektMejdTZDdHNEg5WE1xbzlFYkk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         翟敬梅,董鹏飞,张铁.基于视觉引导的工业机器人定位抓取系统设计[J].机械设计与研究,2014(5):45-49.Zhai Jingmei,Dong Pengfei,Zhang Tie.Design of industrial robot positioning and grasping system based on vision guidance[J].Mechanical Design and Research,2014(5):45-49.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" 敬泽,薛方正,李祖枢.基于单目视觉的空间目标位置测量[J].传感器与微系统,2011,30(3):125-127.Jing Ze,Xue Fangzheng,Li Zushu.Position measurement of spatial targets based on monocular vision[J].Sensors and Microsystems,2011,30(3):125-127." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201103039&amp;v=MjgxNzVxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmhWYnpLSmlyYVpMRzRIOURNckk5R2JZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         敬泽,薛方正,李祖枢.基于单目视觉的空间目标位置测量[J].传感器与微系统,2011,30(3):125-127.Jing Ze,Xue Fangzheng,Li Zushu.Position measurement of spatial targets based on monocular vision[J].Sensors and Microsystems,2011,30(3):125-127.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZKK" target="_blank">电子科技</a>
                2019,32(12),72-75 DOI:10.16180/j.cnki.issn1007-7820.2019.12.015            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于单目视觉的工件定位技术研究</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E4%BA%91%E8%BE%89&amp;code=36955260&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨云辉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%91%E5%8D%97%E5%BC%80%E6%94%BE%E5%A4%A7%E5%AD%A6%E6%9C%BA%E7%94%B5%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1698867&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">云南开放大学机电工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对普通工件的位姿定位问题,文中提出了一种使用单目视觉平台和CAD模型的工件定位方案。为了阐明该方案的具体设计,基于单目相机的标定方法引入工件图像识别的相关技术,设计了工件的图像预处理过程,并提出基于CAD模型的单目视觉定位算法。实验测试结果表明,与基于先验性关系的定位方案相比,该定位方案具有更高的精度和较好的灵活性,可以满足普通工件的定位需要。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E4%BA%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器人;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%95%E7%9B%AE%E8%A7%86%E8%A7%89&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">单目视觉;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8D%E5%A7%BF%E5%AE%9A%E4%BD%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">位姿定位;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨云辉(1975-),女,实验师。研究方向:机械加工与制造技术。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-19</p>

                    <p>

                            <b>基金：</b>
                                                        <span>云南开放大学机电工程学院液压实验室建设项目(YNTTCG20180565);</span>
                    </p>
            </div>
                    <h1><b>Research on Workpiece Location Technology Based on Monocular Vision</b></h1>
                    <h2>
                    <span>YANG Yunhui</span>
            </h2>
                    <h2>
                    <span>Shool of Mechanical and Electrical Engineering,Yunnan Open University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of position and pose location of common workpiece, a workpiece location scheme using monocular vision platform and CAD model was proposed. In order to clarify the specific design of this scheme, this paper introduced the calibration method of monocular camera, the related technology of workpiece image recognition, designed the image preprocessing process of workpiece, and finally proposed a monocular vision localization algorithm based on CAD model. The experimental results showed that, compared with the location scheme based on priori relationship, the location scheme had higher accuracy and better flexibility, and could meet the needs of common workpiece location.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=industrial%20robot&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">industrial robot;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=monocular%20vision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">monocular vision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20processing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image processing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=posture%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">posture recognition;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-19</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="22">机器视觉是一种利用机器代替人类视觉进行测量和判断的方法,其主要功能是提高工业产品的制造和检测等方面的精度,从而促进自动化和人工智能等一系列领域的发展。在机器视觉的快速发展过程中,软件程序和硬件设备均不断地被更新。目前的机器视觉系统主要包括单目视觉、双目视觉、结构光视觉和深度相机等。与其他系统相比,单目视觉虽缺失与三维空间的对应信息,但这类系统具有结构简单和低成本的优点。所以其通常被应用于二维平面物体的检测,即物体表面的缺陷检测、定位、抓取或尺寸测量,尤其是在工件定位技术中。</p>
                </div>
                <div class="p1">
                    <p id="23">因为其自身的特点,单目视觉定位技术被广泛应用于机器视觉领域中<citation id="77" type="reference"><link href="2" rel="bibliography" /><link href="4" rel="bibliography" /><link href="6" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。目前,单目视觉的定位技术主要包括单帧图像、双帧图像和多帧图像<citation id="78" type="reference"><link href="8" rel="bibliography" /><link href="10" rel="bibliography" /><link href="12" rel="bibliography" /><link href="14" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。其中,单帧图像的定位技术是最成熟的,该技术主要利用点或直线来提取图像特征,在这一研究领域,大量学者进行了探索<citation id="79" type="reference"><link href="16" rel="bibliography" /><link href="18" rel="bibliography" /><link href="20" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。为进一步研究普通工件的定位技术,本文基于相机的标定方法和成像原理,阐明了普通工件的识别原理,同时分析和确定了工件图像的预处理方案,并设计了基于CAD模型的普通工件定位方案。</p>
                </div>
                <h3 id="24" name="24" class="anchor-tag"><b>1</b> 工作流程</h3>
                <div class="p1">
                    <p id="25">一般而言,工件定位技术并不是独立的系统。该技术需要与机械抓取设备配合,进行相机标定和设备校准之后,系统才能正常工作。系统工作流程为:首先,相机拍摄工件图像;然后,根据图像处理结果,对工件进行识别和定位;最后,与机器设备进行Socket通信,指挥机器手臂抓取工件。其具体流程,如图1所示。</p>
                </div>
                <div class="area_img" id="26">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201912016_026.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 工件抓取系统流程图" src="Detail/GetImg?filename=images/DZKK201912016_026.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 工件抓取系统流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201912016_026.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1. Flow chart of workpiece capture system</p>

                </div>
                <h3 id="27" name="27" class="anchor-tag"><b>2</b> 相机标定</h3>
                <div class="p1">
                    <p id="28">在现实中,相机的理想成像模型是经典的针孔模型。即把相机的镜头假想为一个针孔,将现实中的光线看作理想的直线传播。但在相机的实际工作过程中,工件的成像经常会发生难以避免的折射。所以,实际使用的成像模型需要在理想针孔模型的基础上做出一些修正。其中,单镜头相机的成像模型如图2所示。</p>
                </div>
                <div class="area_img" id="29">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201912016_029.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 单镜头相机的成像模型" src="Detail/GetImg?filename=images/DZKK201912016_029.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 单镜头相机的成像模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201912016_029.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2. Imaging model of single lens camera</p>

                </div>
                <div class="p1">
                    <p id="30">在图2中,<i>f</i>表示相机的焦距,<i>U</i>是工件到相机镜头中心点的距离,<i>f</i>+<i>V</i>表示相机镜头中心点到成像面的距离,这些参数具有如下关系</p>
                </div>
                <div class="p1">
                    <p id="31"><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mi>f</mi></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>U</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mi>f</mi><mo>+</mo><mi>V</mi></mrow></mfrac></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="32">通常,相机的参数包括内参数和外参数。其中,内参数主要包括x轴、y轴的放大系数1/d、像素物理坐标(u<sub>0</sub>,v<sub>0</sub>)。外参数主要包括旋转矩阵<i><b>r</b></i>和平移向量<i><b>t</b></i>,设像素点在相机中的坐标是(<i>u</i>,<i>v</i>),则坐标系之间的关系如下</p>
                </div>
                <div class="area_img" id="33">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201912016_03300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="35">其中,<i><b>M</b></i><sub><i>i</i></sub>和<i><b>M</b></i><sub><i>o</i></sub>是需要标定的参数,其具体公式为</p>
                </div>
                <div class="area_img" id="36">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201912016_03600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="40">为了标定相机的参数<i><b>M</b></i><sub><i>i</i></sub>和<i><b>M</b></i><sub><i>o</i></sub>,本文利用张氏标定法对定位工件的相机进行标定。张氏标定法是一种常用的相机标定方法,该方法需要使用棋盘格和线性法求解参数的初始值再进行多次迭代,从而得到高精度的内外参数。与其他标定方法相比,张氏标定法具有运算少和精度高等优点。本文使用的相机内外标定参数如表1所示。</p>
                </div>
                <div class="area_img" id="41">
                    <p class="img_tit"><b>表</b>1 <b>相机标定参数结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1. Camera calibration parameters</p>
                    <p class="img_note"></p>
                    <table id="41" border="1"><tr><td>内参</td><td>数值</td><td>外参</td><td>数值</td></tr><tr><td><br /><i>f</i></td><td>16.008</td><td><i>t</i><sub>1</sub></td><td>-97.656</td></tr><tr><td><br /><i>d</i><sub><i>x</i></sub></td><td>2.300</td><td><i>t</i><sub>2</sub></td><td>-104.007</td></tr><tr><td><br /><i>d</i><sub><i>y</i></sub></td><td>2.300</td><td><i>t</i><sub>3</sub></td><td>832.167</td></tr><tr><td><br /><i>u</i><sub>0</sub></td><td>1 306.640</td><td><i>r</i><sub>1</sub></td><td>2.240</td></tr><tr><td><br /><i>v</i><sub>0</sub></td><td>1 186.765</td><td><i>r</i><sub>1</sub></td><td>2.210</td></tr><tr><td><br /><i>K</i><sub>1</sub></td><td>0.075</td><td><i>r</i><sub>1</sub></td><td>0.069</td></tr><tr><td><br /><i>K</i><sub>2</sub></td><td>-6.450</td><td>-</td><td>-</td></tr><tr><td><br /><i>K</i><sub>3</sub></td><td>89.589</td><td>-</td><td>-</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="42" name="42" class="anchor-tag"><b>3</b> 定位原理</h3>
                <div class="p1">
                    <p id="43">基于单目视觉的工件定位的过程主要可以分为图像识别、预处理和工件定位计算等过程。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44"><b>3.1</b> 图像识别</h4>
                <div class="p1">
                    <p id="45">在工件的定位过程中,图像识别是一个分析和理解已获取图像信息的过程,同时也是一个模式识别的过程。本文主要使用了基于灰度的模式匹配方案,其过程是使用已知的物体结构信息与拍摄图像进行对比和匹配,最终从拍摄图像中识别出目标对象。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46"><b>3.2</b> 图像预处理</h4>
                <div class="p1">
                    <p id="47">在进行特征匹配之前,需要对获取的图像进行一系列的操作,该过程通常被称为图像预处理。在该过程中,常见的预处理方法主要有图像的增强、变换、消噪和滤波等。因为不同的环境可能产生不同的干扰,单一的预处理方法难以去除所有图像中的干扰因素。而本文定位对象主要是金属类工件,所以这里主要使用滤波的方法对图像进行预处理。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48"><b>3.3</b> 工件定位</h4>
                <div class="p1">
                    <p id="49">在完成图像的识别和预处理之后,本文就可以定位和抓取相应的工件。在此过程中,首先需要计算工件的形心坐标,从而确定工件的抓取位置。这里设(<i>x</i><sub>0</sub>,<i>y</i><sub>0</sub>)表示工件的形心坐标,则其计算公式为</p>
                </div>
                <div class="area_img" id="50">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201912016_05000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="52">其次,本文利用工件的CAD模型对工件进行视觉定位。为了达成这一目的,文中设置了工件三维模型的模板库,再利用匹配的方法建立相机坐标系和工件姿态的关系,具体算法可分为粗匹配和精确匹配两个阶段。其中,在粗匹配阶段中定位设备通过提取工件的角点特征获取工件的大致姿态参数;在精匹配阶段中,设备使用Leverberg-Marquardt算法进行多次迭代得到工件的精确姿态参数。这两个阶段的算法流程,如图3所示。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201912016_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于CAD模型的工件姿态定位算法流程" src="Detail/GetImg?filename=images/DZKK201912016_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 基于CAD模型的工件姿态定位算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201912016_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3. Workpiece attitude location procedure based on CAD model</p>

                </div>
                <h4 class="anchor-tag" id="54" name="54">(1)粗匹配阶段。</h4>
                <div class="p1">
                    <p id="55">在这一阶段,本文需要确定多种工件的三维模型,其实际做法是使用SolidWorks软件制作格式为stl的模型文件。在制作过程中,需要以工件的几何中心为其重心,重心到工件最长处为其半径<i>r</i>,每转动一定的角度<i>θ</i><sub><i>i</i></sub>,则利用软件进行渲染,同时记录相应的图像参数(<i>r</i>,<i>θ</i><sub><i>i</i></sub>)。最终生成所有的渲染图像序列,作为某工件的模板库。</p>
                </div>
                <div class="p1">
                    <p id="56">工件在相机坐标系中的图像参数可以用(<i>x</i>,<i>y</i>,<i>z</i>,<i>μ</i>,<i>η</i>,<i>γ</i>)表示。其中,<i>x</i><sub><i>γ</i></sub>,<i>y</i><sub><i>γ</i></sub>和<i>z</i><sub><i>γ</i></sub>分别表示工件重心在相机坐标系中的坐标,<i>μ</i>,<i>η</i>和<i>γ</i>表示工件相对于相机坐标系的<i>x</i>轴、<i>y</i>轴和<i>z</i>轴的旋转角度。这几个参数之间的关系如下</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><mo>=</mo><mrow><mi>arctan</mi></mrow><mrow><mo>(</mo><mrow><mfrac><mi>y</mi><mrow><msqrt><mrow><mi>z</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="58"><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>η</mi><mo>=</mo><mrow><mi>arctan</mi></mrow><mrow><mo>(</mo><mrow><mfrac><mi>x</mi><mi>z</mi></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="59">需要说明的是,工件相对于相机坐标系<i>z</i>轴的旋转角度<i>γ</i>通常被初始化为0。</p>
                </div>
                <h4 class="anchor-tag" id="60" name="60">(2)精匹配阶段。</h4>
                <div class="p1">
                    <p id="61">在这一阶段,算法需要把工件的大致图像参数和渲染图像进行精确匹配,计算渲染图像和实际图像的重合度函数<i>S</i><sub>sim</sub>(<i>x</i>,<i>y</i>,<i>z</i>,<i>μ</i>,<i>η</i>,<i>γ</i>)。令<i>S</i><sub>1</sub>表示实际图像中的工件面积,<i>S</i><sub>2</sub>表示渲染图像中的工件面积,<i>S</i><sub>3</sub>表示渲染图像和实际图像重合部分的面积,则其重合度函数的计算公式为</p>
                </div>
                <div class="p1">
                    <p id="62"><mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>i</mtext><mtext>m</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo>,</mo><mi>μ</mi><mo>,</mo><mi>η</mi><mo>,</mo><mi>γ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>S</mi><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo>,</mo><mi>μ</mi><mo>,</mo><mi>η</mi><mo>,</mo><mi>γ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>S</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi><mo>,</mo><mi>μ</mi><mo>,</mo><mi>η</mi><mo>,</mo><mi>γ</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="63">利用<i>Leverberg</i>-<i>Marquardt</i>算法进行多次迭代,当S<sub><i>sim</i></sub>(x,y,z,μ,η,γ)的函数值达到最大时,得到其最优参数(x<sub>0</sub>,y<sub>0</sub>,z<sub>0</sub>,μ<sub>0</sub>,η<sub>0</sub>,γ<sub>0</sub>)。</p>
                </div>
                <h3 id="64" name="64" class="anchor-tag"><b>4</b> 定位实验</h3>
                <div class="p1">
                    <p id="65">为了验证基于CAD模型的定位方案的可行性,本文利用PC计算机和UR5机器人进行了必要的定位实验。在该实验中,以PC计算机作为定位方案的客户端,以UR5机器人作为方案的服务端,设置30003端口作为二者的通信端口,使用Socket协议作为其通信方式,其实验结果如表2所示。</p>
                </div>
                <div class="area_img" id="66">
                    <p class="img_tit"><b>表</b>2 <b>基于</b>CAD<b>模型的工件定位实验数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2. Experimental data of workpiece positioning based on CAD model</p>
                    <p class="img_note"></p>
                    <table id="66" border="1"><tr><td><br />编号</td><td>实际坐标/mm</td><td>定位坐标/mm</td></tr><tr><td><br />1</td><td>(463.32,63.24,85.04)</td><td>(462.26,62.78,84.47)</td></tr><tr><td><br />2</td><td>(463.88,-34.95,83.37)</td><td>(464.33,-35.57,82.35)</td></tr><tr><td><br />3</td><td>(482.06,63.38,84.52)</td><td>(480.38,64.04,82.27)</td></tr><tr><td><br />4</td><td>(435.75,53.65,84.51)</td><td>(436.32,55.21,86.31)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="67">由表2可知,基于CAD模型的工件定位方案在<i>x</i>轴、<i>y</i>轴和<i>z</i>轴上的最大误差分别为1.68 mm、1.56 mm和2.25 mm。</p>
                </div>
                <div class="p1">
                    <p id="68">另外,为了与该实验进行对比,本文还进行了对照实验。在对照实验中,使用了基于先验性关系的工件定位方法,其他设备参数均与上面的实验保持一致,相应的数据如表3所示。</p>
                </div>
                <div class="area_img" id="69">
                    <p class="img_tit"><b>表</b>3 <b>基于先验性关系的工件定位实验数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3. Laboratory data of workpiece location based on priori relationship</p>
                    <p class="img_note"></p>
                    <table id="69" border="1"><tr><td><br />编号</td><td>实际坐标/mm</td><td>定位坐标/mm</td></tr><tr><td><br />1</td><td>(435.64,25.23,83.41)</td><td>(434.87,24.95,83.49)</td></tr><tr><td><br />2</td><td>(463.70,23.51,79.18)</td><td>(465.84,25.32,82.17)</td></tr><tr><td><br />3</td><td>(427.99,-32.44,83.42)</td><td>(428.48,-31.38,84.16)</td></tr><tr><td><br />4</td><td>(465.48,-19.12,84.22)</td><td>(464.76,-18.74,84.32)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="70">由表3可知,基于先验性关系的工件定位方案在<i>x</i>轴、<i>y</i>轴和<i>z</i>轴上的最大误差分别为2.14 mm、1.81 mm和2.99 mm。通过与CAD模型的定位方案的误差对比可知,基于CAD模型的工件定位方案具有更高的精度。所以,该方案在工件定位方面的性能更为优秀。</p>
                </div>
                <h3 id="71" name="71" class="anchor-tag"><b>5</b> 结束语</h3>
                <div class="p1">
                    <p id="72">通过阐述单目相机的标定、工件图像识别和预处理等过程,本文设计了基于CAD模型的单目视觉定位方案。该方案的特点在于采用了粗匹配、精匹配和L-M算法实现工件的精确定位,对于后续的研究和实验,这样的处理方法具有一定的借鉴和参考意义,同时也存在较大的优化空间。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016287146.nh&amp;v=MDY5NjRHTEd3R2RESXFaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXJoVmJ6S1ZGMjY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 张振.基于单目视觉的工件位姿识别与抓取系统[D].杭州:中国计量大学,2016.Zhang Zheng.Workpiece pose recognition and grasping system based on monocular vision [D].Hangzhou:China University of Metrology,2016.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201422054&amp;v=Mjk0ODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXJoVmJ6S0lqclBkTEc0SDlYT3JZOUFZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 严卫生,高智,杨小龙,等.面向AUV自主回收的单目视觉定位算法[J].电子设计工程,2014(22):174-176.Yan Weisheng,Gao Zhi,Yang Xiaolong,et al.Monocular vision localization algorithm for AUV self-recovery[J].Electronic Design Engineering,2014(22):174-176.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYY201704014&amp;v=MjQ1MjBGckNVUjdxZlp1WnBGeXJoVmJ6S0x6N1NkN0c0SDliTXE0OUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 朱统帅,徐维荣,莫锦秋.基于单目立体视觉的顶层工件定位方法[J].机械设计与研究,2017(4):49-52,57.Zhu Tongshuai,Xu Weirong,Mo Jinqiu.Top-level workpiece location method based on monocular stereo vision[J].Mechanical Design and Research,2017(4):49-52,57.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDGC201803014&amp;v=MTc0OTh0R0ZyQ1VSN3FmWnVacEZ5cmhWYnpLTHluTWJiRzRIOW5Nckk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 张驰,廖华丽,周军.基于单目视觉的工业机器人智能抓取系统设计[J].机电工程,2018,35(3):283-287.Zhang Chi,Liao Huahua,Zhou Jun.Design of intelligent grasping system for industrial robots based on monocular vision[J].Mechatronics Engineering,2018,35(3):283-287.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JQRR201902002&amp;v=MTYyNzJyWTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyaFZiektMenpaZkxHNEg5ak0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 陈宗海,洪洋,王纪凯,等.基于循环卷积神经网络的单目视觉里程计[J].机器人,2019,41(2):147-155.Chen Zonghai,Hong Yang,Wang Jikai,et al.Monocular visual odometer based on cyclic convolution neural network[J].Robot,2019,41(2):147-155.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=ZDYY201805004&amp;v=MDY4MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmhWYnpLUHluU2Q3RzRIOW5NcW85RllJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 程亚军,任小洪,蔡绍堂,等.基于级联神经网络的单目视觉目标定位[J].自动化与仪器仪表,2018(5):14-17,23.Cheng Yajun,Ren Xiaohong,Cai Shaotang,et al.Monocular vision target location based on cascaded neural network[J].Automation and Instrumentation,2018(5):14-17,23.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JCYY201509010&amp;v=MDMzNTZWYnpLTHk3U2Q3RzRIOVRNcG85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 李星云,李众立,廖晓波.基于单目视觉的工业机器人定位系统的设计[J].机床与液压,2015,43(9):35-38.Li Xingyun,Li Zhongli,Liao Xiaobo.Design of industrial robot positioning system based on monocular vision[J].Machine Tool and Hydraulic,2015,43(9):35-38.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGJM201405026&amp;v=MTE2ODJDVVI3cWZadVpwRnlyaFZiektKaXJCWTdHNEg5WE1xbzlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 汤月娟,徐晶,司书哲,等.一种基于NAO机器人的单目视觉目标定位方法[J].长春理工大学学报(自然科学版),2014(5):95-98.Tang Yuejuan,Xu Jing,Si Shuzhe,et al.A monocular vision target location method based on NAO robot[J].Journal of Changchun University of Technology(Natural Science Edition),2014(5):95-98.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYY201405018&amp;v=MDY5NjNTZDdHNEg5WE1xbzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpwRnlyaFZiektMejc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 翟敬梅,董鹏飞,张铁.基于视觉引导的工业机器人定位抓取系统设计[J].机械设计与研究,2014(5):45-49.Zhai Jingmei,Dong Pengfei,Zhang Tie.Design of industrial robot positioning and grasping system based on vision guidance[J].Mechanical Design and Research,2014(5):45-49.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201103039&amp;v=MzI2NDVMRzRIOURNckk5R2JZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5cmhWYnpLSmlyYVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 敬泽,薛方正,李祖枢.基于单目视觉的空间目标位置测量[J].传感器与微系统,2011,30(3):125-127.Jing Ze,Xue Fangzheng,Li Zushu.Position measurement of spatial targets based on monocular vision[J].Sensors and Microsystems,2011,30(3):125-127.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZKK201912016" />
        <input id="dpi" type="hidden" value="299" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201912016&amp;v=MTQwMDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeXJoVmJ6TElUZkFaYkc0SDlqTnJZOUVZb1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

