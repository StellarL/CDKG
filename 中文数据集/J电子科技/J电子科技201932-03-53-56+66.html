

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139888875888750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZKK201903012%26RESULT%3d1%26SIGN%3dZ8ozO12O0rtKZCS2P6yXlk1q7CU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201903012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201903012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201903012&amp;v=MDQ2MDBGckNVUjdxZlp1Wm9GeW5sVnJyQklUZkFaYkc0SDlqTXJJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#38" data-title="&lt;b&gt;1&lt;/b&gt;&lt;b&gt;全卷积层的神经网络结构&lt;/b&gt; "><b>1</b><b>全卷积层的神经网络结构</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="&lt;b&gt;2&lt;/b&gt;&lt;b&gt;批量归一化&lt;/b&gt; "><b>2</b><b>批量归一化</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="&lt;b&gt;3&lt;/b&gt;&lt;b&gt;改进的&lt;/b&gt;&lt;i&gt;LeNet&lt;/i&gt;&lt;b&gt;网络结构&lt;/b&gt; "><b>3</b><b>改进的</b><i>LeNet</i><b>网络结构</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="&lt;b&gt;4&lt;/b&gt;&lt;b&gt;实验及结果分析&lt;/b&gt; "><b>4</b><b>实验及结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#69" data-title="&lt;b&gt;4.1&lt;/b&gt;&lt;b&gt;实验数据集&lt;/b&gt;"><b>4.1</b><b>实验数据集</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;4.2&lt;/b&gt;&lt;b&gt;网络实现&lt;/b&gt;"><b>4.2</b><b>网络实现</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;4.3&lt;/b&gt;&lt;b&gt;结果与分析&lt;/b&gt;"><b>4.3</b><b>结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="&lt;b&gt;5&lt;/b&gt;&lt;b&gt;结束语&lt;/b&gt; "><b>5</b><b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#65" data-title="图1 改进的LeNet网络结构">图1 改进的LeNet网络结构</a></li>
                                                <li><a href="#68" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;软硬件环境&lt;/b&gt;"><b>表</b>1 <b>软硬件环境</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;网络参数&lt;/b&gt;"><b>表</b>2 <b>网络参数</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;表&lt;/b&gt;3 4&lt;b&gt;个网络模型的准确率&lt;/b&gt;"><b>表</b>3 4<b>个网络模型的准确率</b></a></li>
                                                <li><a href="#84" data-title="图2 收敛速度">图2 收敛速度</a></li>
                                                <li><a href="#87" data-title="图3 训练时间">图3 训练时间</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     Lecun Y, Bengio Y, Hinton G. Deep learning[J].Nature, 2015, 521 (7553) :436-444.</a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     Lecun Y, Bottou L, Bengio Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.</a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 熊海朋, 陈洋洋, 陈春玮.基于卷积神经网络的场景图像文本定位研究[J].电子科技, 2018, 31 (1) :50-53. Xiong Haipeng, Chen Yangyang, Chen Chunwei.Text location in image based on convolution neural network[J].Electronic Science and Technology, 2018, 31 (1) :50-53." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201801014&amp;v=MjQ5MTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmxWcnJBSVRmQVpiRzRIOW5Ncm85RVk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         熊海朋, 陈洋洋, 陈春玮.基于卷积神经网络的场景图像文本定位研究[J].电子科技, 2018, 31 (1) :50-53. Xiong Haipeng, Chen Yangyang, Chen Chunwei.Text location in image based on convolution neural network[J].Electronic Science and Technology, 2018, 31 (1) :50-53.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Krizhevsky A, Sutskever I, Hinton G E.ImageNet classification with deep convolutional neural networks[C]. Lake Tahoe:International Conference on Neural Information Processing Systems, 2012." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">
                                        <b>[4]</b>
                                         Krizhevsky A, Sutskever I, Hinton G E.ImageNet classification with deep convolutional neural networks[C]. Lake Tahoe:International Conference on Neural Information Processing Systems, 2012.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Simonyan K, Zisserman A.Very deep convolutional networks for large-scale image recognition[J].arXiv Preprint arXiv, 2014, 1409 (1556) :1-14." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[5]</b>
                                         Simonyan K, Zisserman A.Very deep convolutional networks for large-scale image recognition[J].arXiv Preprint arXiv, 2014, 1409 (1556) :1-14.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     Szegedy C, Liu W, Jia Y, et al.Going deeper with convolutions[C].Boston:Computer Vision and Pattern Recognition IEEE, 2015.</a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     He K, Zhang X, Ren S, et al.Deep residual learning for image recognition[C].Las Vegas:IEEE Conference on Computer Vision and Pattern Recognition, 2016.</a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Springenberg J T, Dosovitskiy A, Brox T, et al.Striving for simplicity: the all convolutional net[J].arXiv Preprint arXiv, 2014, 1412 (6806) :1-14." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Striving for simplicity: the all convolutional net">
                                        <b>[8]</b>
                                         Springenberg J T, Dosovitskiy A, Brox T, et al.Striving for simplicity: the all convolutional net[J].arXiv Preprint arXiv, 2014, 1412 (6806) :1-14.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Goodfellow I J, Warde-Farley D, Mirza M, et al. Maxout networks[J].arXiv Preprint arXiv, 2013, 1302 (4389) :1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Maxout networks">
                                        <b>[9]</b>
                                         Goodfellow I J, Warde-Farley D, Mirza M, et al. Maxout networks[J].arXiv Preprint arXiv, 2013, 1302 (4389) :1-9.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Lin M, Chen Q, Yan S.Network in network[J].arXiv preprint arXiv, 2013, 1312 (4400) :1-10." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Network in network">
                                        <b>[10]</b>
                                         Lin M, Chen Q, Yan S.Network in network[J].arXiv preprint arXiv, 2013, 1312 (4400) :1-10.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Srivastava N, Salakhutdinov R.Discriminative transfer learning with tree-based priors[C].Lake Tahoe:Advances in Neural Information Processing Systems, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative Transfer Learning with Tree-based Priors">
                                        <b>[11]</b>
                                         Srivastava N, Salakhutdinov R.Discriminative transfer learning with tree-based priors[C].Lake Tahoe:Advances in Neural Information Processing Systems, 2013.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Zeiler M D, Fergus R.Stochastic pooling for regularization of deep convolutional neural networks[J].arXiv Preprint arXiv, 2013, 1301 (3557) :1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stochastic pooling for regularization of deep convolutional neural networks">
                                        <b>[12]</b>
                                         Zeiler M D, Fergus R.Stochastic pooling for regularization of deep convolutional neural networks[J].arXiv Preprint arXiv, 2013, 1301 (3557) :1-9.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Lee C Y, Xie S, Gallagher P, et al.Deeply-supervised nets[J]. arXiv Preprint arXiv, 2015, 1409 (5185) :1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deeply-supervised nets">
                                        <b>[13]</b>
                                         Lee C Y, Xie S, Gallagher P, et al.Deeply-supervised nets[J]. arXiv Preprint arXiv, 2015, 1409 (5185) :1-9.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     Ioffe S, Szegedy C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C].Lille:International Conference on Machine Learning, 2015.</a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 周飞燕, 金林鹏, 董军.卷积神经网络研究综述[J].计算机学报, 2017, 40 (6) :1229-1251. Zhou Feiyan, Jin Linpeng, Dong Jun.Review of convolutional neural network[J].Chinese Journal of Computers, 2017, 40 (6) :1229-1251." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201706001&amp;v=MDgxNDU3cWZadVpvRnlubFZyckFMejdCZHJHNEg5Yk1xWTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         周飞燕, 金林鹏, 董军.卷积神经网络研究综述[J].计算机学报, 2017, 40 (6) :1229-1251. Zhou Feiyan, Jin Linpeng, Dong Jun.Review of convolutional neural network[J].Chinese Journal of Computers, 2017, 40 (6) :1229-1251.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Sutskever I, Martens J, Dahl G, et al. On the importance of initialization and momentum in deep learning[C].Atlanta: International Conference on Machine Learning, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the importance of initialization and momentum in deep learning">
                                        <b>[16]</b>
                                         Sutskever I, Martens J, Dahl G, et al. On the importance of initialization and momentum in deep learning[C].Atlanta: International Conference on Machine Learning, 2013.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZKK" target="_blank">电子科技</a>
                2019,32(03),53-56+66 DOI:10.16180/j.cnki.issn1007-7820.2019.03.011            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种改进的</b>LeNet<b>网络</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E5%BE%B7%E6%95%8F&amp;code=09616980&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡德敏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E6%99%AE%E8%8A%B3&amp;code=41267702&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程普芳</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0256814&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海理工大学光电信息与计算机工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对卷积神经网络中存在的学习效率低、收敛速度慢、训练时间长等问题, 文中提出一种改进的LeNet卷积神经网络模型。该模型使用卷积核大小为3, 步幅为2的卷积层代替原有的池化层, 并在每层激活函数之前添加批量归一化层。在Mnist和Cifar-10数据集上放入实验证明, 相比于传统的LeNet网络, 所提出的卷积神经网络提高了分类准确率, 并且具有更快的收敛速度及更短的训练时间。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">批量归一化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B1%A0%E5%8C%96%E5%B1%82&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">池化层;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E6%A0%B8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积核;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机梯度下降法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    胡德敏 (1963-) , 男, 博士, 副教授。研究方向:计算机网络、分布式计算、云计算。;
                                </span>
                                <span>
                                    程普芳 (1991-) , 男, 硕士研究生。研究方向:图像分类、深度学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-03-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61170277, 61472256);</span>
                                <span>上海市教委科研创新重点项目 (12zz17);</span>
                                <span>上海市一流学科建设项目 (S1201YLXK);</span>
                    </p>
            </div>
                    <h1><b>An Improved LeNet Network</b></h1>
                    <h2>
                    <span>HU Demin</span>
                    <span>CHENG Pufang</span>
            </h2>
                    <h2>
                    <span>School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problems of low learning efficiency, slow convergence and long training time in convolutional neural networks, this paper presented an improved LeNet convolutional neural network model. The model used a convolutional kernel whose convolution scale was set as 3 and stride was set as 2 instead of the original pooled layer, and added a batch normalization layer before each activation function layer. Experiments on the Mnist dataset showed that compared with the traditional LeNet network, the convolutional neural network proposed in this paper improved the accuracy rate and had faster convergence speed and shorter training time.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=batch%20normalization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">batch normalization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=pooling%20layer&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">pooling layer;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolution%20kernel&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolution kernel;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=stochastic%20gradient%20descent&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">stochastic gradient descent;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-03-18</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>National Natural Science Foundation of China (61170277, 61472256);</span>
                                <span>Key Project of Scientific Research and Innovation of Shanghai Municipal Education Commission (12zz17);</span>
                                <span>First Class Construction Project of Shanghai (S1201YLXK);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="35">在计算机视觉领域中, 图像特征的提取及分类是极为重要的一个研究方向。卷积神经网络<citation id="103" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation> (Convolutional Neural Network, CNN) 不需要对数据进行任何处理就可将其直接输入至网络模型中, 根据图像特征自动学习, 具有很强的鲁棒性。因此, CNN逐渐成为图像识别领域中重要的方法之一。目前, CNN的研究主要集中在两个方向, 一是在结构上做改进, 二是在训练上做提高。</p>
                </div>
                <div class="p1">
                    <p id="36">Krizhevsky等人<citation id="110" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出AlexNet, 通过添加Dropout、Data Augmentation防止过拟合问题, 通过更换激活函数解决梯度弥散问题, 通过大数据量提高训练准确率。Simonyan等人<citation id="108" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出使用较小尺寸的卷积核以加深网络深度, 从而提高了准确率。Szegedy等人<citation id="109" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出在不增加计算资源需求的前提下, 通过改进神经网络的结构提高网络的深度, 从而达到提高效果的目的。He K等人<citation id="104" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>设计的残差块结构直接将Top-5错误率降到了3.57%。Springenberg等人<citation id="105" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>通过实验证明池化层并不是必须的, 使用步幅大于1的卷积层完全可以代替池化层而不损失性能。即便如此, CNN在训练上也存在着如网络收敛过慢、梯度学习参数率较小、训练时间过长、网络层数加深导致梯度弥散、过度拟合等问题。文献<citation id="107" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</citation>提出通过使用更复杂的激活函数来提高性能。Zeiler 等人<citation id="111" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>通过使用归一化操作使数据分布保持不变性以加快训练速度。Lee等人<citation id="112" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>使用标签信息做层次预训练。Ioffe等人<citation id="106" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>则通过使用批量归一化来使数据保持分布不变性, 大幅提高了训练速度。</p>
                </div>
                <div class="p1">
                    <p id="37">本文提出了一种改进的LeNet网络, 即使用卷积层代替原有的池化层, 在每层输入之前添加批量归一化层。在Mnist数据集上的实验证明, 本文所提出的卷积神经网络相比传统的LeNet网络, 拥有更高的准确率、更快的收敛速度以及及更短的训练时间。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag"><b>1</b><b>全卷积层的神经网络结构</b></h3>
                <div class="p1">
                    <p id="39">传统CNN<citation id="113" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>结构包括卷积层、池化层、全连接层三个部分。池化层的操作可以用下面式 (1) 表示</p>
                </div>
                <div class="p1">
                    <p id="40"><mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>u</mi></mrow></msub><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow><mrow><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow></munderover><mspace width="0.25em" /></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>w</mi><mo>=</mo><mo>-</mo><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow><mrow><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow></munderover><mo stretchy="false">|</mo></mstyle><mi>f</mi><msub><mrow></mrow><mrow><mi>g</mi><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>w</mi><mo>, </mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>u</mi><mo stretchy="false">) </mo></mrow></msub><mo stretchy="false">|</mo><msup><mrow></mrow><mi>p</mi></msup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow></msup></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="42">式中<i>g</i> (<i>h</i>, <i>w</i>, <i>i</i>, <i>j</i>, <i>u</i>) 是从<i>s</i>到<i>f</i>的函数映射, <i>p</i>是<i>p</i>范数的大小。当<i>p</i>趋于无穷大时, 该结构即为常用的最大池, 池化大小为<i>k</i> (或<i>k</i>/2) , 步幅为<i>r</i>。</p>
                </div>
                <div class="p1">
                    <p id="43">卷积层的操作可以用式 (2) 表示</p>
                </div>
                <div class="p1">
                    <p id="44"><mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>o</mi></mrow></msub><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>h</mi><mo>=</mo><mo>-</mo><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow><mrow><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow></munderover><mspace width="0.25em" /></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>w</mi><mo>=</mo><mo>-</mo><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow><mrow><mo>⌊</mo><mi>k</mi><mo>/</mo><mn>2</mn><mo>⌋</mo></mrow></munderover><mspace width="0.25em" /></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>u</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>θ</mi></mstyle><msub><mrow></mrow><mrow><mi>h</mi><mo>, </mo><mi>w</mi><mo>, </mo><mi>u</mi><mo>, </mo><mi>o</mi></mrow></msub><mo>⋅</mo><mi>f</mi><msub><mrow></mrow><mrow><mi>g</mi><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>w</mi><mo>, </mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>, </mo><mi>u</mi><mo stretchy="false">) </mo></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="46">式中, <b><i>f</i></b>是CNN某一层产生的特征图, 该图可表示成一个三维阵列 (<i>W</i>和<i>H</i>分别为列阵的宽和高, <i>N</i>为通道数) , <i>θ</i>是卷积层的权重矩阵, <i>σ</i>是激活函数。如果激活函数是线性激活函数ReLU, 那么卷积层的输出特征值如式 (2) 所示。</p>
                </div>
                <div class="p1">
                    <p id="47"><i>σ</i> (<i>x</i>) =max (<i>x</i>, 0)      (3) </p>
                </div>
                <div class="p1">
                    <p id="48">由式 (1) 和式 (2) 可以发现, 以上两种操作都取决于上一层特征图的相同元素, 因此, 池化层可以看作是使用<i>p</i>范数作为激活函数的卷积层。之所以在CNN中使用池化层, 主要有以下3种原因: (1) <i>p</i>规则使CNN的分布保持不变性; (2) 通过池化进行空间降维能在较高层中覆盖大部分输入; (3) 池化操作的特征性质可以使优化更容易。</p>
                </div>
                <div class="p1">
                    <p id="49">其中第二个原因最重要, 可以使用其他方法降低维度并移除池化层。而降低维度则可以使用以下两种方法: (1) 直接删除池化层并增加对应的卷积层步幅; (2) 使用步幅大于1的正常卷积层替换池化层。例如, 对于<i>k</i>=2和<i>r</i>=3的池化层, 可以使用卷积核大小为3, 步幅为2的卷积层代替。</p>
                </div>
                <div class="p1">
                    <p id="50">第一种方法有一个严重的缺点, 该方法会显著减少池化层之前卷积层的重叠, 相当于仅考虑左上方特征响应而导致识别率降低。第二种方法保留所有现有的卷积层不变, 但会导致网络参数相对增加。因此, 本文使用第二种方法, 同时采用<i>k</i>&lt;5的小卷积核以避免网络参数增加过多。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag"><b>2</b><b>批量归一化</b></h3>
                <div class="p1">
                    <p id="52">随机梯度下降法<citation id="115" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation> (Stochastic Gradient Descent, SGD) 在CNN的训练中使用广泛, 虽然简单有效, 但仍需要人为设置参数, 导致了大量时间的浪费。在实际的训练过程中, 每一层的输入都会受之前层的参数影响, 并且随着网络不断加深, 即便是很小的参数变动, 也会严重影响网络的输入。神经网络层输入分布的改变, 使得神经网络层必须不断适应新的数据分布, 这就导致神经网络学习效率不高。为了解决这些问题, 可以使用批量归一化技术<citation id="114" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation> (Batch Normalization, BN) 。</p>
                </div>
                <div class="p1">
                    <p id="53">BN的操作为:在网络的输入层之前插入一个归一化层, 即先做归一化处理, 再进入网络的下一层。其中, 归一化至数据符合均值为0, 方差为1。对于有<i>d</i>维输入的神经网络层, 用以式 (4) 对每一维做归一化处理</p>
                </div>
                <div class="p1">
                    <p id="54"><mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mfrac><mrow><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mi>E</mi><mo stretchy="false">[</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">]</mo></mrow><mrow><msqrt><mrow><mtext>V</mtext><mtext>a</mtext><mtext>r</mtext><mo stretchy="false">[</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">]</mo></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="56">式中, x是输入, E是均值, <i>Var</i>是标准差。这种归一化处理能降低特征之间的相关性, 但可能改变该网络层的表征能力。为了防止这种情况发生, 要确保穿插在网络内部的变换能够表示同样的变换, 于是对每一个激活值都引入一对可学习的参数γ和β, 这两个参数能够缩放和平移归一化后的输入</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msup><mrow></mrow><mi>k</mi></msup><mo>=</mo><mi>γ</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mover accent="true"><mi>x</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo>+</mo><mi>β</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="59">这两个参数与模型原始的参数一起学习, 并具备恢复模型分布特征的能力。如果想要恢复原始激活值, 使用式 (6) 即可</p>
                </div>
                <div class="p1">
                    <p id="60"><mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><msqrt><mrow><mtext>V</mtext><mtext>a</mtext><mtext>r</mtext><mo stretchy="false">[</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">]</mo></mrow></msqrt><mo>, </mo><mi>β</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">]</mo></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="62">通过这一改进将不会影响该层的表征能力。</p>
                </div>
                <h3 id="63" name="63" class="anchor-tag"><b>3</b><b>改进的</b><i>LeNet</i><b>网络结构</b></h3>
                <div class="p1">
                    <p id="64">LeNet是一个经典的CNN结构, 该结构一共包含8层, 开始是输入层, 中间是3个卷积层和两个池化层, 然后是全连接层, 最后是输出层。其中卷积操作使用的卷积核大小为5, 步幅为1, 池化操作使用2×2大小的窗口。根据上述理论部分, 本文在经典LeNet网络模型的基础上做了一定的修改, 提出了改进的LeNet网络结构模型, 改进的地方有两点: (1) 使用卷积层代替池化层。如图1所示, 原来的池化层替换成了卷积层, 使用的卷积核大小为3×3, 步幅为2。之所以使用3×3大小的卷积核, 是为了防止增加的参数太多, 步幅为2可以使输出结果大小与原来一致; (2) 在卷积层和卷积层之间、卷积层和全连接层之间、全连接层和全连接层之间, 在激活函数之前添加批量归一化 (BN) 层。这些BN层共享权值, 即对于一个<i>m</i>×<i>n</i>大小的特征图, 通过训练一对可学习的参数<i>γ</i>和<i>β</i>, 来减少参数数量。添加批量归一化层使得各层输入数据的分布保持不变 (均值为0, 方差为1) , 可以允许使用更大的学习率, 可以不使用Dropout技术。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201903012_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 改进的LeNet网络结构" src="Detail/GetImg?filename=images/DZKK201903012_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 改进的LeNet网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201903012_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1. Structure of improved LeNet network</p>

                </div>
                <h3 id="66" name="66" class="anchor-tag"><b>4</b><b>实验及结果分析</b></h3>
                <div class="p1">
                    <p id="67">本实验的软硬件环境如表1所示。</p>
                </div>
                <div class="area_img" id="68">
                    <p class="img_tit"><b>表</b>1 <b>软硬件环境</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1. Hardware and Software Environment</p>
                    <p class="img_note"></p>
                    <table id="68" border="1"><tr><td><br />参数</td><td>数值</td></tr><tr><td><br />处理器</td><td>英特尔 第四代酷睿 i5-4210H @2.90 GHz</td></tr><tr><td><br />内存</td><td>12.0 GB</td></tr><tr><td><br />操作系统</td><td>WIN10 64位</td></tr><tr><td><br />编程软件</td><td>Python3.5 + TensorFlow框架 (纯CPU模式) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>4.1</b><b>实验数据集</b></h4>
                <div class="p1">
                    <p id="70">本文使用Mnist和Cifar-10数据集作为测试对象。Mnist是一个手写体数字数据库, 它有60 000个训练样本集和10 000个测试样本集。Cifar-10数据集由60 000张32×32的RGB彩色图片构成, 共10个分类, 其中有50 000张训练样本, 有10 000张测试样本 (交叉验证) 。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>4.2</b><b>网络实现</b></h4>
                <div class="p1">
                    <p id="72"><b>步骤1</b> 初始化输入。网络要求输入大小为32×32, 而Mnist的数据大小是28×28, 因此在原图像上加4层padding, padding的值全部设为0。Cifar-10不做任何预处理, 直接将图像输入网络。</p>
                </div>
                <div class="p1">
                    <p id="73"><b>步骤2</b> 初始化参数。所有卷积层和全连接层的权重矩阵 (即卷积核的数值) 全部随机生成, 不做额外的预处理。偏置项全部初始化为0.0, <i>γ</i>全部初始化为1.0, <i>β</i>全部初始化为0.0。</p>
                </div>
                <div class="p1">
                    <p id="74"><b>步骤3</b> 训练设置。激活函数使用Sigmoid函数, patch大小设置为100, 一共做6 000次迭代。在训练过程中, 每训练50个patch计算一次准确率并做记录。</p>
                </div>
                <div class="p1">
                    <p id="75">实验一共设计并训练测试了4个网络模型, 即基本的LeNet模型、仅将池化层替换为卷积层的LeNet模型、仅加入BN层的LeNet模型以及本文提出的网络模型。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76"><b>4.3</b><b>结果与分析</b></h4>
                <div class="p1">
                    <p id="77">通过以上实验, 将得出的数据总结做对比分析:</p>
                </div>
                <div class="p1">
                    <p id="78"> (1) 参数对比。本文在经典LeNet网络的基础上, 增加了一些参数, 如表2所示。</p>
                </div>
                <div class="area_img" id="79">
                    <p class="img_tit"><b>表</b>2 <b>网络参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table2. Parameters of Network</p>
                    <p class="img_note"></p>
                    <table id="79" border="1"><tr><td>LeNet层</td><td>LeNet参数</td><td>本文层级</td><td>本文结构参数</td></tr><tr><td><br />C1</td><td>156</td><td>C1</td><td>156+2+6*2</td></tr><tr><td><br />S2</td><td>0</td><td>C2</td><td>0+ (3*3+1) *6+2+6*2</td></tr><tr><td><br />C3</td><td>1516</td><td>C3</td><td>1516+2+16*2</td></tr><tr><td><br />S4</td><td>0</td><td>C4</td><td>0+ (3*3+1) *16+2+16*2</td></tr><tr><td><br />C5</td><td>48 120</td><td>C5</td><td>1 516+2+1*2</td></tr><tr><td><br />F6</td><td>10 164</td><td>F6</td><td>10 164+2+1*2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="80">由表可知, 相比原来卷积层和全连接层, 增加的参数是BN操作需要的参数, 包括:一个均值、一个方差、一对可学习参数<i>γ</i>和<i>β</i>, 其中<i>γ</i>和<i>β</i>的深度均为当前卷积层的深度。相比原来的池化层, 增加的参数包括两部分:一部分是将池化层改成卷积层后增加的参数, 大小为卷积核大小加偏置项, 再乘以卷积核的个数;另一部分是在该层后面增加BN操作的参数。</p>
                </div>
                <div class="p1">
                    <p id="81"> (2) 准确率对比。表3展示的是4个网络模型在两种数据集上的准确率对比。由于Cifar-10数据比Mnist丰富, 因此Cifar-10的准确率要低于Mnist。首先, 只去除池化层结构准确率要比LeNet高, 这说明使用卷积层代替池化层的操作是可行的, 而且能提高分类准确率。其次, 添加BN的准确率要高于LeNet, 这说明BN操作能够有效加强网络的表征能力。最后, 本文结构在Mnist上比LeNet提高了5.84%的准确率, 在Cifar-10上提高了6.62%的准确率, 具有最高的准确率, 起到最好的分类效果。</p>
                </div>
                <div class="area_img" id="82">
                    <p class="img_tit"><b>表</b>3 4<b>个网络模型的准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3. Accuracy of Four Network Models</p>
                    <p class="img_note"></p>
                    <table id="82" border="1"><tr><td><br />结构</td><td>Mnist准确率</td><td>Cifar-10准确率</td></tr><tr><td><br />LeNet</td><td>90.58%</td><td>73.46%</td></tr><tr><td><br />只去除池化层</td><td>91.80%</td><td>75.78%</td></tr><tr><td><br />只加BN</td><td>94.36%</td><td>78.69%</td></tr><tr><td><br />本文结构</td><td>96.42%</td><td>80.08%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="83"> (3) 收敛速度对比。图2展示的是在Mnist上的收敛速度走势, 其中横坐标表示训练的patch数量, 纵坐标表示当前准确率, 该图展示了10轮的训练过程。首先, 只去除池化层的情况下, 收敛速度会变慢, 这是因为使用卷积层代替池化层要多训练一些参数, 使得速度相对变慢, 但这些参数能加强网络表达能力, 所以最终准确率会高于LeNet。其次, 添加BN操作能达到不错的收敛速度, 说明归一化操作确实能提升训练速度。最后, 本文结构明显具有最快的收敛速度, 第一轮迭代就能达到83.4%的准确率, 而LeNet需要7轮训练才能达到相同的准确率, 其他两种也分别需要2轮和7轮, 这充分说明本文结构收敛速度最快。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201903012_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 收敛速度" src="Detail/GetImg?filename=images/DZKK201903012_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 收敛速度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201903012_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2. Convergence Rate</p>

                </div>
                <div class="p1">
                    <p id="85"> (4) 训练时间对比。由于本文结构相比LeNet增加了一定的计算量, 因此单个批次的训练时间必然是比LeNet长的, 但是总体的训练时间却不一定。图3 (a) 和图3 (b) 展示了达到相应准确率所需的时间。首先, 准确率每上升10%, 两条曲线的斜率也会相应增加, 证明随着准确率的上升, 训练难度会越来越大。其次, 本文结构的斜率比LeNet的斜率要小, 这说明本文结构训练的稳定性要高于LeNet。最后, 通过每个节点的时间对比, 在Mnist上本文结构比LeNet训练时间减少了将近3倍, 在Cifar-10上本文结构比LeNet训练时间减少近2倍, 证明本文结构的训练效率高于LeNet。</p>
                </div>
                <div class="p1">
                    <p id="86">通过以上实验分析可以发现, 本文结构虽然增加了一定数量的参数, 但是收敛速度更快, 在最终的训练速度上比LeNet快2～3倍, 而且准确率提高了约6%。这证明本文所提出的网络结构是一种行之有效的改进方案。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201903012_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 训练时间" src="Detail/GetImg?filename=images/DZKK201903012_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 训练时间  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201903012_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3. Training Time</p>
                                <p class="img_note"> (a) Mnist训练时间 (b) Cifar-10训练时间</p>
                                <p class="img_note"> (a) Training time of Mnist (b) Training time of Cifar-10</p>

                </div>
                <h3 id="88" name="88" class="anchor-tag"><b>5</b><b>结束语</b></h3>
                <div class="p1">
                    <p id="89">本文总结了当前卷积神经网络的相关工作, 并分析了目前该领域存在的问题, 就这些问题提出了一种改进的卷积神经网络结构。该结构去掉了网络中的池化层, 添加了批量归一化层。通过实验分析数据可知, 本文提出的结构具有更快的训练速度和更高的准确率。但是本文结构处理图像大小还不能随意设置, 因此, 在接下来的研究中将重点探索如何把改进网络应用到任意大小的图像上。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 Lecun Y, Bengio Y, Hinton G. Deep learning[J].Nature, 2015, 521 (7553) :436-444.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 Lecun Y, Bottou L, Bengio Y, et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE, 1998, 86 (11) :2278-2324.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201801014&amp;v=MDc4OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5bmxWcnJBSVRmQVpiRzRIOW5Ncm85RVlJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 熊海朋, 陈洋洋, 陈春玮.基于卷积神经网络的场景图像文本定位研究[J].电子科技, 2018, 31 (1) :50-53. Xiong Haipeng, Chen Yangyang, Chen Chunwei.Text location in image based on convolution neural network[J].Electronic Science and Technology, 2018, 31 (1) :50-53.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">

                                <b>[4]</b> Krizhevsky A, Sutskever I, Hinton G E.ImageNet classification with deep convolutional neural networks[C]. Lake Tahoe:International Conference on Neural Information Processing Systems, 2012.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[5]</b> Simonyan K, Zisserman A.Very deep convolutional networks for large-scale image recognition[J].arXiv Preprint arXiv, 2014, 1409 (1556) :1-14.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 Szegedy C, Liu W, Jia Y, et al.Going deeper with convolutions[C].Boston:Computer Vision and Pattern Recognition IEEE, 2015.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 He K, Zhang X, Ren S, et al.Deep residual learning for image recognition[C].Las Vegas:IEEE Conference on Computer Vision and Pattern Recognition, 2016.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Striving for simplicity: the all convolutional net">

                                <b>[8]</b> Springenberg J T, Dosovitskiy A, Brox T, et al.Striving for simplicity: the all convolutional net[J].arXiv Preprint arXiv, 2014, 1412 (6806) :1-14.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Maxout networks">

                                <b>[9]</b> Goodfellow I J, Warde-Farley D, Mirza M, et al. Maxout networks[J].arXiv Preprint arXiv, 2013, 1302 (4389) :1-9.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Network in network">

                                <b>[10]</b> Lin M, Chen Q, Yan S.Network in network[J].arXiv preprint arXiv, 2013, 1312 (4400) :1-10.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative Transfer Learning with Tree-based Priors">

                                <b>[11]</b> Srivastava N, Salakhutdinov R.Discriminative transfer learning with tree-based priors[C].Lake Tahoe:Advances in Neural Information Processing Systems, 2013.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stochastic pooling for regularization of deep convolutional neural networks">

                                <b>[12]</b> Zeiler M D, Fergus R.Stochastic pooling for regularization of deep convolutional neural networks[J].arXiv Preprint arXiv, 2013, 1301 (3557) :1-9.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deeply-supervised nets">

                                <b>[13]</b> Lee C Y, Xie S, Gallagher P, et al.Deeply-supervised nets[J]. arXiv Preprint arXiv, 2015, 1409 (5185) :1-9.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 Ioffe S, Szegedy C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C].Lille:International Conference on Machine Learning, 2015.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201706001&amp;v=MjkxMzZxQnRHRnJDVVI3cWZadVpvRnlubFZyckFMejdCZHJHNEg5Yk1xWTlGWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 周飞燕, 金林鹏, 董军.卷积神经网络研究综述[J].计算机学报, 2017, 40 (6) :1229-1251. Zhou Feiyan, Jin Linpeng, Dong Jun.Review of convolutional neural network[J].Chinese Journal of Computers, 2017, 40 (6) :1229-1251.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the importance of initialization and momentum in deep learning">

                                <b>[16]</b> Sutskever I, Martens J, Dahl G, et al. On the importance of initialization and momentum in deep learning[C].Atlanta: International Conference on Machine Learning, 2013.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZKK201903012" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201903012&amp;v=MDQ2MDBGckNVUjdxZlp1Wm9GeW5sVnJyQklUZkFaYkc0SDlqTXJJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

