

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139163167607500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZKK201911007%26RESULT%3d1%26SIGN%3dcl0eIfUu7FLtkUcG4WgpbvIsVh0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201911007&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201911007&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201911007&amp;v=MjUyMDRaYkc0SDlqTnJvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrVjcvUElUZkE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 卷积神经网络在交通标志识别中的应用&lt;/b&gt; "><b>1 卷积神经网络在交通标志识别中的应用</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="&lt;b&gt;1.1 卷积神经网络基础理论&lt;/b&gt;"><b>1.1 卷积神经网络基础理论</b></a></li>
                                                <li><a href="#40" data-title="&lt;b&gt;1.2 基于卷积神经网络的交通标志识别算法&lt;/b&gt;"><b>1.2 基于卷积神经网络的交通标志识别算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;2 基于改进卷积神经网络的交通标志识别&lt;/b&gt; "><b>2 基于改进卷积神经网络的交通标志识别</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="&lt;b&gt;2.1 改进的&lt;/b&gt;RPN&lt;b&gt;候选区域网络&lt;/b&gt;"><b>2.1 改进的</b>RPN<b>候选区域网络</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;2.2 基于&lt;/b&gt;MaxPooling &lt;b&gt;的多级特征融合&lt;/b&gt;"><b>2.2 基于</b>MaxPooling <b>的多级特征融合</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;3.1 数据集准备&lt;/b&gt;"><b>3.1 数据集准备</b></a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;3.2 识别结果分析&lt;/b&gt;"><b>3.2 识别结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="图1 Faster R-CNN网络结构">图1 Faster R-CNN网络结构</a></li>
                                                <li><a href="#48" data-title="图2 改进后的RPN网络结构">图2 改进后的RPN网络结构</a></li>
                                                <li><a href="#50" data-title="图3 双层RPN网络结构">图3 双层RPN网络结构</a></li>
                                                <li><a href="#61" data-title="图4 改进后的卷积神经网络">图4 改进后的卷积神经网络</a></li>
                                                <li><a href="#65" data-title="图5 交通标志图像实例">图5 交通标志图像实例</a></li>
                                                <li><a href="#68" data-title="图6 交通标志识别结果">图6 交通标志识别结果</a></li>
                                                <li><a href="#70" data-title="图7 改进后的算法和Faster R-CNN对不同尺度交通标志
识别结果
">图7 改进后的算法和Faster R-CNN对不同尺度交通标志
识别结果
</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 张达峰,刘宇红,张荣芬.基于深度学习的智能辅助驾驶系统[J].电子科技,2018,31(10):60-63.Zhang Dafeng,Liu Yuhong,Zhang Rongfen.Intelligent assistantdriving system based on deep learning[J].Electronic Science and Technology,2018,31(10):60-63." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201810015&amp;v=MzE0MTA1NE8zenFxQnRHRnJDVVI3cWZadVpwRnkza1Y3L1BJVGZBWmJHNEg5bk5yNDlFWVlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         张达峰,刘宇红,张荣芬.基于深度学习的智能辅助驾驶系统[J].电子科技,2018,31(10):60-63.Zhang Dafeng,Liu Yuhong,Zhang Rongfen.Intelligent assistantdriving system based on deep learning[J].Electronic Science and Technology,2018,31(10):60-63.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Yao C,Wu F,Chen H J,et al.Traffic sign recognition using HOG-SVM and grid search[C].Hangzhou:International Conference on Signal Processing,2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition using HOG-SVM and grid search">
                                        <b>[2]</b>
                                         Yao C,Wu F,Chen H J,et al.Traffic sign recognition using HOG-SVM and grid search[C].Hangzhou:International Conference on Signal Processing,2015.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Gim J W,Hwang M C,Ko B C,et al.Real-time speed-limit sign detection and recognition using spatial pyramid feature and boosted random forest[C].Genoa:International Conference Image Analysis and Recognition,2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-Time Speed-Limit Sign Detection and Recognition Using Spatial Pyramid Feature and Boosted Random Forest">
                                        <b>[3]</b>
                                         Gim J W,Hwang M C,Ko B C,et al.Real-time speed-limit sign detection and recognition using spatial pyramid feature and boosted random forest[C].Genoa:International Conference Image Analysis and Recognition,2015.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Deng Zhijie,Wang Yong,Tao Xiaoling.Method of network traffic classification using Na&#239;ve Bayes based on FPGA[C].Chongqing:13&lt;sup&gt;th&lt;/sup&gt; IEEE Joint International Computer Science and Information Technology Conference,2011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Method of network traffic classification using Nave Bayes based on FPGA">
                                        <b>[4]</b>
                                         Deng Zhijie,Wang Yong,Tao Xiaoling.Method of network traffic classification using Na&#239;ve Bayes based on FPGA[C].Chongqing:13&lt;sup&gt;th&lt;/sup&gt; IEEE Joint International Computer Science and Information Technology Conference,2011.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Zhang Qi,He Ning,Chi Yue,et al.Traffic sign detection and recognition based on the improved SIFT algorithm[J].Journal of Beijing Union University,2017,31(2):59-65." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJLH201702011&amp;v=MTk0ODBGckNVUjdxZlp1WnBGeTNrVjcvUEp5Zkhackc0SDliTXJZOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Zhang Qi,He Ning,Chi Yue,et al.Traffic sign detection and recognition based on the improved SIFT algorithm[J].Journal of Beijing Union University,2017,31(2):59-65.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Abedin M Z,Dhar P,Deb K.Traffic sign recognition using SURF:Speeded up robust feature descriptor and artificial neural network classifier[C].Dhaka:International Conference on Electrical and Computer Engineering,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition using SURF:Speeded up robust feature descriptor and artificial neural network classifier">
                                        <b>[6]</b>
                                         Abedin M Z,Dhar P,Deb K.Traffic sign recognition using SURF:Speeded up robust feature descriptor and artificial neural network classifier[C].Dhaka:International Conference on Electrical and Computer Engineering,2016.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 李盈盈,李菲菲,陈虬.基于改进HOG共生概率特征的行人检测算法[J].电子科技,2018,31(9):4-8.Li Yingying,Li Feifei,Chen Qiu.Pedestrian detection algorithm using co-occurrence probability feature based on improved HOG[J].Electronic Science and Technology,2018,31(9):4-8." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201809003&amp;v=MDk4MzlQSVRmQVpiRzRIOW5NcG85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5M2tWNy8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         李盈盈,李菲菲,陈虬.基于改进HOG共生概率特征的行人检测算法[J].电子科技,2018,31(9):4-8.Li Yingying,Li Feifei,Chen Qiu.Pedestrian detection algorithm using co-occurrence probability feature based on improved HOG[J].Electronic Science and Technology,2018,31(9):4-8.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Wu Yihui,Liu Yulong,Li Jianmin,et al.Traffic sign detection based on convolutional neural networks[C].Dallas:International Joint Conference on Neural Networks,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Traffic sign detection based on convolutional neural networks">
                                        <b>[8]</b>
                                         Wu Yihui,Liu Yulong,Li Jianmin,et al.Traffic sign detection based on convolutional neural networks[C].Dallas:International Joint Conference on Neural Networks,2014.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Sermanet P,Lecun Y.Traffic sign recognition with multi-scale convolutional networks[C].San Jose:International Joint Conference on Neural Networks,2011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition with multi-scale Convolutional Networks">
                                        <b>[9]</b>
                                         Sermanet P,Lecun Y.Traffic sign recognition with multi-scale convolutional networks[C].San Jose:International Joint Conference on Neural Networks,2011.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Jin J,Fu K,Zhang C.Traffic sign recognition with hinge loss trained convolutional neural networks[J].IEEE Transactions on Intelligent Transportation Systems,2014,15(5):1991-2000." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition with hinge loss trained convolutional neural networks">
                                        <b>[10]</b>
                                         Jin J,Fu K,Zhang C.Traffic sign recognition with hinge loss trained convolutional neural networks[J].IEEE Transactions on Intelligent Transportation Systems,2014,15(5):1991-2000.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Zhu Zhe,Liang Dun,Zhang Songhai,et al.Traffic-sign detection and classification in the wild[C].Las Vegas:IEEE Conference on Computer Vision and Pattern Recognition,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Traffic-Sign Detection and Classification in the Wild">
                                        <b>[11]</b>
                                         Zhu Zhe,Liang Dun,Zhang Songhai,et al.Traffic-sign detection and classification in the wild[C].Las Vegas:IEEE Conference on Computer Vision and Pattern Recognition,2016.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Ciresan D,Meier U,Masci J,et al.A committee of neural networks for traffic sign classification[C].San Jose:International Joint Conference on Neural Networks,2011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A committee of neural networks for traffic signclassification">
                                        <b>[12]</b>
                                         Ciresan D,Meier U,Masci J,et al.A committee of neural networks for traffic sign classification[C].San Jose:International Joint Conference on Neural Networks,2011.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Sermanet P,Eigen D,Zhang Xiang,et al.Overfeat:integrated recognition,localization anddetection using convolutional networks[C].Vancouver:International Conference on Learning Representations,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OverFeat:Integrated recognition, lo-calization and detection using convolutional networks">
                                        <b>[13]</b>
                                         Sermanet P,Eigen D,Zhang Xiang,et al.Overfeat:integrated recognition,localization anddetection using convolutional networks[C].Vancouver:International Conference on Learning Representations,2014.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Girshick R,Donahue J,Darrell T,et al.Rich feature hierarchies for accurate object detection and semantic segmentation[C].Columbus:IEEE Conference on Computer Vision and Pattern Recognition,2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation">
                                        <b>[14]</b>
                                         Girshick R,Donahue J,Darrell T,et al.Rich feature hierarchies for accurate object detection and semantic segmentation[C].Columbus:IEEE Conference on Computer Vision and Pattern Recognition,2013.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Girshick R.Fast R-CNN[C].Santiago:IEEE International Conference on Computer Vision (ICCV),2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">
                                        <b>[15]</b>
                                         Girshick R.Fast R-CNN[C].Santiago:IEEE International Conference on Computer Vision (ICCV),2015.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     Ren S,He K,Girshick R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence,2017,39(6):1137-1149.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2018-12-29 14:50</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZKK" target="_blank">电子科技</a>
                2019,32(11),28-32 DOI:10.16180/j.cnki.issn1007-7820.2019.11.006            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于改进卷积神经网络的交通标志识别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%A2%81%E5%B0%8F%E5%B9%B3&amp;code=09657461&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">袁小平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%B2%97&amp;code=41925914&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王岗</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%99%94%E6%9E%AB&amp;code=38231093&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王晔枫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%AA%E5%96%86%E8%BF%9C&amp;code=42623700&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汪喆远</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E8%BE%89&amp;code=14878020&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙辉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%9F%BF%E4%B8%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E6%8E%A7%E5%88%B6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0041682&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国矿业大学信息与控制工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对智能交通系统中小尺度交通标志识别率低的问题,文中提出一种改进卷积神经网络的交通标志识别方法。该方法通过在Faster R-CNN算法的低层特征图上增加优化的RPN网络,提升了小尺度交通标志的检测率。该方法还利用Max Pooling方法实了现图像的局部细节特征与全局语义特征充分融合。在TT-100K数据集上稍微实验结果表明新方法可以明显提高小尺度交通标志的识别率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%A4%E9%80%9A%E6%A0%87%E5%BF%97%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">交通标志识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Faster%20R-CNN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Faster R-CNN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=RPN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">RPN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征融合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    袁小平(1966-),男,博士,教授。研究方向:模式识别与人工智能。;
                                </span>
                                <span>
                                    王岗(1994-),男,硕士研究生。研究方向:计算机视觉。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-17</p>

                    <p>

                            <b>基金：</b>
                                                        <span>江苏省自然科学基金(BK20170278);</span>
                    </p>
            </div>
                    <h1><b>Traffic Sign Recognition Method Based on Improved Convolutional Neural Network</b></h1>
                    <h2>
                    <span>YUAN Xiaoping</span>
                    <span>WANG Gang</span>
                    <span>WANG Yefeng</span>
                    <span>WANG Zheyuan</span>
                    <span>SUN Hui</span>
            </h2>
                    <h2>
                    <span>School of Information and Control Engineering,China University of Mining and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the low recognition rate of small scale traffic signs in intelligent transportation system, an improved convolution neural network method for traffic sign recognition was proposed in this paper.This method could improve the detection rate of small-scale traffic signs by adding an optimized RPN network to the low-level feature map of Faster R-CNN algorithm.In addition, Max Pooling method was used to fully fuse the local details and global semantic features of the image. The experimental results on TT-100 K data set showed that the proposed method could significantly improve the recognition rate of small-scale traffic signs.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=trafficsign%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">trafficsign recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Faster%20R-CNN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Faster R-CNN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=RPN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">RPN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature fusion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-17</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Natural Science Foundation of Jiangsu(BK20170278);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="35">交通标志识别技术广泛应用于智能辅助驾驶系统<citation id="74" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、无人驾驶汽车、车载导航等领域,是图像处理与模式识别领域的研究热点。虽然交通标志的图形结构简单,但是交通标志多设置在复杂多变的环境中,光照条件、障碍物遮挡、人为破坏、车辆运动、成像模糊、恶劣天气等因素都会对交通标志的检测与识别造成影响。为了解决提高识别准确度,国内外学者进行了大量的研究,其中大多数方法采用传统分类器和特征提取相结合的思想来提高识别度。传统的分类器包括支持向量机<citation id="75" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>(Support Vector Machine,SVM)、随机森林分类器<citation id="76" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、贝叶斯分类器<citation id="77" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等;常见的特征提取算子包括尺度不变特征变换<citation id="78" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>(Scale-Invariant Feature Transform,SIFT)、加速鲁棒特征<citation id="79" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>(Speeded Up Robust Feature,SURF)、方向梯度直方图<citation id="80" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>(Histogram of Oriented Gradient,HOG)等。这些手工设计的特征提取算子时只能提取单一的、浅层的特征,因此无法准确实时地识别交通标志。</p>
                </div>
                <div class="p1">
                    <p id="36">近年来,深度学习在计算机视觉领域得到了越来越多的关注,超过了传统图像处理和机器学习方法。利用深度学习进行目标检测与识别已经成为主流方法,卷积神经网络(Convolutional Neural Network,CNN)是目前最常用的网络模型<citation id="81" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>,在图像分类、检测和识别等任务方面有着巨大的优势。目前大部分交通标志识别算法都是基于德国交通标志识别基准(German Traffic Sign Recognition Benchmark,GTSRB)数据集,许多研究团队在该数据集上取得了优异的成绩<citation id="83" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>。然而,这样的基准数据却无法真正代表实际行车场景下的数据。在真实的行车环境中,交通标志在整幅图片中的比例普遍偏小。因此,本文提出一种改进的卷积神经网络算法,利用改进的双层RPN网络(Region Proposal Network)与特征融合来对不同尺度的交通标志牌进行检测和识别。同时,在更加接近于实际行车环境的数据集Tsinghua-Tencent 100K<citation id="82" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>中设计和评估所提算法。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>1 卷积神经网络在交通标志识别中的应用</b></h3>
                <h4 class="anchor-tag" id="38" name="38"><b>1.1 卷积神经网络基础理论</b></h4>
                <div class="p1">
                    <p id="39">卷积神经网络是一类包含卷积或相关计算且具有深度结构的前馈神经网络,其基本结构由一系列卷积层、池化层以及全连接层组成。在网络前向传播过程中,卷积层主要用来提取图像特征,其最主要的特点是局部感受野和权值共享。局部感受野指一个神经元只能与它下一层附近的神经元相连;权值共享意味着每个特征图由一个滤波器产生,其中一个滤波器代表一种特征。局部感受野和权值共享可以大大减少卷积神经网络的参数量。在反向传播过程中,利用梯度下降法极小化误差函数来对网络中的参数逐层反向调节,可以得到参数的最优解。通过卷积神经网络可以充分提取图像的多层次特征,从而有效提升检测和分类的精度。</p>
                </div>
                <h4 class="anchor-tag" id="40" name="40"><b>1.2 基于卷积神经网络的交通标志识别算法</b></h4>
                <div class="p1">
                    <p id="41">随着深度学习算法迅速发展,目标检测的准确性与实时性得到迅速提升。基于CNN的方法也开始应用于交通标志识别,文献<citation id="84" type="reference">[<a class="sup">12</a>]</citation>最早提出了一种简单的CNN网络识别交通标志后,陆续有一系列研究提出了多尺度CNN网络<citation id="85" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和铰链损失的CNN网络<citation id="86" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>,这两种方法分别在输入层和损失函数上对模型进行了相应的改进。虽然这些方法在GTSRB数据集上取得了不错的分类效果,但是GTSRB中交通标志占据图像的比例较大,且这些算法只能确定交通标志属于哪个子类,无法实现端到端目标检测与识别。</p>
                </div>
                <div class="p1">
                    <p id="42">目标检测算法的发展对交通标志识别有很大的推动作用。Sermanet等人提出的Overfeat<citation id="87" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>算法将图像分类、定位与检测整合在一个框架内,但其基于滑动窗口的检测方式存在大量的计算冗余,因此基于区域提名的方法被相继提出。R-CNN<citation id="88" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>作为区域提名方法的代表之一,首先采用选择性搜索算法来提取目标的候选区域,然后利用CNN模型对每个区域提取特征,最后利用SVM分类得到结果,大大减少了滑动窗口带来的计算冗余。之后,Fast R-CNN<citation id="89" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、Faster R-CNN<citation id="90" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>分别在分类方式和候选区域提取方式改进,其中Faster R-CNN采用RPN网络实现目标候选区域的提取,其结构如图2所示,先由 RPN 网络判断候选框是否为目标,再经分类定位的多任务损失判断目标类型。整个网络流程都能共享卷积神经网络提取的特征信息,可有效节约计算成本。然而,由于 RPN 网络在固定尺寸的高层特征图上生成多尺寸候选框,因此会导致感受野太大而无法准确检测小目标。</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911007_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Faster R-CNN网络结构" src="Detail/GetImg?filename=images/DZKK201911007_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Faster R-CNN网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911007_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1. Structure of Faster R-CNN</p>

                </div>
                <div class="p1">
                    <p id="44">目前大多数基于深度学习的目标检测算法针对的是较大尺度的目标,而公路场景中的交通标志尺度普遍较小,因此上述的目标检测算法均不适用于公路交通标志检测与识别。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag"><b>2 基于改进卷积神经网络的交通标志识别</b></h3>
                <h4 class="anchor-tag" id="46" name="46"><b>2.1 改进的</b>RPN<b>候选区域网络</b></h4>
                <div class="p1">
                    <p id="47">RPN 网络类似于以往目标检测中的选择性搜索算法,其作用是从给定图像中寻找目标建议框的集合。考虑到交通标志的尺度普遍较小,不宜采用太深层次的网络提取特征,因此本文使用VGG(Visual Geometry Group)网络作为基础模型。改进后的RPN网络如图2所示,首先在VGG网络的最后一层特征图上增加3×3的卷积来进一步聚拢特征,产生512维的特征图;然后通过1×1的卷积将输出分为两路,其中一路输出目标和背景的得分概率,另一路输出边界框的4个坐标参数(<i>x</i>,<i>y</i>,<i>w</i>,<i>h</i>)。因为交通标志的候选区域一般为规则正方形,所以去除传统RPN网络中的不同比例候选框,只在卷积特征图的每个位置预测3种不同尺度的区域。这样对于每个anchor来说,回归层输出3×4维的坐标,分类层输出3×2维的概率得分。对于大小为<i>w</i>×<i>h</i>的特征图,总共产生3×<i>w</i>×<i>h</i>个候选区域,与Faster R-CNN相比数量大幅减少,并且每个候选区域的目的性更强。另外,RPN网络得到的候选框存在重叠,可以通过非极大值抑制的方法去除冗余的候选框。设定IoU的阈值为0.7,仅保留覆盖率不超过0.7的候选框。在剩下的box中选取前<i>N</i>个box送入ROI池化层,最终完成候选区域提取。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911007_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 改进后的RPN网络结构" src="Detail/GetImg?filename=images/DZKK201911007_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 改进后的RPN网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911007_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2. Improved RPN structure</p>

                </div>
                <div class="p1">
                    <p id="49">小尺度的交通标志经过VGG网络的多重卷积与池化操作之后,生成的特征图尺寸仅为输入图像的1/16。此时的特征图拥有较大的感受野,虽然对目标的轮廓信息具有较强的表达能力,却失去了图像的细节纹理信息,非常不利于小尺度交通标志的识别。为改变这种状况,本文在高低层特征图上分别进行RPN操作。对于小目标而言,低层的特征图感受野较小,但拥有图像的细节信息比较多。因此,将低层特征图用于生成候选区域可以提升算法对小目标交通标志的检测效果。而高层特征图对大目标的轮廓信息敏感,更适合检测较大尺度交通标志。改进后的双层RPN网络结构如图3所示。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911007_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 双层RPN网络结构" src="Detail/GetImg?filename=images/DZKK201911007_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 双层RPN网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911007_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3. Double-Layer RPN structure</p>

                </div>
                <div class="p1">
                    <p id="51">为了训练RPN网络,需要给每个候选区域分配标签,若候选区域与 Ground Truth(GT)有最高的IOU或者候选区域与 GT 的IOU大于 0.7,就认为是正标签;若候选区域与 GT 的IOU小于 0.3 则认为是负标签。剩余的其他区域不参与训练,这样就可以定义如下的目标函数</p>
                </div>
                <div class="area_img" id="52">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201911007_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="54">目标函数由两部分构成,对应着<i>RPN</i>两条支路,分别为目标与否的分类误差和<i>Bounding Box</i>的回归误差。其中,i是<i>Minibatch</i>候选区域的索引;p<sub>i</sub>是第i个候选区域预测目标的概率。对于目标和背景,标签p<sup>*</sup><sub>i</sub>分别为1和0;t<sub>i</sub>表示预测的4个坐标,t<sup>*</sup><sub>i</sub>是正样本对应的<i>GT</i>包围框的坐标。回归误差中的系数p<sup>*</sup><sub>i</sub>表示回归误差只对包含目标的<i>anchor</i>计算误差。式(1)中的分类损失L<sub><i>cls</i></sub>是两个类别的对数损失</p>
                </div>
                <div class="p1">
                    <p id="55"><i>L</i><sub>cls</sub>(<i>p</i><sub><i>i</i></sub>,<i>p</i><sup>*</sup><sub><i>i</i></sub>)=-log[<i>p</i><sup>*</sup><sub><i>i</i></sub><i>p</i><sub><i>i</i></sub>+(1-<i>p</i><sup>*</sup><sub><i>i</i></sub>)(1-<i>p</i><sub><i>i</i></sub>)]      (2)</p>
                </div>
                <div class="p1">
                    <p id="56">对于回归损失，计算式为L<sub>reg</sub>(t<sub>i</sub>,t<sup>*</sup><sub>i</sub>)=R(x)(t<sub>i</sub>t<sup>*</sup><sub>i</sub>)，其中R(x)是定义的鲁棒损失函数</p>
                </div>
                <div class="area_img" id="57">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201911007_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>2.2 基于</b>MaxPooling <b>的多级特征融合</b></h4>
                <div class="p1">
                    <p id="60">FasterR-CNN算法采用RPN网络生成的候选区域和VGG网络的最后一层特征图进行ROI池化操作,得到固定尺寸的特征图送入后面的全连接层进行目标检测和分类。VGG网络的最后一层特征图都是低分辨率图像,含有丰富的语义抽象特征,适合描述交通标志的外形轮廓,而低层次的高分辨率特征图则更容易分辨交通标志的细节纹理。因此,为了进一步提高交通标志的检测精度和分类精度,本文使用多层特征融合的策略。改进后的卷积神经网络如图4所示,将第4层和第8层的卷积特征图通过MaxPooling方法与最后一层特征图级联在一起,实现了图像的局部细节特征与全局语义特征充分融合。为了避免高维特征图造成模型复杂度过高的问题,在特征融合时,每层间隔一定数量选取特征图进行池化操作,这样轻量级的特征融合可以提升网络对不同尺度交通标志的识别能力。最后把融合后的特征全部送入分类器和回归器,实现交通标志的检测与识别。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911007_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 改进后的卷积神经网络" src="Detail/GetImg?filename=images/DZKK201911007_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 改进后的卷积神经网络  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911007_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4. Improved convolution neural network</p>

                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <h4 class="anchor-tag" id="63" name="63"><b>3.1 数据集准备</b></h4>
                <div class="p1">
                    <p id="64">本次实验使用中国交通标志数据(TT-100K),该数据集包含10万张分辨率为2 048×2 048的街景图像,其中含有30 000个交通标志。值得注意的是,TT-100K数据集涵盖了实际行车环境下的各种场景并且绝大多数交通标志尺度较小。虽然原始图片覆盖了中国大部分地区,但不同类别的交通标志在数量上必然存在不平衡现象,因此本研究排除了实例数量少于100的交通标志。然后将训练集中数量小于1 000的实例全部扩增至1 000,数量超过1 000的实例保持不变。最终得到45个类别的交通标志如图5所示。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911007_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 交通标志图像实例" src="Detail/GetImg?filename=images/DZKK201911007_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 交通标志图像实例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911007_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5. Example of traffic sign image</p>

                </div>
                <h4 class="anchor-tag" id="66" name="66"><b>3.2 识别结果分析</b></h4>
                <div class="p1">
                    <p id="67">实验环境:Intel酷睿i7 CPU、32 GB内存、64位操作系统(Ubuntu16.04)、GPU(GTX1080Ti)。本次实验将包含交通标志的10 000幅全景图以2∶1的比例划分为训练集与测试集,剩余90 000幅无交通标志的全景图全部用于模型的测试。为了降低模型复杂度,所有图像均下采样为原图一半,并去除上方与下方不可能含有交通标志的区域,最终的识别结果如图6所示。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911007_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 交通标志识别结果" src="Detail/GetImg?filename=images/DZKK201911007_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 交通标志识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911007_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 6. Traffic sign recognition results</p>

                </div>
                <div class="p1">
                    <p id="69">根据交通标志的大小将数据集图像分为4类:小对象(0像素&lt;面积&lt;48像素)、较小对象(48像素&lt;面积&lt;96像素)、较大对象(96像素&lt;面积&gt;144像素)和大对象(144像素&lt;面积&lt;400像素)。将这4类图像分别送入Faster R-CNN和改进后的网络,通过实验对比分析可以判断神经网络对不同尺度交通标志的识别能力。改进后的网络和Faster R-CNN在不同尺度交通标志上的识别结果如图7所示,可以明显看出:当交通标志尺度较小时,改进后的网络对交通标志的识别拥有较高的准确率和召回率,明显优于Faster R-CNN。随着交通标志尺度的增加,两种方法的差距逐渐缩小,说明Faster R-CNN针对大尺度目标有较强识别能力,而改进后的算法在不同尺度的交通标志上均表现出优异的性能。总体来说,Faster R-CNN的召回率为0.59,精确率为0.63;改进后的方法有0.87精确率和0.83的召回率。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201911007_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 改进后的算法和Faster R-CNN对不同尺度交通标志
识别结果" src="Detail/GetImg?filename=images/DZKK201911007_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 改进后的算法和Faster R-CNN对不同尺度交通标志
识别结果
  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201911007_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure7. Traffic sign recognition results of different scales based 
on improved algorithm and Faster R-CNN
</p>
                                <p class="img_note">(a)小对象(b)较小对象(c)较大对象(d)大对象</p>
                                <p class="img_note">(a)Small objects (b)Smaller objects (c) Bigger objects 
(d)Big objects</p>

                </div>
                <h3 id="71" name="71" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="72">本文针对小尺度交通标志的识别提出了一种改进卷积神经网络算法。所提算法主要对卷积神经网络结构进行了两部分的优化:(1)对Faster R-CNN算法的RPN网络进行改进,设计了双层RPN网络结构检测不同尺度的交通标志;(2)基于MaxPooling方法将不同层次特征图进行级联,通过特征融合提升不同尺度交通标志的识别率。</p>
                </div>
                <div class="p1">
                    <p id="73">但是文中所提出的方法还存在以下不足:改进后的模型需要提取整张图片的卷积特征进行多尺度训练,由于图像下采样会造成分辨率降低并丢失部分图像细节特征,因此导致样本的特征表达能力有限。实验数据集是在连续帧的静态图片中处理,因此在后续研究中可以考虑直接在视频流中加入车道线和路面交通标志的检测。除此以外,还可进一步考虑将该模型移植到嵌入式平台进行交通标志的实时检测与识别。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201810015&amp;v=MDUzNzh0R0ZyQ1VSN3FmWnVacEZ5M2tWNy9QSVRmQVpiRzRIOW5OcjQ5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 张达峰,刘宇红,张荣芬.基于深度学习的智能辅助驾驶系统[J].电子科技,2018,31(10):60-63.Zhang Dafeng,Liu Yuhong,Zhang Rongfen.Intelligent assistantdriving system based on deep learning[J].Electronic Science and Technology,2018,31(10):60-63.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition using HOG-SVM and grid search">

                                <b>[2]</b> Yao C,Wu F,Chen H J,et al.Traffic sign recognition using HOG-SVM and grid search[C].Hangzhou:International Conference on Signal Processing,2015.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-Time Speed-Limit Sign Detection and Recognition Using Spatial Pyramid Feature and Boosted Random Forest">

                                <b>[3]</b> Gim J W,Hwang M C,Ko B C,et al.Real-time speed-limit sign detection and recognition using spatial pyramid feature and boosted random forest[C].Genoa:International Conference Image Analysis and Recognition,2015.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Method of network traffic classification using Nave Bayes based on FPGA">

                                <b>[4]</b> Deng Zhijie,Wang Yong,Tao Xiaoling.Method of network traffic classification using Naïve Bayes based on FPGA[C].Chongqing:13<sup>th</sup> IEEE Joint International Computer Science and Information Technology Conference,2011.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJLH201702011&amp;v=MjE3NDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEZ5M2tWNy9QSnlmSFpyRzRIOWJNclk5RVpZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Zhang Qi,He Ning,Chi Yue,et al.Traffic sign detection and recognition based on the improved SIFT algorithm[J].Journal of Beijing Union University,2017,31(2):59-65.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition using SURF:Speeded up robust feature descriptor and artificial neural network classifier">

                                <b>[6]</b> Abedin M Z,Dhar P,Deb K.Traffic sign recognition using SURF:Speeded up robust feature descriptor and artificial neural network classifier[C].Dhaka:International Conference on Electrical and Computer Engineering,2016.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201809003&amp;v=MDk0MTN5M2tWNy9QSVRmQVpiRzRIOW5NcG85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacEY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 李盈盈,李菲菲,陈虬.基于改进HOG共生概率特征的行人检测算法[J].电子科技,2018,31(9):4-8.Li Yingying,Li Feifei,Chen Qiu.Pedestrian detection algorithm using co-occurrence probability feature based on improved HOG[J].Electronic Science and Technology,2018,31(9):4-8.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Traffic sign detection based on convolutional neural networks">

                                <b>[8]</b> Wu Yihui,Liu Yulong,Li Jianmin,et al.Traffic sign detection based on convolutional neural networks[C].Dallas:International Joint Conference on Neural Networks,2014.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition with multi-scale Convolutional Networks">

                                <b>[9]</b> Sermanet P,Lecun Y.Traffic sign recognition with multi-scale convolutional networks[C].San Jose:International Joint Conference on Neural Networks,2011.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Traffic sign recognition with hinge loss trained convolutional neural networks">

                                <b>[10]</b> Jin J,Fu K,Zhang C.Traffic sign recognition with hinge loss trained convolutional neural networks[J].IEEE Transactions on Intelligent Transportation Systems,2014,15(5):1991-2000.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Traffic-Sign Detection and Classification in the Wild">

                                <b>[11]</b> Zhu Zhe,Liang Dun,Zhang Songhai,et al.Traffic-sign detection and classification in the wild[C].Las Vegas:IEEE Conference on Computer Vision and Pattern Recognition,2016.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A committee of neural networks for traffic signclassification">

                                <b>[12]</b> Ciresan D,Meier U,Masci J,et al.A committee of neural networks for traffic sign classification[C].San Jose:International Joint Conference on Neural Networks,2011.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OverFeat:Integrated recognition, lo-calization and detection using convolutional networks">

                                <b>[13]</b> Sermanet P,Eigen D,Zhang Xiang,et al.Overfeat:integrated recognition,localization anddetection using convolutional networks[C].Vancouver:International Conference on Learning Representations,2014.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation">

                                <b>[14]</b> Girshick R,Donahue J,Darrell T,et al.Rich feature hierarchies for accurate object detection and semantic segmentation[C].Columbus:IEEE Conference on Computer Vision and Pattern Recognition,2013.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">

                                <b>[15]</b> Girshick R.Fast R-CNN[C].Santiago:IEEE International Conference on Computer Vision (ICCV),2015.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 Ren S,He K,Girshick R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence,2017,39(6):1137-1149.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZKK201911007" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201911007&amp;v=MjUyMDRaYkc0SDlqTnJvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnBGeTNrVjcvUElUZkE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZONEl2ZXMzNXJlUkZjWFB4bHhwYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=P0ea_aWnQfx5aXr8bS4u3GGmKX_ORbqAf_1HJ_4Trvg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

