

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637139857615576250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZKK201905008%26RESULT%3d1%26SIGN%3dUx1mIT4aC7Nw%252bDIkn7%252fiJucvDU0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201905008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZKK201905008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201905008&amp;v=MDkzMzA1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEbVVMckxJVGZBWmJHNEg5ak1xbzlGYklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;1&lt;/b&gt; 基于海洋环境下的预处理 "><b>1</b> 基于海洋环境下的预处理</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;2&lt;/b&gt; 特征提取与融合 "><b>2</b> 特征提取与融合</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="&lt;b&gt;2.1&lt;/b&gt; 倒谱特征"><b>2.1</b> 倒谱特征</a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.2&lt;/b&gt; 时域特征"><b>2.2</b> 时域特征</a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;2.3&lt;/b&gt; 特征融合"><b>2.3</b> 特征融合</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="&lt;b&gt;3&lt;/b&gt; 支持向量机识别 "><b>3</b> 支持向量机识别</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="&lt;b&gt;4&lt;/b&gt; 实验过程及结果分析 "><b>4</b> 实验过程及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#95" data-title="&lt;b&gt;4.1&lt;/b&gt; 声音样本集"><b>4.1</b> 声音样本集</a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;4.2&lt;/b&gt; 实验设计与结果分析"><b>4.2</b> 实验设计与结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;5&lt;/b&gt; 结束语 "><b>5</b> 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="图1 本文算法整体流程图">图1 本文算法整体流程图</a></li>
                                                <li><a href="#47" data-title="图2 本文端点检测流程图">图2 本文端点检测流程图</a></li>
                                                <li><a href="#98" data-title="图4 白鳍豚端点检测结果图">图4 白鳍豚端点检测结果图</a></li>
                                                <li><a href="#99" data-title="图5 白鳍豚特征融合结果图">图5 白鳍豚特征融合结果图</a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同分类器下分类结果&lt;/b&gt;"><b>表</b>1 <b>不同分类器下分类结果</b></a></li>
                                                <li><a href="#104" data-title="图6 用箱线图表示的SVM识别结果">图6 用箱线图表示的SVM识别结果</a></li>
                                                <li><a href="#106" data-title="图7 不同特征在3种环境下不同信噪比的识别率">图7 不同特征在3种环境下不同信噪比的识别率</a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;不同文献所用算法的比较&lt;/b&gt;"><b>表</b>2 <b>不同文献所用算法的比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title=" David E, Hanny et al.Marine mammal acoustic detections in the northeastern Chukchi Sea, September 2007-July 2011[J].Continental Shelf Research, 2013 (67) :127-146." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600250509&amp;v=MTgwNTA0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybkpLRjBYYnhBPU5pZk9mYks4SHRETXFZOUZadTRQQ1h3d29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         David E, Hanny et al.Marine mammal acoustic detections in the northeastern Chukchi Sea, September 2007-July 2011[J].Continental Shelf Research, 2013 (67) :127-146.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title=" Nanaware S, Shastri R, Joshi Y, et al.Passive acoustic detection and classification of marine mammal vocalizations[C].Lucknow:International Conference on Communication and Signal Processing, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Passive acoustic detection and classification of marine mammal vocalizations">
                                        <b>[2]</b>
                                         Nanaware S, Shastri R, Joshi Y, et al.Passive acoustic detection and classification of marine mammal vocalizations[C].Lucknow:International Conference on Communication and Signal Processing, 2014.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title=" Andr&#233; M, Van d S M, Zaugg S, et al.Listening to the Deep:live monitoring of ocean noise and cetacean acoustic signals.[J].Marine Pollution Bulletin, 2011, 63 (1-4) :18-26." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600879610&amp;v=MDUzMjJ3R0NuMDVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybkpLRjBYYnhBPU5pZk9mYks3SHRETnFZOUZiTw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Andr&#233; M, Van d S M, Zaugg S, et al.Listening to the Deep:live monitoring of ocean noise and cetacean acoustic signals.[J].Marine Pollution Bulletin, 2011, 63 (1-4) :18-26.
                                    </a>
                                </li>
                                <li id="8">


                                    <a id="bibliography_4" title=" Ibrahim A K, Zhuang H, Erdol N, et al.A New approach for north atlantic right whale upcall detection[C].Xi’an:International Symposium on Computer, Consumer and Control, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A New approach for north atlantic right whale upcall detection">
                                        <b>[4]</b>
                                         Ibrahim A K, Zhuang H, Erdol N, et al.A New approach for north atlantic right whale upcall detection[C].Xi’an:International Symposium on Computer, Consumer and Control, 2016.
                                    </a>
                                </li>
                                <li id="10">


                                    <a id="bibliography_5" title=" Brown J C, Smaragdis P.Hidden Markov and Gaussian mixture models for automatic call classification[J].Journal of the Acoustical Society of America, 2009, 125 (6) :EL221." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hidden Markov and Gaussian mixture models for automatic call classification">
                                        <b>[5]</b>
                                         Brown J C, Smaragdis P.Hidden Markov and Gaussian mixture models for automatic call classification[J].Journal of the Acoustical Society of America, 2009, 125 (6) :EL221.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_6" title=" Suleman M, Tamaki Ura.Vocalization based individual classification of humpback whales using support vector machine[C].Aberdeen:Oceans, 2007." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Vocalization based individual classification of humpback whales using support vector machine">
                                        <b>[6]</b>
                                         Suleman M, Tamaki Ura.Vocalization based individual classification of humpback whales using support vector machine[C].Aberdeen:Oceans, 2007.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_7" title=" Dugan P J, Rice A N, Urazghildiiev I R, et al.North atlantic right whale acoustic signal processing:Part I.comparison of machine learning recognition algorithms[C].Long Island:Applications and Technology Conference, 2010." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=North atlantic right whale acoustic signal processing:Part I.comparison of machine learning recognition algorithms">
                                        <b>[7]</b>
                                         Dugan P J, Rice A N, Urazghildiiev I R, et al.North atlantic right whale acoustic signal processing:Part I.comparison of machine learning recognition algorithms[C].Long Island:Applications and Technology Conference, 2010.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_8" title=" Zhou X, Garcia-Romero D, Duraiswami R, et al.Linear versus mel frequency cepstral coefficients for speaker recognition[C].Hawaii:Automatic Speech Recognition and Understanding, 2011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Linear versus mel frequency cepstral coefficients for speaker recognition">
                                        <b>[8]</b>
                                         Zhou X, Garcia-Romero D, Duraiswami R, et al.Linear versus mel frequency cepstral coefficients for speaker recognition[C].Hawaii:Automatic Speech Recognition and Understanding, 2011.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_9" title=" Harma A.Automatic identification of bird species based on sinusoidal modeling of syllables[C].Hong Kong:IEEE International Conference on Acoustics, Speech and Signal Processing, 2003." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic identification of bird species based on sinusoidal modeling ofsyllables">
                                        <b>[9]</b>
                                         Harma A.Automatic identification of bird species based on sinusoidal modeling of syllables[C].Hong Kong:IEEE International Conference on Acoustics, Speech and Signal Processing, 2003.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_10" title=" 宋知用.MATLAB在语音信号分析与合成中的应用[M].北京:北京航空航天大学出版社, 2013.Song Zhiyong.Application of MATLAB in speech signal analysis and synthesis[M].Beijing:Beihang University Press, 2013." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787512412286000&amp;v=MDkwODBVcmZMSTFzV1hGcXpHYmE1SE5YTnJZMU5ZdXNQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5q&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         宋知用.MATLAB在语音信号分析与合成中的应用[M].北京:北京航空航天大学出版社, 2013.Song Zhiyong.Application of MATLAB in speech signal analysis and synthesis[M].Beijing:Beihang University Press, 2013.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_11" title=" 张帅林.改进的智能家居语音关键词识别算法[J].电子科技, 2017, 30 (7) :5-8.Zhang Shuailin.Improved speech keyword spotting algorithm in smart home[J].Electronic Science and Technology, 2017, 30 (7) :5-8." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201707003&amp;v=MDE1NTFvRmlEbVVMcktJVGZBWmJHNEg5Yk1xSTlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         张帅林.改进的智能家居语音关键词识别算法[J].电子科技, 2017, 30 (7) :5-8.Zhang Shuailin.Improved speech keyword spotting algorithm in smart home[J].Electronic Science and Technology, 2017, 30 (7) :5-8.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_12" title=" 李艳, 成凌飞, 张培玲.一种基于改进谱熵的语音端点检测方法[J].计算机科学, 2016, 43 (S2) :233-236.Li Yan, Cheng lingfei, Zhang Peiling.Speech endpoint detection based on improved spectral entropy[J].Computer Science, 2016, 43 (S2) :233-236." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2016S2053&amp;v=MDAyMTZxQnRHRnJDVVI3cWZadVpvRmlEbVVMcktMejdCYjdHNEg5ZXZyWTlBWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         李艳, 成凌飞, 张培玲.一种基于改进谱熵的语音端点检测方法[J].计算机科学, 2016, 43 (S2) :233-236.Li Yan, Cheng lingfei, Zhang Peiling.Speech endpoint detection based on improved spectral entropy[J].Computer Science, 2016, 43 (S2) :233-236.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_13" title=" 张冬松, 马琪.一种基于SVM的负载识别算法[J].电子科技, 2017, 30 (8) :59-62.Zhang Dongsong, Ma Qi.A load identification algorithm based on SVM[J].Electronic Science and Technology, 2017, 30 (8) :59-62." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201708017&amp;v=MzIxMzE0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURtVUxyS0lUZkFaYkc0SDliTXA0OUVZNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         张冬松, 马琪.一种基于SVM的负载识别算法[J].电子科技, 2017, 30 (8) :59-62.Zhang Dongsong, Ma Qi.A load identification algorithm based on SVM[J].Electronic Science and Technology, 2017, 30 (8) :59-62.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_14" title=" 余清清, 李应, 李勇.基于SVM模型的自然环境声音的分类[J].计算机与数字工程, 2010, 38 (7) :1-5.Yu Qingqing, Li Ying, Li Yong.A SVM-based classification approach for natural sounds[J].Computer &amp;amp; Digital Engineering, 2010, 38 (7) :1-5." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201007002&amp;v=MDA2MDRhYkc0SDlITXFJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GaURtVUxyS0x6N1k=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         余清清, 李应, 李勇.基于SVM模型的自然环境声音的分类[J].计算机与数字工程, 2010, 38 (7) :1-5.Yu Qingqing, Li Ying, Li Yong.A SVM-based classification approach for natural sounds[J].Computer &amp;amp; Digital Engineering, 2010, 38 (7) :1-5.
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_15" title=" SanDiego University of California.Voices in the sea[EB/OL]. (2015-07-27) [2018-04-02] http://cetus.ucsd.edu/voicesinthesea_org/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Voices in the sea">
                                        <b>[15]</b>
                                         SanDiego University of California.Voices in the sea[EB/OL]. (2015-07-27) [2018-04-02] http://cetus.ucsd.edu/voicesinthesea_org/.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_16" title=" The Cornell Lab of Ornithology.Macaulay library[EB/OL]. (2014-09-28) [2018-04-02] http://macaulaylibrary.org/." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Macaulay library">
                                        <b>[16]</b>
                                         The Cornell Lab of Ornithology.Macaulay library[EB/OL]. (2014-09-28) [2018-04-02] http://macaulaylibrary.org/.
                                    </a>
                                </li>
                                <li id="34">


                                    <a id="bibliography_17" title=" Gingras B, Fitch W T.A three-parameter model for classifying anurans into four genera based on advertisement calls[J].Journal of the Acoustical Society of America, 2013, 133 (1) :547-59." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A three-parameter model for classifying anurans into four genera based on advertisement calls">
                                        <b>[17]</b>
                                         Gingras B, Fitch W T.A three-parameter model for classifying anurans into four genera based on advertisement calls[J].Journal of the Acoustical Society of America, 2013, 133 (1) :547-59.
                                    </a>
                                </li>
                                <li id="36">


                                    <a id="bibliography_18" title=" Oswald M, Oswald J N, Lammers M O, et al.Integration of real time odontocete call classification algorithm into PAMGUARD signal processing software[J].Journal of the Acoustical Society of America, 2011, 129 (4) :2639-2639." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Integration of real time odontocete call classification algorithm into PAMGUARD signal processing software">
                                        <b>[18]</b>
                                         Oswald M, Oswald J N, Lammers M O, et al.Integration of real time odontocete call classification algorithm into PAMGUARD signal processing software[J].Journal of the Acoustical Society of America, 2011, 129 (4) :2639-2639.
                                    </a>
                                </li>
                                <li id="38">


                                    <a id="bibliography_19" title=" Gonz&#225;lez-Hern&#225;ndez F R, S&#225;nchez-Fern&#225;ndez L P, Su&#225;rez-Guerra S, et al.Marine mammal sound classification based on a parallel recognition model and octave analysis[J].Applied Acoustics, 2017, 119 (3) :17-28." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8E1DDB1521154CBB5A88EEAE306A9CCC&amp;v=MzIxMTc2VzQzWTVBWnVvT0NYaEt2V1FXbXpkMVBRcVQyUkUxZjhPZE5zbnNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0NWd6THU4eGFvPU5pZk9mYnZOSA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Gonz&#225;lez-Hern&#225;ndez F R, S&#225;nchez-Fern&#225;ndez L P, Su&#225;rez-Guerra S, et al.Marine mammal sound classification based on a parallel recognition model and octave analysis[J].Applied Acoustics, 2017, 119 (3) :17-28.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZKK" target="_blank">电子科技</a>
                2019,32(05),32-37 DOI:10.16180/j.cnki.issn1007-7820.2019.05.007            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于特征融合的海洋哺乳动物声音识别</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%92%9F%E9%B8%A3%E6%8B%93&amp;code=39058911&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">钟鸣拓</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%94%A1%E6%96%87%E9%83%81&amp;code=17678902&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蔡文郁</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%9D%AD%E5%B7%9E%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0073968&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杭州电子科技大学电子信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了提高海洋哺乳动物声音识别算法的识别率和鲁棒性, 提出了一种将梅尔倒谱系数MFCC、线性倒谱系数LFCC和时域特征融合作为特征参数进行声音识别的方法。该方法通过融合不同倒谱系数以增强对不同频段的表征能力, 通过融合时域特征来更全面地描述声音信息。声音样本通过基于海洋环境下的预处理、特征提取与融合后, 用支持向量机进行分类识别。相对于传统算法只针对一种或几种哺乳动物进行识别, 该方法在包含61种海洋哺乳动物声音的样本库中进行测试。测试结果显示该算法较传统的梅尔倒谱系数在识别率上提升了5.5%, 且在海洋低信噪比环境下有更好的识别表现。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%B7%E6%B4%8B%E5%93%BA%E4%B9%B3%E5%8A%A8%E7%89%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">海洋哺乳动物;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A3%B0%E9%9F%B3%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">声音识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%80%92%E8%B0%B1%E7%B3%BB%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">倒谱系数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E5%9F%9F%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时域特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    钟鸣拓 (1994-) , 男, 硕士研究生。研究方向:语音识别、嵌入式开发。;
                                </span>
                                <span>
                                    蔡文郁 (1979-) , 男, 博士, 副教授。研究方向:嵌入式系统。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-05-16</p>

                    <p>

                            <b>基金：</b>
                                                        <span>浙江省自然科学基金 (LY18F030006);</span>
                    </p>
            </div>
                    <h1><b>Marine Mammal Sound Recognition Based on Feature Fusion</b></h1>
                    <h2>
                    <span>ZHONG Mingtuo</span>
                    <span>CAI Wenyu</span>
            </h2>
                    <h2>
                    <span>School of Electronic Information, Hangzhou Dianzi University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the recognition rate and robustness of marine mammal sound recognition algorithm, this paper proposed a method for sound recognition by using the fusion of MFCC, LFCC and temporal features as feature parameters. This method enhanced the characterization ability of different frequency bands by fusing different cepstral coefficients and described the sound information more comprehensively by integrating the temporal features. To be specific, each continuous marine mammal recording was first preprocessed into individual syllables. Then, cepstral coefficients and temporal features were calculated from each syllable. Finally, the fused features were identified by support vector machine. Unlike traditional algorithms which only recognized few mammals, this method was tested in a sample database containing 61 marine mammal sounds. The test results showed that the proposed algorithm improved the recognition rate by 5.5% compared with the traditional MFCC, and had a better recognition performance in the low SNR environment.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=marine%20mammals&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">marine mammals;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sound%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sound recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=support%20vector%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">support vector machine;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=cepstral%20coefficients&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">cepstral coefficients;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=temporal%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">temporal features;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-05-16</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Zhejiang Provincial Natural Science Foundation of China (LY18F030006);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="40">海洋中有许多濒危的哺乳动物, 有效地对其进行识别进而估计分布区域是该领域的热点问题。目前, 应用较多的是图像观测识别和DNA分析检测方法<citation id="111" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。但是这些方法存在着成本高、识别率有待提高等缺点。生物学家已经证实对于海洋哺乳动物的声音识别是一种估计其物种分布的可靠方法<citation id="112" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。然而, 海底信号包含着不同的噪声, 这为识别带来了一定的难度。</p>
                </div>
                <div class="p1">
                    <p id="41">目前对于海洋哺乳动物声音识别方法主要分为两种:一种是根据其频谱图计算出的特征进行分类。文献<citation id="113" type="reference">[<a class="sup">2</a>]</citation>通过提取出的能量与频谱互相关系数对6种海洋哺乳动物声音进行手动分类。文献<citation id="114" type="reference">[<a class="sup">3</a>]</citation>通过鲸类发出声音的独特频率带宽来识别一段音频中是否有该种鲸类的声音, 达到了90%的准确率。这些方法在声音种类比较少的情况下有较好的分类效果, 但是难以区分一些声音频谱较为相近的物种。海洋哺乳动物能发出多种不同声音, 这也为识别带来了难度;另一种方法则是对海洋哺乳动物声音的特征参数进行提取后, 利用机器学习方法对其进行分类。该方法能够识别一些仅靠频谱图无法分类的声音。文献<citation id="115" type="reference">[<a class="sup">4</a>]</citation>提取了北大西洋鲸类的梅尔倒谱系数 (Mel Frequency Cepstral Coefficients, MFCC) 和离散小波变换 (Discrete Wavelet Transformation, DWT) 系数, 利用支持向量机 (Support Vector Machine, SVM) 对其叫声分类, 实验表明该方法比利用频谱系数分类取得更好的效果。文献<citation id="116" type="reference">[<a class="sup">5</a>]</citation>以MFCC作为特征, 通过隐马尔可夫模型和高斯混合模型对虎鲸的声音进行分类, 达到了90%的识别率;文献<citation id="117" type="reference">[<a class="sup">6</a>]</citation>提取了7种鲸类声音的MFCC并利用SVM识别, 达到了95%的识别率, 但这种方法在低信噪比环境下不能很好地进行分类;文献<citation id="118" type="reference">[<a class="sup">7</a>]</citation>提取了鲸类叫声的时间频域特征, 用回归分类树进行分类, 取得较好的结果, 但是该方法仅适用于鲸类的叫声, 具有一定局限性, 且计算过程较为繁琐。</p>
                </div>
                <div class="p1">
                    <p id="42">由以上描述分析可知, 这些研究都是针对一种或几种海洋哺乳动物音频信号进行分类, 无法推广到更多的海洋哺乳动物物种, 且提取的特征大多依赖于MFCC。海洋中一些动物如鲸类与海豚能发出频率范围宽且在人耳听觉范围之外的声音<citation id="119" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 如蓝鲸能发出高达20 kHz的叫声, 而鳍鲸能发出低至几十赫兹的声音。在识别物种较多、频率跨度较大的情况下仅依靠MFCC并不能很好地表征特征信息<citation id="120" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="43">为了尽可能地识别更多种类的样本, 提高算法在海洋低信噪比环境下的识别率, 本文将不同倒谱系数以及时域特征进行有效融合来获得更为完整的特征参数。本文算法整体流程如图1所示:首先将海洋哺乳动物声音通过基于海洋环境的预处理方法进行处理;接着分别提取MFCC、线性倒谱系数 (Linear Frequency Cepstral Coefficients, LFCC) <citation id="121" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>以及时域特征进行融合;最后, 将融合后的特征利用SVM进行识别, 得到识别结果。</p>
                </div>
                <div class="area_img" id="44">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905008_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法整体流程图" src="Detail/GetImg?filename=images/DZKK201905008_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法整体流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905008_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1. System diagram</p>

                </div>
                <h3 id="45" name="45" class="anchor-tag"><b>1</b> 基于海洋环境下的预处理</h3>
                <div class="p1">
                    <p id="46">海洋动物声音中包括了静态、非静态以及准静态的噪声<citation id="122" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。为了减小背景噪声的影响, 需要通过端点检测算法从背景噪声中提取音频段。Härmä提出了从背景噪声中提取鸟类声音信号的端点检测算法<citation id="123" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 该算法同样适用于海洋哺乳动物声音处理。该算法应用于海洋环境下的流程如图2所示。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905008_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文端点检测流程图" src="Detail/GetImg?filename=images/DZKK201905008_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文端点检测流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905008_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2. Segmentation method of this paper</p>

                </div>
                <div class="p1">
                    <p id="48">其中, <i>D</i>为幅度阈值, 经多次实验取为20 dB。<i>A</i> (<i>n</i>) 为第<i>n</i>次提取得到的最大幅值, <i>B</i> (<i>i</i>) 为第<i>i</i>帧信号的幅值。</p>
                </div>
                <div class="p1">
                    <p id="49">为了提高分类准确率, 需要对提取出的音频段做进一步预处理。声音信号随频率的增长呈指数级的衰减, 使得大多能量集中在低频带<citation id="124" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。为了补偿高频分量的损失<citation id="125" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 需要对音频信号利用FIR (Finite Impulse Response) 滤波器进行预加重, 滤波器公式如式 (1) 所示</p>
                </div>
                <div class="p1">
                    <p id="50"><i>H</i> (<i>z</i>) =1-<i>βz</i><sup>-1</sup>      (1) </p>
                </div>
                <div class="p1">
                    <p id="51">式中, <i>β</i>一般取0.97<citation id="126" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="52">预加重后, 通过汉明窗对声音信号分帧。汉明窗能最小化频域中的最大旁瓣, 获得最大化的旁瓣抑制<citation id="127" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 可以表示为</p>
                </div>
                <div class="area_img" id="53">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZKK201905008_05300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="55">其中, T为一帧信号的长度。加窗前的信号表示为a (n) , 加窗后得到的信号s (n) 计算方法如下</p>
                </div>
                <div class="p1">
                    <p id="56">s (n) =w (n) a (n)      (3) </p>
                </div>
                <h3 id="57" name="57" class="anchor-tag"><b>2</b> 特征提取与融合</h3>
                <h4 class="anchor-tag" id="58" name="58"><b>2.1</b> 倒谱特征</h4>
                <div class="p1">
                    <p id="59">MFCC的提取方法<citation id="128" type="reference"><link href="22" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是将预处理后的信号<i>s</i> (<i>n</i>) 作FFT (Fast Fourier Transformation) 变换后, 将其对数能量谱按梅尔频域分布的滤波器组作卷积, 再对输出向量作离散余弦变换, 其计算如式 (4) 所示</p>
                </div>
                <div class="p1">
                    <p id="60">mfcc<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mfrac><mn>2</mn><mi>Μ</mi></mfrac></mrow></msqrt><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>log</mi></mrow></mstyle><mo stretchy="false">[</mo><mi>S</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mrow><mi>cos</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mtext>π</mtext><mtext>j</mtext><mo stretchy="false"> (</mo><mn>2</mn><mi>m</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><mn>2</mn><mi>Μ</mi></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="62">式中, mfcc (<i>i</i>, <i>j</i>) 为第<i>i</i>帧信号的MFCC, <i>M</i>为滤波器个数, <i>j</i>为MFCC个数, <i>S</i> (<i>i</i>, <i>m</i>) 为在梅尔频域下的功率谱。</p>
                </div>
                <div class="p1">
                    <p id="63">LFCC则是从线性频域中计算得到<citation id="129" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 其计算如式 (5) 所示</p>
                </div>
                <div class="p1">
                    <p id="64">lfcc<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mfrac><mn>2</mn><mi>Μ</mi></mfrac></mrow></msqrt><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>log</mi></mrow></mstyle><mo stretchy="false">[</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mrow><mi>cos</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mtext>π</mtext><mtext>j</mtext><mo stretchy="false"> (</mo><mn>2</mn><mi>m</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><mn>2</mn><mi>Μ</mi></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="66">式中, lfcc (<i>i</i>, <i>j</i>) 为第<i>i</i>帧信号的LFCC;<i>L</i> (<i>i</i>, <i>m</i>) 为在线性频域下计算所得的功率谱。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.2</b> 时域特征</h4>
                <div class="p1">
                    <p id="68">谱熵<citation id="130" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation> (Spectral Entropy, SE) 反映了一段语音帧的无序化程度, 且对噪声有较好的鲁棒性, 其计算如式 (6) 所示</p>
                </div>
                <div class="p1">
                    <p id="69"><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>S</mtext><mtext>E</mtext><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ν</mi><mo>/</mo><mn>2</mn></mrow></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo><mrow><mi>log</mi></mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="71">式中, <i>p</i><sub><i>i</i></sub> (<i>k</i>) 为第<i>i</i>帧第<i>k</i>个频率分量对应的概率密度<citation id="131" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="72">信号长度<citation id="132" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation> (Signal Duration, SD) 为端点检测后得到的一段有声段的长度, 其计算如式 (7) 所示</p>
                </div>
                <div class="p1">
                    <p id="73">SD<sub><i>i</i></sub>=<i>s</i> (<i>n</i><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>e</mi><mi>i</mi></msubsup></mrow></math></mathml>) -<i>s</i> (<i>n</i><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>i</mi></msubsup></mrow></math></mathml>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="76">式中, <i>n</i><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>i</mi></msubsup></mrow></math></mathml>和<i>n</i><mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>e</mi><mi>i</mi></msubsup></mrow></math></mathml>分别为第<i>i</i>帧音频信号对应的语音端的起始、结束时间点。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>2.3</b> 特征融合</h4>
                <div class="p1">
                    <p id="80">本文选取MFCC、LFCC、谱熵与信号长度进行特征融合的理论依据如下:</p>
                </div>
                <div class="p1">
                    <p id="81"> (1) 海洋哺乳动物的发声涵盖了非常宽广的频域<citation id="133" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 而Mel滤波器的频谱分辨率随着频率增加而降低, 使得MFCC在高频段的表征能力不足。LFCC在频率较高时识别性能较好<citation id="134" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 且在噪声环境中有较好的鲁棒性;</p>
                </div>
                <div class="p1">
                    <p id="82"> (2) MFCC能代表声道形状特性, LFCC则更能反映声道长度<citation id="135" type="reference"><link href="16" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 将两者融合能获得对声道特性更为完整的描述;</p>
                </div>
                <div class="p1">
                    <p id="83"> (3) 谱熵与倒谱特征是两种相互独立的特征, 谱熵能够代表声音激励源的特性<citation id="136" type="reference"><link href="24" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 因此本文选取谱熵作为对倒谱特征的一种补充;</p>
                </div>
                <div class="p1">
                    <p id="84"> (4) 信号长度作为最基本的时域特征, 已广泛应用于海洋动物声音识别<citation id="137" type="reference"><link href="14" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。不同海洋哺乳动物能够发出长度差异较大的声音, 且信号长度与谱熵反映的是时域在不同方面的特征。</p>
                </div>
                <div class="p1">
                    <p id="85">基于以上描述, 本文将海洋哺乳动物声音信号的MFCC、LFCC作为倒谱特征, 将谱熵、信号长度作为时域特征进行融合来获得完整的特征参数。融合后的特征表示为</p>
                </div>
                <div class="p1">
                    <p id="86">FUSION=[MFCC LFCC SE SD]</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag"><b>3</b> 支持向量机识别</h3>
                <div class="p1">
                    <p id="88">SVM是为了解决回归和分类问题而提出的一种建立在统计学习理论中的具有严密理论基础的机器学习方法<citation id="138" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。SVM的原理是寻找一个满足分类要求的最优分类超平面, 并使该超平面在保证分类精度的同时能够最大化其两侧的空白区域<citation id="139" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。声音信号是一类线性不可分的数据, 需要利用核函数将其从低维空间映射到高维空间, 并在高维空间中构造线性可分超平面<citation id="140" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。通过引入核函数, 可以将问题转化为如下优化问题</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>max</mi></mrow><mtext> </mtext><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>α</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mi>k</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mtext> </mtext><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn><mo>≤</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≤</mo><mi>C</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">其中α<sub>i</sub>、α<sub>j</sub>是引入的拉格朗日乘子;<b><i>x</i></b><sub><i>i</i></sub>、<b><i>x</i></b><sub><i>j</i></sub>为特征向量;<i>y</i><sub><i>i</i></sub>、<i>y</i><sub><i>j</i></sub>在符号不同时对应不同类别的数据点;<i>C</i>为大于0的参数, 决定样本在多大程序上满足约束条件;<i>k</i> (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>x</i></b><sub><i>j</i></sub>) 为核函数;<i>N</i>为样本总数。求解后得到SVM的输出为</p>
                </div>
                <div class="p1">
                    <p id="91"><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>sgn</mi></mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>b</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="93">式中, <i>b</i>是模型参数。核函数和<i>C</i>的选择对分类结果有较大的影响<citation id="141" type="reference"><link href="28" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。在核函数中, RBF (Radial Basis Function) 核函数表现相对稳定, 分类性能较好<citation id="142" type="reference"><link href="26" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。故本文选用RBF作为核函数, <i>C</i>值则通过网格搜索法结合K交叉验证的方法进行选择。</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag"><b>4</b> 实验过程及结果分析</h3>
                <h4 class="anchor-tag" id="95" name="95"><b>4.1</b> 声音样本集</h4>
                <div class="p1">
                    <p id="96">本文选择的数据源来自加利福尼亚大学的数据库“<i>Voices in the sea</i>”<citation id="143" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>和康奈尔大学的<i>Macaulay</i>项目<citation id="144" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。为了得到尽可能多的数据, 本文选取了其中61种海洋哺乳动物的音频进行实验, 每种动物种类的声音样本数为6～7个, 一共得到407个样本, 其中每个样本的时间长度为10～20 <i>s</i>。</p>
                </div>
                <div class="p1">
                    <p id="97">本文实验平台为<i>MATLAB</i> 2013<i>b</i>。为了便于后续比较, 对每种音频进行44.1 <i>kHz</i>重采样, 按照帧长64, 帧与帧之间重叠50%的条件对信号预处理。海洋环境下的低信噪比会对结果造成一定影响<citation id="145" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。为了提高端点检测的准确率, 对端点检测得到的音频段做如下筛选<citation id="146" type="reference"><link href="34" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>:首先剔除结果中长度小于300的音频段;然后计算所有提取到的音频段的平均能量和最大能量;最后剔除小于最大能量0.15倍或大于平均能量1.5倍的音频段, 得到2 359个音频段。图4是对白鳍豚端点检测后得到的结果, 可以看出音频段被较好地从背景噪声中提取。选取滤波器个数24对声音信号进行特征提取与融合, 结果如图5所示。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905008_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 白鳍豚端点检测结果图" src="Detail/GetImg?filename=images/DZKK201905008_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 白鳍豚端点检测结果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905008_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4. White dolphin spectrogram and sound signal segmentation</p>
                                <p class="img_note"> (a) 语谱图 (b) 端点检测结果</p>
                                <p class="img_note"> (a) Sound spectrogram (b) Sound segmentation result</p>

                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905008_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 白鳍豚特征融合结果图" src="Detail/GetImg?filename=images/DZKK201905008_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 白鳍豚特征融合结果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905008_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5. Feature fusion result of white dolphin</p>
                                <p class="img_note"> (a) MFCC (b) LFCC (c) MFCC+LFCC (d) MFCC+LFCC+SE+SD</p>
                                <p class="img_note"> (a) MFCC (b) LFCC (c) MFCC+LFCC (d) MFCC+LFCC+SE+SD</p>

                </div>
                <h4 class="anchor-tag" id="100" name="100"><b>4.2</b> 实验设计与结果分析</h4>
                <div class="p1">
                    <p id="101"> (1) 为了比较不同分类器下不同特征的识别正确率, 本文除SVM分类之外还选取了2种方法, 即K近邻算法<citation id="147" type="reference"><link href="8" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation> (K Nearest Neighbor, KNN) 及随机森林<citation id="148" type="reference"><link href="36" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation> (Random Forest, RF) 作为分类器, 通过融合前后的特征进行分类并比较结果。为了得到相对客观的结果, 每次实验随机选取样本中的50%为训练集, 结合K折交叉验证得到训练模型。其中, 交叉验证中<i>K</i>取5, 识别率取50次实验的平均值。识别结果如表1所示, 标准差用std表示。</p>
                </div>
                <div class="p1">
                    <p id="102">可以看出在使用同样的特征参数时, SVM分类器的识别率和标准差要优于其它两种分类器, 表明SVM有更好的识别性能。而通过不同特征参数、同一分类器得到的结果可以看出, 融合后的特征较传统倒谱系数在识别率上有较大提升。其中, 在分类器为SVM时, 融合后的特征较MFCC、LFCC分别提升了5.5%、4.66%。图6为用箱线图表示的几种不同特征通过SVM识别后得到的结果。结合表1和图6可以看出, LFCC的正确率要略高于MFCC, 这是由于大多数海洋哺乳动物能发出高频的声音。此外, 由于一些海洋动物声音间的频谱差异较大, 因此对它们的识别率达到了100%。而另一些音频中由于混入了其它动物的声音或较多的背景噪声, 使得分类正确率较低, 在箱线图中作为异常值出现。</p>
                </div>
                <div class="area_img" id="103">
                    <p class="img_tit"><b>表</b>1 <b>不同分类器下分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1. Identification results of different classifiers</p>
                    <p class="img_note"></p>
                    <table id="103" border="1"><tr><td>数据集</td><td>特征</td><td>分类器</td><td>训练时间/s</td><td>识别率/%±std</td></tr><tr><td rowspan="12"><br />海洋哺乳动物音频 (61种, 407个样本) </td><td rowspan="3"><br />MFCC</td><td><br />KNN</td><td>2.02</td><td>87.88%±7.89%</td></tr><tr><td><br />RF</td><td>3.49</td><td>89.04%±4.55%</td></tr><tr><td><br />SVM</td><td>2.57</td><td>90.07%±3.23%</td></tr><tr><td rowspan="3"><br />LFCC</td><td><br />KNN</td><td>2.10</td><td>89.74%±9.97%</td></tr><tr><td><br />RF</td><td>3.53</td><td>91.01%±6.64%</td></tr><tr><td><br />SVM</td><td>2.71</td><td>91.53±5.02%</td></tr><tr><td rowspan="3"><br />MFCC+LFCC</td><td><br />KNN</td><td>4.79</td><td>93.94%±5.73%</td></tr><tr><td><br />RF</td><td>6.11</td><td>93.81%±6.76%</td></tr><tr><td><br />SVM</td><td>5.01</td><td>94.48±4.03%</td></tr><tr><td rowspan="3"><br />MFCC+LFCC+<br />SE+SD</td><td><br />KNN</td><td>4.86</td><td>94.88%±7.04%</td></tr><tr><td><br />RF</td><td>5.91</td><td>94.91%±5.95%</td></tr><tr><td><br />SVM</td><td>5.07</td><td>95.67%±4.96%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905008_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 用箱线图表示的SVM识别结果" src="Detail/GetImg?filename=images/DZKK201905008_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 用箱线图表示的SVM识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905008_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 6. Detailed accuracy with SVM</p>

                </div>
                <div class="p1">
                    <p id="105"> (2) 由于海洋环境的复杂性, 为了进一步验证本文算法的鲁棒性, 文中从样本库中选取了海洋环境下的自然噪声、人为噪声、未知噪声用于加噪处理。对通过端点检测后提取的每个音频段按信噪比40 dB、30 dB、20 dB、10 dB、0 dB、-10 dB分别添加3种噪声, 识别率取50次实验的平均值, 结果如图7所示。从图中可以看出, 在信噪比逐渐降低的过程中, 融合后的特征下降幅度最为平缓, 说明在海洋环境下融合后的特征有较好的抗噪鲁棒性。在信噪比为10 dB和0 dB时, 融合后的特征在识别率上提升最为显著。然而, 当信噪比降低到0 dB时, 融合后的特征取得的识别率低于30%, 这可能是由于此时音频段的能量小于噪声的能量。此外, 通过比较不同种类噪声的结果可以看出, 海洋环境下的不同噪声对识别率影响也不同, 其中未知噪声对识别率影响最大, 识别率下降最明显。同时, 当信噪比低于10 dB时, LFCC的识别率要普遍高于MFCC, 而MFCC在信噪比低于一定阈值后识别性能会明显下降。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZKK201905008_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同特征在3种环境下不同信噪比的识别率" src="Detail/GetImg?filename=images/DZKK201905008_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同特征在3种环境下不同信噪比的识别率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZKK201905008_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 7. Identification results of different SNR for different features in three environments</p>
                                <p class="img_note"> (a) 自然噪声 (b) 人为噪声 (c) 未知噪声</p>
                                <p class="img_note"> (a) natural noise (b) anthropogenic noise (c) unknown noise</p>

                </div>
                <div class="p1">
                    <p id="107"> (3) 表2列出了本文算法与近年来对海洋哺乳动物声音识别的算法之间的比较。这些文献与本文所用数据源有所不同, 为了便于比较, 按文献中的方法对本文数据进行识别, 识别率取50次实验平均值。结果表明, 本文算法在识别样本数较多的情况下较其它对比算法在识别率上有较大提升, 能获得更好的识别性能。</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表</b>2 <b>不同文献所用算法的比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2. Comparison with previous method</p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td>参考文献</td><td>特征参数</td><td>原文识别种类</td><td>识别率/% ±std</td></tr><tr><td><br />[4]</td><td>MFCC+DWT</td><td>1</td><td>91.29%±5.29%</td></tr><tr><td><br />[19]</td><td>倍频程</td><td>11</td><td>89.38%±6.86%</td></tr><tr><td><br />本文算法</td><td>MFCC+LFCC<br />+SE+SD</td><td>61</td><td>95.67%±4.96%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>5</b> 结束语</h3>
                <div class="p1">
                    <p id="110">本文提出了一种将海洋哺乳动物声音的不同倒谱系数和时域特征进行融合来获得更为完整的特征向量来进行识别的方法。该方法将海洋哺乳动物声音经过预处理、特征提取与融合、支持向量机识别后, 得到识别结果。实验表明, 本文算法在样本数较大的情况下能达到较高的识别准确率, 且在海洋低信噪比的环境下比传统倒谱系数有更好的识别性能, 为海洋哺乳动物声音识别提供了新的思路和方向, 具有一定的实用价值。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600250509&amp;v=MTY1NTQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybkpLRjBYYnhBPU5pZk9mYks4SHRETXFZOUZadTRQQ1h3d29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> David E, Hanny et al.Marine mammal acoustic detections in the northeastern Chukchi Sea, September 2007-July 2011[J].Continental Shelf Research, 2013 (67) :127-146.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Passive acoustic detection and classification of marine mammal vocalizations">

                                <b>[2]</b> Nanaware S, Shastri R, Joshi Y, et al.Passive acoustic detection and classification of marine mammal vocalizations[C].Lucknow:International Conference on Communication and Signal Processing, 2014.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600879610&amp;v=MDk1MzQ5RmJPd0dDbjA1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcm5KS0YwWGJ4QT1OaWZPZmJLN0h0RE5xWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> André M, Van d S M, Zaugg S, et al.Listening to the Deep:live monitoring of ocean noise and cetacean acoustic signals.[J].Marine Pollution Bulletin, 2011, 63 (1-4) :18-26.
                            </a>
                        </p>
                        <p id="8">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A New approach for north atlantic right whale upcall detection">

                                <b>[4]</b> Ibrahim A K, Zhuang H, Erdol N, et al.A New approach for north atlantic right whale upcall detection[C].Xi’an:International Symposium on Computer, Consumer and Control, 2016.
                            </a>
                        </p>
                        <p id="10">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hidden Markov and Gaussian mixture models for automatic call classification">

                                <b>[5]</b> Brown J C, Smaragdis P.Hidden Markov and Gaussian mixture models for automatic call classification[J].Journal of the Acoustical Society of America, 2009, 125 (6) :EL221.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Vocalization based individual classification of humpback whales using support vector machine">

                                <b>[6]</b> Suleman M, Tamaki Ura.Vocalization based individual classification of humpback whales using support vector machine[C].Aberdeen:Oceans, 2007.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=North atlantic right whale acoustic signal processing:Part I.comparison of machine learning recognition algorithms">

                                <b>[7]</b> Dugan P J, Rice A N, Urazghildiiev I R, et al.North atlantic right whale acoustic signal processing:Part I.comparison of machine learning recognition algorithms[C].Long Island:Applications and Technology Conference, 2010.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Linear versus mel frequency cepstral coefficients for speaker recognition">

                                <b>[8]</b> Zhou X, Garcia-Romero D, Duraiswami R, et al.Linear versus mel frequency cepstral coefficients for speaker recognition[C].Hawaii:Automatic Speech Recognition and Understanding, 2011.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic identification of bird species based on sinusoidal modeling ofsyllables">

                                <b>[9]</b> Harma A.Automatic identification of bird species based on sinusoidal modeling of syllables[C].Hong Kong:IEEE International Conference on Acoustics, Speech and Signal Processing, 2003.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787512412286000&amp;v=MTg5MDV4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5qVXJmTEkxc1dYRnF6R2JhNUhOWE5yWTFOWXVzUERCTTh6&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 宋知用.MATLAB在语音信号分析与合成中的应用[M].北京:北京航空航天大学出版社, 2013.Song Zhiyong.Application of MATLAB in speech signal analysis and synthesis[M].Beijing:Beihang University Press, 2013.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201707003&amp;v=MDM2MzJPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG1VTHJLSVRmQVpiRzRIOWJNcUk5Rlo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 张帅林.改进的智能家居语音关键词识别算法[J].电子科技, 2017, 30 (7) :5-8.Zhang Shuailin.Improved speech keyword spotting algorithm in smart home[J].Electronic Science and Technology, 2017, 30 (7) :5-8.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2016S2053&amp;v=Mjg0NTQ5QVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG1VTHJLTHo3QmI3RzRIOWV2clk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 李艳, 成凌飞, 张培玲.一种基于改进谱熵的语音端点检测方法[J].计算机科学, 2016, 43 (S2) :233-236.Li Yan, Cheng lingfei, Zhang Peiling.Speech endpoint detection based on improved spectral entropy[J].Computer Science, 2016, 43 (S2) :233-236.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201708017&amp;v=MTM1NjZHNEg5Yk1wNDlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEbVVMcktJVGZBWmI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 张冬松, 马琪.一种基于SVM的负载识别算法[J].电子科技, 2017, 30 (8) :59-62.Zhang Dongsong, Ma Qi.A load identification algorithm based on SVM[J].Electronic Science and Technology, 2017, 30 (8) :59-62.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201007002&amp;v=MDQ0MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVab0ZpRG1VTHJLTHo3WWFiRzRIOUhNcUk5RlpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 余清清, 李应, 李勇.基于SVM模型的自然环境声音的分类[J].计算机与数字工程, 2010, 38 (7) :1-5.Yu Qingqing, Li Ying, Li Yong.A SVM-based classification approach for natural sounds[J].Computer &amp; Digital Engineering, 2010, 38 (7) :1-5.
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Voices in the sea">

                                <b>[15]</b> SanDiego University of California.Voices in the sea[EB/OL]. (2015-07-27) [2018-04-02] http://cetus.ucsd.edu/voicesinthesea_org/.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Macaulay library">

                                <b>[16]</b> The Cornell Lab of Ornithology.Macaulay library[EB/OL]. (2014-09-28) [2018-04-02] http://macaulaylibrary.org/.
                            </a>
                        </p>
                        <p id="34">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A three-parameter model for classifying anurans into four genera based on advertisement calls">

                                <b>[17]</b> Gingras B, Fitch W T.A three-parameter model for classifying anurans into four genera based on advertisement calls[J].Journal of the Acoustical Society of America, 2013, 133 (1) :547-59.
                            </a>
                        </p>
                        <p id="36">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Integration of real time odontocete call classification algorithm into PAMGUARD signal processing software">

                                <b>[18]</b> Oswald M, Oswald J N, Lammers M O, et al.Integration of real time odontocete call classification algorithm into PAMGUARD signal processing software[J].Journal of the Acoustical Society of America, 2011, 129 (4) :2639-2639.
                            </a>
                        </p>
                        <p id="38">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8E1DDB1521154CBB5A88EEAE306A9CCC&amp;v=MzE1ODcxUFFxVDJSRTFmOE9kTnNuc0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXQ1Z3pMdTh4YW89TmlmT2Zidk5INlc0M1k1QVp1b09DWGhLdldRV216ZA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> González-Hernández F R, Sánchez-Fernández L P, Suárez-Guerra S, et al.Marine mammal sound classification based on a parallel recognition model and octave analysis[J].Applied Acoustics, 2017, 119 (3) :17-28.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZKK201905008" />
        <input id="dpi" type="hidden" value="399" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201905008&amp;v=MDkzMzA1NE8zenFxQnRHRnJDVVI3cWZadVpvRmlEbVVMckxJVGZBWmJHNEg5ak1xbzlGYklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNc25zRDRuRVU4L0NLNVRPODU4TT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

