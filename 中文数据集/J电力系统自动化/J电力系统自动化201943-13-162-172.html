

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136545302756250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDLXT201913020%26RESULT%3d1%26SIGN%3dr4ub4TUMxjiqPHlO7vmNGVtroQU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DLXT201913020&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DLXT201913020&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201913020&amp;v=MTg2OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OSVNIVGVyRzRIOWpOckk5SFpJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#77" data-title="&lt;b&gt;0 引言&lt;/b&gt; "><b>0 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#84" data-title="&lt;b&gt;1&lt;/b&gt; 巡检图像目标检测方法 "><b>1</b> 巡检图像目标检测方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="&lt;b&gt;1.1 R-FCN&lt;/b&gt;目标检测方法"><b>1.1 R-FCN</b>目标检测方法</a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;1.2&lt;/b&gt; 对目标检测方法的若干改进"><b>1.2</b> 对目标检测方法的若干改进</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="&lt;b&gt;2&lt;/b&gt; 目标检测流程与实验设计 "><b>2</b> 目标检测流程与实验设计</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#105" data-title="&lt;b&gt;2.1&lt;/b&gt; 数据集"><b>2.1</b> 数据集</a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;2.2&lt;/b&gt; 模型训练"><b>2.2</b> 模型训练</a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;2.3&lt;/b&gt; 模型评估"><b>2.3</b> 模型评估</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;2.4&lt;/b&gt; 对比实验设计"><b>2.4</b> 对比实验设计</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="&lt;b&gt;3 结果分析&lt;/b&gt; "><b>3 结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#125" data-title="&lt;b&gt;3.1 R-FCN&lt;/b&gt;与同类算法对比分析"><b>3.1 R-FCN</b>与同类算法对比分析</a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;3.2&lt;/b&gt; 改进方法结果分析"><b>3.2</b> 改进方法结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#135" data-title="&lt;b&gt;4&lt;/b&gt; 结语 "><b>4</b> 结语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#165" data-title="附录A稀有样本频次加倍算法及在MS COCO数据集上的表现 ">附录A稀有样本频次加倍算法及在MS COCO数据集上的表现</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#168" data-title="附录B ">附录B</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#170" data-title="附录C ">附录C</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#173" data-title="附录D ">附录D</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#175" data-title="附录E ">附录E</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#89" data-title="&lt;b&gt;图1 Faster R-CNN及R-FCN网络结构&lt;/b&gt;"><b>图1 Faster R-CNN及R-FCN网络结构</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;图2 研究流程图&lt;/b&gt;"><b>图2 研究流程图</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;表1 R-FCN及对比算法目标检测mAP及推理时间对比&lt;/b&gt;"><b>表1 R-FCN及对比算法目标检测mAP及推理时间对比</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;图3 R-FCN及对比算法的mAP-IoU阈值曲线&lt;/b&gt;"><b>图3 R-FCN及对比算法的mAP-IoU阈值曲线</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;Table 2 AP of R-FCN object detection before and after improvement&lt;/b&gt;"><b>Table 2 AP of R-FCN object detection before and after improvement</b></a></li>
                                                <li><a href="#167" data-title="表A1稀有样本频次加倍算法在MS COCO 2017val上的AP">表A1稀有样本频次加倍算法在MS COCO 2017val上的AP</a></li>
                                                <li><a href="#169" data-title="图B1样本集图片及目标框标注示例">图B1样本集图片及目标框标注示例</a></li>
                                                <li><a href="#171" data-title="表C1目标框数量及分布">表C1目标框数量及分布</a></li>
                                                <li><a href="#172" data-title="图C1目标框面积占全图比例的分布">图C1目标框面积占全图比例的分布</a></li>
                                                <li><a href="#174" data-title="表D1加入单项改进的R-FCN算法目标检测AP">表D1加入单项改进的R-FCN算法目标检测AP</a></li>
                                                <li><a href="#176" data-title="图E1改进算法目标检测结果示例1">图E1改进算法目标检测结果示例1</a></li>
                                                <li><a href="#177" data-title="图E2改进算法目标检测结果示例2">图E2改进算法目标检测结果示例2</a></li>
                                                <li><a href="#178" data-title="图E3改进算法目标检测结果示例3">图E3改进算法目标检测结果示例3</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     国家能源局, 中国电力企业联合会.2017年全国电力可靠性年度报告[R].北京:国家能源局, 2018.National Energy Administration, China Electricity Council.2017 annual report of national power reliability[R].Beijing:National Energy Administration, 2018.</a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 仝卫国, 苑津莎, 李宝树.图像处理技术在直升机巡检输电线路中的应用综述[J].电网技术, 2010, 34 (12) :204-208.TONG Weiguo, YUAN Jinsha, LI Baoshu.Application of image processing in patrol inspection of overhead transmission line by helicopter[J].Power System Technology, 2010, 34 (12) :204-208." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DWJS201012040&amp;v=MzA3Mjc0SDlITnJZOUJaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeXJtVUwvTklUckJmYkc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         仝卫国, 苑津莎, 李宝树.图像处理技术在直升机巡检输电线路中的应用综述[J].电网技术, 2010, 34 (12) :204-208.TONG Weiguo, YUAN Jinsha, LI Baoshu.Application of image processing in patrol inspection of overhead transmission line by helicopter[J].Power System Technology, 2010, 34 (12) :204-208.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 杨挺, 赵黎媛, 王成山.人工智能在电力系统及综合能源系统中的应用综述[J].电力系统自动化, 2019, 43 (1) :2-14.DOI:10.7500/AEPS20180706005.YANG Ting, ZHAO Liyuan, WANG Chengshan.Review on application of artificial intelligence in power system and integrated energy system[J].Automation of Electric Power Systems, 2019, 43 (1) :2-14.DOI:10.7500/AEPS 20180706005." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201901002&amp;v=MDg3NTlOSVNIVGVyRzRIOWpNcm85RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         杨挺, 赵黎媛, 王成山.人工智能在电力系统及综合能源系统中的应用综述[J].电力系统自动化, 2019, 43 (1) :2-14.DOI:10.7500/AEPS20180706005.YANG Ting, ZHAO Liyuan, WANG Chengshan.Review on application of artificial intelligence in power system and integrated energy system[J].Automation of Electric Power Systems, 2019, 43 (1) :2-14.DOI:10.7500/AEPS 20180706005.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 程乐峰, 余涛, 张孝顺, 等.机器学习在能源与电力系统领域的应用和展望[J].电力系统自动化, 2019, 43 (1) :15-43.DOI:10.7500/AEPS20180814007.CHENG Lefeng, YU Tao, ZHANG Xiaoshun, et al.Machine learning for energy and electric power systems:state of the art and prospects[J].Automation of Electric Power Systems, 2019, 43 (1) :15-43.DOI:10.7500/AEPS20180814007." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201901003&amp;v=MjIwNjRSN3FmWnVac0Z5cm1VTC9OSVNIVGVyRzRIOWpNcm85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         程乐峰, 余涛, 张孝顺, 等.机器学习在能源与电力系统领域的应用和展望[J].电力系统自动化, 2019, 43 (1) :15-43.DOI:10.7500/AEPS20180814007.CHENG Lefeng, YU Tao, ZHANG Xiaoshun, et al.Machine learning for energy and electric power systems:state of the art and prospects[J].Automation of Electric Power Systems, 2019, 43 (1) :15-43.DOI:10.7500/AEPS20180814007.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 赵振兵, 金思新, 刘亚春.基于NSCT的航拍绝缘子图像边缘提取方法[J].仪器仪表学报, 2012, 33 (9) :2045-2052.ZHAO Zhenbing, JIN Sixin, LIU Yachun.Aerial insulator image edge extraction method based on NSCT[J].Chinese Journal of Scientific Instrument, 2012, 33 (9) :2045-2052." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201209018&amp;v=MjMwNzE0TzN6cXFCdEdGckNVUjdxZlp1WnNGeXJtVUwvTlBEelRiTEc0SDlQTXBvOUViSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         赵振兵, 金思新, 刘亚春.基于NSCT的航拍绝缘子图像边缘提取方法[J].仪器仪表学报, 2012, 33 (9) :2045-2052.ZHAO Zhenbing, JIN Sixin, LIU Yachun.Aerial insulator image edge extraction method based on NSCT[J].Chinese Journal of Scientific Instrument, 2012, 33 (9) :2045-2052.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 黄宵宁, 张真良.直升机巡检航拍图像中绝缘子图像的提取算法[J].电网技术, 2010, 34 (1) :194-197.HUANG Xiaoning, ZHANG Zhenliang.A method to extract insulator image from aerial image of helicopter patrol[J].Power System Technology, 2010, 34 (1) :194-197." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DWJS201001038&amp;v=MDIxNjBJVHJCZmJHNEg5SE1ybzlHYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlybVVML04=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         黄宵宁, 张真良.直升机巡检航拍图像中绝缘子图像的提取算法[J].电网技术, 2010, 34 (1) :194-197.HUANG Xiaoning, ZHANG Zhenliang.A method to extract insulator image from aerial image of helicopter patrol[J].Power System Technology, 2010, 34 (1) :194-197.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" WU Q, AN J.An active contour model based on texture distribution for extracting inhomogeneous insulators from aerial images[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (6) :3613-3626." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An active contour model based on texture distribution for extracting inhomogeneous insulators from aerial images">
                                        <b>[7]</b>
                                         WU Q, AN J.An active contour model based on texture distribution for extracting inhomogeneous insulators from aerial images[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (6) :3613-3626.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 赵振兵, 徐磊, 戚银城, 等.基于Hough检测和C-V模型的航拍绝缘子自动协同分割方法[J].仪器仪表学报, 2016, 37 (2) :395-403.ZHAO Zhenbing, XU Lei, QI Yincheng, et al.Automatic co-segmentation method for aerial insulator based on Hough detection and C-V model[J].Chinese Journal of Scientific Instrument, 2016, 37 (2) :395-403." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201602021&amp;v=MTY5MDl1WnNGeXJtVUwvTlBEelRiTEc0SDlmTXJZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         赵振兵, 徐磊, 戚银城, 等.基于Hough检测和C-V模型的航拍绝缘子自动协同分割方法[J].仪器仪表学报, 2016, 37 (2) :395-403.ZHAO Zhenbing, XU Lei, QI Yincheng, et al.Automatic co-segmentation method for aerial insulator based on Hough detection and C-V model[J].Chinese Journal of Scientific Instrument, 2016, 37 (2) :395-403.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 赵振兵, 王乐.一种航拍绝缘子串图像自动定位方法[J].仪器仪表学报, 2014, 35 (3) :558-565.ZHAO Zhenbing, WANG Le.Aerial insulator string image automatic location method[J].Chinese Journal of Scientific Instrument, 2014, 35 (3) :558-565." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201403010&amp;v=MTE5NTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OUER6VGJMRzRIOVhNckk5RVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         赵振兵, 王乐.一种航拍绝缘子串图像自动定位方法[J].仪器仪表学报, 2014, 35 (3) :558-565.ZHAO Zhenbing, WANG Le.Aerial insulator string image automatic location method[J].Chinese Journal of Scientific Instrument, 2014, 35 (3) :558-565.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 付晶, 邵瑰玮, 吴亮, 等.利用层次模型进行训练学习的线路设备缺陷检测方法[J].高电压技术, 2017, 43 (1) :266-275.FU Jing, SHAO Guiwei, WU Liang, et al.Defect detection of line facility using hierarchical model with learning algorithm[J].High Voltage Engineering, 2017, 43 (1) :266-275." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDYJ201701035&amp;v=MDk5MDJuU1pMRzRIOWJNcm85R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OSWk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         付晶, 邵瑰玮, 吴亮, 等.利用层次模型进行训练学习的线路设备缺陷检测方法[J].高电压技术, 2017, 43 (1) :266-275.FU Jing, SHAO Guiwei, WU Liang, et al.Defect detection of line facility using hierarchical model with learning algorithm[J].High Voltage Engineering, 2017, 43 (1) :266-275.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 金立军, 胡娟, 闫书佳.基于图像的高压输电线间隔棒故障诊断方法[J].高电压技术, 2013, 39 (5) :1040-1045.JIN Lijun, HU Juan, YAN Shujia.Method of spacer fault diagnose on transmission line based on image procession[J].High Voltage Engineering, 2013, 39 (5) :1040-1045." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDYJ201305004&amp;v=MDk2MzZxQnRHRnJDVVI3cWZadVpzRnlybVVML05JaW5TWkxHNEg5TE1xbzlGWUlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         金立军, 胡娟, 闫书佳.基于图像的高压输电线间隔棒故障诊断方法[J].高电压技术, 2013, 39 (5) :1040-1045.JIN Lijun, HU Juan, YAN Shujia.Method of spacer fault diagnose on transmission line based on image procession[J].High Voltage Engineering, 2013, 39 (5) :1040-1045.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" HOMMA R Z, SOHN O, BOSE R C.Analysis of the recognition and localisation techniques of power transmission lines components in aerial images acquired by drones[J].CIRED—Open Access Proceedings Journal, 2017, 2017 (1) :29-32." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analysis of the recognition and localisation techniques of power transmission lines components in aerial images acquired by drones">
                                        <b>[12]</b>
                                         HOMMA R Z, SOHN O, BOSE R C.Analysis of the recognition and localisation techniques of power transmission lines components in aerial images acquired by drones[J].CIRED—Open Access Proceedings Journal, 2017, 2017 (1) :29-32.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 黄新波, 刘新慧, 张烨, 等.基于红蓝色差和改进&lt;i&gt;K&lt;/i&gt;-means算法的航拍绝缘子分类识别方法[J].高电压技术, 2018, 44 (5) :1528-1534.HUANG Xinbo, LIU Xinhui, ZHANG Ye, et al.Classification recognition method of insulator in aerial image based on the red-blue difference and developed &lt;i&gt;K&lt;/i&gt;-means algorithm[J].High Voltage Engineering, 2018, 44 (5) :1528-1534." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=GDYJ201805018&amp;v=MjEwMTQ5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OSWluU1pMRzRIOW5NcW8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         黄新波, 刘新慧, 张烨, 等.基于红蓝色差和改进&lt;i&gt;K&lt;/i&gt;-means算法的航拍绝缘子分类识别方法[J].高电压技术, 2018, 44 (5) :1528-1534.HUANG Xinbo, LIU Xinhui, ZHANG Ye, et al.Classification recognition method of insulator in aerial image based on the red-blue difference and developed &lt;i&gt;K&lt;/i&gt;-means algorithm[J].High Voltage Engineering, 2018, 44 (5) :1528-1534.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" ZHAI Y, CHEN R, YANG Q, et al.Insulator fault detection based on spatial morphological features of aerial images[J].IEEE Access, 2018, 6:35316-35326." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Insulator fault detection based on spatial morphological features of aerial images">
                                        <b>[14]</b>
                                         ZHAI Y, CHEN R, YANG Q, et al.Insulator fault detection based on spatial morphological features of aerial images[J].IEEE Access, 2018, 6:35316-35326.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 张烨, 冯玲, 穆靖宇, 等.输电线路绝缘子覆冰厚度图像识别算法[J].电力系统自动化, 2016, 40 (21) :195-202.ZHANG Ye, FENG Ling, MU Jingyu, et al.Image identification algorithm of icing thickness for insulator in power transmission lines[J].Automation of Electric Power Systems, 2016, 40 (21) :195-202." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201621030&amp;v=MzA0NTE0TzN6cXFCdEdGckNVUjdxZlp1WnNGeXJtVUwvTklTSFRlckc0SDlmT3JvOUdaSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         张烨, 冯玲, 穆靖宇, 等.输电线路绝缘子覆冰厚度图像识别算法[J].电力系统自动化, 2016, 40 (21) :195-202.ZHANG Ye, FENG Ling, MU Jingyu, et al.Image identification algorithm of icing thickness for insulator in power transmission lines[J].Automation of Electric Power Systems, 2016, 40 (21) :195-202.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 蒋兴良, 夏云峰, 张志劲, 等.基于优化Gabor滤波器的输电导线断股图像检测[J].电力系统自动化, 2011, 35 (15) :78-83.JIANG Xingliang, XIA Yunfeng, ZHANG Zhijin, et al.Image detection for broken strand faults of transmission conductor based on optimized Gabor filter[J].Automation of Electric Power Systems, 2011, 35 (15) :78-83." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201115016&amp;v=MjIzMTdML05JU0hUZXJHNEg5RE5xbzlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlybVU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         蒋兴良, 夏云峰, 张志劲, 等.基于优化Gabor滤波器的输电导线断股图像检测[J].电力系统自动化, 2011, 35 (15) :78-83.JIANG Xingliang, XIA Yunfeng, ZHANG Zhijin, et al.Image detection for broken strand faults of transmission conductor based on optimized Gabor filter[J].Automation of Electric Power Systems, 2011, 35 (15) :78-83.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" 王万国, 田兵, 刘越, 等.基于RCNN的无人机巡检图像电力小部件识别研究[J].地球信息科学学报, 2017, 19 (2) :256-263.WANG Wanguo, TIAN Bing, LIU Yue, et al.Study on the electrical devices detection in UAV images based on region based convolutional neural networks[J].Journal of Geo-information Science, 2017, 19 (2) :256-263." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQXX201702014&amp;v=MDg2MzJGeXJtVUwvTklUelRkckc0SDliTXJZOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         王万国, 田兵, 刘越, 等.基于RCNN的无人机巡检图像电力小部件识别研究[J].地球信息科学学报, 2017, 19 (2) :256-263.WANG Wanguo, TIAN Bing, LIU Yue, et al.Study on the electrical devices detection in UAV images based on region based convolutional neural networks[J].Journal of Geo-information Science, 2017, 19 (2) :256-263.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" 陈庆, 闫斌, 叶润, 等.航拍绝缘子卷积神经网络检测及自爆识别研究[J].电子测量与仪器学报, 2017, 31 (6) :942-953.CHEN Qing, YAN bin, YE Run, et al.Insulator detection and recognition of explosion fault based on convolutional neural networks[J].Journal of Electronic Measurement and Instrumentation, 2017, 31 (6) :942-953." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201706021&amp;v=MTQ2ODNVUjdxZlp1WnNGeXJtVUwvTklUZkNkN0c0SDliTXFZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         陈庆, 闫斌, 叶润, 等.航拍绝缘子卷积神经网络检测及自爆识别研究[J].电子测量与仪器学报, 2017, 31 (6) :942-953.CHEN Qing, YAN bin, YE Run, et al.Insulator detection and recognition of explosion fault based on convolutional neural networks[J].Journal of Electronic Measurement and Instrumentation, 2017, 31 (6) :942-953.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" 李军锋, 王钦若, 李敏.结合深度学习和随机森林的电力设备图像识别[J].高电压技术, 2017, 43 (11) :3705-3711.LI Junfeng, WANG Qinruo, LI Min.Electric equipment image recognition based on deep learning and random forest[J].High Voltage Engineering, 2017, 43 (11) :3705-3711." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDYJ201711028&amp;v=MDg2NjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeXJtVUwvTklpblNaTEc0SDliTnJvOUhiSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         李军锋, 王钦若, 李敏.结合深度学习和随机森林的电力设备图像识别[J].高电压技术, 2017, 43 (11) :3705-3711.LI Junfeng, WANG Qinruo, LI Min.Electric equipment image recognition based on deep learning and random forest[J].High Voltage Engineering, 2017, 43 (11) :3705-3711.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" 汤踊, 韩军, 魏文力, 等.深度学习在输电线路中部件识别与缺陷检测的研究[J].电子测量技术, 2018, 41 (6) :60-65.TANG Yong, HAN Jun, WEI Wenli, et al.Research on part recognition and defect detection of transmission line in deep learning[J].Electronic Measurement Technology, 2018, 41 (6) :60-65." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201806011&amp;v=MjMxOTlHRnJDVVI3cWZadVpzRnlybVVML05JVGZJWXJHNEg5bk1xWTlFWllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         汤踊, 韩军, 魏文力, 等.深度学习在输电线路中部件识别与缺陷检测的研究[J].电子测量技术, 2018, 41 (6) :60-65.TANG Yong, HAN Jun, WEI Wenli, et al.Research on part recognition and defect detection of transmission line in deep learning[J].Electronic Measurement Technology, 2018, 41 (6) :60-65.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" 张骥, 余娟, 汪金礼, 等.基于深度学习的输电线路外破图像识别技术[J].计算机系统应用, 2018, 27 (8) :176-179.ZHANG Ji, YU Juan, WANG Jinli, et al.Image recognition technology for transmission line external damage based on depth learning[J].Computer System &amp;amp; Applications, 2018, 27 (8) :176-179." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201808029&amp;v=MDYyMDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlybVVML05QVG5TZDdHNEg5bk1wNDlIYllRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         张骥, 余娟, 汪金礼, 等.基于深度学习的输电线路外破图像识别技术[J].计算机系统应用, 2018, 27 (8) :176-179.ZHANG Ji, YU Juan, WANG Jinli, et al.Image recognition technology for transmission line external damage based on depth learning[J].Computer System &amp;amp; Applications, 2018, 27 (8) :176-179.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" >
                                        <b>[22]</b>
                                     DAI J, LI Y, HE K, et al.R-FCN:object detection via region-based fully convolutional networks[C]// Proceedings of the 30th International Conference on Neural Information Processing Systems, December 5-10, 2016, Barcelona, Spain:379-387.</a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" >
                                        <b>[23]</b>
                                     REN S, GIRSHICK R, GIRSHICK R, et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2017, 39 (6) :1137.</a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" REDMON J, FARHADI A.YOLOv3:an incremental improvement [EB/OL].[2018-08-01].https://arxiv.org/abs/1804.02767." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=YOLOv3 an incremental improvement">
                                        <b>[24]</b>
                                         REDMON J, FARHADI A.YOLOv3:an incremental improvement [EB/OL].[2018-08-01].https://arxiv.org/abs/1804.02767.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition [EB/OL].[2018-08-01].https://arxiv.org/abs/1409.1556." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition">
                                        <b>[25]</b>
                                         SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition [EB/OL].[2018-08-01].https://arxiv.org/abs/1409.1556.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" SZEGEDY C, VANHOUCKE V, IOFFE S, et al.Rethinking the inception architecture for computer vision [EB/OL].[2018-08-01].https://arxiv.org/abs/1512.00567." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rethinking the inception architecture for computer vision">
                                        <b>[26]</b>
                                         SZEGEDY C, VANHOUCKE V, IOFFE S, et al.Rethinking the inception architecture for computer vision [EB/OL].[2018-08-01].https://arxiv.org/abs/1512.00567.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title=" HE K, ZHANG X, REN S, et al.Deep residual learning for image recognition[EB/OL].[2018-08-01].https://arxiv.org/abs/1512.03385." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">
                                        <b>[27]</b>
                                         HE K, ZHANG X, REN S, et al.Deep residual learning for image recognition[EB/OL].[2018-08-01].https://arxiv.org/abs/1512.03385.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_28" title=" XIE S, GIRSHICK R, DOLLAR P, et al.Aggregated residual transformations for deep neural networks [EB/OL].[2018-08-01].https://arxiv.org/abs/1611.05431." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aggregated residual transformations for deep neural networks">
                                        <b>[28]</b>
                                         XIE S, GIRSHICK R, DOLLAR P, et al.Aggregated residual transformations for deep neural networks [EB/OL].[2018-08-01].https://arxiv.org/abs/1611.05431.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_29" title=" HU J, SHEN L, SUN G.Squeeze-and-excitation networks [EB/OL].[2018-08-01].https://arxiv.org/abs/1709.01507." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Squeezeand-Excitation Networks">
                                        <b>[29]</b>
                                         HU J, SHEN L, SUN G.Squeeze-and-excitation networks [EB/OL].[2018-08-01].https://arxiv.org/abs/1709.01507.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_30" title=" REDMON J, DIVVALA S, GIRSHICK R, et al.You only look once:unified, real-time object detection [EB/OL].[2018-08-01].https://arxiv.org/abs/1506.02640." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=You only look once:unified,real-time object detection">
                                        <b>[30]</b>
                                         REDMON J, DIVVALA S, GIRSHICK R, et al.You only look once:unified, real-time object detection [EB/OL].[2018-08-01].https://arxiv.org/abs/1506.02640.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_31" title=" GIRSHICK R.Fast R-CNN [EB/OL].[2018-08-01].https://arxiv.org/abs/1504.08083." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">
                                        <b>[31]</b>
                                         GIRSHICK R.Fast R-CNN [EB/OL].[2018-08-01].https://arxiv.org/abs/1504.08083.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_32" >
                                        <b>[32]</b>
                                     NEUBECK A, GOOL L V.Efficient non-maximum suppression[C]// 18th International Conference on Pattern Recognition, August 20-24, 2006, Hong Kong, China:850-855.</a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_33" title=" SHRIVASTAVA A, GUPTA A, GIRSHICK R.Training region-based object detectors with online hard example mining [EB/OL].[2018-08-01].https://arxiv.org/abs/1604.03540." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Training region-based object detectors with online hard example mining">
                                        <b>[33]</b>
                                         SHRIVASTAVA A, GUPTA A, GIRSHICK R.Training region-based object detectors with online hard example mining [EB/OL].[2018-08-01].https://arxiv.org/abs/1604.03540.
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_34" title=" BODLA N, SINGH B, CHELLAPPA R, et al.Soft-NMS:improving object detection with one line of code [EB/OL].[2018-08-01].https://arxiv.org/abs/1704.04503." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Soft-NMS:improving object detection with one line of code">
                                        <b>[34]</b>
                                         BODLA N, SINGH B, CHELLAPPA R, et al.Soft-NMS:improving object detection with one line of code [EB/OL].[2018-08-01].https://arxiv.org/abs/1704.04503.
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_35" title=" LIN T Y, GOYAL P, GIRSHICK R, et al.Focal loss for dense object detection[C]// 2017 IEEE International Conference on Computer Vision, October 22-29, 2017, Venice, Italy." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Focal Loss for Dense Object Detection">
                                        <b>[35]</b>
                                         LIN T Y, GOYAL P, GIRSHICK R, et al.Focal loss for dense object detection[C]// 2017 IEEE International Conference on Computer Vision, October 22-29, 2017, Venice, Italy.
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_36" title=" CAI Z, VASCONCELOS N.Cascade R-CNN:delving into high quality object detection[EB/OL].[2018-08-01].https://arxiv.org/pdf/1712.00726.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cascade R-CNN:Delving into High Quality Object Detection[C/OL]">
                                        <b>[36]</b>
                                         CAI Z, VASCONCELOS N.Cascade R-CNN:delving into high quality object detection[EB/OL].[2018-08-01].https://arxiv.org/pdf/1712.00726.pdf.
                                    </a>
                                </li>
                                <li id="75">


                                    <a id="bibliography_37" title=" HE Y, ZHANG X, SAVVIDES M, et al.Softer-NMS:rethinking bounding box regression for accurate object detection[J].[EB/OL].[2018-08-01].https://arxiv.org/abs/1809.08545." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Softer-NMS:rethinking bounding box regression for accurate object detection">
                                        <b>[37]</b>
                                         HE Y, ZHANG X, SAVVIDES M, et al.Softer-NMS:rethinking bounding box regression for accurate object detection[J].[EB/OL].[2018-08-01].https://arxiv.org/abs/1809.08545.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">

    <div class="head-tag">   
            <p>
               <b> 网络首发时间: 2019-05-15 16:53</b>
            </p>     
    </div>


        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DLXT" target="_blank">电力系统自动化</a>
                2019,43(13),162-172 DOI:10.7500/AEPS20180921005            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于<b>R-FCN</b>的航拍巡检图像目标检测方法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%80%9D%E8%A8%80&amp;code=40224987&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘思言</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%8D%9A&amp;code=37365193&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AB%98%E6%98%86%E4%BB%91&amp;code=37364913&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高昆仑</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%B2%B3&amp;code=39985061&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王岳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AB%98%E7%95%85&amp;code=40224989&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高畅</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%B1%9F%E7%90%A6&amp;code=40224986&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈江琦</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%BD%E5%AE%B6%E7%94%B5%E7%BD%91%E7%94%B5%E5%8A%9B%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD(%E8%81%94%E5%90%88)%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%85%A8%E7%90%83%E8%83%BD%E6%BA%90%E4%BA%92%E8%81%94%E7%BD%91%E7%A0%94%E7%A9%B6%E9%99%A2%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8&amp;code=1700647&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国家电网电力人工智能(联合)实验室全球能源互联网研究院有限公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>航拍巡检是输电线路巡检的主要方式之一, 目前的航拍巡检方式效率较低, 受巡检员主观因素影响大, 亟需一种智能检测算法自动定位并识别输电线路巡检图片中的故障。基于深度学习的航拍巡检图像目标检测技术作为一种可能的解决方案, 得到了广泛关注。提出了一种利用基于区域的全卷积网络 (R-FCN) 的航拍巡检图像目标检测方法, 并利用在线困难样本挖掘 (OHEM) 、样本优化、软性非极大值抑制 (Soft-NMS) 等改进方法进行优化。实验证明, 所提方法具有目标定位准确、平均准确率高、单模型可同时检测目标种类多等特点。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9F%BA%E4%BA%8E%E5%8C%BA%E5%9F%9F%E7%9A%84%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">基于区域的全卷积网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%88%AA%E6%8B%8D%E5%B7%A1%E6%A3%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">航拍巡检;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%85%E9%9A%9C%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">故障识别;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *刘思言 (1992—) , 男, 通信作者, 硕士, 工程师, 主要研究方向:计算机视觉。E-mail:liusiyan@geiri.sgcc.com.cn;
                                </span>
                                <span>
                                    王博 (1989—) , 男, 博士, 工程师, 主要研究方向:计算机视觉、生物信息。E-mail:flish_wang@sina.com;
                                </span>
                                <span>
                                    高昆仑 (1972—) , 男, 博士, 教授级高级工程师, 主要研究方向:人工智能、信息安全。E-mail:gkl@geiri.sgcc.com.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-21</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家电网公司科技项目“电力人工智能实验及公共服务平台技术” (SGGR0000JSJS1800569);</span>
                    </p>
            </div>
                    <h1><b>Object Detection Method for Aerial Inspection Image Based on Region-based Fully Convolutional Network</b></h1>
                    <h2>
                    <span>LIU Siyan</span>
                    <span>WANG Bo</span>
                    <span>GAO Kunlun</span>
                    <span>WANG Yue</span>
                    <span>GAO Chang</span>
                    <span>CHEN Jiangqi</span>
            </h2>
                    <h2>
                    <span>Artificial Intelligence on Electric Power System Joint Laboratory of SGCC, Global Energy Interconnection Research Institute Co.Ltd.</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aerial inspection is one of the main methods of transmission line inspection. In consideration of inefficient of aerial inspection mode and subjective factors of inspectors, there is an urgent need for intelligent detection algorithm to locate and identify the faults in inspection pictures of transmission line. As a possible solution, object detection technology of aerial inspection imagge based on deep learning has attracted extensive attention. An object detection method of aerial inspection image utilizing region-based fully convolutional network (R-FCN) is proposed. Online hard example mining (OHEM) , sample adjusting and soft non-maximum suppression (Soft-NMS) are adopted to improve the performance of the proposed algorithm. The experiment results show that the proposed method has obvious advantages on accurate target location, high average precision, and simultaneous detection of target species by single-model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=region-based%20fully%20convolutional%20network%20(R-FCN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">region-based fully convolutional network (R-FCN) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=object%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">object detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=aerial%20inspection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">aerial inspection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fault%20identification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fault identification;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-09-21</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>supported by State Grid Corporation of China (No.SGGR0000JSJS1800569);</span>
                    </p>
            </div>


        <!--brief start-->
                        <h3 id="77" name="77" class="anchor-tag"><b>0 引言</b></h3>
                <div class="p1">
                    <p id="78">2017年, 中国220 kV及以上电压等级输电线路总长度超过68.7万千米, 相比于2016年增长了6.53%<citation id="142" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。其中许多架空输电线路所在地区地势复杂、环境恶劣, 因此, 航拍巡检是中国输电线路巡检的重要方式之一。</p>
                </div>
                <div class="p1">
                    <p id="79">航拍巡检的主要工作方式是巡检员操控有人机或无人机上的照相机拍摄图片并寻找输电线路故障, 这种巡检方式效率低, 受巡检人员工作经验、注意力等主观因素限制较大<citation id="143" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。而统一采集图像、视频并利用人工智能方法对故障进行检测的工作方式可以有效避免上述问题, 实现输电线路故障智能研判, 提升运检智能化水平。近年来, 随着计算能力的高速增长, 机器学习等人工智能技术迎来高速发展, 强化学习、迁移学习等机器学习方法在电力系统规划、能源预测、运行优化等应用中取得了一定效果<citation id="144" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。然而目前针对航拍巡检图像智能检测的研究尚处于起步阶段, 根据图片识别算法原理, 可将方法可分为传统图像处理类和深度学习类。</p>
                </div>
                <div class="p1">
                    <p id="80">传统图像处理类方法将输电线路巡检图像的故障检测任务分为特征提取、图像分割、目标定位、故障分类等多个阶段处理。文献<citation id="145" type="reference">[<a class="sup">5</a>]</citation>提出了非下采样轮廓波变换的绝缘子边缘提取方法。文献<citation id="146" type="reference">[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</citation>实现了航拍巡检图像中的绝缘子图像分割。文献<citation id="147" type="reference">[<a class="sup">9</a>,<a class="sup">10</a>]</citation>分别研究了绝缘子及防振锤在巡检图像中的定位。文献<citation id="148" type="reference">[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</citation>分别完成了对间隔棒故障、绝缘子故障、覆冰、导线断股的检测。传统图像处理方法虽然在实验环境中可以达到良好的识别效果, 但这些算法只能针对单一种类的目标和故障, 如可变形部件模型 (DMP) 、梯度方向直方图 (HOG) 和支持向量机 (SVM) 等, 耗时较长<citation id="149" type="reference"><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>, 并且容易受到背景及目标材质、形态、大小等因素的影响<citation id="150" type="reference"><link href="17" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>, 因此难以投入实际应用。</p>
                </div>
                <div class="p1">
                    <p id="81">深度学习类方法利用数据驱动的方式对卷积神经网络进行训练, 相比于传统图像处理方法具有超参数对结果影响更小、特征提取能力和抗干扰能力更强的优点。文献<citation id="151" type="reference">[<a class="sup">19</a>]</citation>以AlexNet作为特征提取网络, 利用随机森林算法对绝缘子、变压器等已定位的电力设备图像进行分类。文献<citation id="152" type="reference">[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">20</a>,<a class="sup">21</a>]</citation>使用的进阶基于区域卷积神经网络 (Faster R-CNN) 算法则克服了将目标检测任务分为多个子任务导致的图片细节信息损失的弊端, 实现了对包括绝缘子破损、鸟巢在内的多类输电线路部件及故障的端到端检测, 可以同时实现对故障的定位和分类。</p>
                </div>
                <div class="p1">
                    <p id="82">然而上述深度学习类的航拍巡检图像智能分析算法仍存在一定的局限性。近年来深度学习技术的不断突破使这些算法存在较大改进空间。上述算法主要围绕绝缘子、均压屏蔽环、防振锤等部件及绝缘子破损、鸟巢等常见故障, 选择少量类别进行检测, 故障种类覆盖面不足。</p>
                </div>
                <div class="p1">
                    <p id="83">本文提出一种基于区域的全卷积网络 (R-FCN) <citation id="153" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>及其改进算法的输电线路航拍巡检图像部件及故障检测方法, 构建12类航拍巡检目标检测数据集, 并将提出方法与基于Faster R-CNN<citation id="154" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>、YOLOv3<citation id="155" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>的方法进行对比。提出方法将R-FCN算法与在线难例挖掘 (OHEM) 、软性非极大值抑制 (Soft-NMS) 及样本优化改进方法结合并应用于航拍巡检图像目标检测, 验证了方法在更多种类的输电线路航拍巡检多尺度目标及故障的有效性, 方法目标框定位更准确、检测精度更高。</p>
                </div>
                <h3 id="84" name="84" class="anchor-tag"><b>1</b> 巡检图像目标检测方法</h3>
                <div class="p1">
                    <p id="85">基于深度卷积网络的图像目标检测的网络框架通常包括两个部分。第一部分为特征提取网络, 用于提取不同分辨率、不同层次的语义特征 (即卷积神经网络的输出) 。可用的特征提取网络包括VGGNet, Inception v3, ResNet, ResNext, SENet<citation id="158" type="reference"><link href="51" rel="bibliography" /><link href="53" rel="bibliography" /><link href="55" rel="bibliography" /><link href="57" rel="bibliography" /><link href="59" rel="bibliography" /><sup>[<a class="sup">25</a>,<a class="sup">26</a>,<a class="sup">27</a>,<a class="sup">28</a>,<a class="sup">29</a>]</sup></citation>等。第二部分网络是图像检测算法的核心部分, 它根据第一部分网络提取出的特征对图像中的目标进行定位和分类。目前实用的算法框架分为两类:第一类以Faster R-CNN为代表, 通过包含1～2个卷积层的区域建议网络 (region proposal network, RPN) 生成目标的候选区域, 然后在区域内提取图像特征进行分类和定位<citation id="156" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, 被称为“两阶段”方法;第二类则以YOLO<citation id="157" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>为代表, 直接在特征网络中预测当前位置目标类别和位置, 被称为“单阶段”方法。</p>
                </div>
                <div class="p1">
                    <p id="86">“两阶段”目标检测算法中, Faster R-CNN是较早提出并被广泛使用和改进的算法框架。它通过RPN网络层, 使用提取出的特征预测图片的每个位置存在不同大小、长宽比目标 (被称为前景) 的概率;接下来选取固定数量的前景概率较大的区域, 并将这些尺寸各异的区域所对应的语义特征通过区域池化层 (region of interest pooling layer, ROIPooling) <citation id="159" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>映射为相同的大小和维度;之后, 对每个区域, 将特征经过两个全连接层 (fully-connected layer, FC layer) 和线性整流单元 (rectified linear unit, ReLU) 层的变换, 生成表示该目标属于每个类别概率大小和相对位置的分值;最后, 使用非极大值抑制 (non-maximum suppression, NMS) 算法<citation id="160" type="reference"><link href="65" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>对相近位置、相同类别的预测目标进行去重, 并输出最终的结果。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>1.1 R-FCN</b>目标检测方法</h4>
                <div class="p1">
                    <p id="88">Faster R-CNN及R-FCN算法网络结构如图1所示。</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Faster R-CNN及R-FCN网络结构" src="Detail/GetImg?filename=images/DLXT201913020_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 Faster R-CNN及R-FCN网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.1 Network structures of Faster R-CNN and R-FCN</b></p>

                </div>
                <div class="p1">
                    <p id="90">与Faster R-CNN算法相比, R-FCN算法有两点改进:其一, 使用“位置敏感”的区域池化层 (position sensitive region of interest pooling layer, PSROIPooling) 替换ROIPooling层, 以对抗池化操作带来的目标位置信息的丢失;其二, 在区域池化层之前通过卷积神经网络生成目标属于每个类别概率大小和相对位置的分值, 将这两种分值通过PSROIPooling层映射为相同的大小, 通过对映射后的分值求平均, 直接得到每个区域属于不同类别的概率和相对位置。该算法中, “位置敏感”的区域池化层对每个维度的特征, 无须在整个目标区域中进行池化 (即求最大值) , 仅选取其中的一小块区域进行操作, 因此提取的特征更精细, 并保留了更多的位置信息;此外, 不需要对每个区域提取出的特征进行全连接层的计算, 因此计算量比Faster R-CNN更小。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>1.2</b> 对目标检测方法的若干改进</h4>
                <div class="p1">
                    <p id="92">在R-FCN算法框架的基础上, 研究尝试了OHEM<citation id="161" type="reference"><link href="67" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>、样本优化、Soft-NMS<citation id="162" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>等改进方法。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93"><b>1.2.1</b> OHEM</h4>
                <div class="p1">
                    <p id="94">在训练过程中, 采用1 200×800分辨率的图像会生成56 250个候选区域, 同时其中的数百到数千个区域会参与预测目标类别和位置的训练。这些区域中, 每张图片平均存在5个包含目标的区域, 其余则为背景区域。背景区域与目标区域数量之比过大, 同时不同目标的检测难度存在差异, 提高了模型的训练难度。</p>
                </div>
                <div class="p1">
                    <p id="95">OHEM方法认为大部分背景区域和容易识别的目标区域关于类别的预测精度高, 其损失 (loss) 较小;在训练时, 将损失较小的区域的权重设为0, 可以更重视识别难度较高的区域, 从而有效提高训练效果。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>1.2.2</b> 样本优化</h4>
                <div class="p1">
                    <p id="97">拍摄条件的差异导致同一类目标在图像中的尺寸不同。并且不同类别的目标数量差别很大 (见第2.1节) , 训练过程中当常见的目标已过拟合时, 稀少的目标可能仍未被充分学习, 而存在欠拟合。</p>
                </div>
                <div class="p1">
                    <p id="98">样本优化将同样的样本缩放为不同的大小进行训练, 可以让模型对目标尺寸的变化进行适应;同时将稀少目标所在图片的学习频次加倍, 可以缩小模型充分学习不同目标所需的迭代轮数的差异, 从而提升模型精度 (详见附录A) 。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>1.2.3</b> Soft-NMS</h4>
                <div class="p1">
                    <p id="100">在Faster R-CNN和R-FCN算法框架中, 非极大值抑制算法会移除预测概率较高的目标框附近的其他同类目标, 因此可能导致距离较近或存在重叠的同类目标的漏检。</p>
                </div>
                <div class="p1">
                    <p id="101">Soft-NMS算法对此进行改进, 仅降低预测概率较高的目标框附近的其他同类目标概率分值, 降低的幅度由与高概率目标的接近程度决定, 以提升模型在预测较密集目标时的预测精度。其中, 同类目标与高概率目标的接近程度通过交并比 (intersection-over-union, IoU) 定义;对目标概率分值的修正通过将原分值乘以衰减系数完成;衰减系数取交并比<i>I</i><sub>OU</sub>的高斯函数exp (-<i>I</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>Ο</mtext><mtext>U</mtext></mrow><mn>2</mn></msubsup></mrow></math></mathml>/<i>σ</i>) , 其中<i>σ</i>为超参数。</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag"><b>2</b> 目标检测流程与实验设计</h3>
                <div class="p1">
                    <p id="104">为了实现输电线路航拍巡检图像的部件及缺陷检测, 研究分为数据集制作、模型训练、模型评估3个步骤。围绕不同步骤, 尝试了样本优化及OHEM和Soft-NMS等改进, 研究流程如图2所示。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>2.1</b> 数据集</h4>
                <div class="p1">
                    <p id="106">样本集构建自直升机及无人机输电线路航拍巡检图片:首先从中挑选包含常见故障类别的4 000张图片, 涵盖了多个输电线路悬垂串和耐张串铁塔端、导线端及地线铁塔端等常见航拍巡检场景。图片分辨率约为2×10<sup>7</sup>像素。</p>
                </div>
                <div class="p1">
                    <p id="107">之后对图片中的目标及缺陷进行人工标注。图片对应的标注信息 (目标框) 共包含绝缘子串、地线绝缘子、悬垂串导线端金具、地线金具、均压屏蔽环、防振锤、均压环7类部件, 以及绝缘子破损、放电间隙松动、地线金具倾斜、防振锤损坏、鸟巢5类故障, 共计12类。数据集中占比最高的目标类别为绝缘子串和防振锤, 分别占比22.06%和24.84%;占比最少的类别包括放电间隙松动、地线金具倾斜和防振锤损坏, 分别占比2.87%, 2.22%, 3.08%, 不同类别目标数量差异大。附录B图B1为地线铁塔端、悬垂串导线端、耐张串导线端三类典型输电线路航拍巡检场景的图片及其图片标注的示例。 最后, 将图片进行随机划分, 得到3 189张图片用于模型训练, 811张图片用于模型评估。各类别目标框的数量及占总体的分布如附录C表C1所示。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 研究流程图" src="Detail/GetImg?filename=images/DLXT201913020_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 研究流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.2 Flow chart of research</b></p>

                </div>
                <div class="p1">
                    <p id="110">各类目标框在图中的面积占比的分布图如附录C图C1所示, 部分类别的目标框大小差距较大。其中地线金具倾斜、防振锤、防振锤损坏、绝缘子破损类别面积较大者与较小者之比 (取0.85和0.15分位点) 为4～6倍;绝缘子串、悬垂串导线端金具、均压环两者之比为13～18倍;其余类别两者之比在6～11倍之间。</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>2.2</b> 模型训练</h4>
                <div class="p1">
                    <p id="112">模型训练及评估使用的CPU为AMD Ryzen 1800X, GPU为双NVIDIA GeForce Titan Xp, 深度学习框架为MXNet 1.1.0。</p>
                </div>
                <div class="p1">
                    <p id="113">R-FCN算法的基础网络为ResNet-101, 并基于微软常见目标数据集 (Microsoft common objects in context, MS COCO) 预训练模型对权重进行初始化。训练采用800×1 200的样本分辨率, 使用小批量梯度下降法 (mini-batch SGD) 训练, 每个批次 (batch) 训练2张图片。前2 000个批次采用学习率为5×10<sup>-5</sup>的预热 (warm-up) 学习策略, 此后学习率为5×10<sup>-4</sup>, 学习率衰减策略为阶梯式衰减, 衰减批次为22 000, 26 800, 32 000, 衰减系数为0.1, 一共训练36 000个批次。</p>
                </div>
                <div class="p1">
                    <p id="114">RPN网络层锚框的宽高比例为0.5, 1, 2共3种, 锚框基础尺寸为2, 4, 8, 16, 32共5种, 二者组合共计15种锚框。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>2.3</b> 模型评估</h4>
                <div class="p1">
                    <p id="116">在特定交并比阈值条件下, 准确率和召回率是衡量算法性能的基本指标, 然而准确率和召回率均受到置信度阈值的影响。二者此消彼长, 单独考虑其中之一无法准确地评价算法。因此采用平均准确率 (average precision, AP) , 即在不同召回率下的准确率均值, 作为算法的精度评价指标, 并采用平均准确率在不同类别间的均值 (mean average precision, mAP) 作为算法的综合评价指标。</p>
                </div>
                <div class="p1">
                    <p id="117">同时, 为了全方面评价模型的性能, 推理速度也作为指标纳入考量。</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118"><b>2.4</b> 对比实验设计</h4>
                <div class="p1">
                    <p id="119">研究共设置如下2组对比实验。</p>
                </div>
                <div class="p1">
                    <p id="120">1) 在不使用OHEM、样本优化、Soft-NMS三类改进的情况下, 将R-FCN算法与Faster R-CNN及YOLOv3算法进行对比, 比较其在IoU阈值为0.5情况下的mAP及平均推理时间。Faster R-CNN和YOLOv3是具有代表性的目标检测方法, 并且Faster R-CNN此前被广泛用于航拍巡检图像目标检测<citation id="163" type="reference"><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="121">其中Faster R-CNN算法的学习率参数、RPN网络层参数与R-FCN算法相同。YOLOv3算法的样本分辨率分别设为800×800及1 216×1 216, 分别记为YOLOv3 800和YOLOv3 1 216;训练共进行4 000个批次, 每个批次64张图片, 前1 000个批次采用逐渐增大的动态学习率, 此后学习率为0.001, 学习率衰减策略为阶梯式衰减, 衰减批次为2 500及3 200, 衰减系数为0.1;使用在MS COCO数据集上聚类得到的9组锚框。</p>
                </div>
                <div class="p1">
                    <p id="122">2) 以R-FCN算法为基础, 计算分别及同时使用OHEM、样本优化技术、Soft-NMS等改进方法时, 各类别的AP及mAP。</p>
                </div>
                <div class="p1">
                    <p id="123">此外, 为评估模型的稳定性, 对测试集图片的饱和度、亮度及色相进行随机调整并计算模型的mAP。其中饱和度和亮度的调整不超过50, 色相的调整不超过15°。</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag"><b>3 结果分析</b></h3>
                <h4 class="anchor-tag" id="125" name="125"><b>3.1 R-FCN</b>与同类算法对比分析</h4>
                <div class="p1">
                    <p id="126">R-FCN算法、Faster R-CNN算法、YOLOv3 800及YOLOv3 1 216算法在IoU阈值为0.5时的mAP (本文记作mAP@0.5) 及平均推理时间如表1所示。R-FCN算法的mAP和推理时间与Faster R-CNN相当。这两种算法的mAP@0.5比YOLOv3 800高约7.7%, 在各IoU阈值下的mAP一致高于两种分辨率的YOLOv3算法 (如图3所示) , 但推理单张图片的时间约为后者的5倍。当IoU阈值小于0.6时, R-FCN与Faster R-CNN的mAP曲线基本重合;阈值在0.6～0.8时, R-FCN的mAP曲线高于Faster R-CNN, 表明与Faster R-CNN相比, R-FCN算法预测的目标框与标注框IoU大于0.7的数量更多, 即R-FCN的目标定位相比Faster R-CNN更加准确。</p>
                </div>
                <div class="area_img" id="127">
                    <p class="img_tit"><b>表1 R-FCN及对比算法目标检测mAP及推理时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 mAP and prediction time comparison of object detection for R-FCN and compared algorithms</b></p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td><br />算法</td><td>mAP@0.5/%</td><td>推理时间/s</td></tr><tr><td><br />Faster R-CNN</td><td>84.15</td><td>0.120 7</td></tr><tr><td><br />R-FCN</td><td>84.29</td><td>0.121 2</td></tr><tr><td><br />YOLOv3 800</td><td>80.56</td><td>0.023 8</td></tr><tr><td><br />YOLOv3 1 216</td><td>62.58</td><td>0.054 7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 R-FCN及对比算法的mAP-IoU阈值曲线" src="Detail/GetImg?filename=images/DLXT201913020_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 R-FCN及对比算法的mAP-IoU阈值曲线</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.3 mAP-IoU threshold curves of R-FCN and compared algorithms</b></p>

                </div>
                <h4 class="anchor-tag" id="129" name="129"><b>3.2</b> 改进方法结果分析</h4>
                <div class="p1">
                    <p id="130">在R-FCN算法中分别加入OHEM、样本优化、Soft-NMS改进后的各类别AP如附录D表D1所示。向R-FCN算法逐项加入改进后的各类别AP如表2所示。表中改进①表示加入OHEM;改进②表示加入OHEM和样本优化技术;改进③表示加入OHEM、样本优化技术和Soft-NMS;AP@0.5定义参考mAP@0.5。</p>
                </div>
                <div class="p1">
                    <p id="131">可见, 每种方法都有效提高了模型的识别精度。其中, OHEM和样本优化有效提升了算法对稀少、困难目标, 如防振锤损坏、地线金具倾斜、放电间隙松动等的识别效果。特别地, 对原有效果较差的防振锤损坏类别, AP提升超过10%。4种方法对mAP@0.5的提升总计达到4.86%。 <b>表2 改进前后的R-FCN算法目标检测AP</b></p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 AP of R-FCN object detection before and after improvement</b></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td rowspan="2"><br />类别</td><td colspan="4"><br />AP@0.5/%</td></tr><tr><td><br />无改进</td><td>改进①</td><td>改进②</td><td>改进③</td></tr><tr><td><br />绝缘子串</td><td>93.61</td><td>94.25</td><td>95.85</td><td>96.43</td></tr><tr><td><br />绝缘子破损</td><td>90.11</td><td>91.05</td><td>91.73</td><td>92.54</td></tr><tr><td><br />地线绝缘子</td><td>81.71</td><td>86.51</td><td>88.52</td><td>88.80</td></tr><tr><td><br />放电间隙松动</td><td>81.85</td><td>81.00</td><td>87.48</td><td>87.47</td></tr><tr><td><br />悬垂串导线端金具</td><td>83.99</td><td>82.08</td><td>86.17</td><td>87.61</td></tr><tr><td><br />地线金具</td><td>85.29</td><td>86.38</td><td>88.13</td><td>87.93</td></tr><tr><td><br />地线金具倾斜</td><td>82.90</td><td>83.90</td><td>90.05</td><td>89.17</td></tr><tr><td><br />均压屏蔽环</td><td>95.52</td><td>94.96</td><td>96.30</td><td>96.94</td></tr><tr><td><br />防振锤</td><td>87.42</td><td>89.49</td><td>91.26</td><td>92.62</td></tr><tr><td><br />防振锤损坏</td><td>66.64</td><td>77.20</td><td>78.54</td><td>77.09</td></tr><tr><td><br />均压环</td><td>74.56</td><td>79.07</td><td>78.56</td><td>80.80</td></tr><tr><td><br />鸟巢</td><td>87.29</td><td>89.76</td><td>91.68</td><td>92.41</td></tr><tr><td><br />AP均值</td><td>84.29</td><td>86.30</td><td>88.69</td><td>89.15</td></tr><tr><td colspan="5"><br />注: 红色数字为每一行最大值。</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="133">改进后的模型针对背景较复杂、目标较模糊或目标被遮挡的图片识别效果如附录E所示。</p>
                </div>
                <div class="p1">
                    <p id="134">对于随机调整饱和度、亮度及色相的测试集, 算法得到了88.37%的mAP, 相比于原始数据集mAP降低了0.78%。</p>
                </div>
                <h3 id="135" name="135" class="anchor-tag"><b>4</b> 结语</h3>
                <div class="p1">
                    <p id="136">本文提出了一种基于R-FCN的航拍巡检图像目标检测方法, 进行OHEM、样本优化、Soft-NMS等改进, 并构建了一组覆盖12类目标的输电线路航拍巡检图片目标检测数据集, 在此基础上与Faster R-CNN及YOLOv3算法进行了对比测试。</p>
                </div>
                <div class="p1">
                    <p id="137">1) 在航拍巡检图片目标检测任务中, 与Faster R-CNN算法相比, R-FCN算法分类精度和推理时间相当, 但是在高IOU阈值下其mAP值更高, 可见其目标框定位更加准确。</p>
                </div>
                <div class="p1">
                    <p id="138">2) 提出的方法采用了OHEM、样本优化、Soft-NMS等多种改进, 可以有效提高算法精确度, 在测试集中mAP@0.5提升达4.86%。</p>
                </div>
                <div class="p1">
                    <p id="139">3) 提出的方法可以适应多种类型及尺度的输电线路航拍巡检目标及故障。</p>
                </div>
                <div class="p1">
                    <p id="140">深度学习领域目前仍处于高速发展中, 许多新的改进算法<citation id="164" type="reference"><link href="71" rel="bibliography" /><link href="73" rel="bibliography" /><link href="75" rel="bibliography" /><sup>[<a class="sup">35</a>,<a class="sup">36</a>,<a class="sup">37</a>]</sup></citation>, 被证明了其在通用目标检测任务上的有效性, 但条件有限, 本研究未进行尝试。后续工作中, 将结合更多改进方法对数据集制作、模型训练等步骤进行优化, 提高模型精度;同时将尝试扩展数据集覆盖的航拍巡检线路、部件及缺陷种类, 如子导线间隔棒、悬垂串铁塔端金具等部件及细小金具缺陷等故障等, 以提高模型的适用范围和实用性。</p>
                </div>
                <div class="p1">
                    <p id="141">附录见本刊网络版 (http://www.aeps-info.com/aeps/ch/index.aspx) 。</p>
                </div>
                <h3 id="165" name="165" class="anchor-tag">附录A稀有样本频次加倍算法及在MS COCO数据集上的表现</h3>
                <div class="p1">
                    <p id="166">我们使用R-FCN+OHEM+soft-NMS作为基准模型进行训练, 训练集为MS COCO 2017train, 第8轮 (epoch) 训练完成后, 基准模型在2017val上的mAP为32.5%, 如表A1所示。之后, 选取目标数量较少 (排名位于前1/5) , 且在第6轮模型到第8轮模型中mA P有提升的类别 (提示这些类别可能存在欠拟合) , 将这些类别相关的图片的学习频次加倍。加倍的方法为, 将训练集中包含这些类别的图片和标注信息复制一份、改名, 并做为新样本加入训练集以进行训练。相对于基准模型, 改进后的算法在第6轮得到了32.8%的mA P, 提升0.3%。如表A1所示。</p>
                </div>
                <div class="area_img" id="167">
                                            <p class="img_tit">
                                                表A1稀有样本频次加倍算法在MS COCO 2017val上的AP
                                                    <br />
                                                Table A1 mAP of doubling rare samples on MS COCO 2017val
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_16700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/DLXT201913020_16700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_16700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表A1稀有样本频次加倍算法在MS COCO 2017val上的AP" src="Detail/GetImg?filename=images/DLXT201913020_16700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>
                                <p class="img_note">注:进行改进时, 学习频次加倍的类别标题加黑</p>

                </div>
                <h3 id="168" name="168" class="anchor-tag">附录B</h3>
                <div class="area_img" id="169">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_16900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图B1样本集图片及目标框标注示例" src="Detail/GetImg?filename=images/DLXT201913020_16900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图B1样本集图片及目标框标注示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_16900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.B1 Examples of sample pictures and bounding boxes</p>

                </div>
                <h3 id="170" name="170" class="anchor-tag">附录C</h3>
                <div class="area_img" id="171">
                                            <p class="img_tit">
                                                表C1目标框数量及分布
                                                    <br />
                                                Table C1 The number and distribution of bounding box
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/DLXT201913020_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表C1目标框数量及分布" src="Detail/GetImg?filename=images/DLXT201913020_17100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="172">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_17200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图C1目标框面积占全图比例的分布" src="Detail/GetImg?filename=images/DLXT201913020_17200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图C1目标框面积占全图比例的分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_17200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.C1 Distribution of bounding box area proportion</p>

                </div>
                <h3 id="173" name="173" class="anchor-tag">附录D</h3>
                <div class="area_img" id="174">
                                            <p class="img_tit">
                                                表D1加入单项改进的R-FCN算法目标检测AP
                                                    <br />
                                                Table D1 APs of R-FCN object detection modified respectively
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/DLXT201913020_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表D1加入单项改进的R-FCN算法目标检测AP" src="Detail/GetImg?filename=images/DLXT201913020_17400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="175" name="175" class="anchor-tag">附录E</h3>
                <div class="area_img" id="176">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_17600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图E1改进算法目标检测结果示例1" src="Detail/GetImg?filename=images/DLXT201913020_17600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图E1改进算法目标检测结果示例1  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_17600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.E1 Objects Detection Result 1 of Modified Algorithm</p>

                </div>
                <div class="area_img" id="177">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_17700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图E2改进算法目标检测结果示例2" src="Detail/GetImg?filename=images/DLXT201913020_17700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图E2改进算法目标检测结果示例2  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_17700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.E2 Objects Detection Result 2 of Modified Algorithm</p>

                </div>
                <div class="area_img" id="178">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DLXT201913020_17800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图E3改进算法目标检测结果示例3" src="Detail/GetImg?filename=images/DLXT201913020_17800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图E3改进算法目标检测结果示例3  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DLXT201913020_17800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.E3 Objects Detection Result 3 of Modified Algorithm</p>

                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 国家能源局, 中国电力企业联合会.2017年全国电力可靠性年度报告[R].北京:国家能源局, 2018.National Energy Administration, China Electricity Council.2017 annual report of national power reliability[R].Beijing:National Energy Administration, 2018.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DWJS201012040&amp;v=MTExNDBGckNVUjdxZlp1WnNGeXJtVUwvTklUckJmYkc0SDlITnJZOUJaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 仝卫国, 苑津莎, 李宝树.图像处理技术在直升机巡检输电线路中的应用综述[J].电网技术, 2010, 34 (12) :204-208.TONG Weiguo, YUAN Jinsha, LI Baoshu.Application of image processing in patrol inspection of overhead transmission line by helicopter[J].Power System Technology, 2010, 34 (12) :204-208.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201901002&amp;v=MTY3NjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OSVNIVGVyRzRIOWpNcm85RlpvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 杨挺, 赵黎媛, 王成山.人工智能在电力系统及综合能源系统中的应用综述[J].电力系统自动化, 2019, 43 (1) :2-14.DOI:10.7500/AEPS20180706005.YANG Ting, ZHAO Liyuan, WANG Chengshan.Review on application of artificial intelligence in power system and integrated energy system[J].Automation of Electric Power Systems, 2019, 43 (1) :2-14.DOI:10.7500/AEPS 20180706005.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201901003&amp;v=MTMxOTVtVUwvTklTSFRlckc0SDlqTXJvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeXI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 程乐峰, 余涛, 张孝顺, 等.机器学习在能源与电力系统领域的应用和展望[J].电力系统自动化, 2019, 43 (1) :15-43.DOI:10.7500/AEPS20180814007.CHENG Lefeng, YU Tao, ZHANG Xiaoshun, et al.Machine learning for energy and electric power systems:state of the art and prospects[J].Automation of Electric Power Systems, 2019, 43 (1) :15-43.DOI:10.7500/AEPS20180814007.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201209018&amp;v=MDU5MjZxZlp1WnNGeXJtVUwvTlBEelRiTEc0SDlQTXBvOUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 赵振兵, 金思新, 刘亚春.基于NSCT的航拍绝缘子图像边缘提取方法[J].仪器仪表学报, 2012, 33 (9) :2045-2052.ZHAO Zhenbing, JIN Sixin, LIU Yachun.Aerial insulator image edge extraction method based on NSCT[J].Chinese Journal of Scientific Instrument, 2012, 33 (9) :2045-2052.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DWJS201001038&amp;v=MzIyNTJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OSVRyQmZiRzRIOUhNcm85R2JJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 黄宵宁, 张真良.直升机巡检航拍图像中绝缘子图像的提取算法[J].电网技术, 2010, 34 (1) :194-197.HUANG Xiaoning, ZHANG Zhenliang.A method to extract insulator image from aerial image of helicopter patrol[J].Power System Technology, 2010, 34 (1) :194-197.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An active contour model based on texture distribution for extracting inhomogeneous insulators from aerial images">

                                <b>[7]</b> WU Q, AN J.An active contour model based on texture distribution for extracting inhomogeneous insulators from aerial images[J].IEEE Transactions on Geoscience and Remote Sensing, 2014, 52 (6) :3613-3626.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201602021&amp;v=MDYwNzFNclk5SFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OUER6VGJMRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 赵振兵, 徐磊, 戚银城, 等.基于Hough检测和C-V模型的航拍绝缘子自动协同分割方法[J].仪器仪表学报, 2016, 37 (2) :395-403.ZHAO Zhenbing, XU Lei, QI Yincheng, et al.Automatic co-segmentation method for aerial insulator based on Hough detection and C-V model[J].Chinese Journal of Scientific Instrument, 2016, 37 (2) :395-403.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201403010&amp;v=MDU3MDFEelRiTEc0SDlYTXJJOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGeXJtVUwvTlA=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 赵振兵, 王乐.一种航拍绝缘子串图像自动定位方法[J].仪器仪表学报, 2014, 35 (3) :558-565.ZHAO Zhenbing, WANG Le.Aerial insulator string image automatic location method[J].Chinese Journal of Scientific Instrument, 2014, 35 (3) :558-565.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDYJ201701035&amp;v=MjE1MTdCdEdGckNVUjdxZlp1WnNGeXJtVUwvTklpblNaTEc0SDliTXJvOUdZWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 付晶, 邵瑰玮, 吴亮, 等.利用层次模型进行训练学习的线路设备缺陷检测方法[J].高电压技术, 2017, 43 (1) :266-275.FU Jing, SHAO Guiwei, WU Liang, et al.Defect detection of line facility using hierarchical model with learning algorithm[J].High Voltage Engineering, 2017, 43 (1) :266-275.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDYJ201305004&amp;v=MjI2MDdmWnVac0Z5cm1VTC9OSWluU1pMRzRIOUxNcW85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 金立军, 胡娟, 闫书佳.基于图像的高压输电线间隔棒故障诊断方法[J].高电压技术, 2013, 39 (5) :1040-1045.JIN Lijun, HU Juan, YAN Shujia.Method of spacer fault diagnose on transmission line based on image procession[J].High Voltage Engineering, 2013, 39 (5) :1040-1045.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analysis of the recognition and localisation techniques of power transmission lines components in aerial images acquired by drones">

                                <b>[12]</b> HOMMA R Z, SOHN O, BOSE R C.Analysis of the recognition and localisation techniques of power transmission lines components in aerial images acquired by drones[J].CIRED—Open Access Proceedings Journal, 2017, 2017 (1) :29-32.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=GDYJ201805018&amp;v=MDUzNTJxbzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlybVVML05JaW5TWkxHNEg5bk0=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 黄新波, 刘新慧, 张烨, 等.基于红蓝色差和改进<i>K</i>-means算法的航拍绝缘子分类识别方法[J].高电压技术, 2018, 44 (5) :1528-1534.HUANG Xinbo, LIU Xinhui, ZHANG Ye, et al.Classification recognition method of insulator in aerial image based on the red-blue difference and developed <i>K</i>-means algorithm[J].High Voltage Engineering, 2018, 44 (5) :1528-1534.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Insulator fault detection based on spatial morphological features of aerial images">

                                <b>[14]</b> ZHAI Y, CHEN R, YANG Q, et al.Insulator fault detection based on spatial morphological features of aerial images[J].IEEE Access, 2018, 6:35316-35326.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201621030&amp;v=MTU0NzBac0Z5cm1VTC9OSVNIVGVyRzRIOWZPcm85R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 张烨, 冯玲, 穆靖宇, 等.输电线路绝缘子覆冰厚度图像识别算法[J].电力系统自动化, 2016, 40 (21) :195-202.ZHANG Ye, FENG Ling, MU Jingyu, et al.Image identification algorithm of icing thickness for insulator in power transmission lines[J].Automation of Electric Power Systems, 2016, 40 (21) :195-202.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201115016&amp;v=MTY3OTJGeXJtVUwvTklTSFRlckc0SDlETnFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 蒋兴良, 夏云峰, 张志劲, 等.基于优化Gabor滤波器的输电导线断股图像检测[J].电力系统自动化, 2011, 35 (15) :78-83.JIANG Xingliang, XIA Yunfeng, ZHANG Zhijin, et al.Image detection for broken strand faults of transmission conductor based on optimized Gabor filter[J].Automation of Electric Power Systems, 2011, 35 (15) :78-83.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQXX201702014&amp;v=MTczNjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRnlybVVML05JVHpUZHJHNEg5Yk1yWTlFWUlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 王万国, 田兵, 刘越, 等.基于RCNN的无人机巡检图像电力小部件识别研究[J].地球信息科学学报, 2017, 19 (2) :256-263.WANG Wanguo, TIAN Bing, LIU Yue, et al.Study on the electrical devices detection in UAV images based on region based convolutional neural networks[J].Journal of Geo-information Science, 2017, 19 (2) :256-263.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201706021&amp;v=MTQ2MTh0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OSVRmQ2Q3RzRIOWJNcVk5SFpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 陈庆, 闫斌, 叶润, 等.航拍绝缘子卷积神经网络检测及自爆识别研究[J].电子测量与仪器学报, 2017, 31 (6) :942-953.CHEN Qing, YAN bin, YE Run, et al.Insulator detection and recognition of explosion fault based on convolutional neural networks[J].Journal of Electronic Measurement and Instrumentation, 2017, 31 (6) :942-953.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDYJ201711028&amp;v=MDQ1NDJDVVI3cWZadVpzRnlybVVML05JaW5TWkxHNEg5Yk5ybzlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 李军锋, 王钦若, 李敏.结合深度学习和随机森林的电力设备图像识别[J].高电压技术, 2017, 43 (11) :3705-3711.LI Junfeng, WANG Qinruo, LI Min.Electric equipment image recognition based on deep learning and random forest[J].High Voltage Engineering, 2017, 43 (11) :3705-3711.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201806011&amp;v=MDY0NTMzenFxQnRHRnJDVVI3cWZadVpzRnlybVVML05JVGZJWXJHNEg5bk1xWTlFWllRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 汤踊, 韩军, 魏文力, 等.深度学习在输电线路中部件识别与缺陷检测的研究[J].电子测量技术, 2018, 41 (6) :60-65.TANG Yong, HAN Jun, WEI Wenli, et al.Research on part recognition and defect detection of transmission line in deep learning[J].Electronic Measurement Technology, 2018, 41 (6) :60-65.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201808029&amp;v=MjQyMTVxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OUFRuU2Q3RzRIOW5NcDQ5SGJZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 张骥, 余娟, 汪金礼, 等.基于深度学习的输电线路外破图像识别技术[J].计算机系统应用, 2018, 27 (8) :176-179.ZHANG Ji, YU Juan, WANG Jinli, et al.Image recognition technology for transmission line external damage based on depth learning[J].Computer System &amp; Applications, 2018, 27 (8) :176-179.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" >
                                    <b>[22]</b>
                                 DAI J, LI Y, HE K, et al.R-FCN:object detection via region-based fully convolutional networks[C]// Proceedings of the 30th International Conference on Neural Information Processing Systems, December 5-10, 2016, Barcelona, Spain:379-387.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" >
                                    <b>[23]</b>
                                 REN S, GIRSHICK R, GIRSHICK R, et al.Faster R-CNN:towards real-time object detection with region proposal networks[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2017, 39 (6) :1137.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=YOLOv3 an incremental improvement">

                                <b>[24]</b> REDMON J, FARHADI A.YOLOv3:an incremental improvement [EB/OL].[2018-08-01].https://arxiv.org/abs/1804.02767.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition">

                                <b>[25]</b> SIMONYAN K, ZISSERMAN A.Very deep convolutional networks for large-scale image recognition [EB/OL].[2018-08-01].https://arxiv.org/abs/1409.1556.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rethinking the inception architecture for computer vision">

                                <b>[26]</b> SZEGEDY C, VANHOUCKE V, IOFFE S, et al.Rethinking the inception architecture for computer vision [EB/OL].[2018-08-01].https://arxiv.org/abs/1512.00567.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">

                                <b>[27]</b> HE K, ZHANG X, REN S, et al.Deep residual learning for image recognition[EB/OL].[2018-08-01].https://arxiv.org/abs/1512.03385.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aggregated residual transformations for deep neural networks">

                                <b>[28]</b> XIE S, GIRSHICK R, DOLLAR P, et al.Aggregated residual transformations for deep neural networks [EB/OL].[2018-08-01].https://arxiv.org/abs/1611.05431.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Squeezeand-Excitation Networks">

                                <b>[29]</b> HU J, SHEN L, SUN G.Squeeze-and-excitation networks [EB/OL].[2018-08-01].https://arxiv.org/abs/1709.01507.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=You only look once:unified,real-time object detection">

                                <b>[30]</b> REDMON J, DIVVALA S, GIRSHICK R, et al.You only look once:unified, real-time object detection [EB/OL].[2018-08-01].https://arxiv.org/abs/1506.02640.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast R-CNN">

                                <b>[31]</b> GIRSHICK R.Fast R-CNN [EB/OL].[2018-08-01].https://arxiv.org/abs/1504.08083.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_32" >
                                    <b>[32]</b>
                                 NEUBECK A, GOOL L V.Efficient non-maximum suppression[C]// 18th International Conference on Pattern Recognition, August 20-24, 2006, Hong Kong, China:850-855.
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Training region-based object detectors with online hard example mining">

                                <b>[33]</b> SHRIVASTAVA A, GUPTA A, GIRSHICK R.Training region-based object detectors with online hard example mining [EB/OL].[2018-08-01].https://arxiv.org/abs/1604.03540.
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_34" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Soft-NMS:improving object detection with one line of code">

                                <b>[34]</b> BODLA N, SINGH B, CHELLAPPA R, et al.Soft-NMS:improving object detection with one line of code [EB/OL].[2018-08-01].https://arxiv.org/abs/1704.04503.
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_35" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Focal Loss for Dense Object Detection">

                                <b>[35]</b> LIN T Y, GOYAL P, GIRSHICK R, et al.Focal loss for dense object detection[C]// 2017 IEEE International Conference on Computer Vision, October 22-29, 2017, Venice, Italy.
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cascade R-CNN:Delving into High Quality Object Detection[C/OL]">

                                <b>[36]</b> CAI Z, VASCONCELOS N.Cascade R-CNN:delving into high quality object detection[EB/OL].[2018-08-01].https://arxiv.org/pdf/1712.00726.pdf.
                            </a>
                        </p>
                        <p id="75">
                            <a id="bibliography_37" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Softer-NMS:rethinking bounding box regression for accurate object detection">

                                <b>[37]</b> HE Y, ZHANG X, SAVVIDES M, et al.Softer-NMS:rethinking bounding box regression for accurate object detection[J].[EB/OL].[2018-08-01].https://arxiv.org/abs/1809.08545.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DLXT201913020" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLXT201913020&amp;v=MTg2OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Z5cm1VTC9OSVNIVGVyRzRIOWpOckk5SFpJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c0dMUmphMmFNQm1zaitDU2djYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

