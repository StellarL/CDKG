<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132348502998750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201910011%26RESULT%3d1%26SIGN%3d8V624suDggnY6dNM7JmThJ1EooA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201910011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201910011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201910011&amp;v=Mjg0NzZxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiM0pMejdCWmJHNEg5ak5yNDlFWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#55" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="&lt;b&gt;2 相关研究&lt;/b&gt; "><b>2 相关研究</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="&lt;b&gt;2.1 压缩感知理论&lt;/b&gt;"><b>2.1 压缩感知理论</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;2.2 结构随机矩阵的构造&lt;/b&gt;"><b>2.2 结构随机矩阵的构造</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#78" data-title="&lt;b&gt;3 压缩图像融合方法&lt;/b&gt; "><b>3 压缩图像融合方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="&lt;b&gt;3.1 基于信息论的图像差融合算法&lt;/b&gt;"><b>3.1 基于信息论的图像差融合算法</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;3.2 自适应加权核范数最小化优化算法&lt;/b&gt;"><b>3.2 自适应加权核范数最小化优化算法</b></a></li>
                                                <li><a href="#154" data-title="&lt;b&gt;3.3 本文算法步骤&lt;/b&gt;"><b>3.3 本文算法步骤</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#161" data-title="&lt;b&gt;4 实验结果与分析&lt;/b&gt; "><b>4 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#165" data-title="&lt;b&gt;4.1 医学图像融合&lt;/b&gt;"><b>4.1 医学图像融合</b></a></li>
                                                <li><a href="#169" data-title="&lt;b&gt;4.2 红外与可见光图像融合&lt;/b&gt;"><b>4.2 红外与可见光图像融合</b></a></li>
                                                <li><a href="#176" data-title="&lt;b&gt;4.3 多聚焦图像融合&lt;/b&gt;"><b>4.3 多聚焦图像融合</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#186" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#131" data-title="图1 本文算法">图1 本文算法</a></li>
                                                <li><a href="#171" data-title="&lt;b&gt;表1 医学图像融合结果客观评价&lt;/b&gt;"><b>表1 医学图像融合结果客观评价</b></a></li>
                                                <li><a href="#172" data-title="图2 医学图像及不同算法融合结果图像">图2 医学图像及不同算法融合结果图像</a></li>
                                                <li><a href="#173" data-title="图3 红外与可见光图像及不同算法融合结果图像">图3 红外与可见光图像及不同算法融合结果图像</a></li>
                                                <li><a href="#178" data-title="图4 多聚焦测试图像对">图4 多聚焦测试图像对</a></li>
                                                <li><a href="#180" data-title="&lt;b&gt;表2 红外与可见光图像融合结果客观评价&lt;/b&gt;"><b>表2 红外与可见光图像融合结果客观评价</b></a></li>
                                                <li><a href="#183" data-title="图5 多聚焦图像及不同算法融合结果图像">图5 多聚焦图像及不同算法融合结果图像</a></li>
                                                <li><a href="#184" data-title="&lt;b&gt;表3 乐百氏多聚焦图像融合结果客观评价&lt;/b&gt;"><b>表3 乐百氏多聚焦图像融合结果客观评价</b></a></li>
                                                <li><a href="#185" data-title="&lt;b&gt;表4 Lab多聚焦图像融合结果客观评价&lt;/b&gt;"><b>表4 Lab多聚焦图像融合结果客观评价</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Liu Shuai-qi,Zheng Wei,Zhao Jie,et al.Analysis and application of algorithm for digital image fusion[M].Beijing:China Machine Press,2018.(in Chinese)" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analysis and application of algorithm for digital image fusion">
                                        <b>[1]</b>
                                         Liu Shuai-qi,Zheng Wei,Zhao Jie,et al.Analysis and application of algorithm for digital image fusion[M].Beijing:China Machine Press,2018.(in Chinese)
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Liu Sheng-peng,Fang Yong.Infrared image fusion algorithm based on contourlet transform and improved pulse coupled neural network[J].Journal of Infrared and Millimeter Waves,2007,26(3):217-221.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH200703013&amp;v=MTg1MzlKTFRyU1pyRzRIdGJNckk5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYjM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Liu Sheng-peng,Fang Yong.Infrared image fusion algorithm based on contourlet transform and improved pulse coupled neural network[J].Journal of Infrared and Millimeter Waves,2007,26(3):217-221.(in Chinese)
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     Qu Xiao-bo,Yan Jing-wen,Yang Gui-de.Multifocus image fusion method of sharp frequency localized contourlet transform domain based on sum-modified-laplacian[J].Optics and Precision Engineering,2009,17(5):1203-1212.(in Chinese)</a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Gao Guo-rong,Liu Yan-ping.Infrared and visible light images fusion algorithm based on non-subsampled shearlet transform[J].Transactions of the Chinese Society for Agricultural Machinery,2014,45(3):268-274.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201403044&amp;v=MTgxNTA1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiM0pLelRCZHJHNEg5WE1ySTlCWUlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Gao Guo-rong,Liu Yan-ping.Infrared and visible light images fusion algorithm based on non-subsampled shearlet transform[J].Transactions of the Chinese Society for Agricultural Machinery,2014,45(3):268-274.(in Chinese)
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Liu S Q,Zhang T,Li H L,et al.Medical image fusion based on nuclear norm minimization[J].International Journal of Imaging Systems and Technology,2015,25(4):310-316." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD15112400000101&amp;v=MDI0NDJzU2FCTT1OaWZjYXJLOUg5RE9xNDlGWk9zUERYdzRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKMQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Liu S Q,Zhang T,Li H L,et al.Medical image fusion based on nuclear norm minimization[J].International Journal of Imaging Systems and Technology,2015,25(4):310-316.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     Ma Min,Zhang Cai-xia,Lu Cheng-chao,et al.ECT image processing based on wavelet transform[J].Journal of Central South University (Science and Technology),2016,47(6):1947-1952.(in Chinese)</a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     Zhou Qiang,Zhao Ju-feng,Feng Hua-jun,et al.Infrared polarization image fusion with non-sampling shearlets[J].Journal of Zhejiang University (Engineering Science),2014,48(8):1508-1516.(in Chinese)</a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     Li Jiao,Yang Yan-chun,Dang Jian-wu,et al.NSST and guided filtering for multi-focus image fusion algorithm[J].Journal of Harbin Institute of Technology,2018,50(11):145-152.(in Chinese)</a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Wang Xin,Ji Tong-bo,Liu Fu.Fusion of infrared and visible images based on target segmentation and compressed sensing[J].Optics and Precision Engineering,2016,24(7):1743-1753.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201607025&amp;v=MTMwMTFtRnkvZ1ZiM0pJalhCWTdHNEg5Zk1xSTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Wang Xin,Ji Tong-bo,Liu Fu.Fusion of infrared and visible images based on target segmentation and compressed sensing[J].Optics and Precision Engineering,2016,24(7):1743-1753.(in Chinese)
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Luo X Y,Zhang J,Yang J Y,et al.Image fusion in compressed sensing[C]//Proc of the 16th International Conference on Image Processing,2009:2181-2184." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image fusion in compressed sensing">
                                        <b>[10]</b>
                                         Luo X Y,Zhang J,Yang J Y,et al.Image fusion in compressed sensing[C]//Proc of the 16th International Conference on Image Processing,2009:2181-2184.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Han J J,Loffeld O,Hartmann K,et al.Multi image fusion based on compressive sensing[C]//Proc of International Conference on Audio Language and Image Processing,2010:1463-1469." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi image fusion based on compressivesensing">
                                        <b>[11]</b>
                                         Han J J,Loffeld O,Hartmann K,et al.Multi image fusion based on compressive sensing[C]//Proc of International Conference on Audio Language and Image Processing,2010:1463-1469.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Li X,Qin S Y.Efficient fusion for infrared and visible images based on compressive sensing principle[J].IET Image Processing,2011,5(2):141-147." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient fusion for infrared and visible images based on compressive sensing principle">
                                        <b>[12]</b>
                                         Li X,Qin S Y.Efficient fusion for infrared and visible images based on compressive sensing principle[J].IET Image Processing,2011,5(2):141-147.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Wan T,Qin Z C.An application of compressive sensing for image fusion[J].International Journal of Computer Mathematics,2011,88(18):3915-3930." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD120604084149&amp;v=MDg0NjE0OU5ZT29MQlJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3Z0VTdqTkpsd1ZOam5CYXJLNkh0Zk1x&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Wan T,Qin Z C.An application of compressive sensing for image fusion[J].International Journal of Computer Mathematics,2011,88(18):3915-3930.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Yin H T,Li S T.Multimodal image fusion with joint sparsity model[J].Optical Engineering,2011,50(6):067007-10." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multimodal image fusion with joint sparsity model">
                                        <b>[14]</b>
                                         Yin H T,Li S T.Multimodal image fusion with joint sparsity model[J].Optical Engineering,2011,50(6):067007-10.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Yang B,Li S T.Pixel-level image fusion with simultaneous orthogonal matching pursuit[J].Information Fusion,2012,13(1):10-19." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300328956&amp;v=MDc5NTNCTT1OaWZPZmJLN0h0RE5ySTlGWitrSEJYay9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKMXNTYQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Yang B,Li S T.Pixel-level image fusion with simultaneous orthogonal matching pursuit[J].Information Fusion,2012,13(1):10-19.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Chen Yang,Qin Zheng.Gradient-based compressive image fusion[J].Frontiers of Information Technology &amp;amp; Electronic Engineering,2015,16(3):227-237." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZUS201503005&amp;v=MzAyNDBMemZlZmJHNEg5VE1ySTlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiM0o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Chen Yang,Qin Zheng.Gradient-based compressive image fusion[J].Frontiers of Information Technology &amp;amp; Electronic Engineering,2015,16(3):227-237.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Do T T,Gan L,Nguyen N H,et al.Fast and efficient compressive sensing using structurally random matrices[J].IEEE Transactions on Signal Processing,2012,60(1):139-154." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast and Efficient Compressive Sensing Using Structurally Random Matrices">
                                        <b>[17]</b>
                                         Do T T,Gan L,Nguyen N H,et al.Fast and efficient compressive sensing using structurally random matrices[J].IEEE Transactions on Signal Processing,2012,60(1):139-154.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Nirmala P,Kishore R.Infrared and visible image fusion using discrete cosine transform and swarm intelligence for surveillance applications[J].Infrared Physics &amp;amp; Technology,2018,88:13-22." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES028DF5285FE77B315CD59B9F0A5B79A4&amp;v=MTUzNzJGcVc2cW8xTllaMTZDM3RMekJjV21VdDRRUTNyMmhKRWZNQ1RUTXViQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJodzcyNXdxaz1OaWZPZmJPNg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Nirmala P,Kishore R.Infrared and visible image fusion using discrete cosine transform and swarm intelligence for surveillance applications[J].Infrared Physics &amp;amp; Technology,2018,88:13-22.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_1" title=" 刘帅奇,郑伟,赵杰,等.数字图像融合算法分析与应用[M].北京:机械工业出版社,2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787111593027000&amp;v=MDM1MDFyaWZadTl1RkN2dFU3ak5KbHdWWEZxekdiSzVIOVRGckk5SFkrc1BEQk04enhVU21EZDlTSDduM3hFOWZidm5L&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         刘帅奇,郑伟,赵杰,等.数字图像融合算法分析与应用[M].北京:机械工业出版社,2018.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     刘盛鹏,方勇.基于Contourlet变换和IPCNN的融合算法及其在可见光与红外线图像融合中的应用[J].红外与毫米波学报,2007,26(3):217-221.</a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_3" title=" 屈小波,闫敬文,杨贵德.改进拉普拉斯能量和的尖锐频率局部化Contourlet域多聚焦图像融合方法[J].光学精密工程,2009,17(5):1203-1212." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM200905041&amp;v=MjQ3MTlKSWpYQlk3RzRIdGpNcW85QlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYjM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         屈小波,闫敬文,杨贵德.改进拉普拉斯能量和的尖锐频率局部化Contourlet域多聚焦图像融合方法[J].光学精密工程,2009,17(5):1203-1212.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_4" >
                                        <b>[4]</b>
                                     高国荣,刘艳萍.基于非抽样Shearlet变换的红外与可见光图像融合方法[J].农业机械学报,2014,45(3):268-274.</a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_6" title=" 马敏,张彩霞,陆成超,等.基于小波变换的ECT图像处理[J].中南大学学报(自然科学版),2016,47(6):1947-1952." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNGD201606017&amp;v=MTUwNDllUm1GeS9nVmIzSlB5UE1hckc0SDlmTXFZOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         马敏,张彩霞,陆成超,等.基于小波变换的ECT图像处理[J].中南大学学报(自然科学版),2016,47(6):1947-1952.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_7" title=" 周强,赵巨峰,冯华君,等.非下采样剪切波的红外偏振图像融合[J].浙江大学学报(工学版),2014,48(8):1508-1516." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201408027&amp;v=Mjk5MjhaZVJtRnkvZ1ZiM0pQeW5SYmJHNEg5WE1wNDlIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         周强,赵巨峰,冯华君,等.非下采样剪切波的红外偏振图像融合[J].浙江大学学报(工学版),2014,48(8):1508-1516.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_8" title=" 李娇,杨艳春,党建武,等.NSST与引导滤波相结合的多聚焦图像融合算法[J].哈尔滨工业大学学报,2018,50(11):145-152." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201811021&amp;v=MjY1ODZHNEg5bk5ybzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiM0pMU2pKZHI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         李娇,杨艳春,党建武,等.NSST与引导滤波相结合的多聚焦图像融合算法[J].哈尔滨工业大学学报,2018,50(11):145-152.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     王昕,吉桐伯,刘富.结合目标提取和压缩感知的红外与可见光图像融合[J].光学精密工程,2016,24(7):1743-1753.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(10),1785-1794 DOI:10.3969/j.issn.1007-130X.2019.10.010            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>图像差与加权核范数最小化的压缩图像融合</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%8F%E9%87%91%E5%87%A4&amp;code=40654365&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏金凤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%B4%B5%E4%BB%93&amp;code=09162357&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张贵仓</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%AA%E5%87%AF&amp;code=38219272&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汪凯</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E9%99%A2&amp;code=0012645&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北师范大学数学与统计学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有的图像融合算法存在非线性操作产生的噪声干扰和空间复杂度高等问题,使得融合图像易失真和丢失信息。一些学者提出的压缩感知图像融合算法能有效改善这一问题,但大多忽略了图像矩阵的低秩性,往往会降低融合质量。由此,将压缩感知融合技术与低秩矩阵逼近方法相结合,提出基于信息论图像差与自适应加权核范数最小化的图像融合算法。该算法由3个阶段组成。首先,将2幅源图像通过小波稀疏基稀疏化,并利用结构随机矩阵压缩采样,得到测量输出矩阵。然后,将测量输出矩阵进行分块,再利用图像差融合算法得到融合后的测量输出矩阵块。最后,利用自适应加权核范数最小化优化得到的块权重,通过正交匹配追踪法重建融合图像。实验结果表明了该算法的有效性和普适性,并且在多种评价指标上优于其他融合算法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%8B%E7%BC%A9%E6%84%9F%E7%9F%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">压缩感知;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%A1%E6%81%AF%E8%AE%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息论;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%B7%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像差;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E6%9D%83%E6%A0%B8%E8%8C%83%E6%95%B0%E6%9C%80%E5%B0%8F%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加权核范数最小化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    苏金凤（1995-），女，甘肃武威人，硕士生，研究方向为数字图像处理。E-mail:1184644503@qq.com，通信地址:730070甘肃省兰州市西北师范大学数学与统计学院&lt;image id="235" type="formula" href="images/JSJK201910011_23500.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    张贵仓（1964-），男，甘肃天水人，博士，教授，研究方向为数字图像处理、图像图形学、计算机辅助设计和数字水印。E-mail:zhanggc@nwnu.edu.cn，通信地址:730070甘肃省兰州市西北师范大学数学与统计学院&lt;image id="237" type="formula" href="images/JSJK201910011_23700.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    汪凯（1993-），男，安徽六安人，硕士生，研究方向为数字图像处理和计算机图形学。E-mail:616688448@qq.com，通信地址:730070甘肃省兰州市西北师范大学数学与统计学院&lt;image id="239" type="formula" href="images/JSJK201910011_23900.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-22</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61861040);</span>
                                <span>甘肃省教育厅科技成果转化项目(2017D-09);</span>
                                <span>甘肃省科技项目(17YF1FA119);</span>
                                <span>兰州市科技计划项目(2018-4-35);</span>
                    </p>
            </div>
                    <h1><b>Compressed image fusion based on image difference and weighted kernel norm minimization</b></h1>
                    <h2>
                    <span>SU Jin-feng</span>
                    <span>ZHANG Gui-cang</span>
                    <span>WANG Kai</span>
            </h2>
                    <h2>
                    <span>School of Mathematics and Statistics,Northwest Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Existing image fusion algorithms have some problems caused by non-linear operations, such as noise interference and spatial complexity, which make fused images easy to cause distortion and information loss. Compressed sensing image fusion algorithms proposed by some scholars can effectively improve this problem. However, most of them neglect the low rank of image matrix, thus often reducing the quality of fusion. Thus, combining the compressed sensing fusion technology with the low rank matrix approximation method, we propose an image fusion method based on information theory image difference and adaptive weighted kernel norm minimization. The method consists of three stages. Firstly, the two source images are sparsed by wavelet sparse basis, and the measurement output matrix is obtained by compressing the samplings with structural random matrix. Then, the measurement output matrix is divided into blocks, and the fused measurement output matrix blocks are obtained by using the image difference fusion algorithm. Finally, the block weights obtained by adaptive weighted kernel norm minimization method are used to reconstruct the fused image by the orthogonal matching pursuit method. Experimental results verify the validity and universality and show that our method is superior to other fusion algorithms in many evaluation indexes.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=compressed%20sensing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">compressed sensing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=information%20theory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">information theory;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20difference&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image difference;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=weighted%20kernel%20norm%20minimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">weighted kernel norm minimization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    SU Jin-feng,born in 1995,MS candidate,her research interest includes digital image processing.Address:School of Mathematics and Statistics,Northwest Normal University,Lanzhou 730070,Gansu,P.R.China;
                                </span>
                                <span>
                                    ZHANG Gui-cang,born in 1964,PhD, professor,his research interests include digital image processing,image and graphics,computer aided design,and digital watermarking.Address:School of Mathematics and Statistics,Northwest Normal University,Lanzhou 730070,Gansu,P.R.China;
                                </span>
                                <span>
                                    WANG Kai,born in 1993,MS candidate,his research interests include digital image processing,and computer graphics.Address:School of Mathematics and Statistics,Northwest Normal University,Lanzhou 730070,Gansu,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-22</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="55" name="55" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="56">图像融合是将来自同一场景的2幅或多幅图像合并成一幅图像的过程,目的是减少信息的不确定性,消除冗余的信息,全面利用互补信息,最终形成一幅信息完善、有效的图像。因此,图像融合技术已广泛地应用于医学、军事、遥感及气象预报等多个领域。例如,医学图像的融合能够为医生的诊断提供更准确的疾病信息,以便医生制定科学、完善的治疗方案。红外与可见光图像的融合也在监视和目标跟踪的军事应用中扮演着重要的角色。多聚焦图像融合可以有效利用图像信息增强系统对目标的可靠识别<citation id="211" type="reference"><link href="3" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="57">传统图像融合算法主要包括基于金字塔的算法、基于小波的算法和基于多尺度几何分析的算法。近年来,研究者们又提出了比较新的算法,如2007年刘盛鹏等人<citation id="212" type="reference"><link href="5" rel="bibliography" /><link href="41" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">2</a>]</sup></citation>提出了一种基于Contourlet变换和改进的脉冲耦合神经网络的红外与可见光图像融合算法,获得了很好的视觉效果。2009年屈小波等人<citation id="213" type="reference"><link href="7" rel="bibliography" /><link href="43" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">3</a>]</sup></citation>提出了一种基于SFLCT(Sharp Frequency Localized Contourlet Transform)变换和改进拉普拉斯能量和的多聚焦图像融合算法,融合效果优于基于Contourlet变换的图像融合,但融合图像引入了“伪影”,存在噪声干扰,无法获取图像的细节信息。2014年高国荣等人<citation id="214" type="reference"><link href="9" rel="bibliography" /><link href="45" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">4</a>]</sup></citation>提出一种基于NSST(Non-Subsampled Shearlet Transform)变换的红外与可见光图像融合算法,融合效果优于以上算法的,但算法的空间复杂度高,传输成本上升,导致操作困难。2015年Liu等人<citation id="215" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>利用加核范数最小化WNNM(Weighted Nuclear Norm Minimization)约束的低秩矩阵逼近,提出一种新的医学图像融合算法,融合效果优于变换域算法的,能够去除融合过程中产生的噪声,从而抑制噪声干扰,但是应用到其他场景还是会出现噪声干扰。然而,这些算法都是在全采样的基础上建立的,实际操作过程中空间复杂度高,往往影响融合图像质量。随着实际要求的提高,对于图像融合系统的实时性要求越来越高,所以迫切需要开发有效的融合算法<citation id="216" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="47" rel="bibliography" /><link href="49" rel="bibliography" /><link href="51" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="58">近年来,压缩感知CS(Compressed Sensing)理论引起许多研究者的关注,并取得了较好的效果。与传统算法相比,CS对源图像的采集要求较低。对于稀疏信号,CS能从另一个基底相对较小的一组随机线性投影中恢复出来。所以,由于降低空间复杂度和节约传输成本的优势,CS已经成为图像融合的首选算法<citation id="217" type="reference"><link href="19" rel="bibliography" /><link href="53" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">9</a>]</sup></citation>。2009年Luo等人<citation id="218" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出用加权平均来合并压缩域中图像压缩测量的熵,使得在空域中稀疏信号可以处理变换后的区域,并用梯度投影法重建。2010年Han等人<citation id="219" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>以离散余弦变换为稀疏基,利用小波变换进行测量,再分别融合近似系数和细节系数。2011年Li等人<citation id="220" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出基于标准差的自适应加权压缩融合算法,采用傅里叶变换作为其稀疏基。同年Wan等人<citation id="221" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出以绝对值最大化作为融合规则的压缩融合方案,也是以傅里叶变换为稀疏基,测量值用最小总变差法重建。2011年Yin等人<citation id="222" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出基于联合稀疏表示的多模态图像融合算法,该算法可以有效分离监控同一场景的多模态图像的互补信息。2012年Yang等人<citation id="223" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>又提出了一种基于信号稀疏表示理论的多传感器图像融合算法。2015年Chen等人<citation id="224" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出了一种基于梯度和加扰块哈达玛集成采样的压缩感知图像融合算法,可以应用于不同的融合场景,有很强的场景适应性。虽然这些方法能够得到高质量的融合图像,但也由于融合规则的非线性操作产生噪声干扰,导致像素失真和信息丢失。</p>
                </div>
                <div class="p1">
                    <p id="59">因此,针对图像融合过程中易受噪声干扰和现有融合算法的空间复杂度高等问题,本文提出一种基于信息论的图像差与自适应加权核范数最小化的压缩图像融合算法。首先,以小波稀疏基将源图像稀疏化,选用结构随机矩阵作为采样算子,对稀疏矩阵进行压缩采样,得到测量输出矩阵MOM(Measurement Output Matrix),目的是缩减存储空间,降低空间复杂度。其次,利用基于信息论的图像差融合算法ITID(Information Theory Image Difference)得到块权重,对MOM块进行块融合,有效地结合了同一场景下不同模态的互补信息。然后,对融合后的MOM块利用自适应加权核范数最小化算法AWNNM(Adaptive Weighted Nuclear Norm Minimization)优化块权重。最后,用正交匹配追踪法OMP(Orthogonal Matching Pursuit)重建得到融合图像。实验结果表明,本文提出的算法可以应用于不同模态不同场景,并且在主观和客观评价结果上优于其他融合算法,能够较好地保留源图像边缘信息,抑制噪声干扰,不易造成失真和信息损失,并且降低了空间复杂度。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag"><b>2 相关研究</b></h3>
                <h4 class="anchor-tag" id="61" name="61"><b>2.1 压缩感知理论</b></h4>
                <div class="p1">
                    <p id="62">压缩感知理论是近几年在计算机视觉上广泛应用的算法,其独特之处在于能利用传感器有效地从稀疏信号中以少量的采样获得信号的优化重建。CS理论的核心主要有稀疏表示、测量矩阵和信号重构3方面。给定信号<i><b>x</b></i>∈<b>R</b><sup><i>N</i></sup>,在正交基<i>Ψ</i>=[<i>ψ</i><sup>T</sup><sub>0</sub>,<i>ψ</i><sup>T</sup><sub>1</sub>,…,<i>ψ</i><sup>T</sup><sub><i>N</i></sub><sub>-1</sub>]上表示为:</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">x</mi><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ν</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub><mi mathvariant="bold-italic">ψ</mi><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">Ψ</mi><mi mathvariant="bold-italic">a</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">其中,<i>a</i><sub><i>i</i></sub>是向量<i><b>a</b></i>中的元素。如果系数向量<i><b>a</b></i>中有<i>k</i>个不等于0的元素,那么<i><b>x</b></i>在此变换域上是<mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>k</mi><mrow><mo>(</mo><mrow><mi>k</mi><mo>≥</mo><mn>1</mn></mrow><mo>)</mo></mrow></mrow></math></mathml>稀疏的。</p>
                </div>
                <div class="p1">
                    <p id="65">测量矩阵<i><b>M</b></i>∈<b>R</b><sup><i>M</i></sup><sup>×</sup><sup><i>N</i></sup>投影后,由式(2)得到测量向量<i><b>y</b></i>∈<b>R</b><sup><i>M</i></sup><sup>×1</sup>,即:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">y</mi><mo>=</mo><mi mathvariant="bold-italic">Μ</mi><mi mathvariant="bold-italic">x</mi><mo>=</mo><mi mathvariant="bold-italic">Μ</mi><mi mathvariant="bold-italic">Ψ</mi><mi mathvariant="bold-italic">a</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">因为<i>M</i>≼<i>N</i>,投影过程结合了传统的信号采样和压缩过程。根据<i><b>y</b></i>和<i><b>M</b></i>来恢复<i><b>x</b></i>是一个病态反问题,可以转化为一个稀疏优化问题来解决:</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>min</mi><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">a</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mspace width="0.25em" /><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mi mathvariant="bold-italic">y</mi><mo>=</mo><mi mathvariant="bold-italic">Φ</mi><mi mathvariant="bold-italic">a</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">其中,<i>Φ</i>=<i><b>M</b></i><i>Ψ</i>,‖·‖<sub>1</sub>表示<i>L</i><sub>1</sub>范数,由此信号<i><b>x</b></i>可以从式(3)中恢复出来。</p>
                </div>
                <div class="p1">
                    <p id="70">要准确恢复信号<i><b>x</b></i>,<i>Φ</i>必须满足约束等距性质RIP(Restricted Isometry Property):</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo>-</mo><mi>ε</mi><mo>≤</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Φ</mi><mi mathvariant="bold-italic">v</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>≤</mo><mn>1</mn><mo>+</mo><mi>ε</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">其中<i>ε</i>&gt;0,‖·‖<sub>2</sub>表示<i>L</i><sub>2</sub>范数,<i><b>v</b></i>是一个严格<i>k</i>稀疏的<i>N</i>维向量。换而言之,矩阵<i><b>M</b></i>和基底<i>Ψ</i>是不相关的。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>2.2 结构随机矩阵的构造</b></h4>
                <div class="p1">
                    <p id="74">本文采用的测量矩阵是由文献<citation id="225" type="reference">[<a class="sup">17</a>]</citation>中生成的结构随机矩阵,相对于高斯矩阵、伯努利矩阵、部分傅里叶矩阵和哈达玛矩阵等测量矩阵,它能够得到更好的压缩采样结果。结构随机矩阵定义为3个矩阵的乘积,如式(5)所示:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mi mathvariant="bold-italic">Φ</mi><mo>)</mo></mrow><msub><mrow></mrow><mrow><mi>Μ</mi><mo>×</mo><mi>Ν</mi></mrow></msub><mo>=</mo><msqrt><mrow><mfrac><mi>Ν</mi><mi>Μ</mi></mfrac></mrow></msqrt><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">F</mi><mi mathvariant="bold-italic">R</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">其中,(<i><b>R</b></i>)<sub><i>N</i></sub><sub>×</sub><sub><i>N</i></sub>是均匀随机排列矩阵或对角项<i>R</i><sub><i>ii</i></sub>为具有<mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mrow><mo>(</mo><mrow><mi>R</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow></msub><mo>=</mo><mo>±</mo><mn>1</mn></mrow><mo>)</mo></mrow><mo>=</mo><mn>1</mn><mo>/</mo><mn>2</mn></mrow></math></mathml>的独立同分布伯努利随机变量的对角随机矩阵;<mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mi mathvariant="bold-italic">F</mi><mo>)</mo></mrow><msub><mrow></mrow><mrow><mi>Ν</mi><mo>×</mo><mi>Ν</mi></mrow></msub></mrow></math></mathml>是随机正交变换,例如傅里叶变换、离散余弦变换、沃尔什-哈达玛变换或对角变换;<mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mi mathvariant="bold-italic">D</mi><mo>)</mo></mrow><msub><mrow></mrow><mrow><mi>Μ</mi><mo>×</mo><mi>Ν</mi></mrow></msub></mrow></math></mathml>是子采样矩阵或算子,选中<i><b>FR</b></i>的行随机子集。若选择行的概率是<i>M</i>/<i>N</i>,则选择的行数将是平均的。比例系数<mathml id="192"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mi>Ν</mi><mo>/</mo><mi>Μ</mi></mrow></msqrt></mrow></math></mathml>对变换进行归一化,使得测量向量的能量与输入信号的能量几乎近似。</p>
                </div>
                <div class="p1">
                    <p id="77">根据稀疏重建算法,例如基追踪、<i>L</i><sub>1</sub>范数极小化、正交匹配追踪和梯度投影,本文中使用正交匹配追踪算法重建原始图像。</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag"><b>3 压缩图像融合方法</b></h3>
                <h4 class="anchor-tag" id="79" name="79"><b>3.1 基于信息论的图像差融合算法</b></h4>
                <h4 class="anchor-tag" id="80" name="80">3.1.1 自适应选取标准背景图像</h4>
                <div class="p1">
                    <p id="81">根据源图像的相似性,首先将两个源图像<i>A</i>和<i>B</i>的MOM进行分块,得到<i><b>Y</b></i><sub>1</sub>{<i>i</i>,<i>j</i>}和<i><b>Y</b></i><sub>2</sub>{<i>i</i>,<i>j</i>}。假设以<mathml id="193"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mrow><mo>(</mo><mrow><mi>Ν</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></math></mathml>为标准背景图像的测量输出块,那么可以用<mathml id="194"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo></mrow></math></mathml>来表示2幅源图像对应MOM块的差异信息,从而用<i>μ</i><sub><i>N</i></sub>来选取差异信息中最有效的信息,以此和标准背景图像进行融合。建立以下融合模型:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>=</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>+</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>⋅</mo><mi>μ</mi><msub><mrow></mrow><mi>Ν</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">其中,<i><b>Y</b></i>{<i>i</i>,<i>j</i>}为融合后图像对应的MOM块,<mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mi>Ν</mi></msub><mrow><mo>(</mo><mrow><mi>Ν</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></math></mathml>为不同标准背景图像块对应的块权重,将在3.1.2节中给出。</p>
                </div>
                <div class="p1">
                    <p id="84">选取标准背景图像的关键是能度量图像的MOM整体信息,需要信息熵、互信息和联合信息熵。信息熵是信息论中衡量图像信息丰富程度的重要指标,表示所包含的平均信息量,定义如式(7)所示:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mi>Ν</mi><mrow><mo>(</mo><mi>Y</mi><mo>)</mo></mrow><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>Y</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mspace width="0.25em" /><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mspace width="0.25em" /><mi>p</mi><msub><mrow></mrow><mi>Y</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中,<i>L</i>表示图像<i>Y</i>的像素数,<i>p</i><sub><i>Y</i></sub>(<i>i</i>)为每个灰度级的分布概率。</p>
                </div>
                <div class="p1">
                    <p id="87">互信息在信息论中是非常有用的度量,涉及2幅图像之间的相关性,在图像处理中有广泛的应用。其定义如式(8)所示:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mi>p</mi></mstyle></mrow></mstyle><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mspace width="0.25em" /><mi>ln</mi><mspace width="0.25em" /><mfrac><mrow><mi>p</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>p</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>)</mo></mrow><mi>p</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中,<mathml id="196"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>和<mathml id="197"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>分别为源图像<i>r</i><sub>1</sub>和<i>r</i><sub>2</sub>的边缘概率密度,<mathml id="198"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>为<i>r</i><sub>1</sub>和<i>r</i><sub>2</sub>的联合概率密度。</p>
                </div>
                <div class="p1">
                    <p id="90">联合信息熵公式如下:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mi>p</mi></mstyle></mrow></mstyle><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mspace width="0.25em" /><mi>ln</mi><mspace width="0.25em" /><mi>p</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">由此,本文选取文献<citation id="226" type="reference">[<a class="sup">16</a>]</citation>中描述图像信息差异比重的公式(式(10)和式(11))作为自适应算子,用于计算差异权重<i>w</i><sub>1</sub>和<i>w</i><sub>2</sub>:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mo>-</mo><mfrac><mrow><mi>Η</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mn>2</mn><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi>Η</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mfrac><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mo>-</mo><mfrac><mrow><mi>Η</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mn>2</mn><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mo>⋅</mo><mfrac><mrow><mi>Η</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>E</mi><mrow><mo>(</mo><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">图像差融合算法的核心问题是如何选取标准背景图像得到结果最优的融合图像。因此,定义标准背景图像是信息量最少的图像,目的是将大部分差异信息集中在<mathml id="199"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo></mrow></math></mathml>中,能够提取源图像MOM块中最大化的有效信息。所以,标准背景图像的选取规则如式(12)定义:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>+</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mi>μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>&lt;</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>+</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>≥</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">其中,<i><b>Y</b></i><sub>1</sub>和<i><b>Y</b></i><sub>2</sub>分别是源图像<i>A</i>和<i>B</i>的MOM块,<mathml id="200"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mi>Ν</mi></msub><mrow><mo>(</mo><mrow><mi>Ν</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></math></mathml>是不同标准背景图像块对应的块权重。</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">3.1.2 图像差融合算法</h4>
                <div class="p1">
                    <p id="98">根据3.1.1节得到的标准背景图像对应的<i>MOM</i>块,为了获取源图像中最大化的有效信息,接下来需要计算对应的块权重。</p>
                </div>
                <div class="p1">
                    <p id="99">交叉熵反映了图像间灰度信息分布的差别,可以弥补信息熵的不足。交叉熵如式(13)所示:</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>E</mi><msub><mrow></mrow><mrow><mi>A</mi><mo>,</mo><mi>B</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">其中,<i>p</i><sub><i>A</i></sub>(<i>i</i>)表示图像的灰度级分布概率。</p>
                </div>
                <div class="p1">
                    <p id="102">由于交叉熵中出现的<i>p</i><sub><i>A</i></sub>(<i>i</i>)/<i>p</i><sub><i>B</i></sub>(<i>i</i>)可能大于1或小于1,所以定义以下交叉熵如式(14)所示:</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><mi>C</mi><mi>E</mi><msub><mrow></mrow><mrow><mi>A</mi><mo>,</mo><mi>B</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>|</mo><mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="104">用信息熵表示图像<i>A</i>或<i>B</i>的MOM块所包含的信息,利用交叉熵表示它们之间的信息分布差异,分别得到差异因子为:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>η</mi><msub><mrow></mrow><mi>A</mi></msub><mo>=</mo><mi>E</mi><mi>Ν</mi><mrow><mo>(</mo><mi>A</mi><mo>)</mo></mrow><mo>-</mo><mi>α</mi><mi>C</mi><mi>E</mi><msub><mrow></mrow><mrow><mi>A</mi><mo>,</mo><mi>B</mi></mrow></msub><mo>=</mo></mtd></mtr><mtr><mtd><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ρ</mi></mstyle><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>|</mo><mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>η</mi><msub><mrow></mrow><mi>B</mi></msub><mo>=</mo><mi>E</mi><mi>Ν</mi><mrow><mo>(</mo><mi>B</mi><mo>)</mo></mrow><mo>-</mo><mi>α</mi><mi>C</mi><mi>E</mi><msub><mrow></mrow><mrow><mi>B</mi><mo>,</mo><mi>A</mi></mrow></msub><mo>=</mo></mtd></mtr><mtr><mtd><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ρ</mi></mstyle><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>|</mo><mrow><mfrac><mrow><mi>p</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">由文献<citation id="227" type="reference">[<a class="sup">18</a>]</citation>可知式(17)用于描述图像整体信息量:</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>ρ</mi><mo>=</mo><mi>max</mi><mrow><mo>(</mo><mrow><mfrac><mrow><mn>4</mn><mi>δ</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>B</mi></mrow></msub><mover accent="true"><mi mathvariant="bold-italic">a</mi><mo stretchy="true">¯</mo></mover><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo stretchy="true">¯</mo></mover></mrow><mrow><mrow><mo>(</mo><mrow><mi>δ</mi><msubsup><mrow></mrow><mi>A</mi><mn>2</mn></msubsup><mo>+</mo><mi>δ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup></mrow><mo>)</mo></mrow><mrow><mo>(</mo><mrow><mrow><mo>(</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">a</mi><mo stretchy="true">¯</mo></mover></mrow><mo>)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo>(</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo stretchy="true">¯</mo></mover></mrow><mo>)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>)</mo></mrow></mrow></mfrac></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">a</mi><mo stretchy="true">¯</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>Τ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi mathvariant="bold-italic">a</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo stretchy="true">¯</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>Τ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi mathvariant="bold-italic">b</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">其中,<i><b>a</b></i><sub><i>i</i></sub>和<i><b>b</b></i><sub><i>i</i></sub>表示图像<i>A</i>和<i>B</i>对应的矩阵的列向量。<i>T</i>表示图像<i>A</i>、<i>B</i>对应矩阵的列数。</p>
                </div>
                <div class="p1">
                    <p id="109">同样地,图像<i>A</i>和<i>B</i>对应的矩阵的方差如式(19)所示:</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msubsup><mrow></mrow><mi>A</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">a</mi><mo stretchy="true">¯</mo></mover></mrow><mo>)</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>,</mo><mi>δ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo stretchy="true">¯</mo></mover></mrow><mo>)</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">计算协方差如式(20)所示:</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>B</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">a</mi><mo stretchy="true">¯</mo></mover></mrow><mo>)</mo></mrow></mrow></mstyle><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo stretchy="true">¯</mo></mover></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">则图像<i>A</i>和<i>B</i>对应矩阵的信息分布差异概率如式(21)所示:</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mi>η</mi><msub><mrow></mrow><mi>A</mi></msub></mrow><mi>ρ</mi></mfrac><mo>,</mo></mtd></mtr><mtr><mtd><mi>τ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mfrac><mrow><mi>η</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mi>ρ</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="115">最后得到块权重:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>τ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>,</mo><mi>μ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mfrac><mrow><mi>τ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>τ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">将块权重应用到图像差融合,得到如下融合规则:</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>+</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mfrac><mrow><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>τ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>,</mo><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>&lt;</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>+</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mfrac><mrow><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>τ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>τ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>,</mo><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>≥</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="119" name="119"><b>3.2 自适应加权核范数最小化优化算法</b></h4>
                <h4 class="anchor-tag" id="120" name="120">3.2.1 加权核范数最小化理论</h4>
                <div class="p1">
                    <p id="121">2015年,<i>Liu</i>等人<citation id="228" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了基于核范数最小化的融合算法,对奇异值进行了不同的软阈值操作,能够很好地保留图像中的信息和低秩结构特征。设<i><b>Y</b></i><sub><i>j</i></sub>为含噪图像对应的块矩阵,<i><b>X</b></i><sub><i>j</i></sub>和<i><b>N</b></i><sub><i>j</i></sub>为清晰图像和噪声所对应的块矩阵,则噪声抑制模型可以转化为:</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mi mathvariant="bold-italic">Ν</mi><msub><mrow></mrow><mi>j</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">解决最小化问题表示为:</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>^</mo></mover><mo>=</mo><mi>arg</mi><mspace width="0.25em" /><mi>min</mi><msub><mrow></mrow><mi mathvariant="bold-italic">X</mi></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Y</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>,</mo><mo>*</mo></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">其中,<i><b>Y</b></i>是已知矩阵,<i><b>X</b></i>是要求解的近似<i><b>Y</b></i>的低秩矩阵。<mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mo>⋅</mo><mo stretchy="false">∥</mo><msub><mrow></mrow><mi>F</mi></msub><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>a</mi></mstyle></mrow></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup></mrow></msqrt><mo>,</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Y</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></math></mathml>用来衡量低秩矩阵<i><b>X</b></i>和<i><b>Y</b></i>之间的偏离程度,‖<i><b>X</b></i>‖<sub><i><b>w</b></i></sub><sub>,*</sub>表示矩阵<i><b>X</b></i>的加权核范数,可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>,</mo><mo>*</mo></mrow></msub><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>i</mi></msub><mo stretchy="false">∥</mo></mstyle><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">)</mo><mo stretchy="false">∥</mo><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">其中,<mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">w</mi><mo>=</mo><mrow><mo>[</mo><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>w</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>]</mo></mrow><mo stretchy="false">(</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≥</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>为分配给矩阵<i><b>X</b></i>的不同奇异值<mathml id="203"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mo>(</mo><mi mathvariant="bold-italic">X</mi><mo>)</mo></mrow></mrow></math></mathml>的一个非负权重。在<mathml id="204"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><msub><mrow></mrow><mi>n</mi></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo>≤</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo>≤</mo><mo>⋯</mo><mo>≤</mo><mi>σ</mi><msub><mrow></mrow><mn>0</mn></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>且0≤<i>w</i><sub>1</sub>≤…≤<i>w</i><sub><i>n</i></sub>时,上述加权核范数最小化全局最优解为:</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>^</mo></mover><mo>=</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">S</mi><msub><mrow></mrow><mi mathvariant="bold-italic">w</mi></msub><mrow><mo>(</mo><mi mathvariant="bold-italic">Σ</mi><mo>)</mo></mrow><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="129">其中,<i><b>Y</b></i>=<i><b>UΣV</b></i><sup>T</sup>表示矩阵<i><b>Y</b></i>的奇异值分解,矩阵<i><b>U</b></i>和<i><b>V</b></i>满足<i><b>UU</b></i><sup>T</sup>=<i><b>I</b></i>,<i><b>VV</b></i><sup>T</sup>=<i><b>I</b></i>,<i>Σ</i>是矩阵<i><b>Y</b></i>的奇异值构成的对角阵。<mathml id="205"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mi mathvariant="bold-italic">w</mi></msub><mrow><mo>(</mo><mi mathvariant="bold-italic">Σ</mi><mo>)</mo></mrow></mrow></math></mathml>是权重向量<i><b>w</b></i>的广义软阈值算子,即:</p>
                </div>
                <div class="p1">
                    <p id="130" class="code-formula">
                        <mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mi mathvariant="bold-italic">w</mi></msub><mrow><mo>(</mo><mi mathvariant="bold-italic">Σ</mi><mo>)</mo></mrow><mo>=</mo><mi>max</mi><mrow><mo>(</mo><mrow><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mo>(</mo><mi mathvariant="bold-italic">X</mi><mo>)</mo></mrow><mo>-</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mn>0</mn></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910011_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法" src="Detail/GetImg?filename=images/JSJK201910011_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910011_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 1 <i>The proposed algorithm</i></p>

                </div>
                <h4 class="anchor-tag" id="132" name="132">3.2.2 自适应加权核范数最小化的优化算法</h4>
                <div class="p1">
                    <p id="133"><i>Liu</i>等人<citation id="229" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>利用类似主成分分析的算法精确地保留近似对角元素,在<mathml id="206"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mi mathvariant="bold-italic">w</mi></msub><mrow><mo>(</mo><mi mathvariant="bold-italic">Σ</mi><mo>)</mo></mrow></mrow></math></mathml>中加权参数<i>w</i><sub><i>i</i></sub>是根据融合后图像的奇异值计算得到的。然而,融合后图像由于噪声干扰会丢失一部分源图像的信息,导致最后得到的图像信息不完整,故加权参数与源图像有不可忽视的关系。本文提出<i>AWNNM</i>算法,其核心是产生一个自适应加权参数。利用源图像对应<i>MOM</i>块的奇异值以及融合后图像对应<i>MOM</i>块的奇异值自适应得到加权参数。不同的加权参数应对不同的场景,对融合后的图像起到抑制噪声干扰的作用。其定义如下:</p>
                </div>
                <div class="p1">
                    <p id="134" class="code-formula">
                        <mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mi>min</mi><mrow><mo>|</mo><mrow><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mspace width="0.25em" /></mrow></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mspace width="0.25em" /></mrow></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo></mrow><mo>|</mo></mrow><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>,</mo><mo>*</mo><mspace width="0.25em" /></mrow></msub><mo>=</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Y</mi></msub><mi>S</mi><msub><mrow></mrow><mi mathvariant="bold-italic">w</mi></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Σ</mi><mspace width="0.25em" /></mrow><mo>)</mo></mrow><mi mathvariant="bold-italic">V</mi><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">Y</mi><mspace width="0.25em" /></mrow><mtext>Τ</mtext></msubsup></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="135">其中,<i><b>Y</b></i>{<i>i</i>,<i>j</i>}是融合后的图像对应的测量矩阵块,设<mathml id="207"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mrow><mo>(</mo><mrow><mi>Ν</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></math></mathml>是要求解的近似<i><b>Y</b></i>{<i>i</i>,<i>j</i>}的低秩矩阵块,则对<i><b>Y</b></i>{<i>i</i>,<i>j</i>}进行奇异值分解,得到<mathml id="208"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>=</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi mathvariant="bold-italic">Y</mi></msub><mi mathvariant="bold-italic">Σ</mi><mi mathvariant="bold-italic">V</mi><msubsup><mrow></mrow><mi mathvariant="bold-italic">Y</mi><mtext>Τ</mtext></msubsup></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="136">式(30)表示图像<i>A</i>对应的<i>MOM</i>块的不同奇异值所占的权重:</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>1</mn><mi>i</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mrow><mo>|</mo></mrow><mo>+</mo><mo>⋯</mo><mo>+</mo><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>1</mn><mi>n</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="138">式(31)表示图像<i>B</i>对应的<i>MOM</i>块的不同奇异值所占的权重:</p>
                </div>
                <div class="p1">
                    <p id="139" class="code-formula">
                        <mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>2</mn><mi>i</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub></mrow><mo>|</mo></mrow><mo>+</mo><mo>⋯</mo><mo>+</mo><mrow><mo>|</mo><mrow><mi>σ</mi><msub><mrow></mrow><mrow><mn>2</mn><mi>n</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="140">取图像<i>A</i>、<i>B</i>对应的<i>MOM</i>块的奇异值所占的权重的均值,得到:</p>
                </div>
                <div class="p1">
                    <p id="141" class="code-formula">
                        <mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>+</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mrow><mn>2</mn></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="142">则式(33)表示图像<i>A</i>和<i>B</i>的<i>MOM</i>块的不同奇异值之间的差异性,即为它们之间信息的差异,将其定义为加权参数:</p>
                </div>
                <div class="p1">
                    <p id="143" class="code-formula">
                        <mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>λ</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>=</mo><mi>w</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>-</mo><mi>w</mi><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>,</mo><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="144">利用式(34)和式(35)计算不同加权参数所占的比重:</p>
                </div>
                <div class="p1">
                    <p id="145" class="code-formula">
                        <mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><msqrt><mrow><mrow><mo>(</mo><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>-</mo><mi>w</mi><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><msqrt><mrow><mrow><mo>(</mo><mrow><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>-</mo><mi>w</mi><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow><mrow><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="146">选择所占比重较大的加权参数,获取完整的有效信息:</p>
                </div>
                <div class="p1">
                    <p id="147" class="code-formula">
                        <mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>λ</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>-</mo><mi>w</mi><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>,</mo><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>&gt;</mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mtd></mtr><mtr><mtd><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>-</mo><mi>w</mi><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>,</mo><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>≤</mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mtd></mtr></mtable></mrow><mo>,</mo></mtd></mtr><mtr><mtd><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="148">得到加权参数对应的软阈值算子:</p>
                </div>
                <div class="p1">
                    <p id="149" class="code-formula">
                        <mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mi mathvariant="bold-italic">w</mi></msub><mrow><mo>(</mo><mi mathvariant="bold-italic">Σ</mi><mo>)</mo></mrow><mo>=</mo><mi>max</mi><mrow><mo>(</mo><mrow><mi>σ</mi><msub><mrow></mrow><mi>n</mi></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo></mrow><mo>)</mo></mrow><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>,</mo><mn>0</mn></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="150">进而得到精确的融合图像:</p>
                </div>
                <div class="p1">
                    <p id="151" class="code-formula">
                        <mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>^</mo></mover><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>min</mi><mo stretchy="false">∥</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Y</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>,</mo><mo>*</mo></mrow></msub><mo>,</mo><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>min</mi><mo stretchy="false">∥</mo><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">w</mi><mo>,</mo><mo>*</mo></mrow></msub><mo>,</mo><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>≤</mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="152">其中,<i><b>X</b></i><sub>1</sub>{<i>i</i>,<i>j</i>}和<i><b>X</b></i><sub>2</sub>{<i>i</i>,<i>j</i>}是不同<i>MOM</i>块对应的近似<i><b>Y</b></i>{<i>i</i>,<i>j</i>}的低秩矩阵块,<mathml id="209"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>^</mo></mover></math></mathml>{<i>i</i>,<i>j</i>}是最后优化得到的<i>MOM</i>块。将式(37)代入得:</p>
                </div>
                <div class="p1">
                    <p id="153" class="code-formula">
                        <mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mo stretchy="false">(</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">Y</mi><mspace width="0.25em" /></mrow></msub><mi>max</mi><mo stretchy="false">(</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>n</mi><mspace width="0.25em" /></mrow></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo></mrow><mo>)</mo></mrow><mo>-</mo></mtd></mtr><mtr><mtd><mi>λ</mi><msub><mrow></mrow><mrow><mi>k</mi><mspace width="0.25em" /></mrow></msub><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow><mo>,</mo><mn>0</mn><mo stretchy="false">)</mo><mi mathvariant="bold-italic">V</mi><msubsup><mrow></mrow><mrow><mi mathvariant="bold-italic">Y</mi><mspace width="0.25em" /></mrow><mtext>Τ</mtext></msubsup><mo stretchy="false">)</mo><mo stretchy="false">{</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="154" name="154"><b>3.3 本文算法步骤</b></h4>
                <div class="p1">
                    <p id="155">参照图1,本文算法具体步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="156">(1)利用小波变换将源图像<i>A</i>、<i>B</i>稀疏化,分别得到稀疏矩阵<i><b>A</b></i>、<i><b>B</b></i>。</p>
                </div>
                <div class="p1">
                    <p id="157">(2)为了降低空间复杂度,利用结构随机矩阵对稀疏矩阵<i><b>A</b></i>、<i><b>B</b></i>进行压缩采样,得到测量输出矩阵<i><b>Y</b></i><sub>1</sub>、<i><b>Y</b></i><sub>2</sub>。由于不同场景下图像对应的标准背景图像的<i>MOM</i>不同,所以先根据选取规则自适应选取较小的差异权重对应的<i>MOM</i>作为标准背景图像。然后分别对<i><b>Y</b></i><sub>1</sub>、<i><b>Y</b></i><sub>2</sub>进行分块,得到分块的测量输出矩阵<i><b>Y</b></i><sub>1</sub>{<i>i</i>,<i>j</i>}、<i><b>Y</b></i><sub>2</sub>{<i>i</i>,<i>j</i>}。</p>
                </div>
                <div class="p1">
                    <p id="158">(3)利用<i>ITID</i>算法将分块的<i><b>Y</b></i><sub>1</sub>{<i>i</i>,<i>j</i>}、<i><b>Y</b></i><sub>2</sub>{<i>i</i>,<i>j</i>}进行块融合,得到分块测量输出矩阵<i><b>Y</b></i>{<i>i</i>,<i>j</i>}。</p>
                </div>
                <div class="p1">
                    <p id="159">(4)为了抑制在融合过程中产生的噪声,再利用<i>AWNNM</i>优化块权重,获取完整的有效信息,得到分块测量输出矩阵<mathml id="210"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>^</mo></mover></math></mathml>{<i>i</i>,<i>j</i>}。</p>
                </div>
                <div class="p1">
                    <p id="160">(5)最后利用<i>OMP</i>算法恢复系数矩阵,重构得到融合图像。</p>
                </div>
                <h3 id="161" name="161" class="anchor-tag"><b>4 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="162">图像融合技术广泛应用在民用和军事方面,本文实验针对不同的应用场景建立3组图像融合实验,分别使用医学图像、红外与可见光图像和多聚焦图像。</p>
                </div>
                <div class="p1">
                    <p id="163">图像的大小都是512×512,对测量输出矩阵的分块尺寸是8×8,采样率设置为0.75,实验平台为<i>Matlab</i> 2014<i>a</i>。同时,本文的实验由2部分组成:(1)采用文献<citation id="230" type="reference">[<a class="sup">16</a>]</citation>中基于信息论<i>CS</i>_<i>IT</i>(<i>Information Theory</i>)、主成分分析<i>CS</i>_<i>PCA</i>(<i>Principal Component Analysis</i>)以及高斯梯度<i>CS</i>_<i>GG</i>(<i>Gauss Gradient</i>)的压缩图像融合算法与本文算法进行对比,说明本文算法的时效性;(2)采用基于分块信息论的压缩图像融合算法<i>CS</i>_<i>BIT</i>(<i>Block Information Theory</i>)、基于分块信息论的图像差融合算法<i>CS</i>_<i>ITID</i>(<i>Information Theory Image Difference</i>)和文献<citation id="231" type="reference">[<a class="sup">5</a>]</citation>的基于<i>WNNM</i>的融合算法作为对比实验,说明本文算法的有效性和普适性。</p>
                </div>
                <div class="p1">
                    <p id="164">本文采用信息熵<i>IE</i>(<i>Information Entropy</i>)、均方误差<i>MSE</i>(<i>Mean Square Error</i>)、平均梯度<i>AG</i>(<i>Average Gradient</i>)、互信息<i>MI</i>(<i>Mutual Information</i>)、标准差<i>SD</i>(<i>Standard Deviation</i>)、空间频率<i>SF</i>(<i>Spatial Frequency</i>)和边缘强度<i>Q</i><sup><i>AB</i></sup><sup>/</sup><sup><i>F</i></sup>7种客观评价指标对融合图像的质量进行评价。其中,<i>MSE</i>和<i>SD</i>可以评价图像反差大小,数值越大,表示图像反差越大,可利用的信息越多,融合效果越好;<i>AG</i>反映了融合图像对微小细节反差和纹理变化的表达能力,所以平均梯度值越大,融合图像越清晰;<i>MI</i>可以评价源图像中图像信息的保留情况;<i>SF</i>是用于融合图像空域的总体活跃度的评价;<i>Q</i><sup><i>AB</i></sup><sup>/</sup><sup><i>F</i></sup>则用来评价源图像中边缘信息保留程度。以上几种指标的值越大,表明融合图像越清晰,融合性能越好。</p>
                </div>
                <h4 class="anchor-tag" id="165" name="165"><b>4.1 医学图像融合</b></h4>
                <div class="p1">
                    <p id="166">为了验证本文算法在医学图像融合中的实用性,实验选择正常人的头部<i>CT</i>(<i>Computer Tomography</i>)图像和<i>MRI</i>(<i>Magnetic Resonance Images</i>)图像,如图2<i>a</i>和图2<i>b</i>所示。图2<i>a</i>是<i>MRI</i>医学图像,该图像能够较好地显示软组织及其有关脉络。图2<i>b</i>为<i>CT</i>图像,<i>CT</i>能够对骨骼清晰成像,但是对于软组织成像的对比度能力较低,所以融合2种图像的信息非常重要。使用7种算法对<i>CT</i>图像和<i>MRI</i>图像进行融合处理,效果图如图2<i>c</i>～图2<i>i</i>所示,融合后的图像客观评价如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="167">从图2<i>c</i>～图2<i>i</i>中可以看出,7种算法均可以有效地对2幅图像进行融合。仔细观察图2可以发现:图2<i>c</i>和图2<i>d</i>虽然达到了融合的目的,但是图像亮度低,不利于人眼诊断;图2<i>e</i>～图2<i>h</i>的融合效果相近,但图2<i>i</i>的边缘提取效果更为清晰,并且软组织部分成像对比度明显得到增强。所以,本文提出的基于信息论的图像差与<i>AWNNM</i>相结合的算法在医学图像融合上的视觉效果要优于其他算法的。</p>
                </div>
                <div class="p1">
                    <p id="168">从客观评价指标方面分析,从表1中可以看到:<i>CS</i>_<i>IT</i>和<i>CS</i>_<i>BIT</i>各指标明显低于其他算法的;<i>CS</i>_<i>GG</i>、<i>CS</i>_<i>PCA</i>和<i>CS</i>_<i>ITID</i>的<i>AG</i>低于<i>WNNM</i>的,说明<i>WNNM</i>在提升图像清晰度上有很大优势;但是,本文算法的<i>Q</i><sup><i>AB</i></sup><sup>/</sup><sup><i>F</i></sup>明显最高,说明融合图像的边缘信息保留较为完整。综上分析可以得出,本文算法得到的评价参数最好。</p>
                </div>
                <h4 class="anchor-tag" id="169" name="169"><b>4.2 红外与可见光图像融合</b></h4>
                <div class="p1">
                    <p id="170">红外与可见光图像都存在难以获取目标和场景信息,无法对目标和场景进行分析和识别的问题,综合2种图像可以提高对目标和场景分析的可靠性及系统的空间分辨率、全天候工作能力和抗干扰能力<citation id="232" type="reference"><link href="3" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">1</a>]</sup></citation>。如图3<i>a</i>和图3<i>b</i>为同一场景的红外与可见光图像。从图3<i>c</i>～图3<i>i</i>中可以看出,7种融合算法都能将源图像所提供的信息有效结合起来,充分利用其所提供的信息互补性,达到便于观察的目的。仔细观察图3可以发现:图3<i>c</i>和图3<i>d</i>整体对比度低,造成边缘信息模糊化;图3<i>g</i>明显在融合过程中产生了噪声;图3e、图3f、图3h和图3i的视觉效果比较接近,都很好地融入了源图像中的热目标信息,边缘细节很清楚。但是,图3e、图3f和图3h中房子周围的树木和小坡边缘部分信息不如图3i融合得好,因此图3i的融合图像优于其他6种算法的融合图像。</p>
                </div>
                <div class="area_img" id="171">
                    <p class="img_tit"><b>表1 医学图像融合结果客观评价</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Objective evaluation of medical image fusion results</b></p>
                    <p class="img_note"></p>
                    <table id="171" border="1"><tr><td><br />融合算法</td><td><i>IE</i></td><td><i>MSE</i></td><td><i>AG</i></td><td><i>MI</i></td><td><i>SD</i></td><td><i>SF</i></td><td><i>Q</i><sup><i>AB</i>/<i>F</i></sup></td></tr><tr><td><br />CS_IT<sup>[16]</sup></td><td>4.676 4</td><td>0.032 8</td><td>0.759 7</td><td>1.702 3</td><td>12.185 2</td><td>1.746 6</td><td>0.105 0</td></tr><tr><td><br />CS_BIT</td><td>4.664 1</td><td>0.032 6</td><td>0.753 3</td><td>1.702 7</td><td>12.104 3</td><td>1.731 3</td><td>0.102 6</td></tr><tr><td><br />CS_GG<sup>[16]</sup></td><td>5.535 0</td><td>0.050 6</td><td>1.336 9</td><td>1.706 2</td><td>20.131 2</td><td>2.953 2</td><td>0.239 9</td></tr><tr><td><br />CS_PCA<sup>[16]</sup></td><td>5.296 0</td><td>0.051 8</td><td>1.209 3</td><td>1.704 1</td><td>19.280 4</td><td>2.774 1</td><td>0.262 8</td></tr><tr><td><br />WNNM<sup>[5]</sup></td><td>5.588 4</td><td>0.052 0</td><td>2.013 5</td><td>1.803 4</td><td>19.273 4</td><td>3.817 6</td><td>0.272 5</td></tr><tr><td><br />CS_ITID</td><td>5.561 9</td><td>0.054 5</td><td>1.938 1</td><td>1.817 3</td><td>20.249 8</td><td>3.973 1</td><td>0.282 9</td></tr><tr><td><br />本文算法</td><td><b>5.689 2</b></td><td><b>0.055 8</b></td><td><b>2.024 7</b></td><td><b>1.820 3</b></td><td><b>20.519 2</b></td><td><b>4.003 8</b></td><td><b>0.302 3</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="172">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910011_172.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 医学图像及不同算法融合结果图像" src="Detail/GetImg?filename=images/JSJK201910011_172.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 医学图像及不同算法融合结果图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910011_172.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Medical images and fused 
 images of different algorithms</p>

                </div>
                <div class="area_img" id="173">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910011_173.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 红外与可见光图像及不同算法融合结果图像" src="Detail/GetImg?filename=images/JSJK201910011_173.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 红外与可见光图像及不同算法融合结果图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910011_173.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 Infrared and visible images and 
 fused images of different algorithms</p>

                </div>
                <div class="p1">
                    <p id="175">从表2中可以看出,7种客观评价参数中,本文算法得到的评价参数最优,其中<i>AG</i>、<i>SD</i>、<i>SF</i>和<i>Q</i><sup><i>AB</i></sup><sup>/</sup><sup><i>F</i></sup>的数值明显提高,说明本文算法得到的融合图像含有足够丰富的细节信息,具有更高的清晰度。</p>
                </div>
                <h4 class="anchor-tag" id="176" name="176"><b>4.3 多聚焦图像融合</b></h4>
                <div class="p1">
                    <p id="177">多聚焦图像融合技术能够有效地提高图像信息的利用率和系统对目标探测识别的可靠性,便于人眼的观察和计算机的后续处理<citation id="233" type="reference"><link href="3" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">1</a>]</sup></citation>。如图4所示为不同场景下的多聚焦图像对。</p>
                </div>
                <div class="area_img" id="178">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910011_178.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 多聚焦测试图像对" src="Detail/GetImg?filename=images/JSJK201910011_178.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 多聚焦测试图像对  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910011_178.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 Multi-focus test image pairs</p>

                </div>
                <div class="p1">
                    <p id="179">图5展示了融合后的图像。图5a和图5h为CS_IT的融合结果,图5b和图5i为CS_BIT的融合结果,图5c和图5j为CS_GG的融合结果,图5d和图5k为CS_PCA的融合结果,图5e和图5l为WNNM的融合结果,图5f和图5m为CS_ITID的融合结果,图5g和图5n为本文算法的融合结果。从图5a～图5n可以看出,7种算法都能实现融合图像,得到有效的互补信息。仔细观察融合图像可以发现:CS_IT得到的图5a和图5h的融合图像的亮度低且细节不明显;而CS_BIT算法中引入分块的思想,得到的图5b和图5i在亮度上得到了改善;WNNM和CS_ITID得到的图5e和图5l虽然清晰度都有所提高,但是在融合过程中产生了噪声;CS_GG和CS_PCA得到的图5c和图5j、图5d和图5k中都取得了很好的融合效果,但是本文算法得到的图5g和图5n无论是亮度还是细节部分都明显优于其他算法。</p>
                </div>
                <div class="area_img" id="180">
                    <p class="img_tit"><b>表2 红外与可见光图像融合结果客观评价</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Objective evaluation of fusion results of infrared and visible images</b></p>
                    <p class="img_note"></p>
                    <table id="180" border="1"><tr><td><br />融合算法</td><td><i>IE</i></td><td><i>MSE</i></td><td><i>AG</i></td><td><i>MI</i></td><td><i>SD</i></td><td><i>SF</i></td><td><i>Q</i><sup><i>AB</i>/<i>F</i></sup></td></tr><tr><td><br />CS_IT<sup>[16]</sup></td><td>5.613 3</td><td>0.118 7</td><td>1.521 0</td><td>1.897 1</td><td>14.630 7</td><td>2.766 7</td><td>0.136 3</td></tr><tr><td><br />CS_BIT</td><td>5.622 5</td><td>0.119 2</td><td>1.523 7</td><td>1.896 5</td><td>14.681 7</td><td>2.771 4</td><td>0.137 2</td></tr><tr><td><br />CS_GG<sup>[16]</sup></td><td>6.237 7</td><td>0.183 6</td><td>2.313 2</td><td>1.896 4</td><td>22.368 8</td><td>4.192 9</td><td>0.205 3</td></tr><tr><td><br />CS_PCA<sup>[16]</sup></td><td>6.240 7</td><td>0.183 4</td><td>2.315 2</td><td>1.896 8</td><td>22.518 5</td><td>4.1990</td><td>0.202 8</td></tr><tr><td><br />WNNM<sup>[5]</sup></td><td>6.320 7</td><td>0.184 3</td><td>4.554 3</td><td>1.914 1</td><td>22.359 6</td><td>8.870 3</td><td>0.214 8</td></tr><tr><td><br />CS_ITID</td><td>6.270 4</td><td>0.183 4</td><td>2.959 6</td><td>1.902 4</td><td>22.861 8</td><td>5.366 1</td><td>0.201 5</td></tr><tr><td><br />本文算法</td><td><b>6.375 4</b></td><td><b>0.184 8</b></td><td><b>4.641 9</b></td><td><b>1.9156</b></td><td><b>23.177 6</b></td><td><b>9.247 2</b></td><td><b>0.221 8</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="182">从表3和表4中可以看出,CS_IT和CS_BIT各项指标明显低于其他算法的;CS_GG、CS_PCA和CS_ITID在<i>MSE</i>、<i>AG</i>和<i>SD</i>指标上取得了较好的融合结果,说明融合图像质量总体明显提高;WNNM在<i>SF</i>指标上略高于以上算法的,但是其他指标都较低于其他算法的,说明该算法对于多聚焦图像融合的效果不是很好;CS_ITID在<i>Q</i><sup><i>AB</i></sup><sup>/</sup><sup><i>F</i></sup>指标上取得了很好的融合结果,说明该算法能有效保留多聚焦图像融合的边缘信息;但是,本文算法所得的融合结果在7种指标上均取得了更好的结果,充分说明本文算法既兼顾了2幅不同的聚焦图像信息,又充分保留了两者的空间信息,是多聚焦图像融合中一种有效的算法。</p>
                </div>
                <div class="area_img" id="183">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910011_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 多聚焦图像及不同算法融合结果图像" src="Detail/GetImg?filename=images/JSJK201910011_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 多聚焦图像及不同算法融合结果图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910011_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5 Multi-focus images and fus images of different algorithms</p>

                </div>
                <div class="area_img" id="184">
                    <p class="img_tit"><b>表3 乐百氏多聚焦图像融合结果客观评价</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Robust multi-focus image fusion evaluation results</b></p>
                    <p class="img_note"></p>
                    <table id="184" border="1"><tr><td><br />融合算法</td><td><i>IE</i></td><td><i>MSE</i></td><td><i>AG</i></td><td><i>MI</i></td><td><i>SD</i></td><td><i>SF</i></td><td><i>Q</i><sup><i>AB</i>/<i>F</i></sup></td></tr><tr><td><br />CS_IT<sup>[16]</sup></td><td>6.564 7</td><td>0.142 5</td><td>2.764 7</td><td>1.631 4</td><td>29.983 0</td><td>7.309 9</td><td>0.227 3</td></tr><tr><td><br />CS_BIT</td><td>6.616 7</td><td>0.147 0</td><td>2.817 4</td><td>1.632 6</td><td>30.920 7</td><td>7.484 4</td><td>0.233 8</td></tr><tr><td><br />CS_GG<sup>[16]</sup></td><td>7.116 7</td><td>0.208 9</td><td>4.023 3</td><td>1.633 5</td><td>44.080 5</td><td>10.727 1</td><td>0.358 9</td></tr><tr><td><br />CS_PCA<sup>[16]</sup></td><td>7.117 7</td><td>0.208 0</td><td>4.138 6</td><td>1.628 8</td><td>44.039 5</td><td>11.027 5</td><td>0.411 8</td></tr><tr><td><br />WNNM<sup>[5]</sup></td><td>7.108 8</td><td>0.208 5</td><td>3.763 0</td><td>1.633 4</td><td>43.893 9</td><td>10.731 2</td><td>0.386 7</td></tr><tr><td><br />CS_ITID</td><td>7.122 7</td><td>0.208 8</td><td>4.334 9</td><td>1.632 6</td><td>44.131 2</td><td>11.278 1</td><td>0.428 2</td></tr><tr><td><br />本文算法</td><td><b>7.138 1</b></td><td><b>0.209 0</b></td><td><b>4.340 7</b></td><td><b>1.634 9</b></td><td><b>44.157 3</b></td><td><b>11.287 1</b></td><td><b>0.458 3</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="185">
                    <p class="img_tit"><b>表4 Lab多聚焦图像融合结果客观评价</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Objective evaluation of Lab multi-focus image fusion results</b></p>
                    <p class="img_note"></p>
                    <table id="185" border="1"><tr><td><br />融合算法</td><td><i>IE</i></td><td><i>MSE</i></td><td><i>AG</i></td><td><i>MI</i></td><td><i>SD</i></td><td><i>SF</i></td><td><i>Q</i><sup><i>AB</i>/<i>F</i></sup></td></tr><tr><td><br />CS_IT<sup>[16]</sup></td><td>6.496 9</td><td>0.171 7</td><td>2.269 7</td><td>1.613 5</td><td>30.449 0</td><td>5.334 2</td><td>0.281 1</td></tr><tr><td><br />CS_BIT</td><td>6.538 2</td><td>0.177 9</td><td>2.310 7</td><td>1.607 0</td><td>31.519 0</td><td>5.514 7</td><td>0.297 9</td></tr><tr><td><br />CS_GG<sup>[16]</sup></td><td>7.067 6</td><td>0.256 0</td><td>3.319 9</td><td>1.607 7</td><td>45.401 5</td><td>7.910 0</td><td>0.435 5</td></tr><tr><td><br />CS_PCA<sup>[16]</sup></td><td>7.082 7</td><td>0.253 2</td><td>3.383 7</td><td>1.611 7</td><td>45.509 6</td><td>8.087 4</td><td>0.436 3</td></tr><tr><td><br />WNNM<sup>[5]</sup></td><td>7.066 1</td><td>0.255 9</td><td>3.313 6</td><td>1.606 8</td><td>45.407 3</td><td>7.921 1</td><td>0.403 7</td></tr><tr><td><br />CS_ITID</td><td>7.078 9</td><td>0.254 2</td><td>3.322 7</td><td>1.612 6</td><td>45.489 4</td><td>8.258 6</td><td>0.455 8</td></tr><tr><td><br />本文算法</td><td><b>7.083 1</b></td><td><b>0.256 0</b></td><td><b>3.508 7</b></td><td><b>1.614 3</b></td><td><b>45.527 3</b></td><td><b>8.291 5</b></td><td><b>0.457 0</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="186" name="186" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="187">为了解决图像融合中非线性操作产生的噪声干扰和空间复杂度高,导致融合图像质量降低的问题,本文提出基于信息论的图像差与自适应加权核范数最小化的图像融合算法,将源图像矩阵稀疏化,利用结构随机矩阵进行压缩采样,得到测量输出矩阵。对测量输出矩阵分块利用图像差融合算法得到融合后的测量输出矩阵块,再通过自适应加权核范数最小化优化块权重,最后用正交匹配追踪法重建得到融合图像。该算法在保持融合质量的同时可抑制噪声干扰和降低空间复杂度,而且可以应用在不同的融合场景中。实验结果表明,本文算法相比现有的其他融合算法具有更好的性能。然而,基于CS的融合算法仍需进一步深入研究。一方面,在压缩采样阶段对测量矩阵的设计目的是进一步提升测量输出矩阵的稳定性和可靠性。另一方面,在压缩感知的重建阶段需要进一步改进,主要是提高计算效率和重建准确度。因此,我们今后的工作集中在测量矩阵的设计和重构方面。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analysis and application of algorithm for digital image fusion">

                                <b>[1]</b> Liu Shuai-qi,Zheng Wei,Zhao Jie,et al.Analysis and application of algorithm for digital image fusion[M].Beijing:China Machine Press,2018.(in Chinese)
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH200703013&amp;v=MzA3Mjc0SHRiTXJJOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVmIzSkxUclNackc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Liu Sheng-peng,Fang Yong.Infrared image fusion algorithm based on contourlet transform and improved pulse coupled neural network[J].Journal of Infrared and Millimeter Waves,2007,26(3):217-221.(in Chinese)
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 Qu Xiao-bo,Yan Jing-wen,Yang Gui-de.Multifocus image fusion method of sharp frequency localized contourlet transform domain based on sum-modified-laplacian[J].Optics and Precision Engineering,2009,17(5):1203-1212.(in Chinese)
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYJX201403044&amp;v=MjYwMTh0R0ZyQ1VSTE9lWmVSbUZ5L2dWYjNKS3pUQmRyRzRIOVhNckk5QllJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Gao Guo-rong,Liu Yan-ping.Infrared and visible light images fusion algorithm based on non-subsampled shearlet transform[J].Transactions of the Chinese Society for Agricultural Machinery,2014,45(3):268-274.(in Chinese)
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD15112400000101&amp;v=MzA0MjY0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKMXNTYUJNPU5pZmNhcks5SDlET3E0OUZaT3NQRFh3NG9CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Liu S Q,Zhang T,Li H L,et al.Medical image fusion based on nuclear norm minimization[J].International Journal of Imaging Systems and Technology,2015,25(4):310-316.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 Ma Min,Zhang Cai-xia,Lu Cheng-chao,et al.ECT image processing based on wavelet transform[J].Journal of Central South University (Science and Technology),2016,47(6):1947-1952.(in Chinese)
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 Zhou Qiang,Zhao Ju-feng,Feng Hua-jun,et al.Infrared polarization image fusion with non-sampling shearlets[J].Journal of Zhejiang University (Engineering Science),2014,48(8):1508-1516.(in Chinese)
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 Li Jiao,Yang Yan-chun,Dang Jian-wu,et al.NSST and guided filtering for multi-focus image fusion algorithm[J].Journal of Harbin Institute of Technology,2018,50(11):145-152.(in Chinese)
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM201607025&amp;v=MjI0NzMzenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiM0pJalhCWTdHNEg5Zk1xSTlIWVlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Wang Xin,Ji Tong-bo,Liu Fu.Fusion of infrared and visible images based on target segmentation and compressed sensing[J].Optics and Precision Engineering,2016,24(7):1743-1753.(in Chinese)
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image fusion in compressed sensing">

                                <b>[10]</b> Luo X Y,Zhang J,Yang J Y,et al.Image fusion in compressed sensing[C]//Proc of the 16th International Conference on Image Processing,2009:2181-2184.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi image fusion based on compressivesensing">

                                <b>[11]</b> Han J J,Loffeld O,Hartmann K,et al.Multi image fusion based on compressive sensing[C]//Proc of International Conference on Audio Language and Image Processing,2010:1463-1469.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient fusion for infrared and visible images based on compressive sensing principle">

                                <b>[12]</b> Li X,Qin S Y.Efficient fusion for infrared and visible images based on compressive sensing principle[J].IET Image Processing,2011,5(2):141-147.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD120604084149&amp;v=MjAyNjduS3JpZlp1OXVGQ3Z0VTdqTkpsd1ZOam5CYXJLNkh0Zk1xNDlOWU9vTEJSTTh6eFVTbURkOVNIN24zeEU5ZmJ2&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Wan T,Qin Z C.An application of compressive sensing for image fusion[J].International Journal of Computer Mathematics,2011,88(18):3915-3930.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multimodal image fusion with joint sparsity model">

                                <b>[14]</b> Yin H T,Li S T.Multimodal image fusion with joint sparsity model[J].Optical Engineering,2011,50(6):067007-10.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300328956&amp;v=MjExNTZIdEROckk5Rlora0hCWGsvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSjFzU2FCTT1OaWZPZmJLNw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Yang B,Li S T.Pixel-level image fusion with simultaneous orthogonal matching pursuit[J].Information Fusion,2012,13(1):10-19.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZUS201503005&amp;v=MDg5MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYjNKTHpmZWZiRzRIOVRNckk5RllZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Chen Yang,Qin Zheng.Gradient-based compressive image fusion[J].Frontiers of Information Technology &amp; Electronic Engineering,2015,16(3):227-237.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast and Efficient Compressive Sensing Using Structurally Random Matrices">

                                <b>[17]</b> Do T T,Gan L,Nguyen N H,et al.Fast and efficient compressive sensing using structurally random matrices[J].IEEE Transactions on Signal Processing,2012,60(1):139-154.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES028DF5285FE77B315CD59B9F0A5B79A4&amp;v=MDcyNDBhQnVIWWZPR1FsZkNwYlEzNU5CaHc3MjV3cWs9TmlmT2ZiTzZGcVc2cW8xTllaMTZDM3RMekJjV21VdDRRUTNyMmhKRWZNQ1RUTXViQ09OdkZTaVdXcjdKSUZwbQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Nirmala P,Kishore R.Infrared and visible image fusion using discrete cosine transform and swarm intelligence for surveillance applications[J].Infrared Physics &amp; Technology,2018,88:13-22.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787111593027000&amp;v=MTc2MzJTSDduM3hFOWZidm5LcmlmWnU5dUZDdnRVN2pOSmx3VlhGcXpHYks1SDlURnJJOUhZK3NQREJNOHp4VVNtRGQ5&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 刘帅奇,郑伟,赵杰,等.数字图像融合算法分析与应用[M].北京:机械工业出版社,2018.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 刘盛鹏,方勇.基于Contourlet变换和IPCNN的融合算法及其在可见光与红外线图像融合中的应用[J].红外与毫米波学报,2007,26(3):217-221.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJM200905041&amp;v=MjEyOTZWYjNKSWpYQlk3RzRIdGpNcW85QlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2c=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 屈小波,闫敬文,杨贵德.改进拉普拉斯能量和的尖锐频率局部化Contourlet域多聚焦图像融合方法[J].光学精密工程,2009,17(5):1203-1212.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_4" >
                                    <b>[4]</b>
                                 高国荣,刘艳萍.基于非抽样Shearlet变换的红外与可见光图像融合方法[J].农业机械学报,2014,45(3):268-274.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZNGD201606017&amp;v=MzEzMzc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYjNKUHlQTWFyRzRIOWZNcVk5RVk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 马敏,张彩霞,陆成超,等.基于小波变换的ECT图像处理[J].中南大学学报(自然科学版),2016,47(6):1947-1952.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201408027&amp;v=MDM4MjhaZVJtRnkvZ1ZiM0pQeW5SYmJHNEg5WE1wNDlIWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 周强,赵巨峰,冯华君,等.非下采样剪切波的红外偏振图像融合[J].浙江大学学报(工学版),2014,48(8):1508-1516.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201811021&amp;v=Mjg4MzE0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVmIzSkxTakpkckc0SDluTnJvOUhaWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 李娇,杨艳春,党建武,等.NSST与引导滤波相结合的多聚焦图像融合算法[J].哈尔滨工业大学学报,2018,50(11):145-152.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 王昕,吉桐伯,刘富.结合目标提取和压缩感知的红外与可见光图像融合[J].光学精密工程,2016,24(7):1743-1753.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201910011" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201910011&amp;v=Mjg0NzZxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiM0pMejdCWmJHNEg5ak5yNDlFWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
