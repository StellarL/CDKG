<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132348746592500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201910017%26RESULT%3d1%26SIGN%3d2njFlvFwjK6W5xeC9sNNM5hAZ1o%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201910017&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201910017&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201910017&amp;v=Mjg0MTR6cXFCdEdGckNVUkxPZVplUm1GeS9nVmJ2Tkx6N0JaYkc0SDlqTnI0OUVZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#65" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#72" data-title="&lt;b&gt;2 改进的图模型&lt;/b&gt; "><b>2 改进的图模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="&lt;b&gt;2.1 全局领域信息&lt;/b&gt;"><b>2.1 全局领域信息</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;2.2 短期记忆因子&lt;/b&gt;"><b>2.2 短期记忆因子</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#108" data-title="&lt;b&gt;3 实验结果分析&lt;/b&gt; "><b>3 实验结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#112" data-title="&lt;b&gt;3.1 评价标准&lt;/b&gt;"><b>3.1 评价标准</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;3.2 STMF中&lt;/b&gt;&lt;i&gt;&lt;b&gt;φ&lt;/b&gt;&lt;/i&gt;&lt;b&gt;值的变化&lt;/b&gt;"><b>3.2 STMF中</b><i><b>φ</b></i><b>值的变化</b></a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;3.3 实验结果&lt;/b&gt;"><b>3.3 实验结果</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;3.4 讨论&lt;/b&gt;"><b>3.4 讨论</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#133" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="图1 GSGS模型的结构">图1 GSGS模型的结构</a></li>
                                                <li><a href="#77" data-title="图2 词袋的更新">图2 词袋的更新</a></li>
                                                <li><a href="#100" data-title="图3 短期记忆的更新机制">图3 短期记忆的更新机制</a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;表1 对比算法列表&lt;/b&gt;"><b>表1 对比算法列表</b></a></li>
                                                <li><a href="#116" data-title="图4 &lt;i&gt;φ&lt;/i&gt;值和&lt;i&gt;F&lt;/i&gt;值的关系(&lt;i&gt;φ&lt;/i&gt;∈(0,100))">图4 <i>φ</i>值和<i>F</i>值的关系(<i>φ</i>∈(0,100))</a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;表2 GSGS与原基于图的算法的实验对比结果&lt;/b&gt;"><b>表2 GSGS与原基于图的算法的实验对比结果</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;表3 GSGS和其他消歧算法的实验对比结果&lt;/b&gt;"><b>表3 GSGS和其他消歧算法的实验对比结果</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;表4 STMF对离散型消歧错误的纠错&lt;/b&gt;"><b>表4 STMF对离散型消歧错误的纠错</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;表5 STMF对特殊类型错误的放大&lt;/b&gt;"><b>表5 STMF对特殊类型错误的放大</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Navigli R.Word sense disambiguation:A survey[J].ACM Computing Surveys,2009,41(2):1-69." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000017690&amp;v=MDY3NzBkR2VycVFUTW53WmVadUh5am1VTGZJSjFzU2JoWT1OaWZJWTdLN0h0ak5yNDlGWk9vSUNuVTVvQk1UNlQ0UFFIL2lyUg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Navigli R.Word sense disambiguation:A survey[J].ACM Computing Surveys,2009,41(2):1-69.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Chen Zhao-xiong,Gao Qing-shi.Natural language processing[J].Journal of Computer Research and Development,1989(11):1-16.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ198911000&amp;v=Mjg3NTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVmJ2TUx5dlNkTEt4RnRqTnJvOUZaSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Chen Zhao-xiong,Gao Qing-shi.Natural language processing[J].Journal of Computer Research and Development,1989(11):1-16.(in Chinese)
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Carpuat M,Wu D.Improving statistical machine translation using word sense disambiguation[C]//Proc of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,2007:61-72." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving Statistical Machine Translation using Word Sense Disambiguation">
                                        <b>[3]</b>
                                         Carpuat M,Wu D.Improving statistical machine translation using word sense disambiguation[C]//Proc of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,2007:61-72.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Locke W N,Booth A D.Machine translation of languages[J].Physics Today,1956,9(2):16." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Machine translation of languages">
                                        <b>[4]</b>
                                         Locke W N,Booth A D.Machine translation of languages[J].Physics Today,1956,9(2):16.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Nebhi K.Named entity disambiguation using freebase and syntactic parsing[C]//Proc of International Conference on Linked Data for Information Extraction,2013:50-55." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Named entity disambiguation using freebase and syntactic parsing">
                                        <b>[5]</b>
                                         Nebhi K.Named entity disambiguation using freebase and syntactic parsing[C]//Proc of International Conference on Linked Data for Information Extraction,2013:50-55.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Warren W.Translation[M]//Machine Translation of Languages:Fourteen Essays.Cambridge,MA:MIT Press,1949." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Translation">
                                        <b>[6]</b>
                                         Warren W.Translation[M]//Machine Translation of Languages:Fourteen Essays.Cambridge,MA:MIT Press,1949.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Chan Y S,Ng H T,Chiang D.Word sense disambiguation improves statistical machine translation[C]//Proc of the Meeting of the Association for Computational Linguistics (ACL 2007),2007:33-40." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Word sense disambiguation improves statistical machine translation">
                                        <b>[7]</b>
                                         Chan Y S,Ng H T,Chiang D.Word sense disambiguation improves statistical machine translation[C]//Proc of the Meeting of the Association for Computational Linguistics (ACL 2007),2007:33-40.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Cai J F,Lee W S,Teh Y W,NUS-ML:Improving word sense disambiguation using topic features[C]//Proc of the 4th International Workshop on Semantic Evaluations,Association for Computational Linguistics,2007:249-252." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=NUS-ML:Improving word sense disambiguation using topic features">
                                        <b>[8]</b>
                                         Cai J F,Lee W S,Teh Y W,NUS-ML:Improving word sense disambiguation using topic features[C]//Proc of the 4th International Workshop on Semantic Evaluations,Association for Computational Linguistics,2007:249-252.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Jimeno Y A.Word embeddings and recurrent neural networks based on long-short term memory nodes in supervised biomedical word sense disambiguation[J].Journal of Biomedical Informatics,2017,73:137-147." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDC7501CC6DD99C39528E5A4F92EDC3B5&amp;v=MTMzOTg3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3MjV4S3c9TmlmT2ZjZkxHZFRNcnZ3MllwOTdCWFZLekI4VzZEY0lUUTdtMmhzM0RNYm5Sc2lhQ09OdkZTaVdXcg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Jimeno Y A.Word embeddings and recurrent neural networks based on long-short term memory nodes in supervised biomedical word sense disambiguation[J].Journal of Biomedical Informatics,2017,73:137-147.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Hausman M.A genetic algorithm using semantic relations for word sense disambiguation[D].Colorado:University of Colorado,2011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A genetic algorithm using semantic relations for word sense disambiguation">
                                        <b>[10]</b>
                                         Hausman M.A genetic algorithm using semantic relations for word sense disambiguation[D].Colorado:University of Colorado,2011.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Schwab D,Guillaume N.A global ant colony algorithm for word sense disambiguation based on semantic relatedness[C]//Proc of the 9th International Conference on Practical Applications of Agents and Multiagent Systems,2011:257-264." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A global ant colony algorithm for word sense disambiguation based on semantic relatedness">
                                        <b>[11]</b>
                                         Schwab D,Guillaume N.A global ant colony algorithm for word sense disambiguation based on semantic relatedness[C]//Proc of the 9th International Conference on Practical Applications of Agents and Multiagent Systems,2011:257-264.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Novischi A,Srikanth M,Bennett A.LCC-WSD:System description for English coarse grained all words task at semeval 2007[C]//Proc of the 4th International Workshop on Semantic Evaluations,Association for Computational Linguistics,2007:223-226." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LCC-WSD:System description for English coarse grained all words task at semeval 2007">
                                        <b>[12]</b>
                                         Novischi A,Srikanth M,Bennett A.LCC-WSD:System description for English coarse grained all words task at semeval 2007[C]//Proc of the 4th International Workshop on Semantic Evaluations,Association for Computational Linguistics,2007:223-226.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Miller G.WordNet:An on-line lexical database[J].International Journal of Lexicography,1990,3(4):235-244." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=WordNet: An On-Line Lexical Database">
                                        <b>[13]</b>
                                         Miller G.WordNet:An on-line lexical database[J].International Journal of Lexicography,1990,3(4):235-244.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Miller G,Leacock C,Tengi R,et al.A semantic concordance[C]//Proc of the Workshop on Human Language Technology,1993:303-308." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Semantic Concordance">
                                        <b>[14]</b>
                                         Miller G,Leacock C,Tengi R,et al.A semantic concordance[C]//Proc of the Workshop on Human Language Technology,1993:303-308.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Izquierdo R,Su&#225;rez A,Rigau G.GPLSI:Word coarse-grained disambiguation aided by basic level concepts[C]//Proc of the 4th International Workshop on Semantic Evaluations,2007:157-160." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=GPLSI:Word coarse-grained disambiguation aided by basic level concepts">
                                        <b>[15]</b>
                                         Izquierdo R,Su&#225;rez A,Rigau G.GPLSI:Word coarse-grained disambiguation aided by basic level concepts[C]//Proc of the 4th International Workshop on Semantic Evaluations,2007:157-160.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Alsaeedan W,Menai M E B.A novel genetic algorithm for the word sense disambiguation problem[C]//Proc of the 29th Canadian Conference on Advances in Artificial Intelligence,Lecture Notes in Computer Science,2016:162-167." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel genetic algorithm for the word sense disambiguation problem">
                                        <b>[16]</b>
                                         Alsaeedan W,Menai M E B.A novel genetic algorithm for the word sense disambiguation problem[C]//Proc of the 29th Canadian Conference on Advances in Artificial Intelligence,Lecture Notes in Computer Science,2016:162-167.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Schwab D,Goulian J,Tchechmedjiev A,et al.Ant colony algorithm for the unsupervised word sense disambiguation of texts:Comparison and evaluation[C]//Proc of the 25th International Conference on Computational Linguistics (COLING 2012),2012:2389-2404." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ant colony algorithm for the unsupervised word sense disambiguation of texts:Comparison and evaluation">
                                        <b>[17]</b>
                                         Schwab D,Goulian J,Tchechmedjiev A,et al.Ant colony algorithm for the unsupervised word sense disambiguation of texts:Comparison and evaluation[C]//Proc of the 25th International Conference on Computational Linguistics (COLING 2012),2012:2389-2404.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Nguyen K H,Ock C Y.Word sense disambiguation as a traveling salesman problem[J].Artificial Intelligence Review,2013,40(4):405-427." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13120400000535&amp;v=Mjc2NDlycVFUTW53WmVadUh5am1VTGZJSjFzU2JoWT1OajdCYXJLN0g5UE1xNDlGWk9zUENYODhvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Nguyen K H,Ock C Y.Word sense disambiguation as a traveling salesman problem[J].Artificial Intelligence Review,2013,40(4):405-427.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Widdows D,Dorow B.A graph model for unsupervised lexical acquisition[C]//Proc of International Conference on Computational Linguistics,2002:1093-1099." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A graph model for unsupervised lexical acquisition">
                                        <b>[19]</b>
                                         Widdows D,Dorow B.A graph model for unsupervised lexical acquisition[C]//Proc of International Conference on Computational Linguistics,2002:1093-1099.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Navigli R,Velardi P.Structural semantic interconnections:A knowledge-based approach to word sense disambiguation[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence,2005,27(7):1075-1086." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Structural Semantic Interconnections: A Knowledge-Based Approach to Word Sense Disambiguation">
                                        <b>[20]</b>
                                         Navigli R,Velardi P.Structural semantic interconnections:A knowledge-based approach to word sense disambiguation[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence,2005,27(7):1075-1086.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" Navigli R,Ponzetto S P.BabelNet:The automatic construction,evaluation and application of a wide-coverage multilingual semantic network[J].Artificial Intelligence,2012,193(6):217-250." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702005980&amp;v=MzE3MzdlWnVIeWptVUxmSUoxc1NiaFk9TmlmT2ZiSzdIdEROcUk5SFpPc0tCWFE1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         Navigli R,Ponzetto S P.BabelNet:The automatic construction,evaluation and application of a wide-coverage multilingual semantic network[J].Artificial Intelligence,2012,193(6):217-250.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" Corr&#234;a E A,Lopes A A,Amancio D R.Word sense disambiguation:A complex network approach[J].Information Sciences,2018,442:103-113." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7388C0C1C5DD4947B2BDE95691A410EA&amp;v=MDg1MzVHUWxmQ3BiUTM1TkJodzcyNXhLdz1OaWZPZmJTN0Z0bS9yL3hFRis1N2VIZ3d5eEZoNkUwSlBYYm5xaHMwQ0xhVlJjL3VDT052RlNpV1dyN0pJRnBtYUJ1SFlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         Corr&#234;a E A,Lopes A A,Amancio D R.Word sense disambiguation:A complex network approach[J].Information Sciences,2018,442:103-113.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" Alsaeedan W,Menai M E B,Al-Ahmadi S.A hybrid genetic-ant colony optimization algorithm for the word sense disambiguation problem[J].Information Sciences,2017,417:20-38." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8F1FE166DD9BE8AF803676073F1E9822&amp;v=MDA3MzNLdz1OaWZPZmJ2T0g2ZTVyb2xERUo4R2Zna3h2bUFiNmp4N1QzbmlxeEZEZU1lZFRiaWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3NzI1eA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         Alsaeedan W,Menai M E B,Al-Ahmadi S.A hybrid genetic-ant colony optimization algorithm for the word sense disambiguation problem[J].Information Sciences,2017,417:20-38.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" Magnini B,Cavagli&#224; G.Integrating subject field codes into WordNet[C]//Proc of Conference on LREC,2004:1413-1418." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Integrating subject field codes into WordNet">
                                        <b>[24]</b>
                                         Magnini B,Cavagli&#224; G.Integrating subject field codes into WordNet[C]//Proc of Conference on LREC,2004:1413-1418.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" Magnini B,Strapparava C,Pezzulo G,et al.The role of domain information in word sense disambiguation[J].Natural Language Engineering,2002,8(4):359-373." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The role of domain information in Word Sense Disambiguation">
                                        <b>[25]</b>
                                         Magnini B,Strapparava C,Pezzulo G,et al.The role of domain information in word sense disambiguation[J].Natural Language Engineering,2002,8(4):359-373.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" Huang E H,Socher R,Manning C D,et al.Improving word representations via global context and multiple word prototypes[C]//Proc of Meeting of the Association for Computational Linguistics:Long Papers,2012:873-882." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving word representations via global context and multiple word prototypes">
                                        <b>[26]</b>
                                         Huang E H,Socher R,Manning C D,et al.Improving word representations via global context and multiple word prototypes[C]//Proc of Meeting of the Association for Computational Linguistics:Long Papers,2012:873-882.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" >
                                        <b>[27]</b>
                                     Miller G.The magical number seven,plus or minus two:Some limits on our capacity for processing information[J].Psychological Review,1956,63:311-329.</a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_28" title=" Simon H A.How big is a chunk?[J].Science,1974,183(4124):482-488." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=How big is a chunk">
                                        <b>[28]</b>
                                         Simon H A.How big is a chunk?[J].Science,1974,183(4124):482-488.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_29" title=" Kitamura T,Ogawa S K,Roy S,et al.Engrams and circuits crucial for systems consolidation of a memory[J].Science,2017,356(6333):73-78." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRS1B0D108778E30010E92B1FBF38F3B0C7&amp;v=MTM1OTdsZkNwYlEzNU5CaHc3MjV4S3c9TmlmWmZiTEtIcVhOcjRkQ1krTjZEM3c1emhabTR6MFBTUW1RMmhFOUQ3SG1SY21ZQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[29]</b>
                                         Kitamura T,Ogawa S K,Roy S,et al.Engrams and circuits crucial for systems consolidation of a memory[J].Science,2017,356(6333):73-78.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_30" title=" Hargraves O.SemEval-2007 task 07:Coarse-grained English all-words task[C]//Proc of International Workshop on Semantic Evaluations,2007:30-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SemEval-2007Task07:Coarse-Grained English All-Words Task">
                                        <b>[30]</b>
                                         Hargraves O.SemEval-2007 task 07:Coarse-grained English all-words task[C]//Proc of International Workshop on Semantic Evaluations,2007:30-35.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     陈肇雄,高庆狮.自然语言处理[J].计算机研究与发展,1989(11):1-16.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(10),1829-1836 DOI:10.3969/j.issn.1007-130X.2019.10.016            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于全局领域和短期记忆因子的图模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B5%E7%8E%89%E6%B6%B5&amp;code=37987956&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邵玉涵</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%9F%B9%E5%9F%B9&amp;code=15118419&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李培培</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E5%AD%A6%E9%92%A2&amp;code=05971937&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡学钢</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%88%E8%82%A5%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0083575&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">合肥工业大学计算机与信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>词义消歧是一项具有挑战性的自然语言处理难题。作为词义消歧中的一种优秀的半监督消歧算法,遗传蚁群词义消歧算法能快速进行全文词义消歧。该算法采用了一种局部上下文的图模型来表示语义关系,以此进行词义消歧。然而,在消歧过程中却丢失了全局语义信息,出现了消歧结果冲突的问题,导致算法精度降低。因此,提出了一种基于全局领域和短期记忆因子改进的图模型来表示语义以解决这个问题。该图模型引入了全局领域信息,增强了图对全局语义信息的处理能力。同时根据人的短期记忆原理,在模型中引入了短期记忆因子,增强了语义间的线性关系,避免了消歧结果冲突对词义消歧的影响。大量实验结果表明:与经典词义消歧算法相比,所提的改进图模型提高了词义消歧的精度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%8D%E4%B9%89%E6%B6%88%E6%AD%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">词义消歧;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8A%E7%9B%91%E7%9D%A3%E6%B6%88%E6%AD%A7%E6%96%B9%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">半监督消歧方法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">短期记忆模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%A8%E5%B1%80%E9%A2%86%E5%9F%9F%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">全局领域信息;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    邵玉涵（1994-），男，江苏如皋人，硕士生，研究方向为数据挖掘和知识工程。E-mail:yuhan_shao@yeah.net，通信地址:230601安徽省合肥市合肥工业大学计算机与信息学院&lt;image id="177" type="formula" href="images/JSJK201910017_17700.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    邵玉涵（1994-），男，江苏如皋人，硕士生，研究方向为数据挖掘和知识工程。E-mail:yuhan_shao@yeah.net，通信地址:230601安徽省合肥市合肥工业大学计算机与信息学院&lt;image id="179" type="formula" href="images/JSJK201910017_17900.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    胡学钢（1961-），男，安徽当涂人，博士，教授，研究方向为数据挖掘和知识工程。E-mail:jsjxhuxg@hfut.edu.cn，通信地址:230601安徽省合肥市合肥工业大学计算机与信息学院&lt;image id="181" type="formula" href="images/JSJK201910017_18100.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61673152);</span>
                    </p>
            </div>
                    <h1><b>A graph model based on global domain and short-term memory factor</b></h1>
                    <h2>
                    <span>SHAO Yu-han</span>
                    <span>LI Pei-pei</span>
                    <span>HU Xue-gang</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Information Engineering,Hefei University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Word sense disambiguation(WSD) is a challenging problem in natural language processing. As an excellent semi-supervised disambiguation algorithm in WSD, the genetic max-minant system word sense disambiguation(GMMSWSD) can perform full-text WSD quickly. The algorithm uses a graph based on local context to represent semantic relationships for word sense disambiguation. However, in the process of disambiguation, global semantic information is lost and inconsistent disambiguation results occur, which leads to lower accuracy of the algorithm. We therefore propose an improved graph model based on global domain and short-term memory factor to solve the abovementioned problems. The new graph model introduces global domain information to enhance the processing ability of global semantic information. At the same time, according to the principle of short-term memory, we introduce the short-term memory factor into the model, which can enhance the linear relationship between semantics and avoid the influence of inconsistent disambiguation results on word sense disambiguation. Experimental results show that compared with the classical word sense disambiguation algorithm, the proposal's precision of word sense disambiguation is improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=word%20sense%20disambiguation(WSD)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">word sense disambiguation(WSD);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=semi-supervised%20disambiguation%20method&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">semi-supervised disambiguation method;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=short-term%20memory%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">short-term memory model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=global%20domain%20information&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">global domain information;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    SHAO Yu-han,born in 1994,MS candidate,his research interests include data mining,and knowledge engineering.Address:School of Computer Science and Information Engineering,Hefei University of Technology,Hefei 230601,Anhui,P.R.China;
                                </span>
                                <span>
                                    LI Pei-pei,born in 1982,PhD,associate research fellow,her research interests include data mining,and knowledge engineering.Address:School of Computer Science and Information Engineering,Hefei University of Technology,Hefei 230601,Anhui,P.R.China;
                                </span>
                                <span>
                                    HU Xue-gang,born in 1961,PhD,professor,his research interests include data mining,and knowledge engineering.Address:School of Computer Science and Information Engineering,Hefei University of Technology,Hefei 230601,Anhui,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-15</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="65" name="65" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="66">词义消歧WSD(Word Sense Disambiguation)<citation id="141" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>是自然语言处理中最常见的挑战之一<citation id="142" type="reference"><link href="5" rel="bibliography" /><link href="63" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">2</a>]</sup></citation>。机器翻译<citation id="143" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、情感分析<citation id="144" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、信息提取<citation id="145" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等自然语言的应用都存在歧义词语的问题。比如在理解“The bat isn't a bird.”“My cricket bat has sprung.”这2句话时,辨析bat的含义就直接影响到对整个语句的理解。类似的歧义词语在人类语言中大量存在<citation id="146" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,给自然语言处理带来了挑战。在语境下获得歧义词语的准确词义就是词义消歧的任务。</p>
                </div>
                <div class="p1">
                    <p id="67">自1949年Warren首次提出词义消歧<citation id="147" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>以来,词义消歧方法主要分为有监督的、无监督的和半监督的3类。</p>
                </div>
                <div class="p1">
                    <p id="68">有监督的词义消歧方法基于已标注数据,采用分类器训练模型进行语义消歧。主要的研究成果包括:Chan等<citation id="148" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>利用英汉平行语料库来训练支持向量机SVM(Support Vector Machines)分类器;Cai等<citation id="149" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>结合WordNet知识库中所有的语义特征来改进NaiveBayes分类器;Jimeno<citation id="150" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>基于长短期记忆神经网络模型针对医疗文本进行词义消歧。极度依赖知识是词义消歧的重要特征,因此有监督的词义消歧方法的精度一般高于无监督的和半监督的方法,然而此类方法要求有大量已标注数据集,导致有监督的消歧方法一般只能处理目标词消歧任务。</p>
                </div>
                <div class="p1">
                    <p id="69">无监督的词义消歧方法无需标注数据,利用既定的语义规则进行消歧。如:Hausman<sup></sup><citation id="151" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>运用领域信息等多种语义特征结合遗传算法解决词义歧义问题;Schwab等<sup></sup><citation id="152" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>用树型结构和蚁群算法来解决词义消歧问题;Novischi等<citation id="153" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>利用机器学习算法处理具有关联关系的数据集来完成消歧任务。这些无监督的消歧方法弥补了有监督消歧方法对人工标注的依赖,但是由于词义消歧任务对知识的依赖,导致无监督的消歧方法精度普遍低于有监督的消歧方法的。</p>
                </div>
                <div class="p1">
                    <p id="70">而半监督语义消歧方法(又常称为基于知识的消歧方法)既能利用已有的知识库来改善消歧结果,又能降低人工标注的任务量,提高词义消歧的效率,因此在全文词义消歧任务中较为常见<citation id="154" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。这类方法主要利用已有的知识库,例如WordNet<citation id="155" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、SemCor<citation id="156" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>等协助进行语义消歧,利用SVM<citation id="157" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、遗传算法<citation id="158" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、蚁群算法<citation id="163" type="reference"><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>等技术进行消歧。其中基于图模型的语义消歧最为流行,主要研究成果包括:2002年,Widdows等<citation id="159" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>首次提出了基于图模型的词义消歧方法。他们提出用词语表示节点,词语的共现次数代表边的图模型来表示语义关系。利用图模型结构和马尔科夫聚类算法,较好地完成了词义消歧任务。然而,这种图模型只是记录了简单的统计数据,并不能较好地表达词语之间的语义关系。为了提高图模型对语义信息的表达能力,Navigli等<citation id="160" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>构建了一种结构化的图模型:将WordNet中的词语作为图的节点,将其中的上位词关系、下位词关系、注释关系等10类关系进行结构化。2012年,Navigli等<citation id="161" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>将Wikipedia和WordNet的语义知识结合,通过Dice系数构造了一个结合了WordNet语义和Wikipedia页面信息的语义地图BabelNet。Navigli等<citation id="162" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>让图模型更好地记录语义信息,使已标注语料更好地参与到词义消歧任务当中。这一类图模型大规模地记录了语义信息,大大提高了半监督消歧方法的精度,让全文词义消歧的精确度得到了保证。</p>
                </div>
                <div class="p1">
                    <p id="71">消歧算法中常利用一些语义模型来有效利用语义信息,在基于图的词义消歧算法中常用图模型来表示语义。相比于直接在文本结构中进行消歧,图模型结构能更好地记录词语之间的语义关系,如WordNet等经典的词语知识库也采取了图模型,因此,图(网)模型在词义消歧任务中被广泛使用<citation id="164" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。然而利用自然语言构建全词语的图模型是一项工作量庞大的任务。2017年,Alsaeedam等<citation id="165" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>在遗传蚁群算法中运用了一种表示局部语义的图模型,降低了图模型在表示语义上的构建成本,并运用在遗传蚁群词义消歧算法GMMASWSD(Genetic Max-Min Ant System Word Sense Disambiguation)中。GMMASWSD算法采用一定窗口大小内的局部上下文来构造图模型。在构建图模型时,词语的不同释义为节点,利用注释和领域信息来构建边,很好地表示了词语释义之间的数学关系。算法中不需要构建包含全词语的图模型,只要针对窗口内的词语即可,降低了图模型在词义消歧中的使用代价。大量实验验证了该方法具有较高的鲁棒性和精度。然而,该方法的图模型完全忽视了全局语义信息,正因为运用的语义信息有限,消歧过程中也出现了词语消歧结果冲突的现象,对消歧精度产生了影响。因此,本文针对这种表示局部语义的图模型进行了改进,提出一种基于全局领域和短期记忆因子的图模型GSGS(Graph on Semantic relation based on Global domains and Short term memory factor)。该模型引入了全局领域信息,丰富了图模型中的语义信息,并说明了全局语义信息对局部语义的影响。同时,该模型还引入了一个短期记忆因子STMF(Short Term Memory Factor),通过模拟人的短期记忆,从而优化词语序列在图模型中对语义的表达,让基于图的消歧方法结果更统一、更准确。本文采用大量实验验证了所提的改进模型能进一步提高词义消歧的精度。</p>
                </div>
                <h3 id="72" name="72" class="anchor-tag"><b>2 改进的图模型</b></h3>
                <div class="p1">
                    <p id="73">针对遗传蚁群词义消歧算法GMMASWSD采用的图模型仅包含局部词语义存在的问题,本文有针对性地提出了一种改进的图模型:基于全局领域信息和短期记忆因子的图模型GSGS。GSGS中引入全局领域信息,填补了原图模型中全局语义信息的缺失。短期记忆因子则通过对最近的消歧结果进行记忆,削弱了消歧结果冲突这一噪声对消歧结果的影响。</p>
                </div>
                <div class="p1">
                    <p id="74">GSGS模型形式化表示如下:对于任意给定的文本<i>T</i>,可表示为单词的集合<i>T</i>={<i>w</i><sub>1</sub>,<i>w</i><sub>2</sub>,…,<i>w</i><sub><i>i</i></sub>,…,<i>w</i><sub><i>n</i></sub>},<i>w</i><sub><i>i</i></sub>表示<i>T</i>中第<i>i</i>个单词,<i>n</i>表示单词个数,1≤<i>i</i>≤<i>n</i>。利用窗口机制选出文本中一个规模为<i>m</i>+1的词袋<i>BOW</i>(Bag Of Words),表示为<i>BOW</i>={<i>w</i><sub><i>x</i></sub>,<i>w</i><sub><i>x</i></sub><sub>+1</sub>,…,<i>w</i><sub><i>x</i></sub><sub>+</sub><sub><i>m</i></sub>},<i>m</i>+1表示词袋大小,<i>x</i>≥1。利用WordNet知识库将词袋中的所有词语的释义(Synset)作为节点,即,<i>w</i><sub><i>x</i></sub><sub>+</sub><sub><i>j</i></sub>的释义表示为<i>S</i><sub><i>j</i></sub>={<i>S</i><sub><i>j</i></sub><sub>1</sub>,<i>S</i><sub><i>j</i></sub><sub>2</sub>,…,<i>S</i><sub><i>jk</i></sub>},将这些释义之间拓展的LESK度量关系(由Banerjee 和Pedersen提出,下面简称为BP关系)、短期记忆因子STMF和领域信息Domain关系的和作为边,构建了新的图模型GSGS。如图1所示为GSGS构造模型的一个例子。为了简化描述,假设词袋规模为3,每个词有2～3个释义。具体技术细节详见2.1节和2.2节。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910017_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 GSGS模型的结构" src="Detail/GetImg?filename=images/JSJK201910017_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 GSGS模型的结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910017_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Structure of GSGS model</p>

                </div>
                <div class="p1">
                    <p id="76">根据上述形式化描述,在构建表示语义关系的图结构时,利用上下文窗口(Context Window)在文本中选取规模为<i>m</i>+1的词语序列,并用选取的词组成一个词袋。更新词袋时则滑动窗口,每次移除这个序列的第一个词语,移入当前窗口后的最近一个词语。图2展示了2个临近词袋<i>BOW</i>之间的关系(词袋移除队首的词语word#1,在队尾移入新的词语word#5,构成了新的词袋)。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910017_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 词袋的更新" src="Detail/GetImg?filename=images/JSJK201910017_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 词袋的更新  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910017_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Update of Bag of Word</p>

                </div>
                <div class="p1">
                    <p id="78">在计算2个释义之间关系时,GMMASWSD利用BP关系和局部领域关系参与运算,如式(1)所示:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mtext>Ρ</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mtext>Ρ</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>L</mtext><mtext>o</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">其中,<i>S</i><sub><i>au</i></sub>是单词<i>w</i><sub><i>a</i></sub>的第<i>u</i>个释义,<i>S</i><sub><i>bv</i></sub>同理,1≤<i>a</i>,<i>b</i>≤<i>n</i>;<i>u</i>,<i>v</i>≥1;<i>Relation</i><sub>BP</sub>(<i>S</i><sub><i>au</i></sub>,<i>S</i><sub><i>bv</i></sub>)是由Banerjee和Pedersen提出的the extended LESK measure,利用2个Synset之间注释的重叠部分来衡量两者之间的关系,在WordNet中,相近释义的词语和它们的近似描述构成一组近义词集Synset,其中词语被称为Lemma,注释被称为gloss,<i>Relation</i><sub>BP</sub>(<i>S</i><sub><i>au</i></sub>,<i>S</i><sub><i>bv</i></sub>)则利用注释语义进行计算,如式(2)所示:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mtext>Ρ</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><msup><mi>S</mi><mo>′</mo></msup><mo>:</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mover><mo stretchy="true" symmetric="false">→</mo><mrow><mtext>r</mtext><mtext>e</mtext><mtext>l</mtext></mrow></mover><msup><mi>S</mi><mo>′</mo></msup></mrow></msub><mspace width="0.25em" /></mstyle><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><msup><mi>S</mi><mo>″</mo></msup><mo>:</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mover><mo stretchy="true" symmetric="false">→</mo><mrow><mtext>r</mtext><mtext>e</mtext><mtext>l</mtext></mrow></mover><msup><mi>S</mi><mo>″</mo></msup></mrow></msub><mo stretchy="false">|</mo></mstyle></mtd></mtr><mtr><mtd><mi>g</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo stretchy="false">(</mo><msup><mi>S</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mstyle displaystyle="true"><mo>∩</mo><mi>g</mi></mstyle><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo stretchy="false">(</mo><msup><mi>S</mi><mo>″</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">其中,<i>S</i>′:<mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mover><mo stretchy="true" symmetric="false">→</mo><mrow><mtext>r</mtext><mtext>e</mtext><mtext>l</mtext></mrow></mover><msup><mi>S</mi><mo>′</mo></msup></mrow></math></mathml>,表示<i>S</i><sub><i>au</i></sub>或者在WordNet中和<i>S</i><sub><i>au</i></sub>有关联的其他Synset,<i>S</i>″:<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mover><mo stretchy="true" symmetric="false">→</mo><mrow><mtext>r</mtext><mtext>e</mtext><mtext>l</mtext></mrow></mover><msup><mi>S</mi><mo>″</mo></msup></mrow></math></mathml>,表示<i>S</i><sub><i>bv</i></sub>或者在WordNet中和<i>S</i><sub><i>bv</i></sub>有关联的其他Synset。</p>
                </div>
                <div class="p1">
                    <p id="83"><i>Relation</i><sub>LocalDomain</sub>(<i>S</i><sub><i>au</i></sub>,<i>S</i><sub><i>bv</i></sub>)是利用WordNet Domain信息(Magnini和Cavaglia针对WordNet中在每个词的Synset,添加了相关的领域信息,构成了WordNet Domain,简称WND<citation id="166" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>),来计算<i>S</i><sub><i>au</i></sub>和<i>S</i><sub><i>bv</i></sub>的局部领域关联。它们的关联值通过式(3)计算:</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>L</mtext><mtext>o</mtext><mtext>c</mtext><mtext>a</mtext><mtext>l</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mo stretchy="false">|</mo><mi>d</mi><mi>o</mi><mi>m</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo stretchy="false">)</mo><mstyle displaystyle="true"><mo>∩</mo><mi>d</mi></mstyle><mi>o</mi><mi>m</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>s</mi><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">其中,<i>domains</i>(<i>S</i><sub><i>au</i></sub>)表示<i>S</i><sub><i>au</i></sub>的领域标签信息。</p>
                </div>
                <div class="p1">
                    <p id="86">GMMASWSD中的语义图只强调了文本中的局部信息,即<i>Relation</i><sub>LocalDomain</sub>(<i>S</i><sub>1</sub>,<i>S</i><sub>2</sub>),忽视了全文的各类语义信息。而Magnini等<citation id="167" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>发现因为文本的连贯性,所以一段文本中的词语都倾向于同一领域。同时,Huang等<citation id="168" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>利用全文的词频信息来辅助区分多义词词义,也获得了很好的精度,再次证明了全文语义信息对词义消歧的积极作用。因此,本文在语义图中利用了全局语义信息。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>2.1 全局领域信息</b></h4>
                <div class="p1">
                    <p id="88">领域信息是词义消歧常用的信息,多义词的不同词义往往对应着不同的领域信息。GMMASWSD的语义图中运用了词义窗口内的局部领域信息进行词义消歧。而文献<citation id="169" type="reference">[<a class="sup">7</a>]</citation>的词语倾向于同一个领域<citation id="170" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>,全局领域信息也具备明显的语义特征。基于此,本文在语义图中引入了全局领域信息。全局领域信息通过式(4)进行计算:</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mtext>b</mtext><mtext>a</mtext><mtext>l</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>d</mi><mi>o</mi><mi>m</mi><mi>a</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo stretchy="false">|</mo><mi>D</mi><mi>o</mi><mi>m</mi><mi>a</mi><mi>i</mi><mi>n</mi><mi>s</mi><mo stretchy="false">|</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">其中,<i>S</i>是指输入的Synset,|<i>domain</i>(<i>S</i>)|是Synset的领域在全文中出现的次数,|<i>Domains</i>|是全文中所有领域信息出现的次数。单个词语的领域信息出现的频数相对全文领域的频数显得非常小(除了‘factotum’标签外),直接使用会导致全局领域信息的数值远远小于局部领域信息的,使得其对词义消歧的计算影响十分微小;而且,经过统计可知全局领域信息基本在[0,50],差距不明显,导致全局领域信息的作用受到了限制。为了提高全局领域信息的权重,需要对全局领域信息进行加权,增加其权重数值;同时又应当保证不会过分削弱局部领域信息的作用,全局领域信息的权重不应该远远大于局部领域信息。本文选取领域频数的平方作为分子,既能基本保证全局领域信息和局部领域信息的权重都在1左右,还能尽量区分不同Synset在全局领域信息上的差距。通过全局领域信息和局部领域信息的共同作用,既能降低噪声影响,又完善了语义信息在词义消歧中的应用。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>2.2 短期记忆因子</b></h4>
                <div class="p1">
                    <p id="92">本文在研究GMMASWSD的过程中发现一个现象:在对比GMMASWSD和人工词义消歧的流程中,发现人工处理词义消歧时对词义的判断是连续的。而Alsaeeda等<citation id="171" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>发现单纯地通过扩大上下文窗口,利用前文的词义信息,并不能改善词义消歧的结果,因为单纯地增加窗口规模会引入更多的噪声。而GMMASWSD算法在词义消歧的过程中,词语<i>w</i>会在几个连续的窗口中重复出现,而且在不同窗口中的语义会出现差异。这很有可能是扩大窗口规模时,引起噪声的原因之一。比如在处理句子 “They also allow a more experienced programmer to develop simple applications quickly” 时,GMMASWSD每次选取4个词语组成一个BOW(Alsaeeda等得出的最佳词袋尺寸)。“develop”在<i>BOW</i><sub>1</sub>中的释义为“develop.v.01”,在<i>BOW</i><sub>2</sub>中的释义为“originate.v.01”,因此导致了词语“simple”在<i>BOW</i><sub>2</sub>中被错误地解释为“dim-witted.s.01”。</p>
                </div>
                <div class="p1">
                    <p id="93">为了避免噪声的影响,模型GSGS引入了短期记忆因子。Miller<citation id="172" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>提出人在阅读时,能形成规模相当的短期记忆。我们参照人类短期记忆的特点,构造了短期记忆因子STMF,来加强图模型对语义解释的能力。</p>
                </div>
                <div class="p1">
                    <p id="94">首先,本文设置了一个规模为<i>μ</i>的记忆块,每次能记住<i>μ</i>个词语的释义。随着窗口移动,在得出窗口对应的词袋的结果后,记忆块移除旧词,加入新词,并把最新窗口的结果记录在记忆块中。记忆块的规模<i>μ</i>是一个常数,因为短期记忆的规模和单词数量有关,与词语的长短无关<citation id="173" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="95">在计算新窗口形成的图结构时,新窗口中的词语<i>w</i><sub><i>a</i></sub>如果出现在记忆块中,那么<i>w</i><sub><i>a</i></sub>在记忆块中对应的释义应该对新窗口的图形成反馈。而且越近的释义对新窗口的图影响越大。记忆块对参与计算的释义<i>S</i>为节点相连的边的权值进行奖励:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>Τ</mtext><mtext>Μ</mtext><mtext>F</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo>=</mo><mi>i</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>φ</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">其中,<i>index</i>(<i>S</i>)是指Synset在STMF的位置索引(0&lt;<i>index</i>(<i>S</i>)&lt;<i>μ</i>),如果<i>S</i>不在STMF中,<i>index</i>(<i>S</i>)=0。<i>φ</i>是一个正实数常量。</p>
                </div>
                <div class="p1">
                    <p id="98">STMF能记住一定规模的最近消歧结果,并将最近的消歧结果作为一种特殊的语义信息来帮助当前的消歧处理,因此最佳的<i>μ</i>值应该为<i>m</i>-1。同时,越近的记忆影响能力越强,短期记忆会随着时间的推移迅速被忘记。短期记忆虽然和长期记忆同时产生,但是,随着时间推移短期记忆会由强到弱,长期记忆会由弱到强,记忆的重心逐渐转移<citation id="174" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>。STMF满足了短期记忆的这一特征。图3展示了<i>n</i>=4,<i>μ</i>=3时,短期记忆更新机制的实例。</p>
                </div>
                <div class="p1">
                    <p id="99">图3a展示的是短期记忆块。如图3a中粗虚线方框所示,记忆块中存储了<i>BOW</i><sub>3</sub>最新3个词语的释义,其中<i>S</i><sub>11</sub>是<i>BOW</i><sub>3</sub>经过消歧得到的结果,<i>S</i><sub>12</sub>、<i>S</i><sub>21</sub>是<i>BOW</i><sub>2</sub>经过消歧得到的结果,<i>S</i><sub>13</sub>、<i>S</i><sub>22</sub>、<i>S</i><sub>31</sub>是<i>BOW</i><sub>3</sub>经过消歧得到的结果,我们将最新3个词语的释义视为<i>BOW</i><sub>3</sub>的短期记忆向<i>BOW</i><sub>4</sub>的短期记忆更新的初始状态。图3b展示了具体的更新过程:<i>BOW</i><sub>4</sub>利用<i>BOW</i><sub>3</sub>形成的短期记忆块进行消歧后,得到消歧结果<i>R</i>{<i>S</i><sub>14</sub>,<i>S</i><sub>23</sub>,<i>S</i><sub>32</sub>,<i>S</i><sub>41</sub>}。根据消歧结果,记忆块遗忘掉块中第一个单词<i>w</i><sub><i>n</i></sub><sub>+1</sub>的所有历史释义<i>S</i>{<i>S</i><sub>11</sub>,<i>S</i><sub>12</sub>,<i>S</i><sub>13</sub>},把最新的单词<i>w</i><sub><i>n</i></sub><sub>+4</sub>释义加入块中,新的记忆块如图3b中粗虚线框所示。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910017_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 短期记忆的更新机制" src="Detail/GetImg?filename=images/JSJK201910017_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 短期记忆的更新机制  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910017_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 Update mechanism of short term memory</p>

                </div>
                <div class="p1">
                    <p id="101">基于上述的全局领域信息和短期记忆因子,所构建的图模型边的计算可表示为式(6):</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mtext>Ρ</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo>,</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>Τ</mtext><mtext>Μ</mtext><mtext>F</mtext></mrow></msub><mo>+</mo><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mtext>b</mtext><mtext>a</mtext><mtext>l</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">其中,<i>Relation</i><sub>BPDomain</sub>(<i>S</i><sub><i>au</i></sub>,<i>S</i><sub><i>bv</i></sub>)是原模型中利用局部领域信息和BP关系计算出的值,计算方法如式(1)所示。<i>Relation</i><sub>STMF</sub>是<i>S</i><sub><i>au</i></sub>、<i>S</i><sub><i>bv</i></sub>的短期记忆因子和,计算方法如式(7)所示。</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>Τ</mtext><mtext>Μ</mtext><mtext>F</mtext></mrow></msub><mo>=</mo><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>Τ</mtext><mtext>Μ</mtext><mtext>F</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>Τ</mtext><mtext>Μ</mtext><mtext>F</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">其中,<i>Relation</i><sub>STMF</sub>(<i>S</i><sub><i>au</i></sub>)是<i>S</i><sub><i>au</i></sub>的短期记忆因子,<i>Relation</i><sub>STMF</sub>(<i>S</i><sub><i>bv</i></sub>)同理,计算方法见式(5)。<i>Relation</i><sub>GlobalDomain</sub>的计算方法如式(8)所示。</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mtext>b</mtext><mtext>a</mtext><mtext>l</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo>=</mo><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mtext>b</mtext><mtext>a</mtext><mtext>l</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>a</mi><mi>u</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>R</mi><mi>e</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msub><mrow></mrow><mrow><mtext>G</mtext><mtext>l</mtext><mtext>o</mtext><mtext>b</mtext><mtext>a</mtext><mtext>l</mtext><mtext>D</mtext><mtext>o</mtext><mtext>m</mtext><mtext>a</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">其中,<i>Relation</i><sub>GlobalDomain</sub>(<i>S</i><sub><i>au</i></sub>)是<i>S</i><sub><i>au</i></sub>的全局领域信息值,<i>Relation</i><sub>GlobalDomain</sub>(<i>S</i><sub><i>bv</i></sub>)同理,计算方法如式(4)所示。</p>
                </div>
                <h3 id="108" name="108" class="anchor-tag"><b>3 实验结果分析</b></h3>
                <div class="p1">
                    <p id="109">本文实验采用2007年语义评估大会SemEval2007中的竞赛任务7(Task#7:Coarse-grained English all-words)<citation id="175" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>作为数据集,WordNet2.1和WordNetDomian作为知识库。根据GMMASWSD得出的最佳规模,窗口的规模设置为4。</p>
                </div>
                <div class="p1">
                    <p id="110">本节首先给出评价标准,进而讨论所提模型中的若干重要参数,最后对比了11个近期表现优异的经典算法,算法列表如表1所示。</p>
                </div>
                <div class="area_img" id="111">
                    <p class="img_tit"><b>表1 对比算法列表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 List of algorithms in comparison</b></p>
                    <p class="img_note"></p>
                    <table id="111" border="1"><tr><td><br />算法</td><td>类型</td><td>核心模型描述</td></tr><tr><td><br />Nav05<sup>[20]</sup></td><td>半监督</td><td>图模型</td></tr><tr><td><br />Cha07<sup>[7]</sup></td><td>有监督</td><td>SVM</td></tr><tr><td><br />Cai07<sup>[8]</sup></td><td>有监督</td><td>NaiveBayes</td></tr><tr><td><br />Nov07<sup>[12]</sup></td><td>无监督</td><td>机器学习</td></tr><tr><td><br />Izq07<sup>[15]</sup></td><td>半监督</td><td>SVM</td></tr><tr><td><br />Hau11<sup>[10]</sup></td><td>无监督</td><td>领域信息,遗传算法</td></tr><tr><td><br />Sch11<sup>[11]</sup></td><td>无监督</td><td>树模型,蚁群算法</td></tr><tr><td><br />Sch12<sup>[17]</sup></td><td>半监督</td><td>蚁群算法</td></tr><tr><td><br />Ngu13<sup>[18]</sup></td><td>半监督</td><td>旅行商模型,蚁群算法</td></tr><tr><td><br />GAWSD<sup>[16]</sup></td><td>半监督</td><td>遗传算法</td></tr><tr><td><br />GMMASWSD<sup>[23]</sup></td><td>半监督</td><td>图模型,蚁群算法</td></tr><tr><td><br />GMMASWSD with GSGS</td><td>半监督</td><td>图模型,蚁群算法</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="112" name="112"><b>3.1 评价标准</b></h4>
                <div class="p1">
                    <p id="113">本文使用精确度、召回率和<i>F</i>值作为评价标准。本节展示的结果是10次结果的平均值,因此评价标准表示为平均精确度<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml>(%)、平均召回率<mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>R</mi><mo>¯</mo></mover></math></mathml>(%)和平均F值<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>F</mi><mo>¯</mo></mover></math></mathml>(%)。</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>3.2 STMF中</b><i><b>φ</b></i><b>值的变化</b></h4>
                <div class="p1">
                    <p id="115">在短期记忆因子中有一个重要参数<i>φ</i>,对短期记忆因子的权重有直接影响。为了得到短期记忆因子的最佳表现,本文针对不同的<i>φ</i>值进行了多组实验。图4分别显示了<i>φ</i>取值为0～1、1～10、10～100时引起的精确度实验结果<i>F</i>值变化情况。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910017_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 φ值和F值的关系(φ∈(0,100))" src="Detail/GetImg?filename=images/JSJK201910017_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 <i>φ</i>值和<i>F</i>值的关系(<i>φ</i>∈(0,100))  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910017_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 Relationship between <i>φ</i> and <i>F</i> (<i>φ</i>∈(0,100))</p>

                </div>
                <div class="p1">
                    <p id="117">由图4中结果可知:参数<i>φ</i>对消歧结果的确有所影响,且实验表明<i>φ</i>值为0.9时效果最佳。因此,在3.3节的实验中,本文将<i>φ</i>值均设为0.9。</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118"><b>3.3 实验结果</b></h4>
                <div class="p1">
                    <p id="119">GSGS是基于GMMASWSD来进行修改的,因此本文把GMMASWSD作为基准算法。</p>
                </div>
                <div class="p1">
                    <p id="120">首先,为了证明STMF和Global Domains的加入对词义消歧产生了正向影响,本文先进行了自对比实验,结果如表2所示,其中粗体表示最优结果。表2展示的结果表明,全局领域信息和短期记忆因子均对词义消歧有积极的影响。总体来说GSGS的改进提高了算法的精确度,增强了GMMASWSD的消歧能力。尤其是STMF的引入,增强了用以表示语义关系的图模型对现行文字的处理能力,改善了消歧结果。</p>
                </div>
                <div class="area_img" id="121">
                    <p class="img_tit"><b>表2 GSGS与原基于图的算法的实验对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Comparison results between GSGS and the original graph-based algorithms</b></p>
                    <p class="img_note"></p>
                    <table id="121" border="1"><tr><td><br />算法</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><mo>/</mo><mi>%</mi></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>R</mi><mo>¯</mo></mover><mo>/</mo><mi>%</mi></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>F</mi><mo>¯</mo></mover><mo>/</mo><mi>%</mi></mrow></math></td></tr><tr><td><br />GMMASWSD<sup>[23]</sup></td><td>80.70</td><td>80.70</td><td>80.70</td></tr><tr><td><br />GMMASWSD with STMF</td><td>81.40</td><td>81.40</td><td>81.40</td></tr><tr><td><br />GMMASWSD with GlobalDomains</td><td>80.83</td><td>80.83</td><td>80.83</td></tr><tr><td><br />GMMASWSD with GSGS</td><td><b>81.49</b></td><td><b>81.49</b></td><td><b>81.49</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="122">接着,本文对比了一些其他经典算法。其中Nav05算法实验结果表现最优,比GMMASWSD的效果要高出2.51%。而本文所提算法提升了GMMASWSD的实验效果,比Nav05只低了1.72%,基本达到了Nov07的准确率。表3对实验结果进行了展示,其中粗体表示最优结果。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>3.4 讨论</b></h4>
                <div class="p1">
                    <p id="124">虽然从人对自然语言处理的过程和计算结果上说明了短期记忆的重要性,但本文仍然对短期记忆是如何影响消歧算法以及在短期记忆的影响下消歧算法体现出来的特点感到好奇。于是本文尝试对消歧结果从微观上进行一些观察,也发现了一些短期记忆因子在消歧上体现出来的优势和劣势。</p>
                </div>
                <div class="p1">
                    <p id="125">表4展示了短期记忆STMF对离散型消歧错误的纠正实例。由表4结果可知,短期记忆因子对离散的消歧错误结果有非常好的修正效果。GMMASWSD因为利用的语义信息有限,故在一些词义的消歧上存在误差。而短期记忆能较好地利用前面窗口的残留信息,尽可能地消除这种误差。</p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit"><b>表3 GSGS和其他消歧算法的实验对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Comparison results between GSGS and other algorithms</b></p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td><br />算法</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><mo>/</mo><mi>%</mi></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>R</mi><mo>¯</mo></mover><mo>/</mo><mi>%</mi></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>F</mi><mo>¯</mo></mover><mo>/</mo><mi>%</mi></mrow></math></td></tr><tr><td><br />Nav05<sup>[20]</sup></td><td><b>83.21</b></td><td><b>83.21</b></td><td><b>83.21</b></td></tr><tr><td><br />Cha07<sup>[7]</sup></td><td>82.50</td><td>82.50</td><td>82.50</td></tr><tr><td><br />Cai07<sup>[8]</sup></td><td>81.58</td><td>81.58</td><td>81.58</td></tr><tr><td><br />Nov07<sup>[12]</sup></td><td>81.45</td><td>81.45</td><td>81.45</td></tr><tr><td><br />Izq07<sup>[15]</sup></td><td>79.55</td><td>79.55</td><td>79.55</td></tr><tr><td><br />Hau11<sup>[10]</sup></td><td>74.51</td><td>74.51</td><td>74.51</td></tr><tr><td><br />Sch11<sup>[11]</sup></td><td>74.35</td><td>74.35</td><td>74.35</td></tr><tr><td><br />Sch12<sup>[17]</sup></td><td>77.64</td><td>77.64</td><td>77.64</td></tr><tr><td><br />Ngu13(TSP-ACO)<sup>[18]</sup></td><td>78.50</td><td>78.50</td><td>78.50</td></tr><tr><td><br />GAWSD<sup>[16]</sup></td><td>77.59</td><td>77.59</td><td>77.59</td></tr><tr><td><br />GMMASWSD<sup>[23]</sup></td><td>80.70</td><td>80.70</td><td>80.70</td></tr><tr><td><br />GMMASWSD with GSGS</td><td>81.49</td><td>81.49</td><td>81.49</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="127">
                    <p class="img_tit"><b>表4 STMF对离散型消歧错误的纠错</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Improvement on discrete disambiguation error by the STMF</b></p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td><br />Word</td><td>GMMASWSD</td><td>GMMASWSD with GSGS</td></tr><tr><td><br />let</td><td>1,let.v.01</td><td>1,let.v.01</td></tr><tr><td><br />programmer</td><td>1,programmer.n.01</td><td>1,programmer.n.01</td></tr><tr><td><br />specify</td><td>1,stipulate.v.01</td><td>1,stipulate.v.01</td></tr><tr><td><br />instruction</td><td>1,instruction.n.04</td><td>1,instruction.n.04</td></tr><tr><td><br />text</td><td>1,text.n.01</td><td>1,text.n.01</td></tr><tr><td><br />format</td><td>1,format.n.02</td><td>1,format.n.02</td></tr><tr><td><br />entering</td><td>1,record.v.01</td><td>1,record.v.01:</td></tr><tr><td><br />abbreviations</td><td>1,abbreviation.n.01</td><td>1,abbreviation.n.01</td></tr><tr><td><br />operation</td><td><b>0,operation.n.03</b></td><td><b>1,operation.n.07</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="128">其中,“0” 表示消歧错误;“1”表示消歧正确; GMMASWSD with GSGS表示带有GSGS模型的GMMASWSD算法,该算法的实验结果有所提高,见加粗部分。</p>
                </div>
                <div class="p1">
                    <p id="129">此外,虽然短期记忆能较好地消除一些离散型的消歧错误,但在处理GMMASWSD产生的一些连续性错误时,会导致错误结果放大。通常,短期记忆因子能借助之前窗口的正确结果来消除新窗口中可能出现的消歧错误,但是GMMASWSD的消歧结果中,一些错误是无法用算法中运用的语义信息消除的。当这类错误出现,尤其是密集出现时,短期记忆会不断记忆错误结果,导致消歧错误被放大。表5中展示了这类错误结果放大的例子。</p>
                </div>
                <div class="area_img" id="130">
                    <p class="img_tit"><b>表5 STMF对特殊类型错误的放大</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Deterioration on consecutive error by the STMF</b></p>
                    <p class="img_note"></p>
                    <table id="130" border="1"><tr><td><br />Word</td><td>GMMASWSD</td><td>GMMASWSD with GSGS</td></tr><tr><td><br />todays</td><td>1,today.n.01</td><td>1,today.n.01</td></tr><tr><td><br />hardware</td><td>1,hardware.n.03</td><td>1,hardware.n.03</td></tr><tr><td><br />concerns</td><td>0,concern.n.02</td><td>1,concern.n.01</td></tr><tr><td><br />raised</td><td><b>0,raise.v.20</b></td><td><b>0,raise.v.20</b></td></tr><tr><td><br />original</td><td><b>0,original.a.03</b></td><td><b>0,original.a.03</b></td></tr><tr><td><br />language</td><td><b>1,terminology.n.01</b></td><td><b>0,lyric.n.01</b></td></tr><tr><td><br />second</td><td><b>1,second.s.02</b></td><td><b>0,second.a.03</b></td></tr><tr><td><br />half</td><td>1,half.n.02</td><td>1,one-half.n.01</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="131">其中,“0” 表示消歧错误;“1”表示消歧正确;GMMASWSD with GSGS表示带有GSGS模型的GMMASWSD算法,该算法的实验结果有所提高,见加粗部分。</p>
                </div>
                <div class="p1">
                    <p id="132">从上面的2个特点来看,短期记忆因子有助于提高消歧的准确率,同时也可能导致消歧结果更差。因此,在更高准确率的算法中运用短期记忆因子对词义消歧会有更好的效果。</p>
                </div>
                <h3 id="133" name="133" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="134">针对包含局部语义信息的图模型中缺乏全局领域信息和消歧结果冲突的问题,本文提出了基于全局领域信息和短期记忆的图模型。通过引入全局领域信息和短期记忆因子,本文改进了基于语义关系表示的图模型,提升了GMMASWSD算法的消歧结果。短期记忆因子通过记住一定规模的前期处理结果来辅助最新的词义窗口进行消歧,满足了自然语言的线性特征。全局领域信息的引入让图结构能很好地记录全局语义信息,并运用在词义消歧任务当中。本文分别比较了短期记忆因子和全局领域信息对词义消歧的提升效果,并比较了基于GSGS的GMMASWSD和其他算法的效果:基于GSGS的GMMASWSD对GMMASWSD有了不错的提升,也缩小了和其他优秀算法的差距。本文讨论了短期记忆因子在词义消歧时体现的特点:短期记忆因子能修正离散型的消歧错误,但对特定类型错误会放大。此外,本文还分析了短期记忆因子中参数对消歧结果的影响。</p>
                </div>
                <div class="p1">
                    <p id="135">未来将针对短期记忆因子的特点进行一些改进,找到合适的数学模型计算出短期记忆因子权重。此外,如何将长期记忆(知识)和短期记忆进行更好的配合,以应用在词义消歧任务中,也是下一步准备着手的任务。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000017690&amp;v=MzA0MjJNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSjFzU2JoWT1OaWZJWTdLN0h0ak5yNDlGWk9vSUNuVTVvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Navigli R.Word sense disambiguation:A survey[J].ACM Computing Surveys,2009,41(2):1-69.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ198911000&amp;v=MjA4NDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYnZNTHl2U2RMS3hGdGpOcm85RlpJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Chen Zhao-xiong,Gao Qing-shi.Natural language processing[J].Journal of Computer Research and Development,1989(11):1-16.(in Chinese)
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving Statistical Machine Translation using Word Sense Disambiguation">

                                <b>[3]</b> Carpuat M,Wu D.Improving statistical machine translation using word sense disambiguation[C]//Proc of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,2007:61-72.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Machine translation of languages">

                                <b>[4]</b> Locke W N,Booth A D.Machine translation of languages[J].Physics Today,1956,9(2):16.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Named entity disambiguation using freebase and syntactic parsing">

                                <b>[5]</b> Nebhi K.Named entity disambiguation using freebase and syntactic parsing[C]//Proc of International Conference on Linked Data for Information Extraction,2013:50-55.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Translation">

                                <b>[6]</b> Warren W.Translation[M]//Machine Translation of Languages:Fourteen Essays.Cambridge,MA:MIT Press,1949.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Word sense disambiguation improves statistical machine translation">

                                <b>[7]</b> Chan Y S,Ng H T,Chiang D.Word sense disambiguation improves statistical machine translation[C]//Proc of the Meeting of the Association for Computational Linguistics (ACL 2007),2007:33-40.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=NUS-ML:Improving word sense disambiguation using topic features">

                                <b>[8]</b> Cai J F,Lee W S,Teh Y W,NUS-ML:Improving word sense disambiguation using topic features[C]//Proc of the 4th International Workshop on Semantic Evaluations,Association for Computational Linguistics,2007:249-252.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDC7501CC6DD99C39528E5A4F92EDC3B5&amp;v=MDk5MTdsZkNwYlEzNU5CaHc3MjV4S3c9TmlmT2ZjZkxHZFRNcnZ3MllwOTdCWFZLekI4VzZEY0lUUTdtMmhzM0RNYm5Sc2lhQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Jimeno Y A.Word embeddings and recurrent neural networks based on long-short term memory nodes in supervised biomedical word sense disambiguation[J].Journal of Biomedical Informatics,2017,73:137-147.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A genetic algorithm using semantic relations for word sense disambiguation">

                                <b>[10]</b> Hausman M.A genetic algorithm using semantic relations for word sense disambiguation[D].Colorado:University of Colorado,2011.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A global ant colony algorithm for word sense disambiguation based on semantic relatedness">

                                <b>[11]</b> Schwab D,Guillaume N.A global ant colony algorithm for word sense disambiguation based on semantic relatedness[C]//Proc of the 9th International Conference on Practical Applications of Agents and Multiagent Systems,2011:257-264.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LCC-WSD:System description for English coarse grained all words task at semeval 2007">

                                <b>[12]</b> Novischi A,Srikanth M,Bennett A.LCC-WSD:System description for English coarse grained all words task at semeval 2007[C]//Proc of the 4th International Workshop on Semantic Evaluations,Association for Computational Linguistics,2007:223-226.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=WordNet: An On-Line Lexical Database">

                                <b>[13]</b> Miller G.WordNet:An on-line lexical database[J].International Journal of Lexicography,1990,3(4):235-244.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Semantic Concordance">

                                <b>[14]</b> Miller G,Leacock C,Tengi R,et al.A semantic concordance[C]//Proc of the Workshop on Human Language Technology,1993:303-308.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=GPLSI:Word coarse-grained disambiguation aided by basic level concepts">

                                <b>[15]</b> Izquierdo R,Suárez A,Rigau G.GPLSI:Word coarse-grained disambiguation aided by basic level concepts[C]//Proc of the 4th International Workshop on Semantic Evaluations,2007:157-160.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel genetic algorithm for the word sense disambiguation problem">

                                <b>[16]</b> Alsaeedan W,Menai M E B.A novel genetic algorithm for the word sense disambiguation problem[C]//Proc of the 29th Canadian Conference on Advances in Artificial Intelligence,Lecture Notes in Computer Science,2016:162-167.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ant colony algorithm for the unsupervised word sense disambiguation of texts:Comparison and evaluation">

                                <b>[17]</b> Schwab D,Goulian J,Tchechmedjiev A,et al.Ant colony algorithm for the unsupervised word sense disambiguation of texts:Comparison and evaluation[C]//Proc of the 25th International Conference on Computational Linguistics (COLING 2012),2012:2389-2404.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13120400000535&amp;v=MjcxODZqbVVMZklKMXNTYmhZPU5qN0Jhcks3SDlQTXE0OUZaT3NQQ1g4OG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Nguyen K H,Ock C Y.Word sense disambiguation as a traveling salesman problem[J].Artificial Intelligence Review,2013,40(4):405-427.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A graph model for unsupervised lexical acquisition">

                                <b>[19]</b> Widdows D,Dorow B.A graph model for unsupervised lexical acquisition[C]//Proc of International Conference on Computational Linguistics,2002:1093-1099.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Structural Semantic Interconnections: A Knowledge-Based Approach to Word Sense Disambiguation">

                                <b>[20]</b> Navigli R,Velardi P.Structural semantic interconnections:A knowledge-based approach to word sense disambiguation[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence,2005,27(7):1075-1086.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011702005980&amp;v=MTU4MDBvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKMXNTYmhZPU5pZk9mYks3SHRETnFJOUhaT3NLQlhRNQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> Navigli R,Ponzetto S P.BabelNet:The automatic construction,evaluation and application of a wide-coverage multilingual semantic network[J].Artificial Intelligence,2012,193(6):217-250.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES7388C0C1C5DD4947B2BDE95691A410EA&amp;v=MjkwOTZ5eEZoNkUwSlBYYm5xaHMwQ0xhVlJjL3VDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3NzI1eEt3PU5pZk9mYlM3RnRtL3IveEVGKzU3ZUhndw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> Corrêa E A,Lopes A A,Amancio D R.Word sense disambiguation:A complex network approach[J].Information Sciences,2018,442:103-113.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8F1FE166DD9BE8AF803676073F1E9822&amp;v=MjkxMTdiaWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3NzI1eEt3PU5pZk9mYnZPSDZlNXJvbERFSjhHZmdreHZtQWI2ang3VDNuaXF4RkRlTWVkVA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> Alsaeedan W,Menai M E B,Al-Ahmadi S.A hybrid genetic-ant colony optimization algorithm for the word sense disambiguation problem[J].Information Sciences,2017,417:20-38.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Integrating subject field codes into WordNet">

                                <b>[24]</b> Magnini B,Cavaglià G.Integrating subject field codes into WordNet[C]//Proc of Conference on LREC,2004:1413-1418.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The role of domain information in Word Sense Disambiguation">

                                <b>[25]</b> Magnini B,Strapparava C,Pezzulo G,et al.The role of domain information in word sense disambiguation[J].Natural Language Engineering,2002,8(4):359-373.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving word representations via global context and multiple word prototypes">

                                <b>[26]</b> Huang E H,Socher R,Manning C D,et al.Improving word representations via global context and multiple word prototypes[C]//Proc of Meeting of the Association for Computational Linguistics:Long Papers,2012:873-882.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" >
                                    <b>[27]</b>
                                 Miller G.The magical number seven,plus or minus two:Some limits on our capacity for processing information[J].Psychological Review,1956,63:311-329.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=How big is a chunk">

                                <b>[28]</b> Simon H A.How big is a chunk?[J].Science,1974,183(4124):482-488.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_29" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRS1B0D108778E30010E92B1FBF38F3B0C7&amp;v=MjY0OTE1eEt3PU5pZlpmYkxLSHFYTnI0ZENZK042RDN3NXpoWm00ejBQU1FtUTJoRTlEN0htUmNtWUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3Mg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[29]</b> Kitamura T,Ogawa S K,Roy S,et al.Engrams and circuits crucial for systems consolidation of a memory[J].Science,2017,356(6333):73-78.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SemEval-2007Task07:Coarse-Grained English All-Words Task">

                                <b>[30]</b> Hargraves O.SemEval-2007 task 07:Coarse-grained English all-words task[C]//Proc of International Workshop on Semantic Evaluations,2007:30-35.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 陈肇雄,高庆狮.自然语言处理[J].计算机研究与发展,1989(11):1-16.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201910017" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201910017&amp;v=Mjg0MTR6cXFCdEdGckNVUkxPZVplUm1GeS9nVmJ2Tkx6N0JaYkc0SDlqTnI0OUVZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
