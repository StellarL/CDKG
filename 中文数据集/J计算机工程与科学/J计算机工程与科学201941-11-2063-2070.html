<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132344375186250%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJK201911023%26RESULT%3d1%26SIGN%3dGZHXuc4ddBNmNLrP0GOc1wU%252benA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911023&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911023&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911023&amp;v=MTk3MjdlWmVSbUZ5L2dVcjNPTHo3QlpiRzRIOWpOcm85SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;2 相关知识&lt;/b&gt; "><b>2 相关知识</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="&lt;b&gt;2.1 不平衡数据分类方法&lt;/b&gt;"><b>2.1 不平衡数据分类方法</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.2 不平衡数据分类算法评价指标&lt;/b&gt;"><b>2.2 不平衡数据分类算法评价指标</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="&lt;b&gt;3 SDRSMOTE算法&lt;/b&gt; "><b>3 SDRSMOTE算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="&lt;b&gt;3.1 边界样本的支持度&lt;/b&gt;"><b>3.1 边界样本的支持度</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;3.2 新样本合成中随机数的确定(影响因素&lt;/b&gt;&lt;i&gt;&lt;b&gt;posFac&lt;/b&gt;&lt;/i&gt;)"><b>3.2 新样本合成中随机数的确定(影响因素</b><i><b>posFac</b></i>)</a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;3.3 基于样本分布的SDRSMOTE算法&lt;/b&gt;"><b>3.3 基于样本分布的SDRSMOTE算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#134" data-title="&lt;b&gt;4 实验与分析&lt;/b&gt; "><b>4 实验与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#135" data-title="&lt;b&gt;4.1 实验对象&lt;/b&gt;"><b>4.1 实验对象</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;4.2 实验设计&lt;/b&gt;"><b>4.2 实验设计</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;4.3 实验结果与分析&lt;/b&gt;"><b>4.3 实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#155" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="&lt;b&gt;表1 二分类的混淆矩阵&lt;/b&gt;"><b>表1 二分类的混淆矩阵</b></a></li>
                                                <li><a href="#86" data-title="图1 边界样本支持度示意图">图1 边界样本支持度示意图</a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表2 数据集基本信息&lt;/b&gt;"><b>表2 数据集基本信息</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;表3 各个预测模型在6个数据集上的&lt;/b&gt;&lt;i&gt;&lt;b&gt;F&lt;/b&gt;&lt;/i&gt;&lt;b&gt;-&lt;/b&gt;&lt;i&gt;&lt;b&gt;value&lt;/b&gt;&lt;/i&gt;&lt;b&gt;值&lt;/b&gt;"><b>表3 各个预测模型在6个数据集上的</b><i><b>F</b></i><b>-</b><i><b>value</b></i><b>值</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;表4 各个预测模型在6个数据集上的&lt;/b&gt;&lt;i&gt;&lt;b&gt;G&lt;/b&gt;&lt;/i&gt;&lt;b&gt;-&lt;/b&gt;&lt;i&gt;&lt;b&gt;mean&lt;/b&gt;&lt;/i&gt;&lt;b&gt;值&lt;/b&gt;"><b>表4 各个预测模型在6个数据集上的</b><i><b>G</b></i><b>-</b><i><b>mean</b></i><b>值</b></a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表5 各个预测模型在6个数据集上的&lt;/b&gt;&lt;i&gt;&lt;b&gt;AUC&lt;/b&gt;&lt;/i&gt;&lt;b&gt;值&lt;/b&gt;"><b>表5 各个预测模型在6个数据集上的</b><i><b>AUC</b></i><b>值</b></a></li>
                                                <li><a href="#151" data-title="图2 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的&lt;i&gt;F&lt;/i&gt;-&lt;i&gt;value&lt;/i&gt;值">图2 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的<i>F</i>-<i>value</i>值</a></li>
                                                <li><a href="#152" data-title="图3 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的&lt;i&gt;G&lt;/i&gt;-&lt;i&gt;mean&lt;/i&gt;值">图3 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的<i>G</i>-<i>mean</i>值</a></li>
                                                <li><a href="#153" data-title="图4 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的&lt;i&gt;AUC&lt;/i&gt;值">图4 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的<i>AUC</i>值</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="5">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     Ye Feng,Ding Feng.Research and application of unbalanced data classification[J].Computer Applications and Software,2018,35(1):132-136.(in Chinese)</a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_2" title=" Liu Dong-qi.Support vector machine based classification algorithms research for imbalanced data[D].Hangzhou:Zhejiang University,2017.(in Chinese)" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Support vector machine based classification algorithms research for imbalanced data">
                                        <b>[2]</b>
                                         Liu Dong-qi.Support vector machine based classification algorithms research for imbalanced data[D].Hangzhou:Zhejiang University,2017.(in Chinese)
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_3" title=" Chawla N V,Bowyer K W,Hall L O,et al.SMOTE:Synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research,2002,16(1):321-357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">
                                        <b>[3]</b>
                                         Chawla N V,Bowyer K W,Hall L O,et al.SMOTE:Synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research,2002,16(1):321-357.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_4" title=" Giraldo-Forero A F,Jaramillo-Garz&#243;n J A,Ruiz-Muňoz J F,et al.Managing imbalanced data sets in multi-label problems:A case study with the SMOTE algorithm[C]//Proc of the 18th Iberoamerican Congress on Progress in Pattern Recognition,Image Analysis,Computer Vision,and Application,2013:334-342." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Managing imbalanced data sets in multi-label problems:A case study with the SMOTE algorithm">
                                        <b>[4]</b>
                                         Giraldo-Forero A F,Jaramillo-Garz&#243;n J A,Ruiz-Muňoz J F,et al.Managing imbalanced data sets in multi-label problems:A case study with the SMOTE algorithm[C]//Proc of the 18th Iberoamerican Congress on Progress in Pattern Recognition,Image Analysis,Computer Vision,and Application,2013:334-342.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     Gu Ping,Ouyang Yuan-you.Classification research for unbalanced data based on mixed-sampling[J].Application Research of Computers,2015,32(2):379-381.(in Chinese)</a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_6" title=" Souto M C P D,Bittencourt V G,Costa J A F.An empirical analysis of under-sampling techniques to balance a protein structural class dataset[J].Lecture Notes in Computer Science,2006,4234:21-29." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An empirical analysis of under-sampling techniques to balance a protein structural class dataset">
                                        <b>[6]</b>
                                         Souto M C P D,Bittencourt V G,Costa J A F.An empirical analysis of under-sampling techniques to balance a protein structural class dataset[J].Lecture Notes in Computer Science,2006,4234:21-29.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_7" title=" Laurikkala J.Improving identification of difficult small classes by balancing class distribution[C]//Proc of Conference on AI in Medicine in Europe:Artificial Intelligence Medicine,2001:63-66." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving Identification of Difficult Small Classes by Balancing Class Distribution">
                                        <b>[7]</b>
                                         Laurikkala J.Improving identification of difficult small classes by balancing class distribution[C]//Proc of Conference on AI in Medicine in Europe:Artificial Intelligence Medicine,2001:63-66.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_8" title=" Nguyen T D,Le T,Vu H,et al.Dual Discriminator Generative Adversarial Nets[C]//Proc of the 31th Conference of Neural Information Processing Systems,2017:2671-2681." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dual Discriminator Generative Adversarial Nets">
                                        <b>[8]</b>
                                         Nguyen T D,Le T,Vu H,et al.Dual Discriminator Generative Adversarial Nets[C]//Proc of the 31th Conference of Neural Information Processing Systems,2017:2671-2681.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     Xu Li-li Yan De-qin.Weighted ensemble learning algorithm for imbalanced data sets[J].Microcomputer &amp;amp; its Applications,2015,34(23):7-10.(in Chinese)</a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_10" title=" Nghe N T,Janecek P,Haddawy P.A comparative analysis of techniques for predicting academic performance[C]//Proc of the 37th IEEE Frontiers in Education Conference-global Engineering:Knowledge Without Borders,2007:7-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A comparative analysis of techniques for predicting academic performance">
                                        <b>[10]</b>
                                         Nghe N T,Janecek P,Haddawy P.A comparative analysis of techniques for predicting academic performance[C]//Proc of the 37th IEEE Frontiers in Education Conference-global Engineering:Knowledge Without Borders,2007:7-12.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_11" title=" Feng Hua-min,Li Ming-wei,Hou Xiao-lian,et al.Study of network intrusion detection method based on SMOTE and GBDT[J].Application Research of Computers,2017,34(12):3745-3748.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201712051&amp;v=MzI0NDNVUkxPZVplUm1GeS9nVXIzT0x6N1NaTEc0SDliTnJZOUFaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Feng Hua-min,Li Ming-wei,Hou Xiao-lian,et al.Study of network intrusion detection method based on SMOTE and GBDT[J].Application Research of Computers,2017,34(12):3745-3748.(in Chinese)
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     Wei Hao,Li Hong,Liu Xiao-yu.An improved SMOTE algorithm[J].Henan Science,2018,36(7):1009-1013.(in Chinese)</a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_13" title=" Li Ke-wen,Yang Lei,Liu Wen-ying,et al.Classification method of imbalanced data based on RSBoost[J].Computer Science,2015,42(9):249-252.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201509049&amp;v=MzE3MTE0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIzT0x6N0JiN0c0SDlUTXBvOUJiWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Li Ke-wen,Yang Lei,Liu Wen-ying,et al.Classification method of imbalanced data based on RSBoost[J].Computer Science,2015,42(9):249-252.(in Chinese)
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_14" title=" Yu Qiao,Jiang Shu-juan,Zhang Yan-mei,et al.The impact study of class imbalance on the performance of software defect prediction models[J].Chinese Journal of Computers,2018,41(4):809-824.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201804005&amp;v=MDMzNzZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIzT0x6N0Jkckc0SDluTXE0OUY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Yu Qiao,Jiang Shu-juan,Zhang Yan-mei,et al.The impact study of class imbalance on the performance of software defect prediction models[J].Chinese Journal of Computers,2018,41(4):809-824.(in Chinese)
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_15" title=" Bradley A P.The use of the area under the ROC curve in the evaluation of machine learning algorithms[J].Pattern Recognition,1997,30(7):1145-1159." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600741778&amp;v=MTY3NTNCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUoxc1ZhQlE9TmlmT2ZiSzdIdEROcVk5RlkrOE9DM3N4bw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Bradley A P.The use of the area under the ROC curve in the evaluation of machine learning algorithms[J].Pattern Recognition,1997,30(7):1145-1159.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_16" title=" Huang J,Ling C X.Using AUC and accuracy in evaluating learning algorithms[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2005,17(3):299-310." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using AUC and Accuracy in Evaluating Learning Algorithms">
                                        <b>[16]</b>
                                         Huang J,Ling C X.Using AUC and accuracy in evaluating learning algorithms[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2005,17(3):299-310.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_17" title=" Li K,Zhang W,Lu Q,et al.An improved SMOTE imbalanced data classification method based on support degree[C]//Proc of International Conference on Identification,2014:34-38." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An improved SMOTE imbalanced data classification method based on support degree">
                                        <b>[17]</b>
                                         Li K,Zhang W,Lu Q,et al.An improved SMOTE imbalanced data classification method based on support degree[C]//Proc of International Conference on Identification,2014:34-38.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     Center for Machine Learning and Intelligent Systems.UCI machine learning repository[DB/OL].[2018-04-09].http://archive.ics.uci.edu/ml/datasets.html.附中文参考文献:</a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_1" title=" 叶枫,丁锋.不平衡数据分类研究及其应用[J].计算机应用与软件,2018,35(1):132-136." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801024&amp;v=MDk0MDRSTE9lWmVSbUZ5L2dVcjNPTHpUWlpMRzRIOW5Ncm85SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         叶枫,丁锋.不平衡数据分类研究及其应用[J].计算机应用与软件,2018,35(1):132-136.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_2" title=" 刘东启.基于支持向量机的不平衡数据分类算法研究[D].杭州:浙江大学,2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017054620.nh&amp;v=MDQyNjIyNkdiTzlHdGZPcjVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVcjNPVkY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         刘东启.基于支持向量机的不平衡数据分类算法研究[D].杭州:浙江大学,2017.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_5" title=" 古平,欧阳源遊.基于混合采样的非平衡数据集分类研究[J].计算机应用研究,2015,32(2):379-381." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201502015&amp;v=MDI0ODlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVcjNPTHo3U1pMRzRIOVRNclk5RVlZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         古平,欧阳源遊.基于混合采样的非平衡数据集分类研究[J].计算机应用研究,2015,32(2):379-381.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_9" title=" 徐丽丽,闫德勤.不平衡数据加权集成学习算法[J].微型机与应用,2015,34(23):7-10." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201523003&amp;v=MTE2NDBNalhCZDdHNEg5VE9ySTlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1VyM08=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         徐丽丽,闫德勤.不平衡数据加权集成学习算法[J].微型机与应用,2015,34(23):7-10.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     封化民,李明伟,侯晓莲,等.基于SMOTE和GBDT的网络入侵检测方法研究[J].计算机应用研究,2017,34(12):3745-3748.</a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_12" title=" 魏浩,李红,刘小豫.一种改进的SMOTE算法[J].河南科学,2018,36(7):1009-1013." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNKX201807005&amp;v=MDEyODM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVcjNPTFNQQWRyRzRIOW5NcUk5RllZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         魏浩,李红,刘小豫.一种改进的SMOTE算法[J].河南科学,2018,36(7):1009-1013.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     李克文,杨磊,刘文英,等.基于RSBoost算法的不平衡数据分类方法[J].计算机科学,2015,42(9):249-252.</a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     于巧,姜淑娟,张艳梅,等.分类不平衡对软件缺陷预测模型性能的影响研究[J].计算机学报,2018,41(4):809-824.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(11),2063-2070 DOI:10.3969/j.issn.1007-130X.2019.11.022            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种改进的基于欧氏距离的SDRSMOTE算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%85%8B%E6%96%87&amp;code=09900369&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李克文</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9E%97%E4%BA%9A%E6%9E%97&amp;code=40424759&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">林亚林</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E8%80%80%E5%BF%A0&amp;code=20297524&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨耀忠</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%9F%B3%E6%B2%B9%E5%A4%A7%E5%AD%A6(%E5%8D%8E%E4%B8%9C)%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E9%80%9A%E4%BF%A1%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0034819&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国石油大学(华东)计算机与通信工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%9F%B3%E5%8C%96%E8%83%9C%E5%88%A9%E6%B2%B9%E7%94%B0%E5%88%86%E5%85%AC%E5%8F%B8%E4%BF%A1%E6%81%AF%E5%8C%96%E7%AE%A1%E7%90%86%E4%B8%AD%E5%BF%83&amp;code=1033825&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国石化胜利油田分公司信息化管理中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>SMOTE算法可以扩充少数类样本,提高不平衡数据集中少数类的分类能力,但是它在扩充少数类样本时对于边界样本的选择以及随机数的取值具有盲目性。针对此问题,将传统的SMOTE过采样算法进行改进,改进后的过采样算法定义为SDRSMOTE,该算法综合考虑不平衡数据集中全部样本的分布状况,通过融合支持度<i>sd</i>和影响因素<i>posFac</i>来指导少数类样本的合成。在WEKA平台上分别使用SMOTE、SDRSMOTE算法对所选用的6个不平衡数据集进行过采样数据预处理,然后使用决策树、AdaBoost、Bagging和朴素贝叶斯分类器对预处理后的数据集进行预测,选择<i>F</i>-<i>value</i>、<i>G</i>-<i>mean</i>和<i>AUC</i>作为分类性能的评价指标,实验表明SDRSMOTE算法预处理的不平衡数据集的分类效果更好,证明了该算法的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不平衡数据集;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BE%B9%E7%95%8C%E6%A0%B7%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">边界样本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%B1%E5%93%8D%E5%9B%A0%E7%B4%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">影响因素;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">欧氏距离;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SMOTE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SMOTE;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李克文(1969-),男,黑龙江齐齐哈尔人,博士,教授,博士生导师,CCF会员(E200014144M),研究方向为软件工程和人工智能。E-mail:likw@upc.edu.cn,通信地址:266580山东省青岛市中国石油大学（华东）计算机与通信工程学院;
                                </span>
                                <span>
                                    *林亚林,664103127@qq.com,通信地址:266580山东省青岛市中国石油大学（华东）计算机与通信工程学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-21</p>

            </div>
                    <h1><b>An improved SDRSMOTE algorithm based on Euclidean distance</b></h1>
                    <h2>
                    <span>LI Ke-wen</span>
                    <span>LIN Ya-lin</span>
                    <span>YANG Yao-zhong</span>
            </h2>
                    <h2>
                    <span>College of Computer &amp; Communication Engineering,China University of Petroleum</span>
                    <span>Control Center of Informatization Sinopec Shengli Oil Field</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The SMOTE algorithm can extend the minority samples and improve the classification ability of a few classes in the unbalanced data set. However, it blindly chooses boundary samples and the value of random numbers when extending the minority samples. This paper improves the traditional SMOTE oversampling algorithm, called SDRSMOTE. It takes into account all the unbalanced data sets. The distribution of all the samples, through the introduction of support degree <i>sd</i> and the influencing factor <i>posFac</i> to guide the synthesis of the minority samples. On the WEKA platform, the SMOTE and SDRSMOTE algorithms are used to preprocess the selected six unbalanced data sets and use the decision tree, AdaBoost, Bagging and Naive Bayes classifiers to predict the preprocessed datasets. The data set is classified, and <i>F</i>-<i>value</i>, <i>G</i>-<i>mean</i> and <i>AUC</i> are selected as evaluation indexes. The experiment shows that the unbalanced datasets preprocessed by the improved SDRSMOTE algorithm have better classification effect, which proves the effectiveness of the algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=unbalanced%20data%20set&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">unbalanced data set;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=boundary%20sample&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">boundary sample;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=support%20degree&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">support degree;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=influencing%20factor&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">influencing factor;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Euclidean%20distance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Euclidean distance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SMOTE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SMOTE;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LI Ke-wen,born in 1969,PhD,professor,PhD supervisor,CCF member(E200014144M),his research interests include software engineering,and artificial intelligence.Address:College of Computer &amp;amp; Communication Engineering,China University of Petroleum,Qingdao 266580,Shandong,P.R.China;
                                </span>
                                <span>
                                    LIN Ya-lin,Address:College of Computer &amp;amp; Communication Engineering,China University of Petroleum,Qingdao 266580,Shandong,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-21</p>
                            </div>


        <!--brief start-->
                        <h3 id="57" name="57" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="58">近年来,机器学习得到了前所未有的发展,已经有决策树、朴素贝叶斯等许多相对成熟的分类算法。但是,这些传统的分类算法往往假设数据集是平衡的,即各个类别的样本数量基本相同。而在许多实际应用中,如软件缺陷预测、医疗诊断<citation id="157" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="41" rel="bibliography" /><link href="43" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>,少数类样本的数量远远少于其他类别的样本,这些场景中的数据集被称作不平衡数据集。在不平衡数据集中,本文定义样本数量少的类为少数类,样本数量多的类为多数类。传统的分类器对不平衡数据集进行分类时,由于多数类样本更容易学习,导致分类结果偏向于多数类,但人们最感兴趣的往往是少数类。例如软件缺陷预测中,几乎所有的数据集都是不平衡的,有缺陷的样本属于少数类,无缺陷的样本属于多数类,在实际应用中为有缺陷样本预测错误所付出的代价是惨痛的。因此,分类不平衡问题逐渐成为机器学习领域的研究热点,尤其是正确识别其中的少数类。</p>
                </div>
                <div class="p1">
                    <p id="59">目前,研究人员主要从数据和算法2个层面解决分类不平衡问题。(1)数据层面通过采样法来增加少数类样本或减少多数类样本,从而使数据集中不同类别的样本数量趋于平衡。例如,Chawla等<citation id="158" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出了最经典的数据集重构算法合成少数类过采样技术SMOTE(Synthetic Minority Over-sampling TEchnique),该算法通过在同类近邻样本间线性插值来增加样本数量。Giraldo-Forero等<citation id="159" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出了基于距离度量的SMOTE类算法。古平等<citation id="160" type="reference"><link href="13" rel="bibliography" /><link href="45" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">5</a>]</sup></citation>提出了基于错分的过采样算法。Souto等<citation id="161" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了将Tomek links算法与卷积神经网络CNN(Convolutional Neural Networks)算法结合起来的单边选择的欠采样算法。Laurikkala<citation id="162" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了邻域清理NCL(Neighborhood Cleaning Rule)的欠采样算法。Nguyen等<citation id="163" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了双判别器生成对抗网络D2GAN(Dual Discriminator Generative Adversarial Nets)扩充数据样本。(2)算法层面主要通过代价敏感学习和集成学习来提高分类模型的性能,从而改善分类不平衡问题。例如,徐丽丽等<citation id="164" type="reference"><link href="21" rel="bibliography" /><link href="47" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">9</a>]</sup></citation>通过为各类别分配不同的权重将加权支持向量机模型WSVM(Weighted Support Vector Machine)与模糊聚类结合提出一种新的不平衡数据加权集成学习算法。Nghe等<citation id="165" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将采样技术与使用支持向量机的代价敏感学习算法进行结合来降低不平衡数据集误分类的成本。</p>
                </div>
                <div class="p1">
                    <p id="60">基于此,本文提出一种改进的SMOTE算法(基于样本分布改进的SMOTE算法SDRSMOTE(Support Degree Random Synthetic Minority Over-sampling TEchnique))。在确定边界样本过程中,该算法以少数类样本为中心,距离为半径圈定区域,并统计该区域内的多数类样本个数作为该少数类样本的支持度<i>sd</i>,根据支持度<i>sd</i>对少数类样本进行排序,使得支持度<i>sd</i>大的少数类样本优先被选择作为边界样本;在新样本生成过程中,考虑多数类样本分布对少数类样本生成的影响,引入影响因素<i>posFac</i>对新样本生成过程中的随机数进行约束。该算法的主要贡献如下:(1)通过引入支持度<i>sd</i>确定边界样本的选择顺序,可以缓解传统SMOTE过采样算法中随机选择边界样本的盲目性;(2)通过综合总体样本的分布状况引入影响因素<i>posFac</i>进行新样本的合成,使得新样本合成过程中的随机数取值更有针对性;(3)更加合理地扩展少数类样本,使得新数据集是趋于平衡的,提高分类器对于少数类样本的分类能力。</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag"><b>2 相关知识</b></h3>
                <h4 class="anchor-tag" id="62" name="62"><b>2.1 不平衡数据分类方法</b></h4>
                <div class="p1">
                    <p id="63">目前,处理不平衡数据的方法有很多,可以概括为2类,一类是从数据层面进行处理,另一类是从算法层面提高不平衡数据的分类性能。本文是从数据层面对不平衡数据进行处理。</p>
                </div>
                <div class="p1">
                    <p id="64">数据层面主要是通过采样算法改变数据集中的样本分布状况,使得多数类与少数类的样本分布大致平衡。采样算法包括欠采样和过采样2种类型,这里仅介绍本文采用的过采样算法。</p>
                </div>
                <div class="p1">
                    <p id="65">过采样技术就是使用复制或合成方法增加少数类样本的数量,该算法可以平衡不平衡数据集中的样本分布。经典的过采样算法包括随机过采样ROS(Random-Over-Sampling)和SMOTE。随机过采样是一种直接复制原有少数类样本实现平衡数据集样本分布的过采样算法,该算法容易造成分类模型过拟合<citation id="166" type="reference"><link href="25" rel="bibliography" /><link href="49" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="66">SMOTE是基于随机过采样的一种改进算法<citation id="167" type="reference"><link href="27" rel="bibliography" /><link href="51" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">12</a>]</sup></citation>,它通过相邻2个少数类样本之间的线性插值来合成新的少数类样本。SMOTE具体算法流程:对于每个少数类样本<i><b>x</b></i><sub><i>i</i></sub>,计算<i><b>x</b></i><sub><i>i</i></sub>到其他所有少数类样本的欧氏距离,然后搜索<i><b>x</b></i><sub><i>i</i></sub>的<i>K</i>个最近邻样本,根据采样倍率<i>N</i>从<i><b>x</b></i><sub><i>i</i></sub>的<i>K</i>个最近邻样本随机选择若干个样本(被选中的样本记为<i><b>x</b></i><sub><i>j</i></sub>)与<i><b>x</b></i><sub><i>i</i></sub>进行合成得到新样本<i><b>x</b></i><sub>new</sub>,<i><b>x</b></i><sub>new</sub>=<i><b>x</b></i><sub><i>i</i></sub>+<i>rand</i>(0,1)(<i><b>x</b></i><sub><i>j</i></sub>-<i><b>x</b></i><sub><i>i</i></sub>),其中<i>rand</i>(0,1)表示(0,1)内的随机数。例如,少数类样本点<i><b>x</b></i><sub><i>i</i></sub>为(4,7),被选中的<i>K</i>近邻样本点<i><b>x</b></i><sub><i>j</i></sub>为(3,5),合成新的少数类样本<i><b>x</b></i><sub>new</sub>=(4,7)+<i>rand</i>(0,1)×(-1,-2),假设随机数<i>rand</i>(0,1)取值0.3,则新样本<i><b>x</b></i><sub>new</sub>为(3.7,6.4)。SMOTE算法避免了随机过采样算法中造成分类器模型过拟合的问题,但是对于少数类边界样本的选择以及新样本合成中随机数的取值范围没有进行精细的控制,从而导致合成的新样本质量较差。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.2 不平衡数据分类算法评价指标</b></h4>
                <div class="p1">
                    <p id="68">在分类问题中,传统的预测模型通常选用准确率(<i>Accuracy</i>)作为分类的评价指标,但是对于不平衡数据集而言,由于多数类样本数量远远多于少数类样本数量,所以用分类正确的样本数占样本总数的比例去衡量分类器的性能是不合适的。因此,本文采用不平衡分类<citation id="168" type="reference"><link href="29" rel="bibliography" /><link href="53" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">13</a>]</sup></citation>中常用的评价指标F-value、G-mean和AUC进行评估。首先介绍基本的分类评价指标。</p>
                </div>
                <div class="p1">
                    <p id="69">在分类过程中,多分类问题也可以转化为二分类问题<citation id="169" type="reference"><link href="31" rel="bibliography" /><link href="55" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">14</a>]</sup></citation>,因此本文主要讨论不平衡数据集的二分类问题。传统二分类过程中常用的混淆矩阵如表1所示,通常我们称少数类样本为正类样本(+),多数类样本为负类样本(-)。</p>
                </div>
                <div class="area_img" id="70">
                    <p class="img_tit"><b>表1 二分类的混淆矩阵</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Confusion matrix for the two-class problem</b></p>
                    <p class="img_note"></p>
                    <table id="70" border="1"><tr><td><br />分类</td><td>+(预测类)</td><td>-(预测类)</td></tr><tr><td><br />+(实际类)</td><td><i>TP</i></td><td><i>FN</i></td></tr><tr><td><br />-(实际类)</td><td><i>FP</i></td><td><i>TN</i></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="71">其中,<i>TP</i> (True Positive)表示真正例的样本数,<i>FN</i> (False Negative)表示假负例的样本数,<i>FP</i> (False Positive)表示假正例的样本数,<i>TN</i> (True Negative)表示真负例的样本数。</p>
                </div>
                <div class="p1">
                    <p id="72">(1) 精确率(<i>precision</i>)的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">(2) 召回率(<i>recall</i>)的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">(3) <i>F</i>-<i>value</i>值是精确率(<i>precision</i>)和召回率(<i>recall</i>)的调和均值,计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>-</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>β</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo><mo>×</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>×</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><mrow><mi>β</mi><msup><mrow></mrow><mn>2</mn></msup><mo>×</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>+</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">其中参数<i>β</i>常取1,只有当精确率(<i>precision</i>)和召回率(<i>recall</i>)都高时,<i>F</i>-<i>value</i>值才会高。因此,它可以作为不平衡缺陷数据集分类问题的有效评估标准。</p>
                </div>
                <div class="p1">
                    <p id="79">(4) <i>G</i>-<i>mean</i>是正类样本召回率和负类样本召回率的几何均值,计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>=</mo><msqrt><mrow><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo>×</mo><mfrac><mrow><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></msqrt></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">其值越大分类性能越好,只有当正类样本和负类样本的分类效果都比较好时,<i>G</i>-<i>mean</i>值才会高。因此,它可以作为不平衡缺陷数据集分类问题的有效评估标准。</p>
                </div>
                <div class="p1">
                    <p id="82">(5)ROC(Receiver Operating Characteristic)曲线是描述分类模型真正例率和假正例率关系的二维曲线,该曲线可以比较不同分类器的性能,但不能定量评估分类器的性能。<i>AUC</i><citation id="170" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>是ROC曲线与坐标轴所围成的面积,它的取值是0～1,<i>AUC</i>值越大,预测模型的性能越好。</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag"><b>3 SDRSMOTE算法</b></h3>
                <h4 class="anchor-tag" id="84" name="84"><b>3.1 边界样本的支持度</b></h4>
                <div class="p1">
                    <p id="85">本文中边界样本支持度<i>sd</i>定义<citation id="171" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>:如图1所示,假设样本空间是二维的,我们以少数类样本为圆心,距离<i>S</i><sub>ave</sub>为半径圈定一个圆形区域,并统计该圆型区域内的多数类样本个数作为该少数类样本的支持度<i>sd</i>,其中<i>S</i><sub>ave</sub>的值为所有少数样本与多数类样本的平均欧氏距离。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911023_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 边界样本支持度示意图" src="Detail/GetImg?filename=images/JSJK201911023_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 边界样本支持度示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911023_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 An example of boundary sample support degree</p>

                </div>
                <div class="p1">
                    <p id="87">首先,我们计算少数类样本<i><b>x</b></i><sub><i>i</i></sub>和所有多数类样本之间的欧氏距离<i>S</i><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msqrt><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mstyle><mo>,</mo></mtd></mtr><mtr><mtd><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>m</mi><mo>;</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>n</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中,少数类样本的数量为<i>m</i>,多数类样本的数量为<i>n</i>,<i><b>x</b></i><sub><i>i</i></sub>表示当前的少数类样本,<i><b>y</b></i><sub><i>j</i></sub>表示当前的多数类样本。</p>
                </div>
                <div class="p1">
                    <p id="90">然后,计算所有少数类样本和所有多数类样本之间的距离<i>S</i>:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>S</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">最后,计算少数类样本和多数类样本的平均欧氏距离<i>S</i><sub>ave</sub>。</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mfrac><mi>S</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">以<i><b>x</b></i><sub><i>i</i></sub>为中心,<i>S</i><sub>ave</sub>为半径圈定区域,统计该区域内的多数类样本数量作为少数类样本<i><b>x</b></i><sub><i>i</i></sub>的支持度<i>sd</i>。</p>
                </div>
                <div class="p1">
                    <p id="95">图1中实心五角星表示多数类样本,空心五角星表示少数类样本,圆<i>C</i>1内包含4个多数类样本,即圆<i>C</i>1的支持度<i>sd</i>是4,同理可得圆<i>C</i>2的支持度<i>sd</i>是1,圆<i>C</i>3的支持度<i>sd</i>是0。某一少数类样本的支持度越大,则意味着该样本被确定为边界样本的概率越高;相反,某一少数类样本的支持度越小,则意味着该样本被确定为边界样本的概率越低。通过引入支持度<i>sd</i>避免传统SMOTE过采样算法随机选择边界样本的盲目性。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>3.2 新样本合成中随机数的确定(影响因素</b><i><b>posFac</b></i>)</h4>
                <div class="p1">
                    <p id="97">为了缓解<i>SMOTE</i>算法合成少数类样本时随机数取值的局限性,本文引入影响因素posFac对随机数进行精细控制<citation id="172" type="reference"><link href="27" rel="bibliography" /><link href="51" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">12</a>]</sup></citation>,具体计算步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="98">(1) 计算少数类样本<i><b>x</b></i><sub><i>i</i></sub>与其<i>K</i>个同类近邻的平均欧氏距离<i>d</i><sub><i>pave</i></sub><sub>-</sub><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>a</mi><mi>v</mi><mi>e</mi><mo>-</mo><mi>i</mi></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><msqrt><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mstyle></mrow><mi>Κ</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">其中,<i><b>x</b></i><sub><i>i</i></sub>表示当前的少数类样本,<i><b>x</b></i><sub><i>j</i></sub>表示样本<i><b>x</b></i><sub><i>i</i></sub>的第<i>j</i>个少数类近邻。</p>
                </div>
                <div class="p1">
                    <p id="101">(2) 计算所有少数类样本与其<i>K</i>个同类近邻的平均欧氏距离<i>d</i><sub>pave-sum</sub>:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext><mo>-</mo><mtext>s</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mrow><mi>p</mi><mi>a</mi><mi>v</mi><mi>e</mi><mo>-</mo><mi>i</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">其中,<i>m</i>表示少数类样本的数量。</p>
                </div>
                <div class="p1">
                    <p id="104">(3) 计算少数类样本集间的平均欧氏距离<i>d</i><sub>pave</sub>:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext><mo>-</mo><mtext>s</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub></mrow><mi>m</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">(4) 计算少数类样本与其<i>K</i>个多数类近邻的平均欧氏距离<i>d</i><sub><i>nave</i></sub><sub>-</sub><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>n</mi><mi>a</mi><mi>v</mi><mi>e</mi><mo>-</mo><mi>i</mi></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><msqrt><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mstyle></mrow><mi>Κ</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">其中,<i><b>x</b></i><sub><i>i</i></sub>表示当前的少数类样本,<i><b>y</b></i><sub><i>j</i></sub>表示样本<i><b>x</b></i><sub><i>i</i></sub>的第<i>j</i>个多数类近邻。</p>
                </div>
                <div class="p1">
                    <p id="109">(5) 计算所有少数类样本与其<i>K</i>个多数类近邻的平均欧氏距离<i>d</i><sub>nave-sum</sub>:</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext><mo>-</mo><mtext>s</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>d</mi></mstyle><msub><mrow></mrow><mrow><mi>n</mi><mi>a</mi><mi>v</mi><mi>e</mi><mo>-</mo><mi>i</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">其中,<i>m</i>表示少数类样本的数量。</p>
                </div>
                <div class="p1">
                    <p id="112">(6) 计算少数类样本与多数类样本间的平均欧氏距离<i>d</i><sub>nave</sub>:</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext><mo>-</mo><mtext>s</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub></mrow><mi>m</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">(7) 在合成样本的过程中,计算当前被选中的边界样本与其<i>K</i>个同类近邻的平均欧氏距离<i>d</i><sub>1</sub>。</p>
                </div>
                <div class="p1">
                    <p id="115">(8) 在合成样本的过程中,计算当前被选中的边界样本与其<i>K</i>个多数类近邻的平均欧氏距离d<sub>2</sub>。</p>
                </div>
                <div class="p1">
                    <p id="116">(9) 计算相对距离比<i>u</i>:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><mo>=</mo><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mn>1</mn></msub><mo>/</mo><mi>d</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext></mrow></msub></mrow><mrow><mi>d</mi><msub><mrow></mrow><mn>2</mn></msub><mo>/</mo><mi>d</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>a</mtext><mtext>v</mtext><mtext>e</mtext></mrow></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">(10) 根据相对距离比<i>u</i>,计算影响因素posFac的取值范围:</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mi>F</mi><mi>a</mi><mi>c</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>r</mi><mi>a</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>,</mo><mi>u</mi><mo>&lt;</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn><mo>.</mo><mn>5</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>×</mo><mi>r</mi><mi>a</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>,</mo><mn>1</mn><mo>≤</mo><mi>u</mi><mo>≤</mo><mn>2</mn></mtd></mtr><mtr><mtd><mn>0</mn><mo>.</mo><mn>8</mn><mo>+</mo><mn>0</mn><mo>.</mo><mn>2</mn><mo>×</mo><mi>r</mi><mi>a</mi><mi>n</mi><mi>d</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>,</mo><mi>u</mi><mo>&gt;</mo><mn>2</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120">其中,<i>rand</i>(0,1)表示(0,1)内的随机数,使用posFac作为样本合成的随机数的取值,该影响因素考虑了周围多数类样本的影响,可以更加合理地合成少数类样本。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121"><b>3.3 基于样本分布的SDRSMOTE算法</b></h4>
                <div class="p1">
                    <p id="122">基于样本分布的<i>SDRSMOTE</i>算法,首先根据少数类样本的支持度sd选择边界样本<i><b>x</b></i><sub><i>i</i></sub>,然后使用<i>SMOTE</i>算法选择另一个与<i><b>x</b></i><sub><i>i</i></sub>相邻的少数类样本<i><b>x</b></i><sub><i>j</i></sub>。新样本的合成公式为:</p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula">
                        <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>p</mi><mi>o</mi><mi>s</mi><mi>F</mi><mi>a</mi><mi>c</mi><mo>×</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="124">这种数据合成算法增加了边界上的少数类样本的数量,使得新样本生成过程中的随机数取值更有针对性,有效地缓解了传统<i>SMOTE</i>算法的盲目性,提高了少数类样本的分类性能。</p>
                </div>
                <div class="p1">
                    <p id="125"><i>SDRSMOTE</i>的基本步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="126"><b>Step 1</b> 将应合成的少数类样本数记为<i>Num</i>;</p>
                </div>
                <div class="p1">
                    <p id="127"><b>Step 2</b> 假定少数类样本的数量为<i>m</i>,多数类样本的数量为<i>n</i>。随机选择一个少数类样本<i><b>x</b></i><sub><i>i</i></sub>,并根据式(1)计算<i><b>x</b></i><sub><i>i</i></sub>与每个多数类样本之间的欧氏距离之和<i>S</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="128"><b>Step 3</b> 根据式(2)计算所有<i>S</i><sub><i>i</i></sub>的累加和<i>S</i>;</p>
                </div>
                <div class="p1">
                    <p id="129"><b>Step 4</b> 根据式(3)计算少数类样本和多数类样本之间的平均欧氏距离<i>S</i><sub>ave</sub>;</p>
                </div>
                <div class="p1">
                    <p id="130"><b>Step 5</b> 以<i>S</i><sub>ave</sub>为半径,依次选择每个少数类样本作为中心圈定区域,然后统计该区域中多数类样本的数量作为当前少数类样本的支持度<i>sd</i>;</p>
                </div>
                <div class="p1">
                    <p id="131"><b>Step 6</b> 根据支持度<i>sd</i>选择少数类样本进行新样本的合成,对所选样本使用SMOTE算法,根据式(11)引入影响因素<i>posFac</i>,然后根据式(12)进行合成新样本;</p>
                </div>
                <div class="p1">
                    <p id="132"><b>Step 7</b> 将新合成的少数类样本添加到数据集以参与训练和测试。</p>
                </div>
                <div class="p1">
                    <p id="133">SDRSMOTE算法在样本合成之前通过引入支持度<i>sd</i>确定边界样本的选择顺序,可以缓解传统SMOTE过采样算法随机选择边界样本的盲目性;在样本合成过程中通过综合总体样本的分布状况引入影响因素<i>posFac</i>进行新样本的合成,使得新样本合成过程中的随机数取值更有针对性;该算法可以更加合理地扩展少数类样本,使得新数据集是趋于平衡的,提高分类器对于少数类样本的分类能力。</p>
                </div>
                <h3 id="134" name="134" class="anchor-tag"><b>4 实验与分析</b></h3>
                <h4 class="anchor-tag" id="135" name="135"><b>4.1 实验对象</b></h4>
                <div class="p1">
                    <p id="136">为了评估SDRSMOTE在不平衡数据分类中的有效性,实验选取了6个分类不平衡数据集。blood、haberman、iris、breast数据集来自UCI<citation id="173" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>机器学习库,PC3、JM1来自NASA标准数据集,基本信息如表2所示。第1、2列分别表示序号、数据集名称;第3列表示特征维度,即属性个数;第4列表示样本总数,描述了数据集的规模;第5、6列分别表示少数类样本数、多数类样本数;第7列表示少数类比率即少数类样本数与总样本数的比值;第8列表示数据集的不平衡率,即多数类样本数与少数类样本数的比值,该值越大说明数据集的分类越不平衡<citation id="174" type="reference"><link href="31" rel="bibliography" /><link href="55" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表2 数据集基本信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Basic information of the data set</b></p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td>数据集</td><td>名称</td><td>特征数</td><td>样本总数</td><td>少数类样本数</td><td>多数类样本数</td><td>少数类比率/%</td><td>不平衡率/%</td></tr><tr><td><br />0</td><td>PC3</td><td>41</td><td>1 563</td><td>160</td><td>1 403</td><td>10.2</td><td>8.8</td></tr><tr><td><br />1</td><td>JM1</td><td>22</td><td>7 782</td><td>1 672</td><td>6 110</td><td>21.5</td><td>3.7</td></tr><tr><td><br />2</td><td>blood</td><td>5</td><td>748</td><td>178</td><td>570</td><td>23.8</td><td>3.2</td></tr><tr><td><br />3</td><td>haberman</td><td>4</td><td>306</td><td>81</td><td>225</td><td>26.5</td><td>2.8</td></tr><tr><td><br />4</td><td>iris</td><td>5</td><td>150</td><td>50</td><td>100</td><td>33.3</td><td>2.0</td></tr><tr><td><br />5</td><td>breast</td><td>10</td><td>699</td><td>241</td><td>458</td><td>34.5</td><td>1.9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="137" name="137"><b>4.2 实验设计</b></h4>
                <div class="p1">
                    <p id="138">实验使用开源数据挖掘工具WEAK3.6,本文研究二分类问题,因此将多分类所用的数据集转化为二分类数据集,所用的数据集如表2所示。分别使用SMOTE算和SDRSMOTE算法在选取的数据集上进行过采样,其中邻域值<i>K</i>取5,少数类样本插值倍频<i>N</i>取1.2。在新数据集上分别使用具有代表性的经典分类算法决策树(J48)、朴素贝叶斯以及集成分类算法AdaBoost、Bagging,采用十折交叉验证进行预测。对不平衡数据集分类效果的评价指标使用<i>F</i>-<i>value</i>、<i>G</i>-<i>mean</i>和<i>AUC</i>,验证对比传统SMOTE和SDRSMOTE算法生成少数类样本的合理性。</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139"><b>4.3 实验结果与分析</b></h4>
                <div class="p1">
                    <p id="140">使用改进前的SMOTE和改进后的SDRSMOTE算法对数据集进行过采样处理后,再分别使用决策树(J48)、AdaBoost、Bagging、朴素贝叶斯NB(Naive Bayes)4种算法进行分类,得到分类后的<i>F</i>-<i>value</i>、<i>G</i>-<i>mean</i>和<i>AUC</i>值,结果如表3～表5所示,为了便于比较,采用“加粗”来标记在同一种分类模型下经过SDRSMOTE过采样后的性能优于SMOTE的数值。</p>
                </div>
                <div class="p1">
                    <p id="141">从表3可以看出,采用AdaBoost对6个不平衡数据集分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>F</i>-<i>value</i>的均值提高了0.014,平均提高1.76%,效果最好;采用决策树分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>F</i>-<i>value</i>的均值提高了0.009,平均提高1.1%;采用Bagging分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>F</i>-<i>value</i>的均值提高了0.005,平均提高0.59%;采用朴素贝叶斯分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>F</i>-<i>value</i>的均值提高了0.004,平均提高0.57%。使用SDRSMOTE算法结合决策树、AdaBoost、Bagging、朴素贝叶斯分类器上对不平衡数据集PC3、JM1、blood、haberman、iris、breast进行预测,<i>F</i>-<i>value</i>均值明显提高,其中在AdaBoost分类器上效果最为显著。</p>
                </div>
                <div class="area_img" id="143">
                                            <p class="img_tit">
                                                <b>表3 各个预测模型在6个数据集上的</b><i><b>F</b></i><b>-</b><i><b>value</b></i><b>值</b>
                                                    <br />
                                                <b>Table 3 </b><i><b>F</b></i><b>-</b><i><b>value</b></i><b> of each prediction model on 6 data sets</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911023_14300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJK201911023_14300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911023_14300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 各个预测模型在6个数据集上的F-value值" src="Detail/GetImg?filename=images/JSJK201911023_14300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="147">从表4可以看出,采用AdaBoost对6个不平衡数据集分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>G</i>-<i>mean</i>的均值提高了0.014,平均提高1.83%,效果最好;采用决策树分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>G</i>-<i>mean</i>的均值提高了0.01,平均提高1.25%;采用Bagging分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>G</i>-<i>mean</i>的均值提高了0.011,平均提高1.36%;采用朴素贝叶斯分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>G</i>-<i>mean</i>的均值提高了0.005,平均提高0.71%。使用SDRSMOTE算法结合决策树、AdaBoost、Bagging、朴素贝叶斯分类器上对不平衡数据集PC3、JM1、blood、haberman、iris、breast进行预测,<i>G</i>-<i>mean</i>均值明显提高,其中在AdaBoost分类器上效果最为显著。</p>
                </div>
                <div class="area_img" id="144">
                                            <p class="img_tit">
                                                <b>表4 各个预测模型在6个数据集上的</b><i><b>G</b></i><b>-</b><i><b>mean</b></i><b>值</b>
                                                    <br />
                                                <b>Table 4 </b><i><b>G</b></i><b>-</b><i><b>mean</b></i><b> of each prediction model on 6 data sets</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911023_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJK201911023_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911023_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 各个预测模型在6个数据集上的G-mean值" src="Detail/GetImg?filename=images/JSJK201911023_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="148">从表5可以看出,采用AdaBoost对6个不平衡数据集分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>AUC</i>的均值提高了0.011,平均提高1.32%,效果最好;采用决策树分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>AUC</i>的均值提高了0.007,平均提高0.85%;采用Bagging分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>AUC</i>的均值提高了0.005,平均提高0.56%;采用朴素贝叶斯分类时,SDRSMOTE算法与SMOTE算法相比,在6个数据集上<i>AUC</i>的均值提高了0.008,平均提高1.01%。使用SDRSMOTE算法结合决策树、AdaBoost、Bagging、朴素贝叶斯分类器上对不平衡数据集PC3、JM1、blood、haberman、iris、breast进行预测,<i>AUC</i>均值明显提高,其中在AdaBoost分类器上效果最为显著。</p>
                </div>
                <div class="area_img" id="145">
                                            <p class="img_tit">
                                                <b>表5 各个预测模型在6个数据集上的</b><i><b>AUC</b></i><b>值</b>
                                                    <br />
                                                <b>Table 5 </b><i><b>AUC</b></i><b> of each prediction model on 6 data sets</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911023_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJK201911023_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911023_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 各个预测模型在6个数据集上的AUC值" src="Detail/GetImg?filename=images/JSJK201911023_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="149">综合表3～表5的<i>F</i>-<i>value</i>、<i>G</i>-<i>mean</i>和<i>AUC</i>值发现,SDRSMOTE算法与AdaBoost分类器结合后的分类性能提升最为明显。</p>
                </div>
                <div class="p1">
                    <p id="150">采用AdaBoost分类器对经过SMOTE和SDRSMOTE过采样算法处理的数据集进行分类,图2～图4分别列出了评价指标<i>F</i>-<i>value</i>、<i>G</i>-<i>mean</i>和<i>AUC</i>对比结果。图2显示这些数据集经SDRSMOTE过采样处理后,AdaBoost分类器的<i>F</i>-<i>value</i>值普遍高于经SMOTE处理的<i>F</i>-<i>value</i>值,在数据集JM1上尤其明显。图3的柱状图显示,这些数据集经SDRSMOTE过采样处理后,AdaBoost分类器的<i>G</i>-<i>mean</i>值普遍高于经SMOTE处理的<i>G</i>-<i>mean</i>值,在数据集JM1、haberman上非常明显。从图4中可以清楚地看到,当数据集是PC3、JM1、blood、haberman时,SDRSMOTE与AdaBoost结合的<i>AUC</i>值明显高于SMOTE与AdaBoost结合的<i>AUC</i>值;而在数据集iris、breast上2种模型的<i>AUC</i>值不相上下。综上所述,将AdaBoost作为不平衡数据集的预测模型时,SDRSMOTE的实验结果明显优于SMOTE的。</p>
                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911023_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的F-value值" src="Detail/GetImg?filename=images/JSJK201911023_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的<i>F</i>-<i>value</i>值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911023_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 <i>F</i>-<i>value</i> for SMOTE+AdaBoost and SDRSMOTE+AdaBoost</p>

                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911023_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的G-mean值" src="Detail/GetImg?filename=images/JSJK201911023_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的<i>G</i>-<i>mean</i>值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911023_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 <i>G</i>-<i>mean</i> for SMOTE+AdaBoost and SDRSMOTE+AdaBoost</p>

                </div>
                <div class="area_img" id="153">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911023_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的AUC值" src="Detail/GetImg?filename=images/JSJK201911023_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 SMOTE+AdaBoost和SDRSMOTE+AdaBoost的<i>AUC</i>值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911023_153.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 <i>AUC</i> for SMOTE+AdaBoost and SDRSMOTE+AdaBoost</p>

                </div>
                <div class="p1">
                    <p id="154">综合评价指标<i>F</i>-<i>value</i>、<i>G</i>-<i>mean</i>、<i>AUC</i>来看,SDRSMOTE算法优于SMOTE算法,在AdaBoost分类器上性能提高尤为显著,即SDRSMOTE算法与该分类器结合使用效果最好。</p>
                </div>
                <h3 id="155" name="155" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="156">本文提出的SDRSMOTE算法,在样本合成之前通过引入支持度<i>sd</i>确定边界样本的选择顺序,在样本合成时通过引入影响因素<i>posFac</i>对随机数进行精细控制。它不仅可以避免传统SMOTE过采样算法选择边界样本的盲目性,而且还综合考虑了总体样本的分布状况。实验结果表明,该算法相比传统SMOTE过采样算法,在合成少数类样本时更加合理,有利于提高少数类的分类性能。但提出的SDRSMOTE算法增加了算法的时间复杂度,因此算法还需要进一步优化,以提高运行效率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="178" type="formula" href="images/JSJK201911023_17800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">李克文</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="5">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 Ye Feng,Ding Feng.Research and application of unbalanced data classification[J].Computer Applications and Software,2018,35(1):132-136.(in Chinese)
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Support vector machine based classification algorithms research for imbalanced data">

                                <b>[2]</b> Liu Dong-qi.Support vector machine based classification algorithms research for imbalanced data[D].Hangzhou:Zhejiang University,2017.(in Chinese)
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">

                                <b>[3]</b> Chawla N V,Bowyer K W,Hall L O,et al.SMOTE:Synthetic minority over-sampling technique[J].Journal of Artificial Intelligence Research,2002,16(1):321-357.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Managing imbalanced data sets in multi-label problems:A case study with the SMOTE algorithm">

                                <b>[4]</b> Giraldo-Forero A F,Jaramillo-Garzón J A,Ruiz-Muňoz J F,et al.Managing imbalanced data sets in multi-label problems:A case study with the SMOTE algorithm[C]//Proc of the 18th Iberoamerican Congress on Progress in Pattern Recognition,Image Analysis,Computer Vision,and Application,2013:334-342.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 Gu Ping,Ouyang Yuan-you.Classification research for unbalanced data based on mixed-sampling[J].Application Research of Computers,2015,32(2):379-381.(in Chinese)
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An empirical analysis of under-sampling techniques to balance a protein structural class dataset">

                                <b>[6]</b> Souto M C P D,Bittencourt V G,Costa J A F.An empirical analysis of under-sampling techniques to balance a protein structural class dataset[J].Lecture Notes in Computer Science,2006,4234:21-29.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving Identification of Difficult Small Classes by Balancing Class Distribution">

                                <b>[7]</b> Laurikkala J.Improving identification of difficult small classes by balancing class distribution[C]//Proc of Conference on AI in Medicine in Europe:Artificial Intelligence Medicine,2001:63-66.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dual Discriminator Generative Adversarial Nets">

                                <b>[8]</b> Nguyen T D,Le T,Vu H,et al.Dual Discriminator Generative Adversarial Nets[C]//Proc of the 31th Conference of Neural Information Processing Systems,2017:2671-2681.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 Xu Li-li Yan De-qin.Weighted ensemble learning algorithm for imbalanced data sets[J].Microcomputer &amp; its Applications,2015,34(23):7-10.(in Chinese)
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A comparative analysis of techniques for predicting academic performance">

                                <b>[10]</b> Nghe N T,Janecek P,Haddawy P.A comparative analysis of techniques for predicting academic performance[C]//Proc of the 37th IEEE Frontiers in Education Conference-global Engineering:Knowledge Without Borders,2007:7-12.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201712051&amp;v=MDk5NzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIzT0x6N1NaTEc0SDliTnJZOUFaWVE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Feng Hua-min,Li Ming-wei,Hou Xiao-lian,et al.Study of network intrusion detection method based on SMOTE and GBDT[J].Application Research of Computers,2017,34(12):3745-3748.(in Chinese)
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 Wei Hao,Li Hong,Liu Xiao-yu.An improved SMOTE algorithm[J].Henan Science,2018,36(7):1009-1013.(in Chinese)
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201509049&amp;v=MTM0MzJGeS9nVXIzT0x6N0JiN0c0SDlUTXBvOUJiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm0=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Li Ke-wen,Yang Lei,Liu Wen-ying,et al.Classification method of imbalanced data based on RSBoost[J].Computer Science,2015,42(9):249-252.(in Chinese)
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201804005&amp;v=MTA4MjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIzT0x6N0Jkckc0SDluTXE0OUZZWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Yu Qiao,Jiang Shu-juan,Zhang Yan-mei,et al.The impact study of class imbalance on the performance of software defect prediction models[J].Chinese Journal of Computers,2018,41(4):809-824.(in Chinese)
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600741778&amp;v=MTc1OTNlWnVIeWptVUxmSUoxc1ZhQlE9TmlmT2ZiSzdIdEROcVk5RlkrOE9DM3N4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Bradley A P.The use of the area under the ROC curve in the evaluation of machine learning algorithms[J].Pattern Recognition,1997,30(7):1145-1159.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using AUC and Accuracy in Evaluating Learning Algorithms">

                                <b>[16]</b> Huang J,Ling C X.Using AUC and accuracy in evaluating learning algorithms[J].IEEE Transactions on Knowledge &amp; Data Engineering,2005,17(3):299-310.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An improved SMOTE imbalanced data classification method based on support degree">

                                <b>[17]</b> Li K,Zhang W,Lu Q,et al.An improved SMOTE imbalanced data classification method based on support degree[C]//Proc of International Conference on Identification,2014:34-38.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 Center for Machine Learning and Intelligent Systems.UCI machine learning repository[DB/OL].[2018-04-09].http://archive.ics.uci.edu/ml/datasets.html.附中文参考文献:
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801024&amp;v=MTU3OTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIzT0x6VFpaTEc0SDluTXJvOUhZSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 叶枫,丁锋.不平衡数据分类研究及其应用[J].计算机应用与软件,2018,35(1):132-136.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017054620.nh&amp;v=MDE1MThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1VyM09WRjI2R2JPOUd0Zk9yNUViUEk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 刘东启.基于支持向量机的不平衡数据分类算法研究[D].杭州:浙江大学,2017.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201502015&amp;v=MTIwNzFNclk5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVcjNPTHo3U1pMRzRIOVQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 古平,欧阳源遊.基于混合采样的非平衡数据集分类研究[J].计算机应用研究,2015,32(2):379-381.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201523003&amp;v=MDcwNTR6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIzT01qWEJkN0c0SDlUT3JJOUZaNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 徐丽丽,闫德勤.不平衡数据加权集成学习算法[J].微型机与应用,2015,34(23):7-10.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 封化民,李明伟,侯晓莲,等.基于SMOTE和GBDT的网络入侵检测方法研究[J].计算机应用研究,2017,34(12):3745-3748.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNKX201807005&amp;v=MDUzOTdyM09MU1BBZHJHNEg5bk1xSTlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 魏浩,李红,刘小豫.一种改进的SMOTE算法[J].河南科学,2018,36(7):1009-1013.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 李克文,杨磊,刘文英,等.基于RSBoost算法的不平衡数据分类方法[J].计算机科学,2015,42(9):249-252.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 于巧,姜淑娟,张艳梅,等.分类不平衡对软件缺陷预测模型性能的影响研究[J].计算机学报,2018,41(4):809-824.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201911023" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911023&amp;v=MTk3MjdlWmVSbUZ5L2dVcjNPTHo3QlpiRzRIOWpOcm85SFo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
