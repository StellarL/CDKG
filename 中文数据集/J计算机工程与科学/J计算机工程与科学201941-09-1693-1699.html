<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132358288467500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201909024%26RESULT%3d1%26SIGN%3dtbGqeeGaTZqJdaqKT1yATJzJ7qI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201909024&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201909024&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201909024&amp;v=MjI5NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdrVWJyQUx6N0JaYkc0SDlqTXBvOUhZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#67" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="&lt;b&gt;2 相关知识&lt;/b&gt; "><b>2 相关知识</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#72" data-title="&lt;b&gt;2.1 粒计算&lt;/b&gt;"><b>2.1 粒计算</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;2.2 传统k-prototypes聚类算法&lt;/b&gt;"><b>2.2 传统k-prototypes聚类算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;3 算法优化&lt;/b&gt; "><b>3 算法优化</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#97" data-title="&lt;b&gt;3.1 混合属性样本的相似度&lt;/b&gt;"><b>3.1 混合属性样本的相似度</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;3.2 粒子密度&lt;/b&gt;"><b>3.2 粒子密度</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;3.3 构造粗粒子集&lt;/b&gt;"><b>3.3 构造粗粒子集</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;3.4 更新聚类中心&lt;/b&gt;"><b>3.4 更新聚类中心</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;3.5 目标函数&lt;/b&gt;"><b>3.5 目标函数</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;3.6 Gk-prototypes聚类算法具体步骤&lt;/b&gt;"><b>3.6 Gk-prototypes聚类算法具体步骤</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#138" data-title="&lt;b&gt;4 实验结果及分析&lt;/b&gt; "><b>4 实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#140" data-title="&lt;b&gt;4.1 18维混合属性数据集实验&lt;/b&gt;"><b>4.1 18维混合属性数据集实验</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;4.2 UCI标准数据集实验&lt;/b&gt;"><b>4.2 UCI标准数据集实验</b></a></li>
                                                <li><a href="#153" data-title="&lt;b&gt;4.3 算法分析&lt;/b&gt;"><b>4.3 算法分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#155" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#142" data-title="图1 2种算法在18维混合属性数据集上的聚类效果图">图1 2种算法在18维混合属性数据集上的聚类效果图</a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;表1 2种算法聚类平均准确率比较&lt;/b&gt;"><b>表1 2种算法聚类平均准确率比较</b></a></li>
                                                <li><a href="#145" data-title="图2 2种算法聚类结果的&lt;i&gt;ARI&lt;/i&gt;指数图">图2 2种算法聚类结果的<i>ARI</i>指数图</a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;表2 实验采用的数据集&lt;/b&gt;"><b>表2 实验采用的数据集</b></a></li>
                                                <li><a href="#150" data-title="&lt;b&gt;表3 各算法的聚类平均准确率比较&lt;/b&gt;"><b>表3 各算法的聚类平均准确率比较</b></a></li>
                                                <li><a href="#151" data-title="图3 各算法聚类结果的&lt;i&gt;ARI&lt;/i&gt;指数图">图3 各算法聚类结果的<i>ARI</i>指数图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="232">


                                    <a id="bibliography_1" title=" Hsu C C,Huang Y P.Incremental clustering of mixed data based on distance hierarchy[J].Expert Systems with Applications:An International Journal,2008,35(3):1177-1185." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501643028&amp;v=MTAzMjNtVUxmSUpsOFdieG89TmlmT2ZiSzdIdEROcW85RVl1OE1ESDR4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Hsu C C,Huang Y P.Incremental clustering of mixed data based on distance hierarchy[J].Expert Systems with Applications:An International Journal,2008,35(3):1177-1185.
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_2" title=" Hsu C C,Lin S H,Tai W S.Apply extended self-organizing map to cluster and classify mixed-type data[J].Neurocomputing,2011,74(18):3832-3842." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911120&amp;v=MTA1NjI0NW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsOFdieG89TmlmT2ZiSzdIdEROcW85RWJlb09EWA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Hsu C C,Lin S H,Tai W S.Apply extended self-organizing map to cluster and classify mixed-type data[J].Neurocomputing,2011,74(18):3832-3842.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_3" title=" Huang Z X.Clustering large data sets with mixed numeric and categorical values[C]//Proc of the 1st Pacific-Asia Conference on Knowledge Discovery and Data Mining,1997:21-34." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering Large Data Sets with Mixed Numeric and Categorical Values">
                                        <b>[3]</b>
                                         Huang Z X.Clustering large data sets with mixed numeric and categorical values[C]//Proc of the 1st Pacific-Asia Conference on Knowledge Discovery and Data Mining,1997:21-34.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_4" title=" Sangam R S,Om H.An equi-biased k-prototypes algorithm for clustering mixed-type data[J].Sādhanā,2018,43(3):37-49." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An equi-biased k-prototypes algorithm for clustering mixed-type data">
                                        <b>[4]</b>
                                         Sangam R S,Om H.An equi-biased k-prototypes algorithm for clustering mixed-type data[J].Sādhanā,2018,43(3):37-49.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_5" title=" Ji J C,Bai T,Zhou C G,et al.An improved k-prototypes clustering algorithm for mixed numeric and categorical data[J].Neurocomputing,2013,120(10):590-596." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES959D989A1159D3805B9013BD9D3B44CF&amp;v=MTU5OTUzNU5CaHdybTl4YUE9TmlmT2ZicTlGNlhGcDRZMFplb0tCUWc2eHhZV21EWjlTWHlRMkJ0QmVzQ1FRY25wQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Ji J C,Bai T,Zhou C G,et al.An improved k-prototypes clustering algorithm for mixed numeric and categorical data[J].Neurocomputing,2013,120(10):590-596.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_6" title=" Chen Ning,Chen An,Zhou Long-xiang .Fuzzy K-Prototypes algorithm for clustering mixed numeric and categorical valued data[J].Journal of Software,2001,12(8):1107-1119." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200108000&amp;v=MjI4MzJPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2tVYnJBTnlmVGJMRzRIdERNcDQ5RlpJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Chen Ning,Chen An,Zhou Long-xiang .Fuzzy K-Prototypes algorithm for clustering mixed numeric and categorical valued data[J].Journal of Software,2001,12(8):1107-1119.
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_7" title=" Herawan T,Deris M M,Abawajy J H.A rough set approach for selecting clustering attribute[J].Knowledge-Based Systems,2010,23(3):220-231." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501719412&amp;v=MjExNTZIdEROcW85RVkrb0dDSDA3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmw4V2J4bz1OaWZPZmJLNw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Herawan T,Deris M M,Abawajy J H.A rough set approach for selecting clustering attribute[J].Knowledge-Based Systems,2010,23(3):220-231.
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_8" title=" Chiang J H,Hao P Y.A new kernel-based fuzzy clustering approach:Support vector clustering with cell growing[J].IEEE Transactions on Fuzzy Systems,2003,11(4):518-527." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new kernel-based fuzzy clustering approach: support vector clustering with cell growing">
                                        <b>[8]</b>
                                         Chiang J H,Hao P Y.A new kernel-based fuzzy clustering approach:Support vector clustering with cell growing[J].IEEE Transactions on Fuzzy Systems,2003,11(4):518-527.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_9" title=" Yao Y J,Sun Y,Yao Y J,et al.An anonymous algorithm for hierarchical clustering based on k-prototypes[C]//Proc of the 2016 4th International Conference on Machinery,Materials and Information Technology Applications,2017:1586-1591." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An anonymous algorithm for hierarchical clustering based on k-prototypes">
                                        <b>[9]</b>
                                         Yao Y J,Sun Y,Yao Y J,et al.An anonymous algorithm for hierarchical clustering based on k-prototypes[C]//Proc of the 2016 4th International Conference on Machinery,Materials and Information Technology Applications,2017:1586-1591.
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_10" title=" Cao F Y,Huang J Z,Liang J Y,et al.An algorithm for clustering categorical data with set-valued features[J].IEEE Transactions on Neural Networks &amp;amp; Learning Systems,2018,29(10):4593-4604." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An algorithm for clustering categorical data with set-valued features">
                                        <b>[10]</b>
                                         Cao F Y,Huang J Z,Liang J Y,et al.An algorithm for clustering categorical data with set-valued features[J].IEEE Transactions on Neural Networks &amp;amp; Learning Systems,2018,29(10):4593-4604.
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_11" title=" Ding S,Xu L,Zhu H,et al.Research and progress of cluster algorithms based on Granular computing[J].International Journal of Digital Content Technology and its Applications,2010,4(5):96-104." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00003386298&amp;v=MTYyNTA3S0pWWT1OajNhYXJPNEh0SFBySWREWnVJSFkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNEbFZi&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Ding S,Xu L,Zhu H,et al.Research and progress of cluster algorithms based on Granular computing[J].International Journal of Digital Content Technology and its Applications,2010,4(5):96-104.
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_12" title=" Panoutsos G,Mahfouf M.A neural-fuzzy modelling framework based on granular computing:Concepts and applications[J].Fuzzy Sets &amp;amp; Systems,2010,161(21):2808-2830." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300670531&amp;v=MDI5NjRlcnFRVE1ud1plWnVIeWptVUxmSUpsOFdieG89TmlmT2ZiSzdIdERPckk5Rll1d1BDWDg0b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Panoutsos G,Mahfouf M.A neural-fuzzy modelling framework based on granular computing:Concepts and applications[J].Fuzzy Sets &amp;amp; Systems,2010,161(21):2808-2830.
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_13" title=" Panoutsos G,Mahfouf M.An incremental learning structure using granular computing and model fusion with application to materials processing[C]//Proc of International IEEE Conference on Intelligent Systems,2008:139-153." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An incremental learning structure using granular computing and model fusion with application to materials processing">
                                        <b>[13]</b>
                                         Panoutsos G,Mahfouf M.An incremental learning structure using granular computing and model fusion with application to materials processing[C]//Proc of International IEEE Conference on Intelligent Systems,2008:139-153.
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_14" title=" Kacem M A B H,N’Cir C E B,Essoussi N.MapReduce-based k-prototypes clustering method for big data[C]//Proc of IEEE International Conference on Data Science and Advanced Analytics,2015:1-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MapReduce-Based K-Prototypes Clustering Method for Big Data">
                                        <b>[14]</b>
                                         Kacem M A B H,N’Cir C E B,Essoussi N.MapReduce-based k-prototypes clustering method for big data[C]//Proc of IEEE International Conference on Data Science and Advanced Analytics,2015:1-7.
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_15" title=" Hajkacem M A B,Chiheb E B N,Essoussi N.KP-S:A Spark-based design of the k-prototypes clustering for big data[C]//Proc of ACS/IEEE International Conference on Computer Systems and Applications,2017:557-563." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=KP-S:A Spark-based design of the k-prototypes clustering for big data">
                                        <b>[15]</b>
                                         Hajkacem M A B,Chiheb E B N,Essoussi N.KP-S:A Spark-based design of the k-prototypes clustering for big data[C]//Proc of ACS/IEEE International Conference on Computer Systems and Applications,2017:557-563.
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     Qian Xian,Huang Xuan-jing,Wu Li-de.A Spectral method of K-means initialization[J].Acta Automatica Sinica,2007,33(4):342-346.(in Chinese)</a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_17" title=" Wang Ling,Bo Lie-feng,Jiao Li-cheng.Density-sensitive spectral clustering[J].Acta Electronica Sinica,2007,35(8):1577-1581.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200708030&amp;v=MjE3MzM0OUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdrVWJyQUlUZlRlN0c0SHRiTXA=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Wang Ling,Bo Lie-feng,Jiao Li-cheng.Density-sensitive spectral clustering[J].Acta Electronica Sinica,2007,35(8):1577-1581.(in Chinese)
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_18" title=" Wang Zhong,Liu Gui-quan,Chen En-hong.A K-means algorithm based on optimized initial center points[J].Pattern Recognition and Artificial Intelligence,2009,22(2):299-304.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB200902020&amp;v=MzI3MDhIdGpNclk5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2tVYnJBS0Q3WWJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Wang Zhong,Liu Gui-quan,Chen En-hong.A K-means algorithm based on optimized initial center points[J].Pattern Recognition and Artificial Intelligence,2009,22(2):299-304.(in Chinese)
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_19" title=" Gou Guang-lei,Huang Li-feng,Ni Wei.Conceptual clustering algorithm based on granular compuing[J].Journal of Chongqing University of Technology,2013,27(6):76-79.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGGL201306018&amp;v=MzE2NTZxQnRHRnJDVVJMT2VaZVJtRnk3a1VickFKaXJNWXJHNEg5TE1xWTlFYklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Gou Guang-lei,Huang Li-feng,Ni Wei.Conceptual clustering algorithm based on granular compuing[J].Journal of Chongqing University of Technology,2013,27(6):76-79.(in Chinese)
                                    </a>
                                </li>
                                <li id="270">


                                    <a id="bibliography_20" title=" An Qiu-sheng,Shen Jun-yi,Wang Guo-yin.A clustering method based on information granularity and rough sets[J].Pattern Recognition &amp;amp; Artificial Intelligence,2003,16(4):412-417.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB200304005&amp;v=MDgxMDNZYkxHNEh0TE1xNDlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3a1VickFLRDc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         An Qiu-sheng,Shen Jun-yi,Wang Guo-yin.A clustering method based on information granularity and rough sets[J].Pattern Recognition &amp;amp; Artificial Intelligence,2003,16(4):412-417.(in Chinese)
                                    </a>
                                </li>
                                <li id="272">


                                    <a id="bibliography_21" title=" Yao Yi-yu.Notes on rough set approximations and associated measures[J].Journal of Zhejiang Ocean University(Natural Science),2010,29(5):399-410." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=REEF201005003&amp;v=MDEzMDJDVVJMT2VaZVJtRnk3a1VickFOeWpPYUxHNEg5SE1xbzlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         Yao Yi-yu.Notes on rough set approximations and associated measures[J].Journal of Zhejiang Ocean University(Natural Science),2010,29(5):399-410.
                                    </a>
                                </li>
                                <li id="274">


                                    <a id="bibliography_22" >
                                        <b>[22]</b>
                                     Xie Juan-ying,Lu Xiao-xiao,Qu Ya-nan,et al.K-medoids clustering algorithm with optimized initial seeds by granular computing[J].Journal of Frontiers of Computer Science &amp;amp; Technology,2015,9(5):611-620.(in Chinese)</a>
                                </li>
                                <li id="276">


                                    <a id="bibliography_23" title=" Gao Xin-bo.Fuzzy cluster analysis and its application[M].Xi’an:Xidian University Press,2004:42-46.(in Chinese)" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fuzzy cluster analysis and its application">
                                        <b>[23]</b>
                                         Gao Xin-bo.Fuzzy cluster analysis and its application[M].Xi’an:Xidian University Press,2004:42-46.(in Chinese)
                                    </a>
                                </li>
                                <li id="278">


                                    <a id="bibliography_24" title=" Huang Z X,Ng M.A fuzzy k-modes algorithm for clustering categorical data[J].IEEE Transactions on Fuzzy Systems,1999,7(4):446-452." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A fuzzy k-modes algorithm for clustering categorical data">
                                        <b>[24]</b>
                                         Huang Z X,Ng M.A fuzzy k-modes algorithm for clustering categorical data[J].IEEE Transactions on Fuzzy Systems,1999,7(4):446-452.
                                    </a>
                                </li>
                                <li id="280">


                                    <a id="bibliography_25" title=" Hubert L,Arabie P.Comparing partitions[J].Journal of Classification,1985,2(1):193-218.附中文参考文献:" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00000725207&amp;v=MjIzMjF1ZHRGQ0RsVmI3S0pWWT1OajdCYXJPNEh0SE1xSTFBWnVzSVkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVi&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         Hubert L,Arabie P.Comparing partitions[J].Journal of Classification,1985,2(1):193-218.附中文参考文献:
                                    </a>
                                </li>
                                <li id="282">


                                    <a id="bibliography_16" title=" 钱线,黄萱菁,吴立德.初始化K-means的谱方法[J].自动化学报,2007,33(4):342-346." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO200704002&amp;v=MTM3MjZPZVplUm1GeTdrVWJyQUtDTGZZYkc0SHRiTXE0OUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         钱线,黄萱菁,吴立德.初始化K-means的谱方法[J].自动化学报,2007,33(4):342-346.
                                    </a>
                                </li>
                                <li id="284">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     王玲,薄列峰,焦李成.密度敏感的谱聚类[J].电子学报,2007,35(8):1577-1581.</a>
                                </li>
                                <li id="286">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     汪中,刘贵全,陈恩红.一种优化初始中心点的K-means算法[J].模式识别与人工智能,2009,22(2):299-304.</a>
                                </li>
                                <li id="288">


                                    <a id="bibliography_19" >
                                        <b>[19]</b>
                                     苟光磊,黄丽丰,倪伟.基于粒计算的概念聚类算法[J].重庆理工大学学报(自然科学),2013,27(6):76-79.</a>
                                </li>
                                <li id="290">


                                    <a id="bibliography_20" >
                                        <b>[20]</b>
                                     安秋生,沈钧毅,王国胤.基于信息粒度与Rough集的聚类方法研究[J].模式识别与人工智能,2003,16(4):412-417.</a>
                                </li>
                                <li id="292">


                                    <a id="bibliography_22" title=" 谢娟英,鲁肖肖,屈亚楠,等.粒计算优化初始聚类中心的K-medoids聚类算法[J].计算机科学与探索,2015,9(5):611-620." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201505013&amp;v=MTg1MTA1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3a1VickFMalhmZmJHNEg5VE1xbzlFWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         谢娟英,鲁肖肖,屈亚楠,等.粒计算优化初始聚类中心的K-medoids聚类算法[J].计算机科学与探索,2015,9(5):611-620.
                                    </a>
                                </li>
                                <li id="294">


                                    <a id="bibliography_23" title=" 高新波.模糊聚类分析及其应用[M].西安:西安电子科技大学出版社,2004:42-46." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007560613012999&amp;v=MTY4MzkrSHRmTnJJOUVadUlHQlJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3Z0VTduSklsc2NWVjI3R2Jh&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         高新波.模糊聚类分析及其应用[M].西安:西安电子科技大学出版社,2004:42-46.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(09),1693-1699 DOI:10.3969/j.issn.1007-130X.2019.09.023            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种有效的Gk-prototypes聚类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%98%A0%E6%B1%9F&amp;code=42876325&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭映江</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E8%94%9A%E9%B8%BF&amp;code=06487788&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐蔚鸿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%B2%85%E6%B6%9B&amp;code=06474200&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈沅涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%96%87%E6%B3%BD%E6%9E%97&amp;code=42876326&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文泽林</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%B2%99%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E9%80%9A%E4%BF%A1%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0175884&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长沙理工大学计算机与通信工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统的聚类算法对初始聚类中心敏感、只能对单一属性聚类且聚类效果有时欠佳等不足,提出了一种能处理数值属性和分类属性的Gk-prototypes聚类算法。在经典的k-prototypes聚类算法的基础上,利用去模糊相似矩阵来构造粗粒子集,结合粒计算和最大最小距离法确定初始聚类中心,并改进了目标函数。实验结果和理论分析表明,Gk-prototypes聚类算法与其他基于k-prototypes的改进算法相比,聚类更准确,有效性更好,鲁棒性更强。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=k-prototypes%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">k-prototypes聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E6%A8%A1%E7%B3%8A%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去模糊相似矩阵;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B2%92%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">粒计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%80%E5%A4%A7%E6%9C%80%E5%B0%8F%E8%B7%9D%E7%A6%BB%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">最大最小距离法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郭映江（1995-），女，湖南湘潭人，硕士生，研究方向为智能信息处理。E-mail:gyj25@stu.csust.edu.cn,通信地址：410114湖南省长沙市天心区万家丽南路二段960号长沙理工大学计算机与通信工程学院&lt;image id="222" type="formula" href="images/JSJK201909024_22200.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    徐蔚鸿（1963-），男，湖南长沙人，博士，教授，研究方向为人工智能。E-mail:xwhxd@163.com,通信地址：410114湖南省长沙市天心区万家丽南路二段960号长沙理工大学计算机与通信工程学院&lt;image id="224" type="formula" href="images/JSJK201909024_22400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    陈沅涛（1980-），男，湖南长沙人，博士，副教授，研究方向为计算机图形学和图像处理。E-mail:12129580@qq.com,通信地址：410114湖南省长沙市天心区万家丽南路二段960号长沙理工大学计算机与通信工程学院&lt;image id="226" type="formula" href="images/JSJK201909024_22600.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    文泽林（1993-），男，湖南永州人，硕士生，研究方向为人工智能。E-mail:745529549@qq.com,通信地址：410114湖南省长沙市天心区万家丽南路二段960号长沙理工大学计算机与通信工程学院&lt;image id="228" type="formula" href="images/JSJK201909024_22800.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61702052);</span>
                                <span>湖南省科技服务平台专项(2012TP1001);</span>
                                <span>湖南省教育厅重点项目(17A007);</span>
                                <span>综合交通运输大数据智能处理湖南省重点实验室项目(2015TP1005);</span>
                                <span>长沙市科技计划项目(KQ1703018,KQ1706064);</span>
                    </p>
            </div>
                    <h1><b>A novel Gk-prototypes clustering algorithm</b></h1>
                    <h2>
                    <span>GUO Ying-jiang</span>
                    <span>XU Wei-hong</span>
                    <span>CHEN Yuan-tao</span>
                    <span>WEN Ze-lin</span>
            </h2>
                    <h2>
                    <span>School of Computer and Communication Engineering,Changsha University of Science &amp; Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Traditional clustering algorithms are sensitive to initial clustering centers, and their clustering effect is sometimes poor. For these reasons, we present a Gk-prototypes clustering algorithm to process numerical properties and classification properties. Based on the classical k-prototypes clustering algorithm, the proposed algorithm uses the de-fuzzy similarity matrix to construct coarse particle sets, and employs particle calculation and the maximum and minimum distance method to determine the initial clustering center, thus the objective function is improved. Experimental results and theoretical analysis show that the Gk-prototypes clustering algorithm is more accurate, more effective and more robust than other improved algorithms based on k-prototypes.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=k-prototypes%20clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">k-prototypes clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=de-fuzzy%20similarity%20matrix&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">de-fuzzy similarity matrix;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=granular%20computing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">granular computing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=maximum%20minimum%20distance%20method&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">maximum minimum distance method;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    GUO Ying-jiang,born in 1995,MS candidate,her research interest includes intelligent information processing.Address:School of Computer and Communication Engineering,Changsha University of Science and Technology,960Second Section, Wanjiali South Road,Tianxin District,Changsha 410114,Hunan,P.R.China;
                                </span>
                                <span>
                                    XU Wei-hong,born in 1963,PhD,professor,his research interest includes artificial intelligence.Address:School of Computer and Communication Engineering,Changsha University of Science and Technology,960Second Section, Wanjiali South Road,Tianxin District,Changsha 410114,Hunan,P.R.China;
                                </span>
                                <span>
                                    CHEN Yuan-tao,born in 1980,PhD, associate professor,his research interests include computer graphics,and image processing.Address:School of Computer and Communication Engineering,Changsha University of Science and Technology,960Second Section, Wanjiali South Road,Tianxin District,Changsha 410114,Hunan,P.R.China;
                                </span>
                                <span>
                                    WEN Ze-lin,born in 1993,MS candidate,his research interest includes artificial intelligence.Address:School of Computer and Communication Engineering,Changsha University of Science and Technology,960Second Section, Wanjiali South Road,Tianxin District,Changsha 410114,Hunan,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-03</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="67" name="67" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="68">聚类分析是数据挖掘、模式识别、系统预测等领域中的一种常用技术。它将数据对象划分成多个簇,同簇内对象之间具有高相似性,异簇中对象高度相异。由于数据通常由不同类型的属性(数值型、分类型等)描述<citation id="307" type="reference"><link href="232" rel="bibliography" /><link href="234" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>,而当前大多数的聚类方法只能处理其中一种属性,所以通常需要一个预处理步骤将数据转换为单一类型。1997年,Huang<citation id="296" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出的k-prototypes聚类算法是一种将k-means聚类和k-modes聚类集成到数值和分类属性上的算法,具有可测量性、简洁性和快收敛性<citation id="297" type="reference"><link href="238" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。该算法尽管已问世20多年,此后衍生出大量解决混合属性数据的算法,但它仍然被广泛应用在多个领域<citation id="298" type="reference"><link href="238" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。部分学者基于该算法本身进行了改进,如文献<citation id="299" type="reference">[<a class="sup">4</a>]</citation>讨论了传统k-prototypes聚类算法中不同系数的局限性,提出了一种新的混合相异系数,在同一尺度上定义了2类属性的不同函数的维数,提高了聚类质量。文献<citation id="300" type="reference">[<a class="sup">5</a>]</citation>引入了分布式质心的概念,用于表示聚类中的分类属性原型。部分学者将模糊理论和粗糙集引入了k-prototypes聚类算法中。文献<citation id="301" type="reference">[<a class="sup">6</a>]</citation>讨论了模糊参数和初始原型对聚类精度的影响,以及聚类质量与聚类数之间的关系,并将其应用于数据库混合中。文献<citation id="302" type="reference">[<a class="sup">7</a>]</citation>基于粗糙集理论和数据库的依赖性,提出一种新的聚类属性选择技术——最大依赖属性MDA(Maximum Dependent Attribute),但其计算复杂度很高。还有部分学者将数学模型与聚类算法相结合,提出了基于模型的k-prototypes聚类算法。文献<citation id="303" type="reference">[<a class="sup">8</a>]</citation>将支持向量聚类扩展为一种自适应细胞生长模型,提出一种基于自适应聚类单元生长方法的多球聚类算法,以获得聚类隶属度和聚类原型,实现了手写体数字数据集的原型识别。文献<citation id="304" type="reference">[<a class="sup">9</a>]</citation>建立了一种基于k-prototypes的层次聚类匿名模型(Hierarchical Anonymous Model),提出了新的距离公式和损耗函数,更精准地体现出数组间的区别。文献<citation id="305" type="reference">[<a class="sup">10</a>]</citation>给出了聚类中心的一种集值模式表示,提供了更新聚类中心的方法和初始聚类中心选择的初始化算法。还有不少学者引入了粒计算的相关概念。文献<citation id="306" type="reference">[<a class="sup">11</a>]</citation>对聚类和粒计算的主要研究成果进行了研究和总结,从粗集、模糊集和商空间的角度分析了基于粒度的聚类算法及其优缺点,并对处理高维复杂海量数据的可行性和有效性进行了展望。文献<citation id="308" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>]</citation>利用粒计算从初始数据库中提取关系信息和数据特征,将其转化为模糊系统的语言规则库,并通过神经模糊建模结构进行优化。近年来,大数据聚类技术逐渐成熟,文献<citation id="309" type="reference">[<a class="sup">14</a>,<a class="sup">15</a>]</citation>分别提出了一种基于MapReduce框架的并行k-prototypes算法和一种基于Spark的k-prototypes算法,在维持聚类精度的同时,扩大了数据集的规模。</p>
                </div>
                <div class="p1">
                    <p id="69">初始聚类中心的选择对聚类结果影响很大,不恰当的初始值会导致聚类收敛速度缓慢,或使结果陷入局部最优解<citation id="310" type="reference"><link href="262" rel="bibliography" /><link href="282" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">16</a>]</sup></citation>。针对这一问题,文献<citation id="311" type="reference">[<a class="sup">16</a>,<a class="sup">16</a>]</citation>提出了一种新的初始化k-means方法,先估计出<i>k</i>个类的特征中心位置,再用特征中心初始化k-means。文献<citation id="312" type="reference">[<a class="sup">17</a>,<a class="sup">17</a>]</citation>提出一种密度敏感的相似性度量方法,放大不同高密度区域内数据点间距离,缩短同一高密度区域内数据点间距离,以此描述数据的实际聚类分布。文献<citation id="313" type="reference">[<a class="sup">18</a>,<a class="sup">18</a>]</citation>提出一种基于密度的初始中心点选择算法,满足了聚类的全局一致性特征。文献<citation id="314" type="reference">[<a class="sup">19</a>,<a class="sup">19</a>]</citation>利用背景知识,将“细”粒度层次扩展到了“粗”粒度层次,缩小了搜索空间,提高了求解速度,并由此提出了一种基于粒计算的概念聚类算法。</p>
                </div>
                <div class="p1">
                    <p id="70">本文提出了一种能处理数值属性和分类属性的Gk-prototypes聚类算法。该算法利用去模糊相似矩阵将原始数据集转变为粗粒子集,通过粒子密度和最大最小距离法计算初始聚类中心,结合类内距离和类间距离构建目标函数,增强了算法的准确性和鲁棒性,提高了聚类有效性。</p>
                </div>
                <h3 id="71" name="71" class="anchor-tag"><b>2 相关知识</b></h3>
                <h4 class="anchor-tag" id="72" name="72"><b>2.1 粒计算</b></h4>
                <div class="p1">
                    <p id="73"><b>定义1</b> 设知识库<i>K</i>=(<i>U</i>,<i>R</i>),<i>R</i>为论域<i>U</i>上的一个等价关系簇,在<i>U</i>上存在等价关系<i>Z</i>∈<i>R</i>,记样本集<mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><mo>=</mo><mi>U</mi><mo>/</mo><mi>Ζ</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>h</mi></munderover><mi>X</mi></mstyle><msup><mrow></mrow><mi>i</mi></msup></mrow></math></mathml>为<i>Z</i>在<i>U</i>上导出的划分,且规定<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false">(</mo><mi>Ζ</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>h</mi></munderover><mo stretchy="false">|</mo></mstyle><mi>X</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">|</mo><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext></mrow><mn>2</mn></msubsup></mrow></math></mathml>表示<i>Z</i>⊆<i>U</i>×<i>U</i>的基数<citation id="315" type="reference"><link href="270" rel="bibliography" /><link href="290" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">20</a>]</sup></citation>,则定义<i>GD</i>(<i>Z</i>)=<i>Card</i>(<i>Z</i>)/<i>Card</i>(<i>U</i><sup>2</sup>)=<mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>h</mi></munderover><mo stretchy="false">(</mo></mstyle><mrow><mo stretchy="false">|</mo><mi>X</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">|</mo><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext></mrow><mn>2</mn></msubsup><mo>/</mo></mrow><mo stretchy="false">|</mo><mi>U</mi><mo stretchy="false">|</mo><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext></mrow><mn>2</mn></msubsup><mo stretchy="false">)</mo></mrow></math></mathml>为<i>Z</i>的粒度<citation id="316" type="reference"><link href="272" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>。其中<i>X</i><sup><i>i</i></sup>={<i>x</i><mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>i</mi></msubsup></mrow></math></mathml>,<i>x</i><mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>i</mi></msubsup></mrow></math></mathml>,…,<i>x</i><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Ν</mi><mi>i</mi></msubsup></mrow></math></mathml>}表示划分粒子<i>X</i><sup><i>i</i></sup>包含<i>N</i>个属于该粒子的样本,<i>h</i>为粒子个数,<i>i</i>表示粒子标号,|<i>X</i><sup><i>i</i></sup>|<sub>num</sub>为<i>X</i><sup><i>i</i></sup>包含的样本数,|<i>U</i>|<sub>num</sub>为样本集包含的总样本数,|*|<sub>num</sub>表示集合元素的个数。</p>
                </div>
                <div class="p1">
                    <p id="74">粒度<i>GD</i>(<i>Z</i>)用于描述等价关系<i>Z</i>在某个属性下的分辨能力,粒度越小,表示分辨能力越强,反之则越弱。</p>
                </div>
                <div class="p1">
                    <p id="75"><b>定义2</b> 设<i>K</i>=(<i>X</i>,<i>A</i>)为聚类空间,<i>X</i>为包含<i>n</i>个数值属性样本的集合,<i>A</i>为属性集合,当不讨论样本归属于哪个粒子时,令<i><b>x</b></i><sub><i>p</i></sub>和<i><b>x</b></i><sub><i>q</i></sub>表示样本,则样本相似度函数为:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>A</mi><mo stretchy="false">|</mo><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub></mrow></munderover><mi>Ζ</mi></mstyle><msub><mrow></mrow><mi>l</mi></msub><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mtext>E</mtext></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">其中,|<i>A</i>|<sub>num</sub>为集合<i>A</i>包含的属性个数,<i>Z</i><sub><i>l</i></sub>为样本在第<i>l</i>个属性下的分辨能力,<i>x</i><sub><i>pl</i></sub>和<i>x</i><sub><i>ql</i></sub>分别表示样本<i><b>x</b></i><sub><i>p</i></sub>和<i><b>x</b></i><sub><i>q</i></sub>的第<i>l</i>个属性,1≤<i>p</i>≤<i>n</i>,1≤<i>q</i>≤<i>n</i>。|*|<sub>E</sub>表示欧氏距离。</p>
                </div>
                <div class="p1">
                    <p id="78">则数值属性样本的平均相似度为:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>S</mi><mo stretchy="true">¯</mo></mover><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>,</mo><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>S</mi></mstyle><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>/</mo><mi>n</mi><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80"><b>定义3</b> 设包含<i>N</i>个数值属性样本的粒子<i>X</i><sup><i>i</i></sup>={<i><b>x</b></i><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>i</mi></msubsup></mrow></math></mathml>,<i><b>x</b></i><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>i</mi></msubsup></mrow></math></mathml>,…,<i><b>x</b></i><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Ν</mi><mi>i</mi></msubsup></mrow></math></mathml>},定义该粒子的中心为<i><b>m</b></i><sub><i>i</i></sub>=<i><b>x</b></i><mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>p</mi><mi>i</mi></msubsup></mrow></math></mathml>,其中<mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>p</mi><mi>i</mi></msubsup><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi mathvariant="bold-italic">x</mi></mstyle><msubsup><mrow></mrow><mi>k</mi><mi>i</mi></msubsup></mrow><mo>|</mo></mrow><msub><mrow></mrow><mtext>E</mtext></msub><mo>=</mo><munderover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>v</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mo>{</mo><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>v</mi><mi>i</mi></msubsup><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi mathvariant="bold-italic">x</mi></mstyle><msubsup><mrow></mrow><mi>k</mi><mi>i</mi></msubsup></mrow><mo>|</mo></mrow><msub><mrow></mrow><mtext>E</mtext></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>2.2 传统k-prototypes聚类算法</b></h4>
                <div class="p1">
                    <p id="82">令<i>X</i>表示样本数为<i>n</i>的混合属性样本集,含有<i>m</i>个属性值的样本<i><b>x</b></i><sub><i>p</i></sub>=[<i>x</i><sub><i>p</i></sub><sub>1</sub>,<i>x</i><sub><i>p</i></sub><sub>2</sub>,…,<i>x</i><sub><i>pt</i></sub>,<i>x</i><sub><i>p</i></sub><sub>(</sub><sub><i>t</i></sub><sub>+1)</sub>,…,<i>x</i><sub><i>pm</i></sub>]<sup>T</sup>,其中[<i>x</i><sub><i>p</i></sub><sub>1</sub>,<i>x</i><sub><i>p</i></sub><sub>2</sub>,…,<i>x</i><sub><i>pt</i></sub>]<sup>T</sup>为数值型属性,[<i>x</i><sub><i>p</i></sub><sub>(</sub><sub><i>t</i></sub><sub>+1)</sub>,…<i>x</i><sub><i>pm</i></sub>]<sup>T</sup>为分类型属性。令数据集的初始聚类数为<i>k</i>,对应的初始聚类原型(即聚类中心)集合为<i>P</i>={<i><b>P</b></i><sub>1</sub>,<i><b>P</b></i><sub>2</sub>,…,<i><b>P</b></i><sub><i>k</i></sub>}。算法步骤为<citation id="317" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="83">(1)随机确定<i>k</i>个初始聚类原型<i><b>P</b></i><sub><i>j</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="84">(2)依据式(3),计算样本到各聚类原型的距离<i>d</i>,把样本分配给相应的聚类。其中,数值属性的距离测量利用欧氏距离,样本<i><b>x</b></i><sub><i>p</i></sub>与原型<i><b>P</b></i><sub><i>q</i></sub>的数值属性的距离<i>d</i><sub>1</sub>为:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mtext>E</mtext><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中,<i>P</i><sub><i>ql</i></sub>为原型<i><b>P</b></i><sub><i>q</i></sub>的第<i>l</i>个数值属性。</p>
                </div>
                <div class="p1">
                    <p id="87">分类属性的距离测量利用海明威距离,样本<i><b>x</b></i><sub><i>p</i></sub>与原型<i><b>P</b></i><sub><i>q</i></sub>的分类属性的距离<i>d</i><sub>2</sub>为:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>d</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>δ</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>,</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mi>δ</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>,</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>0</mn><mo>,</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub></mtd></mtr><mtr><mtd><mn>1</mn><mo>,</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>≠</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">综上,样本<i><b>x</b></i><sub><i>p</i></sub>与原型<i><b>P</b></i><sub><i>q</i></sub>的距离<i>d</i>为:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>d</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mi>d</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mtext>E</mtext><mn>2</mn></msubsup><mo>+</mo><mi>γ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>δ</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>,</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">其中,<i>γ</i>为分类属性权重值,一般取值为8<citation id="318" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>,<i>δ</i>为分类属性相异度。</p>
                </div>
                <div class="p1">
                    <p id="92">(3)重新计算聚类原型。对于数值型属性,取聚类样本中各数值属性的平均值;对于分类型属性,取聚类样本中出现概率最高的分类属性,两者结合即为最新的聚类原型。</p>
                </div>
                <div class="p1">
                    <p id="93">(4)重复步骤(3),直到各个聚类中数据对象稳定,迭代目标函数值<i>F</i>(<i>X</i>,<i>P</i>)不变。</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>F</mi><mo stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Ρ</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>u</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mspace width="0.25em" /></mrow></msub><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mspace width="0.25em" /></mrow></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mspace width="0.25em" /></mrow></msub><mo>=</mo><mn>1</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中,<i>u</i><sub><i>ij</i></sub>为划分矩阵<i><b>U</b></i><sub><i>n</i></sub><sub>×</sub><sub><i>k</i></sub>中的元素<citation id="319" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>3 算法优化</b></h3>
                <h4 class="anchor-tag" id="97" name="97"><b>3.1 混合属性样本的相似度</b></h4>
                <div class="p1">
                    <p id="98">令<i>X</i>为样本数为<i>n</i>的混合属性样本集,定义混合属性样本的相似度为:</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>Ζ</mi><msub><mrow></mrow><mi>l</mi></msub><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">其中,<i>d</i>(<i><b>x</b></i><sub><i>p</i></sub>,<i><b>x</b></i><sub><i>q</i></sub>)为混合属性样本相异度,表达式为:</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>d</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mi>d</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mtext>E</mtext><mn>2</mn></msubsup><mo>+</mo><mi>γ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>δ</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>,</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">其中,下标<i>l</i>=1～<i>t</i>的为数值型属性,下标<i>l</i>=(<i>t</i>+1)～<i>m</i>的为分类型属性。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103"><b>3.2 粒子密度</b></h4>
                <div class="p1">
                    <p id="104">定义含混合属性并属于粒子<i>X</i><sup><i>i</i></sup>的样本<i><b>x</b></i><sup><i>i</i></sup><sub><i>p</i></sub>的密度为<citation id="320" type="reference"><link href="274" rel="bibliography" /><link href="292" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">22</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><msub><mrow></mrow><mtext>s</mtext></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>p</mi><mi>i</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo>(</mo><mrow><mi>S</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>S</mi></mstyle><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>l</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo></mrow><mo>)</mo></mrow></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">定义粒子密度为:</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><msub><mrow></mrow><mtext>g</mtext></msub><mo stretchy="false">(</mo><mi>X</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mrow><mo>|</mo><mrow><mi>X</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mo>|</mo></mrow></mrow></munderover><mi>ρ</mi></mstyle><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mi>p</mi><mi>i</mi></msubsup><mo stretchy="false">)</mo><mo>/</mo><mrow><mo>|</mo><mrow><mi>X</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">其中,|<i>X</i><sup><i>i</i></sup>|为粒子<i>X</i><sup><i>i</i></sup>中包含的样本个数。</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>3.3 构造粗粒子集</b></h4>
                <div class="p1">
                    <p id="110">设阈值<mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><mo>∈</mo><mrow><mo>[</mo><mrow><mover accent="true"><mi>S</mi><mo stretchy="true">¯</mo></mover><mo>-</mo><mn>0</mn><mo>.</mo><mn>3</mn><mo>,</mo><mover accent="true"><mi>S</mi><mo stretchy="true">¯</mo></mover><mo>+</mo><mn>0</mn><mo>.</mo><mn>3</mn></mrow><mo>]</mo></mrow><mo>,</mo><mover accent="true"><mi>S</mi><mo stretchy="true">¯</mo></mover></mrow></math></mathml>为样本平均相似度,构造一个<i>n</i>×<i>n</i>维对角线元素为1的对称矩阵<i><b>M</b></i>,称<i><b>M</b></i>为去模糊相似矩阵<citation id="321" type="reference"><link href="276" rel="bibliography" /><link href="294" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">23</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="111"><b>定义4 </b><i><b>x</b></i><sub><i>p</i></sub>,<i><b>x</b></i><sub><i>q</i></sub>∈<i>X</i>,若<i>S</i>(<i><b>x</b></i><sub><i>p</i></sub>,<i><b>x</b></i><sub><i>q</i></sub>)≥<i>θ</i>,则<i>M</i>(<i>p</i>,<i>q</i>)=1,由此得到样本<i><b>x</b></i><sub><i>p</i></sub>的相似类<mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></msub><mo>=</mo><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mrow><mo>|</mo><mrow><mi>Μ</mi><mo stretchy="false">(</mo><mi>p</mi><mo>,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>,</mo></mrow></mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo>∈</mo><mi>X</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="112"><b>定义5</b> ∀<i><b>x</b></i><sub><i>p</i></sub>,<i><b>x</b></i><sub><i>q</i></sub>∈<i>X</i>,若<i>S</i>(<i><b>x</b></i><sub><i>p</i></sub>,<i><b>x</b></i><sub><i>q</i></sub>)&lt;<i>θ</i>,则<i>M</i>(<i>p</i>,<i>q</i>)=0,由此得到样本<i><b>x</b></i><sub><i>p</i></sub>的不相似类<mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msup><mi>C</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></msub></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mrow><mo>|</mo><mrow><mi>Μ</mi><mo stretchy="false">(</mo><mi>p</mi><mo>,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>,</mo></mrow></mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>q</mi></msub><mo>∈</mo><mi>X</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="113">若<i>M</i>(<i>p</i>,<i>r</i>)=<i>M</i>(<i>p</i>,<i>q</i>)=1,即第<i>p</i>行和第<i>q</i>行中位于第<i>r</i>列的元素值均为1(或第<i>p</i>列和第<i>q</i>列中位于第<i>r</i>行的元素值均为1),则<i><b>x</b></i><sub><i>p</i></sub>、<i><b>x</b></i><sub><i>q</i></sub>存在不可分辨关系,令这样的<i><b>x</b></i><sub><i>r</i></sub>的个数为<i>r</i><sub>1</sub>;若<i>M</i>(<i>p</i>,<i>r</i>)=0或<i>M</i>(<i>p</i>,<i>q</i>)=0,即第<i>p</i>行或第<i>q</i>行中位于第<i>r</i>列的元素值为0(或第<i>p</i>列或第<i>q</i>列中位于第<i>r</i>行的元素值为0),则<i><b>x</b></i><sub><i>p</i></sub>与<i><b>x</b></i><sub><i>q</i></sub>不相似,令这样的<i><b>x</b></i><sub><i>r</i></sub>的个数为<i>r</i><sub>2</sub>;若<i>r</i><sub>1</sub>&gt;<i>r</i><sub>2</sub>,则表示<i><b>x</b></i><sub><i>p</i></sub>与<i><b>x</b></i><sub><i>q</i></sub>具有较强的不可分辨性,可构成等价类,合并在同一粒子中。对所有的样本计算其等价类,即可得到粗粒子集{<i>X</i><sup>1</sup>,<i>X</i><sup>2</sup>,…,<i>X</i><sup><i>h</i></sup>},1≤<i>h</i>≤<i>n</i>。</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>3.4 更新聚类中心</b></h4>
                <div class="p1">
                    <p id="115"><b>定义6</b> 对于分类属性数据,设<i>C</i><sub><i>d</i></sub>为包含分类属性<i>x</i><mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>(1≤<i>i</i>≤<i>h</i>,1≤<i>p</i>≤<i>n</i>,<i>t</i>+1≤<i>d</i>≤<i>m</i>)所有唯一值的集合,<i>p</i>(<i>x</i><mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>∈<i>C</i><sub><i>d</i></sub>|<i>l</i>)为属性<i>x</i><mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>在聚类簇<i>l</i>中的概率,则对于当前迭代的聚类簇<i>l</i>,若<i>p</i>(<i>x</i><mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>l</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>∈<i>C</i><sub><i>d</i></sub>|<i>l</i>)=<mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munderover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mrow></math></mathml><i>p</i>(<i>x</i><mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>∈<i>C</i><sub><i>d</i></sub>|<i>l</i>),且<i>x</i><mathml id="177"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>l</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>≠<i>x</i><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>,则<i>x</i><mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>l</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>为下次迭代的聚类中心的分类属性。</p>
                </div>
                <div class="p1">
                    <p id="116"><b>定义7</b> 对于数值属性数据,设<i>C</i><sub><i>d</i></sub>为包含数值属性<i>x</i><mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>(1≤<i>i</i>≤<i>h</i>,1≤<i>p</i>≤<i>n</i>,1≤<i>d</i>≤<i>t</i>)所有唯一值的集合,<i>x</i><mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>∈<i>C</i><sub><i>d</i></sub>|<i>l</i>为属性<i>x</i><mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mi>d</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>在聚类簇<i>l</i>中的属性,|<i>l</i>|为聚类簇<i>l</i>中包含的样本个数,则<mathml id="183"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover><mi>x</mi></mstyle><msubsup><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow><mi>i</mi></msubsup><mo>/</mo><mrow><mo>|</mo><mi>l</mi><mo>|</mo></mrow></mrow></math></mathml>为下次迭代的聚类中心的数值属性,即取当前迭代的聚类簇中所有数值属性的平均值。</p>
                </div>
                <h4 class="anchor-tag" id="117" name="117"><b>3.5 目标函数</b></h4>
                <div class="p1">
                    <p id="118">传统k-prototypes算法中,以类内距离和作为目标函数,当距离和取最小值并保持不变时,表示当前迭代为最后一次迭代,聚类完成。上述算法没有考虑到类间距离对聚类效果的影响,迭代过程冗长。因此,本文将采取类内距离和类间距离共同作用的方式构造目标函数,以期减少迭代次数,提高聚类精度。</p>
                </div>
                <h4 class="anchor-tag" id="119" name="119">(1)类内距离。</h4>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">[</mo></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mtext>E</mtext><mn>2</mn></msubsup><mo>+</mo><mi>γ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>δ</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>l</mi></mrow></msub><mo>,</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="121" name="121">(2)类间距离。</h4>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mfrac><mn>2</mn><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>k</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>,</mo><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>p</mi></msub><mo>-</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>q</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mtext>E</mtext><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">其中,|<i><b>P</b></i><sub><i>p</i></sub>-<i><b>P</b></i><sub><i>q</i></sub>|<sup>2</sup>表示聚类中心<i><b>P</b></i><sub><i>p</i></sub>到聚类中心<i><b>P</b></i><sub><i>q</i></sub>的距离。</p>
                </div>
                <h4 class="anchor-tag" id="124" name="124">(3)目标函数。</h4>
                <div class="p1">
                    <p id="125" class="code-formula">
                        <mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Ρ</mi><mo stretchy="false">)</mo><mo>=</mo><mi>ln</mi><mspace width="0.25em" /><mi>D</mi><msub><mrow></mrow><mn>1</mn></msub><mo>/</mo><mi>ln</mi><mspace width="0.25em" /><mi>D</mi><msub><mrow></mrow><mn>2</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="126" name="126"><b>3.6 Gk-prototypes聚类算法具体步骤</b></h4>
                <div class="p1">
                    <p id="229">输入:样本数为n的混合属性数据集,聚类簇参数k。</p>
                </div>
                <div class="p1">
                    <p id="230">输出:k个聚类中心及最优聚类簇。</p>
                </div>
                <div class="p1">
                    <p id="231">步骤1 确定初始聚类中心。</p>
                </div>
                <div class="p1">
                    <p id="127">(1)根据式(8)计算样本相异度d(<i><b>x</b></i><sub><i>p</i></sub>,<i><b>x</b></i><sub><i>q</i></sub>),根据式(7)计算样本间的相似度<i>S</i>(<i><b>x</b></i><sub><i>p</i></sub>,<i><b>x</b></i><sub><i>q</i></sub>)。</p>
                </div>
                <div class="p1">
                    <p id="128">(2)根据式(2)计算样本平均相似度<mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>S</mi><mo stretchy="true">¯</mo></mover></mrow></math></mathml>,根据定义4和定义5计算去模糊相似矩阵<i><b>M</b></i>,并得到粗粒子集{<i>X</i><sup>1</sup>,<i>X</i><sup>2</sup>,…,<i>X</i><sup><i>h</i></sup>},1≤<i>h</i>≤<i>n</i>。</p>
                </div>
                <div class="p1">
                    <p id="129">(3)根据式(9)计算每个样本的密度<i>ρ</i><sub>s</sub>(<i><b>x</b></i><mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>p</mi><mi>i</mi></msubsup></mrow></math></mathml>),按式(10)计算粒子密度<i>ρ</i><sub>g</sub>(<i>X</i><sup><i>i</i></sup>)。</p>
                </div>
                <div class="p1">
                    <p id="130">(4)根据定义3计算每个粒子的中心,记为{<i><b>m</b></i><sub>1</sub>,<i><b>m</b></i><sub>2</sub>,…,<i><b>m</b></i><sub><i>h</i></sub>}(1≤<i>h</i>≤<i>n</i>),计算任2个粒子中心间的欧氏距离<i>D</i><sub><i>ij</i></sub>(1≤<i>i</i>,<i>j</i>≤<i>h</i>)并记录在矩阵<i><b>H</b></i>中。</p>
                </div>
                <div class="p1">
                    <p id="131">(5)记平均密度最大的粒子所对应的中心<i><b>m</b></i><sub><i>a</i></sub>(1≤<i>a</i>≤<i>h</i>)为第1个聚类中心<i><b>P</b></i><sub>1</sub>;记距离<i><b>P</b></i><sub>1</sub>最远的粒子中平均密度最大的粒子所对应的中心<i><b>m</b></i><sub><i>b</i></sub>(<i>a</i>≠<i>b</i>)为第2个聚类中心<i><b>P</b></i><sub>2</sub>;对{<i><b>m</b></i><sub>1</sub>,<i><b>m</b></i><sub>2</sub>,…,<i><b>m</b></i><sub><i>h</i></sub>}中剩余粒子,根据矩阵<i><b>H</b></i>分别求出其中心到聚类中心<i><b>P</b></i><sub>1</sub>,<i><b>P</b></i><sub>2</sub>的距离,使得<i><b>P</b></i><sub>3</sub>满足<i><b>P</b></i><sub>3</sub>={<i><b>m</b></i><sub><i>c</i></sub>|min{max(<i>D</i><sub><i>c</i></sub><sub>1</sub>,<i>D</i><sub><i>c</i></sub><sub>2</sub>)}}(1≤<i>c</i>≤<i>h</i>,<i>c</i>≠<i>a</i>,<i>b</i>)。依此类推,在剩余粒子中根据最大最小距离选择下一个初始聚类中心<i><b>P</b></i><sub><i>r</i></sub>=<i><b>m</b></i><sub><i>i</i></sub>,使得<i><b>P</b></i><sub><i>r</i></sub>满足<i>P</i><sub><i>r</i></sub>={<i><b>m</b></i><sub><i>i</i></sub>|min{max(<i>D</i><sub><i>i</i></sub><sub>1</sub>,<i>D</i><sub><i>i</i></sub><sub>2</sub>,…,<i>D</i><sub><i>i</i></sub><sub>(</sub><sub><i>r</i></sub><sub>-1)</sub>)}}(1≤<i>i</i>≤<i>h</i>,1≤<i>j</i>≤<i>r</i>-1,<i><b>m</b></i><sub><i>i</i></sub>≠<i><b>P</b></i><sub><i>j</i></sub>,<i>r</i>=3,4,…,<i>k</i>),以此得到<i>k</i>个初始聚类中心<i><b>P</b></i><sub><i>k</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="132"><b>步骤2</b> 依次将样本划分到距离其最近的聚类中心所在聚类簇中。</p>
                </div>
                <div class="p1">
                    <p id="133"><b>步骤3</b> 更新聚类中心。</p>
                </div>
                <div class="p1">
                    <p id="134">根据定义6和定义7重新计算聚类中心。</p>
                </div>
                <div class="p1">
                    <p id="135"><b>步骤4</b> 求当次迭代目标函数值。</p>
                </div>
                <div class="p1">
                    <p id="136">根据式(11)～式(13)求出目标函数<i>F</i>(<i>X</i>,<i>P</i>)。</p>
                </div>
                <div class="p1">
                    <p id="137"><b>步骤5</b> 重复步骤(2)～步骤(4),直至|<i>F</i><sup>(</sup><sup><i>ite</i></sup><sup>)</sup>(<i>X</i>,<i>P</i>)-<i>F</i><sup>(</sup><sup><i>ite</i></sup><sup>-1)</sup>(<i>X</i>,<i>P</i>)|<sub>ab</sub>≤<i>ε</i>,聚类结束。|*|<sub>ab</sub>表示绝对值。</p>
                </div>
                <h3 id="138" name="138" class="anchor-tag"><b>4 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="139">实验环境的软件:操作系统Windows 7;集成开发环境:Python 2.7.11, matplotlib;编辑器:sublime text3;硬件:Intel® Core<sup>TM</sup> i5-2500 CPU,8 GB内存。</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140"><b>4.1 18维混合属性数据集实验</b></h4>
                <div class="p1">
                    <p id="141">为验证本文算法的性能,分别采用传统k-prototypes算法和本文算法在18维混合属性数据集上进行聚类测试。该数据集包括10维连续型变量和8维分类属性变量,共3 000个样本点,分为3个类别。为了加强聚类结果的直观性,特将18维的样本点利用PCA降维显示在二维平面中,分布如图1a所示。传统k-prototypes算法和本文算法在该数据集上的聚类结果分布如图1b和图1c所示。</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201909024_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 2种算法在18维混合属性数据集上的聚类效果图" src="Detail/GetImg?filename=images/JSJK201909024_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 2种算法在18维混合属性数据集上的聚类效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201909024_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Clustering effect diagram of the two algorithms 
 on the 18 dimensional mixed dataset</p>

                </div>
                <div class="p1">
                    <p id="143">本文采用聚类准确率<i>r</i><citation id="322" type="reference"><link href="278" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>来评估各算法的聚类精度,它是目前公认的评价聚类效果的标准之一,表达式为<mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>a</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mi>n</mi></mrow></math></mathml>,其中<i>a</i><sub><i>i</i></sub>表示既出现在第<i>i</i>个类中而该类又是其对应的正确类的样本个数,<i>n</i>为样本集中的样本总个数。采用<i>ARI</i>(Adjusted Rand Index)<citation id="323" type="reference"><link href="280" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>指数衡量各算法的聚类有效性,取值为[-1,1],值越大则聚类结果与真实情况越吻合。对各算法均测试了50次,聚类平均准确率(<i>AA</i>)结果比较如表1所示,2种算法的<i>ARI</i>指数如图2所示,各算法目标函数的误差<i>ε</i>为相同值。</p>
                </div>
                <div class="area_img" id="144">
                    <p class="img_tit"><b>表1 2种算法聚类平均准确率比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Comparison of clustering average accuracy between the two algorithms</b></p>
                    <p class="img_note"></p>
                    <table id="144" border="1"><tr><td><br />算法</td><td><i>AA</i>/%</td></tr><tr><td><br />传统k-prototypes算法</td><td>76.44</td></tr><tr><td><br />本文算法</td><td>95.73</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201909024_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 2种算法聚类结果的ARI指数图" src="Detail/GetImg?filename=images/JSJK201909024_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 2种算法聚类结果的<i>ARI</i>指数图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201909024_145.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 <i>ARI</i> of the clustering 
 results of the two algorithms</p>

                </div>
                <div class="p1">
                    <p id="146">由实验结果可以看出,传统k-prototypes算法的<i>ARI</i>指数为0.75,平均聚类准确率为76.44%;本文算法的<i>ARI</i>指数为0.93,平均聚类准确率为95.73%,比传统算法平均聚类准确率提高了19.29%,<i>ARI</i>指数高了0.18。由此说明,本文优化算法提高了聚类准确率和有效性。比较图1a～图1c可以看出,本文算法能较准确地将混合数据分为3个类别,3种不同形状的样本点界限较为分明,算法可行性较高。</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147"><b>4.2 UCI标准数据集实验</b></h4>
                <div class="p1">
                    <p id="148">为进一步验证本文算法,接下来分别将一种改进的k-prototypes算法(文献<citation id="324" type="reference">[<a class="sup">5</a>]</citation>)、模糊k-prototypes算法(文献<citation id="325" type="reference">[<a class="sup">6</a>]</citation>)、基于k-prototypes的层次聚类匿名算法(文献<citation id="326" type="reference">[<a class="sup">9</a>]</citation>)和本文算法进行聚类对比,数据集采用UCI标准数据集中的Heart Disease数据集、Credit Approval数据集和Iris数据集。各数据集的特征如表2所示,各算法的聚类准确率如表3所示,聚类结果的<i>ARI</i>指数如图3所示。</p>
                </div>
                <div class="area_img" id="149">
                    <p class="img_tit"><b>表2 实验采用的数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Data sets used in the experiment</b></p>
                    <p class="img_note"></p>
                    <table id="149" border="1"><tr><td><br />数据集名称</td><td>样本数目</td><td>属性维数</td><td>类别数</td></tr><tr><td><br />Heart Disease</td><td>303</td><td>14</td><td>5</td></tr><tr><td><br />Credit Approval</td><td>690</td><td>15</td><td>2</td></tr><tr><td><br />Iris</td><td>150</td><td>4</td><td>3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="150">
                    <p class="img_tit"><b>表3 各算法的聚类平均准确率比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Comparison of clustering average accuracy among the algorithms</b></p>
                    <p class="img_note">%</p>
                    <table id="150" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="3"><br />数据集名称</td></tr><tr><td><br />Heart Disease</td><td>Credit Approval</td><td>Iris</td></tr><tr><td><br />传统k-prototypes算法</td><td>68.45</td><td>72.82</td><td>82.34</td></tr><tr><td><br />文献[5]算法</td><td>83.93</td><td>87.11</td><td>92.14</td></tr><tr><td><br />文献[6]算法</td><td>73.88</td><td>83.42</td><td>90.22</td></tr><tr><td><br />文献[9]算法</td><td>79.36</td><td>85.02</td><td>91.02</td></tr><tr><td><br />Gk-prototypes算法</td><td>86.06</td><td>91.01</td><td>95.61</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201909024_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 各算法聚类结果的ARI指数图" src="Detail/GetImg?filename=images/JSJK201909024_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 各算法聚类结果的<i>ARI</i>指数图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201909024_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 ARI exponential graph of the 
 clustering result of each algorithm</p>

                </div>
                <div class="p1">
                    <p id="152">比较表3和图3各项数据可以看出,本文算法在聚类准确率和聚类有效性上均有提升,鲁棒性较好。与传统的k-prototypes算法相比,本文算法的平均准确率提高了16.35%,<i>ARI</i>指数提高了0.18;与文献<citation id="327" type="reference">[<a class="sup">5</a>]</citation>、文献<citation id="328" type="reference">[<a class="sup">6</a>]</citation>和文献<citation id="329" type="reference">[<a class="sup">9</a>]</citation>的算法相比,本文算法的平均准确率分别提高了3.16%,8.38%和5.76%,<i>ARI</i>指数分别提高了0.08,0.10和0.08。由此可知,本文算法结合粒计算和最大最小距离来寻找初始聚类中心,避免了初始聚类中心出现在同一类的情况,有效提高了聚类准确率和有效性。</p>
                </div>
                <h4 class="anchor-tag" id="153" name="153"><b>4.3 算法分析</b></h4>
                <div class="p1">
                    <p id="154">本文算法步骤1中,通过计算样本相似度、去模糊相似矩阵等过程构造粗粒子集的时间复杂度为<i>Ο</i>(<i>n</i><sup>2</sup>),虽然耗时较多,但能在聚类的初始阶段选取较为准确的聚类中心,保证聚类中心位于样本密度最大的区域,且彼此距离最远,减少了算法迭代次数。综上所述,本文算法虽在时间性能上有待加强,但在聚类准确率和聚类有效性上均有了明显提升。</p>
                </div>
                <h3 id="155" name="155" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="156">本文算法利用去模糊相似矩阵构造粗粒子集,定义粒子密度并根据最大最小距离法确定初始聚类中心,避免了以往算法中初始聚类中心出现在同一类的缺陷,结合类内距离和类间距离确定目标函数,有效提高了聚类准确率和聚类有效性,鲁棒性优于其他k-prototypes聚类算法的。本文算法在提升聚类准确率的同时,牺牲了时间性能,面对大数据样本集时可行性欠佳,因此下一步将以改善时间复杂度和面向大数据样本集为主要工作。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="232">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501643028&amp;v=MjAwODRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKbDhXYnhvPU5pZk9mYks3SHRETnFvOUVZdThNREg0eA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Hsu C C,Huang Y P.Incremental clustering of mixed data based on distance hierarchy[J].Expert Systems with Applications:An International Journal,2008,35(3):1177-1185.
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501911120&amp;v=MjE1MjBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmw4V2J4bz1OaWZPZmJLN0h0RE5xbzlFYmVvT0RYNDVvQk1UNlQ0UA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Hsu C C,Lin S H,Tai W S.Apply extended self-organizing map to cluster and classify mixed-type data[J].Neurocomputing,2011,74(18):3832-3842.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering Large Data Sets with Mixed Numeric and Categorical Values">

                                <b>[3]</b> Huang Z X.Clustering large data sets with mixed numeric and categorical values[C]//Proc of the 1st Pacific-Asia Conference on Knowledge Discovery and Data Mining,1997:21-34.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An equi-biased k-prototypes algorithm for clustering mixed-type data">

                                <b>[4]</b> Sangam R S,Om H.An equi-biased k-prototypes algorithm for clustering mixed-type data[J].Sādhanā,2018,43(3):37-49.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES959D989A1159D3805B9013BD9D3B44CF&amp;v=MTUyMjlPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHdybTl4YUE9TmlmT2ZicTlGNlhGcDRZMFplb0tCUWc2eHhZV21EWjlTWHlRMkJ0QmVzQ1FRY25wQw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Ji J C,Bai T,Zhou C G,et al.An improved k-prototypes clustering algorithm for mixed numeric and categorical data[J].Neurocomputing,2013,120(10):590-596.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200108000&amp;v=MjczNjRiTEc0SHRETXA0OUZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdrVWJyQU55ZlQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Chen Ning,Chen An,Zhou Long-xiang .Fuzzy K-Prototypes algorithm for clustering mixed numeric and categorical valued data[J].Journal of Software,2001,12(8):1107-1119.
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501719412&amp;v=MDAwODdHQ0gwN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsOFdieG89TmlmT2ZiSzdIdEROcW85RVkrbw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Herawan T,Deris M M,Abawajy J H.A rough set approach for selecting clustering attribute[J].Knowledge-Based Systems,2010,23(3):220-231.
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new kernel-based fuzzy clustering approach: support vector clustering with cell growing">

                                <b>[8]</b> Chiang J H,Hao P Y.A new kernel-based fuzzy clustering approach:Support vector clustering with cell growing[J].IEEE Transactions on Fuzzy Systems,2003,11(4):518-527.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An anonymous algorithm for hierarchical clustering based on k-prototypes">

                                <b>[9]</b> Yao Y J,Sun Y,Yao Y J,et al.An anonymous algorithm for hierarchical clustering based on k-prototypes[C]//Proc of the 2016 4th International Conference on Machinery,Materials and Information Technology Applications,2017:1586-1591.
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An algorithm for clustering categorical data with set-valued features">

                                <b>[10]</b> Cao F Y,Huang J Z,Liang J Y,et al.An algorithm for clustering categorical data with set-valued features[J].IEEE Transactions on Neural Networks &amp; Learning Systems,2018,29(10):4593-4604.
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00003386298&amp;v=MDU4NzlsVmI3S0pWWT1OajNhYXJPNEh0SFBySWREWnVJSFkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNE&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Ding S,Xu L,Zhu H,et al.Research and progress of cluster algorithms based on Granular computing[J].International Journal of Digital Content Technology and its Applications,2010,4(5):96-104.
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300670531&amp;v=MTg1MjVUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmw4V2J4bz1OaWZPZmJLN0h0RE9ySTlGWXV3UENYODRvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Panoutsos G,Mahfouf M.A neural-fuzzy modelling framework based on granular computing:Concepts and applications[J].Fuzzy Sets &amp; Systems,2010,161(21):2808-2830.
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An incremental learning structure using granular computing and model fusion with application to materials processing">

                                <b>[13]</b> Panoutsos G,Mahfouf M.An incremental learning structure using granular computing and model fusion with application to materials processing[C]//Proc of International IEEE Conference on Intelligent Systems,2008:139-153.
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MapReduce-Based K-Prototypes Clustering Method for Big Data">

                                <b>[14]</b> Kacem M A B H,N’Cir C E B,Essoussi N.MapReduce-based k-prototypes clustering method for big data[C]//Proc of IEEE International Conference on Data Science and Advanced Analytics,2015:1-7.
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=KP-S:A Spark-based design of the k-prototypes clustering for big data">

                                <b>[15]</b> Hajkacem M A B,Chiheb E B N,Essoussi N.KP-S:A Spark-based design of the k-prototypes clustering for big data[C]//Proc of ACS/IEEE International Conference on Computer Systems and Applications,2017:557-563.
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 Qian Xian,Huang Xuan-jing,Wu Li-de.A Spectral method of K-means initialization[J].Acta Automatica Sinica,2007,33(4):342-346.(in Chinese)
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU200708030&amp;v=MDk2NzVHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3a1VickFJVGZUZTdHNEh0Yk1wNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Wang Ling,Bo Lie-feng,Jiao Li-cheng.Density-sensitive spectral clustering[J].Acta Electronica Sinica,2007,35(8):1577-1581.(in Chinese)
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB200902020&amp;v=MDExMDdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3a1VickFLRDdZYkxHNEh0ak1yWTlIWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Wang Zhong,Liu Gui-quan,Chen En-hong.A K-means algorithm based on optimized initial center points[J].Pattern Recognition and Artificial Intelligence,2009,22(2):299-304.(in Chinese)
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGGL201306018&amp;v=MjQ4ODRSTE9lWmVSbUZ5N2tVYnJBSmlyTVlyRzRIOUxNcVk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Gou Guang-lei,Huang Li-feng,Ni Wei.Conceptual clustering algorithm based on granular compuing[J].Journal of Chongqing University of Technology,2013,27(6):76-79.(in Chinese)
                            </a>
                        </p>
                        <p id="270">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB200304005&amp;v=MDI2NDc0SHRMTXE0OUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdrVWJyQUtEN1liTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> An Qiu-sheng,Shen Jun-yi,Wang Guo-yin.A clustering method based on information granularity and rough sets[J].Pattern Recognition &amp; Artificial Intelligence,2003,16(4):412-417.(in Chinese)
                            </a>
                        </p>
                        <p id="272">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=REEF201005003&amp;v=MDUxMzE0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdrVWJyQU55ak9hTEc0SDlITXFvOUZaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> Yao Yi-yu.Notes on rough set approximations and associated measures[J].Journal of Zhejiang Ocean University(Natural Science),2010,29(5):399-410.
                            </a>
                        </p>
                        <p id="274">
                            <a id="bibliography_22" >
                                    <b>[22]</b>
                                 Xie Juan-ying,Lu Xiao-xiao,Qu Ya-nan,et al.K-medoids clustering algorithm with optimized initial seeds by granular computing[J].Journal of Frontiers of Computer Science &amp; Technology,2015,9(5):611-620.(in Chinese)
                            </a>
                        </p>
                        <p id="276">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fuzzy cluster analysis and its application">

                                <b>[23]</b> Gao Xin-bo.Fuzzy cluster analysis and its application[M].Xi’an:Xidian University Press,2004:42-46.(in Chinese)
                            </a>
                        </p>
                        <p id="278">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A fuzzy k-modes algorithm for clustering categorical data">

                                <b>[24]</b> Huang Z X,Ng M.A fuzzy k-modes algorithm for clustering categorical data[J].IEEE Transactions on Fuzzy Systems,1999,7(4):446-452.
                            </a>
                        </p>
                        <p id="280">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00000725207&amp;v=MjMxMTJIdEhNcUkxQVp1c0lZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDRGxWYjdLSlZZPU5qN0Jhck80&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> Hubert L,Arabie P.Comparing partitions[J].Journal of Classification,1985,2(1):193-218.附中文参考文献:
                            </a>
                        </p>
                        <p id="282">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO200704002&amp;v=MTc3ODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdrVWJyQUtDTGZZYkc0SHRiTXE0OUZab1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 钱线,黄萱菁,吴立德.初始化K-means的谱方法[J].自动化学报,2007,33(4):342-346.
                            </a>
                        </p>
                        <p id="284">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 王玲,薄列峰,焦李成.密度敏感的谱聚类[J].电子学报,2007,35(8):1577-1581.
                            </a>
                        </p>
                        <p id="286">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 汪中,刘贵全,陈恩红.一种优化初始中心点的K-means算法[J].模式识别与人工智能,2009,22(2):299-304.
                            </a>
                        </p>
                        <p id="288">
                            <a id="bibliography_19" >
                                    <b>[19]</b>
                                 苟光磊,黄丽丰,倪伟.基于粒计算的概念聚类算法[J].重庆理工大学学报(自然科学),2013,27(6):76-79.
                            </a>
                        </p>
                        <p id="290">
                            <a id="bibliography_20" >
                                    <b>[20]</b>
                                 安秋生,沈钧毅,王国胤.基于信息粒度与Rough集的聚类方法研究[J].模式识别与人工智能,2003,16(4):412-417.
                            </a>
                        </p>
                        <p id="292">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201505013&amp;v=MjExMDJDVVJMT2VaZVJtRnk3a1VickFMalhmZmJHNEg5VE1xbzlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 谢娟英,鲁肖肖,屈亚楠,等.粒计算优化初始聚类中心的K-medoids聚类算法[J].计算机科学与探索,2015,9(5):611-620.
                            </a>
                        </p>
                        <p id="294">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=0007560613012999&amp;v=MjY0NzVuS3JpZlp1OXVGQ3Z0VTduSklsc2NWVjI3R2JhK0h0Zk5ySTlFWnVJR0JSTTh6eFVTbURkOVNIN24zeEU5ZmJ2&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> 高新波.模糊聚类分析及其应用[M].西安:西安电子科技大学出版社,2004:42-46.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201909024" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201909024&amp;v=MjI5NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdrVWJyQUx6N0JaYkc0SDlqTXBvOUhZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
