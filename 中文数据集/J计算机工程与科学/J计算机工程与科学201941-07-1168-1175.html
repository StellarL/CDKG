<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132370829092500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201907004%26RESULT%3d1%26SIGN%3dqr3l2hT43e3KFsSMWUsFstd%252fYmI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907004&amp;v=MjI5NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVnJyTEx6N0JaYkc0SDlqTXFJOUZZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="&lt;b&gt;2 相关工作&lt;/b&gt; "><b>2 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="&lt;b&gt;3 部分页迁移&lt;/b&gt; "><b>3 部分页迁移</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="&lt;b&gt;3.1 基本理念&lt;/b&gt;"><b>3.1 基本理念</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;3.2 部分有效状态&lt;/b&gt;"><b>3.2 部分有效状态</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;3.3 部分页迁移过程&lt;/b&gt;"><b>3.3 部分页迁移过程</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#73" data-title="&lt;b&gt;4 迁移机制&lt;/b&gt; "><b>4 迁移机制</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="&lt;b&gt;4.1 单一有效范围的部分页迁移&lt;/b&gt;"><b>4.1 单一有效范围的部分页迁移</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;4.2 多个有效范围的部分页迁移&lt;/b&gt;"><b>4.2 多个有效范围的部分页迁移</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="&lt;b&gt;5 实验和分析&lt;/b&gt; "><b>5 实验和分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="&lt;b&gt;5.1 环境设置&lt;/b&gt;"><b>5.1 环境设置</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;5.2 单一有效范围的部分页迁移&lt;/b&gt;"><b>5.2 单一有效范围的部分页迁移</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;5.3 多个有效范围的部分页迁移&lt;/b&gt;"><b>5.3 多个有效范围的部分页迁移</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="&lt;b&gt;6 结束语&lt;/b&gt; "><b>6 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="图1 页面状态转换图">图1 页面状态转换图</a></li>
                                                <li><a href="#72" data-title="图2 部分页迁移过程">图2 部分页迁移过程</a></li>
                                                <li><a href="#77" data-title="图3 部分页迁移流程图">图3 部分页迁移流程图</a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;表1 模拟器配置参数&lt;/b&gt;"><b>表1 模拟器配置参数</b></a></li>
                                                <li><a href="#90" data-title="图4 单一有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较">图4 单一有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较</a></li>
                                                <li><a href="#93" data-title="图5 带宽为16 GB/s时迁移单元大小对多个有效范围的部分迁移性能的影响">图5 带宽为16 GB/s时迁移单元大小对多个有效范围的部分迁移性能的影响</a></li>
                                                <li><a href="#104" data-title="图6 多个有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较">图6 多个有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Lindholm E, Nickolls J, Oberman S, et al.NVIDIA Tesla:A unified graphics and computing architecture[J].IEEE Micro, 2008, 28 (2) :39-55." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=NVIDIA Tesla: A unified graphics and computing architecture">
                                        <b>[1]</b>
                                         Lindholm E, Nickolls J, Oberman S, et al.NVIDIA Tesla:A unified graphics and computing architecture[J].IEEE Micro, 2008, 28 (2) :39-55.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Di Carlo S, Gambardella G, Martella I, et al.Fault mitigation strategies for CUDA GPUs[C]//Proc of 2013 IEEE International Test Conference (ITC) , 2013:18." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fault mitigation strategies for CUDA GPUs">
                                        <b>[2]</b>
                                         Di Carlo S, Gambardella G, Martella I, et al.Fault mitigation strategies for CUDA GPUs[C]//Proc of 2013 IEEE International Test Conference (ITC) , 2013:18.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Power J, Hill M D, Wood D A.Supporting x86-64 address translation for 100s of GPU lanes[C]//Proc of 2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA) , 2014:568-578." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supporting x86-64 address translation for 100s of GPU lanes">
                                        <b>[3]</b>
                                         Power J, Hill M D, Wood D A.Supporting x86-64 address translation for 100s of GPU lanes[C]//Proc of 2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA) , 2014:568-578.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Zheng T, Nellans D, Zulfiqar A, et al.Towards high performance paged memory for GPUs[C]//Proc of 2016 IEEE International Symposium on High Performance Computer Architecture (HPCA) , 2016:345-357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards high performance paged memory for GPUs">
                                        <b>[4]</b>
                                         Zheng T, Nellans D, Zulfiqar A, et al.Towards high performance paged memory for GPUs[C]//Proc of 2016 IEEE International Symposium on High Performance Computer Architecture (HPCA) , 2016:345-357.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Landaverde R, Zhang T, Coskun A K, et al.An investigation of unified memory access performance in CUDA[C]//Proc of IEEE High Performance Extreme Computing Conference (HPEC) , 2014:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An investigation of Unified Memory Access performance in CUDA">
                                        <b>[5]</b>
                                         Landaverde R, Zhang T, Coskun A K, et al.An investigation of unified memory access performance in CUDA[C]//Proc of IEEE High Performance Extreme Computing Conference (HPEC) , 2014:1-6.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Kirk D.NVIDIA CUDA software and GPU parallel computing architecture[C]//Proc of ISMM, 2007:103-104." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nvidia cuda software and gpu parallel computing architecture">
                                        <b>[6]</b>
                                         Kirk D.NVIDIA CUDA software and GPU parallel computing architecture[C]//Proc of ISMM, 2007:103-104.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" The top 10 innovations in the new NVIDIA Fermi architecture, and the top 3 next challenges [EB/OL].[2009-09-30].https://www.nvidia.com/content/PDF/fermi_white_papers/D.Patterson_Top10InnovationsInNVIDIAFermi.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The top 10 innovations in the new NVIDIA Fermi architecture,and the top 3 next challenges">
                                        <b>[7]</b>
                                         The top 10 innovations in the new NVIDIA Fermi architecture, and the top 3 next challenges [EB/OL].[2009-09-30].https://www.nvidia.com/content/PDF/fermi_white_papers/D.Patterson_Top10InnovationsInNVIDIAFermi.pdf.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Hammarlund P, Martinez A J, Bajwa A A, et al.Haswell:The fourth-generation Intel core processor[J].IEEE Micro, 2014, 34 (2) :6-20." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Haswell:The Fourth-Generation Intel Core Processor">
                                        <b>[8]</b>
                                         Hammarlund P, Martinez A J, Bajwa A A, et al.Haswell:The fourth-generation Intel core processor[J].IEEE Micro, 2014, 34 (2) :6-20.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Ghorpade J, Parande J, Kulkarni M, et al.GPGPU processing in CUDA architecture[J].Advanced Computing, 2012, 3 (1) :105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=GPGPU processing in CUDA architecture">
                                        <b>[9]</b>
                                         Ghorpade J, Parande J, Kulkarni M, et al.GPGPU processing in CUDA architecture[J].Advanced Computing, 2012, 3 (1) :105.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Rogers P, Fellow A.Heterogeneous system architecture overview[C]//Proc of 2013 IEEE Hot Chips 25 Symposium, 2013:1-41." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Heterogeneous System Architecture Overview">
                                        <b>[10]</b>
                                         Rogers P, Fellow A.Heterogeneous system architecture overview[C]//Proc of 2013 IEEE Hot Chips 25 Symposium, 2013:1-41.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Kim Y, Lee J, Kim D, et al.ScaleGPU:GPU architecture for memory-unaware GPU programming[J].IEEE Computer Architecture Letters, 2014, 13 (2) :101-104." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;ScaleGPU:GPU Architecture for Memory-Unaware GPU Programming,&amp;quot;">
                                        <b>[11]</b>
                                         Kim Y, Lee J, Kim D, et al.ScaleGPU:GPU architecture for memory-unaware GPU programming[J].IEEE Computer Architecture Letters, 2014, 13 (2) :101-104.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Lustig D, Martonosi M.Reducing GPU offload latency via fine-grained CPU-GPU synchronization[C]//Proc of 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA) , 2013:354-365." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reducing GPU offload latency via fine-grained CPU-GPU synchronization">
                                        <b>[12]</b>
                                         Lustig D, Martonosi M.Reducing GPU offload latency via fine-grained CPU-GPU synchronization[C]//Proc of 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA) , 2013:354-365.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Cao Y, Chen L, Zhang Z.Flexible memory:A novel main memory architecture with block-level memory compression[C]//Proc of 2015 IEEE International Conference on Networking, Architecture and Storage (NAS) , 2015:285-294." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Flexible memory:A novel main memory architecture with block-level memory compression">
                                        <b>[13]</b>
                                         Cao Y, Chen L, Zhang Z.Flexible memory:A novel main memory architecture with block-level memory compression[C]//Proc of 2015 IEEE International Conference on Networking, Architecture and Storage (NAS) , 2015:285-294.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Agarwal N, Nellans D, Stephenson M, et al.Page placement strategies for GPUs within heterogeneous memory systems[C]//Proc of ACM SIGPLAN Notices, 2015:607-618." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Page placement strategies for GPUs within heterogeneous memory systems">
                                        <b>[14]</b>
                                         Agarwal N, Nellans D, Stephenson M, et al.Page placement strategies for GPUs within heterogeneous memory systems[C]//Proc of ACM SIGPLAN Notices, 2015:607-618.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Agarwal N, Nellans D, Connor M O, et al.Unlocking bandwidth for GPUs in cc-numa systems[C]//Proc of 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , 2015:354-365." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unlocking bandwidth for GPUs in cc-numa systems">
                                        <b>[15]</b>
                                         Agarwal N, Nellans D, Connor M O, et al.Unlocking bandwidth for GPUs in cc-numa systems[C]//Proc of 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , 2015:354-365.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" GPGPUSim 3.x manual [EB/OL].[2017-06-13].http://gpgpu-sim.org/manual/index.php/Main_Page." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=GPGPUSim 3.x manual">
                                        <b>[16]</b>
                                         GPGPUSim 3.x manual [EB/OL].[2017-06-13].http://gpgpu-sim.org/manual/index.php/Main_Page.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Ajanovic J.PCI Express 3.0 overview[C]//Proc of 2009 IEEE Hot Chips:21 Symposium, 2009:1-61." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PCI Express 3.0 Overview">
                                        <b>[17]</b>
                                         Ajanovic J.PCI Express 3.0 overview[C]//Proc of 2009 IEEE Hot Chips:21 Symposium, 2009:1-61.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" PCI Express 4.0 electrical previews[EB/OL].[2018-50-01].http://pcisig.com/sites/default/files/files/01_05_PCIe_4_0_Electrical_Previews_FROZEN.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PCI Express 4.0 electrical previews">
                                        <b>[18]</b>
                                         PCI Express 4.0 electrical previews[EB/OL].[2018-50-01].http://pcisig.com/sites/default/files/files/01_05_PCIe_4_0_Electrical_Previews_FROZEN.pdf.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Bakhoda A, Yuan G L, Fung W W, et al.Analyzing cuda workloads using a detailed GPU simulator[C]//Proc of 2009 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) , 2009:163-174." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analyzing CUDA workloads using a detailed GPU simulator">
                                        <b>[19]</b>
                                         Bakhoda A, Yuan G L, Fung W W, et al.Analyzing cuda workloads using a detailed GPU simulator[C]//Proc of 2009 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) , 2009:163-174.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(07),1168-1175 DOI:10.3969/j.issn.1007-130X.2019.07.004            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>通过部分页迁移实现CPU-GPU高效透明的数据通信</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%AF%97%E6%83%85&amp;code=42267102&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张诗情</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E8%80%80%E5%8D%8E&amp;code=20297514&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨耀华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B2%88%E7%AB%8B&amp;code=20871192&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">沈立</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%BF%97%E8%8B%B1&amp;code=20250881&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王志英</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%BD%E9%98%B2%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0269230&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国防科技大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>尽管对集成GPU和下一代互连的研究投入日益增加, 但由PCI Express连接的独立GPU仍占据市场的主导地位, CPU和GPU之间的数据通信管理仍在不断发展。最初, 程序员显式控制CPU和GPU之间的数据传输。为了简化编程, GPU供应商开发了一种编程模型, 为“CPU+GPU”异构系统提供单个虚拟地址空间。此模型中的页迁移机制会自动根据需要在CPU和GPU之间迁移页面。为了满足高性能工作负载的需求, 页面大小有增大趋势。受低带宽和高延迟互连的限制, 较大的页面迁移延迟时间较长, 这可能会影响计算和传输的重叠并导致严重的性能下降。提出了部分页迁移机制, 它只迁移页面的所需部分, 以缩短迁移延迟并避免页面变大时整页迁移的性能下降。实验表明, 当页面大小为2 MB且PCI Express带宽为16 GB/s时, 部分页迁移可以显著隐藏整页迁移的性能开销, 相比于程序员控制数据传输, 整页迁移有平均98.62%倍的减速, 而部分页迁移可以实现平均1.29倍的加速。此外, 我们测试了页面大小对快表缺失率的影响以及迁移单元大小对性能的影响, 使设计人员能够基于这些信息做出决策。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E2%80%9CCPU%2BGPU%E2%80%9D%E5%BC%82%E6%9E%84%E7%B3%BB%E7%BB%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">“CPU+GPU”异构系统;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据通信;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A1%B5%E8%BF%81%E7%A7%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">页迁移;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张诗情 (1994-) , 女, 四川眉山人, 硕士生, 研究方向为并行编程和优化技术。E-mail:zhangshiqing12@nudt.edu.cn通信地址:410073湖南省长沙市国防科技大学计算机学院;
                                </span>
                                <span>
                                    杨耀华 (1994-) , 男, 山东临沂人, 硕士生, 研究方向为高性能处理器和优化技术。E-mail:yangyaohua16@nudt.edu.cn通信地址:410073湖南省长沙市国防科技大学计算机学院;
                                </span>
                                <span>
                                    沈立 (1975-) , 男, 四川成都人, 博士, 教授, CCF会员 (12903S) , 研究方向为计算机体系结构、系统结构虚拟化和动态编译优化。E-mail:lishen@nudt.edu.cn通信地址:410073湖南省长沙市国防科技大学计算机学院;
                                </span>
                                <span>
                                    王志英 (1956-) , 男, 山西长治人, 博士, 教授, CCF会员 (E2000055595) , 研究方向为高性能计算机体系结构、异步微处理器设计和计算机系统安全。E-mail:zy-wang@nudt.edu.cn通信地址:410073湖南省长沙市国防科技大学计算机学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-19</p>

            </div>
                    <h1><b>Efficient and transparent CPU-GPU data communication through partial page migration</b></h1>
                    <h2>
                    <span>ZHANG Shi-qing</span>
                    <span>YANG Yao-hua</span>
                    <span>SHEN Li</span>
                    <span>WANG Zhi-ying</span>
            </h2>
                    <h2>
                    <span>School of Computer, National University of Defense Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Despite the increasing investment in integrated GPUs and next-generation interconnect research, discrete GPUs connected by PCI Express still dominate the market, and the management of data communication between CPUs and GPUs continues to evolve. Initially, the programmers control the data transfer between CPUs and GPUs explicitly. To simplify programming, GPU vendors have developed a programming model to provide a single virtual address space for “CPU + GPU” heterogeneous systems. The page migration engine in this model transfers pages between CPUs and GPUs on demand automatically. To meet the needs of high-performance workloads, the page size tends to be larger. Limited by low bandwidth and high latency interconnections, larger page migration has longer delay, which can reduce the overlap of computation and transmission and cause severe performance degradation. We propose a partial page migration mechanism that only transfers the requested part of a page to shorten the migration latency and avoid performance degradation of the whole page migration when the page becomes larger. Experiments show that the proposed partial page migration can well hide the performance overheads of the whole page migration when the page size is 2 MB and the PCI Express bandwidth is 16 GB/sec. Compared with data transmission controlled by the programmers, the whole page migration degrades the performance by 98.62 on average, while the partial page migration upgrades the performance by 1.29 on average. Additionally, we examine the impact of page size on TLB miss rate and the impact of migration unit size on execution time, enabling designers to make informed decisions based on this information.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=heterogeneous%20%E2%80%9CCPU%20%2B%20GPU%E2%80%9D%20system&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">heterogeneous “CPU + GPU” system;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=data%20communication&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">data communication;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=page%20migration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">page migration;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHANG Shi-qing, born in 1994, MS candidate, her research interests include parallel programming, and optimization techniques.Address:School of Computer, National University of Defense Technology, Changsha 410073, Hunan, P.R.China;
                                </span>
                                <span>
                                    YANG Yao-hua, born in 1994, MS candidate, his research interests include high performance processor, and optimization techniques.Address:School of Computer, National University of Defense Technology, Changsha 410073, Hunan, P.R.China;
                                </span>
                                <span>
                                    SHEN Li, born in 1975, PhD, professor, CCF member (12903S) , his research interests include computer architecture, system architecture virtualization, and dynamic compilation optimization.Address:School of Computer, National University of Defense Technology, Changsha 410073, Hunan, P.R.China;
                                </span>
                                <span>
                                    WANG Zhi-ying, born in 1956, PhD, professor, CCF member (E2000055595) , his research interests include high performance computer architecture, asynchronous microprocessor design, and computer system security.Address:School of Computer, National University of Defense Technology, Changsha 410073, Hunan, P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-19</p>
                            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="42">图形处理单元GPU (Graphic Processing Unit) 已被广泛应用于现代高性能计算系统。由于数据处理和传输之间巨大的性能差距, CPU与GPU之间的数据通信成为异构“CPU+GPU”系统中的关键问题。统一内存 (Unified Memory) 创建了一个由CPU和GPU共享的托管内存池, 桥接了CPU与GPU之间的鸿沟<citation id="109" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。系统软件在GPU和CPU之间自动迁移统一内存中的数据<citation id="110" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。统一内存带来至少2个优点:首先, 简化了编程和内存模型。其次, 通过在CPU和GPU之间按需迁移数据, 统一内存可以在GPU上提供访问本地数据的性能。</p>
                </div>
                <div class="p1">
                    <p id="43">在统一内存中, 数据通常以页面为单位进行迁移。页面大小在多个方面影响性能。当采用小页面 (例如4 KB) 时, 由于每次要迁移的数据量小, 页迁移延迟较低, 因此迁移和计算的重叠率很高。但是, 使用小页面可能会降低转换检测缓冲区TLB (Translation Lookaside Buffer) 命中率并生成更多的页表查询操作, 导致更大的地址转换开销<citation id="111" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。当使用大页面 (例如2 MB) 时, 页迁移延迟大, 而地址转换开销较低<citation id="112" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。同时, 由于应用程序数据访问的不连续性, 被迁移的大页面在短时间内只被访问了一小部分。当页面大小为2MB时, 我们对10个基准测试进行了实验, 结果显示被迁移页面的被访问比例小于5%。这种不必要的数据传输会导致带宽浪费, 还会阻塞后续的数据迁移。</p>
                </div>
                <div class="p1">
                    <p id="44">整页迁移机制使用整个页面作为迁移单元和内存管理单元, 很难在大小页面各自的利弊之间进行权衡。因此, 有必要优化页迁移机制本身来综合不同页面大小的优点。新的迁移机制应当在优化地址转换的同时限制迁移延迟, 并且满足大规模应用的CPU-GPU通信需求。</p>
                </div>
                <div class="p1">
                    <p id="45">为了解决这些问题, 本文提出了一种透明的部分页迁移机制, 即只迁移被请求的部分页, 而不是其所在的整个页面。为了实现部分页迁移, 我们在页面状态列表中添加部分有效的状态, 同时在页表项中记录已经迁移到GPU的页内范围, 本文称之为有效范围。实验表明, 部分页迁移相对于整页迁移获得了显著的性能改进。其中单个有效范围的部分页迁移实现了55.94倍的加速, 多个有效范围的部分页迁移实现了93.81倍的加速。此外, 与程序员控制传输机制相比, 部分页转移对程序员来说更简单和方便。</p>
                </div>
                <div class="p1">
                    <p id="46">本文的贡献总结如下:</p>
                </div>
                <div class="p1">
                    <p id="47"> (1) 提出了一种透明的部分页迁移机制, 可以根据需要自动迁移页面的被请求部分, 并在不修改程序代码和运行时库的情况下应用。</p>
                </div>
                <div class="p1">
                    <p id="48"> (2) 提出了两种部分页迁移的实现机制, 即单个有效范围的部分页迁移和多个有效范围的部分页迁移。</p>
                </div>
                <div class="p1">
                    <p id="49"> (3) 评估了不同页面大小的快表 (TLB) 失效率和部分页迁移对迁移单元大小的性能敏感性, 结果表明, 相对于整页迁移机制, 部分页迁移机制获得了显著的性能改进。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag"><b>2 相关工作</b></h3>
                <div class="p1">
                    <p id="51">CPU和GPU之间数据通信的发展经历了3个阶段: (1) CPU和GPU分别拥有自己的私有地址空间。在GPU执行计算之前, 程序员必须显式地将数据从CPU复制到GPU。这种程序员控制传输模型增加了编程的复杂性, 并使得数据传输和数据处理串行化<citation id="113" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。 (2) 引入了统一虚拟地址, 例如Intel的Haswell、AMD的Berlin处理器、NVIDIA的Fermi架构和ARM的Cortex内核<citation id="114" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。虽然统一虚拟地址提供了一些编程方便性, 但由于数据通信的低带宽和高延迟, 对于提高整体性能几乎没有帮助。而且它不能自动迁移数据。 (3) 统一内存是基于统一虚拟地址引入的, 例如Intel的Haswell、ARM的HSA和NVIDIA的Tesla <citation id="115" type="reference"><link href="3" rel="bibliography" /><link href="17" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">8</a>,<a class="sup">10</a>]</sup></citation>。数据可以在主机内存和设备内存之间自动迁移。统一内存简化了编程并具有提高性能的潜力。</p>
                </div>
                <div class="p1">
                    <p id="52">当前统一内存中的数据通信机制是整页迁移<citation id="116" type="reference"><link href="9" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">11</a>]</sup></citation>。当页面变大时, 使用整页迁移机制导致统一内存管理存在一些性能风险, 如引言部分第3段所述。</p>
                </div>
                <div class="p1">
                    <p id="53">Lustig等人<citation id="117" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>在GPU中利用F/E位实现了一种细粒度的同步方法, 通过重叠已传输数据的计算与剩余数据的传输来提高性能。但是, 它需要修改应用程序的源代码, 并对API进行扩展, 对程序员来说不透明。而本文提出的方法是根据需要自动迁移页面的所需部分, 无需修改应用程序和扩展API。子页面是一种精细的页面管理理念, 类似于本文中的部分页, 但目前它的应用场景和目的与本文的部分页不同, 主要用于减少数据规模或增加并行性, 从而加速计算<citation id="118" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。本文的部分页迁移是为了避免仅在请求部分页面时迁移整个页面, 以减少迁移延迟和带宽浪费。此外, 一些研究提出了页面放置机制和迁移阈值<citation id="119" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。本文的迁移机制是按需迁移被请求的部分页而不预设阈值, 这一机制基于以下结论:设置必要的硬件计数器来跟踪系统中的所有页面, 以区分其访问计数的开销, 超过了这一改进相对于简单的“首次请求即迁移”机制得到的性能提升<citation id="120" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <h3 id="54" name="54" class="anchor-tag"><b>3 部分页迁移</b></h3>
                <h4 class="anchor-tag" id="55" name="55"><b>3.1 基本理念</b></h4>
                <div class="p1">
                    <p id="56">为了减小页面变大时整页迁移所带来的迁移延迟和带宽浪费, 本文提出了一种新的迁移方法, 可以保持较大的页面, 同时调整每次迁移的数据量。这种迁移方法就是部分页迁移, 即只迁移页面的被请求部分, 并记录已迁移到GPU本地内存的数据范围。与整页迁移相比, 部分页迁移使迁移单元可调整, 并且每次迁移的数据都是被请求的部分, 而不是整个页面。这种方式可以有效缩短迁移延迟, 降低阻塞后续请求的概率, 并提高计算和传输的重叠率。在整页迁移中, 页面在系统中只有一个副本。在部分页迁移中, 页面可以部分迁移到GPU本地内存, 而其余部分仍在CPU端。为了实现部分页迁移, 需要修改页面状态管理和迁移过程。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57"><b>3.2 部分有效状态</b></h4>
                <div class="p1">
                    <p id="58">在整页迁移中, 有3种页面状态:无效 (not-valid) 、CPU中有效 (valid-in-CPU) 和GPU中有效 (valid-in-GPU) 。无效意味着页面尚未从硬盘传输到异构系统内存。CPU中有效表示页面处于CPU内存中, GPU不能在其本地内存中直接访问该页面。 GPU中有效表示页面已被迁移到GPU本地内存。当请求无效的页面时, 它可以通过页缺失处理从硬盘传输到CPU或直接传输到GPU, 并将状态更改为CPU中有效或GPU中有效。为了简化描述, 我们在下面的章节中不考虑无效状态。图1a显示了整页迁移的页面状态转换图。</p>
                </div>
                <div class="p1">
                    <p id="59">为了执行部分页迁移, 我们添加了部分有效 (partial-valid) 的页面转换状态, 记录页面的有效范围并根据页面迁移操作实时修改它。部分有效意味着页面已经有一部分从CPU内存迁移到GPU。部分页迁移的页面状态转换图如图1b所示。与整页迁移相比, 部分页迁移的状态转换过程具有以下变化: (1) 当页面状态为CPU中有效时, 如果有来自GPU的请求, 系统会将此页面的被请求部分迁移到GPU端, 将页面状态更改为部分有效并修改有效范围。 (2) 当页面状态为部分有效时, 如果有来自GPU的请求, 系统将继续迁移页面的被请求部分到GPU内存并修改有效范围。如果整个页面都已被迁移, 页面状态将被更改为GPU中有效。 (3) 当页面状态不是CPU中有效并且有来自CPU的请求时, 整个页面将被迁移到CPU, 页面状态被更改为CPU中有效。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907004_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 页面状态转换图" src="Detail/GetImg?filename=images/JSJK201907004_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 页面状态转换图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907004_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Page state transition graphs</p>

                </div>
                <h4 class="anchor-tag" id="61" name="61"><b>3.3 部分页迁移过程</b></h4>
                <div class="p1">
                    <p id="62">为了支持部分页迁移, 我们还需要对迁移过程的管理进行修改。部分页迁移过程如图2所示。首先, 来自GPU核的数据请求将所请求的地址和数据长度发送到GPU内存管理单元GMMU。接着, GMMU查询相应页面的状态和有效范围, 根据不同的页面状态, 对GPU的数据请求进行相应的处理。 (1) 如果页面状态为部分有效且被请求的数据在有效范围内, 或者页面状态为GPU中有效, 则GMMU允许GPU直接在本地访问页面。 (2) 如果页面状态为部分有效并且所请求的数据范围不在有效范围内, 或者页面状态为CPU中有效, 则GMMU为该请求分配缓冲器条目并向CPU发送部分迁移请求。然后, 页面的被请求部分从CPU迁移到GPU。在部分页迁移完成后, GMMU更新页面的状态和有效范围, 并允许GPU直接在本地访问页面。</p>
                </div>
                <div class="p1">
                    <p id="63">在部分页迁移中, 添加页面状态和维护有效范围, 可以使GMMU快速确定是否需要迁移所请求的数据并在需要时向CPU发送迁移请求。在同一个周期内, 不同的核可能生成多个迁移请求。当缓冲区满时, 如果出现新的迁移请求, 它将阻塞并等待空闲的缓冲区条目。</p>
                </div>
                <div class="p1">
                    <p id="64">部分页迁移步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="65">①GPU核产生数据请求;</p>
                </div>
                <div class="p1">
                    <p id="66">②GMMU查询对应页面的状态和有效范围, 如果页面状态为GPU中有效或部分有效且请求范围在有效范围内, 则跳转至步骤⑥;</p>
                </div>
                <div class="p1">
                    <p id="67">③GMMU为请求分配迁移缓冲区条目;</p>
                </div>
                <div class="p1">
                    <p id="68">④GMMU向CPU发送迁移请求;</p>
                </div>
                <div class="p1">
                    <p id="69">⑤CPU向GPU迁移被请求的部分页;</p>
                </div>
                <div class="p1">
                    <p id="70">⑥GMMU修改对应页的状态和有效范围;</p>
                </div>
                <div class="p1">
                    <p id="71">⑦GMMU向核发送消息使其在本地访问数据。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907004_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 部分页迁移过程" src="Detail/GetImg?filename=images/JSJK201907004_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 部分页迁移过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907004_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Process of partial page migration</p>

                </div>
                <h3 id="73" name="73" class="anchor-tag"><b>4 迁移机制</b></h3>
                <h4 class="anchor-tag" id="74" name="74"><b>4.1 单一有效范围的部分页迁移</b></h4>
                <div class="p1">
                    <p id="75">要将部分页迁移应用于异构系统, 最简单的方法是向页面状态列表添加部分有效状态, 同时由页表项记录并维护一个有效范围, 包括有效范围起始处的页面偏移量和有效范围的长度。当新请求的范围与页面有效范围不连续时, 将间隙与请求部分一起迁移以保持连续的有效范围。因此, 页面迁移时有效范围始终保持连续。</p>
                </div>
                <div class="p1">
                    <p id="76">如果不考虑CPU产生的请求和无效页面状态, 则单个有效范围的部分页迁移机制的工作方式如图3a所示。 (1) 如果页面状态为GPU中有效, 则GPU可以直接访问本地内存中的数据, 页面状态和有效范围保持不变。 (2) 如果页面状态为CPU中有效并且存在可用的缓冲区条目, 则为请求分配缓冲区条目并等待迁移。如果没有可用的缓冲区条目, 则请求将被阻止, 直到获得空闲条目。迁移请求完成后, GMMU会将页面状态从CPU中有效修改为部分有效, 并更新有效范围的起始页面偏移量和长度, 然后允许GPU直接访问本地内存中的数据。 (3) 如果页面状态是部分有效, GMMU将检查所请求的范围是否在有效范围内。如果是, 则处理过程与页面状态为GPU中有效时相同;如果不是, 则处理过程将与页面状态为CPU中有效时相同, 且若更新后的有效长度等于页面大小, 则GMMU将页面状态修改为GPU中有效。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907004_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 部分页迁移流程图" src="Detail/GetImg?filename=images/JSJK201907004_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 部分页迁移流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907004_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 Flow chart of partial page migration</p>

                </div>
                <div class="p1">
                    <p id="78">单一有效范围的部分页迁移是一种对整页迁移改动较少的部分页迁移实现方式。但是, 这种实现有一个明显的缺陷:当页面较大时, 如果出现较大的偏移间隙, 系统将会迁移大量未被请求数据, 以保持有效范围的连续性。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>4.2 多个有效范围的部分页迁移</b></h4>
                <div class="p1">
                    <p id="80">使用单个连续有效范围无法避免过大迁移长度的可能性。为了解决这个问题, 我们提出了第2种实现机制, 多个有效范围的部分页迁移, 在单个页面中启用多个不连续的有效范围。设定一个阈值, 当新请求的范围与页面有效范围不连续时, 若间隙长度小于阈值, 将间隙与请求部分一起迁移, 以保持连续的有效范围, 否则记录为另一个有效范围。</p>
                </div>
                <div class="p1">
                    <p id="81">为了实现多个有效范围的部分页迁移, 我们需要记录多个有效范围。数据请求根据有效范围分成可能具有不同长度和状态的迁移单元。迁移单元的状态可能是无效、CPU中有效或GPU中有效。 (1) 如果页面状态为GPU中有效, 则GPU在本地访问数据。 (2) 如果页面状态为在CPU中有效:首先, GMMU计算所请求的数据范围对应于哪些迁移单元。其次, GMMU检查每个被请求的迁移单位的有效状态。如果它在CPU中有效, 则GMMU向CPU发送一个迁移请求。迁移完成后, GPU将页面状态更改为GPU中有效并在本地访问此迁移单元。直到所有请求的迁移单元都在GPU中有效, 该请求才能完成。最后, GMMU根据迁移单元状态更新页面有效范围和页面状态。 (3) 如果页面状态是部分有效的, 则该过程类似于 (2) , 唯一的区别是迁移单元可能在GPU中有效, 那么GPU可以在本地访问它。多个有效范围的部分页迁移流程如图3b所示。</p>
                </div>
                <h3 id="82" name="82" class="anchor-tag"><b>5 实验和分析</b></h3>
                <div class="p1">
                    <p id="83">部分页迁移引入了一些新的系统参数, 包括页面大小、迁移单元大小和CPU-GPU互连带宽等。实验侧重于部分页迁移本身的参数以及 (1) 理想“传输+执行”重叠; (2) 程序员控制传输; (3) 整页迁移; (4) 部分页迁移之间的性能比较。理想“传输+执行”重叠代表计算和迁移完全并行时没有通信开销的理想情况。程序员控制传输代表计算和迁移完全串行的情况, 即GPU运行所需的所有数据在程序开始运行之前由程序员从CPU迁移到GPU。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>5.1 环境设置</b></h4>
                <div class="p1">
                    <p id="85">我们修改gpgpu-sim v3.x中的GTX480配置参数, 使它们更接近当前的GPU配置<citation id="121" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>;修改了模拟器的内存管理部分 (包括页表、TLB、迁移缓存等) , 增加了CPU-GPU数据通信模块。部分参数如表1所示。目前广泛使用的PCI Express 3.0×16的带宽为16 GB/s<citation id="122" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, PCI Express 4.0×16的带宽预计为32 GB/s<citation id="123" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。因此, 我们以16 GB/s和32 GB/s作为当前和未来带宽的代表进行测试。计时模型中的部分页迁移的额外开销包括查询和修改页面状态的开销。</p>
                </div>
                <div class="area_img" id="86">
                    <p class="img_tit"><b>表1 模拟器配置参数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Simulator configuration</b></p>
                    <p class="img_note"></p>
                    <table id="86" border="1"><tr><td><br />项目</td><td>参数值</td></tr><tr><td><br />模拟器</td><td>GPGPU-Sim 3.x</td></tr><tr><td><br />GPU架构</td><td>NVIDIA GTX-480 Fermi-like</td></tr><tr><td><br />GPU核</td><td>15 CUs @ 1.4 GHz</td></tr><tr><td><br />一级缓存</td><td>16 KB/CU</td></tr><tr><td><br />二级缓存</td><td>Memory Side 128 KB/DRAM Channel</td></tr><tr><td><br />快表项数 (per CU) </td><td>128-entry, 4-port, supporting hit under miss</td></tr><tr><td><br />时钟频率/MHz</td><td>Core:IC:L2:DRAM 700:700:700:1024</td></tr><tr><td><br />GPU GDDR5</td><td>12-channels, 384 GB/s aggregate</td></tr><tr><td><br />CPU-GPU互连带宽</td><td>16 GB/s or 32 GB/s</td></tr><tr><td><br />迁移缓存条目数</td><td>128 Entries/Memory Partition</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="87">10个基准测试来自不同的基准测试集或被应用于不同的领域。BFS、MUM和NN来自Rodinia测试集, CP来自Parboil测试集。它们在应用程序属性上有所不同, 例如线程的组织、GPU上利用的内存空间、数据量和计算量等<citation id="124" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。通过对这些应用进行测试, 可以显示部分页迁移对具有不同属性的应用程序的影响。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>5.2 单一有效范围的部分页迁移</b></h4>
                <div class="p1">
                    <p id="89">首先, 我们测试了页面大小为2 MB时单个有效范围的部分页迁移的性能, 所有数据在初始化时都在CPU内存中。单一有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较结果如图4所示。由于整页迁移的执行时间过长, 在图4中只给出20以内的标准化时间。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907004_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 单一有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较" src="Detail/GetImg?filename=images/JSJK201907004_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 单一有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907004_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 Performance comparison of single valid range partial page migration, programmers controlled transfer and whole-page migration</p>

                </div>
                <div class="p1">
                    <p id="91">当不采用额外的优化机制时, 整页迁移的性能最差, 因为2 MB页面的迁移延迟太长, 不能重叠, 并且大部分被迁移的数据都未得到使用。对于LIB和WP, 采用2 MB页面的整页迁移的性能相对可以接受。这是因为它们所请求的数据在内存中分布密集, 占用了被迁移页面中相对较大的比例。</p>
                </div>
                <div class="p1">
                    <p id="92">当带宽为16 GB/s时, 单个有效范围的部分页迁移的性能远远优于整页迁移的。在许多情况下, 与程序员控制传输相比, 单个有效范围的部分页迁移可以获得接近甚至更好的性能。但是, 对于LPS和MUM, 单一有效范围的部分页迁移的性能比程序员控制转移的性能差得多。这种现象证明了单一有效范围的缺陷。与程序员控制传输相比, 整页迁移有平均98.62%倍的减速, 而单一有效范围的部分页迁移只有平均30%的减速。也就是说, 单个有效范围的部分页迁移相对于整页迁移获得了平均55.94倍的加速。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907004_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 带宽为16 GB/s时迁移单元大小对多个有效范围的部分迁移性能的影响" src="Detail/GetImg?filename=images/JSJK201907004_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 带宽为16 GB/s时迁移单元大小对多个有效范围的部分迁移性能的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907004_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5 Effect of migration unit size on the performance of partial  migration with multiple valid ranges when the bandwidth is 16 GB/s</p>

                </div>
                <div class="p1">
                    <p id="94">当带宽从16 GB/s增加到32 GB/s时, 单一有效范围的部分页迁移和程序员控制传输之间的平均性能差距从30%下降到10%, 且相对于整页迁移获得了平均70.64倍的加速。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95"><b>5.3 多个有效范围的部分页迁移</b></h4>
                <h4 class="anchor-tag" id="96" name="96"> (1) 迁移单位大小。</h4>
                <div class="p1">
                    <p id="97">迁移单元大小对性能具有显著的影响, 为了简化实现并分析需要支持的有效范围数量, 将每组实验中迁移单位的长度设为一个固定值。实验使用2 MB页面和16 GB/s带宽, 更改迁移单元的大小并确保它大于每个时钟周期可传输的字节数, 以避免带宽浪费。</p>
                </div>
                <div class="p1">
                    <p id="98">如图5所示, 对于不同大小的迁移单元, 各测试程序的性能改变的总体趋势是一致的。随着迁移单元变大, 性能下降, 并且下降率与迁移单元大小不成比例。这是由于当迁移单元较小时被计算隐藏的延迟随着迁移单元的增大不再被隐藏。可以看出, 对于被请求的数据在内存中密集分布的测试程序 (如LIB) , 迁移单元可以取得相对较大, 以实现更高的带宽利用率。但是, 对于被请求的数据在内存中稀疏分布的应用, 采用较大的迁移单元会浪费时间来移动不必要的数据, 对性能有不利影响。</p>
                </div>
                <div class="p1">
                    <p id="99">此外, 我们统计分析了应用执行后页面有效范围, 结果表明, 页面内通常存在2个或3个不连续的有效范围, 因此多个有效范围的部分页迁移中支持的有效范围数可以限制为4或8。</p>
                </div>
                <h4 class="anchor-tag" id="100" name="100"> (2) TLB失效率。</h4>
                <div class="p1">
                    <p id="101">TLB缓存最近使用的虚拟地址及其地址转换, 有助于降低地址转换延迟开销。然而, 显著增加的GPU内存容量、有限的TLB条目数和单指令多线程执行模型使得GPU的TLB失效率难以降低。上述实验结果表明, 部分页迁移可以解决大页面整页迁移的问题, 使页迁移机制对大页面有效。可以推测, 较大的页面使得TLB可以利用有限的条目覆盖较大的存储空间, 从而降低TLB失效率并改善性能。我们测试了页面大小分别为4 KB和2 MB时部分页迁移的TLB失效率。测试所用的TLB具有256个共享条目, GPU存储器容量为1 536 MB。结果表明, 当页面大小为2 MB时, 平均TLB失效率为64.76%, 明显低于页面大小为4 KB时的89.72%。</p>
                </div>
                <h4 class="anchor-tag" id="102" name="102"> (3) 性能比较。</h4>
                <div class="p1">
                    <p id="103">本组实验使用1 KB迁移单位作为多个有效范围的部分页迁移的代表, 页面大小为2 MB。实验结果如图6所示。当带宽为16 GB/s时, 多个有效范围的部分页迁移的性能远远优于整页迁移的。在许多情况下, 与程序员控制传输相比, 它可以获得接近甚至更好的性能。与图5展示的单一有效范围的部分页迁移相比, 多个有效范围的部分页迁移表现更好。以LPS为例, 当采用单一有效范围的部分页迁移时, 其执行时间接近程序员控制传输的2倍。但是, 当采用多个有效范围的部分页迁移时, 与程序员控制传输的性能差距仅为30%左右。这一变化证明多个有效范围的部分页迁移可以弥补单个有效范围的部分页迁移的缺陷。与程序员控制转移相比, 整页迁移有平均98.62%倍的减速, 而多个有效范围的部分页迁移获得了平均1.29倍的加速。也就是说, 多个有效范围的部分页迁移获得了相对于整页迁移的93.81倍加速。</p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907004_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 多个有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较" src="Detail/GetImg?filename=images/JSJK201907004_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 多个有效范围的部分页迁移、程序员控制传输和整页迁移的性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907004_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 6 Performance comparison among multiple valid range partial page migration, programmers controlled transfer and whole page migration</p>

                </div>
                <div class="p1">
                    <p id="105">当带宽从16 GB/s增加到32 GB/s时, 与程序员控制的传输相比, 整页迁移有平均98.72%倍的减速, 而多个有效范围的部分页迁移获得了平均1.22倍的加速。也就是说, 多个有效范围的部分页迁移获得了相对于整页迁移的94.99倍加速。</p>
                </div>
                <div class="p1">
                    <p id="106">通过设置有限数量的有效范围 (根据实验结果, 页面最多有2～3个不连续的请求范围) , 部分页迁移不仅比程序员控制传输更简单方便, 而且还具有性能优势。这是因为部分页迁移限制了迁移单元的大小, 所以迁移延迟更短, 可以通过计算隐藏。但是, 与理想“传输+执行”重叠相比, 对于请求数据在内存中稀疏分布或请求时间间隔较短 (如LPS和MUM) 的应用, 仍存在一些性能差距, 因为传输时间不能被完全隐藏。</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag"><b>6 结束语</b></h3>
                <div class="p1">
                    <p id="108">本文研究了整页迁移中页面增大 (从4 KB到2 MB) 对应用程序性能的影响。测试结果显示, 较大的页面会导致严重的性能下降。当页面较大时, 迁移延迟变长, 计算和传输的并行度降低, 从而导致性能变差。本文提出的部分页迁移机制可以在使用大页面的情况下缩短迁移延迟。本文采用2种机制实现了部分页迁移, 即单一有效范围的部分页迁移和多个有效范围的部分页迁移。实验结果显示, 当页面大小为2 MB时, 若带宽为16 GB/s, 与程序员控制传输相比, 整页迁移有平均98.62%的减速, 而多个有效范围的部分页迁移获得了平均1.29倍的加速。实验结果表明, 在大多数情况下, 部分页迁移相对于整页迁移具有显著的性能优势。部分页迁移不仅能满足高性能工作负载对大页面的需求, 而且还可以限制页面大小增加时可能出现的性能下降。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="126" type="formula" href="images/JSJK201907004_12600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">张诗情</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="128" type="formula" href="images/JSJK201907004_12800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">杨耀华</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="130" type="formula" href="images/JSJK201907004_13000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">沈立</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="132" type="formula" href="images/JSJK201907004_13200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">王志英</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=NVIDIA Tesla: A unified graphics and computing architecture">

                                <b>[1]</b> Lindholm E, Nickolls J, Oberman S, et al.NVIDIA Tesla:A unified graphics and computing architecture[J].IEEE Micro, 2008, 28 (2) :39-55.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fault mitigation strategies for CUDA GPUs">

                                <b>[2]</b> Di Carlo S, Gambardella G, Martella I, et al.Fault mitigation strategies for CUDA GPUs[C]//Proc of 2013 IEEE International Test Conference (ITC) , 2013:18.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supporting x86-64 address translation for 100s of GPU lanes">

                                <b>[3]</b> Power J, Hill M D, Wood D A.Supporting x86-64 address translation for 100s of GPU lanes[C]//Proc of 2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA) , 2014:568-578.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards high performance paged memory for GPUs">

                                <b>[4]</b> Zheng T, Nellans D, Zulfiqar A, et al.Towards high performance paged memory for GPUs[C]//Proc of 2016 IEEE International Symposium on High Performance Computer Architecture (HPCA) , 2016:345-357.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An investigation of Unified Memory Access performance in CUDA">

                                <b>[5]</b> Landaverde R, Zhang T, Coskun A K, et al.An investigation of unified memory access performance in CUDA[C]//Proc of IEEE High Performance Extreme Computing Conference (HPEC) , 2014:1-6.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nvidia cuda software and gpu parallel computing architecture">

                                <b>[6]</b> Kirk D.NVIDIA CUDA software and GPU parallel computing architecture[C]//Proc of ISMM, 2007:103-104.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The top 10 innovations in the new NVIDIA Fermi architecture,and the top 3 next challenges">

                                <b>[7]</b> The top 10 innovations in the new NVIDIA Fermi architecture, and the top 3 next challenges [EB/OL].[2009-09-30].https://www.nvidia.com/content/PDF/fermi_white_papers/D.Patterson_Top10InnovationsInNVIDIAFermi.pdf.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Haswell:The Fourth-Generation Intel Core Processor">

                                <b>[8]</b> Hammarlund P, Martinez A J, Bajwa A A, et al.Haswell:The fourth-generation Intel core processor[J].IEEE Micro, 2014, 34 (2) :6-20.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=GPGPU processing in CUDA architecture">

                                <b>[9]</b> Ghorpade J, Parande J, Kulkarni M, et al.GPGPU processing in CUDA architecture[J].Advanced Computing, 2012, 3 (1) :105.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Heterogeneous System Architecture Overview">

                                <b>[10]</b> Rogers P, Fellow A.Heterogeneous system architecture overview[C]//Proc of 2013 IEEE Hot Chips 25 Symposium, 2013:1-41.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;ScaleGPU:GPU Architecture for Memory-Unaware GPU Programming,&amp;quot;">

                                <b>[11]</b> Kim Y, Lee J, Kim D, et al.ScaleGPU:GPU architecture for memory-unaware GPU programming[J].IEEE Computer Architecture Letters, 2014, 13 (2) :101-104.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reducing GPU offload latency via fine-grained CPU-GPU synchronization">

                                <b>[12]</b> Lustig D, Martonosi M.Reducing GPU offload latency via fine-grained CPU-GPU synchronization[C]//Proc of 2013 IEEE 19th International Symposium on High Performance Computer Architecture (HPCA) , 2013:354-365.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Flexible memory:A novel main memory architecture with block-level memory compression">

                                <b>[13]</b> Cao Y, Chen L, Zhang Z.Flexible memory:A novel main memory architecture with block-level memory compression[C]//Proc of 2015 IEEE International Conference on Networking, Architecture and Storage (NAS) , 2015:285-294.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Page placement strategies for GPUs within heterogeneous memory systems">

                                <b>[14]</b> Agarwal N, Nellans D, Stephenson M, et al.Page placement strategies for GPUs within heterogeneous memory systems[C]//Proc of ACM SIGPLAN Notices, 2015:607-618.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unlocking bandwidth for GPUs in cc-numa systems">

                                <b>[15]</b> Agarwal N, Nellans D, Connor M O, et al.Unlocking bandwidth for GPUs in cc-numa systems[C]//Proc of 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA) , 2015:354-365.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=GPGPUSim 3.x manual">

                                <b>[16]</b> GPGPUSim 3.x manual [EB/OL].[2017-06-13].http://gpgpu-sim.org/manual/index.php/Main_Page.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PCI Express 3.0 Overview">

                                <b>[17]</b> Ajanovic J.PCI Express 3.0 overview[C]//Proc of 2009 IEEE Hot Chips:21 Symposium, 2009:1-61.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PCI Express 4.0 electrical previews">

                                <b>[18]</b> PCI Express 4.0 electrical previews[EB/OL].[2018-50-01].http://pcisig.com/sites/default/files/files/01_05_PCIe_4_0_Electrical_Previews_FROZEN.pdf.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analyzing CUDA workloads using a detailed GPU simulator">

                                <b>[19]</b> Bakhoda A, Yuan G L, Fung W W, et al.Analyzing cuda workloads using a detailed GPU simulator[C]//Proc of 2009 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS) , 2009:163-174.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201907004" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907004&amp;v=MjI5NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVnJyTEx6N0JaYkc0SDlqTXFJOUZZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
