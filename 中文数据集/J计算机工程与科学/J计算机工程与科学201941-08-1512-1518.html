<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132366181905000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201908025%26RESULT%3d1%26SIGN%3d3aDwi6qZo20racC7VLFTXqqQshk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201908025&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201908025&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201908025&amp;v=MDQwOTFNcDQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2xWTHZCTHo3QlpiRzRIOWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="&lt;b&gt;2 关键技术&lt;/b&gt; "><b>2 关键技术</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="&lt;b&gt;2.1 词汇语义相关度&lt;/b&gt;"><b>2.1 词汇语义相关度</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;2.2 BTM算法&lt;/b&gt;"><b>2.2 BTM算法</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;2.3 改进的SimRank算法&lt;/b&gt;"><b>2.3 改进的SimRank算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#116" data-title="&lt;b&gt;3 构建微博检索模型&lt;/b&gt; "><b>3 构建微博检索模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#120" data-title="&lt;b&gt;3.1 基于标签的特征相关度计算&lt;/b&gt;"><b>3.1 基于标签的特征相关度计算</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;3.2 结合BTM主题的相关度计算&lt;/b&gt;"><b>3.2 结合BTM主题的相关度计算</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;3.3 基于图论的相关度计算&lt;/b&gt;"><b>3.3 基于图论的相关度计算</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#149" data-title="&lt;b&gt;4 实验&lt;/b&gt; "><b>4 实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#150" data-title="&lt;b&gt;4.1 实验环境与数据集&lt;/b&gt;"><b>4.1 实验环境与数据集</b></a></li>
                                                <li><a href="#153" data-title="&lt;b&gt;4.2 模型评估指标&lt;/b&gt;"><b>4.2 模型评估指标</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;4.3 实验结果分析&lt;/b&gt;"><b>4.3 实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#172" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="图1 语义分类树">图1 语义分类树</a></li>
                                                <li><a href="#72" data-title="图2 BTM的图解模型">图2 BTM的图解模型</a></li>
                                                <li><a href="#119" data-title="图3 本文微博检索模型流程结构">图3 本文微博检索模型流程结构</a></li>
                                                <li><a href="#165" data-title="&lt;b&gt;表1 实验中各阶段相关度的最优结果参数值&lt;/b&gt;"><b>表1 实验中各阶段相关度的最优结果参数值</b></a></li>
                                                <li><a href="#167" data-title="&lt;b&gt;表2 综合模型中各项参数对实验模型中评估指标的影响&lt;/b&gt;"><b>表2 综合模型中各项参数对实验模型中评估指标的影响</b></a></li>
                                                <li><a href="#169" data-title="图4 3种模型的综合评估比较">图4 3种模型的综合评估比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="193">


                                    <a id="bibliography_1" title=" Li Yu-qing, Li Xin, Han Xu, et al.A bilingual lexicon-based multi-class semantic orientation analysis for microblogs [J].Acta Electronica Sinica, 2016, 44 (9) :2068-2073. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201609007&amp;v=MDAxODRlN0c0SDlmTXBvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdsVkx2QUlUZlQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Li Yu-qing, Li Xin, Han Xu, et al.A bilingual lexicon-based multi-class semantic orientation analysis for microblogs [J].Acta Electronica Sinica, 2016, 44 (9) :2068-2073. (in Chinese) 
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_2" title=" Kingma D P, Rezende D J, Mohamed S, et al.Semi-supervised learning with deep generative models[C]//Proc of the 27th International Conference on Neural Information Processing Systems, 2014:3581-3589." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semisupervised learning with deep generative models">
                                        <b>[2]</b>
                                         Kingma D P, Rezende D J, Mohamed S, et al.Semi-supervised learning with deep generative models[C]//Proc of the 27th International Conference on Neural Information Processing Systems, 2014:3581-3589.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_3" title=" Wei Bing-jie, Shi Liang, Wang Bin.Combining cluster and temporal information for microblog search[J].Journal of Chinese Information Processing, 2015, 29 (3) :177-183. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201503026&amp;v=MzE2MzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2xWTHZBS0NqWWZiRzRIOVRNckk5SFk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Wei Bing-jie, Shi Liang, Wang Bin.Combining cluster and temporal information for microblog search[J].Journal of Chinese Information Processing, 2015, 29 (3) :177-183. (in Chinese) 
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_4" >
                                        <b>[4]</b>
                                     Liu De-xi, Fu Qi, Wei Ya-xiong, et al.Social short text retrieval based on multiple-enhanced graph and topic model[J].Journal of Chinese Information Processing, 2018, 32 (3) :110-119. (in Chinese) </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     Han Zhong-yuan, Yang Mu-yun, Kong Lei-lei, et al.Query expansion based on term time distribution for microblog retrieval[J].Chinese Journal of Computers, 2016, 39 (10) :2031-2044. (in Chinese) </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_6" title=" Meij E, Weerkamp W, de Rijke M.Adding semantics to microblog posts[C]//Proc of the 5th ACM International Conference on Web Search and Data Mining, 2012:563-572." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adding Semantics to Microblog Posts">
                                        <b>[6]</b>
                                         Meij E, Weerkamp W, de Rijke M.Adding semantics to microblog posts[C]//Proc of the 5th ACM International Conference on Web Search and Data Mining, 2012:563-572.
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_7" title=" Saif A, ab Aziz M J, Omar N.Reducing explicit semantic representation vectors using Latent Dirichlet Allocation[J].Knowledge-Based Systems, 2016, 100 (C) :145-159." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reducing explicit semantic representation vectors using latent Dirichlet allocation">
                                        <b>[7]</b>
                                         Saif A, ab Aziz M J, Omar N.Reducing explicit semantic representation vectors using Latent Dirichlet Allocation[J].Knowledge-Based Systems, 2016, 100 (C) :145-159.
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_8" title=" Yan X H, Guo J F, Lan Y Y, et al.A biterm topic model for short texts[C]//Proc of the 22nd International Conference on World Wide Web, 2013:1445-1456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Biterm topic model for short texts">
                                        <b>[8]</b>
                                         Yan X H, Guo J F, Lan Y Y, et al.A biterm topic model for short texts[C]//Proc of the 22nd International Conference on World Wide Web, 2013:1445-1456.
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_9" title=" Kalloubi F, Nfaoui E H, Beqqali O E.Microblog semantic context retrieval system based on linked open data and graph-based theory[J].Expert Systems with Applications, 2016, 53:138-148." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1243A100B393211AF116872D4AB49137&amp;v=MDI4NjhGdWdHRDM0NHptZGw2ejU3UUhqZzJCWkVDN2FkUkxtWUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHdyaTR4S0E9TmlmT2ZiSzZHdEs5cm85Rg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Kalloubi F, Nfaoui E H, Beqqali O E.Microblog semantic context retrieval system based on linked open data and graph-based theory[J].Expert Systems with Applications, 2016, 53:138-148.
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                     Liu Wei-feng, Yang Ai-lan.Unsupervised learning for finite mixture models based on BIC criterion and Gibbs sampling [J].Acta Electronica Sinica, 2011, 39 (Z1) :134-139. (in Chinese) </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_11" title=" Jeh G, Widom J.SimRank:A measure of structural-context similarity[C]//Proc of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002:538-543." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SimRank:A measure of structural-context similarity">
                                        <b>[11]</b>
                                         Jeh G, Widom J.SimRank:A measure of structural-context similarity[C]//Proc of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002:538-543.
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_12" title=" Zhu R, Zou Z N, Li J Z.SimRank on uncertain graphs[J].IEEE Transactions on Knowledge and Data Engineering, 2017, 29 (11) :2522-2536." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SimRank on uncertain graphs">
                                        <b>[12]</b>
                                         Zhu R, Zou Z N, Li J Z.SimRank on uncertain graphs[J].IEEE Transactions on Knowledge and Data Engineering, 2017, 29 (11) :2522-2536.
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     Wang Jia-hai, Xu Xu-hui, Shen Jia-hao, et al.A study of fault diagnosis for cnc machine tool based on rough set and SimRank algorithm[J].Modular Machine Tool &amp;amp; Automatic Manufacturing Technique, 2018 (2) :84-86. (in Chinese) </a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_14" title=" Luo X, Gao J, Zhou C, et al.UniWalk:Unidirectional random walk based scalable SimRank computation over large graph[C]//Proc of 2017 IEEE 33rd International Conference on Data Engineering (ICDE) , 2017:325-336." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=UniWalk:Unidirectional random walk based scalable SimRank computation over large graph">
                                        <b>[14]</b>
                                         Luo X, Gao J, Zhou C, et al.UniWalk:Unidirectional random walk based scalable SimRank computation over large graph[C]//Proc of 2017 IEEE 33rd International Conference on Data Engineering (ICDE) , 2017:325-336.
                                    </a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_15" title=" Xu B, Xu Y, Liang J Q, et al.CN-DBpedia:A never-ending Chinese knowledge extraction system[C]//Proc of International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, 2017:428-438." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CN-DBpedia:A Never-Ending Chinese Knowledge Extraction System">
                                        <b>[15]</b>
                                         Xu B, Xu Y, Liang J Q, et al.CN-DBpedia:A never-ending Chinese knowledge extraction system[C]//Proc of International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, 2017:428-438.
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     栗雨晴, 礼欣, 韩煦, 等.基于双语词典的微博多类情感分析方法[J].电子学报, 2016, 44 (9) :2068-2073.</a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     卫冰洁, 史亮, 王斌.一种融合聚类和时间信息的微博排序新方法[J].中文信息学报, 2015, 29 (3) :177-183.</a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_4" title=" 刘德喜, 付淇, 韦亚雄, 等.基于多重增强图和主题分析的社交短文本检索方法[J].中文信息学报, 2018, 32 (3) :110-119." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201803015&amp;v=MjU5NTZxQnRHRnJDVVJMT2VaZVJtRnk3bFZMdkFLQ2pZZmJHNEg5bk1ySTlFWVlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         刘德喜, 付淇, 韦亚雄, 等.基于多重增强图和主题分析的社交短文本检索方法[J].中文信息学报, 2018, 32 (3) :110-119.
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_5" title=" 韩中元, 杨沐昀, 孔蕾蕾, 等.基于词汇时间分布的微博查询扩展[J].计算机学报, 2016, 39 (10) :2031-2044." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201610007&amp;v=MjQyMjNVUkxPZVplUm1GeTdsVkx2QUx6N0Jkckc0SDlmTnI0OUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         韩中元, 杨沐昀, 孔蕾蕾, 等.基于词汇时间分布的微博查询扩展[J].计算机学报, 2016, 39 (10) :2031-2044.
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_10" title=" 刘伟峰, 杨爱兰.基于BIC准则和Gibbs采样的有限混合模型无监督学习算法[J].电子学报, 2011, 39 (Z1) :134-139." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU2011S1025&amp;v=MTI5ODdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bFZMdkFJVGZUZTdHNEg5Q3ZybzlIWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         刘伟峰, 杨爱兰.基于BIC准则和Gibbs采样的有限混合模型无监督学习算法[J].电子学报, 2011, 39 (Z1) :134-139.
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_13" title=" 王家海, 徐旭辉, 沈佳豪, 等.基于粗糙集结合SimRank算法的数控机床故障诊断研究[J].机床组合与自动化加工技术, 2018 (2) :84-86." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHJC201802021&amp;v=MTI2NTh2QVB5WEJiYkc0SDluTXJZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdsVkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         王家海, 徐旭辉, 沈佳豪, 等.基于粗糙集结合SimRank算法的数控机床故障诊断研究[J].机床组合与自动化加工技术, 2018 (2) :84-86.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(08),1512-1518 DOI:10.3969/j.issn.1007-130X.2019.08.024            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>融合BTM和图论的微博检索模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">蔡晨</a>
                                <a href="javascript:;">罗可</a>
                </h2>
                    <h2>

                    <span>长沙理工大学计算机与通信工程学院</span>
                    <span>长沙理工大学综合交通运输大数据智能处理湖南省重点实验室</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>微博数据量庞大且微博文本的字符数少、特征稀疏, 为提高检索精度, 提出一种融合BTM和图论的微博检索模型, 通过词汇语义相关度计算微博文本中带有标签的特征相关度, 构建bi-term主题模型, 用JSD距离计算映射到该模型中短文本的词对相关度, 抽取CN-DBpedia中实体及图结构, 再使用SimRank算法计算图结构中实体间的相关度。综上3种相关度为该模型最终相关度。最后使用新浪微博数据集进行检索实验, 实验结果表明:对比于融合隐含狄利克雷分布算法与图论的检索模型和基于开放数据关联和图论方法系统模型, 新模型在MAP、准确率和召回率上性能有明显提高, 说明该模型具有较优的检索性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AE%E5%8D%9A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">微博;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%AD%E6%96%87%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">短文本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相似度计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BTM&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BTM;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E8%AE%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图论;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">主题模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    蔡晨 (1993-) , 女, 湖南攸县人, 硕士生, 研究方向为人工智能和自然语言处理。E-mail:1254326325@qq.com通信地址:410114湖南省长沙市长沙理工大学计算机与通信工程学院;
                                </span>
                                <span>
                                    罗可 (1961-) , 男, 湖南长沙人, 博士, 教授, 研究方向为数据挖掘和计算机应用。E-mail:luok@csust.edu.cn通信地址:410114湖南省长沙市长沙理工大学计算机与通信工程学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-27</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (11671125, 71371065);</span>
                    </p>
            </div>
                    <h1><b>A microblog retrieval model combining BTM and graph theory</b></h1>
                    <h2>
                    <span>CAI Chen</span>
                    <span>LUO Ke</span>
            </h2>
                    <h2>
                    <span>School of Computer & Communication Engineering, Changsha University of Science and Technology</span>
                    <span>Hunan Provincial Key Laboratory of Intelligent Processing of Big Data on Transportation, Changsha University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Microblogs have a large amount of data but a few characters in the text, and their features are sparse. In order to improve the retrieval precision, we propose a microblog retrieval model combining BTM and graph theory. The lexical semantic correlation is used to calculate the correlation between features with labels in microblog text. Then we construct a bi-term topic model, use JSD distance to calculate the correlation of pair words in the short text that mapped to the model. Thirdly, we extract the entity and graph structure in CN-DBpedia, and then use the SimRank algorithm to calculate inter-entity correlation between graph structures. The above three correlations are the final correlation of the model. Finally, the Sina Weibo data set is used for the retrieval experiments. Experimental results show that compared with the retrieval model based on the combination of the implicit Dirichlet distribution algorithm and graph theory and the system model based on open data correlation and graph theory, the performance of the new model is significantly improved in MAP, accuracy and recall rate, indicating that the model has better retrieval performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=microblog&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">microblog;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=short%20text&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">short text;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=similarity%20calculation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">similarity calculation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BTM&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BTM;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=graph%20theory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">graph theory;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=topic%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">topic model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CAI Chen, born in 1993, MS candidate, her research interests include artificial intelligence, and natural language processing.Address:School of Computer &amp;Communication Engineering, Changsha University of Science and Technology, Changsha 410114, Hunan, P.R.China;
                                </span>
                                <span>
                                    LUO Ke, born in 1961, PhD, professor, his research interests include data mining, and computer applications.Address:School of Computer &amp;Communication Engineering, Changsha University of Science and Technology, Changsha 410114, Hunan, P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-27</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="45" name="45" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="46">微博财报数据显示, 截至2017年9月, 微博月活跃用户共3.76亿, 其中移动端占比高达92%, 日活跃用户达到1.65亿。微博可以向用户实时分享新鲜热门话题, 微博中庞大的信息数据逐渐成为当下研究的热点。微博文本的突出特点有字符数受限、用户每条博文在140个字符内、发表长短不一、文本口语化、充斥着各种流行网络用语和缩略词等, 使得文本数据结构稀疏度很高。</p>
                </div>
                <div class="p1">
                    <p id="47">目前, 随着搜索难度的剧增, 很多相关学者围绕此展开研究, 研究热点包括: (1) 对检索模型的相关研究; (2) 对用户网络关系的相关研究; (3) 对微博文本内容的相关研究; (4) 对查询扩展算法的相关研究; (5) 对微博相关特性的研究; (6) 对微博话题标签的相关研究。如文献<citation id="235" type="reference">[<a class="sup">1</a>,<a class="sup">1</a>]</citation>对海量微博文本的情感词汇知识库进行扩展构建了一个双语感词典, 采用半监督Gauss混合模型<citation id="236" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>和对称熵的<i>K</i>邻近算法实现对微博文本的情感分类计算。文献<citation id="237" type="reference">[<a class="sup">3</a>,<a class="sup">3</a>]</citation>通过聚类来扩展文本, 把标签引入到集群中, 在聚类过程中, 构建了一个拥有聚类和时间信息的检索模型。文献<citation id="238" type="reference">[<a class="sup">4</a>,<a class="sup">4</a>]</citation>利用多重增强图算法获得初步检索结果, 再利用社交短文本中蕴含的文本、作者、词语等不同层面的关系, 通过不同的图层及图中节点之间的边来建模。文献<citation id="239" type="reference">[<a class="sup">5</a>,<a class="sup">5</a>]</citation>提出了一种利用扩展词与查询词时间分布的相似性方法, 来度量扩展词与查询词之间的相关度, 建立了基于词汇时间分布的查询模型。文献<citation id="240" type="reference">[<a class="sup">6</a>]</citation>通过自动识别与它相关的Seman概念并生成相应的Wikipedia链接, 将Semantics添加到博文中, 所确定的概念随后用于社会媒体挖掘, 从而减少了人工检查选择的需求, 提高了检索的效率。文献<citation id="241" type="reference">[<a class="sup">7</a>]</citation>使用了隐含狄利克雷分布LDA (Latent Dirichlet Allocation) 算法来克服由显式语义分析ESA (Explicit Semantic Analysis) 中形成向量的高维问题, 将来自原始ESA向量单词的语义解释构建为潜在主题的向量, 用于提取主题作为概念的概率分布而不是传统模型中的单词, 但该模型提取稀疏度很高的短文本时冗余度很高。文献<citation id="242" type="reference">[<a class="sup">8</a>]</citation>提出了一种针对短文本的主题模型, 即bi-term主题模型BTM (Biterm Topic Model) , 它不同于传统pLSA (probabilitistic Latent Semantic Analysis) 模型和LDA模型, 它可以通过直接建立语料库中的单词共现模式来生成学习主题, 使得模型对于推断丰富的语料库级信息有效, 但针对微博文本, 该单一模型不能充分利用到其特征。文献<citation id="243" type="reference">[<a class="sup">9</a>]</citation>利用文本中的实体匹配之间的关系, 将DBpedia的链接特性作为载体, 将图中的每个概念置于语境中, 其中心理论是通过计算图结构中2个实体 (查询—被查询文本) 之间关系来计算相似度。虽然在检索效率上有很大提升, 但其检索模型需要考虑的节点众多, 并且要计算任意2点间的Dijkstra最短距离, 且没有考虑到除图结构以外的文本相关度。</p>
                </div>
                <div class="p1">
                    <p id="48">综上分析, 针对目前研究存在的问题及充分利用微博文本的特征, 本文提出一种融合基于标签的特征相关度、基于BTM主题计算相关度及基于图论计算相关度的微博检索模型, 且通过实验验证了该模型具有很好的检索性能。</p>
                </div>
                <div class="p1">
                    <p id="49">本文结构如下:第2节介绍了模型用到的关键技术;第3节详细阐述了模型的构建;第4节展示了实验结果及分析;最后总结全文及未来展望。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag"><b>2 关键技术</b></h3>
                <h4 class="anchor-tag" id="51" name="51"><b>2.1 词汇语义相关度</b></h4>
                <div class="p1">
                    <p id="52">微博检索模型的意义在于用户在查询时, 返回的数据文本能最大程度地与查询指令相接近, 满足用户查询需求, 这就需要模型计算查询文本与被查询数据集中每个文本之间的相关度。在机器学习算法中, 有各种方式衡量用户或者物品的距离或者相似度, 如Manhattan距离、欧几里得距离、Pearson相关系数、jaccard系数等, 本文使用语义知识词典, 在《同义词词林》中的词群构成一个树状结构, 如图1所示。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908025_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 语义分类树" src="Detail/GetImg?filename=images/JSJK201908025_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 语义分类树  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908025_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Semantic classification tree</p>

                </div>
                <div class="p1">
                    <p id="54">词语间距离的度量即为词语之间的语义相似度。若2个词语的距离越大, 则相似度越低;反之, 2个词语距离越小, 其相似程度越大。定义词语距离为0时, 其相似度为1;词语距离为无穷大时, 其相似度为0。计算词汇语义相似度公式如式 (1) 所示:</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>S</mi><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi>Ο</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>Ο</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>) </mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>α</mi><mo>×</mo><mrow><mo> (</mo><mrow><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>) </mo></mrow></mrow><mrow><mrow><mo> (</mo><mrow><mi>D</mi><mi>i</mi><mi>s</mi><mrow><mo> (</mo><mrow><mi>Ο</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>Ο</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>) </mo></mrow><mo>+</mo><mi>α</mi></mrow><mo>) </mo></mrow><mo>×</mo><mi>max</mi><mrow><mo> (</mo><mrow><mrow><mo>|</mo><mrow><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>|</mo></mrow><mo>, </mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>´</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">其中, 2个词语<i>O</i><sub>1</sub>和<i>O</i><sub>2</sub>的相似度记为<mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi>Ο</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>Ο</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>, 2个词语间距离记为<i>Dis</i> (<i>O</i><sub>1</sub>, <i>O</i><sub>2</sub>) , <i>l</i><sub>1</sub>、<i>l</i><sub>2</sub>分别是<i>O</i><sub>1</sub>、<i>O</i><sub>2</sub>所处的层次, <i>α</i>是相似度为0.5时<i>O</i><sub>1</sub>和<i>O</i><sub>2</sub>之间的距离, <i>α</i>是一个可调节的参数, 一般<i>α</i>&gt;0。词语的距离越大, 其相似度越低。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58"><b>2.2 BTM算法</b></h4>
                <div class="p1">
                    <p id="59">BTM对带有潜在主题结构的bi-term的生成过程进行建模, bi-term表示出现在同一文本中的2个无序词构成的词对。BTM的关键思想是使用整个语料库中生成的bi-term来学习短文本模型。对于整个语料库中的词对, BTM定义了如下生成过程:</p>
                </div>
                <div class="p1">
                    <p id="60"><b>Step 1</b> 为整个短文本语料库构建一个主题分布<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>θ</mi><mo>∼</mo><mi>D</mi><mi>i</mi><mi>r</mi><mrow><mo> (</mo><mi>α</mi><mo>) </mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="62"><b>Step 2</b> 对于每个主题<i>z</i>, 特定主题<i>z</i>下的词分布为<image href="images/JSJK201908025_063.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mrow></mrow><mi>z</mi></msub><mo>∼</mo><mi>D</mi><mi>i</mi><mi>r</mi><mrow><mo> (</mo><mi>β</mi><mo>) </mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="65"><b>Step 3</b> 对于词对集<i>B</i>中的每一个词对<i>b</i>, 设<mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>b</mi><mo>=</mo></mrow><mrow><mo> (</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="67"><b>Step 3.1</b> 从整个短文本语料库的主题分布<i>θ</i>中抽取一个<i>z</i>, 记为<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>z</mi><mo>∼</mo><mi>Μ</mi><mi>u</mi><mi>l</mi><mi>t</mi><mi>i</mi><mrow><mo> (</mo><mi>θ</mi><mo>) </mo></mrow><mo>;</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="69"><b>Step 3.2</b> 从抽到的主题<i>z</i>中抽取词对<i>b</i>的2个不同词<i>w</i><sub><i>i</i></sub>, <i>w</i><sub><i>j</i></sub>, 记为<i>w</i><sub><i>i</i></sub>, <i>w</i><sub><i>j</i></sub>～<i>Multi</i><image href="images/JSJK201908025_070.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub><i>z</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="71">其中, <i>α</i>和<i>β</i>都是Dirichlet先验分布的超参数, 生成过程如图2所示。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908025_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 BTM的图解模型" src="Detail/GetImg?filename=images/JSJK201908025_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 BTM的图解模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908025_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Graphical model of BTM</p>

                </div>
                <div class="p1">
                    <p id="73">图2中, <i>K</i>表示整个语料库中的主题数, <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>B</mi><mo>|</mo></mrow></mrow></math></mathml>表示BTM语料库中词对的数目。词对bi-term (<i>b</i>) 的联合分布概率如式 (2) 所示:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>z</mi></msub><mi>Ρ</mi></mstyle><mrow><mo> (</mo><mi>z</mi><mo>) </mo></mrow><mi>Ρ</mi><mrow><mo> (</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>z</mi></mrow><mo>) </mo></mrow><mi>Ρ</mi><mrow><mo> (</mo><mrow><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mi>z</mi></mrow><mo>) </mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><msub><mo>∑</mo><mi>z</mi></msub><mi>θ</mi></mstyle><msub><mrow></mrow><mi>z</mi></msub><mi><mglyph src="数学符号.jpg" height="100%" width="100%" /></mi><msub><mrow></mrow><mrow><mi>i</mi><mo stretchy="false">|</mo><mi>z</mi></mrow></msub><mi><mglyph src="数学符号.jpg" height="100%" width="100%" /></mi><msub><mrow></mrow><mrow><mi>j</mi><mo stretchy="false">|</mo><mi>z</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">所以, 整个BTM语料库的概率表示为:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mrow><mo> (</mo><mi>B</mi><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><msub><mo>∏</mo><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msub><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>z</mi></msub><mi>θ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>z</mi></msub><mi><mglyph src="数学符号.jpg" height="100%" width="100%" /></mi><msub><mrow></mrow><mrow><mi>i</mi><mo stretchy="false">|</mo><mi>z</mi></mrow></msub><mi><mglyph src="数学符号.jpg" height="100%" width="100%" /></mi><msub><mrow></mrow><mrow><mi>j</mi><mo stretchy="false">|</mo><mi>z</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">类似于LDA模型, <image href="images/JSJK201908025_079.jpg" type="" display="inline" placement="inline"><alt></alt></image>和<i>θ</i>是BTM主题模型的隐含变量, 因此可以通过参数估计推理得出。BTM通过Gibbs抽样<citation id="244" type="reference"><link href="211" rel="bibliography" /><link href="231" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">10</a>]</sup></citation>来推断微博文本主题分布和主题下的词分布。</p>
                </div>
                <div class="p1">
                    <p id="80">首先, 为词对计算条件概率分布:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mrow><mo> (</mo><mrow><mi>z</mi><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>b</mi></mrow></msub><mo>, </mo><mi>B</mi><mo>, </mo><mi>α</mi><mo>, </mo><mi>β</mi></mrow><mo>) </mo></mrow><mo>∝</mo></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mi>z</mi></msub><mo>+</mo><mi>α</mi><mo stretchy="false">) </mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>z</mi></mrow></msub><mo>+</mo><mi>β</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>z</mi></mrow></msub><mo>+</mo><mi>β</mi><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>w</mi></msub><mi>n</mi></mstyle><msub><mrow></mrow><mrow><mi>w</mi><mo stretchy="false">|</mo><mi>z</mi></mrow></msub><mo>+</mo><mi>Μ</mi><mi>β</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">其中, <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mrow><mo> (</mo><mrow><mi>z</mi><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>b</mi></mrow></msub><mo>, </mo><mi>B</mi><mo>, </mo><mi>α</mi><mo>, </mo><mi>β</mi></mrow><mo>) </mo></mrow></mrow></math></mathml>是每个词对的条件概率分布, <i>z</i><sub>-<i>b</i></sub>表示除词对<i>b</i>之外的所有词对的主题分布。<i>B</i>是所有词对的集合。<i>n</i><sub><i>z</i></sub>是词对<i>b</i>分配给主题<i>z</i>的次数, <i>n</i><sub><i>w</i>|<i>z</i></sub>是主题词<i>w</i>分配给主题<i>z</i>的次数。<i>M</i>表示语料库中不同词的数目。</p>
                </div>
                <div class="p1">
                    <p id="84">确定整个BTM语料库主题-词的分布<image href="images/JSJK201908025_085.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub><i>w</i>|<i>z</i></sub>和主题分布<i>θ</i><sub><i>z</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi><mglyph src="数学符号.jpg" height="100%" width="100%" /></mi><msub><mrow></mrow><mrow><mi>w</mi><mo stretchy="false">|</mo><mi>z</mi><mspace width="0.25em" /></mrow></msub><mo>=</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mrow><mi>w</mi><mo stretchy="false">|</mo><mi>z</mi><mspace width="0.25em" /></mrow></msub><mo>+</mo><mi>β</mi></mrow><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>w</mi><mspace width="0.25em" /></mrow></msub><mi>n</mi></mstyle><msub><mrow></mrow><mrow><mi>w</mi><mo stretchy="false">|</mo><mi>z</mi><mspace width="0.25em" /></mrow></msub><mo>+</mo><mi>Μ</mi><mi>β</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub><mo>=</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>z</mi></msub><mo>+</mo><mi>α</mi></mrow><mrow><mrow><mo>|</mo><mi>B</mi><mo>|</mo></mrow><mo>+</mo><mi>Κ</mi><msub><mrow></mrow><mi>a</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">通过Gibbs抽样确定最优主题数目<i>K</i>, <i>α</i>=50/K, 根据式 (5) 式 (6) 参数推算, 可得到整个文本的词对概率分布和主题概率分布:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">|</mo><mi>d</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>b</mi></msub><mi>n</mi></mstyle><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">|</mo><mi>d</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>b</mi></msub><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">|</mo><mi>b</mi><mo stretchy="false">) </mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">|</mo><mi>d</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中, <i>n</i><sub><i>d</i></sub> (<i>b</i>) 表示文档<i>d</i>中词对<i>b</i>出现的次数。</p>
                </div>
                <div class="p1">
                    <p id="90">最后, 度量文本之间的相关度时, 只需要通过模型映射得到待比较的文本词汇的二维向量, 采用JSD (Jensen-Shannon Divergence) 距离计算即可, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><msub><mrow></mrow><mrow><mtext>Κ</mtext><mtext>L</mtext></mrow></msub><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>, </mo><mi mathvariant="bold-italic">Q</mi></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi>Ρ</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>ln</mi><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mrow><mi>Q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>J</mi><mi>S</mi><mi>D</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>, </mo><mi mathvariant="bold-italic">Q</mi></mrow><mo>) </mo></mrow><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>D</mi><msub><mrow></mrow><mrow><mtext>Κ</mtext><mtext>L</mtext></mrow></msub><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>, </mo><mi mathvariant="bold-italic">Μ</mi></mrow><mo>) </mo></mrow><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>D</mi><msub><mrow></mrow><mrow><mtext>Κ</mtext><mtext>L</mtext></mrow></msub><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Q</mi><mo>, </mo><mi mathvariant="bold-italic">Μ</mi></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">其中<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Μ</mi><mo>=</mo><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>+</mo><mi mathvariant="bold-italic">Q</mi></mrow><mo>) </mo></mrow><mo>/</mo><mn>2</mn><mo>, </mo><mi>Τ</mi></mrow></math></mathml>为向量<b><i>P</i></b>、<b><i>Q</i></b>的维度。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>2.3 改进的SimRank算法</b></h4>
                <div class="p1">
                    <p id="95"><i>SimRank</i>算法<citation id="245" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是一种基于图的拓扑结构来度量任意2个实体间相关度的算法, 其核心思想是通过已知实体的相关度来推算其他与之关联实体的相关度, 在当今信息检索及相关度计算领域中, <i>SimRank</i>算法及其改进算法得到了广泛的应用<citation id="246" type="reference"><link href="215" rel="bibliography" /><link href="217" rel="bibliography" /><link href="219" rel="bibliography" /><link href="233" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="96">给定有向图<i>G</i>= (<i>V</i>, <i>E</i>) , 其中<i>V</i>和<i>E</i>分别表示节点和边的集合。任意节点<i>v</i>∈<i>V</i>, 用<mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mrow><mo> (</mo><mi>v</mi><mo>) </mo></mrow></mrow></math></mathml>表示对象<i>v</i>的入邻节点集合, <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>Ι</mi><mrow><mo> (</mo><mi>v</mi><mo>) </mo></mrow><mo stretchy="false">|</mo></mrow></math></mathml>表示集合<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mrow><mo> (</mo><mi>v</mi><mo>) </mo></mrow></mrow></math></mathml>中的元素个数, <i>a</i>, <i>b</i>为图<i>G</i>上任意2个节点, 关于SimRank算法的节点间相关度计算定义式表示如下:</p>
                </div>
                <div class="p1">
                    <p id="100"> (1) 当<i>a</i>=<i>b</i>时, <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mo>=</mo><mn>1</mn></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="102"> (2) 当<i>I</i> (<i>a</i>) =Ø或者<i>I</i> (<i>b</i>) =Ø时, <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mo>=</mo><mn>0</mn></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="104"> (3) 其他情况下:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>s</mi><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mi>C</mi><mrow><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></mfrac><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></msubsup><mi>s</mi></mstyle></mrow></mstyle><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">其中, <i>a</i>, <i>b</i>∈<i>V</i>, 0&lt;<i>C</i>&lt;1是一个阻尼系数。</p>
                </div>
                <div class="p1">
                    <p id="107">为提高算法精度, SimRank算法有迭代计算过程:</p>
                </div>
                <div class="p1">
                    <p id="108"> (1) 初始化算法:</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mn>0</mn></msub><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>0</mn><mo>, </mo><mi>a</mi><mo>≠</mo><mi>b</mi></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mi>a</mi><mo>=</mo><mi>b</mi></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110"> (2) 迭代过程:</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mi>C</mi><mrow><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></munderover><mi>s</mi></mstyle></mrow></mstyle><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo> (</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">为减少计算中其他因素带来的误差, 本文在原始的迭代公式中添加一个证据因子, 表示“具有更多的共同的连接对象, 则其之间的相关度就更高”, 表达如下:</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>e</mi><mi>v</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>R</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>R</mi></mstyle><mo stretchy="false"> (</mo><mi>b</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></munderover><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><msup><mrow></mrow><mi>i</mi></msup></mrow></mfrac></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">其中, <i>R</i> (<i>a</i>) 和<i>R</i> (<i>b</i>) 分别表示节点<i>a</i>和<i>b</i>所关联的所有节点, 综合式 (13) 与式 (14) , 最终的相关度计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msubsup><mrow></mrow><mrow><mtext>e</mtext><mtext>v</mtext><mtext>i</mtext><mtext>d</mtext><mtext>e</mtext><mtext>n</mtext><mtext>c</mtext><mtext>e</mtext></mrow><mi>k</mi></msubsup><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mo>=</mo><mi>e</mi><mi>v</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mi>s</mi><mi>i</mi><mi>m</mi><msubsup><mrow></mrow><mrow><mtext>e</mtext><mtext>v</mtext><mtext>i</mtext><mtext>d</mtext><mtext>e</mtext><mtext>n</mtext><mtext>c</mtext><mtext>e</mtext></mrow><mi>k</mi></msubsup><mrow><mo> (</mo><mrow><mi>a</mi><mo>, </mo><mi>b</mi></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="116" name="116" class="anchor-tag"><b>3 构建微博检索模型</b></h3>
                <div class="p1">
                    <p id="117">微博文本内容由#标签话题#、统一资源定位符、所@的用户名以及140个字符内的普通文本构成, 这些内容对搜索都能产生影响。如最近最热的话题“传奇视角-卡洛斯:我看到了真正的巴西队#2018世界杯#”, 通过#2018世界杯#, 就可以精准地知道这是关于2018年世界杯的一条微博, 为了能更快、更准确地识别出来微博传递出来的信息, 本文构造了一个微博检索模型。该模型对查询文本和微博数据集文本进行相同的处理:抽取博文的标签 (一般为##中间的文本, 不同平台符号不同) 、对博文中普通文本隐藏的信息用<i>BTM</i>映射建模, 挖掘出现在<i>CN</i>-<i>DBpedia</i>中的实体关联度, 再综合使用基于特征的相关度、基于主题的相关度以及基于图的相关度进行计算。设查询文本为<b><i>T</i></b><sub>query</sub>, 微博单条博文为<b><i>T</i></b><sub>micro</sub>, 基于标签的相关度为<i>sim</i><sub>feather</sub>, 基于BTM主题的相关度为<i>sim</i><sub>topic</sub>, 基于图论的相关度为<i>sim</i><sub>graph</sub>, 本文微博检索模型流程结构如图3所示。本文模型最后综合的总相关度计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>q</mtext><mtext>u</mtext><mtext>e</mtext><mtext>r</mtext><mtext>y</mtext></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext></mrow></msub></mrow><mo>) </mo></mrow><mo>=</mo><mi>α</mi><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>h</mtext><mtext>e</mtext><mtext>r</mtext></mrow></msub><mo>+</mo><mi>β</mi><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>o</mtext><mtext>p</mtext><mtext>i</mtext><mtext>c</mtext></mrow></msub><mo>+</mo><mi>γ</mi><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>r</mtext><mtext>a</mtext><mtext>p</mtext><mtext>h</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 本文微博检索模型流程结构" src="Detail/GetImg?filename=images/JSJK201908025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 本文微博检索模型流程结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908025_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 3 <i>Process structure of the proposed</i><i>microblog retrieval model</i></p>

                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>3.1 基于标签的特征相关度计算</b></h4>
                <div class="p1">
                    <p id="121">微博文本通常包含有多个标签, 这是一种在“#”字符中间的短文本, 如“#世界杯2018”和“#<i>word cup</i>#”。通过这些标签用户可以快速分类文本话题, 提高检索效率。设用户请求查询的文本集为<mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><msub><mrow></mrow><mi>h</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><mi>q</mi><mi>h</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>q</mi><mi>h</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>q</mi><mi>h</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>, 设每条博文对应的标签集为<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mi>h</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><mi>m</mi><mi>h</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>m</mi><mi>h</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>m</mi><mi>h</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>。将<i>Q</i><sub><i>h</i></sub>和<i>M</i><sub><i>h</i></sub>代入式 (1) 中计算特征相关度, 即:</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>e</mtext><mtext>a</mtext><mtext>t</mtext><mtext>h</mtext><mtext>e</mtext><mtext>r</mtext></mrow></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>m</mi><mrow><mo> (</mo><mrow><mi>Q</mi><msub><mrow></mrow><mi>h</mi></msub><mo>, </mo><mi>Μ</mi><msub><mrow></mrow><mi>h</mi></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="125" name="125"><b>3.2 结合BTM主题的相关度计算</b></h4>
                <div class="p1">
                    <p id="126">微博文本短小、缺乏丰富的上下文, <i>BTM</i>主题模型是针对短文本而提出的。该模型通过整个数据集建立<i>BTM</i>语料库, 不直接使用信息少的单个短文本, 而是利用丰富的整个语料库的信息来进行建模和推断。该模型解决了短文本稀疏问题, 并且无需引用外部语料库进行扩充。</p>
                </div>
                <div class="p1">
                    <p id="127"><i>BTM</i>模型首先抽取<i>bi</i>-<i>term</i>。抽取的方法是:去掉低频和停用词;对于短文本 (如微博或百度知道等) , 取一个文本中的任意2个词对, 然后通过<i>bi</i>-<i>term</i>对文本集合进行建模。再使用<i>BTM</i>结合<i>Gibbs</i>抽样方法通过2.2节的生成训练得到整个<i>BTM</i>语料库主题-词分布<image href="images/JSJK201908025_128.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub><i>w</i>|<i>z</i></sub>和主题分布<i>θ</i><sub><i>z</i></sub>的模型文件。在计算主题相关度时, 同样将<b><i>T</i></b><sub>query</sub>和<b><i>T</i></b><sub>micro</sub>进行去停用词和词干化等处理, 获取文本与主题模型映射后的二维主题向量, 设得到的主题向量分别为:</p>
                </div>
                <div class="p1">
                    <p id="129" class="code-formula">
                        <mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>q</mtext><mtext>u</mtext><mtext>e</mtext><mtext>r</mtext><mtext>y</mtext></mrow></msub><mo>=</mo><mo stretchy="false">[</mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mi>m</mi></mrow></msub><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext></mrow></msub><mo>=</mo><mo stretchy="false">[</mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>c</mi><mi>r</mi><mi>o</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>c</mi><mi>r</mi><mi>o</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Τ</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>c</mi><mi>r</mi><mi>o</mi><mi>n</mi></mrow></msub><mo stretchy="false">]</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="130">通过式 (9) 和式 (10) 计算其相关度:</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>o</mtext><mtext>p</mtext><mtext>i</mtext><mtext>c</mtext></mrow></msub><mo>=</mo><mi>J</mi><mi>S</mi><mi>D</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>q</mtext><mtext>u</mtext><mtext>e</mtext><mtext>r</mtext><mtext>y</mtext></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext></mrow></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="132" name="132"><b>3.3 基于图论的相关度计算</b></h4>
                <div class="p1">
                    <p id="133">因为标签和<i>BTM</i>在模型训练时极少考虑实体, 但实体在检索过程充当很重要的角色。为了计算微博文本中所有实体的相关度, 本文引入<i>CN</i>-<i>DBpedia</i><citation id="247" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 主要从中文百科类网站 (如百度百科、互动百科、中文维基百科等) 的纯文本页面中提取信息, 经过滤、融合、推断等操作后, 最终形成高质量的结构化数据。微博文本包含的是一种无结构的数据, 构建实体关系结构图则需要先将文本中包含<i>CN</i>-<i>DBpedia</i>的概念和实体识别出来。本文采用<i>CN</i>-<i>DBpedia</i>提供的数据流接口<i>API</i> (<i>Application Programming Interface</i>) , 该<i>API</i>符合<i>RESTful</i>接口规范, 调用<i>API</i>, 请求实体 (称项名称) , 接口返回实体 (<i>entity</i>) 的列表。</p>
                </div>
                <div class="p1">
                    <p id="134">设从<b><i>T</i></b><sub>query</sub>和<b><i>T</i></b><sub>micro</sub>抽取的实体集合为:</p>
                </div>
                <div class="p1">
                    <p id="135" class="code-formula">
                        <mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>q</mtext><mtext>u</mtext><mtext>e</mtext><mtext>r</mtext><mtext>y</mtext></mrow></msub></mrow><mo>) </mo></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mi>e</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>e</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>e</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mi>m</mi></mrow></msub></mrow><mo>}</mo></mrow></mtd></mtr><mtr><mtd><mi>E</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext></mrow></msub></mrow><mo>) </mo></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mi>e</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>c</mi><mi>r</mi><mi>o</mi><mn>1</mn></mrow></msub><mo>, </mo><mi>e</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>c</mi><mi>r</mi><mi>o</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>e</mi><msub><mrow></mrow><mrow><mi>m</mi><mi>i</mi><mi>c</mi><mi>r</mi><mi>o</mi><mi>n</mi></mrow></msub></mrow><mo>}</mo></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="136">再将从<b><i>T</i></b><sub>query</sub>和每个微博文本<b><i>T</i></b><sub>micro</sub>的所有实体构成单个实体网络连接图<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mrow><mo> (</mo><mrow><mi>V</mi><mo>, </mo><mi>E</mi></mrow><mo>) </mo></mrow></mrow></math></mathml>, 顶点集合<i>V</i>表示如下:</p>
                </div>
                <div class="p1">
                    <p id="138" class="code-formula">
                        <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mo>=</mo><mstyle displaystyle="true"><mo>∪</mo><mi>E</mi></mstyle><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>q</mtext><mtext>u</mtext><mtext>e</mtext><mtext>r</mtext><mtext>y</mtext></mrow></msub></mrow><mo>) </mo></mrow><mo>, </mo><mi>E</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext></mrow></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="139">设<i>DBpedia</i>中实体<i>e</i><sub><i>i</i></sub>至<i>e</i><sub><i>j</i></sub>相连的属性集合为:</p>
                </div>
                <div class="p1">
                    <p id="140" class="code-formula">
                        <mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>→</mo><mi>e</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mrow><mo>{</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>→</mo><mi>e</mi><msub><mrow></mrow><mrow><mi>j</mi><mn>1</mn></mrow></msub></mrow></msub><mo>, </mo><mi>r</mi><msub><mrow></mrow><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>→</mo><mi>e</mi><msub><mrow></mrow><mrow><mi>j</mi><mn>2</mn></mrow></msub></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>r</mi><msub><mrow></mrow><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>→</mo><mi>e</mi><msub><mrow></mrow><mrow><mi>j</mi><mi>m</mi></mrow></msub></mrow></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="141">则<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mrow><mo> (</mo><mrow><mi>V</mi><mo>, </mo><mi>E</mi></mrow><mo>) </mo></mrow></mrow></math></mathml>中的边集合<i>E</i>表示为<i>E</i>=<i>R</i><sub><i>e</i><sub><i>i</i></sub>→<i>e</i><sub><i>j</i></sub></sub>, 其中<i>e</i><sub><i>i</i></sub>∈<i>V</i>, <i>e</i><sub><i>j</i></sub>∈<i>V</i>, <i>i</i>≠<i>j</i>。</p>
                </div>
                <div class="p1">
                    <p id="143">得到实体和实体之间的边后即实体网络连接图构建完以后, 通过式 (15) 对实体分别以<i>In</i>-<i>neighbours</i>、<i>Out</i>-<i>neighbours</i>方式计算相关度, 邻接表中有向图各顶点的入度和出度权重同等重要, 故均取值为0.5, 综合相加得到实体之间的实际相关度:</p>
                </div>
                <div class="p1">
                    <p id="144" class="code-formula">
                        <mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>e</mtext><mtext>v</mtext><mtext>i</mtext><mtext>d</mtext><mtext>e</mtext><mtext>n</mtext><mtext>c</mtext><mtext>e</mtext></mrow></msub><mrow><mo> (</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>e</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>) </mo></mrow><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>s</mi><mi>i</mi><mi>m</mi><msubsup><mrow></mrow><mrow><mtext>e</mtext><mtext>v</mtext><mtext>i</mtext><mtext>d</mtext><mtext>e</mtext><mtext>n</mtext><mtext>c</mtext><mtext>e</mtext></mrow><mrow><mtext>i</mtext><mtext>n</mtext></mrow></msubsup><mrow><mo> (</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>e</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>) </mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>s</mi><mi>i</mi><mi>m</mi><msubsup><mrow></mrow><mrow><mtext>e</mtext><mtext>v</mtext><mtext>i</mtext><mtext>d</mtext><mtext>e</mtext><mtext>n</mtext><mtext>c</mtext><mtext>e</mtext></mrow><mrow><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext></mrow></msubsup><mrow><mo> (</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>e</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="145">由于上述计算过于单一, 本文检索模型中用户在查询时需匹配所有被查询数据集, 需要包含所有实体的相关度, 综上, 采用以下表达式:</p>
                </div>
                <div class="p1">
                    <p id="146" class="code-formula">
                        <mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>r</mtext><mtext>a</mtext><mtext>p</mtext><mtext>h</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>s</mi></mstyle></mrow></mstyle><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>e</mtext><mtext>v</mtext><mtext>i</mtext><mtext>d</mtext><mtext>e</mtext><mtext>n</mtext><mtext>c</mtext><mtext>e</mtext></mrow></msub><mrow><mo> (</mo><mrow><mi>e</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>e</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>) </mo></mrow></mrow><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="147">其中, <mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>m</mi><mo>=</mo><mo stretchy="false">|</mo><mi>E</mi><mrow><mo> (</mo><mrow><mi>Τ</mi><msub><mrow></mrow><mrow><mtext>q</mtext><mtext>u</mtext><mtext>e</mtext><mtext>r</mtext><mtext>y</mtext></mrow></msub></mrow><mo>) </mo></mrow><mo stretchy="false">|</mo><mo>, </mo><mi>n</mi><mo>=</mo><mo stretchy="false">|</mo><mi>E</mi><mrow><mo> (</mo><mrow><mi>Τ</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext></mrow></msub></mrow><mo>) </mo></mrow><mo stretchy="false">|</mo></mrow></math></mathml>。</p>
                </div>
                <h3 id="149" name="149" class="anchor-tag"><b>4 实验</b></h3>
                <h4 class="anchor-tag" id="150" name="150"><b>4.1 实验环境与数据集</b></h4>
                <div class="p1">
                    <p id="151">本文实验的硬件环境为:内存大小为16 <i>GB</i>、<i>CPU</i>主频为2.8 <i>GHz</i>。软件环境:<i>Java</i>, <i>MySQL</i>数据库。</p>
                </div>
                <div class="p1">
                    <p id="152">实验使用新浪微博数据集作为测试数据集, 包含5 000 000条数据, 并根据此数据集建立<i>BTM</i>语料库训练模型。<i>CN</i>-<i>DBpedia</i>版本为8月 22, 2017。实验目的就是验证本文提出的模型与图论的微博检索模型是否提升了查询质量, 所以, 对比实验分别以融合<i>LDA</i>与图结构的检索模型 (以下简称<i>LDA</i>系统模型) 和文献<citation id="248" type="reference">[<a class="sup">12</a>]</citation>中的检索系统 (以下简称<i>LG</i>系统模型) 为基准, 用本文模型和2个基准模型进行对比实验, 以标准模型评估指标进行对比实验分析。</p>
                </div>
                <h4 class="anchor-tag" id="153" name="153"><b>4.2 模型评估指标</b></h4>
                <div class="p1">
                    <p id="154">准确率 (P) 和召回率 (R) 用来衡量检索模型的查准率和查全率。本文添加平均准确率MAP (<i>Mean Average Precision</i>) 作为评估指标, 单个主题的平均准确率是每篇相关文档检索出后的准确率的平均值。主集合的平均准确率 (MAP) 是每个主题的平均准确率的平均值。MAP是反映系统在全部相关文档上性能的单值指标。系统检索出来的相关文档越靠前 (<i>rank</i>越高) , MAP就可能越高。如果系统没有返回相关文档, 则默认准确率为0。</p>
                </div>
                <div class="p1">
                    <p id="155">准确率 (P) 、召回率 (R) 和MAP的表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="156" class="code-formula">
                        <mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mtext>检</mtext><mtext>出</mtext><mtext>的</mtext><mtext>相</mtext><mtext>关</mtext><mtext>文</mtext><mtext>档</mtext><mtext>数</mtext></mrow><mrow><mtext>检</mtext><mtext>出</mtext><mtext>文</mtext><mtext>档</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>R</mi><mo>=</mo><mfrac><mrow><mtext>检</mtext><mtext>出</mtext><mtext>的</mtext><mtext>相</mtext><mtext>关</mtext><mtext>文</mtext><mtext>档</mtext><mtext>数</mtext></mrow><mrow><mtext>相</mtext><mtext>关</mtext><mtext>文</mtext><mtext>档</mtext><mtext>数</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mi>A</mi><mi>Ρ</mi><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mfrac><mn>1</mn><mrow><mi>Q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munderover><mi>Ρ</mi></mstyle><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="157">其中, <i>N</i>是查询的总数;<i>Q</i><sub><i>j</i></sub>是查询<i>j</i>返回的相关文本数;<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mrow><mo> (</mo><mrow><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>) </mo></mrow></mrow></math></mathml>是相关文本在返回文本所在位置上的准确率。</p>
                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>4.3 实验结果分析</b></h4>
                <div class="p1">
                    <p id="160">在<i>BTM</i>主题相关度计算阶段, 对于<i>BTM</i>相关度中主题值<i>Κ</i>由式 (2) 和式 (22) 计算:</p>
                </div>
                <div class="p1">
                    <p id="161" class="code-formula">
                        <mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>k</mi><mo>=</mo><msqrt><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></msqrt><mo>+</mo><mn>2</mn><mo>×</mo><msqrt><mrow><mrow><mo>|</mo><mi>Τ</mi><mo>|</mo></mrow></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="162">其中, |<i>D</i>|是知识库的概念数;|<i>T</i>|是数据集的词典的词数。经过整理和式 (2) 的计算<i>K</i>值应为1 120。本文选取800、1 000、1 120、1 200对模型进行评测, 通过实验对比发现, <i>K</i>取值为1 000时实验结果达到最优。文献<citation id="249" type="reference">[<a class="sup">6</a>]</citation>指出<i>α</i>的最佳取值为50/<i>K</i>。<i>β</i>通常是一个小于1的值, 本文取<i>β</i>=0.05、0.01、0.02、0.03对模型进行评测, 通过实验对比, <i>β</i>取0.01为最佳。</p>
                </div>
                <div class="p1">
                    <p id="163">在基于图论的相关度计算阶段, 阻尼因子<i>C</i>反映的是2个节点间相隔的节点数量大小, <i>C</i>越大则相似度衰减得越厉害。其取值在0～1, 且通常大于0.5, 实验设置了<i>C</i>=0.7、0.8、0.9进行比对, 发现取值0.8为最佳。</p>
                </div>
                <div class="p1">
                    <p id="164">综上所述, 且经过不同微博文本的测试, 确定<i>Κ</i>=1000, <i>α</i>=0.05, <i>β</i>=0.01, <i>C</i>=0.8为最佳参数取值。各模型参数最优值如表1所示。</p>
                </div>
                <div class="area_img" id="165">
                    <p class="img_tit"><b>表1 实验中各阶段相关度的最优结果参数值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Optimal parameter values of the correlations in each stage of the experiment</b></p>
                    <p class="img_note"></p>
                    <table id="165" border="1"><tr><td><br />相关度</td><td>参数</td><td>取值</td></tr><tr><td><br /></td><td><i>Κ</i></td><td>1 000</td></tr><tr><td><br />主题相关度</td><td><i>α</i></td><td>0.05</td></tr><tr><td><br /></td><td><i>β</i></td><td>0.01</td></tr><tr><td><br />图论相关度</td><td><i>C</i></td><td>0.8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="166">综合模型相关度计算阶段, 式 (16) 综合相关度参数权重求取过程中, 基于标签的特征相关度计算是针对带有标签的微博, 2017年微博报表数据研究统计指出15.8%的博文都至少含1个标签, 所以实验设置<i>α</i>为0.150和0.160, 权重不能设置得过高, 否则对没有带话题标签的微博文本检索返回的相关度很小, 经实验发现, <i>α</i>取值为0.150为最优;基于BTM主题的相关度计算是针对整个微博中的普通文本, 若权重过小则无法体现原博主具体思想意图, 若微博文本不计算话题标签及实体间的相关度的话, 则词汇往往比较相似且短小, 权重过大则返回的相关度也会过大;基于图论的相关度计算中, 由于微博文本过短, 仅根据文本难以准确计算相似度, 在同一实体图结构下的博文同样具有强关联性, 当微博文本因不存在与CN-DBpedia的实体匹配而无法构建实体关系图时, 也能返回大于0的相关度, 所以权重不能设置过高。基于BTM主题模型和图论的2个相似度计算, 对综合博文相关度检索均有强辅助作用, 所以实验分别设置<i>β</i>和<i>γ</i>为0.400、0.425、0.450和0.400、0.420、0440进行对比实验。经实验测试对比, 最优参数值为<i>α</i>=0.150, <i>β</i>=0.425和<i>γ</i>=0.425, 详细过程如表2所示。</p>
                </div>
                <div class="area_img" id="167">
                    <p class="img_tit"><b>表2 综合模型中各项参数对实验模型中评估指标的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Effect of various parameters of the integrated model on the evaluation indicators of the experimental model</b></p>
                    <p class="img_note"></p>
                    <table id="167" border="1"><tr><td colspan="3"><br /><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mtext>参</mtext><mtext>数</mtext><mtext>值</mtext></mrow><mrow><mi>α</mi><mtext> </mtext><mtext> </mtext><mi>β</mi><mtext> </mtext><mtext> </mtext><mi>C</mi></mrow></mfrac></mrow></math></td><td colspan="3"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mtext>本</mtext><mtext>文</mtext><mtext>模</mtext><mtext>型</mtext></mrow><mrow><mi>Μ</mi><mi>A</mi><mi>Ρ</mi><mtext> </mtext><mtext> </mtext><mi>Ρ</mi><mtext> </mtext><mtext> </mtext><mi>R</mi></mrow></mfrac></mrow></math></td><td colspan="3"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mtext>L</mtext><mtext>D</mtext><mtext>A</mtext><mtext>系</mtext><mtext>统</mtext><mtext>模</mtext><mtext>型</mtext></mrow><mrow><mi>Μ</mi><mi>A</mi><mi>Ρ</mi><mtext> </mtext><mtext> </mtext><mi>Ρ</mi><mtext> </mtext><mtext> </mtext><mi>R</mi></mrow></mfrac></mrow></math></td></tr><tr><td><br />0.150</td><td>0.400</td><td>0.450</td><td>0.679</td><td>0.710</td><td>0.632</td><td>0.589</td><td>0.697</td><td>0.623</td></tr><tr><td><br /><b>0.150</b></td><td><b>0.425</b></td><td><b>0.425</b></td><td><b>0.710</b></td><td><b>0.789</b></td><td><b>0.702</b></td><td><b>0.645</b></td><td><b>0.733</b></td><td><b>0.661</b></td></tr><tr><td><br />0.150</td><td>0.450</td><td>0.400</td><td>0.683</td><td>0.732</td><td>0.602</td><td>0.545</td><td>0.633</td><td>0.581</td></tr><tr><td><br />0.160</td><td>0.400</td><td>0.440</td><td>0.612</td><td>0.701</td><td>0.611</td><td>0.606</td><td>0.639</td><td>0.572</td></tr><tr><td><br />0.160</td><td>0.420</td><td>0.420</td><td>0.661</td><td>0.732</td><td>0.659</td><td>0.622</td><td>0.704</td><td>0.623</td></tr><tr><td><br />0.160</td><td>0.440</td><td>0.400</td><td>0.588</td><td>0.684</td><td>0.579</td><td>0.573</td><td>0.592</td><td>0.535</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="168">LG系统模型中不含综合参数, 故无调参过程, 只需取<i>C</i>最佳值即可。为检测本文模型的有效性, 选定上述参数, 以式 (17) ～式 (19) 为评估标准, 图4为在检索微博文本时不同模型的结果, 是经多次对比测试数据集综合统计得出的。</p>
                </div>
                <div class="area_img" id="169">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908025_169.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 3种模型的综合评估比较" src="Detail/GetImg?filename=images/JSJK201908025_169.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 3种模型的综合评估比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908025_169.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 Comparison of comprehensive evaluation  among the three models</p>

                </div>
                <div class="p1">
                    <p id="170">通过图4数据可知, 3种模型都取得了较好结果, 各项评估指标都在64%以上。本文模型的各项性能较前两者都有所提升, 优于LDA系统模型是因为微博文本稀疏特性, 训练数据集得到的LDA模型不如BTM模型有效率, BTM缓和了主题推理中的稀疏问题, 在处理短文本时BTM模型相对LDA模型更具优势。</p>
                </div>
                <div class="p1">
                    <p id="171">本文模型放宽了对整个文档必须同属于一个话题的约束, 加强了LDA模型中每个词对应于一个话题的匹配。而基准系统LG模型考虑得比较片面, 忽略了微博文本中带有标签的强特征性, 未考虑到语义相关性, 本文模型可以查询到带有标签的博文的语义相关度, 能进行更加精准的相关度计算。</p>
                </div>
                <h3 id="172" name="172" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="173">针对微博文本字符数少、特征稀疏、微博数据量大、实时性要求高等特征给微博文本处理带来的困难, 提出一个融合微博特征的标签、通过普通文本生成的BTM以及文本后面隐含实体图的综合微博检索模型, 引入CN-DBpedia 2017中文知识库, 具有很强的时效性。最后用5 000 000条微博文本数据集进行实验, 并与LDA系统模型和LG系统模型进行评估数据比对, 最终实验结果表明, 该模型具有较优的检索性能。在已有研究的基础上, 未来的工作将进一步优化模型的性能, 如针对不同时间段的微博对于时间话题的影响, 或者更多地考虑属性传递和权重等因素, 进一步提高微博检索性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="191" type="formula" href="images/JSJK201908025_19100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">蔡晨</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="192" type="formula" href="images/JSJK201908025_19200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">罗可</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="193">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201609007&amp;v=MjE3MjFUZlRlN0c0SDlmTXBvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdsVkx2QUk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Li Yu-qing, Li Xin, Han Xu, et al.A bilingual lexicon-based multi-class semantic orientation analysis for microblogs [J].Acta Electronica Sinica, 2016, 44 (9) :2068-2073. (in Chinese) 
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semisupervised learning with deep generative models">

                                <b>[2]</b> Kingma D P, Rezende D J, Mohamed S, et al.Semi-supervised learning with deep generative models[C]//Proc of the 27th International Conference on Neural Information Processing Systems, 2014:3581-3589.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201503026&amp;v=MDY2NDNVUkxPZVplUm1GeTdsVkx2QUtDallmYkc0SDlUTXJJOUhZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Wei Bing-jie, Shi Liang, Wang Bin.Combining cluster and temporal information for microblog search[J].Journal of Chinese Information Processing, 2015, 29 (3) :177-183. (in Chinese) 
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_4" >
                                    <b>[4]</b>
                                 Liu De-xi, Fu Qi, Wei Ya-xiong, et al.Social short text retrieval based on multiple-enhanced graph and topic model[J].Journal of Chinese Information Processing, 2018, 32 (3) :110-119. (in Chinese) 
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 Han Zhong-yuan, Yang Mu-yun, Kong Lei-lei, et al.Query expansion based on term time distribution for microblog retrieval[J].Chinese Journal of Computers, 2016, 39 (10) :2031-2044. (in Chinese) 
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adding Semantics to Microblog Posts">

                                <b>[6]</b> Meij E, Weerkamp W, de Rijke M.Adding semantics to microblog posts[C]//Proc of the 5th ACM International Conference on Web Search and Data Mining, 2012:563-572.
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reducing explicit semantic representation vectors using latent Dirichlet allocation">

                                <b>[7]</b> Saif A, ab Aziz M J, Omar N.Reducing explicit semantic representation vectors using Latent Dirichlet Allocation[J].Knowledge-Based Systems, 2016, 100 (C) :145-159.
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Biterm topic model for short texts">

                                <b>[8]</b> Yan X H, Guo J F, Lan Y Y, et al.A biterm topic model for short texts[C]//Proc of the 22nd International Conference on World Wide Web, 2013:1445-1456.
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1243A100B393211AF116872D4AB49137&amp;v=MjEyMjBJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3cmk0eEtBPU5pZk9mYks2R3RLOXJvOUZGdWdHRDM0NHptZGw2ejU3UUhqZzJCWkVDN2FkUkxtWUNPTnZGU2lXV3I3Sg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Kalloubi F, Nfaoui E H, Beqqali O E.Microblog semantic context retrieval system based on linked open data and graph-based theory[J].Expert Systems with Applications, 2016, 53:138-148.
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                 Liu Wei-feng, Yang Ai-lan.Unsupervised learning for finite mixture models based on BIC criterion and Gibbs sampling [J].Acta Electronica Sinica, 2011, 39 (Z1) :134-139. (in Chinese) 
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SimRank:A measure of structural-context similarity">

                                <b>[11]</b> Jeh G, Widom J.SimRank:A measure of structural-context similarity[C]//Proc of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002:538-543.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SimRank on uncertain graphs">

                                <b>[12]</b> Zhu R, Zou Z N, Li J Z.SimRank on uncertain graphs[J].IEEE Transactions on Knowledge and Data Engineering, 2017, 29 (11) :2522-2536.
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 Wang Jia-hai, Xu Xu-hui, Shen Jia-hao, et al.A study of fault diagnosis for cnc machine tool based on rough set and SimRank algorithm[J].Modular Machine Tool &amp; Automatic Manufacturing Technique, 2018 (2) :84-86. (in Chinese) 
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=UniWalk:Unidirectional random walk based scalable SimRank computation over large graph">

                                <b>[14]</b> Luo X, Gao J, Zhou C, et al.UniWalk:Unidirectional random walk based scalable SimRank computation over large graph[C]//Proc of 2017 IEEE 33rd International Conference on Data Engineering (ICDE) , 2017:325-336.
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CN-DBpedia:A Never-Ending Chinese Knowledge Extraction System">

                                <b>[15]</b> Xu B, Xu Y, Liang J Q, et al.CN-DBpedia:A never-ending Chinese knowledge extraction system[C]//Proc of International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, 2017:428-438.
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 栗雨晴, 礼欣, 韩煦, 等.基于双语词典的微博多类情感分析方法[J].电子学报, 2016, 44 (9) :2068-2073.
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 卫冰洁, 史亮, 王斌.一种融合聚类和时间信息的微博排序新方法[J].中文信息学报, 2015, 29 (3) :177-183.
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201803015&amp;v=MDMyNjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2xWTHZBS0NqWWZiRzRIOW5Nckk5RVlZUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 刘德喜, 付淇, 韦亚雄, 等.基于多重增强图和主题分析的社交短文本检索方法[J].中文信息学报, 2018, 32 (3) :110-119.
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201610007&amp;v=MzA5MzJPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2xWTHZBTHo3QmRyRzRIOWZOcjQ5Rlk0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 韩中元, 杨沐昀, 孔蕾蕾, 等.基于词汇时间分布的微博查询扩展[J].计算机学报, 2016, 39 (10) :2031-2044.
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU2011S1025&amp;v=MjA2MjllUm1GeTdsVkx2QUlUZlRlN0c0SDlDdnJvOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 刘伟峰, 杨爱兰.基于BIC准则和Gibbs采样的有限混合模型无监督学习算法[J].电子学报, 2011, 39 (Z1) :134-139.
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHJC201802021&amp;v=MzEzNjVMT2VaZVJtRnk3bFZMdkFQeVhCYmJHNEg5bk1yWTlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 王家海, 徐旭辉, 沈佳豪, 等.基于粗糙集结合SimRank算法的数控机床故障诊断研究[J].机床组合与自动化加工技术, 2018 (2) :84-86.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201908025" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201908025&amp;v=MDQwOTFNcDQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2xWTHZCTHo3QlpiRzRIOWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
