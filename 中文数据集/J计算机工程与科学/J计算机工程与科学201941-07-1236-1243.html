<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132373093780000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201907013%26RESULT%3d1%26SIGN%3dhdiU4Ynj4i2zoU7FlkDOlLarN9o%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907013&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907013&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907013&amp;v=MDQ2MzVFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bVdyekFMejdCWmJHNEg5ak1xSTk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="&lt;b&gt;2 邻域粒化&lt;/b&gt; "><b>2 邻域粒化</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="&lt;b&gt;2.1 相关概念&lt;/b&gt;"><b>2.1 相关概念</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;2.2 各类型属性值距离及邻域的表示&lt;/b&gt;"><b>2.2 各类型属性值距离及邻域的表示</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="&lt;b&gt;3 广义邻域空间中的上、下近似&lt;/b&gt; "><b>3 广义邻域空间中的上、下近似</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#126" data-title="&lt;b&gt;4 基于邻域粒化的动态规则提取模型&lt;/b&gt; "><b>4 基于邻域粒化的动态规则提取模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="&lt;b&gt;4.1 动态粒度下的上、下近似&lt;/b&gt;"><b>4.1 动态粒度下的上、下近似</b></a></li>
                                                <li><a href="#148" data-title="&lt;b&gt;4.2 基于动态粒度下上下近似的规则提取算法&lt;/b&gt;"><b>4.2 基于动态粒度下上下近似的规则提取算法</b></a></li>
                                                <li><a href="#163" data-title="&lt;b&gt;4.3 一个例子&lt;/b&gt;"><b>4.3 一个例子</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#182" data-title="&lt;b&gt;5 实验分析&lt;/b&gt; "><b>5 实验分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#190" data-title="&lt;b&gt;6 结束语&lt;/b&gt; "><b>6 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="图1 条件属性的类型">图1 条件属性的类型</a></li>
                                                <li><a href="#59" data-title="图2 错层型数据示例">图2 错层型数据示例</a></li>
                                                <li><a href="#73" data-title="图3 节点间的路径长度">图3 节点间的路径长度</a></li>
                                                <li><a href="#168" data-title="&lt;b&gt;表1 一个混合信息系统&lt;/b&gt;"><b>表1 一个混合信息系统</b></a></li>
                                                <li><a href="#178" data-title="&lt;b&gt;表2 邻域的计算&lt;/b&gt;"><b>表2 邻域的计算</b></a></li>
                                                <li><a href="#179" data-title="&lt;b&gt;表3 单个属性的依赖度&lt;/b&gt;"><b>表3 单个属性的依赖度</b></a></li>
                                                <li><a href="#184" data-title="&lt;b&gt;表4 数据描述&lt;/b&gt;"><b>表4 数据描述</b></a></li>
                                                <li><a href="#188" data-title="&lt;b&gt;表5 基于MR、CART、RBF-SVM方法的分类精度&lt;/b&gt;"><b>表5 基于MR、CART、RBF-SVM方法的分类精度</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="207">


                                    <a id="bibliography_1" title=" Hall M A.Correlation-based feature selection for discrete and numeric class machine learning[C]//Proc of the 17th International Conference on Machine Learning, 2000:359-366." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning">
                                        <b>[1]</b>
                                         Hall M A.Correlation-based feature selection for discrete and numeric class machine learning[C]//Proc of the 17th International Conference on Machine Learning, 2000:359-366.
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_2" title=" Zhou Z H, Chen Z Q.Hybrid decision tree[J].Knowledge Based Systems, 2002, 15 (8) :515-528." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501719983&amp;v=MDM2MTE3SHRETnFvOUVZK29HQlhRNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsMGRhUm89TmlmT2ZiSw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Zhou Z H, Chen Z Q.Hybrid decision tree[J].Knowledge Based Systems, 2002, 15 (8) :515-528.
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_3" title=" Tang W Y, Mao K Z.Feature selection algorithm for mixed data with both nominal and continuous features[J].Pattern Recognition Letters, 2007, 28 (5) :563-571." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414653&amp;v=Mjk2NDlpZk9mYks3SHRET3JJOUZZT29MQ25rNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsMGRhUm89Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Tang W Y, Mao K Z.Feature selection algorithm for mixed data with both nominal and continuous features[J].Pattern Recognition Letters, 2007, 28 (5) :563-571.
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_4" title=" Pawlak Z.Rough sets[J].International Journal of Computer and Information Sciences, 1982, 11 (5) :341-356." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002176361&amp;v=MjgyMjExWT1OajdCYXJPNEh0SE9yb2hEWiswT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNEbFZiekJJ&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Pawlak Z.Rough sets[J].International Journal of Computer and Information Sciences, 1982, 11 (5) :341-356.
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_5" title=" Pawlak Z, Rauszer C.Dependency of attributes in information systems[J].Bulletin of the Polish Academy of Sciences, Mathematical Sciences, 1985, 33 (9-10) :551-559." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dependency of attributes in information systems">
                                        <b>[5]</b>
                                         Pawlak Z, Rauszer C.Dependency of attributes in information systems[J].Bulletin of the Polish Academy of Sciences, Mathematical Sciences, 1985, 33 (9-10) :551-559.
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_6" title=" Hu Q H, Yu D R, Xie Z X.Information-preserving hybrid data reduction based on fuzzy-rough techniques[J].Pattern Recognition Letters, 2006, 27 (5) :414-423." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414908&amp;v=MDQ2NzV1SHlqbVVMZklKbDBkYVJvPU5pZk9mYks3SHRET3JJOUZZT29MQlh3eG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Hu Q H, Yu D R, Xie Z X.Information-preserving hybrid data reduction based on fuzzy-rough techniques[J].Pattern Recognition Letters, 2006, 27 (5) :414-423.
                                    </a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_7" title=" Tsang E, Hu Q H, Chen D G.Feature and instance reduction for PNN classifiers based on fuzzy rough sets[J].International Journal of Machine Learning and Cybernetics, 2016, 7 (1) :1-11." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Feature and instance reduction for PNN classifiers based on fuzzy rough sets">
                                        <b>[7]</b>
                                         Tsang E, Hu Q H, Chen D G.Feature and instance reduction for PNN classifiers based on fuzzy rough sets[J].International Journal of Machine Learning and Cybernetics, 2016, 7 (1) :1-11.
                                    </a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_8" title=" Dai J H, Hu Q H, Hu H, et al.Neighbor inconsistent pair selection for attribute reduction by rough set approach[J].IEEE Transactions on Fuzzy Systems, 2018, 26 (2) :937-950." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neighbor inconsistent pair selection for attribute reduction by rough set approach">
                                        <b>[8]</b>
                                         Dai J H, Hu Q H, Hu H, et al.Neighbor inconsistent pair selection for attribute reduction by rough set approach[J].IEEE Transactions on Fuzzy Systems, 2018, 26 (2) :937-950.
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_9" title=" Wu W Z, Qian Y H, Li T J, et al.On rule acquisition in incomplete multi-scale decision tables[J].Information Sciences, 2016, 378 (C) :282-302." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD1DC84539CE2EDA9B52B9C27E59FB9BA&amp;v=MjcyNjdncTJjd2NNVG1UTWp1Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJod3J1Mnc2QT1OaWZPZmNlNWFxTEVxNHBHYlpoNkRnbE52aDloN3owUFFReg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Wu W Z, Qian Y H, Li T J, et al.On rule acquisition in incomplete multi-scale decision tables[J].Information Sciences, 2016, 378 (C) :282-302.
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_10" title=" Li T R, Ruan D, Shen Y J, et al.A new weighting approach based on rough set theory and granular computing for road safety indicator analysis[J].Computational Intelligence, 2016, 32 (4) :517-534." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD4760DB8FC31A80A20FA636645327C883&amp;v=MjMxMDBHTkc0M1ljekYrZ09mWFE1dmhRVG5FNTdTM25rcUJjMmU3WG5UYktjQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJod3J1Mnc2QT1OaWZjYXJlLw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Li T R, Ruan D, Shen Y J, et al.A new weighting approach based on rough set theory and granular computing for road safety indicator analysis[J].Computational Intelligence, 2016, 32 (4) :517-534.
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_11" title=" Cheng Y.Forward approximation and backward approximation in fuzzy rough sets[J].Neurocomputing, 2015, 148:340-353." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8EFD4A5C0FB71643AE384F8D930B9530&amp;v=MDQ0MzkveXhWaW56eDFUQW5xMkJzMmVjQ2RRTG1mQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJod3J1Mnc2QT1OaWZPZmJ2TmFLWEkzb28yWkoxOUMzMA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Cheng Y.Forward approximation and backward approximation in fuzzy rough sets[J].Neurocomputing, 2015, 148:340-353.
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_12" title=" Cheng Y.Dynamic maintenance of approximations under fuzzy rough sets[J].International Journal of Machine Learning and Cybernetics, 2018, 9 (12) :2011-2026." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic maintenance of approximations under fuzzy rough sets">
                                        <b>[12]</b>
                                         Cheng Y.Dynamic maintenance of approximations under fuzzy rough sets[J].International Journal of Machine Learning and Cybernetics, 2018, 9 (12) :2011-2026.
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_13" title=" Sun B Z, Ma W M, Qian Y H.Multigranulation fuzzy rough set over two universes and its application to decision making[J].Knowledge-Based Systems, 2017, 123 (C) :61-74." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8B4156F074BAA1F96BCFD167BA8F1674&amp;v=MTg5NzZ1UjhWbUV3TFBIN2txMkJFY2NTVlE3MmJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3cnUydzZBPU5pZk9mYnZLR3RESnFmbEZZKzk5ZlEwNA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Sun B Z, Ma W M, Qian Y H.Multigranulation fuzzy rough set over two universes and its application to decision making[J].Knowledge-Based Systems, 2017, 123 (C) :61-74.
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_14" title=" She Y H, He X L, Shi H X, et al.A multiple-valued logic approach for multigranulation rough set model[J].International Journal of Approximate Reasoning, 2017, 82:270-284." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8B636A829884924F7E7026A8D77301C6&amp;v=MjkzNTJmYnZLR05MSzNvZEhiZU1IQ0hVN3kyQVVuemg5U25tVHBHWXlmckdVUk1tWkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHdydTJ3NkE9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         She Y H, He X L, Shi H X, et al.A multiple-valued logic approach for multigranulation rough set model[J].International Journal of Approximate Reasoning, 2017, 82:270-284.
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_15" title=" Qian Y H, Liang X Y, Lin G P, et al.Local multigranulation decision-theoretic rough sets[J].International Journal of Approximate Reasoning, 2017, 82 (C) :119-137." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA257C4EA1B4C46397D191E2290305691&amp;v=MzA5MzUvekI4VW5qNTBTUXJncmhzMWVyS1JRN09lQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJod3J1Mnc2QT1OaWZPZmNLNkc5YS9xL28wWlprTGYzZw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Qian Y H, Liang X Y, Lin G P, et al.Local multigranulation decision-theoretic rough sets[J].International Journal of Approximate Reasoning, 2017, 82 (C) :119-137.
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_16" title=" Qian Y H, Cheng H H, Wang J T, et al.Grouping granular structures in human granulation intelligence[J].Information Sciences, 2017, 382-383:150-169." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES55AA3D461E587BEE2757088489396AC8&amp;v=MTU3ODN2RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3cnUydzZBPU5pZk9mYmE5YjZEUDI0dERaWjRLQkh0THVtTVI3VHA2U0hmcXFCbzhlcnVTTk1tWENPTg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Qian Y H, Cheng H H, Wang J T, et al.Grouping granular structures in human granulation intelligence[J].Information Sciences, 2017, 382-383:150-169.
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     Hu Qing-hua, Yu Da-ren, Xie Zong-xia.Numerical attribute reduction based on neighborhood granulation and rough approximation[J].Journal of Software, 2008, 19 (3) :640-649. (in Chinese) </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_18" title=" Hu Q H, Yu D R, Xie Z X.Neighborhood classifiers[J].Expert Systems with Applications, 2008, 34 (2) :866-876." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501643510&amp;v=MDk0ODRRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmwwZGFSbz1OaWZPZmJLN0h0RE5xbzlFWXU4TUNYMDVvQk1UNlQ0UA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Hu Q H, Yu D R, Xie Z X.Neighborhood classifiers[J].Expert Systems with Applications, 2008, 34 (2) :866-876.
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_19" title=" Zeng A P, Li T R Liu D.A fuzzy rough set approach for incremental feature selection on hybrid information systems[J].Fuzzy Sets and Systems, 2015, 258 (1) :39-60." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700153250&amp;v=MjI5MjU5RE1xSTlGWmU0TURuazVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKbDBkYVJvPU5pZk9mYks4SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Zeng A P, Li T R Liu D.A fuzzy rough set approach for incremental feature selection on hybrid information systems[J].Fuzzy Sets and Systems, 2015, 258 (1) :39-60.
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_20" title=" Wllson D R, Martinez T R.Improved heterogeneous distance functions[J].Journal of Artificial Intelligence Research, 1997, 6 (1) :1-34." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved heterogeneous distance functions">
                                        <b>[20]</b>
                                         Wllson D R, Martinez T R.Improved heterogeneous distance functions[J].Journal of Artificial Intelligence Research, 1997, 6 (1) :1-34.
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_21" title=" http://www.ics.uci.edu/～mlearn/MLRepository.html." target="_blank"
                                       href="">
                                        <b>[21]</b>
                                         http://www.ics.uci.edu/～mlearn/MLRepository.html.
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_17" title=" 胡清华, 于达仁, 谢宗霞.基于邻域粒化和粗糙逼近的数值属性约简[J].软件学报, 2008, 19 (3) :640-649." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200803018&amp;v=MDU5OTZXcnpBTnlmVGJMRzRIdG5Nckk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N20=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         胡清华, 于达仁, 谢宗霞.基于邻域粒化和粗糙逼近的数值属性约简[J].软件学报, 2008, 19 (3) :640-649.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(07),1236-1243 DOI:10.3969/j.issn.1007-130X.2019.07.013            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于邻域粒化的混合信息系统动态规则提取</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E6%98%B3&amp;code=42020814&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程昳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%8B%87&amp;code=23881564&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘勇</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0054367&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%BB%BA%E7%AD%91%E8%81%8C%E4%B8%9A%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E7%B3%BB&amp;code=0071476&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川建筑职业技术学院信息工程系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%9B%E5%B7%9D%E5%BB%BA%E7%AD%91%E8%81%8C%E4%B8%9A%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2%E8%AE%BE%E5%A4%87%E5%B7%A5%E7%A8%8B%E7%B3%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">四川建筑职业技术学院设备工程系</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有的混合信息系统知识发现模型涵盖的数据类型大多为符号型、数值型条件属性及符号型决策属性, 且大多数模型的关注点是属性约简或特征选择, 针对规则提取的研究相对较少。针对涵盖更多数据类型的混合信息系统构建一个动态规则提取模型。首先修正了现有的属性值距离的计算公式, 对错层型属性值的距离给出了一种定义形式, 从而定义了一个新的混合距离。其次提出了针对数值型决策属性诱导决策类的3种方法。其后构造了广义邻域粗糙集模型, 提出了动态粒度下的上下近似及规则提取算法, 构建了基于邻域粒化的动态规则提取模型。该模型可用于具有以下特点的信息系统的规则提取: (1) 条件属性集可包括单层符号型、错层符号型、数值型、区间型、集值型、未知型等; (2) 决策属性集可包括符号型、数值型。利用UCI数据库中的数据集进行了对比实验, 分类精度表明了规则提取算法的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%84%E5%88%99%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">规则提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B7%E5%90%88%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">混合信息系统;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B2%92%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">粒度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%82%BB%E5%9F%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邻域;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    程昳 (1977-) , 女, 重庆人, 博士后, 副教授, 研究方向为数据挖掘、粒计算、粗糙集理论及应用。E-mail:chengyimail@so-hu.com通信地址:618000四川省德阳市四川建筑职业技术学院;
                                </span>
                                <span>
                                    刘勇 (1976-) , 男, 山东青岛人, 硕士, 研究方向为人工智能和数据挖掘。E-mail:r0708@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61071162);</span>
                    </p>
            </div>
                    <h1><b>Dynamic rule induction for hybrid information systems based on neighborhood granulation</b></h1>
                    <h2>
                    <span>CHENG Yi</span>
                    <span>LIU Yong</span>
            </h2>
                    <h2>
                    <span>College of Computer Science, Sichuan University</span>
                    <span>Department of Information and Engineering, Sichuan College of Architectural Technology</span>
                    <span>Department of Equipment Engineering, Sichuan College of Architectural Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The data types of existing knowledge discovery models of hybrid information systems are mostly symbolic, numerical conditional and symbolic decision attributes. Most of the models focus on attribute reduction or feature selection, but research on rule extraction is relatively few. We construct a dynamic rule induction model for hybrid information systems covering more data types. Firstly, the existing formulas for calculating value differences of different types of attributes are modified, and a definition of the distance of cross-level symbolic values is given, thus a new mixed distance is defined. Secondly, we propose three methods to induce the decision class for numerical decision attributes. Then, we propose a generalized neighborhood rough set model based on neighborhood granulation, and the lower and upper approximations of an arbitrary subset under dynamic granulation are presented, which underlies a foundation for the construction of a dynamic rule induction algorithm. The model can be used to extract rules from the information systems with the following features, namely: (1) condition attribute set includes single-level symbolic, cross-level symbolic, numeric, interval-valued, set-valued and missing data; (2) decision attribute set can include symbolic and numeric data. The rule induction algorithm is evaluated on several data sets from the UC Irvine Machine Learning Repository. Experimental results show that the algorithm can achieve good classification performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=rule%20induction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">rule induction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hybrid%20information%20systems&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hybrid information systems;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=granularity&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">granularity;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neighborhood&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neighborhood;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHENG Yi, born in 1977, post doctor, associate professor, her research interests include data mining, granular computing, rough set theory and its application.Address:Sichuan College of Architectural Technology, Deyang 618000, Sichuan, P.R.China;
                                </span>
                                <span>
                                    LIU Yong, born in 1976, MS, his research interests include artificial intelligence, and data mining.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-03</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="48">计算机自动知识发现面临的主要困难是信息的多样性、不确定性和不一致性。其中, 多样性体现为数据结构的多样性和数据值域的多样性。数据值域的多样性体现在描述对象的属性的类型是复杂多样的, 可分为符号型、数值型、模糊值、集值、区间值等。有时候部分对象的某些属性的值还是缺失的。在实际应用中, 描述分类的属性往往不是单一类型的, 而是多种类型的变量共存的。由于混合数据广泛存在于各种类型的数据库中, 混合数据的知识发现在机器学习研究的早期便得到了重视。其中, 包含数值属性和符号属性的混合数据库的知识发现问题受到较广泛的关注。</p>
                </div>
                <div class="p1">
                    <p id="49">大体上可以将处理混合型数据知识发现的方法分为离散化方法和混合型方法。所谓离散化方法着眼于将数据库中的数值属性转化为离散属性, 则含数值属性的混合数据决策系统转化为离散决策系统, 这种方法的不足是离散化会引入量化误差、改变数值数据的本质结构, 可能导致知识发现性能的下降。此后有研究者提出了一些无需离散化的混合数据知识发现方法。例如, 2000年, Hall<citation id="251" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>提出了混合数据的特征选择方法, 该方法采用线性相关系数计算数值变量之间的相关性, 用信息熵计算符号变量之间的相关性。2002年, Zhou等<citation id="252" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>提出了一种混合数据的决策树构造方法, 本质上, 该方法相当于采用定性信息将一个复杂的分类问题分解为若干小的分类问题, 然后再用定量信息和神经网络为各小分类问题建模。2007 年, Tang等<citation id="253" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出了一种混合数据特征选择的方法, 该方法与 Zhou 等人的观点类似。在评价混合属性集的重要度时, 他们利用符号数据将样本空间解耦为若干子空间, 然后估计数值属性空间中子问题的分类错误率作为属性分类能力的指标。以上方法可以直接处理混合数据, 但是它们将数值信息和符号信息割裂开来进行分析, 优先利用符号信息的策略可能会导致使用分类能力很差的符号数据, 而放弃了分类能力较强的数值数据。</p>
                </div>
                <div class="p1">
                    <p id="50">粗糙集是波兰学者Pawlak<citation id="254" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>于20世纪80年代初提出来的一种刻画由不精确信息描述的分类问题中不一致性的数学工具。其核心概念是基于等价关系的粒化和基于下、上近似的逼近。该方法在属性依赖性分析<citation id="255" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、特征子集选择和约简<citation id="257" type="reference"><link href="217" rel="bibliography" /><link href="219" rel="bibliography" /><link href="221" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>、分类知识发现<citation id="258" type="reference"><link href="223" rel="bibliography" /><link href="225" rel="bibliography" /><link href="227" rel="bibliography" /><link href="229" rel="bibliography" /><link href="231" rel="bibliography" /><link href="233" rel="bibliography" /><link href="235" rel="bibliography" /><link href="237" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>等方面取得了成功。粗糙集理论模拟了人类思维中的粒化和近似2大特点, 但是该模型只是人类思维的简单模型, 要将粗糙集理论应用于复杂问题分析就必须拓展粗糙集理论中某些基本概念。粗糙集模型的泛化包括粒化和近似2个维度。从粒化的维度, 2008年, Hu等<citation id="259" type="reference"><link href="239" rel="bibliography" /><link href="241" rel="bibliography" /><link href="249" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">17</a>]</sup></citation>利用拓扑空间中球形邻域的概念, 以邻域替换了经典粗糙集中的等价类, 继而构造了基于邻域粗糙集模型的数值数据特征选择方法。与其它方法相比, 该方法无需离散化数值特征, 也无需将数值信息和符号信息分开使用, 能够直接处理数值型属性, 给混合数据的利用带来了便利。但是, 文献<citation id="260" type="reference">[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">17</a>]</citation>的方法有其局限性, 适用于条件属性为符号型、数值型, 决策属性为符号型的信息系统。2015年, Zeng等<citation id="256" type="reference"><link href="243" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>通过合并混合距离与高斯核, 构造了一种新的模糊粗糙集, 并基于此模糊粗糙集提出了一种针对混合信息系统的特征选择方法。该方法可以处理符号型、数值型条件属性, 也可处理缺失属性、集值属性, 但决策属性仍局限于符号型。由于决策属性限定为符号型, 对于决策属性为非符号型的信息系统, 文献<citation id="261" type="reference">[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">17</a>]</citation>的方法是不适用的。另外, 针对混合数据的大多数研究集中于数据的特征选择算法, 直接进行规则提取的研究较少。</p>
                </div>
                <div class="p1">
                    <p id="51">总的来说, 目前大多数针对混合数据的知识发现模型通常具有以下特征:条件属性包括符号属性、数值属性、缺失属性等类型, 决策属性为符号型。而通常实际存在的数据库中各种类型数据并存, 条件属性可能包括符号型、数值型、模糊值、区间值、集值和缺失属性等, 决策属性也可能包括符号型、数值型。目前用于上述类型数据的知识发现方法仍然比较欠缺, 本文首先定义了各种类型属性值的距离 (目前有少量文献涉及到多种类型数据距离的计算, 所采用的属性值距离的计算公式在公式内涵或表达形式上可能存在不足, 本文根据实验过程中发现的问题修正或重新定义了现有的计算公式) , 对错层型属性值的距离进行了定义, 从而定义了一个新的混合距离。其次提出了针对数值型决策属性诱导决策类的3种方法。通过邻域粒化, 构造了广义邻域粗糙集模型, 进而提出了动态粒度下的上下近似, 并构建了适用于多种类型数据并存的混合数据库的动态规则提取模型。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag"><b>2 邻域粒化</b></h3>
                <h4 class="anchor-tag" id="53" name="53"><b>2.1 相关概念</b></h4>
                <div class="p1">
                    <p id="54"><b>定义 1</b><citation id="262" type="reference"><link href="239" rel="bibliography" /><link href="249" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">17</a>]</sup></citation> 给定实数空间上的非空有限集合<i>U</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>}, 对于<i>U</i>上的任意对象<i>x</i><sub><i>i</i></sub>, <i>B</i>⊆<i>C</i> (<i>C</i>为属性集) , 定义<i>x</i><sub><i>i</i></sub>在子空间<i>B</i>中的<i>δ</i>邻域为<i>δ</i><sub><i>B</i></sub> (<i>x</i><sub><i>i</i></sub>) ={<i>x</i>|<i>x</i>∈<i>U</i>, <i>d</i><sub><i>B</i></sub> (<i>x</i>, <i>x</i><sub><i>i</i></sub>) ≤<i>δ</i>}, 其中, <i>δ</i>≥0, <i>d</i><sub><i>B</i></sub> (<i>x</i>, <i>x</i><sub><i>i</i></sub>) 表示<i>x</i>与<i>x</i><sub><i>i</i></sub>之间的距离, 实数空间常采用欧氏距离。<i>δ</i><sub><i>B</i></sub> (<i>x</i><sub><i>i</i></sub>) 称为由<i>x</i><sub><i>i</i></sub>生成的<i>δ</i>邻域信息粒子, 简称为<i>x</i><sub><i>i</i></sub>的邻域粒子。邻域粒子族{<i>δ</i><sub><i>B</i></sub> (<i>x</i><sub><i>i</i></sub>) |<i>i</i>=1, 2, …, <i>n</i>}构成了<i>U</i>的一个覆盖。邻域的大小依赖于阈值<i>δ</i>, <i>δ</i>越大, 邻域内包含的样本越多;邻域的形状依赖于所采用的范数。</p>
                </div>
                <div class="p1">
                    <p id="55">文献<citation id="263" type="reference">[<a class="sup">17</a>,<a class="sup">17</a>]</citation>采用了欧氏距离来度量具有数值型属性的对象之间的距离, 能够直接处理数值型属性, 拓展了经典粗糙集理论的应用范围。</p>
                </div>
                <div class="p1">
                    <p id="56">本文借鉴了邻域粗糙集的思想, 拟建立适用于多种类型数据并存的混合数据库的知识发现模型。与现有模型相比, 有以下特点: (1) 条件属性集中数据类型由单一符号型、数值型拓宽到包括广义符号型、区间型、数值型、集值型、未知型 (数据缺失) (如图1所示) , 其中广义符号型数据可能是单一符号, 即传统的符号型数据, 也可能是错层型数据 (实际应用中可能存在层次型属性, 可通过“树”来描述。树的终端节点表示样本的实际属性值, 内部节点表示属性值的聚类, 由下层节点形成。这种具有层次的数据, 称为错层型数据。对多个概念层进行规则提取, 可能挖掘出更多重要的知识。</p>
                </div>
                <div class="p1">
                    <p id="57">图2 给出了错层型数据的一个例子) 。 (2) 决策属性可能为符号型或数值型。</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907013_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 条件属性的类型" src="Detail/GetImg?filename=images/JSJK201907013_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 条件属性的类型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907013_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Types of condition attributes</p>

                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907013_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 错层型数据示例" src="Detail/GetImg?filename=images/JSJK201907013_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 错层型数据示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907013_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 An example of cross-level data</p>

                </div>
                <h4 class="anchor-tag" id="60" name="60"><b>2.2 各类型属性值距离及邻域的表示</b></h4>
                <div class="p1">
                    <p id="61">设<i>x</i>为<i>U</i>上的任意对象, <i>a</i>为属性, <i>a</i> (<i>x</i>) 为对象<i>x</i>在属性<i>a</i>下的值。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"> (1) 符号型。</h4>
                <h4 class="anchor-tag" id="63" name="63">①布尔型:</h4>
                <div class="p1">
                    <p id="64">属性值距离为:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>o</mtext><mtext>o</mtext><mtext>l</mtext><mtext>e</mtext><mtext>a</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>0</mn><mo>, </mo><mi>a</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>a</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mi>a</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>≠</mo><mi>a</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">邻域:<i>δ</i><sub>1</sub> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>d</i><sub>boolean</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) =0}。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67">②单一值:</h4>
                <div class="p1">
                    <p id="68">记<i>W</i><sub><i>x</i></sub>={<i>t</i>|<i>a</i> (<i>t</i>) =<i>a</i> (<i>x</i>) , <i>x</i>∈<i>U</i>}, <i>W</i><sub><i>y</i></sub>={<i>t</i>|<i>a</i> (<i>t</i>) =<i>a</i> (<i>y</i>) , <i>y</i>∈<i>U</i>}, 属性值距离为:</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>d</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>i</mtext><mtext>n</mtext><mtext>g</mtext><mtext>l</mtext><mtext>e</mtext><mo>-</mo><mtext>l</mtext><mtext>e</mtext><mtext>v</mtext><mtext>e</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo> (</mo><mrow><mfrac><mn>1</mn><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>U</mi><mo>/</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>d</mi><msub><mrow></mrow><mi>k</mi></msub><mo>∈</mo><mi>U</mi><mo>/</mo><mi>D</mi></mrow></munder><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>W</mi><msub><mrow></mrow><mi>x</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>d</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>W</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></mrow></mrow></mstyle><mo>-</mo></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mrow><mrow><mfrac><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>W</mi><msub><mrow></mrow><mi>y</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>d</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>W</mi><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">邻域:<i>δ</i><sub>2</sub> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>d</i><sub>single-level</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) ≤<i>δ</i>}。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71">③错层型:</h4>
                <div class="p1">
                    <p id="72">设每层节点至其上层节点路径长度为1, 最长路径记为<i>n</i>, 定义<i>d</i><sub>cross-level</sub> (<i>x</i>, <i>y</i>) =<i>l</i> (<i>x</i>, <i>y</i>) /<i>n</i>, 其中<i>l</i> (<i>x</i>, <i>y</i>) 为<i>x</i>到<i>y</i>所经路径长度。例如图3中, 对象<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>的属性值分别为高级公寓和一般别墅, 则从高级公寓到达一般别墅, 需要先到上层节点“公寓”, 路径长度为1, 再到更上层节点“住房”, 其路径长度为1, 从“住房”至下层节点“别墅”, 路径长度为1, 再至下层节点“一般别墅”, 路径长度为1, 经过的总路径长度为1+1+1+1, 则属性值距离定义为<i>d</i><sub>cross-level</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i><sub><i>j</i></sub>) = (1+1+1+1) /<i>n</i>= (1+1+1+1) /4=1。相应地可定义邻域:<i>δ</i><sub>3</sub> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>d</i><sub>cross-level</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) ≤<i>δ</i>}。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907013_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 节点间的路径长度" src="Detail/GetImg?filename=images/JSJK201907013_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 节点间的路径长度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907013_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 Path length between nodes</p>

                </div>
                <h4 class="anchor-tag" id="74" name="74"> (2) 区间型。</h4>
                <div class="p1">
                    <p id="75">设对象<i>x</i>和<i>y</i>区间型属性值分别为[<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>], [<i>b</i><sub>1</sub>, <i>b</i><sub>2</sub>], 则属性值距离定义为:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>i</mtext><mtext>n</mtext><mtext>t</mtext><mtext>e</mtext><mtext>r</mtext><mtext>v</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>-</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>min</mi><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">}</mo><mo>-</mo><mi>max</mi><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo><mo stretchy="false">|</mo></mrow><mrow><mi>max</mi><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">}</mo><mo>-</mo><mi>min</mi><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mo stretchy="false">[</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">]</mo><mstyle displaystyle="true"><mo>∩</mo><mo stretchy="false">[</mo></mstyle><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">]</mo><mo>≠</mo><mo>∅</mo></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mo stretchy="false">[</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">]</mo><mstyle displaystyle="true"><mo>∩</mo><mo stretchy="false">[</mo></mstyle><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">]</mo><mo>=</mo><mo>∅</mo></mtd></mtr></mtable></mrow><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">邻域:<i>δ</i><sub>4</sub> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>d</i><sub>interval</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) ≤<i>δ</i>}。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78"> (3) 数值型。</h4>
                <div class="p1">
                    <p id="79">属性值距离:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext><mtext>e</mtext><mtext>r</mtext><mtext>i</mtext><mtext>c</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>a</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow><mrow><mn>4</mn><mi>δ</mi><msub><mrow></mrow><mi>a</mi></msub></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">其中, <i>δ</i><sub><i>a</i></sub>为属性<i>a</i>的标准差。</p>
                </div>
                <div class="p1">
                    <p id="82">邻域:<i>δ</i><sub>5</sub> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>d</i><sub>numeric</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) ≤<i>δ</i>}。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83"> (4) 集值型。</h4>
                <div class="p1">
                    <p id="84">设<i>a</i>为集值属性, <i>V</i><sub><i>a</i></sub>为<i>a</i>的值域, 属性值距离定义为:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>e</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><mfrac><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>a</mi></mstyle><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mi>max</mi><mo stretchy="false">{</mo><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>a</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">}</mo></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中, <i>Card</i>表示求基数。</p>
                </div>
                <div class="p1">
                    <p id="87">邻域:<i>δ</i><sub>6</sub> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>d</i><sub>set</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) ≤<i>δ</i>}。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88"> (5) 未知型。</h4>
                <div class="p1">
                    <p id="89">为了处理未知型数据 (记为“?”) , 文献<citation id="264" type="reference">[<a class="sup">20</a>]</citation>定义了如下属性值距离:若<i>a</i> (<i>x</i>) =?或<i>a</i> (<i>y</i>) =?, 且<i>x</i>≠<i>y</i>, 则<i>d</i><sub>unknown</sub> (<i>x</i>, <i>y</i>) =1。</p>
                </div>
                <div class="p1">
                    <p id="90">邻域:<i>δ</i><sub>7</sub> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>d</i><sub>unknown</sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) ≤<i>δ</i>}。</p>
                </div>
                <div class="p1">
                    <p id="91">为了处理混合和不完备属性, 可采用以下2种方法:</p>
                </div>
                <div class="p1">
                    <p id="92"><b>方法1</b> 定义<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∩</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mn>7</mn></munderover><mi>δ</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>, 邻域粒子簇{<i>δ</i> (<i>x</i><sub><i>i</i></sub>) |<i>i</i>=1, 2, …, |<i>U</i>|}构成论域的一个覆盖。邻域信息粒子簇诱导出论域<i>U</i>上的一个广义邻域关系<i>N</i>。</p>
                </div>
                <div class="p1">
                    <p id="94"><b>方法2</b> 定义新的混合距离:<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>d</mi></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></msqrt></mrow><mrow><msqrt><mi>m</mi></msqrt></mrow></mfrac></mrow></math></mathml>, 其中:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>d</mi><msub><mrow></mrow><mrow><mtext>b</mtext><mtext>o</mtext><mtext>o</mtext><mtext>l</mtext><mtext>e</mtext><mtext>a</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>, </mo><mi>a</mi><mtext>为</mtext><mtext>布</mtext><mtext>尔</mtext><mtext>属</mtext><mtext>性</mtext></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>i</mtext><mtext>n</mtext><mtext>g</mtext><mtext>l</mtext><mtext>e</mtext><mo>-</mo><mtext>l</mtext><mtext>e</mtext><mtext>v</mtext><mtext>e</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>, </mo><mi>a</mi><mtext>为</mtext><mtext>单</mtext><mtext>一</mtext><mtext>符</mtext><mtext>号</mtext><mtext>型</mtext><mtext>属</mtext><mtext>性</mtext></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>r</mtext><mtext>o</mtext><mtext>s</mtext><mtext>s</mtext><mo>-</mo><mtext>l</mtext><mtext>e</mtext><mtext>v</mtext><mtext>e</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>, </mo><mi>a</mi><mtext>为</mtext><mtext>错</mtext><mtext>层</mtext><mtext>型</mtext><mtext>符</mtext><mtext>号</mtext><mtext>属</mtext><mtext>性</mtext></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mrow><mtext>i</mtext><mtext>n</mtext><mtext>t</mtext><mtext>e</mtext><mtext>r</mtext><mtext>v</mtext><mtext>a</mtext><mtext>l</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>, </mo><mi>a</mi><mtext>为</mtext><mtext>区</mtext><mtext>间</mtext><mtext>值</mtext><mtext>属</mtext><mtext>性</mtext></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext><mtext>e</mtext><mtext>r</mtext><mtext>i</mtext><mtext>c</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>, </mo><mi>a</mi><mtext>为</mtext><mtext>数</mtext><mtext>值</mtext><mtext>型</mtext><mtext>属</mtext><mtext>性</mtext></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>e</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>, </mo><mi>a</mi><mtext>为</mtext><mtext>集</mtext><mtext>值</mtext><mtext>型</mtext><mtext>属</mtext><mtext>性</mtext></mtd></mtr><mtr><mtd><mn>1</mn><mo>, </mo><mi>a</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo>?</mo><mtext>或</mtext><mi>a</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mo>?</mo><mtext>且</mtext><mi>x</mi><mo>≠</mo><mi>y</mi></mtd></mtr></mtable></mrow><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97"><i>m</i>为属性个数, 定义邻域:<i>δ</i> (<i>x</i>) ={<i>x</i><sub><i>i</i></sub>|<i>x</i><sub><i>i</i></sub>∈<i>U</i>, <i>hd</i> (<i>x</i><sub><i>i</i></sub>, <i>x</i>) ≤<i>δ</i>}, <i>δ</i>为邻域半径。邻域的大小依赖于阈值<i>δ</i>, <i>δ</i>越大, 邻域包含的样本越多。</p>
                </div>
                <div class="p1">
                    <p id="98">方法1的不足之处是对每种类型的属性, 都需确定该类的邻域半径, 可操作性略差。而方法2整体考虑各类属性, 只需确定一个邻域半径值即可。以下我们采用方法2。</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag"><b>3 广义邻域空间中的上、下近似</b></h3>
                <div class="p1">
                    <p id="100"><b>定义2</b> 给定实数空间上的非空有限集合<i>U</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>}和<i>U</i>上的广义邻域关系<i>N</i>, 称二元组<i>NAS</i>= (<i>U</i>, <i>N</i>) 为一个广义邻域近似空间。</p>
                </div>
                <div class="p1">
                    <p id="101"><b>定义3</b> 给定<i>NAS</i>= (<i>U</i>, <i>N</i>) 和<i>X</i>⊆<i>U</i>, <i>X</i>在广义邻域近似空间<i>NAS</i>= (<i>U</i>, <i>N</i>) 的下近似与上近似分别定义为:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><mi>X</mi><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>δ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⊆</mo><mi>X</mi><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd><mover accent="true"><mi>Ν</mi><mo>¯</mo></mover><mi>X</mi><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>δ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>X</mi></mstyle><mo>≠</mo><mo>∅</mo><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><mo stretchy="false">}</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">定义<i>X</i>的边界为<mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><mi>Ν</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi>Ν</mi><mo>¯</mo></mover><mi>X</mi><mo>-</mo><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><mi>X</mi></mrow></math></mathml>。<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><mi>X</mi></mrow></math></mathml>也称为<i>X</i>在近似空间<i>NAS</i>= (<i>U</i>, <i>N</i>) 中的正域, 它是能够被<i>X</i>所完全包含的邻域信息粒子的最大并集, 与<i>X</i>完全无关的邻域信息粒子称为<i>X</i>的负域, 定义为<mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>E</mi><mi>G</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mi>U</mi><mo>-</mo><mover accent="true"><mi>Ν</mi><mo>¯</mo></mover><mi>X</mi><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>δ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mrow><mi>X</mi><mo>=</mo></mrow></mstyle><mo>∅</mo><mo stretchy="false">}</mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="107"><b>定义4</b> 给定样本集合<i>U</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>}, <i>C</i>是描述<i>U</i>的混合型条件属性集合, <i>D</i>是决策属性, <i>C</i>生成论域上的一簇邻域关系, 则称<i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为一个混合邻域决策系统。</p>
                </div>
                <div class="p1">
                    <p id="108"><b>定义5</b><i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为混合邻域决策系统, <i>D</i>将<i>U</i>划分为<i>m</i>个类<i>X</i><sub>1</sub>, <i>X</i><sub>2</sub>, …, <i>X</i><sub><i>m</i></sub>, ∀<i>B</i>⊆<i>C</i>, 定义决策<i>D</i>关于<i>B</i>的下近似和上近似为<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></munder><mi>D</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><munder accentunder="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></munder></mrow></mstyle><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mover accent="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mi>D</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mover accent="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow></mstyle><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>。其中, <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></munder><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>δ</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⊆</mo><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><mo stretchy="false">}</mo><mo>, </mo><mover accent="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>δ</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>≠</mo></mrow></mstyle><mo>∅</mo><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><mo stretchy="false">}</mo><mo>, </mo><mi>δ</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>是由属性<i>B</i>生成的邻域信息粒子。</p>
                </div>
                <div class="p1">
                    <p id="111"><b>注1</b> 决策<i>D</i>的下近似也称为决策正域, 记为<i>POS</i><sub><i>B</i></sub> (<i>D</i>) 。正域的大小反映了分类问题在给定属性空间中的可分离程度。正域越大, 说明各类的重叠区域即边界越少。</p>
                </div>
                <div class="p1">
                    <p id="112"><b>注2</b> 决策的边界定义为<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><mi>Ν</mi><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mi>D</mi><mo>-</mo><munder accentunder="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></munder><mi>D</mi></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="114"><b>注3</b> 决策属性诱导的类。</p>
                </div>
                <div class="p1">
                    <p id="115"> (1) 若决策属性为符号型, 直接划分论域得到等价类。</p>
                </div>
                <div class="p1">
                    <p id="116"> (2) 若决策属性为数值型, 类的产生有下述3种方法:</p>
                </div>
                <div class="p1">
                    <p id="117">①将数值型属性模糊化, 语言项个数即为类数, 样本所属类别为隶属度最大的一类。</p>
                </div>
                <div class="p1">
                    <p id="118">②若<i>a</i>为模糊属性, <i>μ</i><sub><i>a</i></sub> (<i>x</i><sub><i>i</i></sub>) ≥<i>β</i>, <i>μ</i><sub><i>a</i></sub> (<i>x</i><sub><i>j</i></sub>) ≥<i>β</i>, <i>β</i>为阈值, 则对象<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>有<i>β</i>不可分辨关系, 具有<i>β</i>不可分辨关系的对象同属一类, 即[<i>x</i>]<sub><i>β</i></sub>={<i>x</i><sub><i>i</i></sub>|<i>μ</i><sub><i>a</i></sub> (<i>x</i><sub><i>i</i></sub>) ≥<i>β</i>}。</p>
                </div>
                <div class="p1">
                    <p id="119"> (3) 计算邻域, 同一邻域内的对象视为一类。</p>
                </div>
                <div class="p1">
                    <p id="120"><b>定义6</b> 定义决策属性<i>D</i>对条件属性<i>B</i>的依赖度为<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><munder accentunder="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mo stretchy="true">¯</mo></munder><mi>D</mi><mo stretchy="false">) </mo><mo>/</mo><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>U</mi><mo stretchy="false">) </mo><mo>=</mo><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><mi>Ο</mi><mi>S</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>/</mo><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>U</mi><mo stretchy="false">) </mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="122">依赖度<i>γ</i><sub><i>B</i></sub> (<i>D</i>) 表示在条件属性<i>B</i>下能够被某一类决策完全包含的样本所占全体样本的比率。正域越大, 决策<i>D</i>对条件属性<i>B</i>的依赖度越强。</p>
                </div>
                <div class="p1">
                    <p id="123"><b>定理1</b><i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为混合邻域决策系统, 若<i>B</i><sub>1</sub>⊆<i>B</i><sub>2</sub>⊆…⊆<i>C</i>, 则<i>γ</i><sub><i>B</i><sub>1</sub></sub> (<i>D</i>) ≤<i>γ</i><sub><i>B</i><sub>2</sub></sub> (<i>D</i>) ≤…≤<i>γ</i><sub><i>C</i></sub> (<i>D</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="124"><b>证明</b> 设∀<i>x</i><sub><i>i</i></sub>∈<i>POS</i><sub><i>B</i><sub>1</sub></sub> (<i>D</i>) , 则∃<i>D</i><sub><i>j</i></sub>, 使得<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><munder accentunder="true"><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mi>B</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub></mrow><mo stretchy="true">¯</mo></munder><mi>D</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>D</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>表示决策类别为<i>j</i>的样本集, 则有<i>δ</i><sub><i>B</i><sub>1</sub></sub> (<i>x</i><sub><i>i</i></sub>) ⊆<i>D</i><sub><i>j</i></sub>。基于同样的邻域阈值<i>δ</i>和度量, 有<i>δ</i><sub><i>B</i><sub>2</sub></sub> (<i>x</i><sub><i>i</i></sub>) ⊆<i>δ</i><sub><i>B</i><sub>1</sub></sub> (<i>x</i><sub><i>i</i></sub>) ⊆<i>D</i><sub><i>j</i></sub>, 故<i>x</i><sub><i>i</i></sub>∈<i>POS</i><sub><i>B</i><sub>2</sub></sub> (<i>D</i>) , 同理可得<i>x</i><sub><i>i</i></sub>∈<i>POS</i><sub><i>B</i><sub>3</sub></sub> (<i>D</i>) , …, <i>x</i><sub><i>i</i></sub>∈<i>POS</i><sub><i>C</i></sub> (<i>D</i>) 。同时, 可能存在<i>x</i><sub><i>j</i></sub>∈<i>U</i>, 使得<i>x</i><sub><i>j</i></sub>∈<i>BN</i><sub><i>B</i><sub>1</sub></sub> (<i>D</i>) , 但<i>x</i><sub><i>j</i></sub>∈<i>POS</i><sub><i>B</i><sub>2</sub></sub> (<i>D</i>) , …, <i>x</i><sub><i>j</i></sub>∈<i>POS</i><sub><i>C</i></sub> (<i>D</i>) 。因此, 可得<i>POS</i><sub><i>B</i><sub>1</sub></sub> (<i>D</i>) ⊆<i>POS</i><sub><i>B</i><sub>2</sub></sub> (<i>D</i>) ⊆…⊆<i>POS</i><sub><i>C</i></sub> (<i>D</i>) , 而<i>γ</i><sub><i>B</i></sub> (<i>D</i>) =<i>Card</i> (<i>POS</i><sub><i>B</i></sub> (<i>D</i>) ) /<i>Card</i> (<i>U</i>) , 故可得<i>γ</i><sub><i>B</i><sub>1</sub></sub> (<i>D</i>) ≤<i>γ</i><sub><i>B</i><sub>2</sub></sub> (<i>D</i>) ≤…≤<i>γ</i><sub><i>C</i></sub> (<i>D</i>) 。  </p>
                </div>
                <h3 id="126" name="126" class="anchor-tag"><b>4 基于邻域粒化的动态规则提取模型</b></h3>
                <h4 class="anchor-tag" id="127" name="127"><b>4.1 动态粒度下的上、下近似</b></h4>
                <div class="p1">
                    <p id="128">在定义3中, 由集合所描述的概念是在基本邻域信息粒子的基础上通过上、下近似算子来刻画的, 但固定不变的粒度限制了其应用范围。通过逐次添加条件属性, 可获得一簇从粗到细的粒度序列, 从而可以建立粒度序下的上、下近似。在近似的过程中, 首先选择一个较粗的粒度, 将该粒度空间中能够确定决策类的对象从论域中删除, 接下来只需考虑尚不能确定决策类的对象, 采用更细的粒度, 再将该粒度空间中能够确定决策类的对象从论域中删除。每次都把论域中仍需进一步研究的部分作为下一个研究对象, 这样便形成了一系列不同层次的表达式。</p>
                </div>
                <div class="p1">
                    <p id="129"><i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为一个混合邻域决策系统, <i>P</i>, <i>Q</i>∈2<sup><i>C</i></sup>为属性子集, 定义2<sup><i>C</i></sup>上的偏序关系≺: <i>P</i>≺<i>Q</i> (<i>Q</i>≻<i>P</i>) 当且仅当对任意<i>δ</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) , 存在<i>δ</i><sub><i>Q</i></sub> (<i>x</i><sub><i>i</i></sub>) , 使得<i>δ</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) ⊆<i>δ</i><sub><i>Q</i></sub> (<i>x</i><sub><i>i</i></sub>) , 其中<i>δ</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) 、<i>δ</i><sub><i>Q</i></sub> (<i>x</i><sub><i>i</i></sub>) 是由属性子集<i>P</i>、<i>Q</i>生成的邻域信息粒子。</p>
                </div>
                <div class="p1">
                    <p id="130">将满足条件<i>R</i><sub>1</sub>≻<i>R</i><sub>2</sub>≻…≻<i>R</i><sub><i>n</i></sub>的属性集序列 <i>R</i><sub><i>i</i></sub>∈2<sup><i>C</i></sup> (<i>i</i>=1, 2, …, <i>n</i>) 所确定的一列从最粗到最细的粒度空间, 称为粒度序。在粒度序下的上、下近似算子可定义如下。</p>
                </div>
                <div class="p1">
                    <p id="131"><b>定义7</b><i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为一个混合邻域决策系统, <i>X</i>⊆<i>U</i>, <i>P</i>={<i>R</i><sub>1</sub>, <i>R</i><sub>2</sub>, …, <i>R</i><sub><i>n</i></sub>}是一簇属性集且满足<i>R</i><sub>1</sub>≻<i>R</i><sub>2</sub>≻…≻<i>R</i><sub><i>n</i></sub> (<i>R</i><sub><i>i</i></sub>∈2<sup><i>C</i></sup>, <i>i</i>=1, 2…, <i>n</i>) , <i>X</i>的上近似与下近似分别定义为:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><mi>X</mi><mo>=</mo><mover accent="true"><mrow><mi>R</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo stretchy="true">¯</mo></mover><mi>X</mi><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>δ</mi><msub><mrow></mrow><mrow><mi>R</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∩</mo><mi>X</mi></mstyle><mo>≠</mo><mo>∅</mo><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd><munder accentunder="true"><mi>Ρ</mi><mo stretchy="true">¯</mo></munder><mi>X</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><munder accentunder="true"><mrow><mi>R</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo stretchy="true">¯</mo></munder></mrow></mstyle><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">{</mo></mstyle><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>δ</mi><msub><mrow></mrow><mrow><mi>R</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⊆</mo><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>U</mi><mo stretchy="false">}</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中, <mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi>X</mi><mo>, </mo><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mi>X</mi><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><munder accentunder="true"><mrow><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo stretchy="true">¯</mo></munder></mrow></mstyle><mi>X</mi><msub><mrow></mrow><mi>k</mi></msub><mo>, </mo><mi>j</mi><mo>=</mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="135"><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><mi>Ν</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><mi>X</mi><mo>-</mo><munder accentunder="true"><mi>Ρ</mi><mo stretchy="true">¯</mo></munder><mi>X</mi></mrow></math></mathml>称为X的P边界, <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>Ο</mi><mi>S</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><munder accentunder="true"><mi>Ρ</mi><mo stretchy="true">¯</mo></munder><mi>X</mi></mrow></math></mathml>称为<i>X</i>的<i>P</i>正域, <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>E</mi><mi>G</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mi>U</mi><mo>-</mo><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><mi>X</mi></mrow></math></mathml>称为<i>X</i>的<i>P</i>负域, 显然, <mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><mi>X</mi><mo>=</mo><mi>Ρ</mi><mi>Ο</mi><mi>S</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mstyle displaystyle="true"><mo>∪</mo><mi>B</mi></mstyle><mi>Ν</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo></mrow></math></mathml>。定义7说明被描述的概念可以由变化的下近似<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml><i>X</i>和上近似<mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover></math></mathml><i>X</i>来逼近。</p>
                </div>
                <div class="p1">
                    <p id="142">为了描述粒度序下概念的不确定性, 定义近似精度:</p>
                </div>
                <div class="p1">
                    <p id="143"><b>定义8</b><i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为一个混合邻域决策系统, <i>X</i>⊆<i>U</i>, <i>P</i>={<i>R</i><sub>1</sub>, <i>R</i><sub>2</sub>, …, <i>R</i><sub><i>n</i></sub>}是一簇属性集且满足<i>R</i><sub>1</sub>≻<i>R</i><sub>2</sub>≻…≻<i>R</i><sub><i>n</i></sub> (<i>R</i><sub><i>i</i></sub>∈2<sup><i>C</i></sup>, <i>i</i>=1, 2…, <i>n</i>) , 定义近似精度<i>α</i><sub><i>P</i></sub> (<i>F</i>) :</p>
                </div>
                <div class="p1">
                    <p id="144" class="code-formula">
                        <mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>F</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><munder accentunder="true"><mi>Ρ</mi><mo stretchy="true">¯</mo></munder><mi>X</mi><mo stretchy="false">) </mo></mrow><mrow><mi>C</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><mi>X</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="145">其中<i>X</i>≠Ø。</p>
                </div>
                <div class="p1">
                    <p id="146"><b>定理2</b><i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为一个混合邻域决策系统, <i>X</i>⊆<i>U</i>, <i>P</i>={<i>R</i><sub>1</sub>, <i>R</i><sub>2</sub>, …, <i>R</i><sub><i>n</i></sub>}是一簇属性集且满足<i>R</i><sub>1</sub>≻<i>R</i><sub>2</sub>≻…≻<i>R</i><sub><i>n</i></sub> (<i>R</i><sub><i>i</i></sub>∈2<sup><i>C</i></sup>, <i>i</i>=1, 2…, <i>n</i>) , 令<i>P</i><sub><i>i</i></sub>={<i>R</i><sub>1</sub>, <i>R</i><sub>2</sub>, …, <i>R</i><sub><i>i</i></sub>}, 则对∀<i>P</i><sub><i>i</i></sub>, <i>i</i>=1, 2, …, <i>n</i>, 有:</p>
                </div>
                <div class="p1">
                    <p id="147" class="code-formula">
                        <mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder accentunder="true"><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="true">¯</mo></munder><mi>X</mi><mo>⊆</mo><mi>X</mi><mo>⊆</mo><mover accent="true"><mi>Ρ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mi>X</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><munder accentunder="true"><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo stretchy="true">¯</mo></munder><mi>X</mi><mo>⊆</mo><munder accentunder="true"><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo stretchy="true">¯</mo></munder><mi>X</mi><mo>⊆</mo><mo>⋯</mo><mo>⊆</mo><munder accentunder="true"><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo stretchy="true">¯</mo></munder><mi>X</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>α</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false"> (</mo><mi>F</mi><mo stretchy="false">) </mo><mo>≤</mo><mi>α</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false"> (</mo><mi>F</mi><mo stretchy="false">) </mo><mo>≤</mo><mo>⋯</mo><mo>≤</mo><mi>α</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></msub><mo stretchy="false"> (</mo><mi>F</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="148" name="148"><b>4.2 基于动态粒度下上下近似的规则提取算法</b></h4>
                <div class="p1">
                    <p id="149">设<i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 为一个混合邻域决策系统, 其中<i>C</i>是混合条件属性集, <i>D</i>是决策属性集, 且<i>C</i>∩<i>D</i>=Ø。<i>D</i>关于<i>C</i>的正域定义为:<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>Ο</mi><mi>S</mi><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∪</mo><mrow><mi>X</mi><mo>∈</mo><mi>U</mi><mo>/</mo><mi>D</mi></mrow></munder><mrow><munder accentunder="true"><mi>C</mi><mo stretchy="true">¯</mo></munder></mrow></mstyle><mi>X</mi><mo>, </mo><mi>D</mi></mrow></math></mathml>对<i>C</i>的依赖度为<i>γ</i><sub><i>C</i></sub> (<i>D</i>) =<i>Card</i> (<i>POS</i><sub><i>C</i></sub> (<i>D</i>) ) /<i>Card</i> (<i>U</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="151"><b>算法1</b> 规则提取算法MR (Mine Rules) </p>
                </div>
                <div class="p1">
                    <p id="152"><b>输入</b>:混合邻域决策系统<i>HS</i>= (<i>U</i>, <i>C</i>, <i>D</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="153"><b>输出</b>:决策规则。</p>
                </div>
                <div class="p1">
                    <p id="154"><b>步骤1</b> 对∀<i>c</i>∈<i>C</i>, 计算<i>D</i>对<i>c</i>的依赖度<i>γ</i><sub>{<i>c</i>}</sub> (<i>D</i>) , 令<i>γ</i><sub>{<i>c</i><sub>1</sub>}</sub> (<i>D</i>) =max{<i>γ</i><sub>{<i>c</i>}</sub> (<i>D</i>) |<i>c</i>∈<i>C</i>}, <i>P</i><sub>1</sub>={<i>c</i><sub>1</sub>}。</p>
                </div>
                <div class="p1">
                    <p id="155"><b>步骤2</b> 计算<i>U</i>/<i>D</i>={<i>Y</i><sub>1</sub>, <i>Y</i><sub>2</sub>, …, <i>Y</i><sub><i>d</i></sub>}。</p>
                </div>
                <div class="p1">
                    <p id="156"><b>步骤3</b> 令<i>P</i>=<i>P</i><sub>1</sub>, <i>U</i><sub>1</sub>=<i>U</i>, <i>Γ</i>=Ø, <i>Rule</i>′=<i>Rule</i>=Ø, <i>k</i>=1。</p>
                </div>
                <div class="p1">
                    <p id="157"><b>步骤4</b> 令<i>Γ</i>′={<i>x</i><sub><i>i</i></sub>|<i>δ</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) ⊆<i>Y</i><sub><i>j</i></sub>, <i>Y</i><sub><i>j</i></sub>∈<i>U</i>/<i>D</i>, <i>j</i>=1, 2, …, <i>d</i>, <i>x</i><sub><i>i</i></sub>∈<i>U</i><sub><i>k</i></sub>}, 添加<i>des</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) →<i>des</i><sub><i>D</i></sub> (<i>Y</i><sub><i>j</i></sub>) 到<i>Rule</i>′, 令<i>Rule</i>=<i>Rule</i>∪<i>Rule</i>′, <i>Γ</i>=<i>Γ</i>∪<i>Γ</i>′, <i>U</i><sub><i>k</i>+1</sub>=<i>U</i><sub><i>k</i></sub>-<i>Γ</i>。</p>
                </div>
                <div class="p1">
                    <p id="158"><b>步骤5</b> 若<i>U</i><sub><i>k</i>+1</sub>=Ø, 转步骤6;否则, 对∀<i>c</i>∈<i>C</i>-<i>P</i>, 计算<i>γ</i><sub><i>P</i>∪{<i>c</i>}</sub> (<i>D</i>) 。令<i>γ</i><sub><i>P</i>∪{<i>c</i><sub>2</sub>}</sub> (<i>D</i>) =max{<i>γ</i><sub><i>P</i>∪{<i>c</i>}</sub> (<i>D</i>) |<i>c</i>∈<i>C</i>-<i>P</i>}。令<i>P</i><sub><i>k</i>+1</sub>=<i>P</i><sub><i>k</i></sub>∪{<i>c</i><sub>2</sub>}, <i>P</i>=<i>P</i>∪<i>P</i><sub><i>k</i>+1</sub>, <i>k</i>=<i>k</i>+1, 转步骤4。</p>
                </div>
                <div class="p1">
                    <p id="159"><b>步骤6</b> 输出<i>Rule</i>。</p>
                </div>
                <div class="p1">
                    <p id="160"><b>注4</b> 步骤4中, <i>des</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) 表示规则前件, <i>des</i><sub><i>D</i></sub> (<i>Y</i><sub><i>j</i></sub>) 表示规则后件。</p>
                </div>
                <div class="p1">
                    <p id="161"><b>注5</b> 步骤2中, <i>U</i>/<i>D</i>表示根据<citation id="265" type="reference"><link href="211" rel="bibliography" />注3</citation>的方法, 由决策属性诱导的类。</p>
                </div>
                <div class="p1">
                    <p id="162"><b>注6</b> 算法表明决策规则的提取不依赖于属性约简, 而依赖于粒度序<i>P</i>和变化的论域。MR算法能在保持近似精度不变的前提下提取更简单的决策规则 (更简单意味着决策规则前件包含的条件更少) 。</p>
                </div>
                <h4 class="anchor-tag" id="163" name="163"><b>4.3 一个例子</b></h4>
                <div class="p1">
                    <p id="164">下面通过一个例子来说明算法的运行过程。表1为一个混合决策系统, <i>C</i>={<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>, <i>a</i><sub>3</sub>, <i>a</i><sub>4</sub>, <i>a</i><sub>5</sub>} 为条件属性, <i>d</i>为决策属性。</p>
                </div>
                <div class="p1">
                    <p id="165">由表1可知, <i>U</i>/<i>d</i>={<i>Y</i><sub>1</sub>, <i>Y</i><sub>2</sub>, <i>Y</i><sub>3</sub>}, 其中, <i>Y</i><sub>1</sub>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>8</sub>}, <i>Y</i><sub>2</sub>={<i>x</i><sub>4</sub>, <i>x</i><sub>5</sub>}, <i>Y</i><sub>3</sub>={<i>x</i><sub>6</sub>, <i>x</i><sub>7</sub>, <i>x</i><sub>9</sub>}。取<i>δ</i>=0.15。</p>
                </div>
                <div class="p1">
                    <p id="166"> (1) 计算<i>γ</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>D</i>) 。首先计算<i>δ</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>) :<i>a</i><sub>1</sub>为 单一符号属性, 故<i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>) =<mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mfrac><mn>2</mn><mn>2</mn></mfrac><mo>-</mo><mfrac><mn>2</mn><mn>2</mn></mfrac><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mfrac><mn>0</mn><mn>2</mn></mfrac><mo>-</mo><mfrac><mn>0</mn><mn>2</mn></mfrac><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mfrac><mn>0</mn><mn>2</mn></mfrac><mo>-</mo><mfrac><mn>0</mn><mn>2</mn></mfrac><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mo stretchy="false">]</mo><mo>=</mo><mn>0</mn></mrow></math></mathml>, </p>
                </div>
                <div class="area_img" id="168">
                    <p class="img_tit"><b>表1 一个混合信息系统</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 A hybrid information system</b></p>
                    <p class="img_note"></p>
                    <table id="168" border="1"><tr><td><i>U</i></td><td><i>a</i><sub>1</sub></td><td><i>a</i><sub>2</sub></td><td><i>a</i><sub>3</sub></td><td><i>a</i><sub>4</sub></td><td><i>a</i><sub>5</sub></td><td><i>d</i></td></tr><tr><td><br /><i>x</i><sub>1</sub></td><td>sick</td><td>yes</td><td>40</td><td>{C, R, A}</td><td>[2.56, 3.59]</td><td>F</td></tr><tr><td><br /><i>x</i><sub>2</sub></td><td>sick</td><td>yes</td><td>39.5</td><td>{C, R, A}</td><td>[2.53, 3.71]</td><td>F</td></tr><tr><td><br /><i>x</i><sub>3</sub></td><td>middle</td><td>?</td><td>39</td><td>{C}</td><td>[2.35, 2.91]</td><td>F</td></tr><tr><td><br /><i>x</i><sub>4</sub></td><td>middle</td><td>yes</td><td>36.8</td><td>{R}</td><td>[2.29, 3.42]</td><td>R</td></tr><tr><td><br /><i>x</i><sub>5</sub></td><td>middle</td><td>no</td><td>?</td><td>{R}</td><td>[2.92, 3.53]</td><td>R</td></tr><tr><td><br /><i>x</i><sub>6</sub></td><td>no</td><td>no</td><td>36.6</td><td>{R, A}</td><td>[1.67, 2.52]</td><td>H</td></tr><tr><td><br /><i>x</i><sub>7</sub></td><td>no</td><td>?</td><td>?</td><td>{A}</td><td>[2.28, 2.71]</td><td>H</td></tr><tr><td><br /><i>x</i><sub>8</sub></td><td>no</td><td>yes</td><td>38</td><td>{C, R, A}</td><td>[2.32, 3.47]</td><td>F</td></tr><tr><td><br /><i>x</i><sub>9</sub></td><td>?</td><td>yes</td><td>37</td><td>{R}</td><td>[1.82, 2.38]</td><td>H</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="169">类似地可计算<i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>3</sub>) =0.544, <i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>4</sub>) =0.544, <i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>5</sub>) =0.544, <i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>6</sub>) =0.544, <i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>7</sub>) =0.544, <i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>8</sub>) =0.544, <i>d</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>9</sub>) =1, 故<i>δ</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub>1</sub>) ={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>}。</p>
                </div>
                <div class="p1">
                    <p id="170">类似地可计算<i>δ</i><sub>{<i>a</i><sub>1</sub>}</sub> (<i>x</i><sub><i>i</i></sub>) , <i>i</i>=2, …, 9, 如表2所示。故<mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><msub><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo></mrow></msub><mo stretchy="false"> (</mo><mi>Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">}</mo><mo>, </mo><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><msub><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo></mrow></msub><mo stretchy="false"> (</mo><mi>Y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo>=</mo><mo>∅</mo><mo>, </mo><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><msub><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo></mrow></msub><mo stretchy="false"> (</mo><mi>Y</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>9</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mi>γ</mi><msub><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo></mrow></msub><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mn>3</mn><mo>/</mo><mn>9</mn><mo>=</mo><mn>1</mn><mo>/</mo><mn>3</mn></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="172"> (2) 以下依次计算<i>γ</i><sub>{<i>a</i><sub>2</sub>}</sub> (<i>D</i>) , <i>γ</i><sub>{<i>a</i><sub>3</sub>}</sub> (<i>D</i>) , <i>γ</i><sub>{<i>a</i><sub>4</sub>}</sub> (<i>D</i>) , <i>γ</i><sub>{<i>a</i><sub>5</sub>}</sub> (<i>D</i>) , 计算结果如表3所示。下面以对象<i>x</i><sub>1</sub>和<i>x</i><sub>2</sub>之间的距离为例来说明不同类型属性下对象间距离的计算过程:</p>
                </div>
                <div class="p1">
                    <p id="173"> (1) <i>a</i><sub>2</sub>为布尔属性, 故<i>d</i><sub>{<i>a</i><sub>2</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>) =0;</p>
                </div>
                <div class="p1">
                    <p id="174"> (2) <i>a</i><sub>3</sub>为数值型属性, 其标准差为<i>δ</i><sub><i>a</i><sub>3</sub></sub>=1.28, <i>d</i><sub>{<i>a</i><sub>3</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>) =|<i>a</i><sub>3</sub> (<i>x</i><sub>1</sub>) -<i>a</i><sub>3</sub> (<i>x</i><sub>2</sub>) |/ (4<i>δ</i><sub><i>a</i><sub>3</sub></sub>) = (40-39.5) / (4×1.28) =0.098;</p>
                </div>
                <div class="p1">
                    <p id="175"> (3) <i>a</i><sub>4</sub>为集值型属性, <i>d</i><sub>{<i>a</i><sub>4</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>) =1-3/3=0;</p>
                </div>
                <div class="p1">
                    <p id="176"> (4) <i>a</i><sub>5</sub>为区间值属性, <i>d</i><sub>{<i>a</i><sub>5</sub>}</sub> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>) =1- (3.59-2.56) / (3.71-2.53) =0.127。</p>
                </div>
                <div class="p1">
                    <p id="177">由表3可知, <i>γ</i><sub>{<i>a</i><sub>5</sub>}</sub> (<i>D</i>) 最大, 故<i>P</i><sub>1</sub>={<i>a</i><sub>5</sub>}, <i>P</i>=<i>P</i><sub>1</sub>, <i>Γ</i>′={<i>x</i><sub><i>i</i></sub>|<i>δ</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) ⊆<i>Y</i><sub><i>j</i></sub>, <i>Y</i><sub><i>j</i></sub>∈<i>U</i>/<i>D</i>, <i>j</i>=1, 2, 3, <i>x</i><sub><i>i</i></sub>∈<i>U</i><sub>1</sub>}={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>5</sub>, <i>x</i><sub>6</sub>, <i>x</i><sub>7</sub>, <i>x</i><sub>9</sub>}, <i>U</i><sub>2</sub>=<i>U</i><sub>1</sub>-<i>Γ</i>={<i>x</i><sub>4</sub>, <i>x</i><sub>8</sub>}。</p>
                </div>
                <div class="area_img" id="178">
                    <p class="img_tit"><b>表2 邻域的计算</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Neighborhood calculation</b></p>
                    <p class="img_note"></p>
                    <table id="178" border="1"><tr><td><br /><i>k</i></td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>1</sub>) </td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>8</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>8</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>2</sub>) </td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>8</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>8</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>3</sub>) </td><td><i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>5</sub></td><td><i>x</i><sub>3</sub></td><td><i>x</i><sub>2</sub>, <i>x</i><sub>3</sub></td><td><i>x</i><sub>3</sub></td><td><i>x</i><sub>3</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>4</sub>) </td><td><i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>5</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>8</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>6</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>5</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>8</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>5</sub>) </td><td><i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>5</sub></td><td><i>x</i><sub>5</sub>, <i>x</i><sub>6</sub></td><td><i>x</i><sub>5</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>5</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>5</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>6</sub>) </td><td><i>x</i><sub>6</sub>, <i>x</i><sub>7</sub>, <i>x</i><sub>8</sub></td><td><i>x</i><sub>5</sub>, <i>x</i><sub>6</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>6</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>6</sub></td><td><i>x</i><sub>6</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>7</sub>) </td><td><i>x</i><sub>6</sub>, <i>x</i><sub>7</sub>, <i>x</i><sub>8</sub></td><td><i>x</i><sub>7</sub></td><td><i>x</i><sub>7</sub></td><td><i>x</i><sub>7</sub></td><td><i>x</i><sub>7</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>8</sub>) </td><td><i>x</i><sub>6</sub>, <i>x</i><sub>7</sub>, <i>x</i><sub>8</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>8</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>8</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>8</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>8</sub></td></tr><tr><td><br /><i>δ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>x</i><sub>9</sub>) </td><td><i>x</i><sub>9</sub></td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>8</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>6</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>4</sub>, <i>x</i><sub>5</sub>, <i>x</i><sub>9</sub></td><td><i>x</i><sub>9</sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="179">
                    <p class="img_tit"><b>表3 单个属性的依赖度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Dependency of each attribute</b></p>
                    <p class="img_note"></p>
                    <table id="179" border="1"><tr><td><br /><i>k</i></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><msub><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">}</mo></mrow></msub><mo stretchy="false"> (</mo><mi>Y</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mrow></math></td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder accentunder="true"><mi>Ν</mi><mo stretchy="true">¯</mo></munder><msub><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">}</mo></mrow></msub><mo stretchy="false"> (</mo><mi>Y</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mrow></math></td><td><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ν</mi><mo>¯</mo></mover></math><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>Y</i><sub>3</sub>) </td><td><i>γ</i><sub>{<i>a</i><sub><i>k</i></sub>}</sub> (<i>D</i>) </td></tr><tr><td><br />1</td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></td><td>Ø</td><td><i>x</i><sub>9</sub></td><td>1/3</td></tr><tr><td><br />2</td><td><i>x</i><sub>3</sub></td><td>Ø</td><td><i>x</i><sub>7</sub></td><td>2/9</td></tr><tr><td><br />3</td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>8</sub></td><td><i>x</i><sub>5</sub></td><td><i>x</i><sub>7</sub></td><td>2/3</td></tr><tr><td><br />4</td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>8</sub></td><td>Ø</td><td><i>x</i><sub>6</sub>, <i>x</i><sub>7</sub></td><td>2/3</td></tr><tr><td><br />5</td><td><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub></td><td><i>x</i><sub>5</sub></td><td><i>x</i><sub>6</sub>, <i>x</i><sub>7</sub>, <i>x</i><sub>9</sub></td><td>7/9</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="181">对∀<i>c</i>∈<i>C</i>-<i>P</i>, 计算<i>γ</i><sub><i>P</i>∪{<i>c</i>}</sub> (<i>D</i>) 。根据方法2中混合距离的定义, 计算可得<i>γ</i><sub>{<i>a</i><sub>5</sub>}∪{<i>a</i><sub>1</sub>}</sub> (<i>D</i>) =1, <i>γ</i><sub>{<i>a</i><sub>5</sub>}∪{<i>a</i><sub>2</sub>}</sub> (<i>D</i>) =7/9, <i>γ</i><sub>{<i>a</i><sub>5</sub>}∪{<i>a</i><sub>3</sub>}</sub> (<i>D</i>) =1, <i>γ</i><sub>{<i>a</i><sub>5</sub>}∪{<i>a</i><sub>4</sub>}</sub> (<i>D</i>) =1, 故<i>c</i><sub>2</sub>可为<i>a</i><sub>1</sub>, <i>a</i><sub>3</sub>, <i>a</i><sub>4</sub>中任一个, <i>P</i><sub>2</sub>=<i>P</i><sub>1</sub>∪{<i>c</i><sub>2</sub>}, <i>P</i>=<i>P</i>∪<i>P</i><sub>2</sub>, <i>Γ</i>′={<i>x</i><sub><i>i</i></sub>|<i>δ</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) ⊆<i>Y</i><sub><i>j</i></sub>, <i>Y</i><sub><i>j</i></sub>∈<i>U</i>/<i>D</i>, <i>j</i>=1, 2, …, <i>d</i>, <i>x</i><sub><i>i</i></sub>∈<i>U</i><sub>2</sub>}={<i>x</i><sub>4</sub>, <i>x</i><sub>8</sub>}, <i>U</i><sub>3</sub>=Ø, 由于<i>U</i><sub>3</sub>=Ø, 故算法终止, 输出规则。由于<i>c</i><sub>2</sub>的选择不同, 输出规则不同, 在此不一一列举。规则均为以下形式:<i>Rule</i>={<i>des</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) →<i>des</i><sub><i>D</i></sub> (<i>Y</i><sub><i>j</i></sub>) }, 其中<i>des</i><sub><i>P</i></sub> (<i>x</i><sub><i>i</i></sub>) 为规则前件, <i>des</i><sub><i>D</i></sub> (<i>Y</i><sub><i>j</i></sub>) 为规则后件。以其中2条规则为例: (1) <i>d</i><sub>{<i>a</i><sub>5</sub>}</sub> (<i>x</i>, <i>x</i><sub>1</sub>) &lt;0.15→<i>x</i>∈<i>Y</i><sub>1</sub>, 表示在属性<i>a</i><sub>5</sub>下, 若对象<i>x</i>与对象<i>x</i><sub>1</sub>的距离小于0.15, 则<i>x</i>∈<i>Y</i><sub>1</sub>。 (2) <i>d</i><sub>{<i>a</i><sub>5</sub>}∪{<i>a</i><sub>4</sub>}</sub> (<i>x</i>, <i>x</i><sub>4</sub>) &lt;0.15→<i>x</i>∈<i>Y</i><sub>2</sub>, 表示在属性<i>a</i><sub>5</sub>和<i>a</i><sub>4</sub>下, 若对象<i>x</i>与对象<i>x</i><sub>4</sub>的距离小于0.15, 则<i>x</i>∈<i>Y</i><sub>2</sub>。</p>
                </div>
                <h3 id="182" name="182" class="anchor-tag"><b>5 实验分析</b></h3>
                <div class="p1">
                    <p id="183">为了验证上述针对混合数据集的规则提取模型的有效性, 我们从UCI数据库<citation id="266" type="reference"><link href="247" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>中选择了几组数据进行实验, 数据描述如表4所示。</p>
                </div>
                <div class="area_img" id="184">
                    <p class="img_tit"><b>表4 数据描述</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Data description</b></p>
                    <p class="img_note"></p>
                    <table id="184" border="1"><tr><td><br />数据集</td><td>样本数</td><td>属性数</td><td>属性类型</td><td>类数</td></tr><tr><td><br />Horse</td><td>368</td><td>26</td><td>符号型、数值型</td><td>2</td></tr><tr><td><br />Wine</td><td>178</td><td>18</td><td>符号型、数值型</td><td>3</td></tr><tr><td><br />Credit (set) </td><td>690</td><td>16</td><td>符号型、布尔型、数值型、集值型</td><td>2</td></tr><tr><td><br />Image</td><td>2 310</td><td>19</td><td>数值型</td><td>7</td></tr><tr><td><br />German</td><td>1 000</td><td>20</td><td>符号型、布尔型、数值型</td><td>2</td></tr><tr><td><br />Housing</td><td>506</td><td>13</td><td>符号型、数值型</td><td>连续型</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="185">为了评估上述方法处理集值型属性的能力, 我们基于Credit数据集, 通过将3个布尔型属性1, 9, 10合并从而生成一个集值属性16, 构造了一个新的数据集Credit (set) 。为了考查上述方法处理未知型属性的能力, 在Image数据集中, 随机删除了部分样本属性值, 增大了样本的不完备性。数据样本被分为训练集和测试集2部分, 用训练集得出决策分类规则, 用测试集的预测精度来评价模型和方法的质量。</p>
                </div>
                <div class="p1">
                    <p id="186">关于邻域半径<i>δ</i>的取值:当<i>δ</i>较小时, 相应粒度较小, 较少的特征即可区分样本。<i>δ</i>取值越大, 所需特征也越多, 当粒度超过一定程度时, 任何特征都不足以区分样本。所以, <i>δ</i>的取值和具体分类问题有关。<i>δ</i>的取值以0.05为步长从0到1变化, 通过实验发现, <i>δ</i>在[0.1, 0.3]取值较为合适。以下实验中, 我们将在此范围内对<i>δ</i>随机取值。</p>
                </div>
                <div class="p1">
                    <p id="187">为了比较所选择特征的分类能力, 我们引入CART 和RBF-SVM 分类学习算法, 以10 折交叉验证的分类精度来评价选择特征的质量。对数据集Credit (set) , 基于MR算法的方法有效, 其他2种方法不适用。对数据集Housing, 基于RBF-SVM的方法不适用。</p>
                </div>
                <div class="area_img" id="188">
                    <p class="img_tit"><b>表5 基于MR、CART、RBF-SVM方法的分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Classification accuracy based on MR, CART and RBF-SVM methods</b></p>
                    <p class="img_note"></p>
                    <table id="188" border="1"><tr><td><br />数据集</td><td>MR</td><td>CART</td><td>RBF-SVM</td></tr><tr><td><br />Horse</td><td>0.867 5±0.034 6</td><td>0.848 5±0.078 6</td><td>0.837 8±0.048 2</td></tr><tr><td><br />Wine</td><td>0.965 7±0.036 8</td><td>0.898 8±0.056 5</td><td>0.952 6±0.073 1</td></tr><tr><td><br />Credit (set) </td><td>0.843 8±0.045 5</td><td>-</td><td>-</td></tr><tr><td><br />Image</td><td>0.851 2±0.022 5</td><td>0.766 1±0.113 5</td><td>0.782 3±0.062 7</td></tr><tr><td><br />German</td><td>0.732 6±0.042 0</td><td>0.722 8±0.036 1</td><td>0.734 1±0.129 2</td></tr><tr><td><br />Housing</td><td>0.785 8±0.020 3</td><td>0.770 2±0.057 7</td><td>-</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="189">从表5可看出, 当条件属性中包含集值型属性或决策属性为连续型属性时, 算法MR具有较强的适用性, 且对大多数数据集, 算法MR的分类表现要优于其他2种算法的。</p>
                </div>
                <h3 id="190" name="190" class="anchor-tag"><b>6 结束语</b></h3>
                <div class="p1">
                    <p id="191">本文的目的是针对各种类型数据并存的数据集, 构建适用于混合数据规则提取的模型。与目前已有的混合数据处理模型相比, 创新点有3方面: (1) 条件属性包含的类型更多样化:①符号型数据类型从单一值拓宽到错层型;②可以处理区间值数据;③可以处理集值型数据; (2) 能够处理决策属性为数值型数据的数据集; (3) 构建了针对混合决策系统的动态规则提取模型 (算法MR) 。目前大多针对混合数据挖掘的方法通常包括2步:属性约简和规则提取, 而属性约简本身可能存在的不足会对规则提取造成一定影响。本文所构建模型具有3个特征: (1) MR算法基于粒度序提取规则, 避开了属性约简; (2) 对算法MR, 由于论域是逐渐缩小的, 计算复杂度能有效降低; (3) MR能在保持近似精度不变的前提下提取更简单的决策规则。针对UCI数据库中的数据集进行了对比实验, 其分类精度表明了规则提取算法的有效性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="268" type="formula" href="images/JSJK201907013_26800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">程昳</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="270" type="formula" href="images/JSJK201907013_27000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">刘勇</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="207">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning">

                                <b>[1]</b> Hall M A.Correlation-based feature selection for discrete and numeric class machine learning[C]//Proc of the 17th International Conference on Machine Learning, 2000:359-366.
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501719983&amp;v=MTQ2ODc9TmlmT2ZiSzdIdEROcW85RVkrb0dCWFE2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmwwZGFSbw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Zhou Z H, Chen Z Q.Hybrid decision tree[J].Knowledge Based Systems, 2002, 15 (8) :515-528.
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414653&amp;v=MTQyNzVkYVJvPU5pZk9mYks3SHRET3JJOUZZT29MQ25rNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsMA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Tang W Y, Mao K Z.Feature selection algorithm for mixed data with both nominal and continuous features[J].Pattern Recognition Letters, 2007, 28 (5) :563-571.
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002176361&amp;v=Mjc0MDdEWiswT1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNEbFZiekJJMVk9Tmo3QmFyTzRIdEhPcm9o&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Pawlak Z.Rough sets[J].International Journal of Computer and Information Sciences, 1982, 11 (5) :341-356.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dependency of attributes in information systems">

                                <b>[5]</b> Pawlak Z, Rauszer C.Dependency of attributes in information systems[J].Bulletin of the Polish Academy of Sciences, Mathematical Sciences, 1985, 33 (9-10) :551-559.
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300414908&amp;v=Mjk3NDQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsMGRhUm89TmlmT2ZiSzdIdERPckk5RllPb0xCWHd4b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Hu Q H, Yu D R, Xie Z X.Information-preserving hybrid data reduction based on fuzzy-rough techniques[J].Pattern Recognition Letters, 2006, 27 (5) :414-423.
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Feature and instance reduction for PNN classifiers based on fuzzy rough sets">

                                <b>[7]</b> Tsang E, Hu Q H, Chen D G.Feature and instance reduction for PNN classifiers based on fuzzy rough sets[J].International Journal of Machine Learning and Cybernetics, 2016, 7 (1) :1-11.
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neighbor inconsistent pair selection for attribute reduction by rough set approach">

                                <b>[8]</b> Dai J H, Hu Q H, Hu H, et al.Neighbor inconsistent pair selection for attribute reduction by rough set approach[J].IEEE Transactions on Fuzzy Systems, 2018, 26 (2) :937-950.
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD1DC84539CE2EDA9B52B9C27E59FB9BA&amp;v=MDkzMjZ6Z3EyY3djTVRtVE1qdUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHdydTJ3NkE9TmlmT2ZjZTVhcUxFcTRwR2JaaDZEZ2xOdmg5aDd6MFBRUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Wu W Z, Qian Y H, Li T J, et al.On rule acquisition in incomplete multi-scale decision tables[J].Information Sciences, 2016, 378 (C) :282-302.
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD4760DB8FC31A80A20FA636645327C883&amp;v=MjExODlFNTdTM25rcUJjMmU3WG5UYktjQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJod3J1Mnc2QT1OaWZjYXJlL0dORzQzWWN6RitnT2ZYUTV2aFFUbg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Li T R, Ruan D, Shen Y J, et al.A new weighting approach based on rough set theory and granular computing for road safety indicator analysis[J].Computational Intelligence, 2016, 32 (4) :517-534.
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8EFD4A5C0FB71643AE384F8D930B9530&amp;v=MjU3OTB4MVRBbnEyQnMyZWNDZFFMbWZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3cnUydzZBPU5pZk9mYnZOYUtYSTNvbzJaSjE5QzMwL3l4Vmlueg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Cheng Y.Forward approximation and backward approximation in fuzzy rough sets[J].Neurocomputing, 2015, 148:340-353.
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic maintenance of approximations under fuzzy rough sets">

                                <b>[12]</b> Cheng Y.Dynamic maintenance of approximations under fuzzy rough sets[J].International Journal of Machine Learning and Cybernetics, 2018, 9 (12) :2011-2026.
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8B4156F074BAA1F96BCFD167BA8F1674&amp;v=MDIzNzZwYlEzNU5CaHdydTJ3NkE9TmlmT2ZidktHdERKcWZsRlkrOTlmUTA0dVI4Vm1Fd0xQSDdrcTJCRWNjU1ZRNzJiQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Sun B Z, Ma W M, Qian Y H.Multigranulation fuzzy rough set over two universes and its application to decision making[J].Knowledge-Based Systems, 2017, 123 (C) :61-74.
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8B636A829884924F7E7026A8D77301C6&amp;v=MTQzMjdIWWZPR1FsZkNwYlEzNU5CaHdydTJ3NkE9TmlmT2ZidktHTkxLM29kSGJlTUhDSFU3eTJBVW56aDlTbm1UcEdZeWZyR1VSTW1aQ09OdkZTaVdXcjdKSUZwbWFCdQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> She Y H, He X L, Shi H X, et al.A multiple-valued logic approach for multigranulation rough set model[J].International Journal of Approximate Reasoning, 2017, 82:270-284.
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA257C4EA1B4C46397D191E2290305691&amp;v=MDUxMTVXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHdydTJ3NkE9TmlmT2ZjSzZHOWEvcS9vMFpaa0xmM2cvekI4VW5qNTBTUXJncmhzMWVyS1JRN09lQ09OdkZTaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Qian Y H, Liang X Y, Lin G P, et al.Local multigranulation decision-theoretic rough sets[J].International Journal of Approximate Reasoning, 2017, 82 (C) :119-137.
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES55AA3D461E587BEE2757088489396AC8&amp;v=MjA3MTdaNEtCSHRMdW1NUjdUcDZTSGZxcUJvOGVydVNOTW1YQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJod3J1Mnc2QT1OaWZPZmJhOWI2RFAyNHREWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Qian Y H, Cheng H H, Wang J T, et al.Grouping granular structures in human granulation intelligence[J].Information Sciences, 2017, 382-383:150-169.
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 Hu Qing-hua, Yu Da-ren, Xie Zong-xia.Numerical attribute reduction based on neighborhood granulation and rough approximation[J].Journal of Software, 2008, 19 (3) :640-649. (in Chinese) 
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501643510&amp;v=MTkzMzlUNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKbDBkYVJvPU5pZk9mYks3SHRETnFvOUVZdThNQ1gwNW9CTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Hu Q H, Yu D R, Xie Z X.Neighborhood classifiers[J].Expert Systems with Applications, 2008, 34 (2) :866-876.
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700153250&amp;v=MDY2NTdsMGRhUm89TmlmT2ZiSzhIOURNcUk5RlplNE1Ebms1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Zeng A P, Li T R Liu D.A fuzzy rough set approach for incremental feature selection on hybrid information systems[J].Fuzzy Sets and Systems, 2015, 258 (1) :39-60.
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved heterogeneous distance functions">

                                <b>[20]</b> Wllson D R, Martinez T R.Improved heterogeneous distance functions[J].Journal of Artificial Intelligence Research, 1997, 6 (1) :1-34.
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_21" target="_blank" href="">

                                <b>[21]</b> http://www.ics.uci.edu/～mlearn/MLRepository.html.
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200803018&amp;v=MTUyNjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21XcnpBTnlmVGJMRzRIdG5Nckk5RWJJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 胡清华, 于达仁, 谢宗霞.基于邻域粒化和粗糙逼近的数值属性约简[J].软件学报, 2008, 19 (3) :640-649.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201907013" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907013&amp;v=MDQ2MzVFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bVdyekFMejdCWmJHNEg5ak1xSTk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
