<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132344527217500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJK201911026%26RESULT%3d1%26SIGN%3d1sSOms%252bmt2pX4crXcYzOUW0Yb0s%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911026&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911026&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911026&amp;v=MDc5ODViRzRIOWpOcm85SFlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVcnZLTHo3Qlo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="&lt;b&gt;2 ACCS与CBA的对比&lt;/b&gt; "><b>2 ACCS与CBA的对比</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;2.1 基本定义&lt;/b&gt;"><b>2.1 基本定义</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.2 算法各步骤对比&lt;/b&gt;"><b>2.2 算法各步骤对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="&lt;b&gt;3 ACCS算法&lt;/b&gt; "><b>3 ACCS算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="&lt;b&gt;3.1 ACCS算法的规则挖掘&lt;/b&gt;"><b>3.1 ACCS算法的规则挖掘</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;3.2 ACCS算法的伪代码&lt;/b&gt;"><b>3.2 ACCS算法的伪代码</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#126" data-title="&lt;b&gt;4 实验设计与实验结果&lt;/b&gt; "><b>4 实验设计与实验结果</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="&lt;b&gt;4.1 实验设计&lt;/b&gt;"><b>4.1 实验设计</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;4.2 实验结果与分析&lt;/b&gt;"><b>4.2 实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#143" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#96" data-title="&lt;b&gt;表1 训练数据&lt;/b&gt;"><b>表1 训练数据</b></a></li>
                                                <li><a href="#98" data-title="图1 ACCS算法的流程图">图1 ACCS算法的流程图</a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表2 实验所用的UCI数据集&lt;/b&gt;"><b>表2 实验所用的UCI数据集</b></a></li>
                                                <li><a href="#136" data-title="&lt;b&gt;表3 ACCS算法与6种算法的准确率对比&lt;/b&gt;"><b>表3 ACCS算法与6种算法的准确率对比</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;表4 ACCS和CBA、CCCS算法的错误率对比&lt;/b&gt;"><b>表4 ACCS和CBA、CCCS算法的错误率对比</b></a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表5 ACCS算法和CBA算法的4种度量值比较结果&lt;/b&gt;"><b>表5 ACCS算法和CBA算法的4种度量值比较结果</b></a></li>
                                                <li><a href="#142" data-title="图2 不同最大类类支持度阈值下的准确率比较">图2 不同最大类类支持度阈值下的准确率比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Sun Y,Wong A K C,Kamel M S.Classification of imbalanced data:A review[J].International Journal of Pattern Recognition and Artificial Intelligence,2009,23(4):687-719." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification of imbalanced data: A review">
                                        <b>[1]</b>
                                         Sun Y,Wong A K C,Kamel M S.Classification of imbalanced data:A review[J].International Journal of Pattern Recognition and Artificial Intelligence,2009,23(4):687-719.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Chawla N V,Japkowicz N,Kotcz A.Editorial:Special issue on learning from imbalanced data sets[J].ACM SIGKDD Explorations Newsletter,2004,6(1):1-6." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000085394&amp;v=MjIzNjJmSUoxc1ZiaEE9TmlmSVk3SzdIdGpOcjQ5RlpPTUtEM1U5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Chawla N V,Japkowicz N,Kotcz A.Editorial:Special issue on learning from imbalanced data sets[J].ACM SIGKDD Explorations Newsletter,2004,6(1):1-6.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Alwidian J,Hammo B H,Obeid N.WCBA:Weighted classification based on association rules algorithm for breast cancer disease[J].Applied Soft Computing,2017,62:536-549." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA580F32BB35BD95DA123C0F03EEE1FD9&amp;v=MjY3ODRySTAzRnVnS2ZnZ3d5bUppNnoxK08zK1VyQkZBRE1lVk04NldDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3NzIreEtvPU5pZk9mY0s5RnRHNg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Alwidian J,Hammo B H,Obeid N.WCBA:Weighted classification based on association rules algorithm for breast cancer disease[J].Applied Soft Computing,2017,62:536-549.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" He H,Garcia E A.Learning from imbalanced data[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2009,21(9):1263-1284." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning from Imbalanced Data">
                                        <b>[4]</b>
                                         He H,Garcia E A.Learning from imbalanced data[J].IEEE Transactions on Knowledge &amp;amp; Data Engineering,2009,21(9):1263-1284.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Huang Zai-xiang,Zhou Zhong-mei,He Tian-zhong,et al.Improved associative classification algorithm for multiclass unbalanced datasets [J].Pattern Recognition and Artificial Intelligence,2015,28(10):922-929.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201510007&amp;v=MzA3MTZVcnZLS0Q3WWJMRzRIOVROcjQ5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2c=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Huang Zai-xiang,Zhou Zhong-mei,He Tian-zhong,et al.Improved associative classification algorithm for multiclass unbalanced datasets [J].Pattern Recognition and Artificial Intelligence,2015,28(10):922-929.(in Chinese)
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Thabtah F.A review of associative classification mining[J].Knowledge Engineering Review,2017,22(1):37-65." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A review of associative classification mining">
                                        <b>[6]</b>
                                         Thabtah F.A review of associative classification mining[J].Knowledge Engineering Review,2017,22(1):37-65.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Du Wen-liang,Zhan Zhi-jun.Building decision tree classifier on private data[C]//Proc of IEEE International Conference on Data Mining Workshop on Privacy,Security,and Data Mining,2002:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Building Decision Tree Classifier on Private Data">
                                        <b>[7]</b>
                                         Du Wen-liang,Zhan Zhi-jun.Building decision tree classifier on private data[C]//Proc of IEEE International Conference on Data Mining Workshop on Privacy,Security,and Data Mining,2002:1-8.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Quinlan J R,Cameron-Jones R M.FOIL:A midterm report[M]//Machine Learning:ECML-93.Berlin:Springer Berlin Heidelberg,1993:1-20." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=FOIL: A Midterm Report">
                                        <b>[8]</b>
                                         Quinlan J R,Cameron-Jones R M.FOIL:A midterm report[M]//Machine Learning:ECML-93.Berlin:Springer Berlin Heidelberg,1993:1-20.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Liu B,Hsu W,Ma Y.Integrating classification and association rule mining[C]//Proc of International Conference on Knowledge Discovery and Data Mining,1998:80-86." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Integrating classification and association rule mining?">
                                        <b>[9]</b>
                                         Liu B,Hsu W,Ma Y.Integrating classification and association rule mining[C]//Proc of International Conference on Knowledge Discovery and Data Mining,1998:80-86.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Li Wen-min,Han Jia-wei,Pei Jian.CMAR:Accurate and efficient classification based on multiple class-association rules[C]//Proc of the 2001 IEEE International Conference on Data Mining,2001:369-376." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CMAR: Accurate and efficient classification based on multiple class-association rules">
                                        <b>[10]</b>
                                         Li Wen-min,Han Jia-wei,Pei Jian.CMAR:Accurate and efficient classification based on multiple class-association rules[C]//Proc of the 2001 IEEE International Conference on Data Mining,2001:369-376.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Yin Xiao-xin,Han Jia-wei.CPAR:Classification based on predictive association rules[C]//Proc of the 2003 SIAM International Conference on Data Mining,2003:236-255." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CPAR:classification based on predictive association rules">
                                        <b>[11]</b>
                                         Yin Xiao-xin,Han Jia-wei.CPAR:Classification based on predictive association rules[C]//Proc of the 2003 SIAM International Conference on Data Mining,2003:236-255.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Hadi W,Aburub F,Alhawari S.A new fast associative classification algorithm for detecting phishing websites[M].Amsterdam:Elsevier Science Publishers,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new fast associative classification algorithm for detecting phishing websites">
                                        <b>[12]</b>
                                         Hadi W,Aburub F,Alhawari S.A new fast associative classification algorithm for detecting phishing websites[M].Amsterdam:Elsevier Science Publishers,2016.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Hadi W,Issa G,Ishtaiwi A.ACPRISM:Associative classification based on PRISM algorithm[J].Information Sciences,2017,417:287-300." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES60B6B60F0D39EFD89FB6267980996F50&amp;v=Mjg0MzU0Yk5lK3FZOHpaSjhNQlFsUHV4NGFuRTE3U25ubHBSbzFjTHVTTTcrZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3Mit4S289TmlmT2ZiVw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Hadi W,Issa G,Ishtaiwi A.ACPRISM:Associative classification based on PRISM algorithm[J].Information Sciences,2017,417:287-300.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     Arunasalam B,Chawla S.CCCS:A top-down associative classifier for imbalanced class distribution[C]//Proc of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2006:517-522.附中文参考文献:</a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     黄再祥,周忠眉,何田中,等.改进的多类不平衡数据关联分类算法[J].模式识别与人工智能,2015,28(10):922-929.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(11),2088-2094 DOI:10.3969/j.issn.1007-130X.2019.11.025            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于各类支持度阈值独立挖掘的关联改进算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E5%BF%A0%E7%9C%89&amp;code=33195141&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周忠眉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%AE%B6%E8%BE%89&amp;code=39993781&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李家辉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%97%BD%E5%8D%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=1698703&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">闽南师范大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E7%A6%8F%E5%BB%BA%E7%9C%81%E9%AB%98%E7%AD%89%E5%AD%A6%E6%A0%A1%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据科学与智能应用福建省高等学校重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>关联分类及较多的改进算法很难同时既具有较高的整体准确率又有较好的小类分类性能。针对此问题,提出了一种基于类支持度阈值独立挖掘的关联分类改进算法—ACCS。ACCS算法的主要特点是:(1)根据训练集中各类数量大小给出每个类类支持度阈值的设定方法,并基于各类的类支持度阈值独立挖掘该类的关联分类规则,尽量使小类生成更多高置信度的规则;(2)采用类支持度对置信度相同的规则排序,提高小类规则的优先级;(3)用综合考虑置信度和提升度的新的规则度量预测未知实例。在多个数据集上的实验结果表明,相比多种关联分类改进算法,ACCS算法有更高的整体分类准确率,且在不平衡数据上也能取得较好的小类分类性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E8%81%94%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关联分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B1%BB%E6%94%AF%E6%8C%81%E5%BA%A6%E9%98%88%E5%80%BC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">类支持度阈值;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B1%BB%E6%94%AF%E6%8C%81%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">类支持度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB%E5%87%86%E7%A1%AE%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类准确率;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    周忠眉(1965-),女,福建漳州人,博士,教授,研究方向为数据挖掘和机器学习。E-mail:zzm@zju.edu.cn,通信地址:363000福建省漳州市闽南师范大学计算机学院科技楼南1116;
                                </span>
                                <span>
                                    李家辉,通信地址:363000福建省漳州市闽南师范大学计算机学院科技楼南1116;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>福建省自然科学基金(2018J01545);</span>
                    </p>
            </div>
                    <h1><b>An associative classification algorithm based on various class-support thresholds and independent mining rules</b></h1>
                    <h2>
                    <span>ZHOU Zhong-mei</span>
                    <span>LI Jia-hui</span>
            </h2>
                    <h2>
                    <span>School of Computer Science,Minnan Normal University</span>
                    <span>Key Laboratory of Data Science and Intelligence Application,Fujian Province University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Associative classification algorithm and its existing improved algorithms cannot achieve both high overall accuracy and good minority class classification. To solve this problem, we propose an improved associative classification algorithm based on various class-support thresholds(ACCS)independent mining rules. Its main featuresare:(1) ACCS sets the support threshold of each class according to the class size in the training data, and extracts the associative classification rule of each class separately based on the class-support threshold in order to get higher confidence rules of minority classes;(2) ACCS uses the class-support threshold to rank the rules with the same confidence for increasing the priority of the minority classes;(3) ACCS combines confidence and lift degrees together to predict unknown instances. The experimental results on multiple datasets show that ACCS can achieve higher overall classification accuracy than the existing associative algorithms, and can also get good minority class classification performance in imbalanced data.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=associative%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">associative classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=class%20support%20threshold&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">class support threshold;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=class%20support&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">class support;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=classification%20accuracy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">classification accuracy;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHOU Zhong-mei,born in 1965,PhD, professor,her research interests include data mining,and machine learning.Address:Room South 1116,Technology Building,School of Computer Science,Minnan Normal University,Zhangzhou 363000,Fujian,P.R.China;
                                </span>
                                <span>
                                    LI Jia-hui,Address:Room South 1116,Technology Building,School of Computer Science,Minnan Normal University,Zhangzhou 363000,Fujian,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-12</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="34">分类是通过对已知训练集进行学习,建立分类器来预测未知实例类标签的一种数据挖掘技术,不平衡数据分类指对类别分布不均衡的训练集进行分类。分类及不平衡分类技术在各领域都有广泛运用<citation id="161" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>,如:癌症诊断、诈骗识别、股票交易等。分类准确率是分类好坏的评价指标,但是在不平衡数据分类中,除整体准确率外,正确分类小类实例也具有非常重要的价值<citation id="162" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">5</a>]</sup></citation>,因此小类分类性能也是不平衡分类的重要评价指标。不平衡分类中对同时兼顾整体准确率和小类准确率的分类器设计是一个巨大的挑战,所以不平衡数据分类的目标之一是提出一个既具有较高的整体分类准确率,同时又具有很好的小类准确率的分类算法。</p>
                </div>
                <div class="p1">
                    <p id="35">Liu等人<citation id="163" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了基于支持度和置信度阈值的关联分类CBA(Classification Based on Association rules)算法。CBA算法虽然具有较高的分类准确率,但是CBA算法没有考虑各类实例在训练集中所占的比例,生成的部分规则置信度不高,特别对多类不平衡数据集,难以生成高置信度的小类规则。又由于在预测新实例时,CBA算法仅采用优先级最高的单条规则,使得小类实例容易被优先级高的大类规则误判,导致在一些数据集上整体准确率和小类准确率都不高。</p>
                </div>
                <div class="p1">
                    <p id="36">为改进CBA算法,提高分类准确率,许多学者进行了大量研究。Li等人<citation id="164" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出了CMAR(Classification Based on Multiple Association Rules) 算法。 与CBA算法不同的是,CMAR算法在判断新实例时选取多条规则,并采用卡方相关性度量进行预测,取得了比CBA算法更高的分类准确率。Yin等人<citation id="165" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了预测关联规则分类CPAR(Classification based on Prediction Association Rules)算法,CPAR算法采用顺序覆盖且一次生成多条规则的方式,并用综合支持度和类支持度的Laplace度量来预测新实例,取得了比CMAR算法更高的分类准确率。Hadi等人<citation id="166" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了快速关联分类FACA(a new Fast Associative Classification Algorithm for detecting phishing websites)算法,该算法使用垂直格式挖掘算法生成关联规则,然后使用数据库覆盖剪枝技术来删除置信度不高的规则,取得了较高的分类准确率。Hadi等人<citation id="167" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>还结合关联分类算法和PRISM算法,提出了ACPRISM(Associative Classification based on PRISMs) 算法。ACPRISM算法使用信息熵选取最好的属性,对该属性的各个值分别构建条件库,并在条件库中选取置信度最高的属性值与其连接生成规则。ACPRISM算法生成的规则不仅长度短且能覆盖全部训练实例,在多个数据集上取得了比CBA算法更高的分类准确率。此外,为改善CBA算法小类分类性能不佳的问题,Arunasalam等人<citation id="168" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出了CCCS(Classification using Complement Class Support)算法。该算法使用补类支持度生成规则,并综合考虑置信度、类支持度及补类支持度进行规则度量,CCCS算法比CBA算法的分类错误率更低。</p>
                </div>
                <div class="p1">
                    <p id="37">以上几种改进算法虽然在一定程度上提高了分类准确率,但大多没有同时兼顾整体分类准确率和小类分类准确率。本文提出了一种基于各类支持度阈值独立挖掘关联分类规则的分类算法ACCS(Associative Classification algorithm based on various Class-Support thresholds and independent mining rules),ACCS算法不仅在多个数据集上相比上述几种算法具有更高的分类准确率,且同时在不平衡数据上具有更好的小类分类性能。本文的主要贡献是:</p>
                </div>
                <div class="p1">
                    <p id="38">(1) 根据各类与最大类之间的实例数量关系给出设定各类类支持度阈值的方法。</p>
                </div>
                <div class="p1">
                    <p id="39">(2) 对每个类根据该类支持度阈值挖掘类频繁项集,生成该类关联规则,尽量使每个类尤其是小类生成更多高置信度的规则。</p>
                </div>
                <div class="p1">
                    <p id="40">(3) 使用类支持度对置信度相同的规则排序,使小类规则在排序时更具有优势。此外,提出了一种新的剪枝策略,以提高生成规则的质量。</p>
                </div>
                <div class="p1">
                    <p id="41">(4) 提出一种综合考虑规则Laplace强度和提升度的规则度量方法,使得小类规则具有更高的规则强度,在预测时不仅具有更好的整体分类准确率且有更好的小类分类性能。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag"><b>2 ACCS与CBA的对比</b></h3>
                <div class="p1">
                    <p id="43">本节首先介绍文中使用的基本定义,然后将ACCS算法与CBA算法在规则生成、规则排序、规则剪枝和新实例预测等方面进行对比,以更清晰地体现ACCS算法的特点。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44"><b>2.1 基本定义</b></h4>
                <div class="p1">
                    <p id="45">关联分类算法通过挖掘形如<i>X</i>→<i>C</i><sub><i>i</i></sub>的关联规则来对未知实例进行分类。给定数据集<i>D</i>,且<i>D</i>={<i>t</i><sub>1</sub>,<i>t</i><sub>2</sub>,…,<i>t</i><sub><i>m</i></sub>},训练集类属性为<i>C</i>,且<i>C</i>={<i>C</i><sub>1</sub>,<i>C</i><sub>2</sub>,…,<i>C</i><sub><i>K</i></sub>}。每条实例<i>t</i><sub><i>i</i></sub>有<i>n</i>个不同的特征属性值和1个类属性值<i>C</i><sub><i>i</i></sub>,<i>X</i>为由若干不同属性值组成的集合。如果实例<i>t</i><sub><i>i</i></sub>⊇<i>X</i>,则称规则<i>X</i>→<i>C</i><sub><i>i</i></sub>匹配实例<i>t</i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="46"><b>定义1</b>(支持度) 项集<i>X</i>的支持度定义如下:</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>δ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>/</mo><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48">其中,<mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><mrow><mo>(</mo><mi>X</mi><mo>)</mo></mrow></mrow></math></mathml>表示项集<i>X</i>在训练集中出现的次数,|<i>D</i>|表示训练集总的实例数。支持度用来度量项集<i>X</i>在训练集中出现的频繁程度。</p>
                </div>
                <div class="p1">
                    <p id="49"><b>定义2</b>(置信度) 规则<i>X</i>→类<i>C</i><sub><i>i</i></sub>置信度定义如下:</p>
                </div>
                <div class="p1">
                    <p id="50" class="code-formula">
                        <mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>o</mi><mi>n</mi><mi>f</mi><mrow><mo>(</mo><mrow><mi>X</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo><mi>S</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mstyle displaystyle="true"><mo>∪</mo><mi>C</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>/</mo><mi>S</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="51">置信度用来确定在包含项集<i>X</i>的训练实例中类别<i>C</i><sub><i>i</i></sub>出现的频繁程度。</p>
                </div>
                <div class="p1">
                    <p id="52"><b>定义3</b>(频繁项集) 如果一个项集<i>X</i>的支持度大于或等于支持度阈值,那么<i>X</i>就称为频繁项集。</p>
                </div>
                <div class="p1">
                    <p id="53"><b>定义4</b>(类支持度) 规则<i>X</i>→<i>C</i><sub><i>i</i></sub>在类<i>C</i><sub><i>i</i></sub>的类支持度定义如下:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>L</mi><mi>s</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mrow><mi>X</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo><mi>S</mi><mi>u</mi><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mstyle displaystyle="true"><mo>∪</mo><mi>C</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>/</mo><mi>S</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mrow><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="55">由式(3)得知,如果类<i>C</i><sub><i>i</i></sub>的实例较少,则规则<i>X</i>→<i>C</i><sub><i>i</i></sub>的类支持度有可能较高。</p>
                </div>
                <div class="p1">
                    <p id="56"><b>定义5</b>(类频繁项集) 如果一个项集<i>X</i>在类<i>C</i><sub><i>i</i></sub>的类支持度大于或等于<i>C</i><sub><i>i</i></sub>的类支持度阈值,则称项集<i>X</i>为类<i>C</i><sub><i>i</i></sub>的类频繁项集。</p>
                </div>
                <div class="p1">
                    <p id="57">对训练数据的每个类,用类频繁项集生成到该类的关联分类规则。</p>
                </div>
                <div class="p1">
                    <p id="58"><b>定义6</b>(提升度) 规则的提升度定义如下:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>i</mi><mi>f</mi><mi>t</mi><mo stretchy="false">(</mo><mi>X</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>S</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mrow><mi>X</mi><mstyle displaystyle="true"><mo>∪</mo><mi>C</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>S</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mi>X</mi><mo>)</mo></mrow><mo>×</mo><mi>S</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mrow><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">提升度用于度量频繁项集<i>X</i>和类<i>C</i><sub><i>i</i></sub>的相关程度。如果该规则的提升度大于1,说明项集<i>X</i>和类别<i>C</i><sub><i>i</i></sub>是正相关的,提升度越大,项集<i>X</i>和类<i>C</i><sub><i>i</i></sub>正相关度越大。</p>
                </div>
                <div class="p1">
                    <p id="61"><b>定义7</b>(Laplace规则强度) 规则<i>X</i>→<i>C</i><sub><i>i</i></sub>的Laplace规则强度定义如下:</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>a</mi><mi>p</mi><mi>l</mi><mi>a</mi><mi>c</mi><mi>e</mi><mrow><mo>(</mo><mrow><mi>X</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi>X</mi><mstyle displaystyle="true"><mo>∪</mo><mi>C</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn></mrow><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mi>Κ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">其中,<i>C</i><sub><i>i</i></sub>为当前样本类,<i>K</i>为训练集中类别的个数。Laplace强度越高的规则质量越好。</p>
                </div>
                <div class="p1">
                    <p id="64"><b>定义8</b>(规则强度) 规则<i>X</i>→<i>C</i><sub><i>i</i></sub>的规则强度<i>RS</i>(Rule Strength)定义如下:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>S</mi><mrow><mo>(</mo><mrow><mi>X</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi>X</mi><mstyle displaystyle="true"><mo>∪</mo><mi>C</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn></mrow><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mi>Κ</mi></mrow></mfrac><mo>×</mo><mfrac><mrow><mi>l</mi><mi>i</mi><mi>f</mi><mi>t</mi><mrow><mo>(</mo><mrow><mi>X</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>l</mi><mi>i</mi><mi>f</mi><mi>t</mi><mrow><mo>(</mo><mrow><mi>X</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>+</mo><mn>1</mn></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">式(6)中规则强度综合考虑了Laplace强度和提升度,相比单一使用Laplace度量或置信度,能更好地度量小类规则,使小类规则比大类规则具有更高的优先级。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.2 算法各步骤对比</b></h4>
                <h4 class="anchor-tag" id="68" name="68">2.2.1 规则生成</h4>
                <div class="p1">
                    <p id="69">CBA算法对训练集设定全局支持度阈值,挖掘所有满足支持度阈值的频繁项集,计算每一个频繁项集到各类的置信度,生成满足置信度阈值的规则。ACCS算法对每个类设定该类的类支持度阈值,挖掘该类的类频繁项集,利用类频繁项集生成满足置信度阈值的该类规则。两者的不同之处在于CBA算法用频繁项集生成规则,而ACCS算法对每个类用该类的类频繁项集生成只属于该类的规则。</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70">2.2.2 规则排序</h4>
                <div class="p1">
                    <p id="71">CBA算法首先按照规则的置信度从高到低排序,如果2条规则的置信度相同,则按照支持度大小排序。</p>
                </div>
                <div class="p1">
                    <p id="72">ACCS算法同样先按照规则的置信度排序,但当规则的置信度相同时,则按照规则的类支持度大小排序。因为小类规则可能具有较高的类支持度,由式(4)得知,排序时小类规则可能比大类规则有优势。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">2.2.3 规则剪枝</h4>
                <div class="p1">
                    <p id="74">CBA算法按照泛化规则剪枝。对规则集中形如<i>X</i>→<i>C</i><sub><i>i</i></sub>和<i>XF</i>→<i>C</i><sub><i>i</i></sub>2条规则,如果它们的置信度相同,则规则<i>XF</i>→<i>C</i><sub><i>i</i></sub>被剪枝。</p>
                </div>
                <div class="p1">
                    <p id="75">ACCS算法剪枝主要分为如下4步:</p>
                </div>
                <div class="p1">
                    <p id="76"><b>第1步</b> 类似于CBA算法,ACCS算法剪掉规则集中的泛化规则。</p>
                </div>
                <div class="p1">
                    <p id="77"><b>第2步</b> 对规则集中形如<i>X</i>→<i>C</i><sub><i>i</i></sub>和<i>X</i>→<i>C</i><sub><i>j</i></sub>的规则,仅保留置信度高的规则,剪掉置信度较低的规则。</p>
                </div>
                <div class="p1">
                    <p id="78"><b>第3步</b> 计算每一条规则的提升度,剪掉项集与类别负相关的规则。</p>
                </div>
                <div class="p1">
                    <p id="79"><b>第4步</b> ACCS算法采用数据库覆盖的方法对规则集进行剪枝。如果一条规则不能正确预测任何一条匹配的实例的类别,则该规则被剪枝。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80">2.2.4 新实例预测</h4>
                <div class="p1">
                    <p id="81">CBA算法使用最高置信度的单条规则预测未知实例的类别。</p>
                </div>
                <div class="p1">
                    <p id="82">ACCS算法则挑选出匹配到的优先级最高的<i>K</i>条规则,使用文中提出的式(6)中的规则强度计算各类的平均规则强度,选取平均强度最大的类作为新实例的类别。</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag"><b>3 ACCS算法</b></h3>
                <h4 class="anchor-tag" id="84" name="84"><b>3.1 ACCS算法的规则挖掘</b></h4>
                <div class="p1">
                    <p id="85">ACCS算法分3步挖掘关联分类规则。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86">首先,设定各类的类支持度阈值。</h4>
                <div class="p1">
                    <p id="171">我们根据最大类类支持度阈值、各类与最大类之间的实例关系给出计算各类支持度阈值的公式,如式(7)所示:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>m</mi><mi>i</mi><mi>n</mi><mo>_</mo><mi>C</mi><mi>l</mi><mi>s</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mrow><mi>C</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mi>m</mi><mi>i</mi><mi>n</mi><mo>_</mo><mi>C</mi><mi>l</mi><mi>s</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mrow><mi>C</mi><msub><mrow></mrow><mtext>m</mtext></msub></mrow><mo>)</mo></mrow><mo>×</mo><mfrac><mrow><mi>lg</mi><mrow><mo>(</mo><mrow><mi>δ</mi><mrow><mo>(</mo><mrow><mi>C</mi><msub><mrow></mrow><mtext>m</mtext></msub></mrow><mo>)</mo></mrow><mo>/</mo><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow><mo>)</mo></mrow></mrow><mrow><mi>lg</mi><mrow><mo>(</mo><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mo>/</mo><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">从训练集中选取实例数目最大的类并记为<i>C</i><sub>m</sub>,给定<i>C</i><sub>m</sub>类的类支持度阈值为<mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mo>_</mo><mi>C</mi><mi>l</mi><mi>s</mi><mi>u</mi><mi>p</mi><mrow><mo>(</mo><mrow><mi>C</mi><msub><mrow></mrow><mtext>m</mtext></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>,ACCS算法按照式(7)计算各类的类支持度阈值。例如,假设训练集中有100条实例,其中最大类<i>C</i><sub>1</sub>有实例50条,类<i>C</i><sub>2</sub>有实例20条,类<i>C</i><sub>3</sub>有实例10条。给定<i>C</i><sub>1</sub>的类支持度阈值为0.2,通过式(7)得到<i>C</i><sub>2</sub>的类支持度阈值为0.08,<i>C</i><sub>3</sub>的类支持度阈值为0.066。从这个例子可以看出,类<i>C</i><sub>2</sub>与类<i>C</i><sub>3</sub>的类支持度阈值均比类<i>C</i><sub>1</sub>的类支持度阈值小得多。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89">其次,独立挖掘各类的关联分类规则。</h4>
                <div class="p1">
                    <p id="90">对每个类,根据该类的类支持度阈值挖掘该类的类频繁项集,并生成满足置信度阈值的该类规则。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91">第三,合并、排序、剪枝形成规则集。</h4>
                <div class="p1">
                    <p id="92">ACCS算法最后合并所有类的规则,并排序、剪枝形成最终的规则集。</p>
                </div>
                <div class="p1">
                    <p id="93">下面举例说明ACCS算法能挖掘更多小类的高置信度小类规则。</p>
                </div>
                <div class="p1">
                    <p id="94">假设训练集有3个类,共包含1 000条数据,其中类<i>C</i><sub>1</sub>有500条实例,类<i>C</i><sub>2</sub>有494条实例,类<i>C</i><sub>3</sub>只有6条实例。项集<mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mi>k</mi><mo>}</mo></mrow></mrow></math></mathml>和<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>b</mi><mo>,</mo><mi>e</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>只在类<i>C</i><sub>3</sub>的实例中出现,覆盖的实例分别有4条和2条。训练集如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="95">假设置信度阈值为0.8,最大类的类支持度阈值为0.25。由ACCS算法得出类<i>C</i><sub>3</sub>的类支持度阈值为0.03,项集<mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mi>k</mi><mo>}</mo></mrow></mrow></math></mathml>和<mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>b</mi><mo>,</mo><mi>e</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>为类<i>C</i><sub>3</sub>的类频繁项集,且项集<mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mi>k</mi><mo>}</mo></mrow></mrow></math></mathml>和<mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>b</mi><mo>,</mo><mi>e</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>到类<i>C</i><sub>3</sub>置信度为1。因此,ACCS算法能生成<mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi>k</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>和<mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi>b</mi><mo>,</mo><mi>e</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>2条小类<i>C</i><sub>3</sub>的分类规则。对CBA算法,假设全局支持度阈值为0.01,置信度阈值同样为0.8。由于项集<mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mi>k</mi><mo>}</mo></mrow></mrow></math></mathml>和<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>b</mi><mo>,</mo><mi>e</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>都不是训练集中的频繁项集,因此CBA算法无法生成<mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi>k</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>和<mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi>b</mi><mo>,</mo><mi>e</mi><mo>→</mo><mi>C</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>这2条小类<i>C</i><sub>3</sub>中的规则。上述例子也说明了各类独立挖掘关联分类规则的必要性。</p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表1 训练数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Training data</b></p>
                    <p class="img_note"></p>
                    <table id="96" border="1"><tr><td><br /><i>ID</i></td><td>属性1</td><td>属性2</td><td>属性3</td><td>类别</td></tr><tr><td><br />1</td><td><i>a</i></td><td><i>e</i></td><td><i>f</i></td><td><i>C</i><sub>1</sub></td></tr><tr><td><br />2</td><td><i>a</i></td><td><i>e</i></td><td><i>g</i></td><td><i>C</i><sub>2</sub></td></tr><tr><td><br />3</td><td><i>a</i></td><td><i>e</i></td><td><i>h</i></td><td><i>C</i><sub>2</sub></td></tr><tr><td><br />4</td><td><i>b</i></td><td><i>d</i></td><td><i>g</i></td><td><i>C</i><sub>1</sub></td></tr><tr><td><br />︙</td><td>︙</td><td>︙</td><td>︙</td><td>︙</td></tr><tr><td><br />995</td><td><i>k</i></td><td><i>e</i></td><td><i>f</i></td><td><i>C</i><sub>3</sub></td></tr><tr><td><br />996</td><td><i>k</i></td><td><i>e</i></td><td><i>g</i></td><td><i>C</i><sub>3</sub></td></tr><tr><td><br />997</td><td><i>k</i></td><td><i>d</i></td><td><i>h</i></td><td><i>C</i><sub>3</sub></td></tr><tr><td><br />998</td><td><i>k</i></td><td><i>c</i></td><td><i>f</i></td><td><i>C</i><sub>3</sub></td></tr><tr><td><br />999</td><td><i>b</i></td><td><i>e</i></td><td><i>g</i></td><td><i>C</i><sub>3</sub></td></tr><tr><td><br />1 000</td><td><i>b</i></td><td><i>e</i></td><td><i>h</i></td><td><i>C</i><sub>3</sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="97">图1给出ACCS算法从输入训练集到输出规则集的流程图。从图1不仅可以看出各类独立挖掘关联分类规则的过程,而且可以看出从规则生成到规则排序及剪枝的流程。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911026_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 ACCS算法的流程图" src="Detail/GetImg?filename=images/JSJK201911026_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 ACCS算法的流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911026_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Flow chart of ACCS algorithm</p>

                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>3.2 ACCS算法的伪代码</b></h4>
                <div class="p1">
                    <p id="100">ACCS算法包含4大部分:第1部分为设定各类的类支持度阈值;第2部分生成各类的关联分类规则;第3部分对规则进行排序和剪枝;第4部分选取最优的<i>K</i>条规则来预测新实例的类别。ACCS算法伪代码如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="101"><b>算法1</b> ACCS算法</p>
                </div>
                <div class="p1">
                    <p id="102"><b>输入</b>:训练集<i>D</i>,最大类支持度阈值<i>min</i>_<i>Clsup</i>(<i>C</i><sub>m</sub>),置信度<i>conf</i>,提升度<i>lift</i>,测试实例<i>M</i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="103"><b>输出</b>:规则集<i>R</i>,新实例的预测结果。</p>
                </div>
                <div class="p1">
                    <p id="104">1. <i>R</i>=Ø;/*初始规则集<i>R</i>为空*/</p>
                </div>
                <div class="p1">
                    <p id="105">2. For(<i>i</i>=0;<i>i</i>&lt;<i>n</i>;<i>i</i>++) do{</p>
                </div>
                <div class="p1">
                    <p id="106">3.  <i>N</i><sub><i>i</i></sub>=<i>Calculate</i>(<i>D</i><sub><i>i</i></sub>);//计算各类实例数</p>
                </div>
                <div class="p1">
                    <p id="107">4.  <i>Get</i>(<i>N</i><sub>m</sub>);//选出实例数最多类</p>
                </div>
                <div class="p1">
                    <p id="108">5.  <i>min</i>_<i>Clsup</i>(<i>C</i><sub>m</sub>)= <i>insert</i>(<i>C</i><sub>m</sub>);}/*设置最大类的类支持度阈值 */</p>
                </div>
                <div class="p1">
                    <p id="109">6. For(<i>j</i>=0;<i>j</i>&lt;<i>n</i>;<i>j</i>++) do{</p>
                </div>
                <div class="p1">
                    <p id="110">7.  <i>D</i><sub><i>j</i></sub>=<i>extract</i>(<i>D</i>,<i>C</i><sub><i>j</i></sub>);//按类别抽取实例</p>
                </div>
                <div class="p1">
                    <p id="111">8.  <i>min</i>_<i>Clsup</i>(<i>C</i><sub><i>j</i></sub>)=<i>Cal</i>(<i>min</i>_<i>Clsup</i>(<i>C</i><sub>m</sub>),<i>C</i><sub><i>j</i></sub>);/*计算各类的类支持度阈值*/</p>
                </div>
                <div class="p1">
                    <p id="112">9.  <i>L</i><sub><i>j</i></sub>=<i>classfrequent</i>(<i>D</i><sub><i>j</i></sub>,<i>min</i>_<i>Clsup</i>(<i>C</i><sub><i>j</i></sub>));/*根据类支持度阈值生成该类的类频繁项集*/</p>
                </div>
                <div class="p1">
                    <p id="113">10. <i>R</i><sub><i>j</i></sub>=<i>generaterules</i>(<i>L</i><sub><i>j</i></sub>,<i>conf</i>);/*根据置信度生成该类规则*/</p>
                </div>
                <div class="p1">
                    <p id="114">11. <i>R</i> = <i>R</i><sub>1</sub>∪<i>R</i><sub>2</sub>∪<i>R</i><sub>3</sub>∪…∪<i>R</i><sub><i>j</i></sub>}//合并所有规则</p>
                </div>
                <div class="p1">
                    <p id="115">12.<i>sort</i> (<i>R</i>);//对规则集<i>R</i>排序</p>
                </div>
                <div class="p1">
                    <p id="116">13.<i>purn</i> (<i>R</i>,<i>lift</i>);//对规则集剪枝</p>
                </div>
                <div class="p1">
                    <p id="117">14.<i>T</i>=<i>selectrule</i>(<i>R</i>,<i>M</i><sub><i>i</i></sub>,<i>K</i>)/*挑选与新实例匹配的<i>K</i>条规则*/</p>
                </div>
                <div class="p1">
                    <p id="118">15.If(<i>T</i>==Ø)</p>
                </div>
                <div class="p1">
                    <p id="119">16. <i>M</i><sub><i>i</i></sub> = <i>C</i><sub><i>j</i></sub>;//给新实例赋予默认的类标签</p>
                </div>
                <div class="p1">
                    <p id="120">17.else{</p>
                </div>
                <div class="p1">
                    <p id="121">18. For(<i>j</i>=0;<i>j</i>&lt;<i>n</i>;<i>j</i>++) do{</p>
                </div>
                <div class="p1">
                    <p id="122">19.  <i>T</i><sub><i>j</i></sub>=<i>Groupeverger</i>(<i>T</i>);//对规则按类分组</p>
                </div>
                <div class="p1">
                    <p id="123">20.  <i>S</i><sub><i>j</i></sub>=<i>score</i>(<i>T</i><sub><i>j</i></sub>)}//计算各类平均规则强度</p>
                </div>
                <div class="p1">
                    <p id="124">21. <i>C</i><sub><i>i</i></sub> = <i>M</i><sub><i>j</i></sub> }//给新实例赋予类标签</p>
                </div>
                <div class="p1">
                    <p id="125">第3～5行是扫描数据集,统计出每个类中实例的个数,给实例数目最多的类设定类支持度阈值;第6～8行是计算各类的类支持度阈值;第9～10行是对训练集各类挖掘类频繁项集,生成该类规则;第11～13行是合并所有类的规则,对规则排序、剪枝生成最终的规则集;第14行是选取最优的<i>K</i>条规则;第15～21行是计算各类规则的平均强度,赋予新实例规则平均强度最大的类。</p>
                </div>
                <h3 id="126" name="126" class="anchor-tag"><b>4 实验设计与实验结果</b></h3>
                <h4 class="anchor-tag" id="127" name="127"><b>4.1 实验设计</b></h4>
                <div class="p1">
                    <p id="128">实验选取了如表2所示的15个UCI数据集,从表2中可以看出每个数据集所包含的样本总个数、类别数、属性数目。所有实验都在Microsoft 64 位Windows 10系统和Java 8.0环境下进行,对每个数据集实验均采用10折交叉验证方法。</p>
                </div>
                <div class="p1">
                    <p id="129">本次实验采用6个分类评价指标,分别是分类准确率、查全率、查准率、<i>G</i>-<i>mean</i>、<i>F</i>-<i>score</i>和分类错误率。</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>4.2 实验结果与分析</b></h4>
                <div class="p1">
                    <p id="131">本文做3方面的实验比较。首先,ACCS算法在15个数据集上与其他6个算法比较整体分类准确率,并在7个数据集上与CCCS算法和CBA算法比较分类错误率;其次,ACCS算法与CBA算法比较小类分类性能;第三,ACCS算法在5个数据集上给出最大类支持度阈值的设定对分类准确率的影响。</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表2 实验所用的UCI数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 UCI Data sets used in the experiment</b></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><br />数据集</td><td>属性数目</td><td>类别</td><td>实例数</td></tr><tr><td><br />Austral</td><td>14</td><td>2</td><td>690</td></tr><tr><td><br />breast</td><td>10</td><td>2</td><td>699</td></tr><tr><td><br />cleve</td><td>13</td><td>2</td><td>303</td></tr><tr><td><br />diabetes</td><td>8</td><td>2</td><td>768</td></tr><tr><td><br />heart</td><td>13</td><td>2</td><td>270</td></tr><tr><td><br />pima</td><td>8</td><td>2</td><td>768</td></tr><tr><td><br />labor</td><td>16</td><td>2</td><td>57</td></tr><tr><td><br />Iris</td><td>4</td><td>3</td><td>150</td></tr><tr><td><br />horse</td><td>22</td><td>2</td><td>368</td></tr><tr><td><br />glass</td><td>9</td><td>7</td><td>214</td></tr><tr><td><br />german</td><td>20</td><td>2</td><td>1 000</td></tr><tr><td><br />wine</td><td>13</td><td>3</td><td>178</td></tr><tr><td><br />Led7</td><td>7</td><td>10</td><td>3 200</td></tr><tr><td><br />vehicle</td><td>18</td><td>4</td><td>846</td></tr><tr><td><br />zoo</td><td>16</td><td>7</td><td>101</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="133" name="133">4.2.1 ACCS算法的整体分类性能</h4>
                <div class="p1">
                    <p id="134">表3显示了ACCS算法与其它算法的分类准确率的对比,表3中所有其它算法的分类准确率均来自参考文献。在ACCS算法中,设定置信度阈值为0.85,最大类的类支持度阈值为0.10,提升度的阈值为1.0。从表3可以看出,虽然实验只在15个数据集上进行,ACCS算法在10个数据集上分类准确率高于对比算法的,同时ACCS算法较其他算法一致取得了最高的平均分类准确率。</p>
                </div>
                <div class="area_img" id="136">
                    <p class="img_tit"><b>表3 ACCS算法与6种算法的准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Comparison of accuracy among ACCS algorithm and the other 6 algorithms</b></p>
                    <p class="img_note"></p>
                    <table id="136" border="1"><tr><td><br />数据集</td><td>C4.5</td><td>CBA</td><td>CMAR</td><td>CPAR</td><td>FACA</td><td>ACPRISM</td><td>ACCS</td></tr><tr><td><br />Austral</td><td>0.847</td><td>0.849</td><td>0.861</td><td>0.862</td><td>0.859 6</td><td>0.872 5</td><td><b>0.876 2</b></td></tr><tr><td><br />breast</td><td>0.950</td><td>0.963</td><td>0.964</td><td>0.960</td><td>0.957 3</td><td>0.955 0</td><td>0.935 6</td></tr><tr><td><br />cleve</td><td>0.782</td><td>0.828</td><td>0.822</td><td>0.815</td><td>0.814 6</td><td>0.818 2</td><td><b>0.841 5</b></td></tr><tr><td><br />diabetes</td><td>0.742</td><td>0.745</td><td>0.758</td><td>0.751</td><td>0.776 9</td><td>0.786 1</td><td>0.783 9</td></tr><tr><td><br />heart</td><td>0.818</td><td>0.819</td><td>0.822</td><td>0.826</td><td>—</td><td>—</td><td><b>0.829 0</b></td></tr><tr><td><br />pima</td><td>0.755</td><td>0.729</td><td>0.751</td><td>0.738</td><td>—</td><td>—</td><td><b>0.783 5</b></td></tr><tr><td><br />labor</td><td>0.793</td><td>0.863</td><td>0.897</td><td>0.847</td><td>—</td><td>—</td><td>0.863 3</td></tr><tr><td><br />Iris</td><td>0.946</td><td>0.940</td><td>0.947</td><td>0.940</td><td>0.929 4</td><td>0.920 0</td><td><b>0.997 3</b></td></tr><tr><td><br />horse</td><td>0.826</td><td>0.821</td><td>0.826</td><td>0.842</td><td>—</td><td>—</td><td>0.839 6</td></tr><tr><td><br />glass</td><td>0.687</td><td>0.739</td><td>0.701</td><td>0.744</td><td>0.752 4</td><td>0.654 2</td><td><b>0.845 7</b></td></tr><tr><td><br />german</td><td>0.723</td><td>0.734</td><td>0.749</td><td>0.734</td><td>—</td><td>—</td><td>0.742 1</td></tr><tr><td><br />wine</td><td>0.927</td><td>0.95</td><td>0.950</td><td>0.955</td><td>—</td><td>—</td><td><b>0.971 9</b></td></tr><tr><td><br />Led7</td><td>0.735</td><td>0.719</td><td>0.725</td><td>0.736</td><td>0.719 0</td><td>0.750 0</td><td><b>0.757 7</b></td></tr><tr><td><br />vehicle</td><td>0.726</td><td>0.687</td><td>0.688</td><td>0.695</td><td>—</td><td>—</td><td><b>0.770 9</b></td></tr><tr><td><br />zoo</td><td>0.922</td><td>0.968</td><td>0.971</td><td>0.951</td><td>0.959 6</td><td>0.804 9</td><td><b>0.980 2</b></td></tr><tr><td><br />平均值</td><td>0.811 9</td><td>0.823 6</td><td>0.828 8</td><td>0.826 4</td><td>0.846 1</td><td>0.820 1</td><td><b>0.854 5</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="135">表4显示了ACCS算法与CBA算法和CCCS算法在7个数据集上的分类错误率的对比。ACCS算法参数设置同表3,CBA算法和CCCS算法的分类错误率来自参考文献。从表4可以看出,ACCS算法平均分类错误率均低于CBA算法和CCCS算法的。</p>
                </div>
                <div class="area_img" id="137">
                    <p class="img_tit"><b>表4 ACCS和CBA、CCCS算法的错误率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Comparison of error rate among ACCS, CCCS, CBA</b></p>
                    <p class="img_note"></p>
                    <table id="137" border="1"><tr><td rowspan="2"><br />数据集</td><td colspan="3"><br />错误率/%</td></tr><tr><td><br />CBA</td><td>CCCS</td><td>ACCS</td></tr><tr><td><br />Austral</td><td>13.40</td><td>14.40</td><td><b>12.38</b></td></tr><tr><td><br />breast</td><td>4.20</td><td>3.10</td><td>6.44</td></tr><tr><td><br />cleve</td><td>16.70</td><td>16.40</td><td><b>15.85</b></td></tr><tr><td><br />diabetes</td><td>25.30</td><td>23.90</td><td><b>21.61</b></td></tr><tr><td><br />heart</td><td>18.50</td><td>18.10</td><td><b>17.10</b></td></tr><tr><td><br />pima</td><td>27.60</td><td>27.90</td><td><b>21.65</b></td></tr><tr><td><br />horse</td><td>18.70</td><td>19.00</td><td><b>16.04</b></td></tr><tr><td><br />平均值</td><td>17.77</td><td>17.54</td><td><b>15.86</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="138" name="138">4.2.2 ACCS算法在不平衡数据集上的小类分类性能</h4>
                <div class="p1">
                    <p id="139">表5显示了ACCS算法和CBA算法在11个数据集上对4种不平衡数据分类评价度量的对比。ACCS算法中各实验参数设置同样同表3。在CBA算法中,全局支持度阈值为0.08,置信度阈值为0.85。由表5可以看出,ACCS算法在4种度量上一致优于CBA算法。此实验结果也说明ACCS算法具有较好的小类分类性能。</p>
                </div>
                <div class="area_img" id="145">
                                            <p class="img_tit">
                                                <b>表5 ACCS算法和CBA算法的4种度量值比较结果</b>
                                                    <br />
                                                <b>Table 5 Comparison of 4 measurements between ACCS algorithm and CBA algorithm</b>
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911026_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JSJK201911026_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911026_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 ACCS算法和CBA算法的4种度量值比较结果" src="Detail/GetImg?filename=images/JSJK201911026_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="140" name="140">4.2.3 ACCS算法最大类的支持度阈值对算法分类性能的影响</h4>
                <div class="p1">
                    <p id="141">图2显示了5个数据集上不同的最大类类支持度阈值对ACCS算法分类准确率的影响。由图2可以得出,当支持度阈值过低时,ACCS算法生成的规则太多,容易造成一些实例被质量不好的规则误判;而当支持度阈值过高时,规则过少,容易遗漏重要规则。因此,在ACCS算法中,最大类的类支持度阈值过高或过低均易导致分类准确率较低。当最大类的类支持度阈值设置在0.06～0.1时,算法具有相对高的分类准确率。</p>
                </div>
                <div class="area_img" id="142">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911026_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同最大类类支持度阈值下的准确率比较" src="Detail/GetImg?filename=images/JSJK201911026_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同最大类类支持度阈值下的准确率比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911026_142.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Accuracy comparison with different maximum class support thresholds</p>

                </div>
                <h3 id="143" name="143" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="144">基于全局支持度阈值的关联分类算法难以生成小类的频繁项集,更难以生成高置信度的小类规则,且许多关联分类的改进算法也很难同时兼顾整体准确率和小类分类性能。本文提出基于各类支持度阈值独立挖掘规则的关联改进算法ACCS。ACCS算法对每个类设定不同的类支持度阈值,单独挖掘各类的分类规则,能生成更多高置信度的小类规则。此外,算法采用更加合理的规则排序方法及规则强度度量。实验结果表明,ACCS算法不仅具有较好的整体分类准确率且同时具有较好的小类分类性能。下一步工作可考虑结合特征选择技术,在减少规则数量的同时提高分类准确率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="174" type="formula" href="images/JSJK201911026_17400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">周忠眉</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification of imbalanced data: A review">

                                <b>[1]</b> Sun Y,Wong A K C,Kamel M S.Classification of imbalanced data:A review[J].International Journal of Pattern Recognition and Artificial Intelligence,2009,23(4):687-719.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000085394&amp;v=MDM2NDJkR2VycVFUTW53WmVadUh5am1VTGZJSjFzVmJoQT1OaWZJWTdLN0h0ak5yNDlGWk9NS0QzVTlvQk1UNlQ0UFFIL2lyUg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Chawla N V,Japkowicz N,Kotcz A.Editorial:Special issue on learning from imbalanced data sets[J].ACM SIGKDD Explorations Newsletter,2004,6(1):1-6.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA580F32BB35BD95DA123C0F03EEE1FD9&amp;v=MDE5NzBGQURNZVZNODZXQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJodzcyK3hLbz1OaWZPZmNLOUZ0RzZySTAzRnVnS2ZnZ3d5bUppNnoxK08zK1VyQg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Alwidian J,Hammo B H,Obeid N.WCBA:Weighted classification based on association rules algorithm for breast cancer disease[J].Applied Soft Computing,2017,62:536-549.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning from Imbalanced Data">

                                <b>[4]</b> He H,Garcia E A.Learning from imbalanced data[J].IEEE Transactions on Knowledge &amp; Data Engineering,2009,21(9):1263-1284.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201510007&amp;v=MTA3MzVnVXJ2S0tEN1liTEc0SDlUTnI0OUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Huang Zai-xiang,Zhou Zhong-mei,He Tian-zhong,et al.Improved associative classification algorithm for multiclass unbalanced datasets [J].Pattern Recognition and Artificial Intelligence,2015,28(10):922-929.(in Chinese)
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A review of associative classification mining">

                                <b>[6]</b> Thabtah F.A review of associative classification mining[J].Knowledge Engineering Review,2017,22(1):37-65.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Building Decision Tree Classifier on Private Data">

                                <b>[7]</b> Du Wen-liang,Zhan Zhi-jun.Building decision tree classifier on private data[C]//Proc of IEEE International Conference on Data Mining Workshop on Privacy,Security,and Data Mining,2002:1-8.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=FOIL: A Midterm Report">

                                <b>[8]</b> Quinlan J R,Cameron-Jones R M.FOIL:A midterm report[M]//Machine Learning:ECML-93.Berlin:Springer Berlin Heidelberg,1993:1-20.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Integrating classification and association rule mining?">

                                <b>[9]</b> Liu B,Hsu W,Ma Y.Integrating classification and association rule mining[C]//Proc of International Conference on Knowledge Discovery and Data Mining,1998:80-86.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CMAR: Accurate and efficient classification based on multiple class-association rules">

                                <b>[10]</b> Li Wen-min,Han Jia-wei,Pei Jian.CMAR:Accurate and efficient classification based on multiple class-association rules[C]//Proc of the 2001 IEEE International Conference on Data Mining,2001:369-376.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CPAR:classification based on predictive association rules">

                                <b>[11]</b> Yin Xiao-xin,Han Jia-wei.CPAR:Classification based on predictive association rules[C]//Proc of the 2003 SIAM International Conference on Data Mining,2003:236-255.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new fast associative classification algorithm for detecting phishing websites">

                                <b>[12]</b> Hadi W,Aburub F,Alhawari S.A new fast associative classification algorithm for detecting phishing websites[M].Amsterdam:Elsevier Science Publishers,2016.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES60B6B60F0D39EFD89FB6267980996F50&amp;v=MDc0MTVXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3Mit4S289TmlmT2ZiVzRiTmUrcVk4elpKOE1CUWxQdXg0YW5FMTdTbm5scFJvMWNMdVNNNytmQ09OdkZTaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Hadi W,Issa G,Ishtaiwi A.ACPRISM:Associative classification based on PRISM algorithm[J].Information Sciences,2017,417:287-300.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 Arunasalam B,Chawla S.CCCS:A top-down associative classifier for imbalanced class distribution[C]//Proc of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2006:517-522.附中文参考文献:
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 黄再祥,周忠眉,何田中,等.改进的多类不平衡数据关联分类算法[J].模式识别与人工智能,2015,28(10):922-929.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201911026" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911026&amp;v=MDc5ODViRzRIOWpOcm85SFlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVcnZLTHo3Qlo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
