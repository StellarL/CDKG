<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132340907373750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJK201911014%26RESULT%3d1%26SIGN%3dS5Gi4UhdIniYVL8YnmVskDZ5R2o%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911014&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911014&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911014&amp;v=MTI1NjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L25WcnZKTHo3QlpiRzRIOWpOcm85RVlJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#75" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#81" data-title="&lt;b&gt;2 MA检测方法&lt;/b&gt; "><b>2 MA检测方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#83" data-title="&lt;b&gt;2.1 预处理&lt;/b&gt;"><b>2.1 预处理</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;2.2 稀疏自编码器&lt;/b&gt;"><b>2.2 稀疏自编码器</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;2.3 基于SAE的MA检测&lt;/b&gt;"><b>2.3 基于SAE的MA检测</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#110" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#122" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="图1 彩色眼底图像中的MA">图1 彩色眼底图像中的MA</a></li>
                                                <li><a href="#87" data-title="图2 眼底图像对比度增强结果">图2 眼底图像对比度增强结果</a></li>
                                                <li><a href="#92" data-title="图3 SAE模型">图3 SAE模型</a></li>
                                                <li><a href="#109" data-title="图4 检测模型的框架">图4 检测模型的框架</a></li>
                                                <li><a href="#113" data-title="图5 &lt;i&gt;MA&lt;/i&gt;的正检结果">图5 <i>MA</i>的正检结果</a></li>
                                                <li><a href="#114" data-title="图6 误检为&lt;i&gt;MA&lt;/i&gt;的背景噪声点与血管交叉点">图6 误检为<i>MA</i>的背景噪声点与血管交叉点</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表1 已有方法在DIARETDB1数据库上的准确率比较&lt;/b&gt;"><b>表1 已有方法在DIARETDB1数据库上的准确率比较</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;表2 已有方法在公共数据库上的灵敏度比较&lt;/b&gt;"><b>表2 已有方法在公共数据库上的灵敏度比较</b></a></li>
                                                <li><a href="#121" data-title="图7 &lt;i&gt;F&lt;/i&gt;-&lt;i&gt;ROC&lt;/i&gt;曲线">图7 <i>F</i>-<i>ROC</i>曲线</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Yau J W Y,Rogers S,Kawasaki R,et al.Global prevalence and major risk factors of diabetic retinopathy[J].Diabetes Care,2012,35(3):556-564." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00005104585&amp;v=MjA0ODNhYXJPNEh0SEpybzlCWWVNS1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNEbFZMM05KRjg9Tmoz&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Yau J W Y,Rogers S,Kawasaki R,et al.Global prevalence and major risk factors of diabetic retinopathy[J].Diabetes Care,2012,35(3):556-564.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Harris S B,Tompkins J W,Tehiwi B,et al.Call to action:A new path for improving diabetes care for indigenous peoples,a global review[J].Diabetes Research and Clinical Practice,2017,123:120-133." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDBAC675C997F76FD38AD03AFACA2F8B0&amp;v=MTg0MzFKU0h5VDJtTkdDTERpVGNpZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3cTZ4S2s9TmlmT2ZjZktiNkxLcUlvMmJlSUllbnMvdVdJUTRrNA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Harris S B,Tompkins J W,Tehiwi B,et al.Call to action:A new path for improving diabetes care for indigenous peoples,a global review[J].Diabetes Research and Clinical Practice,2017,123:120-133.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Porta M,Bandello F.Diabetic retinopathy[J].Diabetologia,2002,45(12):1617-1634." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001997066&amp;v=MTY3MDROajdCYXJPNEh0SE5wb1pDWk8wSlkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNEbFZMM05KRjg9&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Porta M,Bandello F.Diabetic retinopathy[J].Diabetologia,2002,45(12):1617-1634.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Lazar I,Hajdu A.Microaneurysm detection in retinal images using a rotating cross-section based model[C]//IEEE International Symposium on Biomedical Imaging,2011:1405-1409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Microaneurysm detection in retinal images using a rotating cross-section based model">
                                        <b>[4]</b>
                                         Lazar I,Hajdu A.Microaneurysm detection in retinal images using a rotating cross-section based model[C]//IEEE International Symposium on Biomedical Imaging,2011:1405-1409.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Lazar I,Hajdu A.Retinal microaneurysm detection through local rotating cross-section profile analysis[J].IEEE Transactions on Medical Imaging,2013,32(2):400-407." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Retinal microaneurysm detection through local rotating cross-section profile analysis">
                                        <b>[5]</b>
                                         Lazar I,Hajdu A.Retinal microaneurysm detection through local rotating cross-section profile analysis[J].IEEE Transactions on Medical Imaging,2013,32(2):400-407.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Wu B,Zhu W,Shi F,et al.Automatic detection of microaneurysm in retinal fundus images[J].Computerized Medical Imaging and Graphics,2016,55:106-112." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3DC3B4F39EC27D7DB264D24427FB4083&amp;v=MjEyMDJDUVJiS2NDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3N3E2eEtrPU5pZk9mYkRNYmRLK3EvbEdiWjU4RG50TnlHSmg2RGw1UEgzbXFCQXlEOA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Wu B,Zhu W,Shi F,et al.Automatic detection of microaneurysm in retinal fundus images[J].Computerized Medical Imaging and Graphics,2016,55:106-112.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Ding S,Ma W.An accurate approach for microaneurysm detection in digital fundus images[C]//Proc of International Conference on Pattern Recognition,2014:1846-1851." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An accurate approach for microaneurysm detection in digital fundus images">
                                        <b>[7]</b>
                                         Ding S,Ma W.An accurate approach for microaneurysm detection in digital fundus images[C]//Proc of International Conference on Pattern Recognition,2014:1846-1851.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Srivastava R,Duan L,Wong D W K,et al.Detecting retinal microaneurysms and hemorrhages with robustness to the presence of blood vessels[J].Computer Methods and Programs in Biomedicine,2016,138:83-91." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE34241A25A5E326EC21752D7F00F587F&amp;v=MDA4NDVab0tlWDg3eVdOZzZENTZUWDJXcTJRMWVjU1JUYjNwQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJodzdxNnhLaz1OaWZPZmNhN0d0UElydjVIWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Srivastava R,Duan L,Wong D W K,et al.Detecting retinal microaneurysms and hemorrhages with robustness to the presence of blood vessels[J].Computer Methods and Programs in Biomedicine,2016,138:83-91.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Akram M U,Khalid S,Khan S A.Identification and classification of microaneurysms for early detection of diabetic retinopathy[J].Pattern Recognition,2013,46(1):107-116." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600107361&amp;v=MjczMjVMZklKMXdSYmhNPU5pZk9mYks4SHRETXFZOUZaZXNJRDNvNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Akram M U,Khalid S,Khan S A.Identification and classification of microaneurysms for early detection of diabetic retinopathy[J].Pattern Recognition,2013,46(1):107-116.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Lazar I,Qureshi R J,Hajdu A.A novel approach for the automatic detection of microaneurysms in retinal images[C]//Proc of 2010 6th International Conference on Emerging Technologies (ICET),2010:193-197." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel approach for the automatic detection of microaneurysms in retinal images">
                                        <b>[10]</b>
                                         Lazar I,Qureshi R J,Hajdu A.A novel approach for the automatic detection of microaneurysms in retinal images[C]//Proc of 2010 6th International Conference on Emerging Technologies (ICET),2010:193-197.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Kamble R,Kokare M.Detection of microaneurysm using local rank transform in color fundus images[C]//Proc of IEEE International Conference on Image Processing (ICIP),2017:4442-4446." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detection of microaneurysm using local rank transform in color fundus images">
                                        <b>[11]</b>
                                         Kamble R,Kokare M.Detection of microaneurysm using local rank transform in color fundus images[C]//Proc of IEEE International Conference on Image Processing (ICIP),2017:4442-4446.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Javidi M,Pourreza H R,Harati A.Vessel segmentation and microaneurysm detection using discriminative dictionary learning and sparse representation[J].Computer Methods and Programs in Biomedicine,2017,139:93-108." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB88EBA648FFAA133A98152D511CE5461&amp;v=MDQyMTRmQ3BiUTM1TkJodzdxNnhLaz1OaWZPZmNHd0ZxUyszb2xCYkoxNWZRMDR6QlZpNHpkOFRYMldxUk0wQ3NlUlFieWVDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Javidi M,Pourreza H R,Harati A.Vessel segmentation and microaneurysm detection using discriminative dictionary learning and sparse representation[J].Computer Methods and Programs in Biomedicine,2017,139:93-108.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Wang S,Tang H L,Turk L I A,et al.Localizing microaneurysms in fundus images through singular spectrum analysis[J].IEEE Transactions on Biomedical Engineering,2016,64(5):600-605." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Localizing microaneurysms in fundus images through singular spectrum analysis">
                                        <b>[13]</b>
                                         Wang S,Tang H L,Turk L I A,et al.Localizing microaneurysms in fundus images through singular spectrum analysis[J].IEEE Transactions on Biomedical Engineering,2016,64(5):600-605.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Eftekheri N,Masoudi M,Pourreza H,et al.Microaneurysm detection in fundus images using a two-step convolutional neural networks[J].arXiv:1710.05191,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Microaneurysm detection in fundus images using a two-step convolutional neural networks">
                                        <b>[14]</b>
                                         Eftekheri N,Masoudi M,Pourreza H,et al.Microaneurysm detection in fundus images using a two-step convolutional neural networks[J].arXiv:1710.05191,2017.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" ChudzikP,Majumdar S,Caliv&#225; F,et al.Microaneurysm detection using fully convolutional neural networks[J].Computer Methods and Programs in Biomedicine,2018,158:185-192." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3A91E698B128054298EA1725A1F63D02&amp;v=MzA0OTRTWE1icWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3N3E2eEtrPU5pZk9mYkRKRjlDNXFZWk5GdW9OQkh3OHl4UWE0a29NU1hqZ3FXTTBENw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         ChudzikP,Majumdar S,Caliv&#225; F,et al.Microaneurysm detection using fully convolutional neural networks[J].Computer Methods and Programs in Biomedicine,2018,158:185-192.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Dai L,Fang R,Li H,et al.Clinical report guided retinal microaneurysm detection with multi-sieving deep learning[J].IEEE Transactions on Medical Imaging,2018,37(5):1149-1165." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clinical report guided retinal microaneurysm detection with multi-sieving deep learning">
                                        <b>[16]</b>
                                         Dai L,Fang R,Li H,et al.Clinical report guided retinal microaneurysm detection with multi-sieving deep learning[J].IEEE Transactions on Medical Imaging,2018,37(5):1149-1165.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Walter T,Massin P,Erginay A,et al.Automatic detection of microaneurysms in color fundus images[J].Medical Image Analysis,2007,11(6):555-566." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300711561&amp;v=MTQzMDVCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUoxd1JiaE09TmlmT2ZiSzdIdEROckk5Rlkrb09DWG80bw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Walter T,Massin P,Erginay A,et al.Automatic detection of microaneurysms in color fundus images[J].Medical Image Analysis,2007,11(6):555-566.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Tan J H,Fujita H,Sivaprasad S,et al.Automated segmentation of exudates,haemorrhages,microaneurysms using single convolutional neural network[J].Information Sciences,2017,420:66-76." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES124B2FE1E6598966DBF5197A46869D0C&amp;v=MjUzMDBOaWZPZmJLNkdxUE8yZnBFRWUwS0JYUXd5UkJubUVsNFNYYmwzUll6Y2JTZE1icnNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQmh3N3E2eEtrPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Tan J H,Fujita H,Sivaprasad S,et al.Automated segmentation of exudates,haemorrhages,microaneurysms using single convolutional neural network[J].Information Sciences,2017,420:66-76.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Tamilarasi M,Duraiswamy K.Automatic detection of microaneurysms using microstructure and wavelet methods[J].Sadhana,2015,40(4):1185-1203." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic detection of microaneurysms using microstructure and wavelet methods">
                                        <b>[19]</b>
                                         Tamilarasi M,Duraiswamy K.Automatic detection of microaneurysms using microstructure and wavelet methods[J].Sadhana,2015,40(4):1185-1203.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Xiao Z,Zhang X,Zhang F,et al.Diabetic retinopathy retinal image enhancement based on gamma correction[J].Journal of Medical Imaging and Health Informatics,2017,7(1):149-154." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJAH&amp;filename=SJAH3FCB74FAC09E4E4D68ED55C784EDC8E0&amp;v=MzA3MTJwYlEzNU5CaHc3cTZ4S2s9TmlmS1pyRE9iYVBMcS9rMEYrc0dlWGhNeTJJVjRrb0pUWHFScXhveERNYm5UYytmQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         Xiao Z,Zhang X,Zhang F,et al.Diabetic retinopathy retinal image enhancement based on gamma correction[J].Journal of Medical Imaging and Health Informatics,2017,7(1):149-154.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" Ng A.Sparse autoencoder[J].CS294A Lecture Notes,2011,72(2011):1-19." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse autoencoder">
                                        <b>[21]</b>
                                         Ng A.Sparse autoencoder[J].CS294A Lecture Notes,2011,72(2011):1-19.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" Xu J,Xiang L,Liu Q,et al.Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images[J].IEEE Transactions on Medical Imaging,2016,35(1):119-130." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked Sparse Autoencoder(SSAE)for Nuclei Detection on Breast Cancer Histopathology images.">
                                        <b>[22]</b>
                                         Xu J,Xiang L,Liu Q,et al.Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images[J].IEEE Transactions on Medical Imaging,2016,35(1):119-130.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" Morales J L,Nocedal J.Remark on“Algorithm 778:L-BFGS-B:Fortran subroutines for large-scale bound constrained optimization”[J].Transactions on Mathematical Software,2011,38(1):1-4." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001054&amp;v=MDc1NTd0ak5yNDlGWk9zT0RIazlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKMXdSYmhNPU5pZklZN0s3SA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         Morales J L,Nocedal J.Remark on“Algorithm 778:L-BFGS-B:Fortran subroutines for large-scale bound constrained optimization”[J].Transactions on Mathematical Software,2011,38(1):1-4.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" Zheng W,Bo P,Liu Y,et al.Fast B-spline curve fitting by L-BFGS[J].Computer Aided Geometric Design,2012,29(7):448-462." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300418080&amp;v=MTg3MjJRNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUoxd1JiaE09TmlmT2ZiSzdIdERPckk5RllPb0hESA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         Zheng W,Bo P,Liu Y,et al.Fast B-spline curve fitting by L-BFGS[J].Computer Aided Geometric Design,2012,29(7):448-462.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" Quellec G,Lamard M,Josselin P M,et al.Optimal wavelet transform for the detection of microaneurysms in retina photographs[J].IEEE Transactions on Medical Imaging,2008,27(9):1230-1241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimal wavelet transform for the detection of microaneurysms in retina photographs">
                                        <b>[25]</b>
                                         Quellec G,Lamard M,Josselin P M,et al.Optimal wavelet transform for the detection of microaneurysms in retina photographs[J].IEEE Transactions on Medical Imaging,2008,27(9):1230-1241.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" Mizutani A,Muramatsu C,Hatanaka Y,et al.Automated microaneurysm detection method based on double ring filter in retinal fundus images[C]//Proc of IEEE International Symposium on Computer-Based Medical Systems (CBMS),2012:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automated microaneurysm detection method based on double ring filter in retinal fundus images">
                                        <b>[26]</b>
                                         Mizutani A,Muramatsu C,Hatanaka Y,et al.Automated microaneurysm detection method based on double ring filter in retinal fundus images[C]//Proc of IEEE International Symposium on Computer-Based Medical Systems (CBMS),2012:1-4.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title=" Aravind C,Ponnibala M,Vijayachitra S.Automatic de-tection of microaneurysms and classification of diabetic retinopathy images using SVM technique[C]//Proc of International Conference on Innovations in Intelligent Instrumentation,Optimization and Electrical Sciences,2013:18-22." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic detection of microaneurysms and classification of diabetic retinopathy images using SVM technique">
                                        <b>[27]</b>
                                         Aravind C,Ponnibala M,Vijayachitra S.Automatic de-tection of microaneurysms and classification of diabetic retinopathy images using SVM technique[C]//Proc of International Conference on Innovations in Intelligent Instrumentation,Optimization and Electrical Sciences,2013:18-22.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_28" >
                                        <b>[28]</b>
                                     Long J,Shelhamer E,Darrell T.Fully convolutional networks for semantic segmentation[C]//Proc of the IEEE Conference on Computer Vision and Pattern Recognition,2015:3431-3440.</a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_29" title=" Haloi M.Improved microaneurysm detection using deep neural networks[J].arXiv:1505.04424,2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved microaneurysm detection using deep neural networks">
                                        <b>[29]</b>
                                         Haloi M.Improved microaneurysm detection using deep neural networks[J].arXiv:1505.04424,2015.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_30" title=" Wang S,Tang H L,Turk L I A,et al.Localizing microaneurysms in fundus images through singular spectrum analysis[J].IEEE Transactions on Biomedical Medical Engineering,2017,64(5):990-1002." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Localizing microaneurysms in fundus images through singular spectrum analysis">
                                        <b>[30]</b>
                                         Wang S,Tang H L,Turk L I A,et al.Localizing microaneurysms in fundus images through singular spectrum analysis[J].IEEE Transactions on Biomedical Medical Engineering,2017,64(5):990-1002.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_31" title=" Dai B,Wu X,Bu W,et al.Retinal microaneurysms detection using gradient vector analysis and class imbalance classification[J].Plos One,2016,11(8):e0161556." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Retinal Microaneurysms Detection Using Gradient Vector Analysis and Class Imbalance Classification">
                                        <b>[31]</b>
                                         Dai B,Wu X,Bu W,et al.Retinal microaneurysms detection using gradient vector analysis and class imbalance classification[J].Plos One,2016,11(8):e0161556.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_32" title=" Zhang X.Image processing methods for computer-aided screening of diabetic retinopathy[D].Paris:Ecole Nationale Sup&#233;rieure Des Mines De Paris,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image processing methods for computer-aided screening of diabetic retinopathy">
                                        <b>[32]</b>
                                         Zhang X.Image processing methods for computer-aided screening of diabetic retinopathy[D].Paris:Ecole Nationale Sup&#233;rieure Des Mines De Paris,2014.
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_33" title=" Dashtbozorg B,Zhang J,Huang F,et al.Retinal micro-aneurysms detection using local convergence index features[J].IEEE Transactions on Image Processing,2018,27(7):3300-3315." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Retinal microaneurysms detection using local convergence index features">
                                        <b>[33]</b>
                                         Dashtbozorg B,Zhang J,Huang F,et al.Retinal micro-aneurysms detection using local convergence index features[J].IEEE Transactions on Image Processing,2018,27(7):3300-3315.
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_34" title=" Pereira C,Veiga D,Mahdjoub J,et al.Using a multi-agent system approach for microaneurysm detection in fundus images[J].Artificial Intelligence in Medicine,2014,60(3):179-188." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600386315&amp;v=MjA0NjBKMXdSYmhNPU5pZk9mYks4SHRETXFZOUZaK01KRDMwOG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[34]</b>
                                         Pereira C,Veiga D,Mahdjoub J,et al.Using a multi-agent system approach for microaneurysm detection in fundus images[J].Artificial Intelligence in Medicine,2014,60(3):179-188.
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_35" title=" Antal B,Hajdu A.An ensemble-based system for microaneurysm detection and diabetic retinopathy grading[J].IEEE Transactions on Biomedical Engineering,2012,59(6):1720-1726." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Ensemble-Based System for Microaneurysm Detection and Diabetic Retinopathy Grading">
                                        <b>[35]</b>
                                         Antal B,Hajdu A.An ensemble-based system for microaneurysm detection and diabetic retinopathy grading[J].IEEE Transactions on Biomedical Engineering,2012,59(6):1720-1726.
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_36" title=" Khurd P,Liu B,Gindi G.Ideal AFROC and FROC observers[J].IEEE Transactions on Medical Imaging,2010,29(2):375-386." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ideal AFROC and FROC observers">
                                        <b>[36]</b>
                                         Khurd P,Liu B,Gindi G.Ideal AFROC and FROC observers[J].IEEE Transactions on Medical Imaging,2010,29(2):375-386.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(11),2000-2006 DOI:10.3969/j.issn.1007-130X.2019.11.014            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向眼底图像小目标检测的无监督学习方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E4%B8%80%E9%A3%9E&amp;code=42318853&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙一飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AD%A6%E7%BB%A7%E5%88%9A&amp;code=33834933&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武继刚</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%AC%A3%E9%B9%8F&amp;code=40897830&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张欣鹏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0139774&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东工业大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>小目标检测是图像处理领域的一个难点,尤其是医学图像中的小目标检测。微动脉瘤MA作为眼底图像中的一类小目标,尺寸小、局部对比度较低,并且存在较多的噪声干扰,检测难度较大。传统的检测方法需要手工提取特征,难以准确检测MA。而基于深度学习的检测需要进行复杂的前期准备工作,工作量大,并且难以解决正负样本数量不平衡的问题,容易产生过拟合。稀疏编码器SAE是一种无监督机器学习算法,可以在样本数量不平衡的环境中有效地提取样本的特征。因此,提出了一种基于SAE的无监督学习方法检测MA,采用反向传播更新SAE的权重和偏置以提取样本的特征,并利用提取的特征训练Softmax,最终实现MA的准确检测。为验证方法性能,选取了Retinopathy Online Challenge、DIARETDB1和E-ophtha-MA 3个数据库分别进行实验。实验结果表明,本文方法能够准确地检测出眼底图像中的MA,并且获得了较高的准确率和灵敏度。准确率分别为98.5%,87.2%和92.6%,灵敏度分别为99.9%,99.8%和98.7%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">无监督学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E7%BC%96%E7%A0%81%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏编码器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AE%E5%8A%A8%E8%84%89%E7%98%A4%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">微动脉瘤检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%A9%E8%89%B2%E7%9C%BC%E5%BA%95%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">彩色眼底图像;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    孙一飞(1996-),男,安徽马鞍山人,硕士生,研究方向为图像处理。E-mail:2645650849@qq.com,通信地址:510006广东省广州市广东工业大学计算机学院;
                                </span>
                                <span>
                                    武继刚(1963-),男,江苏沛县人,博士,教授,CCF会员(15924M),研究方向为智能计算和移动计算。E-mail:asjgwucn@outlook.com,通信地址:510006广东省广州市广东工业大学计算机学院;
                                </span>
                                <span>
                                    张欣鹏(1989-),男,天津人,博士后,CCF会员(94041M),研究方向为人工智能和图像处理。E-mail:xpzhangtjpu@163.com,通信地址:510006广东省广州市广东工业大学计算机学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61672171);</span>
                                <span>广东省科技计划重点领域研发项目(2019B010121001);</span>
                                <span>广东省自然科学基金重点项目(2018B030311007);</span>
                    </p>
            </div>
                    <h1><b>Unsupervised learning for small objects detection in retinal images</b></h1>
                    <h2>
                    <span>SUN Yi-fei</span>
                    <span>WU Ji-gang</span>
                    <span>ZHANG Xin-peng</span>
            </h2>
                    <h2>
                    <span>School of Computer Science,Guangdong University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Small object detection is an unresolved problem for image processing, especially for medical image processing. Microaneurysm(MA) is a kind of small objects in retinal images. It has small size, low local contrast, and more noise interference, so it is difficult to be detected.Traditional detection methods require manual extraction of features, making it difficult to accurately detect MA.The detection based on deep learning requires a large amount of complex preparatory work, and it is difficult to solve the imbalance problem between positive and negative samples, which is easy to cause over-fitting.Sparse autoencoder(SAE) is an unsupervised machine learning algorithm that efficiently extracts the features of samples in an environment with unbalanced sample data.Therefore, an unsupervised learning method based on SAE is proposed to detect MA. The weights and offsets of SAE are updated by backpropagation to extract the features of the samples, and the extracted features are used to train softmax to achieve accurate detection of MA.In order to evaluate the performance of the method, three databases(Retinopathy Online Challenge, DIARETDB1 and E-ophtha-MA) are used to carry out experiments.Experimental results show that the method can accurately detect MA in retinal image and obtain higher accuracy and sensitivity. The accuracy rates are 98.5%, 87.2%, and 92.6% respectively, and the sensitivity are 99.9%, 99.8%, and 98.7% respectively.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=unsupervised%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">unsupervised learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20autoencoder&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse autoencoder;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=microaneurysm%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">microaneurysm detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20retinal%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color retinal image;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    SUN Yi-fei,born in 1996,MS candidate,his research interest includes image processing.Address:School of Computer Science,Guangdong University of Technology,Guangzhou 510006,Guangdong,P.R.China;
                                </span>
                                <span>
                                    WU Ji-gang,born in 1963,PhD,professor,CCF member(15924M),his research interests include smart computing,and mobile computing.Address:School of Computer Science,Guangdong University of Technology,Guangzhou 510006,Guangdong,P.R.China;
                                </span>
                                <span>
                                    ZHANG Xin-peng,born in 1989,post doctor,CCF member(94041M),his research interests include artificial intelligence,and image processing.Address:School of Computer Science,Guangdong University of Technology,Guangzhou 510006,Guangdong,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-06-20</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="75" name="75" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="76">小目标检测是图像处理领域的难点,传统的方法以及深度学习对于此种目标的检测均存在一定的局限性。微动脉瘤MA(MicroAneurysm)作为眼底图像中的小目标,由于自身的特点以及图像的成像环境更是增加了检测的难度。MA是糖尿病的主要并发症,大约三分之一的糖尿病患者具有视网膜病变迹象<citation id="139" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>。MA在眼底图像中呈现为小的红色或者暗红色的类圆形斑点。图1展示了彩色眼底图像中的多种MA,其中,图1b和图1c中的MA分别靠近血管与黄斑;图1d中的MA相比图1a中的MA,尺寸较小;图1e中的MA虽然可见,但局部对比度较低;而图1f中的MA模糊不清,难以直接观察。此外,眼底图像中存在大量噪声,并且出血点、血管交叉点与MA的特性相似,会对检测产生干扰,降低算法性能。</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911014_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 彩色眼底图像中的MA" src="Detail/GetImg?filename=images/JSJK201911014_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 彩色眼底图像中的MA  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911014_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 MAs in the color retinal images</p>

                </div>
                <div class="p1">
                    <p id="78">目前已有的MA检测方法可以分为传统检测方法与基于深度学习的检测方法。传统检测方法主要基于MA的可视特征,通过建立数学模型逐层筛选,最终实现MA的检测。文献<citation id="149" type="reference">[<a class="sup">4</a>,<a class="sup">5</a>]</citation>基于MA的类高斯特性,提出了一种基于灰度剖面图的数学模型。该模型以图像中每个像素点为中心构建局部区域,通过从不同方向扫描局部区域内的灰度值,得到灰度剖面图。MA相比于其他眼底目标,其剖面图均具有相似的类高斯曲线。因此,通过提取灰度剖面图中曲线的特征点,设计一种高斯性的度量方法,以检测MA与非MA,但该方法对图像亮度和对比度较敏感。为克服这一不足,文献<citation id="140" type="reference">[<a class="sup">6</a>]</citation>对文献<citation id="141" type="reference">[<a class="sup">5</a>]</citation>的方法进行改进,采用KNN(K-Nearest Neighbor)分类器对提取到的多类特征进行训练,得到了较高的灵敏度。文献<citation id="142" type="reference">[<a class="sup">7</a>]</citation>基于模板匹配机制,设计一组动态高斯滤波器对图像进行粗略分割,得到候选的MA。为了准确地检测不同尺寸的MA,该方法设计了一种自适应权重算法调整高斯滤波器尺度。此外,细小血管片段是MA检测的主要误检之一,为降低血管对MA检测的干扰,文献<citation id="143" type="reference">[<a class="sup">8</a>]</citation>提出了一种新型滤波器,用于血管与MA的分类。文献<citation id="144" type="reference">[<a class="sup">9</a>]</citation>提出了基于滤波器组的三阶段检测系统,利用数学形态学操作、对比度归一化与滤波器组以提高深色区域的对比度,同时进行血管增强和血管分割,降低血管对检测的影响。文献<citation id="145" type="reference">[<a class="sup">10</a>]</citation>通过从多个方向扫描眼底图像中的每个像素点,得到局部最大值图。MA在图中表现为孤立的亮点,因此选择图中取值较大的孤立区域作为MA检测结果。文献<citation id="146" type="reference">[<a class="sup">11</a>]</citation>提出了一种基于灰度编码的MA检测方法,通过基于图像引导的滤波器分割并移除眼底血管。为了降低眼底噪声对MA检测的影响,该方法对局部连通域进行编码,剔除孤立的噪声点。文献<citation id="147" type="reference">[<a class="sup">12</a>]</citation>设计一种尺度约束的Frangi滤波器实现对血管的准确检测。采用多核学习方法选取最优的核函数组合计算特征距离,检测MA和非MA。文献<citation id="148" type="reference">[<a class="sup">13</a>]</citation>首先提出一种适用于图像暗目标的滤波器,得到候选的MA。然后采用谱分析算法对灰度剖面图进行重构,有效滤除剖面图中的干扰点,得到更加平滑的曲线。最后通过提取描述剖面图高斯性的多维特征实现了MA的准确检测。虽然上述方法得到了不错的结果,但经过人工提取的特征具有一定的局限性,难以有效降低眼底图像噪声对MA检测的干扰,无法识别眼底图像中的小尺寸和模糊的MA。</p>
                </div>
                <div class="p1">
                    <p id="79">近年来,深度学习尤其是卷积神经网络CNN(Convolutional Neural Network)被广泛应用于图像中的目标检测,通过从大量样本中自动提取高维特征,提高特征的表达能力。因此,文献<citation id="151" type="reference">[<a class="sup">14</a>,<a class="sup">15</a>]</citation>采用CNN来检测MA,为了提高分类的准确性,将预处理结果也用于训练。文献<citation id="150" type="reference">[<a class="sup">16</a>]</citation>提出了一种基于数据挖掘和深度学习的MA检测方法,建立临床报告与对应眼底图像的特征映射模型。将报告中的微动脉瘤数量、位置等相关信息通过超像素聚类映射至特征空间,得到特征图。然后将其作为训练样本用于训练CNN网络模型,提高模型的训练精度。该方法在DIARETDB1和医院数据集上获得了较高的准确率和灵敏度。与传统方法相比,基于CNN的MA检测方法可以自动学习眼底图像中的MA与非MA的高维特征,有效减少误检和漏检。虽然已有基于深度学习的MA检测方法通过平移旋转等刚性变换丰富正样本的多样性,但由于目标较小且数量有限,训练集中的正负样本数量严重不均衡,容易导致深度神经网络对正样本训练的过拟合,降低网络泛化性。</p>
                </div>
                <div class="p1">
                    <p id="80">针对上述问题,本文提出了一种基于稀疏编码器SAE(Sparse AutoEncoder)的无监督学习方法,通过对样本进行编码和解码操作提取样本的有效特征,实现了MA的精确检测。本文主要贡献如下:(1)基于SAE良好的特征提取功能,实现对眼底图像中MA的精确检测,训练时间短;(2)在学习样本特征时无需借助标签信息,能够有效克服MA样本数量不平衡的问题;(3)相比于已有方法,本文提出的方法获得了更高的准确率和灵敏度。</p>
                </div>
                <h3 id="81" name="81" class="anchor-tag"><b>2 MA检测方法</b></h3>
                <div class="p1">
                    <p id="82">本文提出了一种基于SAE的无监督学习方法,能够有效地提取小目标的特征。与传统CNN相比,SAE通过对样本进行编码与解码学习目标特征,无需池化操作,适用于尺寸较小的图像目标。同时,SAE能够在正负样本数量不平衡的环境下提取待检测目标的有效特征,有效地解决了MA检测中正负样本数量不平衡的问题。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>2.1 预处理</b></h4>
                <div class="p1">
                    <p id="84">绿色通道相比于其他通道具有较高的对比度,并且包含更多的眼底有效信息,因此已有方法多采用绿色通道检测MA<citation id="152" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。但是,文献<citation id="153" type="reference">[<a class="sup">18</a>,<a class="sup">19</a>]</citation>指出彩色眼底图像中的红色通道和蓝色通道同样包含MA的一些有效信息。此外,病变程度严重的眼底图像的整体对比度和亮度过低,因此预处理步骤是必要的。采用Gamma校正对绿色通道进行预处理可以有效地提高眼底图像的对比度和亮度。Gamma校正函数为:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>φ</mi><mrow><mo>(</mo><mi>p</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>2</mn><mn>5</mn><mn>5</mn><mrow><mo>(</mo><mrow><mi>p</mi><mo>/</mo><mn>2</mn><mn>5</mn><mn>5</mn></mrow><mo>)</mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mi>ν</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msup><mo>,</mo><mi>p</mi><mo>∈</mo><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>]</mo></mrow></mtd></mtr><mtr><mtd><mn>2</mn><mn>5</mn><mn>5</mn><mrow><mo>(</mo><mrow><mi>p</mi><mo>/</mo><mn>2</mn><mn>5</mn><mn>5</mn></mrow><mo>)</mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mo stretchy="false">(</mo><mi>ν</mi><msub><mrow></mrow><mn>1</mn></msub><mi>ν</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></msup><mo>,</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mi>p</mi><mo>∈</mo><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo>,</mo><mi>ν</mi><msub><mrow></mrow><mn>1</mn></msub><mo>&lt;</mo><mn>1</mn><mo>,</mo><mi>ν</mi><msub><mrow></mrow><mn>2</mn></msub><mo>&gt;</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn><mn>5</mn><mn>5</mn><mo>,</mo><mi>p</mi><mo>∈</mo><mrow><mo>[</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub></mrow><mo>]</mo></mrow></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中,<i>p</i>为图像中任意一点的灰度值,<i>p</i><sub>1</sub>和<i>p</i><sub>2</sub>分别为灰度直方图的上升沿和下降沿,<i>p</i><sub>max</sub>为原始绿色通道的最大灰度级,<i>ν</i><sub>1</sub>和 <i>ν</i><sub>2</sub>分别为在不同像素区间内设定的Gamma函数的亮度因子<citation id="154" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>。图2为Gamma校正结果,经过Gamma校正的眼底图像相比于原始图像(图2a),整体亮度和对比度得到了显著提升,如图2b所示。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911014_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 眼底图像对比度增强结果" src="Detail/GetImg?filename=images/JSJK201911014_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 眼底图像对比度增强结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911014_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Enhancement results of Gamma correction</p>

                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>2.2 稀疏自编码器</b></h4>
                <div class="p1">
                    <p id="89">稀疏自编码器SAE是一种无监督机器学习算法,是深度学习领域的重要组成部分。算法能够有效地压缩输入信息,提取样本特征。SAE由3层组成,分别为编码层、隐藏层和解码层<citation id="155" type="reference"><link href="43" rel="bibliography" /><link href="45" rel="bibliography" /><sup>[<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>,结构如图3所示。SAE的主要目标是尽可能使得输出与原始输入之间的误差最小,即:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ο</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow></msub><mrow><mo>(</mo><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>≈</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>f</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mo>-</mo><mi>x</mi></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>Ο</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow></msub><mrow><mo>(</mo><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo><mi>f</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mrow><mo>(</mo><mrow><mi>f</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mrow><mo>(</mo><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">其中,<i>a</i><sub><i>i</i></sub>为稀疏编码器的原始输入,<i><b>W</b></i>为稀疏编码器的权重矩阵,<i><b>b</b></i>为稀疏编码器的偏置矩阵,<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow></msub><mrow><mo>(</mo><mo>⋅</mo><mo>)</mo></mrow></mrow></math></mathml>为<b>SAE</b>的输出,<i><b>f</b></i>为非线性激活函数, <i><b>f</b></i><sub><i><b>W</b></i></sub><sub>1,</sub><sub><i><b>b</b></i></sub><sub>1</sub>(·)与<i>f</i><sub><i><b>W</b></i></sub><sub>2,</sub><sub><i><b>b</b></i></sub><sub>2</sub>(·)分别为隐藏层与解码层的激活响应,<i><b>W</b></i><sub>1</sub>、<i><b>b</b></i><sub>1</sub>分别为稀疏编码器隐藏层的权重矩阵和偏置矩阵,<i><b>W</b></i><sub>2</sub>、<i><b>b</b></i><sub>2</sub>分别为稀疏编码器输出层的权重矩阵和偏置矩阵。</p>
                </div>
                <div class="p1">
                    <p id="93">SAE可以自动地从无标注数据中学习特征,并且通过对隐藏层施加稀疏性限制,可以更好地在样本数量不平衡的环境中提取样本的特征。将无标签的训练集<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>a</mi><msub><mrow></mrow><mi>Ν</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>输入SAE模型中,编码层对所有样本进行编码,采用非线性激活函数<i>f</i>对编码结果进行激活。SAE的损失函数<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>A</mtext><mtext>E</mtext></mrow></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>定义为:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>J</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>A</mtext><mtext>E</mtext></mrow></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>)</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi>Ο</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow></msub><mrow><mo>(</mo><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mo>-</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>)</mo></mrow></mrow></mstyle></mrow><mo>]</mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mi>λ</mi><mn>2</mn></mfrac><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>(</mo><mrow><mi>W</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mo>)</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>β</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>Κ</mi></mstyle><mi>L</mi><mrow><mo>(</mo><mrow><mi>χ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中,<i>N</i>为样本数量;<mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>(</mo><mrow><mi>W</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mo>)</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>为正则项;<i>W</i><sub><i>ij</i></sub>为第<i>j</i>层中第<i>i</i>个神经元的权重;防止由于参数值过大导致的训练过拟合,<i>λ</i>为惩罚因子。<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>Κ</mi></mstyle><mi>L</mi><mrow><mo>(</mo><mrow><mi>χ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>为稀疏限制项,<i>S</i>为隐藏层神经元个数。KL(Kullback-Leibler divergence)称为散度,即相对熵,用于测量2个概率分布之间的差异:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mrow><mo>(</mo><mrow><mi>χ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo><mi>χ</mi><mi>ln</mi><mfrac><mi>χ</mi><mrow><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo>+</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mi>χ</mi></mrow><mo>)</mo></mrow><mi>ln</mi><mfrac><mrow><mn>1</mn><mo>-</mo><mi>χ</mi></mrow><mrow><mn>1</mn><mo>-</mo><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">其中,<i>χ</i>为稀疏项,<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>χ</mi><mo>^</mo></mover></math></mathml><sub><i>j</i></sub>为平均激活响应:</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>S</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>f</mi></mstyle><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">其中,<i>x</i><sub><i>i</i></sub>表示样本集中的第<i>i</i>个样本。</p>
                </div>
                <div class="p1">
                    <p id="100">L-BFGS算法<citation id="156" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>是求解无约束非线性极小化问题的拟牛顿方法<citation id="157" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>,通过计算最优的<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">W</mi><mo>^</mo></mover></math></mathml>,<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo>^</mo></mover></math></mathml>使得<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>A</mtext><mtext>E</mtext></mrow></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>最小。该算法不需要存储高维度的矩阵,具有收敛速度快、内存开销少的优点。因此,本文采用L-BFGS算法对SAE参数进行优化。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911014_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 SAE模型" src="Detail/GetImg?filename=images/JSJK201911014_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 SAE模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911014_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 SAE model</p>

                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>2.3 基于SAE的MA检测</b></h4>
                <div class="p1">
                    <p id="102">本文方法的主要目标是训练出一个适用于小目标(<i>MA</i>)检测的模型,模型框架如图4所示。首先,随机初始化<i>SAE</i>的参数为<i><b>W</b></i><sup>0</sup>,<i><b>b</b></i><sup>0</sup>,将包含绿色通道、蓝色通道和预处理的训练集输入至SAE中,提取样本的特征,将特征输入至Softmax,通过Softmax进行降维,最终输出二维向量。训练过程中,不断更新SAE的参数以寻求最优的<mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">W</mi><mo>^</mo></mover></math></mathml>,<mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo>^</mo></mover></math></mathml>使得<mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>A</mtext><mtext>E</mtext></mrow></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>达到最小。最后将测试集输入至模型,对MA进行检测。具体计算步骤为:</p>
                </div>
                <div class="p1">
                    <p id="103">(1)输入训练集:绿色通道{<i>a</i><sup>G</sup><sub>1</sub>,<i>a</i><sup>G</sup><sub>2</sub>,…,<i>a</i><sup>G</sup><sub><i>N</i></sub>}、蓝色通道{<i>a</i><sup>B</sup><sub>1</sub>,<i>a</i><sup>B</sup><sub>2</sub>,…,<i>a</i><sup>B</sup><sub><i>N</i></sub>}、图像 Gamma校正结果{<i>a</i><sup>P</sup><sub>1</sub>,<i>a</i><sup>P</sup><sub>2</sub>,…,<i>a</i><sup>P</sup><sub><i>N</i></sub>}。</p>
                </div>
                <div class="p1">
                    <p id="104">(2)通过反向传播更新SAE权重<i><b>W</b></i>、偏置<i><b>b</b></i>以最小化损失函数<mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mtext>S</mtext><mtext>A</mtext><mtext>E</mtext></mrow></msub><mrow><mo>(</mo><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>的值,参数通过以下计算过程更新:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>m</mi></msup><mo>-</mo><mi>α</mi><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mi>S</mi></mfrac><mi>Δ</mi><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>m</mi></msup><mo>+</mo><mi>λ</mi><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>m</mi></msup></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>Δ</mi><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>m</mi></msup><mo>=</mo><mi>f</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><mo>,</mo><mi mathvariant="bold-italic">b</mi></mrow></msub><mrow><mo>(</mo><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mstyle displaystyle="true"><mo>∑</mo><mi mathvariant="bold-italic">W</mi></mstyle><msup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msup><mi>Δ</mi><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msup><mo>+</mo></mtd></mtr><mtr><mtd><mi>β</mi><mrow><mo>(</mo><mrow><mo>-</mo><mfrac><mi>χ</mi><mrow><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>1</mn><mo>-</mo><mi>χ</mi></mrow><mrow><mn>1</mn><mo>-</mo><mover accent="true"><mi>χ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac></mrow><mo>)</mo></mrow><msup><mi>f</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msup><mo>,</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow></msub><mrow><mo>(</mo><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mrow><mi>m</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mi>m</mi></msup><mo>-</mo><mfrac><mi>α</mi><mi>S</mi></mfrac><mi>Δ</mi><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mi>m</mi></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">其中,<i>α</i>为学习率,<i>a</i><sub><i>i</i></sub>∈{<i>a</i><sup>G</sup><sub>1</sub>,<i>a</i><sup>G</sup><sub>2</sub>,…,<i>a</i><sup>G</sup><sub><i>N</i></sub>,<i>a</i><sup>B</sup><sub>1</sub>,<i>a</i><sup>B</sup><sub>2</sub>,…,<i>a</i><sup>B</sup><sub><i>N</i></sub>,<i>a</i><sup>P</sup><sub>1</sub>,<i>a</i><sup>P</sup><sub>2</sub>,…,<i>a</i><sup>P</sup><sub><i>N</i></sub>},<i><b>W</b></i><sup><i>m</i></sup><sup>+1</sup>为第<i>m</i>+1次更新的权重矩阵,<i>Δ</i><i><b>W</b></i><sup><i>m</i></sup>为第<i>m</i>次更新时损失函数关于权重的偏导数矩阵,<i>β</i>为稀疏惩罚因子,<i><b>b</b></i><sup><i>m</i></sup><sup>+1</sup>为第<i>m</i>+1次更新的偏置矩阵,<i>Δ</i><i><b>b</b></i><sup><i>m</i></sup>为第<i>m</i>次更新的损失函数关于偏置的偏导数矩阵。</p>
                </div>
                <div class="p1">
                    <p id="107">(3)得到最终的参数<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">W</mi><mo>^</mo></mover></math></mathml>,<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">b</mi><mo>^</mo></mover></math></mathml>,对训练集进行分类,获得检测结果。</p>
                </div>
                <div class="p1">
                    <p id="108">(4)将测试样本输入至模型,分别对3个通道的测试集进行测试。</p>
                </div>
                <div class="area_img" id="109">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911014_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 检测模型的框架" src="Detail/GetImg?filename=images/JSJK201911014_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 检测模型的框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911014_109.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 4 <i>Framework of the detection model</i></p>

                </div>
                <h3 id="110" name="110" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="111">本节基于<i>Matlab</i>平台,在配备有<i>Intel Core i</i>5-4200<i>M CPU</i>,工作频率为2.5 <i>GHz</i>的<i>PC</i>机上进行实验。本文选取了3个数据库进行实验,分别为<i>Retinopathy Online Challenge</i> (<i>ROC</i>)、<i>DIARETDB</i>1(<i>DB</i>1)和<i>E</i>-<i>ophtha</i>-<i>MA</i>。<i>ROC</i>数据库包含50幅训练图像和50幅测试图像。训练图像由4位眼科专家进行标注,其中包括至少含有1个<i>MA</i>的37幅图像和不含有<i>MA</i>的13幅图像。测试集图像没有对<i>MA</i>进行标注,因此选择训练集的图像进行实验。<i>DB</i>1数据库包含89幅图像,本文将标注概率大于50%的候选目标区域作为真正的<i>MA</i>。<i>E</i>-<i>ophtha</i>-<i>MA</i>由381幅图像组成,其中148幅图像包含<i>MA</i>,共1 295个<i>MA</i>。</p>
                </div>
                <div class="p1">
                    <p id="112">蓝色通道具有较多的噪声干扰,但相对于红色通道,蓝色通道包含更多的信息。因此,本文选择<i>Gamma</i>校正结果、绿色通道和蓝色通道训练网络模型并测试。为了能够更好地验证模型的性能,本文采用交叉验证方法构建训练集和测试集,即从每个数据库中选取70%的图像用于构建训练样本集,剩余30%的图像用于构建测试样本集,其中样本是以目标像素为中心,大小为21×21的图像块,本文主要针对<i>MA</i>和非<i>MA</i>进行二分类,但是<i>MA</i>与非<i>MA</i>的样本数量极不平衡,正样本数量远小于负样本数量,容易产生漏检。为了避免样本数量不平衡带来的影响,本文在训练阶段采用交叉验证的方法,首先随机初始化<i>SAE</i>的参数,选取与正样本相同数量的负样本以构建训练集,将其输入至模型进行训练,通过反向传播更新<i>SAE</i>的权重和偏置参数,提取样本的特征,利用提取到的特征训练<i>Softmax</i>。测试阶段,采用相同的方式构建测试集,利用训练后的模型进行<i>MA</i>的检测。为了得到更加准确的检测结果,本文将10次测试结果的平均值作为最终实验结果。如图5所示,可以看出本文方法能够准确地检测不同大小和不同位置的<i>MA</i>。图6为检测结果中的误检,主要为背景噪声与细小血管的交叉点。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911014_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 MA的正检结果" src="Detail/GetImg?filename=images/JSJK201911014_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 <i>MA</i>的正检结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911014_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 5 <i>Experimental results of MAs</i></p>

                </div>
                <div class="area_img" id="114">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911014_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 误检为MA的背景噪声点与血管交叉点" src="Detail/GetImg?filename=images/JSJK201911014_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 误检为<i>MA</i>的背景噪声点与血管交叉点  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911014_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 6 <i>Misclassifications of noise points</i><i>and junctions of thin blood vessels</i></p>

                </div>
                <div class="p1">
                    <p id="115">为了更加准确地评估本文方法的性能,采用灵敏度(<i>Sensitivity</i>)和准确率(<i>Accuracy</i>)评估检测方法的整体性能。</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>S</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">其中,<i>TP</i>为真阳数量,即检测为<i>MA</i>,实际也为<i>MA</i>的图像数量,<i>TN</i>为真阴数量,即检测为非<i>MA</i>,实际也为非<i>MA</i>的图像数量,<i>FN</i>为假阴数量,即检测为非<i>MA</i>,实际为<i>MA</i>的图像数量,<i>FP</i>为假阳数量,即检测为<i>MA</i>,实际为非<i>MA</i>的图像数量。为了验证本文方法的性能,分别在公开数据库上进行测试。由于大多数已有的方法在<i>ROC</i>与<i>E</i>-<i>ophtha</i>-<i>MA</i>数据库上并没有记录准确率,表1展示了本文方法在<i>DB</i>1数据库上的准确率与已有方法的准确率比较。可以看出,本文方法在<i>DB</i>1数据库上获得了较高的准确率,虽然文献<citation id="158" type="reference">[<a class="sup">27</a>]</citation>方法的准确率高于本文方法的,但是该方法的计算量较大。本文方法在不借助<i>GPU</i>的帮助下所花费的训练时间较少,在<i>ROC</i>、<i>DB</i>1、<i>E</i>-<i>ophtha</i>-<i>MA</i> 3个数据库上的训练时间分别为163.05 <i>s</i>,426.31 <i>s</i>,2 128.18 <i>s</i>。本文提出的方法与现有方法在公开数据库上的灵敏度比较如表2所示,其中“-”表示该方法未在相应数据库上进行实验。从表2中可以看出,本文提出的方法相比于已有方法均获得了更高的灵敏度。</p>
                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表1 已有方法在DIARETDB1数据库上的准确率比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Accuracy comparisons on DIARETDB1 dataset</b></p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td><br />方法</td><td>准确率/%</td></tr><tr><td><br />本文方法</td><td>87.2</td></tr><tr><td><br />Quallec et al.<sup>[25]</sup></td><td>80.5</td></tr><tr><td><br />Mizutani et al.<sup>[26]</sup></td><td>71.3</td></tr><tr><td><br />Aravind et al.<sup>[27]</sup></td><td>90.0</td></tr><tr><td><br />Long et al.<sup>[28]</sup></td><td>72.2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="119">
                    <p class="img_tit"><b>表2 已有方法在公共数据库上的灵敏度比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Sensitivity comparisons on ROC</b>, <b>DIARETDB1 and E-ophtha-MA datasets</b></p>
                    <p class="img_note">%</p>
                    <table id="119" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="3"><br />灵敏度/%</td></tr><tr><td><br />ROC</td><td>DB1</td><td>E-ophtha-MA</td></tr><tr><td><br />本文方法</td><td>99.9</td><td>99.8</td><td>98.7</td></tr><tr><td><br />Haloi<sup>[29]</sup></td><td>60.0</td><td>-</td><td>-</td></tr><tr><td><br />Eftekheri et al.<sup>[14]</sup></td><td>61.0</td><td>-</td><td>-</td></tr><tr><td><br />Wang et al.<sup>[30]</sup></td><td>59.8</td><td>71.5</td><td>-</td></tr><tr><td><br />Dai et al.<sup>[16]</sup></td><td>-</td><td>99.0</td><td>-</td></tr><tr><td><br />Wu et al.<sup>[6]</sup></td><td>29.5</td><td>-</td><td>32.0</td></tr><tr><td><br />Lazer et al.<sup>[5]</sup></td><td>47.2</td><td>-</td><td>-</td></tr><tr><td><br />Dai et al.<sup>[31]</sup></td><td>52.8</td><td>-</td><td>-</td></tr><tr><td><br />Zhang<sup>[32]</sup></td><td>-</td><td>-</td><td>74.0</td></tr><tr><td><br />Dashtbozorg et al.<sup>[33]</sup></td><td>50.6</td><td>61.7</td><td>63.8</td></tr><tr><td><br />Mizutani et al.<sup>[26]</sup></td><td>-</td><td>-</td><td>46.6</td></tr><tr><td><br />Pereira et al.<sup>[34]</sup></td><td>54.0</td><td>-</td><td>-</td></tr><tr><td><br />Antal et al.<sup>[35]</sup></td><td>64.3</td><td>25.7</td><td>-</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="120">实验结果表明,本文方法在公开的数据库上获得了较好的检测结果。虽然文献<citation id="159" type="reference">[<a class="sup">16</a>]</citation>方法在DB1上获得了较高的灵敏度,但是计算量大、复杂度高,需要依赖于GPU。而本文提出的方法复杂度低、计算量小,无需池化操作,能够有效克服MA检测中正负样本数量不平衡的问题。同时,本文提出的方法在低误检的情况下实现了较高的灵敏度,能够准确地区分MA与非MA。此外,当误检数量增加时,仍然保持着高灵敏度。因此,本文方法不仅适用于小目标的检测,而且还解决了样本数量不平衡的问题。图7分别为本文方法在3个公共数据库上进行实验得到的<i>F</i>-<i>ROC</i>(Free-response Receiver Operating Characteristic)<citation id="160" type="reference"><link href="73" rel="bibliography" /><sup>[<a class="sup">36</a>]</sup></citation>曲线,用于衡量检测方法的性能。</p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911014_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 F-ROC曲线" src="Detail/GetImg?filename=images/JSJK201911014_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 <i>F</i>-<i>ROC</i>曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911014_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 7 <i>F</i>-<i>ROC</i> curves</p>

                </div>
                <h3 id="122" name="122" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="123">本文提出一种基于SAE的无监督学习方法,采用Gamma校正显著提升眼底图像的亮度与对比度,为了充分提取MA的有效特征,将蓝色通道、绿色通道以及Gamma校正结果作为训练集。将无池化操作的SAE作为训练模型,采用L-BFGS算法进行反向传播,通过更新SAE的权值与偏置进行特征提取,最后利用特征训练Softmax,以准确区分MA与非MA。实验结果表明,本文提出的方法能够准确地检测彩色眼底图像中的MA,相比于已有方法,获得了更高的准确率和灵敏度。并且本文方法训练时间较短,无需借助GPU提升计算性能。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="167" type="formula" href="images/JSJK201911014_16700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">孙一飞</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="168" type="formula" href="images/JSJK201911014_16800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">武继刚</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="169" type="formula" href="images/JSJK201911014_16900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">张欣鹏</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00005104585&amp;v=MTcyNDNoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNEbFZMM05KRjg9TmozYWFyTzRIdEhKcm85QlllTUtZM2s1ekJk&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Yau J W Y,Rogers S,Kawasaki R,et al.Global prevalence and major risk factors of diabetic retinopathy[J].Diabetes Care,2012,35(3):556-564.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDBAC675C997F76FD38AD03AFACA2F8B0&amp;v=MDkxMTVLYjZMS3FJbzJiZUlJZW5zL3VXSVE0azRKU0h5VDJtTkdDTERpVGNpZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3cTZ4S2s9TmlmT2ZjZg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Harris S B,Tompkins J W,Tehiwi B,et al.Call to action:A new path for improving diabetes care for indigenous peoples,a global review[J].Diabetes Research and Clinical Practice,2017,123:120-133.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001997066&amp;v=MDc1MjNScnhveGNNSDdSN3FlYnVkdEZDRGxWTDNOSkY4PU5qN0Jhck80SHRITnBvWkNaTzBKWTNrNXpCZGg0ajk5U1hx&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Porta M,Bandello F.Diabetic retinopathy[J].Diabetologia,2002,45(12):1617-1634.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Microaneurysm detection in retinal images using a rotating cross-section based model">

                                <b>[4]</b> Lazar I,Hajdu A.Microaneurysm detection in retinal images using a rotating cross-section based model[C]//IEEE International Symposium on Biomedical Imaging,2011:1405-1409.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Retinal microaneurysm detection through local rotating cross-section profile analysis">

                                <b>[5]</b> Lazar I,Hajdu A.Retinal microaneurysm detection through local rotating cross-section profile analysis[J].IEEE Transactions on Medical Imaging,2013,32(2):400-407.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3DC3B4F39EC27D7DB264D24427FB4083&amp;v=MTY4NjJKaDZEbDVQSDNtcUJBeUQ4Q1FSYktjQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJodzdxNnhLaz1OaWZPZmJETWJkSytxL2xHYlo1OERudE55Rw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Wu B,Zhu W,Shi F,et al.Automatic detection of microaneurysm in retinal fundus images[J].Computerized Medical Imaging and Graphics,2016,55:106-112.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An accurate approach for microaneurysm detection in digital fundus images">

                                <b>[7]</b> Ding S,Ma W.An accurate approach for microaneurysm detection in digital fundus images[C]//Proc of International Conference on Pattern Recognition,2014:1846-1851.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE34241A25A5E326EC21752D7F00F587F&amp;v=MTUwMTJZWm9LZVg4N3lXTmc2RDU2VFgyV3EyUTFlY1NSVGIzcENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3cTZ4S2s9TmlmT2ZjYTdHdFBJcnY1SA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Srivastava R,Duan L,Wong D W K,et al.Detecting retinal microaneurysms and hemorrhages with robustness to the presence of blood vessels[J].Computer Methods and Programs in Biomedicine,2016,138:83-91.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600107361&amp;v=MDI3MThNPU5pZk9mYks4SHRETXFZOUZaZXNJRDNvNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUoxd1JiaA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Akram M U,Khalid S,Khan S A.Identification and classification of microaneurysms for early detection of diabetic retinopathy[J].Pattern Recognition,2013,46(1):107-116.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel approach for the automatic detection of microaneurysms in retinal images">

                                <b>[10]</b> Lazar I,Qureshi R J,Hajdu A.A novel approach for the automatic detection of microaneurysms in retinal images[C]//Proc of 2010 6th International Conference on Emerging Technologies (ICET),2010:193-197.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detection of microaneurysm using local rank transform in color fundus images">

                                <b>[11]</b> Kamble R,Kokare M.Detection of microaneurysm using local rank transform in color fundus images[C]//Proc of IEEE International Conference on Image Processing (ICIP),2017:4442-4446.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB88EBA648FFAA133A98152D511CE5461&amp;v=MjU4NTE9TmlmT2ZjR3dGcVMrM29sQmJKMTVmUTA0ekJWaTR6ZDhUWDJXcVJNMENzZVJRYnllQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJodzdxNnhLaw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Javidi M,Pourreza H R,Harati A.Vessel segmentation and microaneurysm detection using discriminative dictionary learning and sparse representation[J].Computer Methods and Programs in Biomedicine,2017,139:93-108.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Localizing microaneurysms in fundus images through singular spectrum analysis">

                                <b>[13]</b> Wang S,Tang H L,Turk L I A,et al.Localizing microaneurysms in fundus images through singular spectrum analysis[J].IEEE Transactions on Biomedical Engineering,2016,64(5):600-605.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Microaneurysm detection in fundus images using a two-step convolutional neural networks">

                                <b>[14]</b> Eftekheri N,Masoudi M,Pourreza H,et al.Microaneurysm detection in fundus images using a two-step convolutional neural networks[J].arXiv:1710.05191,2017.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES3A91E698B128054298EA1725A1F63D02&amp;v=MTkzMThrPU5pZk9mYkRKRjlDNXFZWk5GdW9OQkh3OHl4UWE0a29NU1hqZ3FXTTBEN1NYTWJxZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3cTZ4Sw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> ChudzikP,Majumdar S,Calivá F,et al.Microaneurysm detection using fully convolutional neural networks[J].Computer Methods and Programs in Biomedicine,2018,158:185-192.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clinical report guided retinal microaneurysm detection with multi-sieving deep learning">

                                <b>[16]</b> Dai L,Fang R,Li H,et al.Clinical report guided retinal microaneurysm detection with multi-sieving deep learning[J].IEEE Transactions on Medical Imaging,2018,37(5):1149-1165.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300711561&amp;v=MzEyMzNYbzRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKMXdSYmhNPU5pZk9mYks3SHRETnJJOUZZK29PQw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Walter T,Massin P,Erginay A,et al.Automatic detection of microaneurysms in color fundus images[J].Medical Image Analysis,2007,11(6):555-566.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES124B2FE1E6598966DBF5197A46869D0C&amp;v=MTY0NzNiSzZHcVBPMmZwRUVlMEtCWFF3eVJCbm1FbDRTWGJsM1JZemNiU2RNYnJzQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkJodzdxNnhLaz1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Tan J H,Fujita H,Sivaprasad S,et al.Automated segmentation of exudates,haemorrhages,microaneurysms using single convolutional neural network[J].Information Sciences,2017,420:66-76.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic detection of microaneurysms using microstructure and wavelet methods">

                                <b>[19]</b> Tamilarasi M,Duraiswamy K.Automatic detection of microaneurysms using microstructure and wavelet methods[J].Sadhana,2015,40(4):1185-1203.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJAH&amp;filename=SJAH3FCB74FAC09E4E4D68ED55C784EDC8E0&amp;v=MjAzNzVuVGMrZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5CaHc3cTZ4S2s9TmlmS1pyRE9iYVBMcS9rMEYrc0dlWGhNeTJJVjRrb0pUWHFScXhveERNYg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> Xiao Z,Zhang X,Zhang F,et al.Diabetic retinopathy retinal image enhancement based on gamma correction[J].Journal of Medical Imaging and Health Informatics,2017,7(1):149-154.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse autoencoder">

                                <b>[21]</b> Ng A.Sparse autoencoder[J].CS294A Lecture Notes,2011,72(2011):1-19.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked Sparse Autoencoder(SSAE)for Nuclei Detection on Breast Cancer Histopathology images.">

                                <b>[22]</b> Xu J,Xiang L,Liu Q,et al.Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images[J].IEEE Transactions on Medical Imaging,2016,35(1):119-130.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001054&amp;v=MTI5MjBOaWZJWTdLN0h0ak5yNDlGWk9zT0RIazlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKMXdSYmhNPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> Morales J L,Nocedal J.Remark on“Algorithm 778:L-BFGS-B:Fortran subroutines for large-scale bound constrained optimization”[J].Transactions on Mathematical Software,2011,38(1):1-4.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300418080&amp;v=MjkxMTE3SHRET3JJOUZZT29IREhRNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUoxd1JiaE09TmlmT2ZiSw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> Zheng W,Bo P,Liu Y,et al.Fast B-spline curve fitting by L-BFGS[J].Computer Aided Geometric Design,2012,29(7):448-462.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimal wavelet transform for the detection of microaneurysms in retina photographs">

                                <b>[25]</b> Quellec G,Lamard M,Josselin P M,et al.Optimal wavelet transform for the detection of microaneurysms in retina photographs[J].IEEE Transactions on Medical Imaging,2008,27(9):1230-1241.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automated microaneurysm detection method based on double ring filter in retinal fundus images">

                                <b>[26]</b> Mizutani A,Muramatsu C,Hatanaka Y,et al.Automated microaneurysm detection method based on double ring filter in retinal fundus images[C]//Proc of IEEE International Symposium on Computer-Based Medical Systems (CBMS),2012:1-4.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic detection of microaneurysms and classification of diabetic retinopathy images using SVM technique">

                                <b>[27]</b> Aravind C,Ponnibala M,Vijayachitra S.Automatic de-tection of microaneurysms and classification of diabetic retinopathy images using SVM technique[C]//Proc of International Conference on Innovations in Intelligent Instrumentation,Optimization and Electrical Sciences,2013:18-22.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_28" >
                                    <b>[28]</b>
                                 Long J,Shelhamer E,Darrell T.Fully convolutional networks for semantic segmentation[C]//Proc of the IEEE Conference on Computer Vision and Pattern Recognition,2015:3431-3440.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved microaneurysm detection using deep neural networks">

                                <b>[29]</b> Haloi M.Improved microaneurysm detection using deep neural networks[J].arXiv:1505.04424,2015.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Localizing microaneurysms in fundus images through singular spectrum analysis">

                                <b>[30]</b> Wang S,Tang H L,Turk L I A,et al.Localizing microaneurysms in fundus images through singular spectrum analysis[J].IEEE Transactions on Biomedical Medical Engineering,2017,64(5):990-1002.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Retinal Microaneurysms Detection Using Gradient Vector Analysis and Class Imbalance Classification">

                                <b>[31]</b> Dai B,Wu X,Bu W,et al.Retinal microaneurysms detection using gradient vector analysis and class imbalance classification[J].Plos One,2016,11(8):e0161556.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image processing methods for computer-aided screening of diabetic retinopathy">

                                <b>[32]</b> Zhang X.Image processing methods for computer-aided screening of diabetic retinopathy[D].Paris:Ecole Nationale Supérieure Des Mines De Paris,2014.
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Retinal microaneurysms detection using local convergence index features">

                                <b>[33]</b> Dashtbozorg B,Zhang J,Huang F,et al.Retinal micro-aneurysms detection using local convergence index features[J].IEEE Transactions on Image Processing,2018,27(7):3300-3315.
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_34" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600386315&amp;v=Mjg0ODhiaE09TmlmT2ZiSzhIdERNcVk5RlorTUpEMzA4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSjF3Ug==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[34]</b> Pereira C,Veiga D,Mahdjoub J,et al.Using a multi-agent system approach for microaneurysm detection in fundus images[J].Artificial Intelligence in Medicine,2014,60(3):179-188.
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_35" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Ensemble-Based System for Microaneurysm Detection and Diabetic Retinopathy Grading">

                                <b>[35]</b> Antal B,Hajdu A.An ensemble-based system for microaneurysm detection and diabetic retinopathy grading[J].IEEE Transactions on Biomedical Engineering,2012,59(6):1720-1726.
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ideal AFROC and FROC observers">

                                <b>[36]</b> Khurd P,Liu B,Gindi G.Ideal AFROC and FROC observers[J].IEEE Transactions on Medical Imaging,2010,29(2):375-386.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201911014" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911014&amp;v=MTI1NjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L25WcnZKTHo3QlpiRzRIOWpOcm85RVlJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
