<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132366017373750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201908018%26RESULT%3d1%26SIGN%3dRpZX7FJI6UQ6A4q1mcpx5qrf%252bHY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201908018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201908018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201908018&amp;v=MDU4MDJDVVJMT2VaZVJtRnk3bFZMcklMejdCWmJHNEg5ak1wNDlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="&lt;b&gt;2 SDNO算法&lt;/b&gt; "><b>2 SDNO算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="&lt;b&gt;2.1 初始显著性图的构造&lt;/b&gt;"><b>2.1 初始显著性图的构造</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;2.2 初始显著性图的优化&lt;/b&gt;"><b>2.2 初始显著性图的优化</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="&lt;b&gt;3.1 目标显著性图检测结果比较&lt;/b&gt;"><b>3.1 目标显著性图检测结果比较</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;3.2 客观评估&lt;/b&gt;"><b>3.2 客观评估</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;3.3 算法复杂度评估&lt;/b&gt;"><b>3.3 算法复杂度评估</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#108" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="图1 SDNO算法视觉效果对比">图1 SDNO算法视觉效果对比</a></li>
                                                <li><a href="#53" data-title="图2 算法流程图">图2 算法流程图</a></li>
                                                <li><a href="#90" data-title="图3 显著性目标区域检测结果对比实验1">图3 显著性目标区域检测结果对比实验1</a></li>
                                                <li><a href="#91" data-title="图4 显著性目标区域检测结果对比实验2">图4 显著性目标区域检测结果对比实验2</a></li>
                                                <li><a href="#99" data-title="图5 在&lt;i&gt;ASD&lt;/i&gt;数据集上不同算法的 准确率和召回率曲线图">图5 在<i>ASD</i>数据集上不同算法的 准确率和召回率曲线图</a></li>
                                                <li><a href="#100" data-title="图6 在&lt;i&gt;ASD&lt;/i&gt;数据集上不同算法的准确率、召回率和F值">图6 在<i>ASD</i>数据集上不同算法的准确率、召回率和F值</a></li>
                                                <li><a href="#101" data-title="图7 在&lt;i&gt;ECSSD&lt;/i&gt;数据集上不同算法的 准确率和召回率曲线图">图7 在<i>ECSSD</i>数据集上不同算法的 准确率和召回率曲线图</a></li>
                                                <li><a href="#102" data-title="图8 在&lt;i&gt;ECSSD&lt;/i&gt;数据集上不同算法的准确率、召回率和F值">图8 在<i>ECSSD</i>数据集上不同算法的准确率、召回率和F值</a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;表1 不同算法产生一幅显著性图像平均所需时间表&lt;/b&gt;"><b>表1 不同算法产生一幅显著性图像平均所需时间表</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="149">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     Zhao Jie, Ma Yu-jiao, Liu Shuai-qi.Image denoising optimization algorithm combined with visual saliency[J].Computer Science, 2018, 45 (2) :312-317. (in Chinese) </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     Zhang Xu-dong, L&#252; Yan-yan, Miao Yong-wei, et al.Image saliency detection using regional covariance analysis[J].Journal of Image and Graphics, 2016, 21 ( 5) :605-615. (in Chinese) </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_3" title=" Qu L, He S, Zhang J, et al.RGBD salient object detection via deep fusion[J].IEEE Transactions on Image Processing, 2017, 26 (5) :2274-2285." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;RGBD Salient Object Detection via Deep Fusion.&amp;quot;">
                                        <b>[3]</b>
                                         Qu L, He S, Zhang J, et al.RGBD salient object detection via deep fusion[J].IEEE Transactions on Image Processing, 2017, 26 (5) :2274-2285.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_4" title=" Xi T, Zhao W, Wang H, et al.Salient object detection with spatiotemporal background priors for video[J].IEEE Transactions on Image Processing, 2017, 26 (7) :3425-3436." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Salient object detection with spatiotemporal background priors for video">
                                        <b>[4]</b>
                                         Xi T, Zhao W, Wang H, et al.Salient object detection with spatiotemporal background priors for video[J].IEEE Transactions on Image Processing, 2017, 26 (7) :3425-3436.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     Cui Ling-ling, Xu Jin-lan, Xu Gang, et al.Image saliency detection method based on a pair of feature maps[J].Journal of Image and Graphics, 2018, 23 (4) :583-594. (in Chinese) </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     Itti L, Koch C, Niebur E.A model of saliency-based visual attention for rapid scene analysis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1998, 20 (11) :1254-1259.</a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_7" title=" Harel J, Koch C, Perona P.Graph-based visual saliency[C]//Proc of the 19th International Conference on in Neural Information Processing Systems, 2006:545-552." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Graph-based visual saliency">
                                        <b>[7]</b>
                                         Harel J, Koch C, Perona P.Graph-based visual saliency[C]//Proc of the 19th International Conference on in Neural Information Processing Systems, 2006:545-552.
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_8" title=" Rahtu E, Kannala J, Salo M, et al.Segmenting salient objects from images and videos[C]//Proc of the 11th European Conference on Computer Vision, 2010:366-379." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmenting salient objects from images and videos">
                                        <b>[8]</b>
                                         Rahtu E, Kannala J, Salo M, et al.Segmenting salient objects from images and videos[C]//Proc of the 11th European Conference on Computer Vision, 2010:366-379.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_9" title=" Seo H J, Milanfar P.Static and space-time visual saliency detection by self-resemblance[J].Journal of Vision, 2009, 9 (12) :1-27." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Static and space-time visual saliency detection by self-resemblance">
                                        <b>[9]</b>
                                         Seo H J, Milanfar P.Static and space-time visual saliency detection by self-resemblance[J].Journal of Vision, 2009, 9 (12) :1-27.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_10" title=" Achanta R, Estrada F, Wils P, et al.Salient region detection and segmentation[C]//Proc of the 16th International Conference on Computer Vision Systems, 2008:66-75." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Salient region detection and segmentation">
                                        <b>[10]</b>
                                         Achanta R, Estrada F, Wils P, et al.Salient region detection and segmentation[C]//Proc of the 16th International Conference on Computer Vision Systems, 2008:66-75.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_11" title=" Tavakoli H R, Rahtu E, Heikkil&#228; J.Fast and efficient saliency detection using sparse sampling and kernel density estimation[C]//Proc of the 17th Scandinavian Conference on Image Analysis, 2011:666-675." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast and efficient saliency detection using sparse sampling and kernel density estimation">
                                        <b>[11]</b>
                                         Tavakoli H R, Rahtu E, Heikkil&#228; J.Fast and efficient saliency detection using sparse sampling and kernel density estimation[C]//Proc of the 17th Scandinavian Conference on Image Analysis, 2011:666-675.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_12" title=" Hou X D, Zhang L Q.Saliency detection:A spectral residual approach[C]//Proc of 2007 IEEE Conference on Computer Vision and Pattern Recognition, 2007:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saliency detection:a spectral residual approach">
                                        <b>[12]</b>
                                         Hou X D, Zhang L Q.Saliency detection:A spectral residual approach[C]//Proc of 2007 IEEE Conference on Computer Vision and Pattern Recognition, 2007:1-8.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_13" title=" Wang Z J, Li B X.A two-stage approach to saliency detection in images[C]//Proc of IEEE International Conference on Acoustics, Speech and Signal Processing, 2008:965-968." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A two - stage approach to saliency detection in images">
                                        <b>[13]</b>
                                         Wang Z J, Li B X.A two-stage approach to saliency detection in images[C]//Proc of IEEE International Conference on Acoustics, Speech and Signal Processing, 2008:965-968.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_14" title=" Ma Y F, Zhang H J.Contrast-based image attention analysis by using fuzzy growing[C]//Proc of the 11th ACM International Conference on Multimedia, 2003:374-381." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contrast-based image attention analysis by using fuzzy growing">
                                        <b>[14]</b>
                                         Ma Y F, Zhang H J.Contrast-based image attention analysis by using fuzzy growing[C]//Proc of the 11th ACM International Conference on Multimedia, 2003:374-381.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_15" title=" Yang C, Zhang L H, Lu H C.Graph-regularized saliency detection with convex-hull-based center prior[J].IEEE Signal Processing Letters, 2013, 20 (7) :637-640." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Graph-regularized Saliency Detection withConvex-hull-based Center Prior">
                                        <b>[15]</b>
                                         Yang C, Zhang L H, Lu H C.Graph-regularized saliency detection with convex-hull-based center prior[J].IEEE Signal Processing Letters, 2013, 20 (7) :637-640.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_16" title=" Hou X D, Harel J, Koch C.Image signature:Highlighting sparse salient regions[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (1) :194-201." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Signature: Highlighting Sparse Salient Regions">
                                        <b>[16]</b>
                                         Hou X D, Harel J, Koch C.Image signature:Highlighting sparse salient regions[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (1) :194-201.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_17" title=" Jiang B W, Zhang L H, Lu H C, et al.Saliency detection via absorbing Markov chain[C]//Proc of the 2013 IEEE International Conference on Computer Vision, 2013:1665-1672." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saliency Detection via Absorbing Markov Chain">
                                        <b>[17]</b>
                                         Jiang B W, Zhang L H, Lu H C, et al.Saliency detection via absorbing Markov chain[C]//Proc of the 2013 IEEE International Conference on Computer Vision, 2013:1665-1672.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_18" title=" Murray N, Vanrell M, Otazu X, et al.Saliency estimation using a non-parametric low-level vision model[C]//Proc of 2011 IEEE Conference on Computer vision and Pattern Recognition, 2011:433-440." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saliency estimation using a non-parametric low-level vision model">
                                        <b>[18]</b>
                                         Murray N, Vanrell M, Otazu X, et al.Saliency estimation using a non-parametric low-level vision model[C]//Proc of 2011 IEEE Conference on Computer vision and Pattern Recognition, 2011:433-440.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_1" title=" 赵杰, 马玉娇, 刘帅奇.结合视觉显著性的图像去噪优化算法[J].计算机科学, 2018, 45 (2) :312-317." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201802056&amp;v=MTczMjBGckNVUkxPZVplUm1GeTdsVkxyTEx6N0JiN0c0SDluTXJZOUFZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         赵杰, 马玉娇, 刘帅奇.结合视觉显著性的图像去噪优化算法[J].计算机科学, 2018, 45 (2) :312-317.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_2" title=" 张旭东, 吕言言, 缪永伟, 等.结合区域协方差分析的图像显著性检测[J].中国图象图形学报, 2016, 21 (5) :605-615." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201605008&amp;v=MTE2NzVxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2xWTHJMUHlyZmJMRzRIOWZNcW85RmJJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         张旭东, 吕言言, 缪永伟, 等.结合区域协方差分析的图像显著性检测[J].中国图象图形学报, 2016, 21 (5) :605-615.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_5" title=" 崔玲玲, 许金兰, 徐岗, 等.融合双特征图信息的图像显著性检测方法[J].中国图象图形学报, 2018, 23 (4) :583-594." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201804013&amp;v=MTc3MTBuTXE0OUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdsVkxyTFB5cmZiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         崔玲玲, 许金兰, 徐岗, 等.融合双特征图信息的图像显著性检测方法[J].中国图象图形学报, 2018, 23 (4) :583-594.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(08),1459-1465 DOI:10.3969/j.issn.1007-130X.2019.08.017            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于邻域优化机制的图像显著性目标检测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AD%8F%E4%BC%9F%E4%B8%80&amp;code=09142217&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">魏伟一</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E7%91%9C&amp;code=34158530&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王瑜</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%AA%A6%E9%95%AD%E5%93%8D&amp;code=42704881&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">窦镭响</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%96%87%E9%9B%85%E5%AE%8F&amp;code=38202846&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文雅宏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8C%97%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0012645&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西北师范大学计算机科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在显著性目标检测中, 背景区域和前景区域区分度不高会导致检测结果不理想。针对这一问题, 提出一种基于邻域优化机制的图像显著性目标检测算法。首先对图像进行超像素分割;然后在CIELab颜色空间建立对比图和分布图, 并通过一种新的合并方式进行融合;最后在空间距离等约束下, 建立邻域更新机制, 对初始显著性图进行优化。实验对比表明, 该算法显著性目标检测效果更好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%98%BE%E8%91%97%E6%80%A7%E7%9B%AE%E6%A0%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">显著性目标;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%82%BB%E5%9F%9F%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邻域优化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%83%8F%E7%B4%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超像素;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    魏伟一 (1976-) , 男, 甘肃皋兰人, 博士, 副教授, CCF会员 (33096M) , 研究方向为数字图像处理。E-mail:wx165@qq.com通信地址:730070甘肃省兰州市西北师范大学计算机科学与工程学院;
                                </span>
                                <span>
                                    王瑜 (1992-) , 男, 陕西榆林人, 硕士生, 研究方向为数字图像处理。E-mail:1214243411@qq.com通信地址:730070甘肃省兰州市西北师范大学计算机科学与工程学院;
                                </span>
                                <span>
                                    窦镭响 (1992-) , 男, 河南沈丘人, 硕士生, 研究方向为数字图像处理。E-mail:986485610@qq.com通信地址:730070甘肃省兰州市西北师范大学计算机科学与工程学院;
                                </span>
                                <span>
                                    文雅宏 (1993-) , 男, 甘肃天水人, 硕士生, 研究方向为数字图像处理。E-mail:1172060962@qq.com通信地址:730070甘肃省兰州市西北师范大学计算机科学与工程学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-14</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61861040);</span>
                                <span>甘肃省科技计划资助项目 (17YF1FA119;</span>
                    </p>
            </div>
                    <h1><b>Salient object detection based on neighborhood optimization mechanism</b></h1>
                    <h2>
                    <span>WEI Wei-yi</span>
                    <span>WANG Yu</span>
                    <span>DOU Lei-xiang</span>
                    <span>WEN Ya-hong</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Engineering, Northwest Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In the salient object detection, the detection results are not ideal when the difference between the background region and the foreground region is not obvious. To address this problem, we propose a saliency object detection algorithm based on neighborhood optimization mechanism. Firstly, the image is segmented by super-pixels. Then, the contrast map and distribution map are established in the CIELab color space and they are merged by a new merging method. Finally, under the constraints such as spatial distance, a neighborhood updating mechanism is established to optimize the initial salient maps. Experimental results show that the algorithm is more effective in salient object detection.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=salient%20object&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">salient object;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neighborhood%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neighborhood optimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=super-pixels&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">super-pixels;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WEI Wei-yi, born in 1976, PhD, associate professor, CCF member (33096M) , his research interest includes digital image processing.Address:College of Computer Science and Engineering, Northwest Normal University, Lanzhou 730070, Gansu, P.R.China;
                                </span>
                                <span>
                                    WANG Yu, born in 1992, MS candidate, his research interest includes digital image processing.Address:College of Computer Science and Engineering, Northwest Normal University, Lanzhou 730070, Gansu, P.R.China;
                                </span>
                                <span>
                                    DOU Lei-xiang, born in 1992, MS candidate, his research interest includes digital image processing.Address:College of Computer Science and Engineering, Northwest Normal University, Lanzhou 730070, Gansu, P.R.China;
                                </span>
                                <span>
                                    WEN Ya-hong, born in 1993, MS candidate, his research interest includes digital image processing.Address:College of Computer Science and Engineering, Northwest Normal University, Lanzhou 730070, Gansu, P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-14</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="45" name="45" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="46">人类视觉系统中, 视觉注意力可以从图像中找到人类感兴趣的区域而忽略不感兴趣的区域。感兴趣区域一般是最能抓住人眼球的中间区域, 而周围区域一般属于背景, 是不感兴趣区域, 因为中间区域的事物相比其他区域事物具有差异性, 也是整幅图像中最具有价值的部分, 所以称为显著性目标<citation id="191" type="reference"><link href="149" rel="bibliography" /><link href="185" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">1</a>]</sup></citation>。图像显著性目标检测的目的是获得高质量且能够反映图像不同区域显著性程度的显著性图, 利用图像显著性图可以快速有效地处理图像中的视觉显著区域<citation id="192" type="reference"><link href="151" rel="bibliography" /><link href="187" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">2</a>]</sup></citation>。模拟生物视觉系统的视觉显著性目标检测, 已经受到计算机视觉研究人员和心理学家的广泛关注, 学者们也提出了许多显著性计算模型来减少信息冗余。同时, 显著性目标检测已应用于感兴趣的区域检测、图像分类、对象定位和图像压缩等计算机视觉任务中<citation id="193" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="47">从人类视觉注意机制的角度来看, 显著性目标检测算法分为自下向上的显著性目标检测算法和自上向下的显著性目标检测算法<citation id="194" type="reference"><link href="155" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。自上向下的显著性目标检测算法通常与特定任务相关联, 需要手动标记真值监督学习。为了更好地区分前景与背景, 引入高级信息和监督算法, 以提高显著性图的准确性。自下向上的显著性目标检测算法一般是基于低级特征信息, 并且不与特定目标相关联, 其中最重要的影响因素是对比度。现有的显著性目标区域检测算法通过计算每个图像子区域同其一定范围内的相邻区域的对比度来度量该图像子区域的显著性, 即将颜色对比度或空间距离作为区域的显著性特征<citation id="195" type="reference"><link href="157" rel="bibliography" /><link href="189" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="48">近几十年来, 许多图像显著性目标检测算法把高对比度、唯一性和独特性作为显著性线索。Itti等<citation id="196" type="reference"><link href="159" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>根据底层特征, 利用图像多尺度特征和中心与周边差原则, 提出了基于生物模型和特征理论的显著性目标检测算法, 得到一种低分辨率的目标显著性图。Harel等<citation id="197" type="reference"><link href="161" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>基于图论的算法, 利用马尔可夫链合成特征显著性图。Rahtu等<citation id="198" type="reference"><link href="163" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>将显著性度量与条件随机场模型相结合, 根据统计框架、亮度和颜色等局部特征来计算显著性, 把所得到的显著性图用于条件随机场CRF (Conditional Random Field) 模型中以定义能量最小化的分割方法, 对显著性图进行优化。Seo等<citation id="199" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>根据图像的局部回归核来测量每个像素与其周围环境的相似性, 使用“自相似性”计算视觉显著性。这些算法基本都能获得期望的检测结果, 但效率不是很高。Achanta等<citation id="200" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>利用不同局部区域与其相邻区域在亮度和色度上的对比度, 提出了一种基于图像对比度显著性目标检测算法。Tavakoli等<citation id="201" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>使用稀疏采样和核密度估计进行显著性区域估计, 提出一种基于贝叶斯框架的估计局部对比特征的显著性目标检测算法。Hou等<citation id="202" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>通过对图像的对数谱分析, 提取图像在光谱域中的光谱残差, 提出了一种快速构造空域对应显著性图的算法。Wang等<citation id="203" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了一种基于2阶段的显著性目标检测算法, 第1阶段扩展现有的频谱残差模型;第2阶段利用相关传播机制来进一步完善第1阶段的结果得到显著性图。这些算法简单、运行速度快, 具有实时性, 但准确率需要提升。Ma等<citation id="204" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>根据局部对比度分析生成一个初始显著性图, 通过模拟人的感知, 采用模糊增长从初始显著性图中提取突出的区域, 再由图像注意力分析模型提取显著性目标区域。Yang等<citation id="205" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>利用对比度、中心和平滑度先验, 提出了一种自下向上的突出物体检测算法。用对比度和兴趣点的凸包估计突出物体的中心先验来计算初始显著性图, 并通过图形正则化的连续能量函数改进初始显著性图。这2种算法使用局部对比度代替全局对比度, 时间效率高, 但丧失了图像整体信息的关联性。Hou等<citation id="206" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>在稀疏信号混合的理论框架内, 引入图像签名进行显著性目标检测。Jiang等<citation id="207" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>根据显著性目标区域与背景区域的特征差异和空间分布, 利用图模型中的马尔可夫链来构造显著性图。这2种算法的检测结果不太理想, 主要是边界不清晰、区域不完整。</p>
                </div>
                <div class="p1">
                    <p id="49">以上显著性目标检测模型虽然在某些方面已经取得了比较理想的效果, 但当图像背景或前景复杂时, 生成的显著性图会把部分背景区域突显出来, 或把前景区域与背景融合, 会使显著性目标区域的完整性降低、边界不清晰、检测结果不够准确。针对现有算法存在显著性目标区域完整性不够、边界不清楚和运算量大等问题, 本文提出了一种基于邻域优化机制的图像显著性目标检测算法SDNO (Salient object Detection based on Neighborhood Optimization) , 通过区域对比度和分布性的特征, 构造对比图和分布图并进行合并, 生成的初始显著性图有效地减少了背景区域的突出显示, 同时生成了比较完整的显著性目标区域, 根据生成的初始显著性图, 建立超像素邻域优化机制, 在空间距离等约束下, 更新每个超像素的显著性值。更新后的超像素显著性值由其当前显著性和邻域显著性共同决定, 这样可以有效避免区域的误分, 减少显著性目标区域与背景的相互融合, 图1为每阶段对应的视觉效果图。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SDNO算法视觉效果对比" src="Detail/GetImg?filename=images/JSJK201908018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SDNO算法视觉效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Visual effect of the SDNO algorithm</p>

                </div>
                <h3 id="51" name="51" class="anchor-tag"><b>2 SDNO算法</b></h3>
                <div class="p1">
                    <p id="52">首先对图像进行简单线性迭代聚类SLIC (Simple Linear Iterative Clustering) 超像素分割, 其次在CIELab颜色空间中提取超像素特征, 根据超像素之间的对比性和显著性目标区域的连续性构造对比图和分布图, 并对这2种图进行融合;最后利用邻域信息和空间距离关系对融合后的显著性图进一步优化。SDNO算法流程如图2所示。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 算法流程图" src="Detail/GetImg?filename=images/JSJK201908018_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Flowchart of SDNO algorithm</p>

                </div>
                <h4 class="anchor-tag" id="54" name="54"><b>2.1 初始显著性图的构造</b></h4>
                <div class="p1">
                    <p id="55">为了降低算法的复杂度, 本文对图像进行SLIC超像素分割处理。SLIC通过聚类使具有相似特征的相邻像素组成介于像素与目标层之间带有空间性和结构性的处理单元。SLIC分割算法能快速准确地将图像分割成均匀紧凑的超像素块, 本文采用此算法对图像做超像素分割, 通过对比度和空间分布性来确定超像素的显著性图。首先把图像<b><i>I</i></b>分割成<i>k</i>个超像素{<b><i>p</i></b><sub>1</sub>, <b><i>p</i></b><sub>2</sub>, …, <b><i>p</i></b><sub><i>k</i></sub>}, 然后在CIELab颜色空间提取每个超像素的特征。图像中, 超像素<b><i>p</i></b><sub><i>i</i></sub>的显著性取决于它与周围环境的差异, 差异越大其为显著性超像素的可能性越大。邻域超像素对其也有很大的影响, 邻域超像素距离超像素<b><i>p</i></b><sub><i>i</i></sub>越近, 则对比性越大, 即距离和显著性存在一种反比的关系。因此, 本文根据显著性与距离和对比度的关系来计算超像素<b><i>p</i></b><sub><i>i</i></sub>的局部显著性值, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>C</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mfrac><mrow><mo>-</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">l</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo>∂</mo><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mo>⋅</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57">其中, ‖<b><i>l</i></b><sub><i>i</i></sub>-<b><i>l</i></b><sub><i>j</i></sub>‖是超像素<b><i>p</i></b><sub><i>i</i></sub>和<b><i>p</i></b><sub><i>j</i></sub>之间的空间距离, <b><i>l</i></b><sub><i>i</i></sub>, <b><i>l</i></b><sub><i>j</i></sub>分别为超像素<b><i>p</i></b><sub><i>i</i></sub>和<b><i>p</i></b><sub><i>j</i></sub>的中心位置, 根据实验得到空间位置调节因子∂<sub>1</sub>=10, <b><i>c</i></b><sub><i>i</i></sub>, <b><i>c</i></b><sub><i>j</i></sub>分别为超像素<b><i>p</i></b><sub><i>i</i></sub>和<b><i>p</i></b><sub><i>j</i></sub>中像素的平均颜色特征, ‖<b><i>c</i></b><sub><i>i</i></sub>-<b><i>c</i></b><sub><i>j</i></sub>‖为超像素<b><i>p</i></b><sub><i>i</i></sub>和<b><i>p</i></b><sub><i>j</i></sub>的颜色特征的欧氏距离。</p>
                </div>
                <div class="p1">
                    <p id="58">虽然超像素的局部显著性值能表示超像素的显著性, 但对背景复杂的图像效果不佳。在图像中边界超像素属于背景的可能性比较大<citation id="208" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 像素与边界的超像素对比度越大, 其为显著性超像素的可能性就越大, 因此本文通过计算超像素与边界超像素的对比度表示局部显著性值。边界显著性对比度的计算如下:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><mi>C</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>¯</mo></mover><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">其中, <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>¯</mo></mover><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>为超像素<b><i>p</i></b><sub><i>i</i></sub>与图<b><i>I</i></b>的边界超像素特征平均值<mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>¯</mo></mover></math></mathml>的差值, <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>¯</mo></mover><mo>=</mo><mfrac><mn>1</mn><mrow><mi>l</mi><msub><mrow></mrow><mi>b</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>l</mi><msub><mrow></mrow><mi>b</mi></msub></mrow></munderover><mi mathvariant="bold-italic">c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mi>b</mi></msub></mrow></math></mathml>是边界超像素的个数。</p>
                </div>
                <div class="p1">
                    <p id="64">最后超像素<b><i>p</i></b><sub><i>i</i></sub>的对比度显著性值计算如下:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>L</mi><mi>C</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>B</mi><mi>C</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">在图像中, 显著性目标区域一般是连续的, 显著性目标区域的超像素分布比较集中;背景区域被目标区域分隔开, 背景区域的超像素分布比较分散。在空间分布上背景区域的方差高于显著性目标区域的。因此, 本文采用方差来度量区域的显著性, 超像素特征分布的空间方差的计算如下:</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>C</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mfrac><mrow><mo>-</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo>∂</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中, 超像素<b><i>p</i></b><sub><i>i</i></sub>的质心为<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mfrac><mrow><mi>m</mi><msub><mrow></mrow><mi>p</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></mfrac></mrow></mstyle><mo>, </mo><mi>m</mi><msub><mrow></mrow><mi>p</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></math></mathml>分别为超像素<b><i>p</i></b><sub><i>i</i></sub>中第<i>p</i>个像素的灰度值和位置, <i>n</i>为超像素<b><i>p</i></b><sub><i>i</i></sub>中的像素个数, ‖<b><i>s</i></b><sub><i>i</i></sub>-<b><i>s</i></b><sub><i>j</i></sub>‖为超像素<b><i>p</i></b><sub><i>i</i></sub>与超像素<b><i>p</i></b><sub><i>j</i></sub>之间的方差特征距离, <b><i>v</i></b><sub><i>i</i></sub>, <b><i>v</i></b><sub><i>j</i></sub>分别为超像素<b><i>p</i></b><sub><i>i</i></sub>与超像素<b><i>p</i></b><sub><i>j</i></sub>的方差特征相似度, 根据实验得到方差调节因子∂<sub>2</sub>=2。</p>
                </div>
                <div class="p1">
                    <p id="70">最后由每个超像素的对比度和分布性来计算显著性值, 根据人类视觉注意力机制, 对一幅图像, 人更容易注意中心的超像素, 因此采用与图像中心超像素的距离作为权重<i>w</i><sub><i>i</i></sub>, 这样可以使靠近图像中间的超像素的显著性得到加强。同时, 为了使成为显著性超像素可能性大的超像素突出显示, 本文引入变量<i>T</i><sub><i>i</i></sub>, 当超像素的显著性值大于<i>T</i><sub><i>i</i></sub>时, 属于显著性目标区域的可能性比较大, 对其突出显示, 反之, 抑制其显示。其表达式如下。</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>, </mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&gt;</mo><mi>α</mi><mi mathvariant="bold-italic">A</mi><mspace width="0.25em" /><mtext>o</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mi>β</mi><mi mathvariant="bold-italic">A</mi></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mtext>o</mtext><mtext>t</mtext><mtext>h</mtext><mtext>e</mtext><mtext>r</mtext><mtext>w</mtext><mtext>i</mtext><mtext>s</mtext><mtext>e</mtext></mtd></mtr></mtable></mrow><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72">其中, 根据实验得到显著性值调节因子<i>α</i>=0.7, <i>β</i>=0.02, <b><i>A</i></b>为图像中所有像素的颜色特征均值。</p>
                </div>
                <div class="p1">
                    <p id="73">超像素<b><i>p</i></b><sub><i>i</i></sub>显著性值的计算如下:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>C</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⋅</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>/</mo><mo>∂</mo><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>⋅</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>w</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⋅</mo><mi>Τ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.2 初始显著性图的优化</b></h4>
                <div class="p1">
                    <p id="76">为了进一步准确完整地提取显著性目标, 本文根据超像素在邻域内与其它超像素的距离关系, 提出一种迭代更新的优化策略对初始显著性图进行优化。在图像中, 由于显著性目标区域一般是连续的, 因此可以根据邻域的关系来确定每个超像素的显著性值。在每次迭代更新中, 每个超像素的下一次迭代的显著性值由其当前显著性值和邻域显著性值共同决定, 同时, 距离该超像素越近的邻域超像素对其显著性值的影响越大, 反之越小。这样可以减少显著性目标区域与邻域的差异性, 使其趋于一致, 更加紧凑突出。将超像素邻域定义为与该超像素共享边界的超像素, 邻域超像素的颜色特征和位置信息影响该超像素下一次迭代过程中的显著性, 颜色特征越相似、空间距离越近, 影响越大。根据颜色特征<i>f</i><sub><i>ij</i></sub>和位置信息<i>w</i><sub><i>ij</i></sub>建立邻域超像素之间的关系矩阵<b><i>G</i></b>=[<i>g</i><sub><i>ij</i></sub>]<sub><i>k</i>×<i>k</i></sub>, 其中, <i>g</i><sub><i>ij</i></sub>=<i>f</i><sub><i>ij</i></sub>×<i>w</i><sub><i>ij</i></sub><i>j</i>∈<image href="images/JSJK201908018_077.jpg" type="" display="inline" placement="inline"><alt></alt></image> (<i>i</i>) 0, <i>i</i>=<i>j</i> or otherwise, <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mo>-</mo><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo></mrow><mrow><mo>∂</mo><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></mfrac><mo stretchy="false">) </mo><mo>, </mo><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mo stretchy="false">∥</mo><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>, <image href="images/JSJK201908018_080.jpg" type="" display="inline" placement="inline"><alt></alt></image> (<i>i</i>) 是超像素<b><i>p</i></b><sub><i>i</i></sub>的邻域集合, 实验得颜色空间调节因子∂<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>2</mn></msubsup></mrow></math></mathml>=0.1。在初始的显著性图中, 如果超像素的显著性值接近0或1, 则此超像素成为背景或前景的概率很大, 对最终的显著性结果有很大的影响, 构建影响矩阵<b><i>O</i></b>=<i>diag</i> (<i>o</i><sub>1</sub>, <i>o</i><sub>2</sub>, …, <i>o</i><sub><i>k</i></sub>) , <i>o</i><sub><i>i</i></sub>=exp (-<b><i>v</i></b><sub><i>i</i></sub> (1-<b><i>v</i></b><sub><i>i</i></sub>) /<i>λ</i><sup>2</sup>) , 根据实验结果取<i>λ</i>=2, <b><i>v</i></b><sub><i>i</i></sub>是初始显著性图中超像素的显著性值。</p>
                </div>
                <div class="p1">
                    <p id="82">最终显著性图迭代更新公式定义如下:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">C</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">G</mi><mo>-</mo><mi mathvariant="bold-italic">D</mi><mo>+</mo><mi>μ</mi><mo>⋅</mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>μ</mi><mo>⋅</mo><mi mathvariant="bold-italic">Ο</mi><mo>⋅</mo><mi mathvariant="bold-italic">C</mi><mtext> </mtext><msup><mrow></mrow><mi>t</mi></msup><mo>+</mo><mi mathvariant="bold-italic">D</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd></mtr><mtr><mtd><mo>⋅</mo><mi mathvariant="bold-italic">G</mi><mo>⋅</mo><mi mathvariant="bold-italic">C</mi><mtext> </mtext><msup><mrow></mrow><mi>t</mi></msup></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">其中, 影响矩阵调节因子<i>μ</i>=0.1, <b><i>D</i></b>=<i>diag</i> (<i>d</i><sub>11</sub>, <i>d</i><sub>22</sub>, …, <i>d</i><sub><i>kk</i></sub>) 是一个对角矩阵, <i>d</i><sub><i>ii</i></sub>是关系矩阵中每一列元素的和, 即<i>d</i><sub><i>ii</i></sub>=∑<sub><i>j</i></sub><i>g</i><sub><i>ij</i></sub>, 当<i>t</i>=0时, <b><i>C</i></b><sup>0</sup>为初始显著性图。</p>
                </div>
                <h3 id="85" name="85" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="86">实验在<i>Windows</i> 7, 内存4 <i>GB</i>, <i>CPU</i>为<i>Intel i</i>5-2500 <i>M</i>, <i>Matlab</i>2009环境下进行, 本文算法中超像素分割数目为300, 迭代更新次数为10, 采用<i>ASD</i>和<i>ECSSD</i> 2种公开图像数据库的1 000幅图像和对应的人工标注显著性目标区域图<i>GT</i> (<i>Ground Truth</i>) 来验证算法的有效性, 并将实验结果与近几年比较经典的显著性目标检测算法<i>FES</i> (<i>Fast and Efficient Saliency detection</i>) <citation id="209" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、<i>GR</i> (<i>Graph</i>-<i>Regularized saliency detection</i>) <citation id="210" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、<i>MC</i> (<i>Markov Chain</i>) <citation id="211" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、<i>SEG</i> (<i>SEGmenting salient objects</i>) <citation id="212" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、<i>SER</i> (<i>SElf</i>-<i>Resemblance</i>) <citation id="213" type="reference"><link href="165" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、<i>SS</i> (<i>highlighting Sparse Salient regions</i>) <citation id="214" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、<i>AC</i> (<i>AChanta</i>) <citation id="215" type="reference"><link href="167" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、<i>GB</i> (<i>Graph</i>-<i>Based visual saliency</i>) <citation id="216" type="reference"><link href="161" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、<i>IG</i> (<i>salIent reGion</i>) <citation id="217" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、<i>IT</i> (<i>salIency deTection</i>) <citation id="218" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、<i>MZ</i> (<i>Ma</i>-<i>Zhang</i>) <citation id="219" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、<i>SR</i> (<i>Spectral Residual</i>) <citation id="220" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、<i>SIM</i> (<i>Saliency vIsion Model</i>) <citation id="221" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>从主观视觉和客观评价方面进行比较, 其中, 对比算法中的参数与原文保持一致, 代码均来自公开的<i>Matlab</i>源码。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>3.1 目标显著性图检测结果比较</b></h4>
                <div class="p1">
                    <p id="88">由于篇幅所限, 从2个图像数据库中挑选了6幅比较典型的图像, 用于主观视觉效果比较。图3和图4为显著性目标图的主观视觉效果图。在图3<i>a</i>中, 圆形“表盘”的颜色相对其他颜色更明显, 更能引起人的视觉注意, 其为显著性目标, 在13种对比算法中, <i>GR</i>、<i>MC</i>、<i>SEG</i>、<i>IG</i>相对其他算法检测出的显著性目标效果相对较好, 但是由于在背景中存在3个矩形的区域, 其相对背景的其他区域更突出, 在检测中和显著性目标区域一同被突出显示出来, 而本文算法只检测出显著性目标区域, 忽略了3个矩形区域, 相较对比算法, 效果更好。对图3<i>b</i>, 在14种算法的实验中, 除本文算法和<i>FES</i>算法外, 其他算法均把背景区域中的“花”检测为显著性目标, 虽然<i>FES</i>算法去除了背景区域, 但减少了显著性目标区域的面积, 因此本文算法的检测结果相对更准确。图3<i>c</i>由5种比较突出的颜色构成, 对比算法生成的显著性图中都把背景显示出来, 而本文算法只突出显示了显著性目标。</p>
                </div>
                <div class="p1">
                    <p id="89">图4中的3幅图比图3背景更复杂, 因为在图4中显著性目标区域和背景区域颜色比较接近, 区分度低, 增加了检测的难度。在图4<i>a</i>中, 显著性目标“白色的羊”和背景区域中的“白色云朵”在对比算法中被检测为相同的区域, 虽然部分对比算法 (<i>FES</i>、<i>SS</i>、<i>SER</i>) 避免了这个问题, 但是检测出的显著性目标区域不完整, 本文算法检测出来的结果更接近<i>GT</i>图。图4<i>b</i>中, 在检测过程中除<i>MC</i>算法和本文算法外, 其余算法均突出显示了背景区域, 降低了检测结果的准确性, 本文算法相对<i>MC</i>算法, 更加突出显示显著性目标区域, 抑制了周围背景区域的显示。图4<i>c</i>中, 背景区域中的“白色的花”和显著性目标区域“白色的鸟”在颜色上更接近, 因此对比算法均把“白色的花”突显出来, 而本文算法有效地避免了背景区域的干扰。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 显著性目标区域检测结果对比实验1" src="Detail/GetImg?filename=images/JSJK201908018_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 显著性目标区域检测结果对比实验1  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 3 <i>Comparison</i> 1 <i>of salient object region detection results</i></p>

                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 显著性目标区域检测结果对比实验2" src="Detail/GetImg?filename=images/JSJK201908018_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 显著性目标区域检测结果对比实验2  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 4 <i>Comparison</i> 2 <i>of salient object region detection results</i></p>

                </div>
                <div class="p1">
                    <p id="92">总之, 从显著性图检测结果可以看出, 本文算法相比其它对比算法, 显著性目标区域更突出, 检测效果更好, 并且在一定程度上抑制了背景区域的显示。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93"><b>3.2 客观评估</b></h4>
                <div class="p1">
                    <p id="94">为了客观地测试本文算法在2个数据集上的算法性能, 使用目前常用的Recall和Precision曲线以及与F-measure柱状图定量地比较本文算法与13种经典算法。在该测试方法中, 设定一个阈值<i>T</i>∈[0, 255]对生成的显著性图进行二值化分割, 并把分割后的图与<i>GT</i>图比较, 计算召回率Recall和准确率Precision。为了全面评价显著性目标区域的检测效果, 在综合召回率和准确率的基础上计算F-measure:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>β</mi><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">) </mo><mo>×</mo><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>β</mi><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>×</mo><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">其中, <i>β</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>=0.3。</p>
                </div>
                <div class="p1">
                    <p id="98">图5～图8分别是在<i>ASD</i>和<i>ECSSD</i>数据库上得到的测试性能图, 从图5和图7可以看出本文算法明显优于其它对比算法, 图5中本文算法的曲线虽然与<i>MC</i>算法的几乎重合。但是, 图6的柱状图数据表明, 本文算法的平均准确率 (0.9191) 和F值 (0.8234) 均高于其它算法的, 其中<i>MC</i>算法的平均准确率和F值分别为0.810 5, 0.819 5, 低于本文算法的。图7中, 从Recall=0.39开始本文算法的Precision低于<i>MC</i>算法的, 图8的柱状图数据表明, 本文算法的平均召回率 (0.5849) 、平均准确率 (0.7425) 和F值 (0.6688) 高于其它算法的, 其中<i>MC</i>算法的平均召回率、平均准确率和F值分别为0.564 1, 0.719 0, 0.609 5, 均低于本文算法的。综上所述, 本文算法的性能优于其它算法的, 能更好地突出显示显著性目标区域, 提高了显著性目标区域检测的准确性。</p>
                </div>
                <div class="area_img" id="99">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 在ASD数据集上不同算法的 准确率和召回率曲线图" src="Detail/GetImg?filename=images/JSJK201908018_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 在<i>ASD</i>数据集上不同算法的 准确率和召回率曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_099.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 5 Precision <i>and</i> Recall <i>curves of</i><i>different algorithms on the ASD dataset</i></p>

                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 在ASD数据集上不同算法的准确率、召回率和F值" src="Detail/GetImg?filename=images/JSJK201908018_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 在<i>ASD</i>数据集上不同算法的准确率、召回率和F值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 6 Precision, Recall <i>rate and</i> F-measure  <i>of different algorithms on the ASD dataset</i></p>

                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 在ECSSD数据集上不同算法的 准确率和召回率曲线图" src="Detail/GetImg?filename=images/JSJK201908018_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 在<i>ECSSD</i>数据集上不同算法的 准确率和召回率曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 7 Precision <i>and</i> Recall <i>curves of</i><i>different algorithms on the ECSSD databset</i></p>

                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201908018_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 在ECSSD数据集上不同算法的准确率、召回率和F值" src="Detail/GetImg?filename=images/JSJK201908018_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 在<i>ECSSD</i>数据集上不同算法的准确率、召回率和F值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201908018_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 8 Precision, Recall <i>rate and</i>  F-measure <i>of different algorithms on the ECSSD database</i></p>

                </div>
                <h4 class="anchor-tag" id="103" name="103"><b>3.3 算法复杂度评估</b></h4>
                <div class="p1">
                    <p id="104">本文算法和对比算法的<i>Matlab</i>源码产生一幅显著性图像平均所需时间如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="105">从表1中可以看出, 本文算法所用时间为2.43 <i>s</i>, 其中用<i>SLIC</i>算法对图像进行超像素分割所用时间为1.46 <i>s</i>, 虽然本文算法总时间略高于其他部分对比算法, 但本文算法的量化评价指标占优, 综合而言, 本文算法仍然具有一定的优势。</p>
                </div>
                <div class="area_img" id="106">
                    <p class="img_tit"><b>表1 不同算法产生一幅显著性图像平均所需时间表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Average time required for different algorithms to produce a salient image</b></p>
                    <p class="img_note"></p>
                    <table id="106" border="1"><tr><td><br />算法</td><td>时间</td><td>算法</td><td>时间</td></tr><tr><td><br />FES</td><td>0.55</td><td>GB</td><td>2.47</td></tr><tr><td><br />MC</td><td>0.26</td><td>IT</td><td>0.83</td></tr><tr><td><br />SEG</td><td>8.05</td><td>MZ</td><td>0.19</td></tr><tr><td><br />SER</td><td>1.70</td><td>SR</td><td>0.16</td></tr><tr><td><br />SS</td><td>0.49</td><td>SM</td><td>1.63</td></tr><tr><td><br />AC</td><td>0.34</td><td>SDNO</td><td>2.43</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="108" name="108" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="109">本文根据超像素与邻域和边缘超像素的对比性以及显著性目标区域的连续性和背景区域的分散性, 构造一个初始的显著性图, 再利用邻域和距离的关系来优化初始显著性图。在标准图像数据库上测试, 用召回率、准确率和<i>F</i>值进行度量, 结果显示本文算法显著性目标检测效果更好, 显著性目标区域检测的准确性更高。下一步工作是将所提的显著性目标检测算法应用到具体的任务中, 如图像检索等, 同时分析更丰富的显著性特征, 来提高显著性区域和背景区域区分度低的图像检测结果的准确性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="145" type="formula" href="images/JSJK201908018_14500.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">魏伟一</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="146" type="formula" href="images/JSJK201908018_14600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">王瑜</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="147" type="formula" href="images/JSJK201908018_14700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">窦镭响</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="148" type="formula" href="images/JSJK201908018_14800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">文雅宏</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="149">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 Zhao Jie, Ma Yu-jiao, Liu Shuai-qi.Image denoising optimization algorithm combined with visual saliency[J].Computer Science, 2018, 45 (2) :312-317. (in Chinese) 
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 Zhang Xu-dong, Lü Yan-yan, Miao Yong-wei, et al.Image saliency detection using regional covariance analysis[J].Journal of Image and Graphics, 2016, 21 ( 5) :605-615. (in Chinese) 
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;RGBD Salient Object Detection via Deep Fusion.&amp;quot;">

                                <b>[3]</b> Qu L, He S, Zhang J, et al.RGBD salient object detection via deep fusion[J].IEEE Transactions on Image Processing, 2017, 26 (5) :2274-2285.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Salient object detection with spatiotemporal background priors for video">

                                <b>[4]</b> Xi T, Zhao W, Wang H, et al.Salient object detection with spatiotemporal background priors for video[J].IEEE Transactions on Image Processing, 2017, 26 (7) :3425-3436.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 Cui Ling-ling, Xu Jin-lan, Xu Gang, et al.Image saliency detection method based on a pair of feature maps[J].Journal of Image and Graphics, 2018, 23 (4) :583-594. (in Chinese) 
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 Itti L, Koch C, Niebur E.A model of saliency-based visual attention for rapid scene analysis[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1998, 20 (11) :1254-1259.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Graph-based visual saliency">

                                <b>[7]</b> Harel J, Koch C, Perona P.Graph-based visual saliency[C]//Proc of the 19th International Conference on in Neural Information Processing Systems, 2006:545-552.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmenting salient objects from images and videos">

                                <b>[8]</b> Rahtu E, Kannala J, Salo M, et al.Segmenting salient objects from images and videos[C]//Proc of the 11th European Conference on Computer Vision, 2010:366-379.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Static and space-time visual saliency detection by self-resemblance">

                                <b>[9]</b> Seo H J, Milanfar P.Static and space-time visual saliency detection by self-resemblance[J].Journal of Vision, 2009, 9 (12) :1-27.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Salient region detection and segmentation">

                                <b>[10]</b> Achanta R, Estrada F, Wils P, et al.Salient region detection and segmentation[C]//Proc of the 16th International Conference on Computer Vision Systems, 2008:66-75.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast and efficient saliency detection using sparse sampling and kernel density estimation">

                                <b>[11]</b> Tavakoli H R, Rahtu E, Heikkilä J.Fast and efficient saliency detection using sparse sampling and kernel density estimation[C]//Proc of the 17th Scandinavian Conference on Image Analysis, 2011:666-675.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saliency detection:a spectral residual approach">

                                <b>[12]</b> Hou X D, Zhang L Q.Saliency detection:A spectral residual approach[C]//Proc of 2007 IEEE Conference on Computer Vision and Pattern Recognition, 2007:1-8.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A two - stage approach to saliency detection in images">

                                <b>[13]</b> Wang Z J, Li B X.A two-stage approach to saliency detection in images[C]//Proc of IEEE International Conference on Acoustics, Speech and Signal Processing, 2008:965-968.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contrast-based image attention analysis by using fuzzy growing">

                                <b>[14]</b> Ma Y F, Zhang H J.Contrast-based image attention analysis by using fuzzy growing[C]//Proc of the 11th ACM International Conference on Multimedia, 2003:374-381.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Graph-regularized Saliency Detection withConvex-hull-based Center Prior">

                                <b>[15]</b> Yang C, Zhang L H, Lu H C.Graph-regularized saliency detection with convex-hull-based center prior[J].IEEE Signal Processing Letters, 2013, 20 (7) :637-640.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Signature: Highlighting Sparse Salient Regions">

                                <b>[16]</b> Hou X D, Harel J, Koch C.Image signature:Highlighting sparse salient regions[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (1) :194-201.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saliency Detection via Absorbing Markov Chain">

                                <b>[17]</b> Jiang B W, Zhang L H, Lu H C, et al.Saliency detection via absorbing Markov chain[C]//Proc of the 2013 IEEE International Conference on Computer Vision, 2013:1665-1672.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saliency estimation using a non-parametric low-level vision model">

                                <b>[18]</b> Murray N, Vanrell M, Otazu X, et al.Saliency estimation using a non-parametric low-level vision model[C]//Proc of 2011 IEEE Conference on Computer vision and Pattern Recognition, 2011:433-440.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201802056&amp;v=MTc4MjhIOW5Nclk5QVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2xWTHJMTHo3QmI3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 赵杰, 马玉娇, 刘帅奇.结合视觉显著性的图像去噪优化算法[J].计算机科学, 2018, 45 (2) :312-317.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201605008&amp;v=MjI2Mjk5Zk1xbzlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bFZMckxQeXJmYkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 张旭东, 吕言言, 缪永伟, 等.结合区域协方差分析的图像显著性检测[J].中国图象图形学报, 2016, 21 (5) :605-615.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201804013&amp;v=MjYyNzhyTFB5cmZiTEc0SDluTXE0OUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdsVkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 崔玲玲, 许金兰, 徐岗, 等.融合双特征图信息的图像显著性检测方法[J].中国图象图形学报, 2018, 23 (4) :583-594.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201908018" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201908018&amp;v=MDU4MDJDVVJMT2VaZVJtRnk3bFZMcklMejdCWmJHNEg5ak1wNDlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
