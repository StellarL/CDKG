<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132373478936250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201907024%26RESULT%3d1%26SIGN%3d0PpkTeV%252bG0xzr%252bgXoefy8cS9bjs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907024&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907024&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907024&amp;v=MjA5Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVzc3T0x6N0JaYkc0SDlqTXFJOUhZSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="&lt;b&gt;2 老挝语分词网络模型框架与流程&lt;/b&gt; "><b>2 老挝语分词网络模型框架与流程</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="&lt;b&gt;2.1 划分老挝语音节序列&lt;/b&gt;"><b>2.1 划分老挝语音节序列</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.2 词向量技术&lt;/b&gt;"><b>2.2 词向量技术</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;2.3 BLSTM神经网络&lt;/b&gt;"><b>2.3 BLSTM神经网络</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;2.4 标签推断&lt;/b&gt;"><b>2.4 标签推断</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#78" data-title="&lt;b&gt;3 实验及分析&lt;/b&gt; "><b>3 实验及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="&lt;b&gt;3.1 语料预处理&lt;/b&gt;"><b>3.1 语料预处理</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;3.2 实验设计与评估指标&lt;/b&gt;"><b>3.2 实验设计与评估指标</b></a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;3.3 实验结果分析&lt;/b&gt;"><b>3.3 实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="图1 老挝语分词框架">图1 老挝语分词框架</a></li>
                                                <li><a href="#62" data-title="图2 老挝语字母表">图2 老挝语字母表</a></li>
                                                <li><a href="#72" data-title="图3 音节标注语料">图3 音节标注语料</a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;表1 BLSTM与其他分词方法的实验结果对比&lt;/b&gt;"><b>表1 BLSTM与其他分词方法的实验结果对比</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;表2 不同规模的训练语料的实验结果对比&lt;/b&gt;"><b>表2 不同规模的训练语料的实验结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="123">


                                    <a id="bibliography_1" title=" Zhang Liang-min.Lao practical grammar [M].Beijing:Foreign Language Teaching and Research Press, 2009. (in Chinese) " target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lao practical grammar">
                                        <b>[1]</b>
                                         Zhang Liang-min.Lao practical grammar [M].Beijing:Foreign Language Teaching and Research Press, 2009. (in Chinese) 
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_2" title=" Yang Bei.The reseach of Lao word segmentation and part of speech tagging[D].Kunming:Kunming University of Science and Technology, 2016. (in Chinese) " target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The reseach of Lao word segmentation and part of speech tagging">
                                        <b>[2]</b>
                                         Yang Bei.The reseach of Lao word segmentation and part of speech tagging[D].Kunming:Kunming University of Science and Technology, 2016. (in Chinese) 
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_3" title=" Xue N, Converse S P.Combining classifiers for Chinese word segmentation[C]//Proc of the 1st SIGHAN Workshop on Chinese Language Processing, 2002:57-63." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining classifiers for Chinese word segmentation">
                                        <b>[3]</b>
                                         Xue N, Converse S P.Combining classifiers for Chinese word segmentation[C]//Proc of the 1st SIGHAN Workshop on Chinese Language Processing, 2002:57-63.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_4" title=" Vanthanavong S, Haruechaiyasak C.LaoWS:Lao word segmentation based on conditional random fields[C]//Proc of Conference on Human Language Technology for Development, 2011:21-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lao Word Segmentation Based on Conditional Random Fields">
                                        <b>[4]</b>
                                         Vanthanavong S, Haruechaiyasak C.LaoWS:Lao word segmentation based on conditional random fields[C]//Proc of Conference on Human Language Technology for Development, 2011:21-26.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_5" title=" Peng F C, Feng F F, McCallum A.Chinese segmentation and new word detection using conditional random fields[C]//Proc of the 20th International Conference on Computational Linguistics, 2004:562-568." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Chinese segmentation and new word detection using conditional random fields">
                                        <b>[5]</b>
                                         Peng F C, Feng F F, McCallum A.Chinese segmentation and new word detection using conditional random fields[C]//Proc of the 20th International Conference on Computational Linguistics, 2004:562-568.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_6" title=" Liu Qun, Zhang Hua-ping, Yu Hong-kui, et al.Chinese lexical analysis using cascaded hidden Markov model[J].Journal of Computer Research and Development, 2004, 41 (8) :1421-1429. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200408017&amp;v=MjIzMjNTZExHNEh0WE1wNDlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bVc3N0JMeXY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Liu Qun, Zhang Hua-ping, Yu Hong-kui, et al.Chinese lexical analysis using cascaded hidden Markov model[J].Journal of Computer Research and Development, 2004, 41 (8) :1421-1429. (in Chinese) 
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_7" title=" Xue N, Shen L.Chinese word segmentation as LMR tagging[C]//Proc of SIGHAN Workshop on Chinese Language Processing, 2003:176-179." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Chinese word segmentation as LMR tagging">
                                        <b>[7]</b>
                                         Xue N, Shen L.Chinese word segmentation as LMR tagging[C]//Proc of SIGHAN Workshop on Chinese Language Processing, 2003:176-179.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     Collobert R, Weston J, Bottou L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12 (8) :2493-2537.</a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     Zheng X, Chen H, Xu T.Deep learning for Chinese word segmentation and POS tagging[C]//Proc of the 2013 Conference on Empirical Methods in Natural Language Processing, 2013:647-657.</a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_10" title=" Chen Xin-chi, Qin Xi-peng, Zhu Chen-xi, et al.Long short-term memory neural networks for Chinese word segmentation[C]//Proc of the 2015 Conferenee on Empirical Methods in Natural Language Processing, 2015:1197-1206." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Long Short-Term Memory Neural Networks for Chinese Word Segmentation">
                                        <b>[10]</b>
                                         Chen Xin-chi, Qin Xi-peng, Zhu Chen-xi, et al.Long short-term memory neural networks for Chinese word segmentation[C]//Proc of the 2015 Conferenee on Empirical Methods in Natural Language Processing, 2015:1197-1206.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_11" title=" Zhang Hong-gang, Li Huan.Chinese word segmentation method on the basis of bidirectional long-short term memory model [J].Journal of South China University of Technology (Natural Science Edition) , 2017, 45 (3) :61-67. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNLG201703009&amp;v=MDQzOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVzc3QkxTUEhhYkc0SDliTXJJOUZiWVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Zhang Hong-gang, Li Huan.Chinese word segmentation method on the basis of bidirectional long-short term memory model [J].Journal of South China University of Technology (Natural Science Edition) , 2017, 45 (3) :61-67. (in Chinese) 
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_12" title=" Phissamay P, Dalolay V, Chanhsililath C, et al.Syllabification of Lao script for line breaking:Technical report of STEA, Lao PDR[R].[S.l.]:Science Technology and Environment Agency, 2004." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Syllabification of Lao script for line breaking:Technical report of STEA,Lao PDR">
                                        <b>[12]</b>
                                         Phissamay P, Dalolay V, Chanhsililath C, et al.Syllabification of Lao script for line breaking:Technical report of STEA, Lao PDR[R].[S.l.]:Science Technology and Environment Agency, 2004.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_13" title=" Xiao Li-hai.Lao (Volume 1) [M].Beijing:Foreign Language Teaching and Research Press, 1988. (in Chinese) " target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lao">
                                        <b>[13]</b>
                                         Xiao Li-hai.Lao (Volume 1) [M].Beijing:Foreign Language Teaching and Research Press, 1988. (in Chinese) 
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_14" title=" Huang Yong, Qin Hai-lun, Boli&#183;Bapapan.Basic Lao (1) [M].Beijing:World Book Publishing Corporation, 2013. (in Chinese) " target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Boli Bapapan.Basic Lao (1)">
                                        <b>[14]</b>
                                         Huang Yong, Qin Hai-lun, Boli&#183;Bapapan.Basic Lao (1) [M].Beijing:World Book Publishing Corporation, 2013. (in Chinese) 
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_15" title=" Santos C N D, Xiang B, Zhou B.Classifying relations by ranking with convolutional neural networks[J].ArXiv:1504.06580v1, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classifying relations by ranking with convolutional neural networks">
                                        <b>[15]</b>
                                         Santos C N D, Xiang B, Zhou B.Classifying relations by ranking with convolutional neural networks[J].ArXiv:1504.06580v1, 2015.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_16" title=" Huang Z, Xu W, Yu K.Bidirectional LSTM-CRF models for sequence tagging[J].arXiv:1508.01991, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF models for sequence tagging">
                                        <b>[16]</b>
                                         Huang Z, Xu W, Yu K.Bidirectional LSTM-CRF models for sequence tagging[J].arXiv:1508.01991, 2015.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     张良民.老挝语实用语法[M].北京:外语教学与研究出版社, 2009.</a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_2" title=" 杨蓓.老挝语分词和词性标注方法研究[D].昆明:昆明理工大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016229683.nh&amp;v=MzAxNjBGckNVUkxPZVplUm1GeTdtVzc3QlZGMjZHTEc2RjlmRXJKRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         杨蓓.老挝语分词和词性标注方法研究[D].昆明:昆明理工大学, 2016.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     刘群, 张华平, 俞鸿魁, 等.基于层叠隐马模型的汉语词法分析[J].计算机研究与发展, 2004, 41 (8) :1421-1429.</a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     张洪刚, 李焕.基于双向长短时记忆模型的中文分词方法[J].华南理工大学学报 (自然科学版) , 2017, 45 (3) :61-67.</a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_13" title=" 肖礼海.老挝语 (第一册) [M].北京:外语教学与研究出版社, 1988." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=000756000394X999&amp;v=MzI2NzBkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkN2dFU3bkxLRjhkVlYyN0diYStIdEhNcklaQkRPSUdCUk04enhVU21E&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         肖礼海.老挝语 (第一册) [M].北京:外语教学与研究出版社, 1988.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_14" title=" 黄勇, 覃海伦, 波里&#183;巴帕潘.基础老挝语 (1) [M].北京:世界图书出版公司, 2013." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787510059322000&amp;v=MTE0NzVQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3Z0VTduTEtGOGRYRnF6R2JhNUh0SEpwb3hIWnVz&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         黄勇, 覃海伦, 波里&#183;巴帕潘.基础老挝语 (1) [M].北京:世界图书出版公司, 2013.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(07),1312-1317 DOI:10.3969/j.issn.1007-130X.2019.07.024            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于双向长短期记忆神经网络的老挝语分词方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E5%8A%9B&amp;code=42267115&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何力</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E5%85%B0%E6%B1%9F&amp;code=07894197&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周兰江</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E6%9E%AB&amp;code=08529670&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周枫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E5%89%91%E6%AF%85&amp;code=07895859&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭剑毅</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%98%86%E6%98%8E%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0242668&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">昆明理工大学信息工程与自动化学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>作为语言最小独立运行且有意义的单位, 将连续型的老挝语划分成词是非常有必要的。提出一种基于双向长短期记忆BLSTM神经网络模型的老挝语分词方法, 使用包含913 487个词的人工分词语料来训练模型, 将老挝语分词任务转化为基于音节的序列标注任务, 即将老挝语音节标注为词首 (B) 、词中 (M) 、词尾 (E) 和单独成词 (S) 4个标签。首先将老挝语句子划分成音节并训练成向量, 然后把这些向量作为BLSTM神经网络模型的输入来预估该音节所属标签, 再使用序列推断算法确定其标签, 最后使用人工标注的分词语料进行实验。实验表明, 基于双向长短期记忆神经网络的老挝语分词方法在准确率上达到了87.48%, 效果明显好于以往的分词方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9F%B3%E8%8A%82&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">音节;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E5%90%91%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双向长短期记忆;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%80%81%E6%8C%9D%E8%AF%AD%E5%88%86%E8%AF%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">老挝语分词;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    何力 (1991-) , 男, 陕西榆林人, 硕士, 研究方向为自然语言处理和信息检索。E-mail:helicopterup@163.com通信地址:650500云南省昆明市呈贡区昆明理工大学信息工程与自动化学院;
                                </span>
                                <span>
                                    周兰江 (1964-) , 男, 云南玉溪人, 硕士, 副教授, 研究方向为自然语言处理和信息检索。E-mail:915090822@qq.com通信地址:650500云南省昆明市呈贡区昆明理工大学信息工程与自动化学院;
                                </span>
                                <span>
                                    周枫 (1958-) , 男, 云南昆明人, 硕士, 副教授, 研究方向为自然语言处理和信息检索。E-mail:1143713448@qq.com通信地址:650500云南省昆明市呈贡区昆明理工大学信息工程与自动化学院;
                                </span>
                                <span>
                                    郭剑毅 (1964-) , 女, 云南昆明人, 硕士, 教授, 研究方向为自然语言处理和信息提取。E-mail:Gjade86@hotmail.com通信地址:650500云南省昆明市呈贡区昆明理工大学信息工程与自动化学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61662040, 61562049);</span>
                    </p>
            </div>
                    <h1><b>A Lao word segmentation method based on bidirectional long-short term memory neural network model</b></h1>
                    <h2>
                    <span>HE Li</span>
                    <span>ZHOU Lan-jiang</span>
                    <span>ZHOU Feng</span>
                    <span>GUO Jian-yi</span>
            </h2>
                    <h2>
                    <span>Faculty of Information Engineering and Automation, Kunming University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>It is necessary to divide the continuous Lao language into words, which are the smallest independent and meaningful unit of language. We propose a Lao word segmentation method based on bidirectional long-short term memory (BLSTM) neural network model. The model is trained from a Lao corpus that contains 913487 manually tagged words. In this model, the Lao word segmentation task can be transformed into a syllable-based sequential tagging task, in which a Lao syllable is labeled as four tags: begin-word (B) , middle-word (M) , end-word (E) and single-word (S) . Firstly, Lao sentences are divided into syllables and the syllables are trained into vectors. Secondly, as the input of the BLSTM neural network model, these vectors are used to predict the label of the syllable. Thirdly, the sequence inference algorithm is used to determine the label of the syllable. We carry out experiments on the manually labeled word-segmentation corpus. Experimental results show that the proposal has an accuracy of 87.48%, which is obviously better than that of existing word segmentation methods.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=syllable&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">syllable;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=bidirectional%20long-short%20term%20memory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">bidirectional long-short term memory;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Lao%20word%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Lao word segmentation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    HE Li, born in 1991, MS, his research interests include natural language processing, and information retrieval.Address:Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Chenggong District, Kunming 650500, Yunnan, P.R.China;
                                </span>
                                <span>
                                    ZHOU Lan-jiang, born in 1964, MS, associate professor, his research interests include natural language processing, and information re-trieval.Address:Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Chenggong District, Kunming 650500, Yunnan, P.R.China;
                                </span>
                                <span>
                                    ZHOU Feng, born in 1958, MS, associate professor, his research interests include natural language processing, and information retrieval.Address:Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Chenggong District, Kunming 650500, Yunnan, P.R.China;
                                </span>
                                <span>
                                    GUO Jian-yi, born in 1964, MS, professor, her research interests include natural language processing, and information extraction.Address:Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Chenggong District, Kunming 650500, Yunnan, P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-07-18</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="48">老挝语分词就是将一连串的老挝语字符按一定的规则划分成单个老挝词语序列的过程。老挝语句子与汉语句子相似, 在结构上是连续的, 词与词之间没有明显的分隔符, 因此对老挝语进行分词是分析老挝语文本信息的基础。老挝语分词是文本分类、命名实体识别、词性标注及词向量等老挝语机器学习工作的重要前期准备工作。目前, 老挝语分词方面的研究成果甚少, 主要集中于基于词典的字符串匹配模型和个别机器学习方法, 其缺点是对词典中未收录的词语识别度低, 并且依赖大量复杂的人工设计的特征。深度神经网络的强大学习能力使得计算机能够自动识别词语界线, 从而在一定程度上解决未收录词问题以及减少更多的人工成本。老挝文是由元音、辅音、尾辅音和声调组成的多音节文字<citation id="167" type="reference"><link href="123" rel="bibliography" /><link href="155" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">1</a>]</sup></citation>, 因此本文将老挝语按照音节粒度进行分词遵循了其语言本身的内在客观规律。</p>
                </div>
                <div class="p1">
                    <p id="49">老挝语分词的问题主要在于如何根据上下文意思有效识别词语的边界, 目前主要有以下2种方法能够解决这一问题: (1) 基于词典的字符串匹配方法; (2) 基于更小粒度字符标注的机器学习方法。基于词典匹配的方法严重依赖于所构建词典的规则, 优点是实现和部署相对容易且分词准确率较高, 但是其不足也很明显, 不能解决分词歧义, 对词典中未收录的词识别率低, 如果所依赖的词典中收录的词语不全面, 将大大影响其分词的准确率。杨蓓<citation id="168" type="reference"><link href="125" rel="bibliography" /><link href="157" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">2</a>]</sup></citation>提出的分词方法在使用词典分词的基础上, 利用人工构建的错误词典和规则对分词结果进行2次校正, 以提高准确率, 虽然取得了不错的效果, 但其依赖的特定错误词典不仅构建复杂, 而且有很大的局限性, 从而无法在实质上解决未收录词和歧义问题。基于标注的机器学习方法是将分词过程转化为一个更小粒度字符序列标注的过程<citation id="169" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 即为每个更小的粒度赋予一个标记, 将分词工作转化为有监督的分类问题, 此类方法能够很好地解决词典中未登录词和分词歧义的问题。Vanthanavong等人<citation id="170" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>使用条件随机场模型对老挝语进行分词, 其准确率达到了80.29%, 该方法在不依赖特征的情况下, 利用音节上下文标签出现的概率来识别未登录词和消除分词歧义。但是, 基于统计的模型仍然无法通过使用长距离的上下文语义信息有效解决分词歧义问题。</p>
                </div>
                <div class="p1">
                    <p id="50">中文分词方面, 条件随机场<citation id="171" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、隐马尔科夫<citation id="172" type="reference"><link href="133" rel="bibliography" /><link href="159" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">6</a>]</sup></citation>和最大熵<citation id="173" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等主流统计机器学习方法被用于中文分词序列标注模型当中, 但是这些模型依赖于人工筛选的特征, 而特征筛选是一个庞大的工程。近年来, 深层神经网络<citation id="174" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>的发展为计算机自动学习文本特征提供了便利, 这大大减少了人工筛选特征的工作量。Zheng等人<citation id="175" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>首次将神经网络用到中文分词工作上, 在不损失分词准确率的情况下, 应用感知器算法加速了整个训练过程。Chen等人<citation id="176" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将长短期记忆神经网络用于中文分词, 并取得了不错的效果。张洪刚等人<citation id="177" type="reference"><link href="143" rel="bibliography" /><link href="161" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">11</a>]</sup></citation>提出了基于双向长短时记忆模型的中文分词方法, 使得句子的上下文信息得到更充分的利用。</p>
                </div>
                <div class="p1">
                    <p id="51">受以上启发, 本文提出使用BLSTM (Bidirectional Long-Short Term Memory) 神经网络模型并以音节为标注单位, 采用词首B (Begin) 、词中M (Middle) 、词尾E (End) 和单独成词S (Single) 4词位标注的老挝语分词方法。老挝语词汇由单音节的单纯词和多音节的连绵词组成<citation id="178" type="reference"><link href="123" rel="bibliography" /><link href="155" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">1</a>]</sup></citation>, 因此以音节作为标注单位符合老挝语语言规范, BLSTM神经网络模型可以自动识别并保留音节所在的整个句子的特征信息, 使用其强大的学习能力, 不仅可以通过学习音节在词语中的位置特性来从方法上更出色地辨别词边界和未登录词, 而且其保留的音节所在句子的上下文语义信息能够从本质上解决分词歧义的问题。通过在老挝语分词语料上进行的实验表明, 本文提出的分词方法比其他分词方法有着更优表现, 分词准确率达到了87.48%。</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag"><b>2 老挝语分词网络模型框架与流程</b></h3>
                <div class="p1">
                    <p id="53">将老挝语分词看做是一个以音节为基本单位的序列标注过程, 使用BMES 4词位的标注方法对音节进行标注, 其中B表示该音节位于词汇的首位, M表示位于中间, E表示位于结尾, S表示该音节单独成词。</p>
                </div>
                <div class="p1">
                    <p id="54">以音节作为最小粒度基于BLSTM神经网络模型的架构主要由4部分组成:第1部分将老挝语句子划分为音节序列;第2部分使用词向量技术 (Word Embedding) 将音节文本向量化;第3部分为BLSTM神经网络结构;第4部分为标签推断, 推断出音节所属标签。具体框架如图1所示。</p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907024_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 老挝语分词框架" src="Detail/GetImg?filename=images/JSJK201907024_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 老挝语分词框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907024_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Framework of Lao word segmentation</p>

                </div>
                <div class="p1">
                    <p id="56">根据老挝语音节规则将待分词的老挝语句子按照音节字典分成一个由<i>n</i>个音节组成的序列<i>c</i> (1:<i>n</i>) , 对于一个音节选择其左右两边距离为 (<i>w</i>-1) /2的音节与本身组成长度为<i>w</i>的词窗。按以上方法将长度为<i>w</i>中的每一个音节文本表示成<i>d</i>维的向量<b><i>v</i></b><sub><i>i</i></sub>, 将<i>w</i>个向量合成<i>w</i>*<i>d</i>的输入矩阵<b><i>x</i></b> (<i>t</i>) 作为神经网络的输入层。从输入层到隐藏层的函数为:</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">z</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">x</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">其中, <b><i>z</i></b> (<i>t</i>) 表示隐藏层的输出矩阵, <i>σ</i> (<i>x</i>) 为激活函数, <b><i>w</i></b><sub>1</sub>表示输入层到隐藏层的权值矩阵, <b><i>b</i></b><sub>1</sub>表示输入层到隐藏层的偏置矩阵。这里使用tanh函数作为激活函数。</p>
                </div>
                <div class="p1">
                    <p id="59">隐藏层到输出层的函数为:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">y</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>2</mn></msub><mi mathvariant="bold-italic">h</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mn>2</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">其中, <b><i>h</i></b> (<i>t</i>) 表示从隐藏层到输出层的输入矩阵, <b><i>w</i></b><sub>2</sub>和<b><i>b</i></b><sub>2</sub>分别表示隐藏层到输出层的权值矩阵和偏置矩阵, <b><i>y</i></b> (<i>t</i>) 为当前音节对应各标签的概率矩阵。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907024_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 老挝语字母表" src="Detail/GetImg?filename=images/JSJK201907024_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 老挝语字母表  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907024_062.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 2 <i>Alphabet of Lao language</i></p>

                </div>
                <div class="p1">
                    <p id="63">本文提出的老挝语分词模型, 将上述的传统分词网络模型中的神经网络部分使用<i>BLSTM</i>神经网络替换, 其优点是能够保留较长距离的依赖信息, 可以收集到每个音节更全面的上下文特征。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64"><b>2.1 划分老挝语音节序列</b></h4>
                <div class="p1">
                    <p id="65">老挝语是一种孤立型语言<citation id="179" type="reference"><link href="123" rel="bibliography" /><link href="155" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">1</a>]</sup></citation>, 共有元音28个、辅音32个、辅音韵尾8个和声调4个。另外, 还有不常用的17个复合辅音, 具体如图2所示。作为一个语言单位, 音节可能有意义也可能没有意义, 一个语言单位可以由一个或者多个音节组成<citation id="180" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。根据文献<citation id="181" type="reference">[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">13</a>,<a class="sup">14</a>]</citation>, 老挝语的音节规则包括辅音加声调、辅音与元音相拼、辅音与元音相拼加声调、辅音与元音相拼加死闭音节、辅音与元音相拼加活闭音节及辅音与元音相拼加活闭音节加声调所构成的音节拼写规则, 其中需特别注意的有辅音与特殊元音相拼时不能加尾辅音, 辅音与单元音、复合元音相拼加死闭音节时不能加声调, 声调符号位于辅音字母的上方, 如辅音字母上方有元音字母, 则位于元音字母上方。</p>
                </div>
                <div class="p1">
                    <p id="66">本文使用文献<citation id="182" type="reference">[<a class="sup">12</a>]</citation>中的老挝语音节化方法将待分词的老挝语句子划分成由音节组成的序列, 该方法利用老挝语音节构成的规则和条件, 提出了一种老挝字符串音节化算法, 其准确率达到了98%。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.2 词向量技术</b></h4>
                <div class="p1">
                    <p id="68">词向量在自然语言处理方面应用越来越广泛, 是神经网络必要的前期文本处理技术。老挝语中大多数词汇是单音节的单纯词, 因此低维、稠密、连续的向量表示方法分布式表示 (<i>Distributed Representation</i>) 能够很好地刻画音节之间的关联性, 意思相近的音节距离也相近, 同时低维、稠密的向量能大大减少计算的复杂度。</p>
                </div>
                <div class="p1">
                    <p id="69">有研究表明, 使用分布式表示的词向量作为输入矩阵能够更好地提升模型的性能<citation id="183" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70"><b>2.3 BLSTM神经网络</b></h4>
                <div class="p1">
                    <p id="71">为避免循环神经网络<i>RNN</i> (<i>Recurrent Neural Network</i>) 训练时会出现梯度消失与梯度爆炸而无法很好处理远距离依赖问题, 研究者提出长短期记忆网络<i>LSTM</i> (<i>Long Short</i>-<i>Term Memony</i>) 来解决这一问题, 它通过加入记忆单元来过滤历史信息并根据新信息更新记忆单元。<i>LSTM</i>解决了保存长距离信息的问题, 但是作为<i>RNN</i>网络的变种, <i>LSTM</i>也只能使用当前音节序列中的前导信息, 而不能利用后续的音节信息。音节在句子中的特征应该由前导和后续2个方面的信息决定。双向长短期记忆网络<i>BLSTM</i> (<i>Bidirectional LSTM</i>) <citation id="184" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>有效地解决了这一问题, 其核心思想是使用2个隐藏层分别保存来自序列中2个方面的输入信息, 然后将对应的输出信息连接到同一个输出层。因此, <i>BLSTM</i>可以有效地将当前音节序列上下文的信息应用到老挝语分词任务中。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907024_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 音节标注语料" src="Detail/GetImg?filename=images/JSJK201907024_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 音节标注语料  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907024_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 3 <i>Syllable labeled corpus</i></p>

                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>2.4 标签推断</b></h4>
                <div class="p1">
                    <p id="74">为了构建标签间的依赖, 标签推断部分使用动态规划的维特比算法推断音节序列<i>c</i> (1:<i>n</i>) 最有可能的标签序列<i>y</i> (1:<i>n</i>) , 引入转移得分矩阵<b><i>A</i></b><sub><i>ij</i></sub>来评估标签<i>i</i>到标签<i>j</i>的概率。序列级概率由转移概率与网络标注概率求和得到, 其计算公式如下所示:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mo stretchy="false"> (</mo><mi>c</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>n</mi><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>:</mo><mi>n</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>A</mi><msub><mrow></mrow><mrow><mi>y</mi><mo stretchy="false"> (</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mi>y</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msub><mo>+</mo><mi>y</mi><msubsup><mrow></mrow><mrow><mi>y</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">其中, <i>A</i><sub><i>y</i> (<i>t</i>-1) <i>y</i> (<i>t</i>) </sub>表示前一标签到当前标签的转换概率, <i>y</i><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>y</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>表示神经网络层输出的标注概率矩阵中各标签对应的概率, 由公式 (2) 计算得出。</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag"><b>3 实验及分析</b></h3>
                <div class="p1">
                    <p id="79">本文使用<i>word</i>2<i>vec</i>来向量化音节, 长度为250维, 使用基于<i>Python</i>的深度学习库<i>Keras</i>实现<i>BLSTM</i>神经网络, 其隐藏层单元数为64, <i>dropout</i>值为0.2。</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80"><b>3.1 语料预处理</b></h4>
                <div class="p1">
                    <p id="81">由于本文采用的老挝语分词方法依赖基于音节标注的分词语料, 而老挝语没有相应的已标注语料, 因此需要对原始的分词语料 (包括互联网上获取到的老挝语分词及词性标注语料2 112个长句子, 以及老挝语语言专家人工分词的67 784个短句子, 共计913 487词) 进行处理, 处理过程如下所示:</p>
                </div>
                <div class="p1">
                    <p id="82"> (1) 整理语料:对老挝语分词语料进行降噪, 去掉<i>unicode</i>编码为<i>u</i>200<i>b</i>等特殊字符, 并将语料中的词语使用空格隔开;</p>
                </div>
                <div class="p1">
                    <p id="83"> (2) 划分音节:将分词语料中的词语按照文献<citation id="185" type="reference">[<a class="sup">4</a>]</citation>中的方法划分为1个或多个音节;</p>
                </div>
                <div class="p1">
                    <p id="84"> (3) 音节标注:将音节按照第1节中提到的方法进行<i>BMES</i>标注, 音节与标签之间使用“+”号连接, 标注部分结果如图3所示。</p>
                </div>
                <div class="p1">
                    <p id="85">以上过程所形成的标注语料中的90%作为训练语料用于神经网络模型的训练, 10%作为测试语料用于测试模型性能。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>3.2 实验设计与评估指标</b></h4>
                <div class="p1">
                    <p id="87"><b>实验1</b> 设计实验对比本文方法与其他老挝语分词方法的性能。利用测试语料评估本文方法的分词性能, 其结果与文献<citation id="186" type="reference">[<a class="sup">2</a>,<a class="sup">2</a>]</citation>中基于规模为31 719词的词典分词方法和文献<citation id="187" type="reference">[<a class="sup">4</a>]</citation>中基于条件随机场的老挝语分词方法进行对比。</p>
                </div>
                <div class="p1">
                    <p id="88"><b>实验2</b> 设计实验对比不同规模的训练语料对分词结果的影响。分别使用30%, 50%, 70%和90%的标注语料来训练模型, 然后利用测试语料进行实验, 观察不同规模的训练语料对分词性能的影响。</p>
                </div>
                <div class="p1">
                    <p id="89">本文使用常用的指标准确率P (<i>Precision</i>) 、召回率R (<i>Recall</i>) 和F1值来评估分词方法的性能。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>3.3 实验结果分析</b></h4>
                <div class="p1">
                    <p id="91">实验1的结果如表1所示。由表1可知, 本文分词方法的效果要明显好于<i>Vanthanavong</i>等人<citation id="188" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>的基于条件随机场的老挝语分词方法。杨蓓<citation id="189" type="reference"><link href="125" rel="bibliography" /><link href="157" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">2</a>]</sup></citation>的方法是在基于词典匹配的分词基础上加入了人工设计的错误词典和规则校正2个特征, 与该方法相比, 本文方法在没有进行特征工程构建的情况下, 分词准确率比该方法高1.39%。该实验结果充分表明了深度学习在老挝语分词任务中的合理性与优越性。</p>
                </div>
                <div class="area_img" id="92">
                    <p class="img_tit"><b>表1 BLSTM与其他分词方法的实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Comparison of experimental results between the BLSTM and other word segmentation methods</b></p>
                    <p class="img_note"></p>
                    <table id="92" border="1"><tr><td><br />模型</td><td><i>P</i></td><td><i>R</i></td><td><i>F</i>1</td></tr><tr><td><br />文献[2]</td><td>0.860 9</td><td>--</td><td>--</td></tr><tr><td><br />文献[4]</td><td>0.802 8</td><td>0.784 5</td><td>0.793 6</td></tr><tr><td><br />BLSTM</td><td>0.874 8</td><td>0.871 2</td><td>0.873 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="93">实验2的结果如表2所示。由表2可知, 分词的准确率与训练语料的规模成正比。实验结果表明, 训练语料规模越大分词效果越好, 因此扩大训练语料的规模是十分必要的。而由实验结果可知, 十万级别的语料增长对结果的提升已非常之小, 根据文献<citation id="190" type="reference">[<a class="sup">9</a>]</citation>和文献<citation id="191" type="reference">[<a class="sup">11</a>,<a class="sup">11</a>]</citation>中的实验结果推测, 要达到95%以上的分词准确率至少需要千万级别的分词语料。</p>
                </div>
                <div class="area_img" id="94">
                    <p class="img_tit"><b>表2 不同规模的训练语料的实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Comparison of experimental results of training corpus of different sizes</b></p>
                    <p class="img_note"></p>
                    <table id="94" border="1"><tr><td><br />训练语料规模/%</td><td><i>P</i></td><td><i>R</i></td><td><i>F</i>1</td></tr><tr><td><br />30</td><td>0.824 1</td><td>0.805 0</td><td>0.814 4</td></tr><tr><td><br />50</td><td>0.829 2</td><td>0.803 1</td><td>0.815 9</td></tr><tr><td><br />70</td><td>0.836 2</td><td>0.832 0</td><td>0.814 1</td></tr><tr><td><br />90</td><td>0.874 8</td><td>0.871 2</td><td>0.873 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="95">本文提出的老挝语分词方法虽然能达到很好的分词效果, 但仍存在一些问题, 在做了充分的错误分析之后发现, 本文方法对语料中占比较少的阿拉伯数字、英文命名实体和多个连续的单音节成词的情况识别度较差, 此问题可以通过增加训练语料的规模来实现, 而老挝语由于受众小, 分词语料库的构建缓慢且困难, 因此还需融入更有效的特征词典来进一步提升性能。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="97">本文介绍了一种基于双向长短期记忆神经网络的老挝语分词方法。首先将老挝语句子切分成音节序列, 然后对其进行向量化表示并作为神经网络的输入计算其输出, 最后使用标签推断算法确定音节对应的标签, 从而达到分词的目的。本文设计的实验1显示出深度学习在老挝语分词方面的可行性与优越性, 本文方法在避免了繁杂的特征工程的情况下, 不仅保证了较高的准确率, 而且性能明显好于其他分词方法的;实验2表明了语料规模对分词结果的重要性, 本文方法依然有很大的提升空间, 今后应当继续进一步扩充老挝语分词语料。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="193" type="formula" href="images/JSJK201907024_19300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">何力</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="195" type="formula" href="images/JSJK201907024_19500.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">周兰江</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="197" type="formula" href="images/JSJK201907024_19700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">周枫</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="199" type="formula" href="images/JSJK201907024_19900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">郭剑毅</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="123">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lao practical grammar">

                                <b>[1]</b> Zhang Liang-min.Lao practical grammar [M].Beijing:Foreign Language Teaching and Research Press, 2009. (in Chinese) 
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The reseach of Lao word segmentation and part of speech tagging">

                                <b>[2]</b> Yang Bei.The reseach of Lao word segmentation and part of speech tagging[D].Kunming:Kunming University of Science and Technology, 2016. (in Chinese) 
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining classifiers for Chinese word segmentation">

                                <b>[3]</b> Xue N, Converse S P.Combining classifiers for Chinese word segmentation[C]//Proc of the 1st SIGHAN Workshop on Chinese Language Processing, 2002:57-63.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lao Word Segmentation Based on Conditional Random Fields">

                                <b>[4]</b> Vanthanavong S, Haruechaiyasak C.LaoWS:Lao word segmentation based on conditional random fields[C]//Proc of Conference on Human Language Technology for Development, 2011:21-26.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Chinese segmentation and new word detection using conditional random fields">

                                <b>[5]</b> Peng F C, Feng F F, McCallum A.Chinese segmentation and new word detection using conditional random fields[C]//Proc of the 20th International Conference on Computational Linguistics, 2004:562-568.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200408017&amp;v=MTIzNjJ2U2RMRzRIdFhNcDQ5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21XNzdCTHk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Liu Qun, Zhang Hua-ping, Yu Hong-kui, et al.Chinese lexical analysis using cascaded hidden Markov model[J].Journal of Computer Research and Development, 2004, 41 (8) :1421-1429. (in Chinese) 
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Chinese word segmentation as LMR tagging">

                                <b>[7]</b> Xue N, Shen L.Chinese word segmentation as LMR tagging[C]//Proc of SIGHAN Workshop on Chinese Language Processing, 2003:176-179.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 Collobert R, Weston J, Bottou L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12 (8) :2493-2537.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 Zheng X, Chen H, Xu T.Deep learning for Chinese word segmentation and POS tagging[C]//Proc of the 2013 Conference on Empirical Methods in Natural Language Processing, 2013:647-657.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Long Short-Term Memory Neural Networks for Chinese Word Segmentation">

                                <b>[10]</b> Chen Xin-chi, Qin Xi-peng, Zhu Chen-xi, et al.Long short-term memory neural networks for Chinese word segmentation[C]//Proc of the 2015 Conferenee on Empirical Methods in Natural Language Processing, 2015:1197-1206.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HNLG201703009&amp;v=MDA5NzdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21XNzdCTFNQSGFiRzRIOWJNckk5RmI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Zhang Hong-gang, Li Huan.Chinese word segmentation method on the basis of bidirectional long-short term memory model [J].Journal of South China University of Technology (Natural Science Edition) , 2017, 45 (3) :61-67. (in Chinese) 
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Syllabification of Lao script for line breaking:Technical report of STEA,Lao PDR">

                                <b>[12]</b> Phissamay P, Dalolay V, Chanhsililath C, et al.Syllabification of Lao script for line breaking:Technical report of STEA, Lao PDR[R].[S.l.]:Science Technology and Environment Agency, 2004.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lao">

                                <b>[13]</b> Xiao Li-hai.Lao (Volume 1) [M].Beijing:Foreign Language Teaching and Research Press, 1988. (in Chinese) 
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Boli Bapapan.Basic Lao (1)">

                                <b>[14]</b> Huang Yong, Qin Hai-lun, Boli·Bapapan.Basic Lao (1) [M].Beijing:World Book Publishing Corporation, 2013. (in Chinese) 
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classifying relations by ranking with convolutional neural networks">

                                <b>[15]</b> Santos C N D, Xiang B, Zhou B.Classifying relations by ranking with convolutional neural networks[J].ArXiv:1504.06580v1, 2015.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF models for sequence tagging">

                                <b>[16]</b> Huang Z, Xu W, Yu K.Bidirectional LSTM-CRF models for sequence tagging[J].arXiv:1508.01991, 2015.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 张良民.老挝语实用语法[M].北京:外语教学与研究出版社, 2009.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016229683.nh&amp;v=MTI3NzBSbUZ5N21XNzdCVkYyNkdMRzZGOWZFckpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 杨蓓.老挝语分词和词性标注方法研究[D].昆明:昆明理工大学, 2016.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 刘群, 张华平, 俞鸿魁, 等.基于层叠隐马模型的汉语词法分析[J].计算机研究与发展, 2004, 41 (8) :1421-1429.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 张洪刚, 李焕.基于双向长短时记忆模型的中文分词方法[J].华南理工大学学报 (自然科学版) , 2017, 45 (3) :61-67.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=000756000394X999&amp;v=MDk4MzdyaWZadTl1RkN2dFU3bkxLRjhkVlYyN0diYStIdEhNcklaQkRPSUdCUk04enhVU21EZDlTSDduM3hFOWZidm5L&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 肖礼海.老挝语 (第一册) [M].北京:外语教学与研究出版社, 1988.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787510059322000&amp;v=MDg4Mzk1SHRISnBveEhadXNQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3Z0VTduTEtGOGRYRnF6R2Jh&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 黄勇, 覃海伦, 波里·巴帕潘.基础老挝语 (1) [M].北京:世界图书出版公司, 2013.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201907024" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907024&amp;v=MjA5Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVzc3T0x6N0JaYkc0SDlqTXFJOUhZSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
