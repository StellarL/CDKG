<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132348307217500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201910008%26RESULT%3d1%26SIGN%3ds7JTZTa0xjoPocWDtBJPH3lAlKA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201910008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201910008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201910008&amp;v=MTc1NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pMejdCWmJHNEg5ak5yNDlGYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#64" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="&lt;b&gt;2 相关理论&lt;/b&gt; "><b>2 相关理论</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="&lt;b&gt;2.1 STN网络结构&lt;/b&gt;"><b>2.1 STN网络结构</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;2.2 LSTM网络结构&lt;/b&gt;"><b>2.2 LSTM网络结构</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;2.3 ConvLSTM网络结构&lt;/b&gt;"><b>2.3 ConvLSTM网络结构</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="&lt;b&gt;3 基于面部动作时空特征的疲劳预警算法&lt;/b&gt; "><b>3 基于面部动作时空特征的疲劳预警算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="&lt;b&gt;3.1 基于S-CNN结构的人脸检测算法&lt;/b&gt;"><b>3.1 基于S-CNN结构的人脸检测算法</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;3.2 基于SCL结构的面部状态预测算法&lt;/b&gt;"><b>3.2 基于SCL结构的面部状态预测算法</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;3.3 面部特征点提取&lt;/b&gt;"><b>3.3 面部特征点提取</b></a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;3.4 基于PERCLOS标准及嘴部开合统计的疲劳检测&lt;/b&gt;"><b>3.4 基于PERCLOS标准及嘴部开合统计的疲劳检测</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="&lt;b&gt;4 实验分析&lt;/b&gt; "><b>4 实验分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#133" data-title="&lt;b&gt;4.1 人脸检测实验与结果分析&lt;/b&gt;"><b>4.1 人脸检测实验与结果分析</b></a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;4.2 状态预测实验与结果分析&lt;/b&gt;"><b>4.2 状态预测实验与结果分析</b></a></li>
                                                <li><a href="#154" data-title="&lt;b&gt;4.3 眼部与嘴部综合疲劳检测实验分析&lt;/b&gt;"><b>4.3 眼部与嘴部综合疲劳检测实验分析</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;4.4 预警结果实验分析&lt;/b&gt;"><b>4.4 预警结果实验分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#165" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="图1 STN结构">图1 STN结构</a></li>
                                                <li><a href="#84" data-title="图2 LSTM 网络结构">图2 LSTM 网络结构</a></li>
                                                <li><a href="#85" data-title="图4 本文算法流程">图4 本文算法流程</a></li>
                                                <li><a href="#90" data-title="图3 &lt;i&gt;ConvLSTM&lt;/i&gt;内部结构">图3 <i>ConvLSTM</i>内部结构</a></li>
                                                <li><a href="#97" data-title="图5 S-CNN网络结构">图5 S-CNN网络结构</a></li>
                                                <li><a href="#102" data-title="图6 SCL内部结构">图6 SCL内部结构</a></li>
                                                <li><a href="#114" data-title="图7 人脸特征点检测">图7 人脸特征点检测</a></li>
                                                <li><a href="#120" data-title="图8 人眼特征点检测">图8 人眼特征点检测</a></li>
                                                <li><a href="#128" data-title="图9 嘴唇轮廓示意图">图9 嘴唇轮廓示意图</a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表1 实验者的数据收集情况&lt;/b&gt;"><b>表1 实验者的数据收集情况</b></a></li>
                                                <li><a href="#138" data-title="图10 测试集上&lt;i&gt;MSE&lt;/i&gt;结果对比">图10 测试集上<i>MSE</i>结果对比</a></li>
                                                <li><a href="#152" data-title="图11 各网络上实验对比分析">图11 各网络上实验对比分析</a></li>
                                                <li><a href="#158" data-title="图12 &lt;i&gt;w&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;、&lt;i&gt;w&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;值寻优">图12 <i>w</i><sub>1</sub>、<i>w</i><sub>2</sub>值寻优</a></li>
                                                <li><a href="#162" data-title="图13 &lt;i&gt;t&lt;/i&gt;-2时刻至&lt;i&gt;t&lt;/i&gt;时刻内预警点位置">图13 <i>t</i>-2时刻至<i>t</i>时刻内预警点位置</a></li>
                                                <li><a href="#164" data-title="图14 预警点准确率结果">图14 预警点准确率结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="249">


                                    <a id="bibliography_1" title="Wang Lin,Zhang Chen,Yin Xiao-wei,et al.A non-contact driving fatigue detection technique based on driver’s physiological signals[J].Automotive Engineering,2018,40(3):333-341.(in Chinese）" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QCGC201803014&amp;v=Mjg2MTZWYi9KTkM3TWJiRzRIOW5Nckk5RVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2c=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Wang Lin,Zhang Chen,Yin Xiao-wei,et al.A non-contact driving fatigue detection technique based on driver’s physiological signals[J].Automotive Engineering,2018,40(3):333-341.(in Chinese）
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_2" title="Li Jiang-tian,Li Min,Song Zhan-bing.Driving fatigue detection based on multi-source physiological signal[J].Logistics Technology,2018,37(2):78-83.(in Chinese）" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLJS201802017&amp;v=Mjg1MDc0SDluTXJZOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVmIvSk1pSEJmYkc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Li Jiang-tian,Li Min,Song Zhan-bing.Driving fatigue detection based on multi-source physiological signal[J].Logistics Technology,2018,37(2):78-83.(in Chinese）
                                    </a>
                                </li>
                                <li id="253">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                    Li Hong-tao,Ba Xing-qiang,Lu Zhao-you,et al.Highway driving state detection method based on steering wheel signal[J].Shanxi Architecture,2018,44(28):110-112.(in Chinese）</a>
                                </li>
                                <li id="255">


                                    <a id="bibliography_4" >
                                        <b>[4]</b>
                                    Tang Yang-shan,Xu zhong-shuai,Yang Yu-yao.Driver fatigue detection based on head pose for eye differential positioning[J].Science Technology and Engineering,2018,18(31):235-239.(in Chinese）</a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_5" title="Cai Jia.Research on fatigue driving recognition based on human eye state detection[D].Shijiazhuang:Hebei University of Science and Technology,2018.(in Chinese）" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Research on fatigue driving recognition based on human eye state detection">
                                        <b>[5]</b>
                                        Cai Jia.Research on fatigue driving recognition based on human eye state detection[D].Shijiazhuang:Hebei University of Science and Technology,2018.(in Chinese）
                                    </a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                    Zhao Xue-peng,Meng Chun-ning,Feng Ming-kui,et al.Fatigue detection based on cascade convolutional nerual network[J].Journal of Optoelectronics&#183;Laser,2017,28(5):497-502.(in Chinese）</a>
                                </li>
                                <li id="261">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                    Lu Wei,Hu Hai-yang,Wang Jia-peng,et al.Tractor driver fatigue detection based on convolution neural network and facial image recognition[J].Transactions of the Chinese Society of Agricultural Engineering,2018,34(7):192-199.(in Chinese）</a>
                                </li>
                                <li id="263">


                                    <a id="bibliography_8" title="Yu Ming,An Meng-tao,Liu Yi.Facial expression recognition based on multiple features and convolutional neural networks[J].Science Technology and Engineering,2018,18(13):104-110.(in Chinese）" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201813017&amp;v=MTQzMzQvZ1ZiL0pMalhCZmJHNEg5bk5ySTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Yu Ming,An Meng-tao,Liu Yi.Facial expression recognition based on multiple features and convolutional neural networks[J].Science Technology and Engineering,2018,18(13):104-110.(in Chinese）
                                    </a>
                                </li>
                                <li id="265">


                                    <a id="bibliography_9" title="Liu Jun-chao,Chen Zhi-jun,Fan Xiao-chao,et al.Eye detection based on deep convolutional nerual networks[J].Modern Electronics Technique,2018,41(18):72-75.(in Chinese）" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201818017&amp;v=MjYwMzQvZ1ZiL0pQU25QWkxHNEg5bk5wNDlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Liu Jun-chao,Chen Zhi-jun,Fan Xiao-chao,et al.Eye detection based on deep convolutional nerual networks[J].Modern Electronics Technique,2018,41(18):72-75.(in Chinese）
                                    </a>
                                </li>
                                <li id="267">


                                    <a id="bibliography_10" title="Ji Qiu-min,Zhang Ling,Luo Yuan,et al.Mental fatigue detection based on multi-inter-domain optical flow characterisitics[J].Computer Engineering and Design,2018,39(8):2582-2586.(in Chinese）" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201808032&amp;v=Mjc4MjJDVVJMT2VaZVJtRnkvZ1ZiL0pOaWZZWkxHNEg5bk1wNDlHWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Ji Qiu-min,Zhang Ling,Luo Yuan,et al.Mental fatigue detection based on multi-inter-domain optical flow characterisitics[J].Computer Engineering and Design,2018,39(8):2582-2586.(in Chinese）
                                    </a>
                                </li>
                                <li id="269">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                    Geng Lei,Liang Xiao-yu,Xiao Zhi-tao,et al.Real-time driver fatigue detection based on morphology infrared features and deep learning[J].Infrared and Laser Engineering,2018,47(2):60-68.(in Chinese）</a>
                                </li>
                                <li id="271">


                                    <a id="bibliography_12" title="Jaderberg M,Simonyan K,Zisserman A,et al.Spatial transformer networks[C]∥Proc of the 28th International Conference on NIPS,2015:2017-2025．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial transformer networks">
                                        <b>[12]</b>
                                        Jaderberg M,Simonyan K,Zisserman A,et al.Spatial transformer networks[C]∥Proc of the 28th International Conference on NIPS,2015:2017-2025．
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_13" title="Liang X,Liang L,Shen X,et al.Interpretable structure-evolving LSTM[C]∥Proc of 2017IEEE Conference on Computer Vision and Pattern Recognition,2017:1010-1019．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interpretable Structure-evolving LSTM">
                                        <b>[13]</b>
                                        Liang X,Liang L,Shen X,et al.Interpretable structure-evolving LSTM[C]∥Proc of 2017IEEE Conference on Computer Vision and Pattern Recognition,2017:1010-1019．
                                    </a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_14" title="Zafeiriou S,Chrysos G G,Roussos A,et al.The 3D menpo facial landmark tracking challenge[C]∥Proc of IEEE International Conference on Computer Vision,2017:2503-2511．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The 3D menpo facial landmark tracking challenge">
                                        <b>[14]</b>
                                        Zafeiriou S,Chrysos G G,Roussos A,et al.The 3D menpo facial landmark tracking challenge[C]∥Proc of IEEE International Conference on Computer Vision,2017:2503-2511．
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_15" title="Fang Z,Su J,Lei G,et al.Driver fatigue detection based on eye state recognition[C]∥Proc of International Conference on Machine Vision&amp;amp;Information Technology,2017:105-110．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Driver fatigue detection based on eye state recognition">
                                        <b>[15]</b>
                                        Fang Z,Su J,Lei G,et al.Driver fatigue detection based on eye state recognition[C]∥Proc of International Conference on Machine Vision&amp;amp;Information Technology,2017:105-110．
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_16" title="Hafizoglu F,Kucukoglu E C,Altingovde I S.On the efficiency of selective search[C]∥Proc of European Conference on Information Retrieval,2017:705-712．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the efficiency of selective search">
                                        <b>[16]</b>
                                        Hafizoglu F,Kucukoglu E C,Altingovde I S.On the efficiency of selective search[C]∥Proc of European Conference on Information Retrieval,2017:705-712．
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_17" title="Soukupov&#225; T,Cech J.Real-time eye blink detection using facial landmarks[C]∥Proc of the 21st Computer Vision Winter Workshop,2016:1-6．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-Time Eye Blink Detection using Facial Landmarks">
                                        <b>[17]</b>
                                        Soukupov&#225; T,Cech J.Real-time eye blink detection using facial landmarks[C]∥Proc of the 21st Computer Vision Winter Workshop,2016:1-6．
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_18" title="Conneau A,Schwenk H,Barrault L,et al.Very deep convolutional networks for text classification[C]∥Proc of Conference of the European Chapter of the Association for Computational Lingusitics,2017:1107-1116．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for text classification">
                                        <b>[18]</b>
                                        Conneau A,Schwenk H,Barrault L,et al.Very deep convolutional networks for text classification[C]∥Proc of Conference of the European Chapter of the Association for Computational Lingusitics,2017:1107-1116．
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_19" title="Dai Shi-qi,Zeng Zhi-yong.Fatigue driving detection algorithm based on deep learning[J].Computer System&amp;amp;Applications,2018,27(7):113-120.(in Chinese）" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201807017&amp;v=MjkzNDJuU2Q3RzRIOW5NcUk5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYi9KUFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        Dai Shi-qi,Zeng Zhi-yong.Fatigue driving detection algorithm based on deep learning[J].Computer System&amp;amp;Applications,2018,27(7):113-120.(in Chinese）
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                    王琳，张陈，尹晓伟，等．一种基于驾驶员生理信号的非接触式驾驶疲劳检测技术[J]．汽车工程，2018,40(3):333-341．</a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                    李江天，李敏，宋战兵．基于多源生理信号的驾驶疲劳检测[J]．物流技术，2018,37(2):78-83．</a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_3" title="李洪涛，巴兴强，逯兆友，等．基于方向盘信号的高速公路驾驶状态检测方法[J]．山西建筑，2018,44(28):110-112．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZSX201828058&amp;v=MjgzMDRSTE9lWmVSbUZ5L2dWYi9KTHpmWWRyRzRIOW5PcDQ5QWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        李洪涛，巴兴强，逯兆友，等．基于方向盘信号的高速公路驾驶状态检测方法[J]．山西建筑，2018,44(28):110-112．
                                    </a>
                                </li>
                                <li id="293">


                                    <a id="bibliography_4" title="唐阳山，徐忠帅，杨语尧．基于头部姿态眼睛差分定位的驾驶员疲劳检测[J]．科学技术与工程，2018,18(31):235-239．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201831037&amp;v=MzAyNDZHNEg5blBybzlHWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pMalhCZmI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        唐阳山，徐忠帅，杨语尧．基于头部姿态眼睛差分定位的驾驶员疲劳检测[J]．科学技术与工程，2018,18(31):235-239．
                                    </a>
                                </li>
                                <li id="295">


                                    <a id="bibliography_5" title="蔡伽．基于人眼状态检测的疲劳驾驶识别研究[D]．石家庄：河北科技大学，2018．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018027863.nh&amp;v=MTYxNDZPNkdkbktySkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pWRjI2RnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        蔡伽．基于人眼状态检测的疲劳驾驶识别研究[D]．石家庄：河北科技大学，2018．
                                    </a>
                                </li>
                                <li id="297">


                                    <a id="bibliography_6" title="赵雪鹏，孟春宁，冯明奎，等．基于级联卷积神经网络的疲劳检测[J]．光电子&#183;激光，2017,28(5):497-502．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201705008&amp;v=MDM5NTlKSWluUlpMRzRIOWJNcW85RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYi8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        赵雪鹏，孟春宁，冯明奎，等．基于级联卷积神经网络的疲劳检测[J]．光电子&#183;激光，2017,28(5):497-502．
                                    </a>
                                </li>
                                <li id="299">


                                    <a id="bibliography_7" title="卢伟，胡海阳，王家鹏，等．基于卷积神经网络面部图像识别的拖拉机驾驶员疲劳检测[J]．农业工程学报，2018,34(7):192-199．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201807025&amp;v=MzIzMTVxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYi9KS3pUTWU3RzRIOW5NcUk5SFlZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        卢伟，胡海阳，王家鹏，等．基于卷积神经网络面部图像识别的拖拉机驾驶员疲劳检测[J]．农业工程学报，2018,34(7):192-199．
                                    </a>
                                </li>
                                <li id="301">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                    于明，安梦涛，刘依．基于多特征与卷积神经网络的人脸表情识别[J]．科学技术与工程，2018,18(13):104-110．</a>
                                </li>
                                <li id="303">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                    刘俊超，陈志军，樊小朝，等．基于深度卷积神经网络的人眼检测[J]．现代电子技术，2018,41(18):72-75．</a>
                                </li>
                                <li id="305">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                    姬秋敏，张灵，罗源，等．基于多帧间区域性光流特征的精神疲劳检测[J]．计算机工程与设计，2018,39(8):2582-2586．</a>
                                </li>
                                <li id="307">


                                    <a id="bibliography_11" title="耿磊，梁晓昱，肖志涛，等．基于多形态红外特征与深度学习的实时驾驶员疲劳检测[J]．红外与激光工程，2018,47(2):60-68．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201802010&amp;v=MTE3MThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pMVHJTWkxHNEg5bk1yWTlFWkk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        耿磊，梁晓昱，肖志涛，等．基于多形态红外特征与深度学习的实时驾驶员疲劳检测[J]．红外与激光工程，2018,47(2):60-68．
                                    </a>
                                </li>
                                <li id="309">


                                    <a id="bibliography_19" >
                                        <b>[19]</b>
                                    戴诗琪，曾智勇．基于深度学习的疲劳驾驶检测算法[J]．计算机系统应用，2018,27(7):113-120.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(10),1763-1770 DOI:10.3969/j.issn.1007-130X.2019.10.007            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于面部动作时空特征的疲劳预警算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%81%E6%9D%BE&amp;code=10159226&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郁松</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E9%9C%96%E8%83%A4&amp;code=43026336&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢霖胤</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%8D%97%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=0193746&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中南大学软件学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>目前疲劳预警算法多采用实时监测报警的方式,这在高速行驶中具有很大的安全隐患。鉴于人类疲劳状态的时序相关性,提出一种基于面部动作时空特征提取的预警算法。首先,构建加入空间变换结构的卷积神经网络,识别人脸区域,对脸部特征点进行检测标记;其次,建立时空特征提取网络,利用采集的人脸图像序列,对未来图像序列进行预测并输出;最后,在输出的图像序列中根据眼部、嘴部综合状态判断是否发出警告。实验结果表明,以15 fps的速率采集图像,预测未来2 s 30帧图像的方式下,该算法能以90%以上的准确率提前26帧(约1.5 s)预警,且提前15帧(1 s)预警的准确率达到97%。在我国高速公路平均100 km/h的车速下,相当于提前40 m预警,能进一步减少交通事故的发生。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%96%B2%E5%8A%B3%E9%A2%84%E8%AD%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">疲劳预警;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E7%A9%BA%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时空特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%8A%B6%E6%80%81%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">状态预测;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郁松（1974-），男，湖南长沙人，博士，副教授，CCF会员（E200012136M），研究方向为数据挖掘和图像处理。E-mail:8190185@qq.com，通信地址:410083湖南省长沙市中南大学软件学院&lt;image id="246" type="formula" href="images/JSJK201910008_24600.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    卢霖胤（1993-），男，湖南岳阳人，硕士生，研究方向为深度学习和图像处理。E-mail:2329845446@qq.com，通信地址:410083湖南省长沙市中南大学软件学院&lt;image id="248" type="formula" href="images/JSJK201910008_24800.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-08</p>

                    <p>

                            <b>基金：</b>
                                                        <span>湖南省自然科学基金(S2018JJMSXM0177);</span>
                    </p>
            </div>
                    <h1><b>A fatigue warning algorithm based on spatiotemporal feature extraction of facial motion</b></h1>
                    <h2>
                    <span>YU Song</span>
                    <span>LU Lin-yin</span>
            </h2>
                    <h2>
                    <span>School of Software Engineering,Central South University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>At present, the fatigue early warning algorithm mostly adopts real-time monitoring and alarming, which has great security risks in the high-speed driving environment. In view of the temporal correlation of human fatigue state, this paper proposes an early warning algorithm based on spatiotemporal feature extraction of facial motion. Firstly, a convolutional neural network with spatial transformation structure is constructed to identify the face region and detect and mark the facial feature points. Secondly, a spatiotemporal feature extraction network is established, and the real-time acquired facial image feature sequence is used to predict and output the future image sequence. Finally, in the outputted image sequence, the comprehensive states of eyes and mouth are used to determine whether a fatigue warning is issued or not.Experimental results show that, under the condition that the image is acquired at 15 frames per second and the 30 frames in the future 2 seconds are predicted, the proposed algorithm can achieve the accuracy of more than 90% when issuing a fatigue warning 26 frames(about 1.5 seconds) in advance, and the accuracy of 97% when issuing a fatigue warning 15 frames(1 second) in advance. Under the average speed of 100 km/h in China's expressways, it is equivalent to an early warning of 40 meters in advance, which can further reduce the occurrence of traffic accidents.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fatigue%20warning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fatigue warning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spatiotemporal%20feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spatiotemporal feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=state%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">state prediction;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YU Song,born in 1974,PhD,associate professor,CCF member(E200012136M),his research interests include data mining,and image processing.Address:School of Software Engineering,Central South University,Changsha 410083,Hunan,P.R.China;
                                </span>
                                <span>
                                    LU Lin-yin,born in 1993,MS candidate,his research interests include deep learning,and image processing.Address:School of Software Engineering,Central South University,Changsha 410083,Hunan,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-03-08</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="64" name="64" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="65">目前,被用于疲劳驾驶检测的方法主要有3类:第1类方法根据人类在疲劳时产生的生理信息,包括脑电图、心电图以及肌电特征等进行预测<citation id="312" type="reference"><link href="249" rel="bibliography" /><link href="251" rel="bibliography" /><link href="287" rel="bibliography" /><link href="289" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。这种方法精确率虽然很高,但驾驶员必须穿戴相应的仪器设备,对驾驶会产生不便,而且成本较高。第2类方法根据驾驶员对方向盘的掌握状况,如手握方向、力度等数据,以及汽车前进方向和轨迹来分析其疲劳状态<citation id="311" type="reference"><link href="253" rel="bibliography" /><link href="291" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">3</a>]</sup></citation>。这种方法的精度不是很高,稳定性很差,个体差异和道路差异对结果会造成很大影响。第3类是基于计算机视觉的方法。研究表明,当人类陷入疲劳状态时,人眼的闭合频率、闭眼时长以及打哈欠的频率都会增加,头部姿态与其他器官的位置也会发生变化<citation id="313" type="reference"><link href="255" rel="bibliography" /><link href="257" rel="bibliography" /><link href="293" rel="bibliography" /><link href="295" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。用摄像机等设备实时采集驾驶员的状态,并利用这些图像信息分析驾驶员的疲劳状态。这种方法精确度较高,对驾驶员的影响极小,设备成本也相对低廉。目前已有多种技术手段可作为分析驾驶员状态的工具,本文选择了深度学习技术进行研究。</p>
                </div>
                <div class="p1">
                    <p id="66">深度学习技术可以在空间和时间上对图像序列进行特征提取,在计算机视觉领域被大量使用。在疲劳检测领域,使用卷积结构对空间特征提取融合的研究相对较多,如使用级联卷积神经网络的疲劳检测<citation id="314" type="reference"><link href="259" rel="bibliography" /><link href="297" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">6</a>]</sup></citation>,基于卷积神经网络CNN(Convolutional Neural Networks)的面部图像识别以及疲劳检测等<citation id="317" type="reference"><link href="261" rel="bibliography" /><link href="263" rel="bibliography" /><link href="265" rel="bibliography" /><link href="299" rel="bibliography" /><link href="301" rel="bibliography" /><link href="303" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>;在对时间特征的提取方面一般借助于光流法等对人脸进行跟踪<citation id="315" type="reference"><link href="267" rel="bibliography" /><link href="305" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">10</a>]</sup></citation>;在时空特征提取上多为先使用卷积结构对图像的空间特征进行提取,之后使用LSTM(Long Short-Term Memory)等循环神经网络RNN(Recurrent Neural Networks)结构对时间特征进行提取<citation id="316" type="reference"><link href="269" rel="bibliography" /><link href="307" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="67">仅提取空间特征或者仅提取时间特征不能完整地描述整个疲劳过程,而先采用卷积网络再使用循环网络的方法也不能同时提取空间和时间的综合特征。</p>
                </div>
                <div class="p1">
                    <p id="68">鉴于上述算法的局限性,本文采用深度学习的方法,建立时空网络模型,同时提取空间和时间上的特征,根据眼部、嘴部的变化趋势,对未来状态进行预测,从而判断是否提前预警。经过实验分析证明,本文提出的算法可以有效地预测面部状态变化趋势,能准确地进行提前预警,进一步保证了驾驶安全。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag"><b>2 相关理论</b></h3>
                <h4 class="anchor-tag" id="70" name="70"><b>2.1 STN网络结构</b></h4>
                <div class="p1">
                    <p id="71">时空转换网络STN(Spatial Transformer Networks)<citation id="318" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>的结构如图1所示,引入转换参数<i>θ</i>,在网格生成器(Grid Generator)中将输入数据<i>U</i>通过与<i>θ</i>有关的函数转换为输出数据<i>V</i>:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>,</mo><mi>U</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中,函数<i>f</i>可以定义为旋转、放缩、仿射等矩阵变换。Jaderberg等人<citation id="319" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>证明了STN结构可以被安装在CNN的任意层中,通过此结构将原始数据根据一定的变换方式转换为新的数据之后再进行卷积计算,转换参数<i>θ</i>可以通过网络的不断训练被学习和更新。这种做法使得CNN具有位置可变性,从而使真实有用的位置特征被有效学习到。</p>
                </div>
                <div class="area_img" id="74">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 STN结构" src="Detail/GetImg?filename=images/JSJK201910008_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 STN结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_074.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Structure of STN</p>

                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.2 LSTM网络结构</b></h4>
                <div class="p1">
                    <p id="76">LSTM<citation id="320" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>是一种典型RNN结构,如图2所示,LSTM结构中包含输入门、遗忘门、输出门3种门结构。输入门控制输入数据中哪些信息可以被保留;遗忘门的作用是选择放弃部分网络认为无用的信息;输出门将细胞单元中的信息与上一细胞单元传递下来的信息综合处理并输出结果。3种门结构共同作用,控制LSTM网络细胞单元的信息传递过程。</p>
                </div>
                <div class="p1">
                    <p id="77">3种门结构以及细胞单元状态的更新由式(2)～式(6)来控制:</p>
                </div>
                <div class="p1">
                    <p id="78"><i><b>i</b></i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i><b>xi</b></i></sub><i><b>x</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Hi</b></i></sub><i><b>H</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>W</b></i><sub><i><b>Ci</b></i></sub>。<i><b>C</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub><i><b>i</b></i></sub>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="79"><i><b>f</b></i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i><b>xf</b></i></sub><i><b>x</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Hf</b></i></sub><i><b>H</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>W</b></i><sub><i><b>Cf</b></i></sub>。<i><b>C</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub><i><b>f</b></i></sub>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="80"><i><b>C</b></i><sub><i>t</i></sub>=<i><b>f</b></i><sub><i>t</i></sub>。<i><b>C</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>i</b></i><sub><i>t</i></sub>。tanh(<i><b>W</b></i><sub><i><b>xC</b></i></sub><i><b>x</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>HC</b></i></sub><i><b>H</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub><i><b>C</b></i></sub>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="81"><i><b>o</b></i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i><b>xo</b></i></sub><i><b>x</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>HO</b></i></sub><i><b>H</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>W</b></i><sub><i><b>Co</b></i></sub>。<i><b>C</b></i><sub><i>t</i></sub>+<i><b>b</b></i><sub><i><b>o</b></i></sub>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="82"><i><b>H</b></i><sub><i>t</i></sub>=<i><b>o</b></i><sub><i>t</i></sub> 。tanh(<i><b>C</b></i><sub><i>t</i></sub>)      (6)</p>
                </div>
                <div class="p1">
                    <p id="83">其中,式(2)、式(3)和式(5)分别为<i>t</i>时刻输入门、遗忘门和输出门的计算过程,<i><b>i</b></i><sub><i>t</i></sub>、<i><b>f</b></i><sub><i>t</i></sub>、<i><b>C</b></i><sub><i>t</i></sub>均为向量,表示计算结果;式(4)和式(6)分别为<i>t</i>时刻中间记忆状态和细胞状态的计算过程 ,<i><b>o</b></i><sub><i>t</i></sub>、<i><b>H</b></i><sub><i>t</i></sub>均为向量,表示计算结果;<i><b>W</b></i>为参数矩阵,<i><b>b</b></i>为偏置向量,<i><b>x</b></i>为输入向量,<i>t</i>表示时刻,<i>σ</i>表示Sigmoid激活函数;。代表哈达马乘积(Hadamard Product)。LSTM复杂的网络结构有效抑制了传统RNN存在的梯度消失问题。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 LSTM 网络结构" src="Detail/GetImg?filename=images/JSJK201910008_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 LSTM 网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Structure of LSTM network</p>

                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 本文算法流程" src="Detail/GetImg?filename=images/JSJK201910008_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 本文算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 The proposed algorithm flowchart</p>

                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>2.3 ConvLSTM网络结构</b></h4>
                <div class="p1">
                    <p id="87">ConvLSTM<citation id="321" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>模型将LSTM结构信息传递过程由矩阵相乘替换成卷积计算。<i>t</i>-1时刻信息传递到<i>t</i>时刻的过程如图3所示。<i><b>H</b></i><sub><i>t</i></sub>表示<i>t</i>时刻细胞状态,<i><b>C</b></i><sub><i>t</i></sub>表示<i>t</i>时刻记忆单元,<i><b>x</b></i><sub><i>t</i></sub>表示<i>t</i>时刻输入数据 ,当前状态<i><b>H</b></i><sub><i>t</i></sub>和中间记忆单元<i><b>C</b></i><sub><i>t</i></sub>的计算公式可简单表示如下:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mi>t</mi></msub><mo>,</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mi>o</mi><mi>n</mi><mi>v</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中,<i>Conv</i>()表示卷积函数。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 ConvLSTM内部结构" src="Detail/GetImg?filename=images/JSJK201910008_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 <i>ConvLSTM</i>内部结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Figure</i> 3 <i>Internal structure of ConvLSTM</i></p>

                </div>
                <h3 id="91" name="91" class="anchor-tag"><b>3 基于面部动作时空特征的疲劳预警算法</b></h3>
                <div class="p1">
                    <p id="92">本文主要使用了2种网络模型:结合<i>STN</i>的卷积神经网络结构模型<i>S</i>-<i>CNN</i>(<i>Spatial transformer Convolutional Neural Networks</i>),其作用是检测脸部区域,缩小输入图像大小,减少后续过程计算量,以及标记眼部和嘴部关键区域的特征点;结合<i>STN</i>的卷积长短期记忆网络结构模型<i>SCL</i>(<i>Spatial transformer ConvLSTM</i>),其作用是根据目前已采集图像的时空特征,预测未来的图像。</p>
                </div>
                <div class="p1">
                    <p id="93">算法结构分为4部分:首先训练<i>S</i>-<i>CNN</i>网络模型,检测脸部区域;其次训练<i>SCL</i>网络模型,根据目前已采集图像的时空特征,预测未来的图像;然后使用<i>Landmark</i>算法<citation id="322" type="reference"><link href="275" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>标记眼部和嘴部关键区域的特征点;最后通过<i>PERCLOS</i>(<i>PERcentage of eyelid CLOSure over the pupil over time</i>)标准以及嘴部开闭特征判断疲劳状态,从而确定是否进行预警。具体算法流程如图4所示。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>3.1 基于S-CNN结构的人脸检测算法</b></h4>
                <div class="p1">
                    <p id="95">本文采用选择性搜索<i>SS</i>(<i>Selective Search</i>)算法<citation id="323" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>实现图像的矩形位置搜索,使用<i>S</i>-<i>CNN</i>模型训练矩形框内图像信息,提取图像特征并进行分类,得到待检测图像人脸与非人脸的分类结果并添加矩形位置标签。</p>
                </div>
                <div class="p1">
                    <p id="96"><i>S</i>-<i>CNN</i>是一种结合了<i>STN</i>的卷积神经网络,共有7层,包括2个卷积层、2个池化层、<i>BN</i>(<i>Batch Normolizaton</i>)层、全连接层和<i>Softmax</i>层。<i>BN</i>层对中间层的输出数据进行标准化操作,有效改善梯度消失,同时加快训练速度。<i>S</i>-<i>CNN</i>网络模型在每个卷积层前加入仿射变换因子<i>θ</i>,其结构如图5所示。</p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 S-CNN网络结构" src="Detail/GetImg?filename=images/JSJK201910008_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 S-CNN网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_097.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5 Structure of S-CNN</p>

                </div>
                <div class="p1">
                    <p id="98">在驾驶过程中,驾驶员不会一直保持直面摄像机的姿势,随时伴有抬头、低头、侧头、旋转等动作。因此,面部像素点在相邻图像中可能存在不同方向的偏移,这种位置变换对脸部检测的结果会造成一定误差。S-CNN模型的空间变换训练方式可以减小由于驾驶员的动作变化对脸部区域检测的影响。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>3.2 基于SCL结构的面部状态预测算法</b></h4>
                <div class="p1">
                    <p id="100">将每幅图像中被标记为人脸的矩形区域按照对应的时间保存,形成连续的人脸图像序列。将该序列作为SCL模型的输入数据,最终得到面部预测结果。</p>
                </div>
                <div class="p1">
                    <p id="101">SCL模型同时在空间和时间两方面提取特征,并预测未来一段时间内脸部状态的变化趋势。其内部结构如图6所示,该模型以ConvLSTM网络结构为基础,在ConvLSTM中的卷积过程加入位置变换因子<i>θ</i>,以减少位置变化带来的误差。</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 SCL内部结构" src="Detail/GetImg?filename=images/JSJK201910008_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 SCL内部结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 6 Internal structure of SCL</p>

                </div>
                <div class="p1">
                    <p id="103">SCL网络结构信息传递计算公式如式(7)～式(11)所示,<i>t</i>时刻输入数据<i><b>x</b></i><sub><i>t</i></sub>和<i>t</i>-1时刻细胞状态<i><b>H</b></i><sub><i>t</i></sub><sub>-1</sub>进入ConvLSTM网络之前先经过位置仿射,仿射函数如式(1)所示。</p>
                </div>
                <div class="p1">
                    <p id="104"><i><b>i</b></i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i><b>xi</b></i></sub>*<i><b>v</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Hi</b></i></sub>*<i><b>u</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Ci</b></i></sub>。<i><b>C</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub><i><b>i</b></i></sub>)      (7)</p>
                </div>
                <div class="p1">
                    <p id="105"><i><b>f</b></i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i><b>xi</b></i></sub>*<i><b>v</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Hf</b></i></sub>*<i><b>u</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Cf</b></i></sub>。<i><b>C</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub><i><b>f</b></i></sub>)      (8)</p>
                </div>
                <div class="p1">
                    <p id="106"><i><b>C</b></i><sub><i>t</i></sub>=<i><b>f</b></i><sub><i>t</i></sub>。<i><b>C</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>i</b></i><sub><i>t</i></sub>。tanh(<i><b>W</b></i><sub><i><b>xC</b></i></sub>*<i><b>v</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>HC</b></i></sub>*<i><b>u</b></i><sub><i>t</i></sub>+<i><b>b</b></i><sub><i><b>C</b></i></sub>)      (9)</p>
                </div>
                <div class="p1">
                    <p id="107"><i><b>o</b></i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub><i><b>xo</b></i></sub><i><b>v</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Ho</b></i></sub><i><b>u</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub><i><b>Co</b></i></sub>。<i><b>C</b></i><sub><i>t</i></sub>+<i><b>b</b></i><sub><i><b>o</b></i></sub>)      (10)</p>
                </div>
                <div class="p1">
                    <p id="108"><i><b>H</b></i><sub><i>t</i></sub>=<i><b>o</b></i><sub><i>t</i></sub>。tanh(<i><b>C</b></i><sub><i>t</i></sub>)      (11)</p>
                </div>
                <div class="p1">
                    <p id="109">其中,*代表卷积计算过程,<i><b>v</b></i><sub><i>t</i></sub>表示<i>t</i>时刻的输入数据<i><b>x</b></i><sub><i>t</i></sub>经过空间变换后的结果,<i><b>u</b></i><sub><i>t</i></sub>表示<i>t</i>-1时刻的状态<i><b>H</b></i><sub><i>t</i></sub><sub>-1</sub>经过空间变换后的结果:</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>,</mo><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>3.3 面部特征点提取</b></h4>
                <div class="p1">
                    <p id="112">理论表明,当人处于疲劳状态时,会出现眼皮逐渐覆盖眼球、眨眼频率增加等现象,通过眼睛的生理特征来判断人的疲劳状态是目前最常用的方法,利用眼部特征点来判断眼部状态是疲劳判断的重要依据;同时,人体血液中二氧化碳的含量升高,从而导致大脑运作变得缓慢,此时人体将通过打哈欠来缓解疲劳,刺激大脑让肌肉得到放松,打哈欠作为疲劳的另一种生理特征,是疲劳判断的补充。目前,对于打哈欠判断疲劳的研究中,主要是以张口程度来判断,因此利用嘴部特征点来判断嘴部状态也是疲劳判断的重要依据。</p>
                </div>
                <div class="p1">
                    <p id="113">本文采用Landmark算法检测人脸特征点,标记人脸的68个特殊标志点,从眉毛外沿至下颌底部,包括眼部轮廓和嘴部轮廓等,检测结果如图7所示。</p>
                </div>
                <div class="area_img" id="114">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 人脸特征点检测" src="Detail/GetImg?filename=images/JSJK201910008_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 人脸特征点检测  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 7 Face feature point detection</p>

                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>3.4 基于PERCLOS标准及嘴部开合统计的疲劳检测</b></h4>
                <div class="p1">
                    <p id="116">根据相关研究,着重考虑眼部、嘴部状态对疲劳程度的影响,选择PERCLOS和嘴部开合情况作为判断疲劳状态的依据。</p>
                </div>
                <h4 class="anchor-tag" id="117" name="117">3.4.1 眼部状态分析</h4>
                <div class="p1">
                    <p id="118">眼部特征点检测主要检测眼部的6个特征点位置<i>P</i><sub>1</sub>～<i>P</i><sub>6</sub>,如图8所示,根据Soukupova等人<citation id="324" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出的基于眼睛周围特征点纵横比EAR(Eye Aspectration)的概念,定义人眼的张合度为<i>r</i><sub>EAR</sub>,由特征点的距离运算得到:</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><msub><mrow></mrow><mrow><mtext>E</mtext><mtext>A</mtext><mtext>R</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>6</mn></msub><mo stretchy="false">∥</mo><mo>+</mo><mo stretchy="false">∥</mo><mi>Ρ</mi><msub><mrow></mrow><mn>3</mn></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>5</mn></msub><mo stretchy="false">∥</mo></mrow><mrow><mn>2</mn><mo stretchy="false">∥</mo><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>4</mn></msub><mo stretchy="false">∥</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 人眼特征点检测" src="Detail/GetImg?filename=images/JSJK201910008_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 人眼特征点检测  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 8 Eyes feature point detection</p>

                </div>
                <div class="p1">
                    <p id="121">其中,分子为眼睛特征点在垂直方向上的距离和,分母为水平方向上的距离,其中分母中“2”的意义是取平均垂直距离作为眼睛睁开时的垂直距离。清醒状态下每个人眼睛的张合度是不同的,在数据输入时首先计算<i>r</i><sub>EAR</sub>的平均值<i>r</i><sub>m</sub>。在网络预测出的系列图像中分别计算<i>r</i><sub>EAR</sub>值记为<i>r</i><sub>c</sub>,规定当<i>r</i><sub>c</sub>&lt;<i>r</i><sub>m</sub>时,认为驾驶员处于眼睛闭合状态。</p>
                </div>
                <div class="p1">
                    <p id="122">本文采用PERCLOS<citation id="325" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>疲劳判断标准统计一段时间内眼睛闭合帧数的百分比,PERCLOS可以简单地表示为:<i>PERCLOS</i>=闭眼帧数/总帧数,将眼部状态结果记为<i>T</i><sub>eye</sub>。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123">3.4.2 嘴部状态分析</h4>
                <div class="p1">
                    <p id="124">通常情况下,嘴部有闭合、打哈欠和其他动作3种状态。打哈欠的情况下嘴部张开程度会明显较大,保持张开的时间也会比说话等动作要长,因此可直接根据嘴部的高宽比例来判断嘴部的张开程度,进而对打哈欠的图像进行标记。</p>
                </div>
                <div class="p1">
                    <p id="125">如图9所示,嘴部的部分特征点由位置<i>P</i><sub>1</sub>～<i>P</i><sub>8</sub>表示,嘴部高宽比定义为:</p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>z</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi>Ρ</mi><msub><mrow></mrow><mn>3</mn></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>7</mn></msub><mo stretchy="false">∥</mo></mrow><mrow><mo stretchy="false">∥</mo><mi>Ρ</mi><msub><mrow></mrow><mn>5</mn></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">∥</mo></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127">其中,分子为嘴部垂直高度值,分母为嘴部水平宽度值。根据先验理论,当<i>z</i>值大于阈值<i>m</i>时,可判断此图像为嘴巴张开状态;当连续<i>k</i>幅图像的<i>z</i>值均大于阈值<i>m</i>时,将图像序列标记为打哈欠。统计一段时间内打哈欠的图像帧数,记<i>T</i><sub>mou</sub>为嘴部状态分析结果,<i>T</i><sub>mou</sub>=打哈欠帧数/总帧数。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 嘴唇轮廓示意图" src="Detail/GetImg?filename=images/JSJK201910008_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 嘴唇轮廓示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 9 Landmarks of mouth outline</p>

                </div>
                <h4 class="anchor-tag" id="129" name="129">3.4.3 疲劳检测分析</h4>
                <div class="p1">
                    <p id="130">对眼部、嘴部状态分别做了分析之后,将眼部对疲劳程度的影响权重设置为<i>w</i><sub>1</sub>,嘴部对疲劳程度的影响权重设置为<i>w</i><sub>2</sub>,计算最终的疲劳状态检测值<i>T</i>,通过对<i>T</i>的分析得出疲劳检测结果。<i>T</i>值的计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mo>=</mo><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mi>Τ</mi><msub><mrow></mrow><mrow><mtext>e</mtext><mtext>y</mtext><mtext>e</mtext></mrow></msub><mo>+</mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mi>Τ</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>o</mtext><mtext>u</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="132" name="132" class="anchor-tag"><b>4 实验分析</b></h3>
                <h4 class="anchor-tag" id="133" name="133"><b>4.1 人脸检测实验与结果分析</b></h4>
                <div class="p1">
                    <p id="134">实验采用自建数据集。以15 fps的帧率采集了20名实验者的红外视频片段,其中包括10名男性实验者和10名女性实验者。采集每位实验者戴墨镜、戴近视镜、不戴眼镜3种情况下的视频。将存在1～2个自然疲劳驾驶行为作为采集标准,共采集了60段长度为20 s的视频。每段含有300幅图像,视频图像大小为640*480,共含有18 000幅图像,作为数据集I。在训练前,将所有图像的灰度值归一化到(0,1),减小光照变化的影响。每位实验者的数据收集情况如表1所示。</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表1 实验者的数据收集情况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Experimenter data collection</b></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br />情况分类</td><td>戴墨镜</td><td>戴近视镜</td><td>不戴眼镜</td></tr><tr><td><br />视频时长/s</td><td>20</td><td>20</td><td>20</td></tr><tr><td><br />图像数量</td><td>300</td><td>300</td><td>300</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="136">进行人脸检测实验时,根据数据集I,在每秒产生的15帧中随机抽取5帧共6 000幅图像(每位实验者每种情况100幅),其中5 000幅作为训练集,1 000幅作为测试集。在SS算法中,每幅图像选取1 000个搜索矩形,矩形大小设置为150*150。</p>
                </div>
                <div class="p1">
                    <p id="137">在数据集I的测试集上,将S-CNN与简单7层CNN 2种结构作为实验对照组,以均方误差<i>MSE</i>(Mean Square Error)作为误差指标,<i>MSE</i>越小证明准确率越高。在测试集上的<i>MSE</i>对比如图10所示,其中横坐标为整个数据集迭代轮数,纵坐标为<i>MSE</i>值。</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 测试集上MSE结果对比" src="Detail/GetImg?filename=images/JSJK201910008_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 测试集上<i>MSE</i>结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 10 <i>MSE</i> comparison on test set</p>

                </div>
                <div class="p1">
                    <p id="139">分析可知,经过200轮迭代收敛后,2个网络模型对脸部检测均有较高的准确率,但S-CNN网络的<i>MSE</i>明显比普通CNN更低,STN的加入对于脸部定位准确率的提高有显著的效果。</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140"><b>4.2 状态预测实验与结果分析</b></h4>
                <div class="p1">
                    <p id="141">将数据集I的所有图像通过脸部特征点检测得到正标签的脸部矩形区域图像,按照算法1的步骤生成数据集II,由训练集和测试集2部分构成。</p>
                </div>
                <div class="p1">
                    <p id="142"><b>算法1</b> 数据集II生成算法</p>
                </div>
                <div class="p1">
                    <p id="143"><b>输入</b>:数据集I。</p>
                </div>
                <div class="p1">
                    <p id="144"><b>输出</b>:数据集II的训练集和测试集。</p>
                </div>
                <div class="p1">
                    <p id="145"><b>步骤1</b> 数据集I通过脸部区域检测,得到只包含脸部区域信息的图像集。此图像集包含有18 000幅图像,且从第1幅开始,每300幅存在时间关系,每幅图像的大小为150*150。</p>
                </div>
                <div class="p1">
                    <p id="146"><b>步骤2</b> 在步骤1生成的图像集中,从第1幅开始,将300幅图像作为一个片段,即每个片段都是同1个实验者连续20 s 没有重叠的图像序列,18 000幅图像共生成60个片段。</p>
                </div>
                <div class="p1">
                    <p id="147"><b>步骤3</b> 随机取50个片段作为训练集,在每个片段中,取大小为150帧的滑动窗口以10为步长覆盖该片段。因此,每个片段会得到16个150幅连续不重叠的图像序列,即800个图像序列作为训练集。</p>
                </div>
                <div class="p1">
                    <p id="148"><b>步骤4</b> 在剩余的10个片段中,每个片段取大小为150帧的滑动窗口以1为步长覆盖该片段,每个片段获得151个150幅连续不重叠的图像序列。最终得到1 510个图像序列作为预测使用的测试集。</p>
                </div>
                <div class="p1">
                    <p id="149">将数据集II的训练集输入到SCL网络结构进行训练,每次将1个图像序列(150幅)输入网络,其中前120幅用来训练,后30幅进行损失函数的计算,即使用前8 s的眼部状态特征来预测后2 s的图像(30幅)。网络收敛或者损失函数值到达0.01时,保存网络模型并将测试集在该模型中运算得到预测结果。</p>
                </div>
                <div class="p1">
                    <p id="150">在实际应用中,摄像机每捕捉到1帧图像就要生成相应的系列预测图像,数据集II的验证集即是按照实际情况设计的,没有漏掉1幅图像,完整地模拟了每个20 s片段中可能出现的预警情况。</p>
                </div>
                <div class="p1">
                    <p id="151">将本文提出的SCL网络与经典RNN网络LSTM以及传统CNN网络VGG(牛津大学Visual Geometry Group研发的网络,命名来自其缩写)<citation id="326" type="reference"><link href="283" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>在数据集II的测试集上做对比实验,误差指标选择<i>MSE</i>,对比结果如图11所示,其中横纵坐标分别为数据集迭代轮数和<i>MSE</i>值。</p>
                </div>
                <div class="area_img" id="152">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 各网络上实验对比分析" src="Detail/GetImg?filename=images/JSJK201910008_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 各网络上实验对比分析  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_152.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 11 Experiment comparison on 
 different network structures</p>

                </div>
                <div class="p1">
                    <p id="153">图11中3条曲线由上到下分别表示VGG、LSTM、SCL模型的<i>MSE</i>, 经过200轮迭代后3条曲线均趋于稳定。SCL模型的<i>MSE</i>明显低于LSTM和VGG的,相较于LSTM和VGG,SCL模型在准确率方面有所提升,VGG网络的<i>MSE</i>最大,表明疲劳状态的改变在时序上有很大的关联性,传统的CNN网络在此问题上有一定的劣势。</p>
                </div>
                <h4 class="anchor-tag" id="154" name="154"><b>4.3 眼部与嘴部综合疲劳检测实验分析</b></h4>
                <div class="p1">
                    <p id="155">本文采用PERCLOS眼部疲劳判断标准,以及打哈欠统计结果来判断眼部、嘴部疲劳状态。</p>
                </div>
                <div class="p1">
                    <p id="156">已有研究证明<citation id="327" type="reference"><link href="285" rel="bibliography" /><link href="309" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">19</a>]</sup></citation>嘴部疲劳状态检测中,嘴部高宽比阈值<i>m</i>取1.6并且维持0.5 s嘴部张开时被判定为打哈欠的准确率最高,因此本文算法将(<i>m</i>,<i>k</i>)取值为(1.6,7)。</p>
                </div>
                <div class="p1">
                    <p id="157">用式(13)的值来衡量疲劳值,其中权重<i>w</i><sub>1</sub>、<i>w</i><sub>2</sub>的设定对准确率有重要的作用。图12为2个权重的取值组合对预警准确率的影响,其中<i>w</i><sub>1</sub>+<i>w</i><sub>2</sub>=1。图12中折线显示,在<i>w</i><sub>1</sub>值为0或者<i>w</i><sub>2</sub>值为0时,折线均没有达到准确率的最高点,但<i>w</i><sub>1</sub>值为0时的准确率比<i>w</i><sub>2</sub>值为0时的准确率高,这说明综合状态特征判定比只根据眼部状态或者只根据嘴部状态来判定疲劳状态更加准确,嘴部状态特征比眼部状态特征更能凸显疲劳状态的特征;折线在<i>w</i><sub>1</sub>值为0.2、<i>w</i><sub>2</sub>值为0.8处达到最高点,即准确率最高,是算法的最优参数组合。</p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 w1、w2值寻优" src="Detail/GetImg?filename=images/JSJK201910008_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 <i>w</i><sub>1</sub>、<i>w</i><sub>2</sub>值寻优  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 12 Optimization of <i>w</i><sub>1</sub>,<i>w</i><sub>2</sub></p>

                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>4.4 预警结果实验分析</b></h4>
                <div class="p1">
                    <p id="160">本文算法预测了2 s后的眼部、嘴部状态系列图像,并得出疲劳检测结果。目前我国高速公路上的车速在100 km/h以上,在2 s内车辆至少可以行驶40 m,相较于其他预警方法,本文提出的提前预警无疑具有很重要的现实意义;同时,预警是否成功的衡量标准和传统的预警标准也会有所不同。</p>
                </div>
                <div class="p1">
                    <p id="161">本文的模型实验使用数据集II的测试集,图像的采集帧率为15 fps。本文认为如果在<i>t</i>时刻出现疲劳,那么在<i>t</i>-2～<i>t</i>的2 s时间段内任何一个时间点预警均看作预警成功。根据网络训练过程,模型每收集到1幅新图像就会根据新的序列做一次预测,故2 s内会有30个预测序列输出。以生成2个预测序列为1个预警点,2 s内会有15个预警点,预警位置如图13所示。</p>
                </div>
                <div class="area_img" id="162">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_162.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 t-2时刻至t时刻内预警点位置" src="Detail/GetImg?filename=images/JSJK201910008_162.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 <i>t</i>-2时刻至<i>t</i>时刻内预警点位置  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_162.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 13 Location of warning points</p>

                </div>
                <div class="p1">
                    <p id="163">多次实验得到模型运算1次的平均耗时为0.056 s,分析图14所示的预警点准确率可知,在编号为2的预警点处(提前1.5 s预警),模型准确率已在90%之上。此时,获取新图像并预测结果的耗时分为2部分,由4幅摄像机图像的输入时间0.27 s,加上4次模型运算的耗时0.22 s,共0.49 s;另外,根据结果分析可知,越靠近<i>t</i>时刻,预警准确率越高,在编号为7的预警点,即提前1 s预警的准确率更是达到97%以上。如果使用更好的硬件设备,增加帧率或者减少模型运算时间,预警效果会更好。</p>
                </div>
                <div class="area_img" id="164">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201910008_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图14 预警点准确率结果" src="Detail/GetImg?filename=images/JSJK201910008_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图14 预警点准确率结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201910008_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 14 Precision of warning points</p>

                </div>
                <h3 id="165" name="165" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="166">为了解决疲劳驾驶的预警问题,本文使用深度学习算法,利用疲劳特征的时序性,提出了基于时空特征提取的疲劳检测算法。实验结果表明,本文提出的算法能有效地提前预警,进一步避免交通事故的发生。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="249">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QCGC201803014&amp;v=MDYyODhaZVJtRnkvZ1ZiL0pOQzdNYmJHNEg5bk1ySTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Wang Lin,Zhang Chen,Yin Xiao-wei,et al.A non-contact driving fatigue detection technique based on driver’s physiological signals[J].Automotive Engineering,2018,40(3):333-341.(in Chinese）
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLJS201802017&amp;v=MjU4ODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pNaUhCZmJHNEg5bk1yWTlFWTRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Li Jiang-tian,Li Min,Song Zhan-bing.Driving fatigue detection based on multi-source physiological signal[J].Logistics Technology,2018,37(2):78-83.(in Chinese）
                            </a>
                        </p>
                        <p id="253">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                Li Hong-tao,Ba Xing-qiang,Lu Zhao-you,et al.Highway driving state detection method based on steering wheel signal[J].Shanxi Architecture,2018,44(28):110-112.(in Chinese）
                            </a>
                        </p>
                        <p id="255">
                            <a id="bibliography_4" >
                                    <b>[4]</b>
                                Tang Yang-shan,Xu zhong-shuai,Yang Yu-yao.Driver fatigue detection based on head pose for eye differential positioning[J].Science Technology and Engineering,2018,18(31):235-239.(in Chinese）
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Research on fatigue driving recognition based on human eye state detection">

                                <b>[5]</b>Cai Jia.Research on fatigue driving recognition based on human eye state detection[D].Shijiazhuang:Hebei University of Science and Technology,2018.(in Chinese）
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                Zhao Xue-peng,Meng Chun-ning,Feng Ming-kui,et al.Fatigue detection based on cascade convolutional nerual network[J].Journal of Optoelectronics·Laser,2017,28(5):497-502.(in Chinese）
                            </a>
                        </p>
                        <p id="261">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                Lu Wei,Hu Hai-yang,Wang Jia-peng,et al.Tractor driver fatigue detection based on convolution neural network and facial image recognition[J].Transactions of the Chinese Society of Agricultural Engineering,2018,34(7):192-199.(in Chinese）
                            </a>
                        </p>
                        <p id="263">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201813017&amp;v=MTE1NjFyQ1VSTE9lWmVSbUZ5L2dWYi9KTGpYQmZiRzRIOW5Ockk5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Yu Ming,An Meng-tao,Liu Yi.Facial expression recognition based on multiple features and convolutional neural networks[J].Science Technology and Engineering,2018,18(13):104-110.(in Chinese）
                            </a>
                        </p>
                        <p id="265">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201818017&amp;v=MDM3NDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pQU25QWkxHNEg5bk5wNDlFWTRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Liu Jun-chao,Chen Zhi-jun,Fan Xiao-chao,et al.Eye detection based on deep convolutional nerual networks[J].Modern Electronics Technique,2018,41(18):72-75.(in Chinese）
                            </a>
                        </p>
                        <p id="267">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201808032&amp;v=MTM2NTMzenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pOaWZZWkxHNEg5bk1wNDlHWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Ji Qiu-min,Zhang Ling,Luo Yuan,et al.Mental fatigue detection based on multi-inter-domain optical flow characterisitics[J].Computer Engineering and Design,2018,39(8):2582-2586.(in Chinese）
                            </a>
                        </p>
                        <p id="269">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                Geng Lei,Liang Xiao-yu,Xiao Zhi-tao,et al.Real-time driver fatigue detection based on morphology infrared features and deep learning[J].Infrared and Laser Engineering,2018,47(2):60-68.(in Chinese）
                            </a>
                        </p>
                        <p id="271">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial transformer networks">

                                <b>[12]</b>Jaderberg M,Simonyan K,Zisserman A,et al.Spatial transformer networks[C]∥Proc of the 28th International Conference on NIPS,2015:2017-2025．
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interpretable Structure-evolving LSTM">

                                <b>[13]</b>Liang X,Liang L,Shen X,et al.Interpretable structure-evolving LSTM[C]∥Proc of 2017IEEE Conference on Computer Vision and Pattern Recognition,2017:1010-1019．
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The 3D menpo facial landmark tracking challenge">

                                <b>[14]</b>Zafeiriou S,Chrysos G G,Roussos A,et al.The 3D menpo facial landmark tracking challenge[C]∥Proc of IEEE International Conference on Computer Vision,2017:2503-2511．
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Driver fatigue detection based on eye state recognition">

                                <b>[15]</b>Fang Z,Su J,Lei G,et al.Driver fatigue detection based on eye state recognition[C]∥Proc of International Conference on Machine Vision&amp;Information Technology,2017:105-110．
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the efficiency of selective search">

                                <b>[16]</b>Hafizoglu F,Kucukoglu E C,Altingovde I S.On the efficiency of selective search[C]∥Proc of European Conference on Information Retrieval,2017:705-712．
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-Time Eye Blink Detection using Facial Landmarks">

                                <b>[17]</b>Soukupová T,Cech J.Real-time eye blink detection using facial landmarks[C]∥Proc of the 21st Computer Vision Winter Workshop,2016:1-6．
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for text classification">

                                <b>[18]</b>Conneau A,Schwenk H,Barrault L,et al.Very deep convolutional networks for text classification[C]∥Proc of Conference of the European Chapter of the Association for Computational Lingusitics,2017:1107-1116．
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201807017&amp;v=MTQzNjVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVmIvSlBUblNkN0c0SDluTXFJOUVZNFFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Dai Shi-qi,Zeng Zhi-yong.Fatigue driving detection algorithm based on deep learning[J].Computer System&amp;Applications,2018,27(7):113-120.(in Chinese）
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                王琳，张陈，尹晓伟，等．一种基于驾驶员生理信号的非接触式驾驶疲劳检测技术[J]．汽车工程，2018,40(3):333-341．
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                李江天，李敏，宋战兵．基于多源生理信号的驾驶疲劳检测[J]．物流技术，2018,37(2):78-83．
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZSX201828058&amp;v=MDA2MzlHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pMemZZZHJHNEg5bk9wNDlBYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>李洪涛，巴兴强，逯兆友，等．基于方向盘信号的高速公路驾驶状态检测方法[J]．山西建筑，2018,44(28):110-112．
                            </a>
                        </p>
                        <p id="293">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201831037&amp;v=MTc2MjVMT2VaZVJtRnkvZ1ZiL0pMalhCZmJHNEg5blBybzlHWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>唐阳山，徐忠帅，杨语尧．基于头部姿态眼睛差分定位的驾驶员疲劳检测[J]．科学技术与工程，2018,18(31):235-239．
                            </a>
                        </p>
                        <p id="295">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018027863.nh&amp;v=MDMxMzFLckpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYi9KVkYyNkZyTzZHZG4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>蔡伽．基于人眼状态检测的疲劳驾驶识别研究[D]．石家庄：河北科技大学，2018．
                            </a>
                        </p>
                        <p id="297">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GDZJ201705008&amp;v=MjkxNzJxbzlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pJaW5SWkxHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>赵雪鹏，孟春宁，冯明奎，等．基于级联卷积神经网络的疲劳检测[J]．光电子·激光，2017,28(5):497-502．
                            </a>
                        </p>
                        <p id="299">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201807025&amp;v=MDYwNDJDVVJMT2VaZVJtRnkvZ1ZiL0pLelRNZTdHNEg5bk1xSTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>卢伟，胡海阳，王家鹏，等．基于卷积神经网络面部图像识别的拖拉机驾驶员疲劳检测[J]．农业工程学报，2018,34(7):192-199．
                            </a>
                        </p>
                        <p id="301">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                于明，安梦涛，刘依．基于多特征与卷积神经网络的人脸表情识别[J]．科学技术与工程，2018,18(13):104-110．
                            </a>
                        </p>
                        <p id="303">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                刘俊超，陈志军，樊小朝，等．基于深度卷积神经网络的人眼检测[J]．现代电子技术，2018,41(18):72-75．
                            </a>
                        </p>
                        <p id="305">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                姬秋敏，张灵，罗源，等．基于多帧间区域性光流特征的精神疲劳检测[J]．计算机工程与设计，2018,39(8):2582-2586．
                            </a>
                        </p>
                        <p id="307">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYJ201802010&amp;v=MTcxMjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dWYi9KTFRyU1pMRzRIOW5Nclk5RVpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>耿磊，梁晓昱，肖志涛，等．基于多形态红外特征与深度学习的实时驾驶员疲劳检测[J]．红外与激光工程，2018,47(2):60-68．
                            </a>
                        </p>
                        <p id="309">
                            <a id="bibliography_19" >
                                    <b>[19]</b>
                                戴诗琪，曾智勇．基于深度学习的疲劳驾驶检测算法[J]．计算机系统应用，2018,27(7):113-120.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201910008" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201910008&amp;v=MTc1NDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1ZiL0pMejdCWmJHNEg5ak5yNDlGYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
