<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132356149405000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201909001%26RESULT%3d1%26SIGN%3dF4iYRnHOwcDL%252fiZIqZ8MhEyIHfY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201909001&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201909001&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201909001&amp;v=MDk0NTh0R0ZyQ1VSTE9lWmVSbUZ5N2tVci9NTHo3QlpiRzRIOWpNcG85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="&lt;b&gt;2 背景&lt;/b&gt; "><b>2 背景</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;3 传统作业调度策略&lt;/b&gt; "><b>3 传统作业调度策略</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="&lt;b&gt;3.1 先来先服务策略&lt;/b&gt;"><b>3.1 先来先服务策略</b></a></li>
                                                <li><a href="#62" data-title="&lt;b&gt;3.2 回填策略&lt;/b&gt;"><b>3.2 回填策略</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#65" data-title="&lt;b&gt;4 作业调度能效性分析&lt;/b&gt; "><b>4 作业调度能效性分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="&lt;b&gt;4.1 缩短总繁忙时间&lt;/b&gt;"><b>4.1 缩短总繁忙时间</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;4.2 调度算法优化&lt;/b&gt;"><b>4.2 调度算法优化</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;4.3 自适应功耗管理策略&lt;/b&gt;"><b>4.3 自适应功耗管理策略</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;4.4 功率封顶(预算)技术&lt;/b&gt;"><b>4.4 功率封顶(预算)技术</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;4.5 热管理技术&lt;/b&gt;"><b>4.5 热管理技术</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="&lt;b&gt;5 面临的技术挑战和未来发展方向&lt;/b&gt; "><b>5 面临的技术挑战和未来发展方向</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title="&lt;b&gt;5.1 认知计算&lt;/b&gt;"><b>5.1 认知计算</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;5.2 设备异构性&lt;/b&gt;"><b>5.2 设备异构性</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;5.3 调度公平性&lt;/b&gt;"><b>5.3 调度公平性</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="&lt;b&gt;6 结束语&lt;/b&gt; "><b>6 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="图1 作业调度流程及其能效性优化">图1 作业调度流程及其能效性优化</a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;表1 作业调度能效性分析&lt;/b&gt;"><b>表1 作业调度能效性分析</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="118">


                                    <a id="bibliography_1" title="Agerwala T.Challenges on the road to exascale computing[C]∥Proc of the 22nd Annual International Conference on Supercomputing(ICS’08),2008:2．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Challenges on the road to exascale computing">
                                        <b>[1]</b>
                                        Agerwala T.Challenges on the road to exascale computing[C]∥Proc of the 22nd Annual International Conference on Supercomputing(ICS’08),2008:2．
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_2" title="Lucas R,Ang J,Bergman K,et al.Top ten exascale research challenges:DOE ASCAC Subcommittee Report[R].New York:USDOE Office of Science,2014:1-2．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Top ten exascale research challenges">
                                        <b>[2]</b>
                                        Lucas R,Ang J,Bergman K,et al.Top ten exascale research challenges:DOE ASCAC Subcommittee Report[R].New York:USDOE Office of Science,2014:1-2．
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_3" title="Wu C.Making a case for efficient supercomputing[J].ACMQueue,2003,1(7):54-64．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000036632&amp;v=MTc0NzRZPU5pZklZN0s3SHRqTnI0OUZaT2dKQ244N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsOFZhaA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        Wu C.Making a case for efficient supercomputing[J].ACMQueue,2003,1(7):54-64．
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_4" title="Ge R,Feng X,Cameron K W.Improvement of power-performance efficiency for high-end computing[C]∥Proc of the19th IEEE International Parallel and Distributed Processing Symposium,2005:1-8．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improvement of Power-Performance Efficiency forHigh-End Computing">
                                        <b>[4]</b>
                                        Ge R,Feng X,Cameron K W.Improvement of power-performance efficiency for high-end computing[C]∥Proc of the19th IEEE International Parallel and Distributed Processing Symposium,2005:1-8．
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_5" title="Etinski M,Corbalan J,Labarta,et al.Parallel job scheduling for power constrained HPC systems[J].Parallel Computing,2012,38(12):615-630．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300419162&amp;v=MjU3MDJZPU5pZk9mYks3SHRET3JJOUZZT29HRFhvN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsOFZhaA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Etinski M,Corbalan J,Labarta,et al.Parallel job scheduling for power constrained HPC systems[J].Parallel Computing,2012,38(12):615-630．
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_6" title="Srinivasan S,Jha N K.Safety and reliability driven task allocation in distributed systems[J].IEEE Transactions on Parallel&amp;amp;Distributed Systems,1999,10(3):238-251．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Safety and reliability driven task allocation in distributed systems">
                                        <b>[6]</b>
                                        Srinivasan S,Jha N K.Safety and reliability driven task allocation in distributed systems[J].IEEE Transactions on Parallel&amp;amp;Distributed Systems,1999,10(3):238-251．
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_7" title="Zong Z,Qin X,Ruan X,et al.Energy-efficient scheduling for parallel applications running on heterogeneous clusters[C]∥Proc of the 36th International Conference on Parallel Processing(ICPP’07),2007:19-26．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Energy-Efficient Scheduling for Parallel Applications Running on Heterogeneous Clusters">
                                        <b>[7]</b>
                                        Zong Z,Qin X,Ruan X,et al.Energy-efficient scheduling for parallel applications running on heterogeneous clusters[C]∥Proc of the 36th International Conference on Parallel Processing(ICPP’07),2007:19-26．
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_8" title="Liao Xiang-ke,Pang Zheng-bin,Wang Ke-fei,et al.High performance interconnect network for Tianhe system[J].Journal of Computer Science and Technology,2015,30(2):259-272．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High performance interconnect network for Tianhe System">
                                        <b>[8]</b>
                                        Liao Xiang-ke,Pang Zheng-bin,Wang Ke-fei,et al.High performance interconnect network for Tianhe system[J].Journal of Computer Science and Technology,2015,30(2):259-272．
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_9" title="Pang Zheng-bin,Xie Min,Zhang Jun,et al.The TH express high performance interconnect networks[J].Frontiers of Computer Science,2014,8(3):357-366．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14061700001662&amp;v=MDE1ODNPQ25vN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsOFZhaFk9Tmo3QmFySzhIdGZOcUk5RlpPcw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Pang Zheng-bin,Xie Min,Zhang Jun,et al.The TH express high performance interconnect networks[J].Frontiers of Computer Science,2014,8(3):357-366．
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_10" title="Valentini G L,Lassonde W,Khan S U,et al.An overview of energy efficiency techniques in cluster computing systems[J].Cluster Computing,2013,16(1):3-15．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130410199612&amp;v=MjU4MzR2bktyaWZadTl1RkN2dFU3bkpJVjRRTmo3QmFySzdIdFhOcjQ1TWJlME9EaE04enhVU21EZDlTSDduM3hFOWZi&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        Valentini G L,Lassonde W,Khan S U,et al.An overview of energy efficiency techniques in cluster computing systems[J].Cluster Computing,2013,16(1):3-15．
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_11" title="Li K.Energy efficient scheduling of parallel tasks on multiprocessor computers[J].The Journal of Supercomputing,2012,60(2):223-247．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003855181&amp;v=MjM2NTBxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ0RsVmI3SklGbz1OajdCYXJPNEh0SFBwNHBBWmVNT1kzazV6QmRoNGo5OVNY&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        Li K.Energy efficient scheduling of parallel tasks on multiprocessor computers[J].The Journal of Supercomputing,2012,60(2):223-247．
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_12" title="Masanet E R,Brown R E,Shehabi A,et al.Estimating the energy use and efficiency potential of U.S.data centers[J].Proceeding of the IEEE,2011,99(8):1440-1453．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Estimating the energy use and efficiency potential of U.S. data centers">
                                        <b>[12]</b>
                                        Masanet E R,Brown R E,Shehabi A,et al.Estimating the energy use and efficiency potential of U.S.data centers[J].Proceeding of the IEEE,2011,99(8):1440-1453．
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_13" title="Shuja J,Madani S A,Bilal K,et al.Energy-efficient data centers[J].Computing,2012,94(12):973-994．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD121113001177&amp;v=MjMzMzluS3JpZlp1OXVGQ3Z0VTduSklWNFFOajdCYXJLNkg5RE5ySTlGWmVvSUN4TTh6eFVTbURkOVNIN24zeEU5ZmJ2&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Shuja J,Madani S A,Bilal K,et al.Energy-efficient data centers[J].Computing,2012,94(12):973-994．
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_14" title="Koomey J G.Growth in data center electricity use 2005to2010[M].Oakland:Analytics Press,2011．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Growth in data center electricity use 2005to2010">
                                        <b>[14]</b>
                                        Koomey J G.Growth in data center electricity use 2005to2010[M].Oakland:Analytics Press,2011．
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_15" title="Koomey J G.Worldwide electricity used in data centers[J].Environmental Research Letters,2008(3):Article ID034008．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPD00000013370&amp;v=MDM3NTc3cWVidWR0RkNEbFZiN0pJRm89TmlUYmFyTzRIdEhNcjQ1R1ord1BZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdS&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        Koomey J G.Worldwide electricity used in data centers[J].Environmental Research Letters,2008(3):Article ID034008．
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_16" title="Hikita J,Hirano A,Nakashima H.Saving 200kW and$200K/year by power-aware job/machine scheduling[C]∥Proc of 2008IEEE International Symposium on Parallel and Distributed Processing(IPDPS 2008),2008:1-8．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saving 200kw and$200 k/year by power-aware job/machine scheduling">
                                        <b>[16]</b>
                                        Hikita J,Hirano A,Nakashima H.Saving 200kW and$200K/year by power-aware job/machine scheduling[C]∥Proc of 2008IEEE International Symposium on Parallel and Distributed Processing(IPDPS 2008),2008:1-8．
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_17" title="Ge R,Feng X,Cameron K W.Performance-constrained distributed DVS scheduling for scientific applications on poweraware clusters[C]∥Proc of ACM/IEEE Conference on Supercomputing(SC’05),2005:34-44．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Performance-constrained distributed dvs scheduling for scientific applications on power-aware clusters,&amp;quot;">
                                        <b>[17]</b>
                                        Ge R,Feng X,Cameron K W.Performance-constrained distributed DVS scheduling for scientific applications on poweraware clusters[C]∥Proc of ACM/IEEE Conference on Supercomputing(SC’05),2005:34-44．
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_18" title="Cao Z,Watson L T,Cameron K W,et al.A power aware study for VTDIRECT95using DVFS[C]∥Proc of the 2009Spring Simulation Multiconference,2009:531-536．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A power aware study for VTDIRECT95 using DVFS">
                                        <b>[18]</b>
                                        Cao Z,Watson L T,Cameron K W,et al.A power aware study for VTDIRECT95using DVFS[C]∥Proc of the 2009Spring Simulation Multiconference,2009:531-536．
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_19" title="Weiser M,Welch B,Demers A,et al.Scheduling for reduced CPU energy[C]∥Proc of the 1st USENIX Conference on Operating Systems Design and Implementation(OS-DI’94),1994:13-23．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scheduling for reduced CPU energy">
                                        <b>[19]</b>
                                        Weiser M,Welch B,Demers A,et al.Scheduling for reduced CPU energy[C]∥Proc of the 1st USENIX Conference on Operating Systems Design and Implementation(OS-DI’94),1994:13-23．
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_20" title="Gruian F,Kuchcinski K.LEneS:Task scheduling for lowenergy systems using variable supply voltage processors[C]∥Proc of the ASP-DAC,2001:449-455．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LEneS: Task Scheduling for Low-Energy Systems UsingVariable Supply Voltage Processors">
                                        <b>[20]</b>
                                        Gruian F,Kuchcinski K.LEneS:Task scheduling for lowenergy systems using variable supply voltage processors[C]∥Proc of the ASP-DAC,2001:449-455．
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_21" title="Horvath T,Abdelzaher T,Skadron K,et al.Dynamic voltage scaling in multitier web servers with end-to-end delay control[J].IEEE Transactions on Computers,2007,56(4):444-458．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic Voltage Scaling in Multitier Web Servers with End-to-End Delay Control">
                                        <b>[21]</b>
                                        Horvath T,Abdelzaher T,Skadron K,et al.Dynamic voltage scaling in multitier web servers with end-to-end delay control[J].IEEE Transactions on Computers,2007,56(4):444-458．
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_22" title="Zhong X L,Xu C Z.System-wide energy minimization for real-time tasks:Lower bound and approximation[J].ACMTransactions on Embedded Computing System,2008,7(3):1-24．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000092635&amp;v=MDE2MDNHZXJxUVRNbndaZVp1SHlqbVVMZklKbDhWYWhZPU5pZklZN0s3SHRqTnI0OUZaT0lOQ244OG9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                        Zhong X L,Xu C Z.System-wide energy minimization for real-time tasks:Lower bound and approximation[J].ACMTransactions on Embedded Computing System,2008,7(3):1-24．
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_23" title="Bilal K,Khan S U,Madani S A,et al.A survey on green communications using adaptive link rate[J].Cluster Computing,2013,16(3):575-589．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13081300002183&amp;v=MTc0NDNpclJkR2VycVFUTW53WmVadUh5am1VTGZJSmw4VmFoWT1OajdCYXJLN0h0bk5ySTlGWk9zTkRYUTZvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        Bilal K,Khan S U,Madani S A,et al.A survey on green communications using adaptive link rate[J].Cluster Computing,2013,16(3):575-589．
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_24" title="Pinheiro E,Bianchini R,Carrera E V,et al.Load balancing and unbalancing for power and performance in cluster-based systems[C]∥Proc of the Workshop on Compilers&amp;amp;Operating Systems for Low Power,2001:1-8．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Load Balancing and Unbalancing for power and performance in Cluster-Based Systems">
                                        <b>[24]</b>
                                        Pinheiro E,Bianchini R,Carrera E V,et al.Load balancing and unbalancing for power and performance in cluster-based systems[C]∥Proc of the Workshop on Compilers&amp;amp;Operating Systems for Low Power,2001:1-8．
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_25" title="Liu Y,Zhu H.A survey of the research on power management techniques for high-performance systems[J].Software Practice&amp;amp;Experience,2010,40(11):943-964．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001284484&amp;v=MTk0MDNOcllkQllPTUxZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDRGxWYjdKSUZvPU5pZmNhck80SHRI&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                        Liu Y,Zhu H.A survey of the research on power management techniques for high-performance systems[J].Software Practice&amp;amp;Experience,2010,40(11):943-964．
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_26" title="Intel Corporation.ACPI:Advanced configuration and power interface[EB/OL].[2019-02-26].http：//www.acpi.info/．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ACPI:Advanced configuration and power interface">
                                        <b>[26]</b>
                                        Intel Corporation.ACPI:Advanced configuration and power interface[EB/OL].[2019-02-26].http：//www.acpi.info/．
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_27" title="Intel Corporation.Intel64and IA-32architectures software developer’s manual[EB/OL].[2019-02-26].https：//software.intel.com/en-us/articles/intel-sdm．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Intel64and IA-32architectures software developer&amp;#39;&amp;#39;s manual">
                                        <b>[27]</b>
                                        Intel Corporation.Intel64and IA-32architectures software developer’s manual[EB/OL].[2019-02-26].https：//software.intel.com/en-us/articles/intel-sdm．
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_28" title="Intel Corporation.Difference between deep and deeper sleep states for processors[EB/OL].[2019-02-26].https：//www.intel.com/content/www/us/en/support/articles/000006619/processors/intel-core-processors.html．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Difference between deep and deeper sleep states for processors">
                                        <b>[28]</b>
                                        Intel Corporation.Difference between deep and deeper sleep states for processors[EB/OL].[2019-02-26].https：//www.intel.com/content/www/us/en/support/articles/000006619/processors/intel-core-processors.html．
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_29" title="Janzen J.Calculating memory system power for DDRSDRAM[J].Micro Designline,2001,10(2):1-12．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Calculating Memory System Power for DDR SDRAM">
                                        <b>[29]</b>
                                        Janzen J.Calculating memory system power for DDRSDRAM[J].Micro Designline,2001,10(2):1-12．
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_30" title="Pandey V,Jiang W,Zhou Y,et al.DMA-aware memory energy management[C]∥Proc of the 12th International Symposium on High-Performance Computer Architecture(HP-CA’06),2006:133-144．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DMA-aware Memory Energy Management">
                                        <b>[30]</b>
                                        Pandey V,Jiang W,Zhou Y,et al.DMA-aware memory energy management[C]∥Proc of the 12th International Symposium on High-Performance Computer Architecture(HP-CA’06),2006:133-144．
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_31" title="Colarelli D,Grunwald D.Massive arrays of idle disks for storage archives[C]∥Proc of the 2002ACM/IEEE Conference on Supercomputing(SC’02),2002:1-11．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Massive arrays of idle disks for storage archives">
                                        <b>[31]</b>
                                        Colarelli D,Grunwald D.Massive arrays of idle disks for storage archives[C]∥Proc of the 2002ACM/IEEE Conference on Supercomputing(SC’02),2002:1-11．
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_32" title="Pinheiro E,Bianchini R,Dubnicki C.Exploiting redundancy to conserve energy in storage systems[J].ACM SIGMET-RICS Performance Evaluation Review,2006,34(1):15-26．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000057069&amp;v=MDkwNjI0SURIb3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKbDhWYWhZPU5pZklZN0s3SHRqTnI0OUZaTw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[32]</b>
                                        Pinheiro E,Bianchini R,Dubnicki C.Exploiting redundancy to conserve energy in storage systems[J].ACM SIGMET-RICS Performance Evaluation Review,2006,34(1):15-26．
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_33" title="Chen G,He W,Liu J,et al.Energy-aware server provisioning and load dispatching for connection-intensive internet services[C]∥Proc of the 5th USENIX Symposium on Networked Systems Design and Implementation(NSDI’08),2008:337-350．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Energy-aware server provisioning and load dispatching for connection-intensive internet services">
                                        <b>[33]</b>
                                        Chen G,He W,Liu J,et al.Energy-aware server provisioning and load dispatching for connection-intensive internet services[C]∥Proc of the 5th USENIX Symposium on Networked Systems Design and Implementation(NSDI’08),2008:337-350．
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_34" title="Liu J,Zhao F,Liu X,et al.Challenges towards elastic power management in internet data centers[C]∥Proc of the2nd International Workshop on Cyber-Physical Systems(WCPS’09),2009:65-72．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Challenges towards elastic power management in internet data centers">
                                        <b>[34]</b>
                                        Liu J,Zhao F,Liu X,et al.Challenges towards elastic power management in internet data centers[C]∥Proc of the2nd International Workshop on Cyber-Physical Systems(WCPS’09),2009:65-72．
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_35" title="Kliazovich D,Bouvry P,Khan S U.DENS:Data center energy-efficient network-aware scheduling[J].Cluster Computing,2013,16(1):65-75．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130410199617&amp;v=MzExMTg1TWJlME9DeE04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDdnRVN25KSVY0UU5qN0Jhcks3SHRYTnI0&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[35]</b>
                                        Kliazovich D,Bouvry P,Khan S U.DENS:Data center energy-efficient network-aware scheduling[J].Cluster Computing,2013,16(1):65-75．
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_36" title="Chen C R,Chen J,Chang E C.Reducing static energy in supercomputer interconnection networks using topology-aware partitioning[J].IEEE Transactions on Computers,2016,65(8):2588-2602．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reducing static energy in supercomputer interconnection networks using topology-aware partitioning">
                                        <b>[36]</b>
                                        Chen C R,Chen J,Chang E C.Reducing static energy in supercomputer interconnection networks using topology-aware partitioning[J].IEEE Transactions on Computers,2016,65(8):2588-2602．
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_37" title="Benini L,Bogliolo A,Micheli G D.A survey of design techniques for system-level dynamic power management[J].Hardware/Software Co-Design,2000,8(3):299-316．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A survey of design techniques for system-level dynamic power management">
                                        <b>[37]</b>
                                        Benini L,Bogliolo A,Micheli G D.A survey of design techniques for system-level dynamic power management[J].Hardware/Software Co-Design,2000,8(3):299-316．
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_38" title="Meisner D,Wenisch T F.DreamWeaver:Architectural support for deep sleep[J].ACM SIGARCH Computer Architecture News,2012,40(1):313-324．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000015130&amp;v=MDk3NTdIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKbDhWYWhZPU5pZklZN0s3SHRqTnI0OUZaT29LRFg4NW9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[38]</b>
                                        Meisner D,Wenisch T F.DreamWeaver:Architectural support for deep sleep[J].ACM SIGARCH Computer Architecture News,2012,40(1):313-324．
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_39" title="Louis R.Dryad:Distributed data-parallel programs from sequential building blocks[J].ACM SIGOPS Operating Systems Review,2007,41(3):59-72．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001922&amp;v=MDAzOThmSUpsOFZhaFk9TmlmSVk3SzdIdGpOcjQ5RlpPc09CWDQ3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[39]</b>
                                        Louis R.Dryad:Distributed data-parallel programs from sequential building blocks[J].ACM SIGOPS Operating Systems Review,2007,41(3):59-72．
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_40" title="Nedevschi S,Popa L,Iannaccone G,et al.Reducing network energy consumption via sleeping and rate-adaptation[C]∥Proc of USENIX Symposium on Networked Systems Design&amp;amp;Implementation(NSDI’08),2008:323-336．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reducing Network Energy Consumption via Sleeping and Rate-adaptation">
                                        <b>[40]</b>
                                        Nedevschi S,Popa L,Iannaccone G,et al.Reducing network energy consumption via sleeping and rate-adaptation[C]∥Proc of USENIX Symposium on Networked Systems Design&amp;amp;Implementation(NSDI’08),2008:323-336．
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_41" title="Wallace S,Yang X,Vishwanath V,et al.A data driven scheduling approach for power management on HPC systems in High Performance Computing[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis(SC’16),2016:56:1-56．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A data driven scheduling approach for power management on HPC systems in High Performance Computing">
                                        <b>[41]</b>
                                        Wallace S,Yang X,Vishwanath V,et al.A data driven scheduling approach for power management on HPC systems in High Performance Computing[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis(SC’16),2016:56:1-56．
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_42" title="Graham S L,Snir M,Patterson C A.Getting up to speed:The future of supercomputing[M].Washington:Committee on the Future of Supercomputing,National Research Council,National Academies Press,2005．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Getting up to speed:The future of supercomputing">
                                        <b>[42]</b>
                                        Graham S L,Snir M,Patterson C A.Getting up to speed:The future of supercomputing[M].Washington:Committee on the Future of Supercomputing,National Research Council,National Academies Press,2005．
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_43" title="Chen Y,Das A,Qin W,et al.Managing server energy and operational costs in hosting centers[C]∥Proc of the 2005ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems,2005:303-314．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Managing server energy and operational costs in hosting centers">
                                        <b>[43]</b>
                                        Chen Y,Das A,Qin W,et al.Managing server energy and operational costs in hosting centers[C]∥Proc of the 2005ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems,2005:303-314．
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_44" title="Horvath T,Skadron K.Multi-mode energy management for multi-tier server clusters[C]∥Proc of the 17th International Conference on Parallel Architectures and Compilation Techniques(PACT’08),2008:270-279．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-mode energy management for multi-tier server clusters">
                                        <b>[44]</b>
                                        Horvath T,Skadron K.Multi-mode energy management for multi-tier server clusters[C]∥Proc of the 17th International Conference on Parallel Architectures and Compilation Techniques(PACT’08),2008:270-279．
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_45" title="Wu F,Chen J,Chen Z,et al.A holistic energy-efficient approach for a processor-memory system[J].Tsinghua Science and Technology,2019,24(4):468-483．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QHDY201904010&amp;v=MTY3MTlHRnJDVVJMT2VaZVJtRnk3a1VyL01OQ1hQZDdHNEg5ak1xNDlFWklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[45]</b>
                                        Wu F,Chen J,Chen Z,et al.A holistic energy-efficient approach for a processor-memory system[J].Tsinghua Science and Technology,2019,24(4):468-483．
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_46" title="Komoda T,Hayashi S,Nakada T,et al.Power capping of CPU-GPU heterogeneous systems through coordinating DVFS and task mapping[C]∥Proc of the 31st International Conference on Computer Design(ICCD 2013),2013:349-356．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Power capping of CPU-GPU heterogeneous systems through coordinating DVFS and task mapping">
                                        <b>[46]</b>
                                        Komoda T,Hayashi S,Nakada T,et al.Power capping of CPU-GPU heterogeneous systems through coordinating DVFS and task mapping[C]∥Proc of the 31st International Conference on Computer Design(ICCD 2013),2013:349-356．
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_47" title="Mei J,Li K L,Li K Q.Energy-aware task scheduling in heterogeneous computing environments[J].Cluster Computing,2014,17(2):537-550．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14060600000895&amp;v=Mjc1MjFlWnVIeWptVUxmSUpsOFZhaFk9Tmo3QmFySzhIdGZNcVk5RlpPc1BCSFU4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[47]</b>
                                        Mei J,Li K L,Li K Q.Energy-aware task scheduling in heterogeneous computing environments[J].Cluster Computing,2014,17(2):537-550．
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_48" title="Garey M R,Johnson D S.Computers and intractability:Aguide to the theory of NP-completeness[M].New York:W.H.Freeman&amp;amp;Co,1979．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computers and intractability: a guide to the theory of NP-completeness">
                                        <b>[48]</b>
                                        Garey M R,Johnson D S.Computers and intractability:Aguide to the theory of NP-completeness[M].New York:W.H.Freeman&amp;amp;Co,1979．
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_49" title="Ullman J D.NP-complete scheduling problems[J].Journal of Computer and Systems Sciences,1975,10(3):384-393．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=NP -complete scheduling problems">
                                        <b>[49]</b>
                                        Ullman J D.NP-complete scheduling problems[J].Journal of Computer and Systems Sciences,1975,10(3):384-393．
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_50" title="Kwok Y K,Ahmad I.Benchmarking the task graph scheduling algorithms[C]∥Proc of the 1st International Parallel Processing Symposium,1998:531-537．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Benchmarking the task graph scheduling algorithms">
                                        <b>[50]</b>
                                        Kwok Y K,Ahmad I.Benchmarking the task graph scheduling algorithms[C]∥Proc of the 1st International Parallel Processing Symposium,1998:531-537．
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_51" title="Wu F,Juan C,Dong Y,et al.Improve energy efficiency by processor overclocking and memory frequency scaling[C]∥Proc of the 20th International Conference on High Performance Computing and Communications(HPCC’18),2018:960-967．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improve energy efficiency by processor overclocking and memory frequency scaling">
                                        <b>[51]</b>
                                        Wu F,Juan C,Dong Y,et al.Improve energy efficiency by processor overclocking and memory frequency scaling[C]∥Proc of the 20th International Conference on High Performance Computing and Communications(HPCC’18),2018:960-967．
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_52" title="Feitelson D G,Rudolph L,Schwiegelhohn U,et al.Theory and practice in parallel job scheduling[J].Lecture Notes in Computer Science,1997,1291(13):1-34．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Theory and practice in parallel job scheduling">
                                        <b>[52]</b>
                                        Feitelson D G,Rudolph L,Schwiegelhohn U,et al.Theory and practice in parallel job scheduling[J].Lecture Notes in Computer Science,1997,1291(13):1-34．
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_53" title="Majumdar S,Eager D L,Bunt R B.Scheduling in multiprogrammed parallel systems[C]∥Proc of SIGMETRICS Conference on Measurement and Modeling of Computer Systems,1988:104-113．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scheduling in multiprogrammed parallel systems">
                                        <b>[53]</b>
                                        Majumdar S,Eager D L,Bunt R B.Scheduling in multiprogrammed parallel systems[C]∥Proc of SIGMETRICS Conference on Measurement and Modeling of Computer Systems,1988:104-113．
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_54" title="Cime W,Desai N.Job scheduling strategies for parallel processing[J].Computer Science,2014,2862(4):128-152．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Job scheduling strategies for parallel processing">
                                        <b>[54]</b>
                                        Cime W,Desai N.Job scheduling strategies for parallel processing[J].Computer Science,2014,2862(4):128-152．
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_55" title="Celik B,Suryanarayanan S,Maciejewski A A,et al.A comparison of three parallel processing methods for a resource allocation problem in the smart grid[C]∥Proc of 2017North American Power Symposium(NAPS),2017:1-7．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A comparison of three parallel processing methods for a resource allocation problem in the smart grid">
                                        <b>[55]</b>
                                        Celik B,Suryanarayanan S,Maciejewski A A,et al.A comparison of three parallel processing methods for a resource allocation problem in the smart grid[C]∥Proc of 2017North American Power Symposium(NAPS),2017:1-7．
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_56" title="Lifka D.The ANL/IBM SP scheduling system[C]∥Proc of the Workshop on Job Scheduling Strategies for Parallel Processing(IPPS’95),1995:187-191．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The anl/ibm sp scheduling system">
                                        <b>[56]</b>
                                        Lifka D.The ANL/IBM SP scheduling system[C]∥Proc of the Workshop on Job Scheduling Strategies for Parallel Processing(IPPS’95),1995:187-191．
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_57" title="Maheswaran M,Ali S,Siegil H J,et al.Dynamic mapping of a class of independent tasks onto heterogeneous computing systems[J].Journal of Parallel&amp;amp;Distributed Computing,1999,59(2):107-131．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100265297&amp;v=MjA4NjRVTGZJSmw4VmFoWT1OaWZPZmJLN0h0RE9ybzlGWnUwS0RuVStvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[57]</b>
                                        Maheswaran M,Ali S,Siegil H J,et al.Dynamic mapping of a class of independent tasks onto heterogeneous computing systems[J].Journal of Parallel&amp;amp;Distributed Computing,1999,59(2):107-131．
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_58" title="Mu’alem A W,Feitelson D G.Utilization,predictability,workloads,and user runtime estimates in scheduling the IBM SP2 with backfilling[J].Parallel&amp;amp;Distributed Systems,2001,12(6):529-543．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Utilization, predictability, workloads, and user runtime estimates in scheduling the IBM SP2 with backfilling">
                                        <b>[58]</b>
                                        Mu’alem A W,Feitelson D G.Utilization,predictability,workloads,and user runtime estimates in scheduling the IBM SP2 with backfilling[J].Parallel&amp;amp;Distributed Systems,2001,12(6):529-543．
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_59" title="Dong Jing.Design and research of low power resource management in high performance parallel computing system[D].Changsha:National University of Defense Technology,2009.(in Chinese）" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Design and research of low power resource management in high performance parallel computing system">
                                        <b>[59]</b>
                                        Dong Jing.Design and research of low power resource management in high performance parallel computing system[D].Changsha:National University of Defense Technology,2009.(in Chinese）
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_60" title="Chandio A A,Bllal K,Tziritas N,et al.A comparative study on resource allocation and energy efficient job scheduling strategies in large-scale parallel computing systems[J].Cluster Computing,2014,17(4):1349-1367．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111900010533&amp;v=MjAyMTA5RlpPb1BDWDg2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmw4VmFoWT1OajdCYXJLOEg5RE5wbw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[60]</b>
                                        Chandio A A,Bllal K,Tziritas N,et al.A comparative study on resource allocation and energy efficient job scheduling strategies in large-scale parallel computing systems[J].Cluster Computing,2014,17(4):1349-1367．
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_61" title="Cai Li-jun,Pan Jiang-bo,Chen Lei,et al.A parallel scheduling energy consumption optimization algorithm based on busy hours[J].Computer Engineering&amp;amp;Science,2017,39(1):42-48.(in Chinese）" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A parallel scheduling energy consumption optimization algorithm based on busy hours">
                                        <b>[61]</b>
                                        Cai Li-jun,Pan Jiang-bo,Chen Lei,et al.A parallel scheduling energy consumption optimization algorithm based on busy hours[J].Computer Engineering&amp;amp;Science,2017,39(1):42-48.(in Chinese）
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_62" title="Li B,Li J,Huai J,et al.EnaCloud:An energy-saving application live placement approach for cloud computing environments[C]∥Proc of 2009IEEE International Conference on Cloud Computing,2009:17-24．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enacloud:An energy-saving application live placement approach for cloud computing environments">
                                        <b>[62]</b>
                                        Li B,Li J,Huai J,et al.EnaCloud:An energy-saving application live placement approach for cloud computing environments[C]∥Proc of 2009IEEE International Conference on Cloud Computing,2009:17-24．
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_63" title="Shalom M,Voloshin A,Wong P W H,et al.Online optimization of busy time on parallel machines[C]∥Proc of the9th Annual Conference on Theory and Applications of Models of Computation,2012:448-460．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online optimization of busy time on parallel machines">
                                        <b>[63]</b>
                                        Shalom M,Voloshin A,Wong P W H,et al.Online optimization of busy time on parallel machines[C]∥Proc of the9th Annual Conference on Theory and Applications of Models of Computation,2012:448-460．
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_64" title="Zhu Ming-fa,Pang Yu,Liang Ai-hua,et al.A job scheduling method for optimizing the energy consumption of multi-task communication:China,201110333204.3[P].2011-10-28.(in Chinese）" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A job scheduling method for optimizing the energy consumption of multi-task communication">
                                        <b>[64]</b>
                                        Zhu Ming-fa,Pang Yu,Liang Ai-hua,et al.A job scheduling method for optimizing the energy consumption of multi-task communication:China,201110333204.3[P].2011-10-28.(in Chinese）
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_65" title="Ahmad I.Editorial:Resource management of parallel and distributed systems with static scheduling:Challenges,solutions and new problems[J].Concurrency&amp;amp;Computation Practice&amp;amp;Experience,2010,7(5):339-347．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Editorial:Resource management of parallel and distributed systems with static scheduling:Challenges,solutions and new problems">
                                        <b>[65]</b>
                                        Ahmad I.Editorial:Resource management of parallel and distributed systems with static scheduling:Challenges,solutions and new problems[J].Concurrency&amp;amp;Computation Practice&amp;amp;Experience,2010,7(5):339-347．
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_66" title="Khandekar R,Schieber B,Shachnai H,et al.Minimizing busy time in multiple machine real-time scheduling[C]∥Proc of IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science,2010:169-180．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Minimizing busy time in multiple machine real-time scheduling">
                                        <b>[66]</b>
                                        Khandekar R,Schieber B,Shachnai H,et al.Minimizing busy time in multiple machine real-time scheduling[C]∥Proc of IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science,2010:169-180．
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_67" title="Tian W,Xiong Q,Cao J.An online parallel scheduling method with application to energy-efficiency in cloud computing[J].Journal of Supercomputing,2013,66(3):1773-1790．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An online parallel scheduling method with application to energy-efficiency in cloud computing">
                                        <b>[67]</b>
                                        Tian W,Xiong Q,Cao J.An online parallel scheduling method with application to energy-efficiency in cloud computing[J].Journal of Supercomputing,2013,66(3):1773-1790．
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_68" title="Kluscek D,Park B.Analysis of mixed workloads from shared cloud infrastructure[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2017:25-42．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analysis of mixed workloads from shared cloud infrastructure">
                                        <b>[68]</b>
                                        Kluscek D,Park B.Analysis of mixed workloads from shared cloud infrastructure[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2017:25-42．
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_69" >
                                        <b>[69]</b>
                                    Wang Jie,Zeng Yu.Research on job scheduling strategy of high performance computer based on adaptive power management[J].Computer Science,2012,39(10):313-317.(in Chinese）</a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_70" title="Ranganathan P,Leech P,Irwin D,et al.Ensemble-level power management for dense blade servers[C]∥Proc of the33rd International Symposium on Computer Architecture,2006:66-77．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ensemble-level power management for dense bladeservers">
                                        <b>[70]</b>
                                        Ranganathan P,Leech P,Irwin D,et al.Ensemble-level power management for dense blade servers[C]∥Proc of the33rd International Symposium on Computer Architecture,2006:66-77．
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_71" title="Wu C.The importance of being low power in high performance computing[J].Cyberinfrastructure Technology Watch Quarterly(CTWatch Quarterly),2005,1(3):12-20．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Importance of Being Low Power in High Performance Computing">
                                        <b>[71]</b>
                                        Wu C.The importance of being low power in high performance computing[J].Cyberinfrastructure Technology Watch Quarterly(CTWatch Quarterly),2005,1(3):12-20．
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_72" title="Sarood O,Meneses E,Kale L V.A‘cool’way of improving the reliability of HPC machines[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis,2013:Article No.58．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A&amp;#39;&amp;#39;cool&amp;#39;&amp;#39;way of improving the reliability of HPC machines">
                                        <b>[72]</b>
                                        Sarood O,Meneses E,Kale L V.A‘cool’way of improving the reliability of HPC machines[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis,2013:Article No.58．
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_73" title="Lee E K,Kulkarni I,Pompili D,et al.Proactive thermal management in green datacenters[J].Journal of Supercomputing,2012,60(2):165-195．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDC261C3CC7D17A362934345FC7F74A369&amp;v=Mjg4NjFCdUhZZk9HUWxmQ3BiUTM1TkJod3JtK3dLdz1OajdCYXNDNkdOQy9yUHcyWTU4T0N3MDZ5UlFhNlR0K1RIcVUzeFZEZnJibFJyeVdDT052RlNpV1dyN0pJRnBtYQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[73]</b>
                                        Lee E K,Kulkarni I,Pompili D,et al.Proactive thermal management in green datacenters[J].Journal of Supercomputing,2012,60(2):165-195．
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_74" title="Gaussier E,Glesser D,Reis V,et al.Improving backfilling by using machine learning to predict running time[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis,2015:1-64．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving backfilling by using machine learning to predict running times">
                                        <b>[74]</b>
                                        Gaussier E,Glesser D,Reis V,et al.Improving backfilling by using machine learning to predict running time[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis,2015:1-64．
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_75" title="Rodrigo G P,Elmroth E，stberg P O,et al.ScSF:A scheduling simulation framework[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2017:152-173．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ScSF:A scheduling simulation framework">
                                        <b>[75]</b>
                                        Rodrigo G P,Elmroth E，stberg P O,et al.ScSF:A scheduling simulation framework[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2017:152-173．
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_76" title="Lopez V,Jokanovic A,Amico M D,et al.DJSB:Dynamic job scheduling benchmark[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2018:174-188．" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DJSB:Dynamic job scheduling benchmark">
                                        <b>[76]</b>
                                        Lopez V,Jokanovic A,Amico M D,et al.DJSB:Dynamic job scheduling benchmark[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2018:174-188．
                                    </a>
                                </li>
                                <li id="270">


                                    <a id="bibliography_59" title="董晶．高性能并行计算系统中低功耗资源管理的设计与研究[D]．长沙：国防科学技术大学，2009．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=2010165305.nh&amp;v=MDA5MzVxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2tVci9NVjEyNkhySytHOUxNcXBFYlBJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[59]</b>
                                        董晶．高性能并行计算系统中低功耗资源管理的设计与研究[D]．长沙：国防科学技术大学，2009．
                                    </a>
                                </li>
                                <li id="272">


                                    <a id="bibliography_61" title="蔡立军，潘江波，陈磊，等．一种基于繁忙时间的并行调度能耗优化算法[J]．计算机工程与科学，2017,39(1):42-48．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201701005&amp;v=MTk5NjJDVVJMT2VaZVJtRnk3a1VyL01MejdCWmJHNEg5Yk1ybzlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[61]</b>
                                        蔡立军，潘江波，陈磊，等．一种基于繁忙时间的并行调度能耗优化算法[J]．计算机工程与科学，2017,39(1):42-48．
                                    </a>
                                </li>
                                <li id="274">


                                    <a id="bibliography_64" title="祝明发，庞瑜，梁爱华，等．一种优化多任务间通信能耗的作业调度方法：中国，201110333204.3[P].2011-10-28．" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SCPD&amp;filename=CN102364447A&amp;v=MjUwODVyRzdHTlhJcTRnMEMrNFBEMzFMeHhZVDZ6b09TM2ZtcFdGYWU3S1ZUTHVkWmU5dUVTbmtVN3M9SmlPNkg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[64]</b>
                                        祝明发，庞瑜，梁爱华，等．一种优化多任务间通信能耗的作业调度方法：中国，201110333204.3[P].2011-10-28．
                                    </a>
                                </li>
                                <li id="276">


                                    <a id="bibliography_69" title="王洁，曾宇．基于自适应功耗管理的高性能计算机作业调度策略的研究[J]．计算机科学，2012,39(10):313-317." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201210072&amp;v=MDYyNTVDWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3a1VyL01MejdCYjdHNEg5UE5yNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[69]</b>
                                        王洁，曾宇．基于自适应功耗管理的高性能计算机作业调度策略的研究[J]．计算机科学，2012,39(10):313-317.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(09),1525-1533 DOI:10.3969/j.issn.1007-130X.2019.09.001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>用于高性能计算的作业调度能效性研究综述</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E6%96%87%E6%97%AD&amp;code=42876318&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑文旭</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%BD%98%E6%99%93%E4%B8%9C&amp;code=42876319&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">潘晓东</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E8%BF%AA&amp;code=34613092&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马迪</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%AA%E6%B5%A9&amp;code=20590691&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汪浩</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%BD%E9%98%B2%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0269230&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国防科技大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>由于科学研究与商业应用等对高性能计算的需求与日俱增,高性能计算的性能和系统规模得到迅速发展。但是,急剧增长的功耗严重限制了高性能计算系统的设计和使用,使得低功耗技术成为高性能计算领域的关键技术。作为整个系统的核心组件,作业调度系统立足有限的系统资源,对用户提交的应用进行作业-资源分配,其能效性对于整个高性能计算系统的能耗控制与调节起到至关重要的作用。首先介绍主要的能量效率技术和常用的作业调度策略,然后对当前高性能计算作业调度能效性进行分析,并讨论了其面临的挑战及未来发展方向。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高性能计算;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%9C%E4%B8%9A%E8%B0%83%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">作业调度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%BD%E9%87%8F%E6%9C%89%E6%95%88%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">能量有效性;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郑文旭（1988-），男，湖南邵东人，硕士生，研究方向为系统软件。E-mail:zhengwen5241@qq.com,通信地址：410073湖南省长沙市国防科技大学计算机学院&lt;image id="111" type="formula" href="images/JSJK201909001_11100.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    潘晓东（1989-），男，河南驻马店人，硕士生，研究方向为高性能计算。E-mail:sheldon.pan@hotmail.com,通信地址：410073湖南省长沙市国防科技大学计算机学院&lt;image id="113" type="formula" href="images/JSJK201909001_11300.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    马迪（1988-），男，四川广元人，硕士，工程师，研究方向为高性能计算。E-mail:535907803@qq.com,通信地址：410073湖南省长沙市国防科技大学计算机学院&lt;image id="115" type="formula" href="images/JSJK201909001_11500.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    汪浩（1990-），男，安徽铜陵人，硕士生，研究方向为高性能计算。E-mail:wanghao18d@nudt.edu.cn,通信地址：410073湖南省长沙市国防科技大学计算机学院&lt;image id="117" type="formula" href="images/JSJK201909001_11700.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家数值风洞项目(NNW2018-ZT6B13);</span>
                    </p>
            </div>
                    <h1><b>Overview on the energy efficiency of job scheduling for high performance computing</b></h1>
                    <h2>
                    <span>ZHENG Wen-xu</span>
                    <span>PAN Xiao-dong</span>
                    <span>MA Di</span>
                    <span>WANG Hao</span>
            </h2>
                    <h2>
                    <span>School of Computer,National University of Defense Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Due to the increasing demand for high performance computing in scientific research and commercial applications, the performance and system scale of high performance computing are developing rapidly. However, the rapid increase in power consumption severely limits the design and use of high-performance computing(HPC) systems, which makes low-power technologies become the key technology in the HPC field. As the core component of the whole system and based on limited system resources, the job scheduling system distributes job resources to the applications submitted by the users. Its energy efficiency plays an important role in the control and regulation of the energy consumption of the whole HPC system. We first introduce the main energy efficiency techniques and common job scheduling strategies, then analyze the energy efficiency of current HPC job scheduling, and discuss the challenges it faces and future development directions.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=high%20performance%20computing%20(HPC)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">high performance computing (HPC);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=job%20scheduling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">job scheduling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=energy%20efficiency&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">energy efficiency;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHENG Wen-xu,born in 1988,MS candidate,his research interest includes system software,Address:School of Computer,National University of Defense Technology,Changsha 410073,Hunan,P.R.China;
                                </span>
                                <span>
                                    PAN Xiao-dong,born in 1989,MS can-didate,his research interest includes high performance computing,Address:School of Computer,National University of Defense Technology,Changsha 410073,Hunan,P.R.China;
                                </span>
                                <span>
                                    MA Di,born in 1988,MS,engineer,his research interest includes high performance computing,Address:School of Computer,National University of Defense Technology,Changsha 410073,Hunan,P.R.China;
                                </span>
                                <span>
                                    WANG Hao,born in 1990,MS candi-date,his research interest includes high performance computing,Address:School of Computer,National University of Defense Technology,Changsha 410073,Hunan,P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="42">过去几十年中,高性能计算HPC(High Performance Computing)在能源、生物、气象、科研、地质勘探等计算密集型应用中得到长足发展。随着应用程序趋向于大型化、并行化,需要更高性能的分布式计算系统,而系统性能的快速提升又带来组件密度的增加,能耗问题随之引起人们普遍关注。IBM发布报告<citation id="278" type="reference"><link href="118" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>指出实现百亿亿次计算系统的5大瓶颈,其中能耗瓶颈排在首位。2014年美国能源局更是将能量和功耗问题作为未来E级系统面临的首要挑战<citation id="279" type="reference"><link href="120" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。根据“功耗摩尔定律”,每隔18个月计算机结点功耗就会翻倍<citation id="280" type="reference"><link href="122" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。未来更大规模的高性能计算系统功耗更将不断攀升,其发展将面临严重的功耗危机,将会在一定程度上阻碍其快速发展。</p>
                </div>
                <div class="p1">
                    <p id="43">Ge等人<citation id="281" type="reference"><link href="124" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>研究了5台超级计算机,发现这些高性能计算系统的性能仅为峰值性能的54%～71%,在实际应用中,其性能仅为峰值的10%。如此低的性能比重主要是缘自于在庞大的集群中,各种计算、通信和I/O操作在结点之间的分布不均衡,导致部分结点运行速度相差太大,大量的松弛时间(Slack Time)造成了计算资源和能量的浪费。为了控制负载分配,作业调度策略在处理器数量有限的高性能计算系统中对用户提交的应用程序进行作业-资源分配<sup></sup><citation id="282" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>,这对于合理利用计算结点并确保并行作业高效运行起到重要作用。</p>
                </div>
                <div class="p1">
                    <p id="44">本文主要对高性能计算系统中作业调度能量有效性进行综述,能量有效性(Energy-Efficiency of Job Scheduling System,下文简称“能效性”)为单位时间内结点负载与能量消耗之间的比值,用于衡量系统在作业调度过程中的能量效率。对于不断发展的高性能计算系统,能提供给用户作业负载运行的计算资源已经不再是设计并行作业调度策略的唯一考虑因素,由于庞大的系统引发的能耗问题日益突出,因此如何最大化作业调度能量有效性成为关键因素。</p>
                </div>
                <div class="p1">
                    <p id="45">本文第2节介绍作业调度能效的研究背景,主要是被广泛运用于高性能计算系统中的动态电压频率调节DVFS(Dynamic Voltage and Frequency Scaling)和动态功耗管理DPM(Dynamic Power Management)两个传统的能量效率技术。</p>
                </div>
                <div class="p1">
                    <p id="46">第3节对作业调度系统、算法进行了回顾,这些单纯的策略主要以提升资源利用率,减少资源碎片,提升作业吞吐率,减少饥饿作业为目的,并没有充分考虑作业在不同结点上运行时功耗的变化,也没有考虑作业的能效需求差异。由于没有足够的作业负载,以及作业调度和资源分配策略无法充分利用系统资源,常常会有空闲资源浪费系统能耗的情况。</p>
                </div>
                <div class="p1">
                    <p id="47">作业调度策略研究领域的相关技术发展,融合了应用和系统层面,追求既能满足用户实时需求,又能最大化利用系统资源,从而在一定程度上提高作业调度能效性。第4节将介绍调度系统、调度算法能效性优化技术和自适应功耗管理策略等。这些方法在一定程度上提高了资源利用率,缩短了作业等待时间,提高了高性能计算系统总体性能,同时也兼顾了作业调度的能效性,取得了一定的积极效果。</p>
                </div>
                <div class="p1">
                    <p id="48">当前,作业调度能效性的研究处于起步阶段,仍然有许多地方亟待研究人员深入研究。在第5节中,我们讨论了高性能计算作业调度能效性的主要挑战,以及未来应该关注的方向,包括:计算认知能力、设备异构性、调度公平性等方面。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag"><b>2 背景</b></h3>
                <div class="p1">
                    <p id="50">高性能计算主要在分布式集群或超级计算机上进行,对于传统的高性能计算应用,研究人员主要关注的是系统的性能、可靠性和安全问题,因此在高性能计算中节约能耗的问题并没有得到足够的关注<citation id="283" type="reference"><link href="128" rel="bibliography" /><link href="130" rel="bibliography" /><link href="132" rel="bibliography" /><link href="134" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。近年来,随着现代数据中心能源需求的稳步增长,人们开始意识到能源消耗问题也是至关重要的。</p>
                </div>
                <div class="p1">
                    <p id="51">起初,研究人员主要研究计算机系统内部对功率感知的处理器和内存设计技术,提出了静态与动态的功率管理方法<citation id="284" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>,分别从热感知的硬件设计和功率感知的软件设计方面入手<citation id="285" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,以降低处理器和内存资源的能耗。文献<citation id="286" type="reference">[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</citation>将能效性策略主要归结为:(1)动态电压频率调节DVFS技术;(2)动态功耗管理DPM技术;(3)提高服务器、存储器和冷却效率的技术;(4)多核处理器设计;(5)虚拟化技术。</p>
                </div>
                <div class="p1">
                    <p id="52">由于在整个高性能计算系统中,处理器的功耗占总功耗的很大一部分(作业负载时,处理器能耗占整个结点能耗的将近50%<citation id="287" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>;在超级计算机中,CPU支配着整个系统功耗的35%<citation id="288" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>),负载功率越高,能耗越大。控制CPU功耗的DVFS技术<citation id="289" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>能够通过降低电源电压或时钟频率来降低功耗,这已经成为一个热门的研究课题<citation id="293" type="reference"><link href="154" rel="bibliography" /><link href="156" rel="bibliography" /><link href="158" rel="bibliography" /><link href="160" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>,被广泛应用于Intel Xeon、AMD Atholon和ATI co-processors等处理器中。越少的工作负载导致越少的能耗,这是能量比例技术的概念,DVFS就是这个技术的一个例子<citation id="290" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。DVFS可以被分为2个层次<citation id="291" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>:行为层和系统层。在行为层中,一旦一个功能单元在设计期间确定了功率电压,它在运行过程中将保持不变;在系统层中,处理器的供电电压可以在运行过程中发生变化,这就为降低系统能耗提供了更大的灵活性和潜力。因此,利用DVFS进行功耗调整,主要是在系统层面上。Etinski等人<citation id="292" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>基于功率配置的整型线性方程提出了利用DVFS调整结点功耗的并行作业调度策略,从而实现对整个系统功耗的控制。虽然通过在较低频率/电压下运行处理器能有效地减少总功耗,但也可能会以增加作业执行时间为代价<citation id="294" type="reference"><link href="126" rel="bibliography" /><link href="164" rel="bibliography" /><link href="166" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">24</a>,<a class="sup">25</a>]</sup></citation>。为了缩短作业执行时间,研究者提出了在给定功耗阈值的情况下提高功率的方法(将在第4节中介绍),但也无法显著地节省功耗,更有可能给硬件带来一定的损伤。</p>
                </div>
                <div class="p1">
                    <p id="53">随着系统结点的增多,结点间通信成为重要的能耗,尤其在大规模分布式计算系统中,通信引起的能耗是巨大的,有必要对应用与系统资源进行综合协调,以发挥最大效益。而在分布式的集群系统中,每个组件要么处于活动运行状态,要么处于不同的休眠或者断电状态。例如,在ACPI(Advanced Configuration and Power Interface)标准中<citation id="295" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>,处理器的活动状态为<i>C</i>0,而休眠状态可以分为<i>C</i>1,<i>C</i>2,…,<i>Cn</i>,不仅仅是处理器,内存、芯片、磁盘、I/O总线和其它设备都有活动、就绪与休眠等多个不同状态<citation id="299" type="reference"><link href="168" rel="bibliography" /><link href="170" rel="bibliography" /><link href="172" rel="bibliography" /><link href="174" rel="bibliography" /><link href="176" rel="bibliography" /><link href="178" rel="bibliography" /><link href="180" rel="bibliography" /><sup>[<a class="sup">26</a>,<a class="sup">27</a>,<a class="sup">28</a>,<a class="sup">29</a>,<a class="sup">30</a>,<a class="sup">31</a>,<a class="sup">32</a>]</sup></citation>。Chen等人<citation id="296" type="reference"><link href="182" rel="bibliography" /><sup>[<a class="sup">33</a>]</sup></citation>研究表明,空闲状态下的元件消耗了整个系统中峰值负载电量的大约2/3,所有的功能元件在低负载或零负载时都会有大量的能耗。而事实上,一个数据中心资源的平均负载仅占总资源的30%<citation id="297" type="reference"><link href="184" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>,这就为调整大约70%资源的状态模式,从而减少空闲功耗提供了可能<citation id="298" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>。为了提高系统能效性,系统选择性地暂停设备或者调整空闲资源状态,当需要时才启动已停止工作的设备,以优化活动资源的数量,使其较准确地满足应用程序需求<citation id="300" type="reference"><link href="148" rel="bibliography" /><link href="164" rel="bibliography" /><link href="170" rel="bibliography" /><link href="188" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">24</a>,<a class="sup">27</a>,<a class="sup">36</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="54">DPM就是运用了这一项技术,动态地配置系统资源,为所运行的作业提供最小数量的活动组件或最小负载,以达到节能的效果<citation id="304" type="reference"><link href="186" rel="bibliography" /><link href="190" rel="bibliography" /><sup>[<a class="sup">35</a>,<a class="sup">37</a>]</sup></citation>。DPM技术可以运用到CPU<citation id="301" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">38</a>]</sup></citation>、存储盘、内存<citation id="302" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">39</a>]</sup></citation>、服务器和网络设备<citation id="305" type="reference"><link href="162" rel="bibliography" /><link href="186" rel="bibliography" /><link href="196" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">35</a>,<a class="sup">40</a>]</sup></citation>等不同的耗电元件,Benini等人<citation id="303" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">37</a>]</sup></citation>利用DPM方法实现了电子设备动态重新配置,为用户的服务请求提供了最小数量的活动部件,从而最小化系统能耗。</p>
                </div>
                <div class="p1">
                    <p id="55">由于这种方法高度依赖于系统工作负载,因此该方法的关键挑战是确定何时关闭哪个结点或其组件<citation id="306" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">41</a>]</sup></citation>。而且不同设备存在不同的电气性能,关闭后启动设备或者转换状态时带来的额外功耗、过渡成本难以估计,可能会超过用户设定的功耗阈值,抵销了一个或多个低功耗操作状态带来的节能效果。例如,处理器休眠程度越深,能耗越少,但唤醒处理器或转变状态都需要更多的能量<citation id="307" type="reference"><link href="172" rel="bibliography" /><link href="200" rel="bibliography" /><sup>[<a class="sup">28</a>,<a class="sup">42</a>]</sup></citation>。而且在作业调度策略中,关闭空闲结点或者状态转换并不是实时的,时效性较差<citation id="308" type="reference"><link href="202" rel="bibliography" /><link href="204" rel="bibliography" /><sup>[<a class="sup">43</a>,<a class="sup">44</a>]</sup></citation>,有悖于高性能计算对于运行速度的要求。</p>
                </div>
                <div class="p1">
                    <p id="56">DVFS和DPM是目前研究比较广泛的两种系统层级的能效性策略。DVFS相对更细粒化,更加关注处理器和内存的协调<citation id="309" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">45</a>]</sup></citation>,但也有系统级作业分配能效性的相关研究<citation id="310" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">46</a>]</sup></citation>。而DPM可以被认为是一种作业-资源调度策略,其未来发展更有可能是融合不同层次的,综合使用DVFS技术在通信计算阶段节省处理器功耗,同时在运行时将负载平衡技术用于结点内存的资源调度<citation id="311" type="reference"><link href="210" rel="bibliography" /><link href="212" rel="bibliography" /><link href="214" rel="bibliography" /><link href="216" rel="bibliography" /><link href="218" rel="bibliography" /><sup>[<a class="sup">47</a>,<a class="sup">48</a>,<a class="sup">49</a>,<a class="sup">50</a>,<a class="sup">51</a>]</sup></citation>,进一步节省能耗。经过几十年的发展,研究人员已经提出了许多作业调度算法和系统<citation id="312" type="reference"><link href="220" rel="bibliography" /><link href="222" rel="bibliography" /><link href="224" rel="bibliography" /><sup>[<a class="sup">52</a>,<a class="sup">53</a>,<a class="sup">54</a>]</sup></citation>,其关注点也逐渐从执行速度转移到能量效率上。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag"><b>3 传统作业调度策略</b></h3>
                <div class="p1">
                    <p id="58">高性能计算系统的能效性可以在3个层次上改善:(1)能效性的应用程序;(2)功率感知的资源管理系统;(3)高效率的硬件基础<citation id="313" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">46</a>]</sup></citation>。而作业调度就是在第2个层次上进行的。设计一个高效的作业调度系统并不是容易的事,因为不同的应用程序、工作负载、集群系统和调度策略的节能差异很大<citation id="314" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。作业调度最主要的功能就是根据作业调度策略从作业队列中选择合适的作业,并通知资源管理器为其分配资源<citation id="315" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>(如图1所示),主要关注运行作业所需要的资源和时间<citation id="316" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">39</a>]</sup></citation>。计算资源利用率和用户所提交的作业等待时间决定了调度策略的好坏,影响作业调度算法的因素包括了用户提交作业的序列分布、系统的利用率、单位时间内平均完成的作业数、作业的平均周转时间等。以往的高性能计算系统在设计调度策略时很少考虑能效性<citation id="317" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">37</a>]</sup></citation>,但能效性优化往往正是从以上几个方面入手的,如图1虚线框内所示。本节主要从常用的先来先服务FCFS和回填BackFill策略入手,介绍传统的作业调度策略。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201909001_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 作业调度流程及其能效性优化" src="Detail/GetImg?filename=images/JSJK201909001_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 作业调度流程及其能效性优化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201909001_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Job scheduling process and 
 its energy efficiency optimization</p>

                </div>
                <h4 class="anchor-tag" id="60" name="60"><b>3.1 先来先服务策略</b></h4>
                <div class="p1">
                    <p id="61">先来先服务FCFS(First Come First Serve)策略是一种简单的静态作业调度策略<citation id="318" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">55</a>]</sup></citation>,按到达顺序运行作业,不允许插队。一旦将一个执行时间较短的作业放在一个执行时间较长的作业后面执行,就会让该作业等待时间过长,增加了作业的等待时间<citation id="319" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">56</a>]</sup></citation>;若作业不在队首,即便有足够的空闲资源满足作业,作业也无法运行,系统资源得不到充分利用。短作业优先SJF(Shortest Job First)对FCFS进行了改进,按照作业的大小顺序进行排序,越短的作业越先运行,从而缩短了作业平均周转时间。同样地,Maheswaran等人<citation id="320" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">57</a>]</sup></citation>提出的MinET就是利用类似的作业长度进行排序。由于FCFS方式只考虑每个作业的等待时间而未考虑执行时间的长短,而SJF方式只考虑执行时间而未考虑等待时间的长短,因此SJF出现了一些变形,如最短剩余时间优先SRT(Shortest Remaining Time)和最高响应比优先HRN(Highest Response-ratio Next),但仍然无法避免系统开销的增加。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>3.2 回填策略</b></h4>
                <div class="p1">
                    <p id="63">回填(BackFill)策略<citation id="322" type="reference"><link href="228" rel="bibliography" /><link href="232" rel="bibliography" /><sup>[<a class="sup">56</a>,<a class="sup">58</a>]</sup></citation>允许作业插队,原则是优先作业的开始执行时间不可被延迟。策略根据用户提供的估计作业执行时间,为作业预留资源,在不违反原则的前提下,选择非队首作业尝试运行。回填的有效性取决于系统对执行时间估计的准确性,使得被回填的作业优于其他作业,从而提升整体作业集的性能。如果实际运行作业的运行时间长于预期值,系统将终止作业。尽管如此,即使存在不准确的估计,BackFill也减少了系统的碎片,增加了系统利用率,并最小化作业运行时间,提高了系统整体性能。美国Argonne国家实验室在IBM SP2超级计算机上使用的可扩展Argonne调度系统EASY(the Extensible Argonne Scheduling sYstem)<citation id="321" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">56</a>]</sup></citation>,就是运用了回填技术。与回填策略类似的首次适配FF(First-Fit)是在作业队列中查找能够与第一个可用空闲资源相匹配的作业,从而减少空闲结点数量,提高资源利用率和缩短作业平均等待时间,但可能导致作业饿死。</p>
                </div>
                <div class="p1">
                    <p id="64">回填策略比先来先服务策略更能保证系统不会有作业饿死,而且回填策略更利于提高系统利用率和降低作业平均等待时间。大多数情况下,回填策略比先来先服务策略更能提高系统性能,而较首次适配策略性能差距较小,且用户的不准确估计并不会对回填策略的表现造成大的影响,因此成为了大多数调度系统的选择。</p>
                </div>
                <h3 id="65" name="65" class="anchor-tag"><b>4 作业调度能效性分析</b></h3>
                <div class="p1">
                    <p id="66">在作业调度过程中,尤其对于并行计算系统,作业调度策略往往造成运行速度快、执行时间短的结点等待运行速度慢、执行时间长的结点<citation id="323" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。不同结点之间的负载不平衡不仅带来不必要的能耗,还会增加整个应用程序的执行时间,导致空闲结点能量白白浪费掉。作业调度系统节能的目标是在满足性能要求的前提下,所有任务消耗的总功耗最低,这是个NP难问题<citation id="327" type="reference"><link href="152" rel="bibliography" /><link href="212" rel="bibliography" /><link href="214" rel="bibliography" /><link href="234" rel="bibliography" /><link href="270" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">48</a>,<a class="sup">49</a>,<a class="sup">59</a>,<a class="sup">59</a>]</sup></citation>。为此,研究者做了大量的实验工作,结合不同的调度策略和能效性技术<citation id="324" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">60</a>]</sup></citation>,针对负载功率与负载时长<citation id="325" type="reference"><link href="238" rel="bibliography" /><link href="272" rel="bibliography" /><sup>[<a class="sup">61</a>,<a class="sup">61</a>]</sup></citation>,从应用层和系统层对作业调度能效性进行优化。典型的作业调度能效性策略主要考虑2个方面:(1)将作业负载整合到最少的计算资源中;(2)增加可转换为低功耗模式的计算资源数量<citation id="326" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">62</a>]</sup></citation>。下面对一些主流的作业调度能效性策略进行介绍,并在表1中进行了对比分析。</p>
                </div>
                <div class="area_img" id="67">
                    <p class="img_tit"><b>表1 作业调度能效性分析</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Analysis of job scheduling energy efficiency</b></p>
                    <p class="img_note"></p>
                    <table id="67" border="1"><tr><td><br />优化策略</td><td>优势</td><td>不足</td></tr><tr><td><br />缩短总繁忙时间</td><td>缩短作业运行时间,<br />提高资源利用率</td><td>未考虑异构性对能耗的影响</td></tr><tr><td><br />调度算法优化</td><td>优化作业-资源分配</td><td>对系统参数依赖大,与其它作业调度策略结合性差</td></tr><tr><td><br />自适应功耗管理策略</td><td>提高资源利用率,降低系统整体功耗</td><td>未充分考虑通信对能耗的影响</td></tr><tr><td><br />功率封顶(预算)技术</td><td>控制系统整体功耗</td><td>功率预算精度问题</td></tr><tr><td><br />热管理技术</td><td>控制系统整体能耗</td><td>对设备要求高</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"><b>4.1 缩短总繁忙时间</b></h4>
                <div class="p1">
                    <p id="69">评价一个作业调度系统,最普遍的标准就是衡量其负载运行时间和系统资源利用率,而降低系统能耗也是从这2个方面入手。为了节省能耗,大多数以往的研究选择降低结点频率或者直接关闭一些设备的方式,而忽略了资源利用率这一方面,这往往会造成计算资源的闲置与浪费。目前已经有许多研究致力于优化作业调度策略,使得服务器总繁忙时间(即如果服务器某一时刻至少有一个作业正在运行,那么此服务器在这一时刻是繁忙的,所有繁忙的时间总和,就是总繁忙时间)最小化,或者是在给定的繁忙时间预算约束下最大化系统资源利用率。</p>
                </div>
                <div class="p1">
                    <p id="70">Shalom等人<citation id="328" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">63</a>]</sup></citation>首先提出线上调度总繁忙时间最小化的目标,这一点比较符合当前用户缩短运行时间,以节省计算费用的需求(但没有考虑异构系统对能耗的不同影响)。蔡立军等人<citation id="329" type="reference"><link href="238" rel="bibliography" /><link href="272" rel="bibliography" /><sup>[<a class="sup">61</a>,<a class="sup">61</a>]</sup></citation>立足降低服务器运行时间,分析服务器处理作业请求的繁忙时间与能耗之间的关系,提出一种基于繁忙时间的并行调度能耗优化算法——BTEOA(Busy Time Energy Optimize Algorithm)。在保持作业请求原有的排队序列基础上,调度作业请求到能使所有服务器总繁忙时间局部最优的服务器上执行,以降低系统能耗,同时保证原有作业调度性能不受影响。但是,由于服务器系统能耗是由繁忙状态和空闲状态能耗组成,该方法只考虑服务器在处理作业请求时处于繁忙状态的时间与能耗,将功率消耗与服务CPU利用率之间的关系单纯地设为线性关系,而忽略了空闲结点的能耗问题。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>4.2 调度算法优化</b></h4>
                <div class="p1">
                    <p id="72">作业调度能效性优化是NP难问题,除了单纯地使用FCFS、回填或者其它方法外,还可以运用算法优化、路径选择等方法进行作业-资源分配。祝明发等人<citation id="330" type="reference"><link href="244" rel="bibliography" /><link href="274" rel="bibliography" /><sup>[<a class="sup">64</a>,<a class="sup">64</a>]</sup></citation>将用户提交的作业划分为具有依赖关系的多个独立任务,形成标准有向无环图DAG(Directed Acyclic Graph)模型<citation id="331" type="reference"><link href="216" rel="bibliography" /><link href="246" rel="bibliography" /><sup>[<a class="sup">50</a>,<a class="sup">65</a>]</sup></citation>,再根据DAG获知任务的前驱和后继信息,为每个任务设置1个信息表和1个通信队列,利用作业间通信消耗选择分配给作业的资源。</p>
                </div>
                <div class="p1">
                    <p id="73">Shalom等人<citation id="332" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">63</a>]</sup></citation>利用贪婪算法进行调度,首先根据设定的范围划分参数生成多个初始作业区,然后按照作业请求执行时间长短,将作业请求分装在不同的作业区,最后将作业区调度到满足条件的服务器上执行,以达到缩短服务器总繁忙时间的效果。Khandekar等人<citation id="333" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">66</a>]</sup></citation>提出最长处理时间优先结合最早开始时间作业优先MFFDE(ModiFied First Decreasing Earliest)的调度方法,以最小化服务器总繁忙时间。Tian等人<citation id="334" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">67</a>]</sup></citation>提出动态二分优先BFF(Bipartition First Fit)的调度方法,将作业请求按照结束时间分为2个执行窗口依次执行,然后按照服务器首次适配策略FF进行匹配调度,来最小化服务器总繁忙时间,从而降低系统能耗。</p>
                </div>
                <div class="p1">
                    <p id="74">这些现有的方法虽然能够在一定程度上降低能耗,但是也存在一些不足之处,比如,经常对CPU调频调压不但会影响服务器的计算性能,同时也影响硬件的电气性能;贪婪算法需要每个作业区只对应1个服务器,在一般的情形中作业区划分参数很难确定,任何不当的参数都会引起资源利用不充分的情况发生;缩短服务器总繁忙时间,多数都对作业请求与服务器匹配只是单纯地应用了FF的服务器匹配策略,随机性大。此外,在作业请求调度过程中忽视了其对作业调度性能的影响,对作业请求排队模型进行了变更操作,牺牲了部分作业调度性能,无法与其他有调度性能优势的作业调度算法结合使用。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>4.3 自适应功耗管理策略</b></h4>
                <div class="p1">
                    <p id="76">目前,许多研究致力于对高性能计算系统级作业功耗监控分析,并依此进行最优化功耗调度策略的探索,总结出符合实际应用情况的功耗分析和管理算法<citation id="335" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">68</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="77">王洁等人<citation id="336" type="reference"><link href="254" rel="bibliography" /><link href="276" rel="bibliography" /><sup>[<a class="sup">69</a>,<a class="sup">69</a>]</sup></citation>提出的自适应功耗管理策略就是基于作业的周期性和连续性分析,利用遗传算法的自适应功耗调度策略作为作业调度算法,通过任务之间的相关性和出现概率对负载变化进行预测,根据通信需求和预测的负载确定任务在不同结点上的运行时间和功耗,最小化两者的乘积(即能耗),达到提高资源利用率和降低系统整体功耗的目的。Wallace等人<citation id="337" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">41</a>]</sup></citation>发现高性能计算作业之间显著不同的功耗分布,并以此通过动态学习技术跟踪观察、分析、评估系统和用户作业进入、执行、退出时的能耗数据,以“数据驱动”的方式进行作业调度,以节省能耗,再利用基于窗口的调度方式提高系统资源利用率,满足用户给定的任意功耗限制,达到了节省系统能耗的效果。</p>
                </div>
                <div class="p1">
                    <p id="78">由于作业具有一定的连续性和周期性,不仅仅是结点负载,通信开销也与应用相关。随着资源利用率增加,其计算负担和通信量也会随之增加,能耗也会增加。通过有效地调度分配资源,以减少计算负载和处理时间,可以节省总体电量,尤其是运用MPI的并行程序,对于分布式存储系统,通信量对于总能耗的影响是不可忽视的<citation id="338" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">54</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>4.4 功率封顶(预算)技术</b></h4>
                <div class="p1">
                    <p id="80">Ranganathan等人<citation id="339" type="reference"><link href="256" rel="bibliography" /><sup>[<a class="sup">70</a>]</sup></citation>的研究表明,大规模集群计算资源利用率大多数时间是维持在低水平的,实际使用的最大功率与其理论峰值之间可能相差40%,而且极少发生异常情况。这就为整个高性能计算系统设置一个功耗阈值提供了可能性,系统不仅能正常运行,同时整体功耗得到了控制。目前功率封顶(预算)技术已经在许多数据中心上得以实现,Etinski等人<citation id="340" type="reference"><link href="126" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出的并行作业调度策略就是利用DVFS调整结点功耗,确保整个系统功耗维持在一个给定的功率限度下,Wallace等人<citation id="341" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">41</a>]</sup></citation>也是在用户给定的功率预算情况下利用数据驱动方式对IBM-Q上的作业进行调度,以控制高性能计算系统功耗的。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>4.5 热管理技术</b></h4>
                <div class="p1">
                    <p id="82">由于内核温度每升高10℃,系统错误率就增加1倍<citation id="342" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">71</a>]</sup></citation>,较高的温度对系统的可靠性有很大的影响,同时也增加了冷却成本。在作业调度过程中应用热管理技术,与DPM、功率封顶技术类似,但热管理更偏向于硬件层。研究者可以利用热量传感器和热量调节系统,根据预定的温度阈值调整系统工作负荷和平衡负载,从而提高并行设备的可靠性,并降低应用程序的整体运行时间<citation id="345" type="reference"><link href="198" rel="bibliography" /><link href="260" rel="bibliography" /><sup>[<a class="sup">41</a>,<a class="sup">72</a>]</sup></citation>。Sarood等人<citation id="343" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">72</a>]</sup></citation>用实验证明了控制内核温度与作业调度过程中各结点平衡负载的可能性,设备可靠性不仅提高了2.3倍,程序执行时间也缩短了12%。当给定结点温度超过阈值时,系统工作量就会减少。热管理技术的缺点是响应不及时,存在过热、过冷的风险<citation id="344" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">73</a>]</sup></citation>,而且对于数以千计的系统组件,对其温度进行全面实时的监控就需要更多的监控器。因此,该技术很少运用在作业调度中,更多的是用于整体系统热量的统计。</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag"><b>5 面临的技术挑战和未来发展方向</b></h3>
                <div class="p1">
                    <p id="84">随着高性能计算技术的飞速发展,计算环境越来越复杂,如何充分利用有限的计算资源,满足用户的应用需求,同时达到最佳能效性,始终是作业调度策略的最基本、也是亟需解决的问题。本节主要从计算认知性、设备异构性、调度公平性等方面分析作业调度能效性所面临的技术挑战和未来发展。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>5.1 认知计算</b></h4>
                <div class="p1">
                    <p id="86">为了描述让计算机系统能够像人的大脑一样学习、思考,并做出正确决策的现象,人们提出“认知计算”的概念。它源自模拟人脑的计算机系统的人工智能,试图解决生物系统中的不精确、不确定和部分真实的问题,以实现感知、记忆、学习、语言、思维和问题解决等过程,不同于传统定量、着重于精度和序列的计算技术。随着科技发展以及大数据时代的到来,如何实现类似人脑的认知与判断,发现新的关联和模式,从而做出正确的决定,显得尤为重要。Gaussier等人<citation id="346" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">74</a>]</sup></citation>利用经典的机器学习方法从大量的实测数据中预测出作业运行时间,优化了EASY回填算法,使作业调度性能提升了28%。显然,大数据给认知计算领域带来新的机遇和挑战的同时,也给超大规模的作业调度技术及其能效性提出了新的要求——以非常灵活的方式进行作业调度,并以交互的方式指导计算,以支持人类的认知过程<citation id="347" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">52</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>5.2 设备异构性</b></h4>
                <div class="p1">
                    <p id="88">如今的高性能计算的工作负载和基础设备日益复杂,即使是在单个结点中,核和GPU的数量也在不断变大,系统的异构性导致功耗模式、功率状态、功率管理机制、计算能力和通信模式的不同,造成的系统能耗也会截然不同<citation id="348" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>,对如此复杂的大规模系统作业进行调度是当前最主要的挑战之一,迫切需要更加先进的调度方法。尤其表现在作业调度的模拟器及其系统性能评估基准的创新方面。Zong等人<citation id="349" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>将异构系统分为4种类型,并将作业调度区分组建和分配2个阶段,预估结点上运行的作业能耗,进而决定最佳的分配策略,以最小化系统总能耗,达到较好的节能效果。虽然最新的研究设计出调度系统模拟器(ScSF<citation id="350" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">75</a>]</sup></citation>)及基准(DJSB<citation id="351" type="reference"><link href="268" rel="bibliography" /><sup>[<a class="sup">76</a>]</sup></citation>),但也仅局限于对大规模作业/应用程序进行资源分配时的性能测试,对于作业调度能效性的研究仍然有待进一步深入。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>5.3 调度公平性</b></h4>
                <div class="p1">
                    <p id="90">用户提交的作业一直以来都有着不同计算需求:有的用户对于精确度要求高,只要求作业能在一定期限内完成;有的用户对作业计算时间要求高,越早完成越好;有的用户既不要求高速度,也不要求高精度;有的则相反。不管系统结构如何不一样,计算规模有多大,调度的公平性始终是设计人员必须关注的一个重要方面,那么,如何在保证调度公平性的前提下,实现最佳的能效性,也是研究人员所应该追求的目标。进一步地,大多数批处理调度程序都是基于作业队列的,其中每个作业在其到达前就已经计划好其调度序列。在云数据时代,对大规模数据进行作业调度时,能否及时对如此庞大的作业数量进行规划并提交给用户,同时确保作业-资源分配的公平性,成为应用程序能否达到最佳性能的关键因素。</p>
                </div>
                <h3 id="91" name="91" class="anchor-tag"><b>6 结束语</b></h3>
                <div class="p1">
                    <p id="92">高性能计算过程中,大量的能耗已成为技术发展的瓶颈。作业调度系统作为高性能计算机中的核心组件,对于提高系统性能,合理利用有限的计算资源有着关键作用,其能效性也决定着性能所能提升的空间。本文首先介绍传统能效性技术和作业调度策略,并就最新的作业调度技术优化及其能效性进行了论述,最后是作业调度能效性方面面临的挑战及未来走向。目前作业调度策略在能效性方面的研究仍有待于进一步深入。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="118">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Challenges on the road to exascale computing">

                                <b>[1]</b>Agerwala T.Challenges on the road to exascale computing[C]∥Proc of the 22nd Annual International Conference on Supercomputing(ICS’08),2008:2．
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Top ten exascale research challenges">

                                <b>[2]</b>Lucas R,Ang J,Bergman K,et al.Top ten exascale research challenges:DOE ASCAC Subcommittee Report[R].New York:USDOE Office of Science,2014:1-2．
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000036632&amp;v=MzE1NzQ4N29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsOFZhaFk9TmlmSVk3SzdIdGpOcjQ5RlpPZ0pDbg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>Wu C.Making a case for efficient supercomputing[J].ACMQueue,2003,1(7):54-64．
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improvement of Power-Performance Efficiency forHigh-End Computing">

                                <b>[4]</b>Ge R,Feng X,Cameron K W.Improvement of power-performance efficiency for high-end computing[C]∥Proc of the19th IEEE International Parallel and Distributed Processing Symposium,2005:1-8．
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300419162&amp;v=MjYzMzFGWU9vR0RYbzdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKbDhWYWhZPU5pZk9mYks3SHRET3JJOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Etinski M,Corbalan J,Labarta,et al.Parallel job scheduling for power constrained HPC systems[J].Parallel Computing,2012,38(12):615-630．
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Safety and reliability driven task allocation in distributed systems">

                                <b>[6]</b>Srinivasan S,Jha N K.Safety and reliability driven task allocation in distributed systems[J].IEEE Transactions on Parallel&amp;Distributed Systems,1999,10(3):238-251．
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Energy-Efficient Scheduling for Parallel Applications Running on Heterogeneous Clusters">

                                <b>[7]</b>Zong Z,Qin X,Ruan X,et al.Energy-efficient scheduling for parallel applications running on heterogeneous clusters[C]∥Proc of the 36th International Conference on Parallel Processing(ICPP’07),2007:19-26．
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High performance interconnect network for Tianhe System">

                                <b>[8]</b>Liao Xiang-ke,Pang Zheng-bin,Wang Ke-fei,et al.High performance interconnect network for Tianhe system[J].Journal of Computer Science and Technology,2015,30(2):259-272．
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14061700001662&amp;v=MTMwMDlubzdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMZklKbDhWYWhZPU5qN0Jhcks4SHRmTnFJOUZaT3NPQw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Pang Zheng-bin,Xie Min,Zhang Jun,et al.The TH express high performance interconnect networks[J].Frontiers of Computer Science,2014,8(3):357-366．
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130410199612&amp;v=MDA0NjNNYmUwT0RoTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkN2dFU3bkpJVjRRTmo3QmFySzdIdFhOcjQ1&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>Valentini G L,Lassonde W,Khan S U,et al.An overview of energy efficiency techniques in cluster computing systems[J].Cluster Computing,2013,16(1):3-15．
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003855181&amp;v=MDg0MThxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ0RsVmI3SklGbz1OajdCYXJPNEh0SFBwNHBBWmVNT1kzazV6QmRoNGo5OVNY&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>Li K.Energy efficient scheduling of parallel tasks on multiprocessor computers[J].The Journal of Supercomputing,2012,60(2):223-247．
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Estimating the energy use and efficiency potential of U.S. data centers">

                                <b>[12]</b>Masanet E R,Brown R E,Shehabi A,et al.Estimating the energy use and efficiency potential of U.S.data centers[J].Proceeding of the IEEE,2011,99(8):1440-1453．
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD121113001177&amp;v=MjkwNDd0VTduSklWNFFOajdCYXJLNkg5RE5ySTlGWmVvSUN4TTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZadTl1RkN2&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Shuja J,Madani S A,Bilal K,et al.Energy-efficient data centers[J].Computing,2012,94(12):973-994．
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Growth in data center electricity use 2005to2010">

                                <b>[14]</b>Koomey J G.Growth in data center electricity use 2005to2010[M].Oakland:Analytics Press,2011．
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPD00000013370&amp;v=MTY1MTNpVGJhck80SHRITXI0NUdaK3dQWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ0RsVmI3SklGbz1O&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>Koomey J G.Worldwide electricity used in data centers[J].Environmental Research Letters,2008(3):Article ID034008．
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saving 200kw and$200 k/year by power-aware job/machine scheduling">

                                <b>[16]</b>Hikita J,Hirano A,Nakashima H.Saving 200kW and$200K/year by power-aware job/machine scheduling[C]∥Proc of 2008IEEE International Symposium on Parallel and Distributed Processing(IPDPS 2008),2008:1-8．
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Performance-constrained distributed dvs scheduling for scientific applications on power-aware clusters,&amp;quot;">

                                <b>[17]</b>Ge R,Feng X,Cameron K W.Performance-constrained distributed DVS scheduling for scientific applications on poweraware clusters[C]∥Proc of ACM/IEEE Conference on Supercomputing(SC’05),2005:34-44．
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A power aware study for VTDIRECT95 using DVFS">

                                <b>[18]</b>Cao Z,Watson L T,Cameron K W,et al.A power aware study for VTDIRECT95using DVFS[C]∥Proc of the 2009Spring Simulation Multiconference,2009:531-536．
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scheduling for reduced CPU energy">

                                <b>[19]</b>Weiser M,Welch B,Demers A,et al.Scheduling for reduced CPU energy[C]∥Proc of the 1st USENIX Conference on Operating Systems Design and Implementation(OS-DI’94),1994:13-23．
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LEneS: Task Scheduling for Low-Energy Systems UsingVariable Supply Voltage Processors">

                                <b>[20]</b>Gruian F,Kuchcinski K.LEneS:Task scheduling for lowenergy systems using variable supply voltage processors[C]∥Proc of the ASP-DAC,2001:449-455．
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic Voltage Scaling in Multitier Web Servers with End-to-End Delay Control">

                                <b>[21]</b>Horvath T,Abdelzaher T,Skadron K,et al.Dynamic voltage scaling in multitier web servers with end-to-end delay control[J].IEEE Transactions on Computers,2007,56(4):444-458．
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000092635&amp;v=MjkzMDFsOFZhaFk9TmlmSVk3SzdIdGpOcjQ5RlpPSU5Dbjg4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b>Zhong X L,Xu C Z.System-wide energy minimization for real-time tasks:Lower bound and approximation[J].ACMTransactions on Embedded Computing System,2008,7(3):1-24．
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13081300002183&amp;v=MDY5MjhKbDhWYWhZPU5qN0Jhcks3SHRuTnJJOUZaT3NORFhRNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>Bilal K,Khan S U,Madani S A,et al.A survey on green communications using adaptive link rate[J].Cluster Computing,2013,16(3):575-589．
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Load Balancing and Unbalancing for power and performance in Cluster-Based Systems">

                                <b>[24]</b>Pinheiro E,Bianchini R,Carrera E V,et al.Load balancing and unbalancing for power and performance in cluster-based systems[C]∥Proc of the Workshop on Compilers&amp;Operating Systems for Low Power,2001:1-8．
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00001284484&amp;v=MjExOTVOcllkQllPTUxZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDRGxWYjdKSUZvPU5pZmNhck80SHRI&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b>Liu Y,Zhu H.A survey of the research on power management techniques for high-performance systems[J].Software Practice&amp;Experience,2010,40(11):943-964．
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ACPI:Advanced configuration and power interface">

                                <b>[26]</b>Intel Corporation.ACPI:Advanced configuration and power interface[EB/OL].[2019-02-26].http：//www.acpi.info/．
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Intel64and IA-32architectures software developer&amp;#39;&amp;#39;s manual">

                                <b>[27]</b>Intel Corporation.Intel64and IA-32architectures software developer’s manual[EB/OL].[2019-02-26].https：//software.intel.com/en-us/articles/intel-sdm．
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Difference between deep and deeper sleep states for processors">

                                <b>[28]</b>Intel Corporation.Difference between deep and deeper sleep states for processors[EB/OL].[2019-02-26].https：//www.intel.com/content/www/us/en/support/articles/000006619/processors/intel-core-processors.html．
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Calculating Memory System Power for DDR SDRAM">

                                <b>[29]</b>Janzen J.Calculating memory system power for DDRSDRAM[J].Micro Designline,2001,10(2):1-12．
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DMA-aware Memory Energy Management">

                                <b>[30]</b>Pandey V,Jiang W,Zhou Y,et al.DMA-aware memory energy management[C]∥Proc of the 12th International Symposium on High-Performance Computer Architecture(HP-CA’06),2006:133-144．
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Massive arrays of idle disks for storage archives">

                                <b>[31]</b>Colarelli D,Grunwald D.Massive arrays of idle disks for storage archives[C]∥Proc of the 2002ACM/IEEE Conference on Supercomputing(SC’02),2002:1-11．
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_32" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000057069&amp;v=MDQxMzF1SHlqbVVMZklKbDhWYWhZPU5pZklZN0s3SHRqTnI0OUZaTzRJREhvd29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[32]</b>Pinheiro E,Bianchini R,Dubnicki C.Exploiting redundancy to conserve energy in storage systems[J].ACM SIGMET-RICS Performance Evaluation Review,2006,34(1):15-26．
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Energy-aware server provisioning and load dispatching for connection-intensive internet services">

                                <b>[33]</b>Chen G,He W,Liu J,et al.Energy-aware server provisioning and load dispatching for connection-intensive internet services[C]∥Proc of the 5th USENIX Symposium on Networked Systems Design and Implementation(NSDI’08),2008:337-350．
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_34" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Challenges towards elastic power management in internet data centers">

                                <b>[34]</b>Liu J,Zhao F,Liu X,et al.Challenges towards elastic power management in internet data centers[C]∥Proc of the2nd International Workshop on Cyber-Physical Systems(WCPS’09),2009:65-72．
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_35" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130410199617&amp;v=MzI0OTNyaWZadTl1RkN2dFU3bkpJVjRRTmo3QmFySzdIdFhOcjQ1TWJlME9DeE04enhVU21EZDlTSDduM3hFOWZidm5L&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[35]</b>Kliazovich D,Bouvry P,Khan S U.DENS:Data center energy-efficient network-aware scheduling[J].Cluster Computing,2013,16(1):65-75．
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reducing static energy in supercomputer interconnection networks using topology-aware partitioning">

                                <b>[36]</b>Chen C R,Chen J,Chang E C.Reducing static energy in supercomputer interconnection networks using topology-aware partitioning[J].IEEE Transactions on Computers,2016,65(8):2588-2602．
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_37" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A survey of design techniques for system-level dynamic power management">

                                <b>[37]</b>Benini L,Bogliolo A,Micheli G D.A survey of design techniques for system-level dynamic power management[J].Hardware/Software Co-Design,2000,8(3):299-316．
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_38" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000015130&amp;v=MDAyMDVpZklZN0s3SHRqTnI0OUZaT29LRFg4NW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxmSUpsOFZhaFk9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[38]</b>Meisner D,Wenisch T F.DreamWeaver:Architectural support for deep sleep[J].ACM SIGARCH Computer Architecture News,2012,40(1):313-324．
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_39" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001922&amp;v=MDIxNDhlcnFRVE1ud1plWnVIeWptVUxmSUpsOFZhaFk9TmlmSVk3SzdIdGpOcjQ5RlpPc09CWDQ3b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[39]</b>Louis R.Dryad:Distributed data-parallel programs from sequential building blocks[J].ACM SIGOPS Operating Systems Review,2007,41(3):59-72．
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_40" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reducing Network Energy Consumption via Sleeping and Rate-adaptation">

                                <b>[40]</b>Nedevschi S,Popa L,Iannaccone G,et al.Reducing network energy consumption via sleeping and rate-adaptation[C]∥Proc of USENIX Symposium on Networked Systems Design&amp;Implementation(NSDI’08),2008:323-336．
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_41" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A data driven scheduling approach for power management on HPC systems in High Performance Computing">

                                <b>[41]</b>Wallace S,Yang X,Vishwanath V,et al.A data driven scheduling approach for power management on HPC systems in High Performance Computing[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis(SC’16),2016:56:1-56．
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_42" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Getting up to speed:The future of supercomputing">

                                <b>[42]</b>Graham S L,Snir M,Patterson C A.Getting up to speed:The future of supercomputing[M].Washington:Committee on the Future of Supercomputing,National Research Council,National Academies Press,2005．
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_43" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Managing server energy and operational costs in hosting centers">

                                <b>[43]</b>Chen Y,Das A,Qin W,et al.Managing server energy and operational costs in hosting centers[C]∥Proc of the 2005ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems,2005:303-314．
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_44" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-mode energy management for multi-tier server clusters">

                                <b>[44]</b>Horvath T,Skadron K.Multi-mode energy management for multi-tier server clusters[C]∥Proc of the 17th International Conference on Parallel Architectures and Compilation Techniques(PACT’08),2008:270-279．
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_45" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QHDY201904010&amp;v=MDg3NDNVUkxPZVplUm1GeTdrVXIvTU5DWFBkN0c0SDlqTXE0OUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[45]</b>Wu F,Chen J,Chen Z,et al.A holistic energy-efficient approach for a processor-memory system[J].Tsinghua Science and Technology,2019,24(4):468-483．
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_46" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Power capping of CPU-GPU heterogeneous systems through coordinating DVFS and task mapping">

                                <b>[46]</b>Komoda T,Hayashi S,Nakada T,et al.Power capping of CPU-GPU heterogeneous systems through coordinating DVFS and task mapping[C]∥Proc of the 31st International Conference on Computer Design(ICCD 2013),2013:349-356．
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_47" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14060600000895&amp;v=MzE0MTg3QmFySzhIdGZNcVk5RlpPc1BCSFU4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmw4VmFoWT1Oag==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[47]</b>Mei J,Li K L,Li K Q.Energy-aware task scheduling in heterogeneous computing environments[J].Cluster Computing,2014,17(2):537-550．
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_48" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computers and intractability: a guide to the theory of NP-completeness">

                                <b>[48]</b>Garey M R,Johnson D S.Computers and intractability:Aguide to the theory of NP-completeness[M].New York:W.H.Freeman&amp;Co,1979．
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_49" target="_blank" href="http://scholar.cnki.net/result.aspx?q=NP -complete scheduling problems">

                                <b>[49]</b>Ullman J D.NP-complete scheduling problems[J].Journal of Computer and Systems Sciences,1975,10(3):384-393．
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_50" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Benchmarking the task graph scheduling algorithms">

                                <b>[50]</b>Kwok Y K,Ahmad I.Benchmarking the task graph scheduling algorithms[C]∥Proc of the 1st International Parallel Processing Symposium,1998:531-537．
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_51" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improve energy efficiency by processor overclocking and memory frequency scaling">

                                <b>[51]</b>Wu F,Juan C,Dong Y,et al.Improve energy efficiency by processor overclocking and memory frequency scaling[C]∥Proc of the 20th International Conference on High Performance Computing and Communications(HPCC’18),2018:960-967．
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_52" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Theory and practice in parallel job scheduling">

                                <b>[52]</b>Feitelson D G,Rudolph L,Schwiegelhohn U,et al.Theory and practice in parallel job scheduling[J].Lecture Notes in Computer Science,1997,1291(13):1-34．
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_53" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scheduling in multiprogrammed parallel systems">

                                <b>[53]</b>Majumdar S,Eager D L,Bunt R B.Scheduling in multiprogrammed parallel systems[C]∥Proc of SIGMETRICS Conference on Measurement and Modeling of Computer Systems,1988:104-113．
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_54" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Job scheduling strategies for parallel processing">

                                <b>[54]</b>Cime W,Desai N.Job scheduling strategies for parallel processing[J].Computer Science,2014,2862(4):128-152．
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_55" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A comparison of three parallel processing methods for a resource allocation problem in the smart grid">

                                <b>[55]</b>Celik B,Suryanarayanan S,Maciejewski A A,et al.A comparison of three parallel processing methods for a resource allocation problem in the smart grid[C]∥Proc of 2017North American Power Symposium(NAPS),2017:1-7．
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_56" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The anl/ibm sp scheduling system">

                                <b>[56]</b>Lifka D.The ANL/IBM SP scheduling system[C]∥Proc of the Workshop on Job Scheduling Strategies for Parallel Processing(IPPS’95),1995:187-191．
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_57" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100265297&amp;v=MDY0MzJlcnFRVE1ud1plWnVIeWptVUxmSUpsOFZhaFk9TmlmT2ZiSzdIdERPcm85Rlp1MEtEblUrb0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[57]</b>Maheswaran M,Ali S,Siegil H J,et al.Dynamic mapping of a class of independent tasks onto heterogeneous computing systems[J].Journal of Parallel&amp;Distributed Computing,1999,59(2):107-131．
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_58" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Utilization, predictability, workloads, and user runtime estimates in scheduling the IBM SP2 with backfilling">

                                <b>[58]</b>Mu’alem A W,Feitelson D G.Utilization,predictability,workloads,and user runtime estimates in scheduling the IBM SP2 with backfilling[J].Parallel&amp;Distributed Systems,2001,12(6):529-543．
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_59" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Design and research of low power resource management in high performance parallel computing system">

                                <b>[59]</b>Dong Jing.Design and research of low power resource management in high performance parallel computing system[D].Changsha:National University of Defense Technology,2009.(in Chinese）
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_60" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14111900010533&amp;v=MTQ0NjFNbndaZVp1SHlqbVVMZklKbDhWYWhZPU5qN0Jhcks4SDlETnBvOUZaT29QQ1g4Nm9CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[60]</b>Chandio A A,Bllal K,Tziritas N,et al.A comparative study on resource allocation and energy efficient job scheduling strategies in large-scale parallel computing systems[J].Cluster Computing,2014,17(4):1349-1367．
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_61" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A parallel scheduling energy consumption optimization algorithm based on busy hours">

                                <b>[61]</b>Cai Li-jun,Pan Jiang-bo,Chen Lei,et al.A parallel scheduling energy consumption optimization algorithm based on busy hours[J].Computer Engineering&amp;Science,2017,39(1):42-48.(in Chinese）
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_62" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enacloud:An energy-saving application live placement approach for cloud computing environments">

                                <b>[62]</b>Li B,Li J,Huai J,et al.EnaCloud:An energy-saving application live placement approach for cloud computing environments[C]∥Proc of 2009IEEE International Conference on Cloud Computing,2009:17-24．
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_63" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online optimization of busy time on parallel machines">

                                <b>[63]</b>Shalom M,Voloshin A,Wong P W H,et al.Online optimization of busy time on parallel machines[C]∥Proc of the9th Annual Conference on Theory and Applications of Models of Computation,2012:448-460．
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_64" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A job scheduling method for optimizing the energy consumption of multi-task communication">

                                <b>[64]</b>Zhu Ming-fa,Pang Yu,Liang Ai-hua,et al.A job scheduling method for optimizing the energy consumption of multi-task communication:China,201110333204.3[P].2011-10-28.(in Chinese）
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_65" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Editorial:Resource management of parallel and distributed systems with static scheduling:Challenges,solutions and new problems">

                                <b>[65]</b>Ahmad I.Editorial:Resource management of parallel and distributed systems with static scheduling:Challenges,solutions and new problems[J].Concurrency&amp;Computation Practice&amp;Experience,2010,7(5):339-347．
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_66" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Minimizing busy time in multiple machine real-time scheduling">

                                <b>[66]</b>Khandekar R,Schieber B,Shachnai H,et al.Minimizing busy time in multiple machine real-time scheduling[C]∥Proc of IARCS Annual Conference on Foundations of Software Technology and Theoretical Computer Science,2010:169-180．
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_67" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An online parallel scheduling method with application to energy-efficiency in cloud computing">

                                <b>[67]</b>Tian W,Xiong Q,Cao J.An online parallel scheduling method with application to energy-efficiency in cloud computing[J].Journal of Supercomputing,2013,66(3):1773-1790．
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_68" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analysis of mixed workloads from shared cloud infrastructure">

                                <b>[68]</b>Kluscek D,Park B.Analysis of mixed workloads from shared cloud infrastructure[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2017:25-42．
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_69" >
                                    <b>[69]</b>
                                Wang Jie,Zeng Yu.Research on job scheduling strategy of high performance computer based on adaptive power management[J].Computer Science,2012,39(10):313-317.(in Chinese）
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_70" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ensemble-level power management for dense bladeservers">

                                <b>[70]</b>Ranganathan P,Leech P,Irwin D,et al.Ensemble-level power management for dense blade servers[C]∥Proc of the33rd International Symposium on Computer Architecture,2006:66-77．
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_71" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Importance of Being Low Power in High Performance Computing">

                                <b>[71]</b>Wu C.The importance of being low power in high performance computing[J].Cyberinfrastructure Technology Watch Quarterly(CTWatch Quarterly),2005,1(3):12-20．
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_72" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A&amp;#39;&amp;#39;cool&amp;#39;&amp;#39;way of improving the reliability of HPC machines">

                                <b>[72]</b>Sarood O,Meneses E,Kale L V.A‘cool’way of improving the reliability of HPC machines[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis,2013:Article No.58．
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_73" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDC261C3CC7D17A362934345FC7F74A369&amp;v=MjA5Njdod3JtK3dLdz1OajdCYXNDNkdOQy9yUHcyWTU4T0N3MDZ5UlFhNlR0K1RIcVUzeFZEZnJibFJyeVdDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVOQg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[73]</b>Lee E K,Kulkarni I,Pompili D,et al.Proactive thermal management in green datacenters[J].Journal of Supercomputing,2012,60(2):165-195．
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_74" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving backfilling by using machine learning to predict running times">

                                <b>[74]</b>Gaussier E,Glesser D,Reis V,et al.Improving backfilling by using machine learning to predict running time[C]∥Proc of the International Conference for High Performance Computing,Networking,Storage and Analysis,2015:1-64．
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_75" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ScSF:A scheduling simulation framework">

                                <b>[75]</b>Rodrigo G P,Elmroth E，stberg P O,et al.ScSF:A scheduling simulation framework[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2017:152-173．
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_76" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DJSB:Dynamic job scheduling benchmark">

                                <b>[76]</b>Lopez V,Jokanovic A,Amico M D,et al.DJSB:Dynamic job scheduling benchmark[C]∥Proc of Workshop on Job Scheduling Strategies for Parallel Processing,2018:174-188．
                            </a>
                        </p>
                        <p id="270">
                            <a id="bibliography_59" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=2010165305.nh&amp;v=MTA2NTA1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3a1VyL01WMTI2SHJLK0c5TE1xcEViUElRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[59]</b>董晶．高性能并行计算系统中低功耗资源管理的设计与研究[D]．长沙：国防科学技术大学，2009．
                            </a>
                        </p>
                        <p id="272">
                            <a id="bibliography_61" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201701005&amp;v=MjIzNjZPZVplUm1GeTdrVXIvTUx6N0JaYkc0SDliTXJvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[61]</b>蔡立军，潘江波，陈磊，等．一种基于繁忙时间的并行调度能耗优化算法[J]．计算机工程与科学，2017,39(1):42-48．
                            </a>
                        </p>
                        <p id="274">
                            <a id="bibliography_64" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SCPD&amp;filename=CN102364447A&amp;v=MDM0MzJxNGcwQys0UEQzMUx4eFlUNnpvT1MzZm1wV0ZhZTdLVlRMdWRaZTl1RVNua1U3cz1KaU82SHJHN0dOWEk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[64]</b>祝明发，庞瑜，梁爱华，等．一种优化多任务间通信能耗的作业调度方法：中国，201110333204.3[P].2011-10-28．
                            </a>
                        </p>
                        <p id="276">
                            <a id="bibliography_69" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201210072&amp;v=MjEzNzQ5Q1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N2tVci9NTHo3QmI3RzRIOVBOcjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[69]</b>王洁，曾宇．基于自适应功耗管理的高性能计算机作业调度策略的研究[J]．计算机科学，2012,39(10):313-317.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201909001" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201909001&amp;v=MDk0NTh0R0ZyQ1VSTE9lWmVSbUZ5N2tVci9NTHo3QlpiRzRIOWpNcG85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
