<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132373396436250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201907022%26RESULT%3d1%26SIGN%3dnOvAqo9rXly0awrrZuHdDquvkv8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907022&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907022&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907022&amp;v=MDI0OTMzenFxQnRHRnJDVVJMT2VaZVJtRnk3bVc3N0xMejdCWmJHNEg5ak1xSTlIWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;2 DI LDA模型描述&lt;/b&gt; "><b>2 DI LDA模型描述</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#75" data-title="&lt;b&gt;3 DI LDA模型推理&lt;/b&gt; "><b>3 DI LDA模型推理</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#101" data-title="&lt;b&gt;4 实验&lt;/b&gt; "><b>4 实验</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="图1 DI LDA模型">图1 DI LDA模型</a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;表1 DI LDA模型中符号含义&lt;/b&gt;"><b>表1 DI LDA模型中符号含义</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;表2 DI LDA模型推理中参数说明&lt;/b&gt;"><b>表2 DI LDA模型推理中参数说明</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;表3 &lt;i&gt;n&lt;/i&gt;取不同值时领域判别精度&lt;/b&gt;"><b>表3 <i>n</i>取不同值时领域判别精度</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;表4 不同数量的测试集下领域判别精度&lt;/b&gt;"><b>表4 不同数量的测试集下领域判别精度</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="124">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     Pang B, Lee L.Opinion mining and sentiment analysis[J].Foundations and Trends in Information Retrieval, 2008, 2 (1-2) :1-135.</a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_2" title=" Inui T, Okumura M.A survey of sentiment analysis[J].Journal of Natural Language Processing, 2006, 13 (3) :201-241." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A survey of sentiment analysis">
                                        <b>[2]</b>
                                         Inui T, Okumura M.A survey of sentiment analysis[J].Journal of Natural Language Processing, 2006, 13 (3) :201-241.
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_3" title=" Li Jun.A survey of sentiment analysis and opinion mining on product reviews[J].Modern Computer, 2013 (5) :11-16. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201307002&amp;v=MjA2OTc3N0xQU25CZmJHNEg5TE1xSTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bVc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Li Jun.A survey of sentiment analysis and opinion mining on product reviews[J].Modern Computer, 2013 (5) :11-16. (in Chinese) 
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_4" title=" Pang B, Lee L, Vaithyanathan S.Thumbs up?Sentiment classification using machine learning techniques[C]//Proc of the ACL-02 Conference on Empirical Methods in Natural Language Processing:Association for Computational Linguistics, 2002:79-86." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Thumbs up? sentiment classification using machine learning techniques">
                                        <b>[4]</b>
                                         Pang B, Lee L, Vaithyanathan S.Thumbs up?Sentiment classification using machine learning techniques[C]//Proc of the ACL-02 Conference on Empirical Methods in Natural Language Processing:Association for Computational Linguistics, 2002:79-86.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_5" title=" Pang B, Lee L.A sentimental education:Sentiment analysis using subjectivity summarization based on minimum cuts[C]//Proc of the 42nd Annual Meeting on Association for Computational Linguistics:Association for Computational Linguistics, 2004:Article No.271." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A sentimental education:sentiment analysis using subjectivity summarization based on minimum cuts">
                                        <b>[5]</b>
                                         Pang B, Lee L.A sentimental education:Sentiment analysis using subjectivity summarization based on minimum cuts[C]//Proc of the 42nd Annual Meeting on Association for Computational Linguistics:Association for Computational Linguistics, 2004:Article No.271.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_6" title=" Sista S P, Srinivasan S H.Polarized lexicon for review classification[C]//Proc of International Conference on Machine Learning, 2004:867-872." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Polarized Lexicon for ReviewClassification">
                                        <b>[6]</b>
                                         Sista S P, Srinivasan S H.Polarized lexicon for review classification[C]//Proc of International Conference on Machine Learning, 2004:867-872.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     Xu Jun, Ding Yu-xin, Wang Xiao-long.Sentiment classification for Chinese news using machine learning methods [J].Journal of Chinese Information Processing, 2007, 21 (6) :95-100. (in Chinese) </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_8" title=" Ni X, Xue G R, Ling X, et al.Exploring in the Weblog space by detecting informative and affective articles[C]//Proc of the 16th International Conference on World Wide Web, 2007:281-290." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploring in the Weblog Space by Detecting Informative and Affective Articles">
                                        <b>[8]</b>
                                         Ni X, Xue G R, Ling X, et al.Exploring in the Weblog space by detecting informative and affective articles[C]//Proc of the 16th International Conference on World Wide Web, 2007:281-290.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_9" title=" Wang Su-ge, Li De-yu, Wei Ying-jie.A method of text sentiment classification based on weighted rough membership [J].Journal of Computer Research and Development, 2011, 48 (5) :855-861. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201105022&amp;v=MzAwNzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVzc3TEx5dlNkTEc0SDlETXFvOUhab1E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Wang Su-ge, Li De-yu, Wei Ying-jie.A method of text sentiment classification based on weighted rough membership [J].Journal of Computer Research and Development, 2011, 48 (5) :855-861. (in Chinese) 
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                     Wang Gen, Zhao Jun.Sentence sentiment analysis based on multi-redundant-labeled CRFs[J].Journal of Chinese Information Processing, 2007, 21 (5) :51-55. (in Chinese) </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_11" title=" Ma Chang-lin, Wang Meng, Chen Xue-wen.Topic and sentiment unification maximum entropy model for online review analysis[C]//Proc of the 24th International Conference on World Wide Web, 2015:649-654." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Topic and sentiment unification maximum entropy model for online review analysis">
                                        <b>[11]</b>
                                         Ma Chang-lin, Wang Meng, Chen Xue-wen.Topic and sentiment unification maximum entropy model for online review analysis[C]//Proc of the 24th International Conference on World Wide Web, 2015:649-654.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_12" title=" http://www.sogou.com/labs/." target="_blank"
                                       href="">
                                        <b>[12]</b>
                                         http://www.sogou.com/labs/.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_13" title=" http://ictclas.nlpir.org/." target="_blank"
                                       href="">
                                        <b>[13]</b>
                                         http://ictclas.nlpir.org/.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     李俊.面向产品评论的意见挖掘研究综述[J].现代计算机 (专业版) , 2013 (5) :11-16.</a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_7" title=" 徐军, 丁宇新, 王晓龙.使用机器学习方法进行新闻的情感自动分类[J].中文信息学报, 2007, 21 (6) :95-100." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200706016&amp;v=MzA0ODNZZmJHNEh0Yk1xWTlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bVc3N0xLQ2o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         徐军, 丁宇新, 王晓龙.使用机器学习方法进行新闻的情感自动分类[J].中文信息学报, 2007, 21 (6) :95-100.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     王素格, 李德玉, 魏英杰.基于赋权粗糙隶属度的文本情感分类方法[J].计算机研究与发展, 2011, 48 (5) :855-861.</a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_10" title=" 王根, 赵军.基于多重冗余标记CRFs的句子情感分析研究[J].中文信息学报, 2007, 21 (5) :51-55." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200705011&amp;v=MTkzMTVtVzc3TEtDallmYkc0SHRiTXFvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         王根, 赵军.基于多重冗余标记CRFs的句子情感分析研究[J].中文信息学报, 2007, 21 (5) :51-55.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(07),1297-1302 DOI:10.3969/j.issn.1007-130X.2019.07.022            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于领域识别的主题模型观点挖掘研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A9%AC%E9%95%BF%E6%9E%97&amp;code=11010440&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">马长林</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%97%B5%E6%B4%81&amp;code=35028246&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">闵洁</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%A2%E7%BD%97%E8%BF%AA&amp;code=33812105&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谢罗迪</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%AD%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0200298&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华中师范大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BF%A1%E9%98%B3%E5%86%9C%E6%9E%97%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1699375&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信阳农林学院信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>网络新媒体的快速发展, 使得网上评论数据呈现爆炸性增长, 面对数量庞大的网络文本, 使用传统的人工方式来提取观点会导致效率低下、分类界限模糊、领域适应性差等问题。为解决以上问题, 在对传统LDA模型进行改进的基础上, 提出了一个基于领域判别的LDA主题模型来对在线评论进行观点挖掘。首先, 在标准LDA模型中引入领域层, 对语料库中的文档采样领域标签, 利用领域化的参数来求解LDA模型;其次, 考虑到句子间的情感从属关系, 在主题层和单词层之间加入情感层, 并引入情感转移变量进行表示, 提高了情感极性分析的精度, 实验结果表明了本文所提模型和理论的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LDA%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LDA模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%86%E5%9F%9F%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">领域识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%82%E7%82%B9%E6%8C%96%E6%8E%98&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">观点挖掘;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E8%BD%AC%E7%A7%BB%E5%8F%98%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感转移变量;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    马长林 (1972-) , 女, 安徽淮北人, 博士, 副教授, CCF会员 (E200035647M) , 研究方向为机器学习和数据挖掘。E-mail:clma@mail.ccnu.edu.cn通信地址:464000河南省信阳市信阳农林学院信息工程学院;
                                </span>
                                <span>
                                    *闵洁 (1981-) , 女, 湖北广水人, 硕士, 讲师, 研究方向为数据挖掘。E-mail:7188087@qq.com通信地址:464000河南省信阳市信阳农林学院信息工程学院;
                                </span>
                                <span>
                                    谢罗迪 (1989-) , 男, 湖北襄阳人, 硕士, 研究方向为机器学习。E-mail:741207430@qq.com通信地址:464000河南省信阳市信阳农林学院信息工程学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-19</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61003192);</span>
                    </p>
            </div>
                    <h1><b>Opinion mining research on topic model based on domain identification</b></h1>
                    <h2>
                    <span>MA Chang-lin</span>
                    <span>MIN Jie</span>
                    <span>XIE Luo-di</span>
            </h2>
                    <h2>
                    <span>School of Computer, Central China Normal University</span>
                    <span>School of Information Engineering, Xinyang Agriculture and Forestry University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the rapid development of new network media, the quantity of online reviews has a tendency of explosive growth. Traditional manual methods for opinion mining have some problems when dealing with tremendous online texts, such as low efficiency, fuzzy classification boundary, and limited domain-adaption ability. In order to solve the above problems, we improve the traditional latent Dirichlet allocation (LDA) model, and propose a LDA topic model based on domain identification for opinion mining of online reviews. Firstly, a domain layer is added to the standard LDA model to sample the domain tags of the document, and field parameters are utilized to solve the LDA model. Secondly, given the sentimental connection between sentences, we insert a sentiment layer between the topic layer and word layer. Sentimental transition variable is introduced to denote related characters, which can increase the accuracy of sentiment polarity analysis. Experimental results verify the validity of the proposed model and theory.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LDA%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LDA model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=domain%20identification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">domain identification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=opinion%20mining&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">opinion mining;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sentimental%20transition%20variable&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sentimental transition variable;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    MA Chang-lin, born in 1972, PhD, associate professor, CCF member (E200035647M) , her research interests include machine learning, and data mining.Address:School of Information Engineering, Xinyang Agriculture and Forestry University, Xinyang 464000, Henan, P.R.China;
                                </span>
                                <span>
                                    MIN Jie, born in 1981, MS, lecturer, her research interest includes data mining.Address:School of Information Engineering, Xinyang Agriculture and Forestry University, Xinyang 464000, Henan, P.R.China;
                                </span>
                                <span>
                                    XIE Luo-di, born in 1989, MS, his re-search interest includes machine learning.Address:School of Information Engineering, Xinyang Agriculture and Forestry University, Xinyang 464000, Henan, P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-19</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="38">2016年8月中国互联网络信息中心发布了第38次《中国互联网络发展状况统计报告》, 截至2016年6月, 中国网民规模达7.10亿, 互联网普及率达到51.7%。以上数据显示, 互联网已经成为现代人生活中的必需品, 借助互联网的快速发展, 信息的传递方式与效率日新月异。</p>
                </div>
                <div class="p1">
                    <p id="39">信息技术的快速发展带来了海量的网络文本信息并且以极高的速度增长, 面对海量且无结构化的文本信息, 通过传统的人工方式在阅读之后再分析、整理获取文本中的观点信息显然是不可能的。因此, 如何快速从这些评论中提取有用的观点信息并对其进行分析总结, 形成直观易懂、针对性强的结果是当前迫切需要解决的问题。观点挖掘正是在这种背景下产生, 成为了用户和文本信息之间一道便捷的桥梁, 使用户能够快速准确地获取所需要的观点信息。</p>
                </div>
                <div class="p1">
                    <p id="40">当前国内外学者针对观点挖掘进行的相关研究工作<citation id="158" type="reference"><link href="124" rel="bibliography" /><link href="126" rel="bibliography" /><link href="128" rel="bibliography" /><link href="150" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">3</a>]</sup></citation>表明, 观点挖掘研究主要聚集在以下2个方面:情感分类和观点抽取。情感分类的主要任务是判定主观信息的情感极性和识别主客观文本;观点抽取主要判断文章中一个句子或者单词所描述的观点, 包括分析情感表达者、抽取特征词和观点词。</p>
                </div>
                <div class="p1">
                    <p id="41">特征词和观点词的抽取是观点挖掘的一个重要任务, 如果能正确识别特征词与观点词的对应关系, 则可以得到基于主题的评论摘要。此外, 根据观点挖掘的粒度来看, 相关研究主要在词语级别、句子级别、篇章级别这3个层次展开。</p>
                </div>
                <div class="p1">
                    <p id="42">Pang等<citation id="164" type="reference"><link href="130" rel="bibliography" /><link href="132" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>最早在划分文本极性和主客观分类方面展开了相关研究工作, 他们运用多种分类器包括朴素贝叶斯、支持向量机等对文本进行极性分析, 采用基于图的最小切割方法来识别句子的主客观性。Sista等<citation id="159" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>利用扩展后的褒义词和贬义词作为分类特征, 提出了一种文本褒贬自动分类器。徐军等<citation id="160" type="reference"><link href="136" rel="bibliography" /><link href="152" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">7</a>]</sup></citation>利用朴素贝叶斯和最大熵模型针对中文新闻进行了情感分类。Ni等<citation id="161" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>使用朴素贝叶斯、支持向量机和Roechio’s算法进行文本情感分类, 并采用信息增益的方法进行特征选择。王素格等<citation id="162" type="reference"><link href="140" rel="bibliography" /><link href="154" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">9</a>]</sup></citation>采用情感词代替句子, 使用线性加权组合的方法来建立分类函数, 从而确定句子的褒贬极性。王根等<citation id="163" type="reference"><link href="142" rel="bibliography" /><link href="156" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">10</a>]</sup></citation>使用条件随机场来划分句子的情感极性, 在此基础上提出了一种基于多重冗余标记的模型, 该模型能够对句子进行主客观和褒贬分类, 同时能够量化句子的褒贬强弱。</p>
                </div>
                <div class="p1">
                    <p id="43">以上研究都是基于篇章级别或句子级别开展的粗粒度观点挖掘, 而广大用户想获取事物更为全面的特征细节, 因此细粒度观点挖掘应运而生。它基于词语级别进行情感分类, 不仅能从整体上分析评论的情感倾向, 还能得到各个特征下的观点信息, 更好地满足实际应用需求。</p>
                </div>
                <div class="p1">
                    <p id="44">Ma等<citation id="165" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了主题情感统一最大熵LDA (Latent Dirichlet Allocation) 模型, 基于词语级别进行细粒度的观点挖掘。该模型在标准LDA模型的基础上加入了最大熵组件和情感层, 在进行主题抽取的同时完成了情感分类的任务, 但该研究没有对语料库中文档的领域归属进行划分, 忽略了不同领域的文档之间的内在联系, 而不同领域文档的主题与所服从的主题分布区别很大。</p>
                </div>
                <div class="p1">
                    <p id="45">另外, 连词在情感分析中起着重要作用, 文档中句子之间有着一定的情感从属关系, 前一个句子的情感往往会对后面句子的情感产生一定的影响, 而以上研究都忽略了这种情感从属关系。</p>
                </div>
                <div class="p1">
                    <p id="46">综合以上研究, 本文提出基于领域判别的LDA主题模型DI LDA (LDA model based on Domain Identification) 进行细粒度观点挖掘。该模型在结合文档领域信息和句子间情感从属关系的前提下对LDA模型进行扩展改进, 引入领域层对语料库中的文档采样领域标签, 利用领域化的主题先验参数求解文档的主题分布, 保证了不同领域文档主题分布的独立性;引入情感转移变量处理句子间的情感从属关系, 提高了情感极性分析的精度。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>2 DI LDA模型描述</b></h3>
                <div class="p1">
                    <p id="48">标准LDA主题模型认为文档是由不同主题按照一定比例混合组成, 而主题则是由不同单词按照一定比例混合组成。在进行观点挖掘时所选取的语料库往往是由同一个领域的文档组成, 然后依据语料特性选取最佳先验参数, 这种做法忽略了不同领域的文档之间的内在联系。不同领域的文档所讨论的主题与服从的主题分布区别非常大, 例如教育领域的文档所讨论的主题主要是“高考”“六级”等, 而科技领域的文档所讨论的主题主要是“计算机”“手机”, 但是不同领域的主题所使用的情感词则具有一定的共性, 例如“喜欢”“优秀”“差”等修饰性词汇几乎在所有领域都可适用并且在文档中占据较大比例。</p>
                </div>
                <div class="p1">
                    <p id="49">目前, 许多关于观点挖掘的研究以句子为单位来获取情感标签, 对句子与句子之间的情感联系则完全没有考虑。但是, 在实际应用中, 句子与句子之间存在着一定的情感从属关系, 前一个句子的情感往往会对后面句子的情感产生影响, 如下面2段语料可以体现这种情感从属关系。</p>
                </div>
                <div class="p1">
                    <p id="50"><b>语料1</b> “第2盘比赛开始后, 彭帅再接再厉给马泰克施加压力。相反, 美国选手则连续出现非压迫性失误, 彭帅以6-3拿下第2盘比赛。这样总比分2-0, 彭帅挺进第2轮。大赛2号种子—捷克新星萨法洛娃苦战3盘, 以1-2告负斯洛伐克选手拉伊巴利科娃。第1盘, 两位选手展开激战一直战至抢7。抢7局中, 萨法洛娃无奈告负。但在第2盘比赛中, 大赛2号种子找回些许状态, 以6-4将总比分追成1-1平”。</p>
                </div>
                <div class="p1">
                    <p id="51"><b>语料2</b> “这3名总经理比较一致的看法就是频繁换帅对保持球队的稳定并没有好处。而且频繁换帅还要付出较高的经济代价, 像范甘迪等人的年薪高达500万美元, 球队单方解约意味着要支付高额赔偿金, 当然最主要的是各球队的老板不希望球队因为换帅而出现大的波动”。</p>
                </div>
                <div class="p1">
                    <p id="52">在第1段语料中共出现2次句子与句子之间的情感转折, 第1句话描述彭帅在指挥上的优势, 表征的是正向的情感, 而第2句话通过连词“相反”与前一句话进行连接, 描述美国选手的状态不佳, 表征的是负向的情感。同样地, 第5个句子与第6个句子之间通过连词“但”完成了句子之间的情感转折。在第2段语料中, 首先描述换帅对于球队的坏处, 是负向的情感, 然后利用连词“而且”继续叙述换帅对于经济带来的巨大损失, 2个句子之间通过连词完成了情感的延续。</p>
                </div>
                <div class="p1">
                    <p id="53">从以上分析中可以看出, 2个句子之间如果通过“相反”“不过”等转折连词进行连接, 后一个句子往往与前一个句子有着相反的情感, 认为是前一个句子在情感上的转折;而用“甚至”“并且”等并列连词连接的句子, 往往与前一个句子有着相同的情感, 认为是前一个句子在情感上的延续;如果2个句子之间没有用连词或者是其它连词连接, 则认为2个句子之间情感相互独立, 没有情感从属关系。</p>
                </div>
                <div class="p1">
                    <p id="54">本文提出的DI LDA模型是对标准LDA模型的改进, 它通过引入领域层对语料库中的文档采样领域标签, 利用领域化的主题先验参数求解文档的主题分布, 保证了不同领域文档主题分布的独立性;为解决句子之间的情感从属关系, 本文模型引入情感转移变量<i>r</i>进行表征, <i>r</i>的取值对应连词特性 ({-1, 0, 1}, -1:转折连词, 0:无连词, 1:并列连词) 。DI LDA模型图如图1所示, 所使用的符号含义如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="55">DI LDA模型的生成过程描述如下:</p>
                </div>
                <div class="p1">
                    <p id="56"> (1) 对一个语料库:</p>
                </div>
                <div class="p1">
                    <p id="57">①由先验参数<i>λ</i>得到语料库中领域分布<i>Ω</i>～<i>Dir</i> (<i>λ</i>) ;</p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907022_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 DI LDA模型" src="Detail/GetImg?filename=images/JSJK201907022_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 DI LDA模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907022_058.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 DI LDA model</p>

                </div>
                <div class="area_img" id="59">
                    <p class="img_tit"><b>表1 DI LDA模型中符号含义</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Meaning of the notations in the DI LDA model</b></p>
                    <p class="img_note"></p>
                    <table id="59" border="1"><tr><td><br />符号</td><td>含义</td><td>符号</td><td>含义</td></tr><tr><td><br /><i>D</i></td><td>整个语料库中文档总数</td><td><i>s</i></td><td>情感, 取值{-1, 1} (-1:负向, 1:正向) </td></tr><tr><td><br /><i>M</i></td><td>每篇文档中句子个数</td><td><i>α</i></td><td><i>θ</i>的Dirichlet先验参数</td></tr><tr><td><br /><i>N</i></td><td>每个句子中单词个数</td><td><i>β</i></td><td><i>Φ</i>的Dirichlet先验参数</td></tr><tr><td><br /><i>T</i></td><td>主题个数</td><td><i>τ</i></td><td><i>ε</i>的Dirichlet先验参数</td></tr><tr><td><br /><i>S</i></td><td>情感个数</td><td><i>θ</i></td><td>主题的Dirichlet分布</td></tr><tr><td><br /><i>W</i></td><td>语料库中单词列表</td><td><i>Φ</i></td><td>单词的Dirichlet分布</td></tr><tr><td><br /><i>V</i></td><td>整个语料库中单词总数</td><td><i>π</i></td><td>情感的Beta分布</td></tr><tr><td><br /><i>F</i></td><td>文档所属领域个数</td><td><i>ε</i></td><td>转移变量的Dirichlet分布</td></tr><tr><td><br /><i>R</i></td><td>转移变量个数</td><td><i>λ</i></td><td><i>Ω</i>的Dirichlet先验参数</td></tr><tr><td><br /><i>w</i></td><td>语料库中单词</td><td><i>Ω</i></td><td>领域的Dirichlet分布</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="60">②由先验参数<i>β</i>获得每个领域的单词分布<i>Φ</i><sup><i>f</i>, <i>t</i>, <i>s</i></sup>～<i>Dir</i> (<i>β</i>) (其中<i>f</i>表示领域, 取值1～<i>F</i>;<i>s</i>表示情感, 取值{-1, 1};<i>t</i>表示主题, 取值1～<i>T</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="61"> (2) 对语料库中每一篇文档<i>d</i> :</p>
                </div>
                <div class="p1">
                    <p id="62">①为文档选择对应领域标签, <i>g</i><sup><i>d</i></sup>～<i>Multinomial</i> (<i>Ω</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="63">②得出对应领域的文档的主题分布<i>θ</i><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mi>d</mi></msubsup></mrow></math></mathml>～<i>Dir</i> (<i>α</i><sub><i>f</i></sub>) ;</p>
                </div>
                <div class="p1">
                    <p id="65">③由先验参数<i>τ</i>获得文档的连词分布<i>ε</i><sup><i>d</i></sup>～<i>Dir</i> (<i>τ</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="66">④对文档中的每个主题<i>z</i>, 得出对应主题下的情感分布<i>π</i><sup><i>d</i>, <i>z</i></sup>～<i>Beta</i> (<i>γ</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="67"> (3) 对每一篇文档<i>d</i>中的第<i>m</i>个句子 :</p>
                </div>
                <div class="p1">
                    <p id="68">①选择对应领域的主题<i>z</i><sub><i>d</i>, <i>m</i></sub>, 其中<i>z</i><sub><i>d</i>, <i>m</i></sub>～ <i>Multinomial</i> (<i>θ</i><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>f</mi><mi>d</mi></msubsup></mrow></math></mathml>) ;</p>
                </div>
                <div class="p1">
                    <p id="70">②当<i>m</i>=1时, <i>r</i><sub><i>d</i>, <i>m</i></sub>=0, 当<i>m</i>≠1时, <i>r</i><sub><i>d</i>, <i>m</i></sub>～ <i>Multinomial</i> (<i>ε</i><sup><i>d</i></sup>) ;</p>
                </div>
                <div class="p1">
                    <p id="71">③对给定主题<i>z</i><sub><i>d</i>, <i>m</i></sub>, 结合<i>r</i><sub><i>d</i>, <i>m</i></sub>选择其对应情感<i>s</i><sub><i>d</i>, <i>m</i>, <i>z</i></sub>, 当<i>r</i><sub><i>d</i>, <i>m</i></sub>=0时, <i>s</i><sub><i>d</i>, <i>m</i>, <i>z</i></sub>～<i>Bernoulli</i> (<i>π</i><sup><i>d</i>, <i>z</i></sup>) , 当<i>r</i><sub><i>d</i>, <i>m</i></sub>=1时, <i>s</i><sub><i>d</i>, <i>m</i>, <i>z</i></sub> = <i>s</i><sub><i>d</i>, <i>m</i>-1, <i>z</i></sub>, 当<i>r</i><sub><i>d</i>, <i>m</i></sub>=-1时, <i>s</i><sub><i>d</i>, <i>m</i>, <i>z</i></sub> =-<i>s</i><sub><i>d</i>, <i>m</i>-1, <i>z</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="72"> (4) 对句子<i>m</i> 中每个词<i>n</i> (<i>w</i><sub><i>d</i>, <i>m</i>, <i>n</i></sub>) :</p>
                </div>
                <div class="p1">
                    <p id="73">①为单词<i>w</i><sub><i>d</i>, <i>m</i>, <i>n</i></sub>选择主题<i>z</i><sub><i>d</i>, <i>m</i></sub>和情感<i>s</i><sub><i>d</i>, <i>m</i>, <i>z</i></sub>, 根据本文假设句子中所有单词隶属于同一主题和情感, 单词<i>w</i><sub><i>d</i>, <i>m</i>, <i>n</i></sub>的主题与情感即为所在句子的主题与情感;</p>
                </div>
                <div class="p1">
                    <p id="74">②选择具体的单词, <i>w</i><sub><i>d</i>, <i>m</i>, <i>n</i></sub>～<i>Multinomial</i> (<i>Φ</i><sup><i>f</i>, <i>t</i>, <i>s</i></sup>) 。</p>
                </div>
                <h3 id="75" name="75" class="anchor-tag"><b>3 DI LDA模型推理</b></h3>
                <div class="p1">
                    <p id="76">对LDA模型的推理难点在于求解模型中的各个分布参数。求解LDA主题模型的方法很多, 最常见的有EM (Expectation Maximization) 算法、Gibbs采样算法等, 其中Gibbs采样算法因为其实现简单和容易理解的特点而被研究者们广泛采用, 本文采用Gibbs采样算法进行推理。DI LDA模型与LDA主题模型一样属于生成模型, 对本文模型的推理需要求解领域分布、对应领域的主题分布、情感分布等多个参数。本节的推理过程中所有以<i>N</i>为代表的计数均排除了当前文档、句子或者单词的数目。推理参数描述如表2所示。</p>
                </div>
                <div class="area_img" id="77">
                    <p class="img_tit"><b>表2 DI LDA模型推理中参数说明</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Meaning of the notations in DI LDA model inference</b></p>
                    <p class="img_note"></p>
                    <table id="77" border="1"><tr><td><br />符号</td><td>含义</td></tr><tr><td><br /><i>g</i><sub>-<i>d</i></sub></td><td>去除文档<i>d</i>, 语料库中所有文档的领域</td></tr><tr><td><br /><i>S</i><sub>-<i>m</i></sub></td><td>去除第<i>m</i>个句子, 文档中所有句子的情感</td></tr><tr><td><br /><i>N</i><sub> (<i>f</i>) </sub></td><td>语料库中属于领域<i>f</i>的文档数目</td></tr><tr><td><br /><i>N</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></td><td>文档<i>d</i>中句子被分配为领域<i>f</i>主题为<i>t</i>的次数</td></tr><tr><td><br /><i>N</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></td><td>文档<i>d</i>中句子总数目</td></tr><tr><td><br /><i>m</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup></mrow></math></td><td>第<i>m</i>篇文档中单词<i>v</i><sub><i>i</i></sub>属于领域<i>f</i>的数目</td></tr><tr><td><br /><i>N</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo>, </mo><mi>s</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></td><td>文档<i>d</i>中领域为<i>f</i>主题为<i>t</i>情感为<i>s</i>的句子数目</td></tr><tr><td><br /><i>Z</i><sub>-<i>m</i></sub></td><td>去除第<i>m</i>个句子后文档中所有句子的主题</td></tr><tr><td><br /><i>r</i><sub>-<i>m</i></sub></td><td>去除第<i>m</i>个句子后文档中所有句子转移变量</td></tr><tr><td><br /><i>N</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>⋅</mo><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup></mrow></math></td><td>语料库中属于领域<i>f</i>的单词数目</td></tr><tr><td><br /><i>N</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>r</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></td><td>文档<i>d</i>中转移变量为<i>r</i>的句子数目</td></tr><tr><td><br /><i>N</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup></mrow></math></td><td>语料库中单词<i>v</i><sub><i>i</i></sub>属于领域<i>f</i>的数目</td></tr><tr><td><br /><i>N</i> (.) </td><td>语料库中文档总数</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="78">对一篇文档来说, 词频越高的单词对领域的贡献越大, 综合该因素, 用式 (1) 对语料库中文档<i>d</i>采样分配领域标签:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mrow><mo> (</mo><mrow><mi>g</mi><msub><mrow></mrow><mi>d</mi></msub><mo>=</mo><mi>f</mi><mo stretchy="false">|</mo><mi>g</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>d</mi></mrow></msub></mrow><mo>) </mo></mrow><mo>∝</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo></mrow></msub><mo>+</mo><mi>λ</mi></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow></msub><mo>+</mo><mi>F</mi><mi>λ</mi></mrow></mfrac><mo>*</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>Γ</mi><mo stretchy="false"> (</mo><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup><mo>+</mo><mi>V</mi><mi>β</mi><msub><mrow></mrow><mi>f</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>Γ</mi><mo stretchy="false"> (</mo><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup><mo>+</mo><mi>m</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup><mo>+</mo><mi>V</mi><mi>β</mi><msub><mrow></mrow><mi>f</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mfrac><mrow><mi>Γ</mi><mo stretchy="false"> (</mo><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup><mo>+</mo><mi>m</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup><mo>+</mo><mi>β</mi><msub><mrow></mrow><mi>f</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mi>Γ</mi><mo stretchy="false"> (</mo><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mi>f</mi></msubsup><mo>+</mo><mi>β</mi><msub><mrow></mrow><mi>f</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">其中, <i>n</i>表示文档<i>d</i>中词频最高的前<i>n</i>个单词。</p>
                </div>
                <div class="p1">
                    <p id="81">考虑到句子与句子之间的情感从属关系, 用式 (2) 为文档<i>d</i>中第<i>m</i>个句子分配连词标签:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mrow><mo> (</mo><mrow><mi>r</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi></mrow></msub><mo>=</mo><mi>r</mi><mo stretchy="false">|</mo><mi>r</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>m</mi></mrow></msub></mrow><mo>) </mo></mrow><mo>∝</mo><mfrac><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>r</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>τ</mi></mrow><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>R</mi><mi>τ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">文档中的连词分布只关乎语言特性以及评论者的表达习惯, 与文档所在的领域关系较小, 因此本文并未将其进行领域化。</p>
                </div>
                <div class="p1">
                    <p id="84">对文档<i>d</i>中的第<i>m</i>个句子分配主题与情感标签:</p>
                </div>
                <div class="p1">
                    <p id="85"> (1) 当<i>r</i><sub><i>d</i>, <i>m</i></sub>=0时, 第<i>m</i>个句子与其前一个句子之间在情感上是独立的, 不存在情感从属关系, 按照式 (3) 为其分配对应领域的主题与情感标签:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi></mrow></msub><mo>=</mo><mi>t</mi><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi></mrow></msub><mo>=</mo><mi>s</mi><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>m</mi></mrow></msub><mo>, </mo><mi>s</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>m</mi></mrow></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>∝</mo><mfrac><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>α</mi><msub><mrow></mrow><mi>f</mi></msub></mrow><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>Τ</mi><mi>α</mi><msub><mrow></mrow><mi>f</mi></msub></mrow></mfrac><mo>×</mo><mfrac><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo>, </mo><mi>s</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>γ</mi></mrow><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>S</mi><mi>γ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87"> (2) 当<i>r</i><sub><i>d</i>, <i>m</i></sub>≠0时, 表示2个句子之间存在情感从属关系, 首先用式 (4) 为句子采样主题标签:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mrow><mo> (</mo><mrow><mi>z</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi></mrow></msub><mo>=</mo><mi>t</mi><mo stretchy="false">|</mo><mi>z</mi><msub><mrow></mrow><mrow><mo>-</mo><mi>m</mi></mrow></msub></mrow><mo>) </mo></mrow><mo>∝</mo><mfrac><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>α</mi><msub><mrow></mrow><mi>f</mi></msub></mrow><mrow><mi>Ν</mi><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup><mo>+</mo><mi>Τ</mi><mi>α</mi><msub><mrow></mrow><mi>f</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">此时, 第<i>m</i>个句子的情感由其连词标签和前一个句子的情感共同确定, 依据式 (5) 得到该句的情感标签2:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi></mrow></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>s</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi>r</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi></mrow></msub><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd><mo>-</mo><mi>s</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi>r</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>, </mo><mi>m</mi></mrow></msub><mo>=</mo><mo>-</mo><mn>1</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">语料库中文档的领域分布为<i>Ω</i><sub><i>f</i></sub>= (<i>N</i><sub> (<i>f</i>) </sub>+<i>λ</i>) / (<i>N</i><sub> (.) </sub>+<i>Fλ</i>) , 文档<i>d</i>中句子的连词分布为<i>ε</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>r</mi><mi>d</mi></msubsup></mrow></math></mathml>= (<i>N</i><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>r</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></mathml>+<i>τ</i>) / (<i>N</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></mathml>+<i>Rτ</i>) , 文档<i>d</i>中的领域<i>f</i>的主题分布为<i>θ</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>t</mi></mrow><mi>d</mi></msubsup></mrow></math></mathml>= (<i>N</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></mathml>+<i>α</i>) / (<i>N</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>.</mo><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></mathml>+<i>Tα</i>) , 文档<i>d</i>中领域<i>f</i>主题<i>t</i>下的情感分布为<i>π</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>f</mi><mo>, </mo><mi>t</mi><mo>, </mo><mi>s</mi></mrow><mi>d</mi></msubsup></mrow></math></mathml>= (<i>N</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo>, </mo><mi>s</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></mathml>+<i>γ</i><sub><i>s</i></sub>) / (<i>N</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>f</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mi>d</mi></msubsup></mrow></math></mathml>+<i>Sγ</i><sub><i>s</i></sub>) 。</p>
                </div>
                <h3 id="101" name="101" class="anchor-tag"><b>4 实验</b></h3>
                <div class="p1">
                    <p id="102">本文实验选用面向对象的Java语言进行开发, 使用来自sougou实验室<citation id="166" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>的中文语料库, 包括汽车、财经、IT、健康、体育、旅游、教育、招聘、文化、军事10个类别的相关内容, 每个类别包含1 990篇文档。</p>
                </div>
                <div class="p1">
                    <p id="103">在进行实验之前需要对实验数据进行预处理。首先将语料库进行去停用词处理, 本文采用中国科学院计算技术研究所提供的汉语词法分析系统<citation id="167" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 其有着速度快、准确率高的特点, 因此在中文信息处理领域得到了广泛应用。</p>
                </div>
                <div class="p1">
                    <p id="104">本文所提出的DI LDA模型与传统LDA模型相比, 引入了领域层对文档进行领域识别, 不同领域中的文档使用对应的领域参数进行求解, 在引入情感层进行情感极性分析的基础上, 考虑到句子与句子之间的情感从属关系, 使用转移变量进行表示。本文实验主要从领域识别精度进行语料分析结果对比, 以语料库中的IT、体育、健康、教育、旅游、军事这6个区分明显且为当下热门舆论的类别进行领域采样分析, 每个类别中选取800篇文档作为训练语料, 再抽取200篇作为测试语料。本文对领域判别精度定义如下:</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>领</mtext><mtext>域</mtext><mtext>判</mtext><mtext>别</mtext><mtext>精</mtext><mtext>度</mtext><mo stretchy="false"> (</mo><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mtable columnalign="left"><mtr><mtd><mtext>领</mtext><mtext>域</mtext><mtext>采</mtext><mtext>样</mtext><mtext>正</mtext><mtext>确</mtext><mtext>的</mtext><mtext>文</mtext><mtext>档</mtext><mtext>数</mtext><mtext>目</mtext></mtd></mtr><mtr><mtd></mtd></mtr></mtable><mrow><mtext>测</mtext><mtext>试</mtext><mtext>集</mtext><mtext>中</mtext><mtext>文</mtext><mtext>档</mtext><mtext>总</mtext><mtext>数</mtext><mtext>目</mtext></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">在DI LDA模型中为每一篇文档采样领域标签时, 本文考虑到了高词频的单词对文档所在领域的贡献, 取词频最高的前<i>n</i>个单词, 随着<i>n</i>取值的变化, 领域区分的精度也会变化, 为保证结果稳定性对每个<i>n</i>的取值进行10次重复实验, 结果如表3所示。</p>
                </div>
                <div class="area_img" id="107">
                    <p class="img_tit"><b>表3 <i>n</i>取不同值时领域判别精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Domain identification accuracy under different value of <i>n</i></b></p>
                    <p class="img_note"></p>
                    <table id="107" border="1"><tr><td rowspan="2"><br />次数</td><td colspan="6"><br /><i>n</i></td></tr><tr><td><br />0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td><br />1</td><td>0.694</td><td>0.744</td><td>0.785</td><td>0.830</td><td>0.814</td><td>0.803</td></tr><tr><td><br />2</td><td>0.715</td><td>0.726</td><td>0.779</td><td>0.856</td><td>0.825</td><td>0.829</td></tr><tr><td><br />3</td><td>0.729</td><td>0.759</td><td>0.803</td><td>0.829</td><td>0.816</td><td>0.803</td></tr><tr><td><br />4</td><td>0.703</td><td>0.747</td><td>0.794</td><td>0.817</td><td>0.838</td><td>0.811</td></tr><tr><td><br />5</td><td>0.711</td><td>0.782</td><td>0.797</td><td>0.824</td><td>0.827</td><td>0.821</td></tr><tr><td><br />6</td><td>0.672</td><td>0.790</td><td>0.817</td><td>0.824</td><td>0.817</td><td>0.801</td></tr><tr><td><br />7</td><td>0.681</td><td>0.712</td><td>0.760</td><td>0.831</td><td>0.832</td><td>0.807</td></tr><tr><td><br />8</td><td>0.711</td><td>0.719</td><td>0.755</td><td>0.814</td><td>0.829</td><td>0.825</td></tr><tr><td><br />9</td><td>0.701</td><td>0.733</td><td>0.772</td><td>0.837</td><td>0.835</td><td>0.817</td></tr><tr><td><br />10</td><td>0.641</td><td>0.741</td><td>0.767</td><td>0.838</td><td>0.817</td><td>0.807</td></tr><tr><td><br />平均</td><td>0.695</td><td>0.745</td><td>0.782</td><td>0.829</td><td>0.826</td><td>0.813</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="108">由表3可知, 当<i>n</i>取值为0时, 精度最低, 此时为文档采样领域标签时并未考虑到高词频单词的影响, 当<i>n</i>取值为3即在采样领域标签时考虑到词频最高的前3个单词的影响时, 领域判别精度最高, 通过对语料库中文档分析发现, 通常情况下语料库中词频最高的3～4个单词往往是最具有领域代表性的。当<i>n</i>的取值超过3时, 领域判别的精度逐渐平稳略有下降, 综合来看领域判别的精度最高可以达到0.856。</p>
                </div>
                <div class="p1">
                    <p id="109">为验证DI LDA模型在进行领域判别时的稳定性, 本文在<i>n</i>=3时分别以6个类别中的各200, 400, 600, 800, 1 000篇文档作为测试语料, 每次测试重复10次, 结果如表4所示。</p>
                </div>
                <div class="area_img" id="110">
                    <p class="img_tit"><b>表4 不同数量的测试集下领域判别精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Domain identification accuracy under different test set sizes</b></p>
                    <p class="img_note"></p>
                    <table id="110" border="1"><tr><td rowspan="2"><br />次数</td><td colspan="5"><br />文档数目</td></tr><tr><td><br />200</td><td>400</td><td>600</td><td>800</td><td>1 000</td></tr><tr><td><br />1</td><td>0.842</td><td>0.834</td><td>0.822</td><td>0.854</td><td>0.820</td></tr><tr><td><br />2</td><td>0.822</td><td>0.851</td><td>0.846</td><td>0.856</td><td>0.844</td></tr><tr><td><br />3</td><td>0.837</td><td>0.844</td><td>0.811</td><td>0.844</td><td>0.851</td></tr><tr><td><br />4</td><td>0.849</td><td>0.851</td><td>0.824</td><td>0.803</td><td>0.836</td></tr><tr><td><br />5</td><td>0.816</td><td>0.837</td><td>0.835</td><td>0.817</td><td>0.829</td></tr><tr><td><br />6</td><td>0.846</td><td>0.837</td><td>0.839</td><td>0.827</td><td>0.839</td></tr><tr><td><br />7</td><td>0.803</td><td>0.849</td><td>0.815</td><td>0.817</td><td>0.843</td></tr><tr><td><br />8</td><td>0.856</td><td>0.837</td><td>0.835</td><td>0.833</td><td>0.846</td></tr><tr><td><br />9</td><td>0.807</td><td>0.843</td><td>0.824</td><td>0.831</td><td>0.820</td></tr><tr><td><br />10</td><td>0.812</td><td>0.841</td><td>0.826</td><td>0.830</td><td>0.842</td></tr><tr><td><br />平均</td><td>0.833</td><td>0.843</td><td>0.827</td><td>0.834</td><td>0.836</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="111">从表4中可以看出, 在不同数量的测试集下, DI LDA模型的领域识别精度比较稳定, 没有发生较大幅度的波动, 维持在0.83～0.84。</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="113">本文提出了一个基于领域判别的LDA主题模型来对在线评论进行观点挖掘。在标准LDA模型中引入领域层, 对语料库中的文档采样领域标签;另外, 考虑到句子间的情感从属关系, 在主题层和单词层之间加入情感层, 并引入情感转移变量进行表示, 提高了情感极性分析的精度, 实验结果表明了本文所提模型和理论的有效性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="169" type="formula" href="images/JSJK201907022_16900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">马长林</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="171" type="formula" href="images/JSJK201907022_17100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">闵洁</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="124">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 Pang B, Lee L.Opinion mining and sentiment analysis[J].Foundations and Trends in Information Retrieval, 2008, 2 (1-2) :1-135.
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A survey of sentiment analysis">

                                <b>[2]</b> Inui T, Okumura M.A survey of sentiment analysis[J].Journal of Natural Language Processing, 2006, 13 (3) :201-241.
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201307002&amp;v=MDMwNDllUm1GeTdtVzc3TFBTbkJmYkc0SDlMTXFJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Li Jun.A survey of sentiment analysis and opinion mining on product reviews[J].Modern Computer, 2013 (5) :11-16. (in Chinese) 
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Thumbs up? sentiment classification using machine learning techniques">

                                <b>[4]</b> Pang B, Lee L, Vaithyanathan S.Thumbs up?Sentiment classification using machine learning techniques[C]//Proc of the ACL-02 Conference on Empirical Methods in Natural Language Processing:Association for Computational Linguistics, 2002:79-86.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A sentimental education:sentiment analysis using subjectivity summarization based on minimum cuts">

                                <b>[5]</b> Pang B, Lee L.A sentimental education:Sentiment analysis using subjectivity summarization based on minimum cuts[C]//Proc of the 42nd Annual Meeting on Association for Computational Linguistics:Association for Computational Linguistics, 2004:Article No.271.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Polarized Lexicon for ReviewClassification">

                                <b>[6]</b> Sista S P, Srinivasan S H.Polarized lexicon for review classification[C]//Proc of International Conference on Machine Learning, 2004:867-872.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 Xu Jun, Ding Yu-xin, Wang Xiao-long.Sentiment classification for Chinese news using machine learning methods [J].Journal of Chinese Information Processing, 2007, 21 (6) :95-100. (in Chinese) 
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploring in the Weblog Space by Detecting Informative and Affective Articles">

                                <b>[8]</b> Ni X, Xue G R, Ling X, et al.Exploring in the Weblog space by detecting informative and affective articles[C]//Proc of the 16th International Conference on World Wide Web, 2007:281-290.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201105022&amp;v=MzA0NDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21XNzdMTHl2U2RMRzRIOURNcW85SFpvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Wang Su-ge, Li De-yu, Wei Ying-jie.A method of text sentiment classification based on weighted rough membership [J].Journal of Computer Research and Development, 2011, 48 (5) :855-861. (in Chinese) 
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                 Wang Gen, Zhao Jun.Sentence sentiment analysis based on multi-redundant-labeled CRFs[J].Journal of Chinese Information Processing, 2007, 21 (5) :51-55. (in Chinese) 
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Topic and sentiment unification maximum entropy model for online review analysis">

                                <b>[11]</b> Ma Chang-lin, Wang Meng, Chen Xue-wen.Topic and sentiment unification maximum entropy model for online review analysis[C]//Proc of the 24th International Conference on World Wide Web, 2015:649-654.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_12" target="_blank" href="">

                                <b>[12]</b> http://www.sogou.com/labs/.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_13" target="_blank" href="">

                                <b>[13]</b> http://ictclas.nlpir.org/.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 李俊.面向产品评论的意见挖掘研究综述[J].现代计算机 (专业版) , 2013 (5) :11-16.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200706016&amp;v=MTY2NTR6cXFCdEdGckNVUkxPZVplUm1GeTdtVzc3TEtDallmYkc0SHRiTXFZOUVZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 徐军, 丁宇新, 王晓龙.使用机器学习方法进行新闻的情感自动分类[J].中文信息学报, 2007, 21 (6) :95-100.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 王素格, 李德玉, 魏英杰.基于赋权粗糙隶属度的文本情感分类方法[J].计算机研究与发展, 2011, 48 (5) :855-861.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200705011&amp;v=MjA0MjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21XNzdMS0NqWWZiRzRIdGJNcW85RVpZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 王根, 赵军.基于多重冗余标记CRFs的句子情感分析研究[J].中文信息学报, 2007, 21 (5) :51-55.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201907022" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907022&amp;v=MDI0OTMzenFxQnRHRnJDVVJMT2VaZVJtRnk3bVc3N0xMejdCWmJHNEg5ak1xSTlIWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
