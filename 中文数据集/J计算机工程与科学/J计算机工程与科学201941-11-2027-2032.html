<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132344186436250%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJSJK201911017%26RESULT%3d1%26SIGN%3dFW%252bOkAax8HovNnUUP%252fh6MABwtjk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911017&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201911017&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911017&amp;v=MDA1NzdCdEdGckNVUkxPZVplUm1GeS9nVXIvQkx6N0JaYkc0SDlqTnJvOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;2 Stacking集成学习方法&lt;/b&gt; "><b>2 Stacking集成学习方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="&lt;b&gt;2.1 基分类器的改进&lt;/b&gt;"><b>2.1 基分类器的改进</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;2.2 基分类器的组合方式探究&lt;/b&gt;"><b>2.2 基分类器的组合方式探究</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;3 数据准备与评价指标&lt;/b&gt; "><b>3 数据准备与评价指标</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;3.1 问题描述&lt;/b&gt;"><b>3.1 问题描述</b></a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;3.2 数据集选择和特征提取&lt;/b&gt;"><b>3.2 数据集选择和特征提取</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;3.3 特征选择&lt;/b&gt;"><b>3.3 特征选择</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;3.4 评价指标&lt;/b&gt;"><b>3.4 评价指标</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;4 实验分析&lt;/b&gt; "><b>4 实验分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="&lt;b&gt;4.1 基分类器预测得分&lt;/b&gt;"><b>4.1 基分类器预测得分</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;4.2 不同分类器组合的模型得分&lt;/b&gt;"><b>4.2 不同分类器组合的模型得分</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="图1 Stacking集成框架">图1 Stacking集成框架</a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;表1 单一分类器验证集得分&lt;/b&gt;"><b>表1 单一分类器验证集得分</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;表2 不同的基分类器组合方式&lt;/b&gt;"><b>表2 不同的基分类器组合方式</b></a></li>
                                                <li><a href="#82" data-title="图2 召回率对比">图2 召回率对比</a></li>
                                                <li><a href="#89" data-title="图3 &lt;i&gt;F&lt;/i&gt;1-&lt;i&gt;score&lt;/i&gt;对比">图3 <i>F</i>1-<i>score</i>对比</a></li>
                                                <li><a href="#90" data-title="图4 分类准确率对比">图4 分类准确率对比</a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表3 不同组合方式的召回率最高得分与基础分的比较&lt;/b&gt;"><b>表3 不同组合方式的召回率最高得分与基础分的比较</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;表4 不同组合方式的&lt;/b&gt;&lt;i&gt;&lt;b&gt;F&lt;/b&gt;&lt;/i&gt;&lt;b&gt;1-&lt;/b&gt;&lt;i&gt;&lt;b&gt;score&lt;/b&gt;&lt;/i&gt;&lt;b&gt;最高得分与基础分的比较&lt;/b&gt;"><b>表4 不同组合方式的</b><i><b>F</b></i><b>1-</b><i><b>score</b></i><b>最高得分与基础分的比较</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;表5 不同组合方式的准确率最高得分与基础分的比较&lt;/b&gt;"><b>表5 不同组合方式的准确率最高得分与基础分的比较</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;表6 BS-Stacking与其它模型的比较&lt;/b&gt;"><b>表6 BS-Stacking与其它模型的比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="5">


                                    <a id="bibliography_1" title=" Hassouna M,Tarhini A,Elyas T,et al.Customer churn in mobile markets:A comparison of techniques[J].International Business Research,2015,8(6):224-237." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Customer churn in mobile markets:a comparison of techniques">
                                        <b>[1]</b>
                                         Hassouna M,Tarhini A,Elyas T,et al.Customer churn in mobile markets:A comparison of techniques[J].International Business Research,2015,8(6):224-237.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_2" title=" Tiwari A,Sam R,Shaikh S.Analysis and prediction of churn customers for telecommunication industry[C]//Proc of 2017 International Conference on I-SMAC (IoT in Social,Mobile,Analytics and Cloud)(I-SMAC),2017:218-222." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analysis and prediction of churn customers for telecommunication industry">
                                        <b>[2]</b>
                                         Tiwari A,Sam R,Shaikh S.Analysis and prediction of churn customers for telecommunication industry[C]//Proc of 2017 International Conference on I-SMAC (IoT in Social,Mobile,Analytics and Cloud)(I-SMAC),2017:218-222.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_3" title=" Soltani Z,Navimipour N J.Customer relationship management mechanisms:A systematic review of the state of the art literature and recommendations for future research[J].Computers in Human Behavior,2016,61:667-688." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Customer relationship management mechanisms:A systematic review of the state of the art literature and recommendations for future research">
                                        <b>[3]</b>
                                         Soltani Z,Navimipour N J.Customer relationship management mechanisms:A systematic review of the state of the art literature and recommendations for future research[J].Computers in Human Behavior,2016,61:667-688.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_4" title=" Gillies C,Rigby D,Reichheld F.The story behind successful customer relations management[J].European Business Journal,2002,14(2):73-77." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Story Behind Successful Customer Relations Management">
                                        <b>[4]</b>
                                         Gillies C,Rigby D,Reichheld F.The story behind successful customer relations management[J].European Business Journal,2002,14(2):73-77.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     Zhu Zhi-yong,Xu Chang-mei,Liu Zhi-bing,et al.Research of customer churn analysis based on the Bayesian network[J].Computer Engineering &amp;amp; Science,2013,35(3):155-158.(in Chinese)</a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_6" title=" Dalvi P K,Khandge S K,Deomore A,et al.Analysis of customer churn prediction in telecom industry using decision trees and logistic regression[C]//Proc of 2016 Symposium on Colossal Data Analysis and Networking (CDAN),2016:1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analysis of customer churn prediction in telecom industry using decision trees and logistic regression">
                                        <b>[6]</b>
                                         Dalvi P K,Khandge S K,Deomore A,et al.Analysis of customer churn prediction in telecom industry using decision trees and logistic regression[C]//Proc of 2016 Symposium on Colossal Data Analysis and Networking (CDAN),2016:1-4.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_7" title=" Dulhare U N,Ghori I.An efficient hybrid clustering to predict the risk of customer churn[C]//Proc of 2018 2nd International Conference on Inventive Systems and Control (ICISC),2018:673-677." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient hybrid clustering to predict the risk of customer churn">
                                        <b>[7]</b>
                                         Dulhare U N,Ghori I.An efficient hybrid clustering to predict the risk of customer churn[C]//Proc of 2018 2nd International Conference on Inventive Systems and Control (ICISC),2018:673-677.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_8" title=" Kasiran Z,Ibrahim Z,Ribuan M S M.Mobile phone customers churn prediction using elman and Jordan recurrent neural network[C]//Proc of International Conference on Computing &amp;amp; Convergence Technology,2013:673-678." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mobile phone customers churn prediction using elman and Jordan recurrent neural network">
                                        <b>[8]</b>
                                         Kasiran Z,Ibrahim Z,Ribuan M S M.Mobile phone customers churn prediction using elman and Jordan recurrent neural network[C]//Proc of International Conference on Computing &amp;amp; Convergence Technology,2013:673-678.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_9" title=" Wolpert D H.Stacked generalization[J].Neural Networks,1992,5(2):241-259." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked generalization">
                                        <b>[9]</b>
                                         Wolpert D H.Stacked generalization[J].Neural Networks,1992,5(2):241-259.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_10" title=" www.kesci.com/landing/bdc2018." target="_blank"
                                       href="">
                                        <b>[10]</b>
                                         www.kesci.com/landing/bdc2018.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     Yao Xu,Wang Xiao-dan,Zhang Yu-xi,et al.Summary of feature selection algorithms [J].Control and Decision,2012,27(2):161-166.(in Chinese)</a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_12" title=" Peng Xiao-bing,Zhu Yu-quan.Weighted support vector machine algorithm based on inner-correlations and mutual information of features [J].Computer Science,2018,45(12):182-186.(in Chinese)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201812030&amp;v=MjQ3ODRiN0c0SDluTnJZOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIvQkx6N0I=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Peng Xiao-bing,Zhu Yu-quan.Weighted support vector machine algorithm based on inner-correlations and mutual information of features [J].Computer Science,2018,45(12):182-186.(in Chinese)
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     Cheng Yu-sheng,Li Yu,Wang Yi-bin,et al.Streaming feature selection with weighted fuzzy mutual information based on dynamic sliding window[J].Journal of Nanjing University(Natural Sciences),2018,54(5):974-985.(in Chinese)</a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     Zheng Hong,Li Hai-bin,Lu Xing-jian,et al.A multiple kernel learning approach for air quality prediction[J].Advances in Meteorology,2018,2018:Article ID.3506394.附中文参考文献:</a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_5" title=" 朱志勇,徐长梅,刘志兵,等.基于贝叶斯网络的客户流失分析研究[J].计算机工程与科学,2013,35(3):155-158." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201303031&amp;v=MDM0NDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIvQkx6N0JaYkc0SDlMTXJJOUdaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         朱志勇,徐长梅,刘志兵,等.基于贝叶斯网络的客户流失分析研究[J].计算机工程与科学,2013,35(3):155-158.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_11" title=" 姚旭,王晓丹,张玉玺,等.特征选择方法综述[J].控制与决策,2012,27(2):161-166." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201202002&amp;v=MTQ5NzVxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVci9CTGpmU2JiRzRIOVBNclk5RlpvUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         姚旭,王晓丹,张玉玺,等.特征选择方法综述[J].控制与决策,2012,27(2):161-166.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     彭晓冰,朱玉全.基于特征内相关和互信息的加权SVM算法[J].计算机科学,2018,45(12):182-186.</a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_13" title=" 程玉胜,李雨,王一宾,等.动态滑动窗口加权互信息流特征选择[J].南京大学学报(自然科学版),2018,54(5):974-985." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJDZ201805013&amp;v=MTM5ODhIOW5NcW85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVci9CS3lmUGRMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         程玉胜,李雨,王一宾,等.动态滑动窗口加权互信息流特征选择[J].南京大学学报(自然科学版),2018,54(5):974-985.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(11),2027-2032 DOI:10.3969/j.issn.1007-130X.2019.11.017            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多模型融合的流失用户预测方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8F%B6%E6%88%90&amp;code=40581048&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">叶成</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E7%BA%A2&amp;code=07535132&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑红</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E4%BA%91%E8%BE%89&amp;code=43338818&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程云辉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0024290&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华东理工大学信息科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>准确的用户流失预测能力有助于企业提高用户保持率、增加用户数量和增加盈利。现有的流失用户预测模型大多为单一模型或是多个模型的简单融合,没有充分发挥多模型集成的优势。借鉴了随机森林的Bootstrap Sampling的思想,提出了一种改进的Stacking集成方法,并将该方法应用到了真实数据集上进行流失用户的预测。通过验证集上的实验比较可知,提出的方法在流失用户<i>F</i>1值、召回率和预测准确率3项指标上均好于所有相同结构的经典Stacking集成方法;当采用恰当的集成结构时,其表现可超越基分类器上的最优表现。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Stacking%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Stacking集成学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">用户流失预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bootstrap%20Sampling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bootstrap Sampling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    叶成(1993-),男,宁夏银川人,硕士生,研究方向为形式化建模、服务计算和机器学习。E-mail:cheng_yc17@163.com,通信地址:200237上海市华东理工大学信息科学与工程学院;
                                </span>
                                <span>
                                    *郑红,zhenghong@ecust.edu.cn,通信地址:200237上海市华东理工大学信息科学与工程学院;
                                </span>
                                <span>
                                    程云辉,通信地址:200237上海市华东理工大学信息科学与工程学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61103115,61103172);</span>
                                <span>上海市科委科技创新行动计划高新技术领域项目(16511101000);</span>
                    </p>
            </div>
                    <h1><b>A user churn prediction method based on multi-model fusion</b></h1>
                    <h2>
                    <span>YE Cheng</span>
                    <span>ZHENG Hong</span>
                    <span>CHENG Yun-hui</span>
            </h2>
                    <h2>
                    <span>School of Information Science and Engineering,East China University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Accurate user churn prediction ability facilitates improving user retention rate, increasing user count and increasing profitability. Most of the existing user churn prediction models are single model or simple integration of multiple models, and the advantages of multi-model integration are not fully utilized.This paper draws on the idea of Bootstrap Sampling in random forests, proposes an improved Stacking ensemble method, and applies the method to the real data set to predict the user churn. Through the experimental comparison on the validation set, the proposed method is better than the classical Stacking ensemble method with the same structure in the terms of the <i>F</i>1-score, recall rate and prediction accuracy of user churn. When the appropriate structure is adopted, the performance can surpass the optimal performance on the base classifier.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Stacking%20ensemble%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Stacking ensemble learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=user%20churn%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">user churn prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bootstrap%20Sampling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bootstrap Sampling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YE Cheng,born in 1993,MS candidate,his research interests include formal modeling,service computing,and machine learning.Address:School of Information Science and Engineering,East China University of Science and Technology,Shanghai 200237,P.R. China;
                                </span>
                                <span>
                                    ZHENG Hong,Address:School of Information Science and Engineering,East China University of Science and Technology,Shanghai 200237,P.R. China;
                                </span>
                                <span>
                                    CHENG Yun-hui,Address:School of Information Science and Engineering,East China University of Science and Technology,Shanghai 200237,P.R. China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-06-15</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="42">由于激烈的市场竞争,企业产品之间的差异性越来越小。这种趋势使得企业之间竞争的核心逐渐从以产品为核心到以服务为核心再到以用户为核心。用户是企业盈利的来源,也是公司生存的重要因素<citation id="108" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="43">用户流失可以解释为用户在一段时间内从当前平台转移到其它平台的现象<citation id="109" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。大量的用户流失将会给企业带来巨大的经济损失。及时准确的流失预警信息可以给企业制定用户保留措施以足够的时间。在移动应用领域,随着移动互联时代的到来,手机应用程序、手机游戏等迅速更迭,用户的高流失率更加明显。已有研究表明,吸引1个新用户的成本是维护1个老用户成本的4～5倍<citation id="110" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。另一项研究表明,如果用户保留率提高5%,利润率将提高25%<citation id="111" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。因此,提高用户流失预测的准确率,及时准确地提供用户流失预警信号至关重要。</p>
                </div>
                <div class="p1">
                    <p id="44">国内外学者提出了许多方法来试图提高流失用户预测准确率,如决策树、支持向量机、聚类算法以及人工神经网络等。文献<citation id="112" type="reference">[<a class="sup">5</a>,<a class="sup">5</a>]</citation>采用贝叶斯网络进行流失用户分析,实验结果表明,提出的马尔科夫毯贝叶斯网络模型的分类性能相比于神经网络有一定提高。文献<citation id="113" type="reference">[<a class="sup">6</a>]</citation>同样针对电信行业的用户流失进行研究,提出了利用决策树和Logistic回归预测流失用户的方法。文献<citation id="114" type="reference">[<a class="sup">7</a>]</citation>提出了一种公理模糊集AFS(Axiomatic Fuzzy Set)与并行DBSCAN(Density  Based Spatial  Clustering of Applications with Noise)相结合的混合聚类方法来预测用户。Kasiran等<citation id="115" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>将用户流失现象看做是一个时序问题,用循环神经网络算法对手机端流失用户进行预测。</p>
                </div>
                <div class="p1">
                    <p id="45">现有的流失用户预测模型大多只使用了单一的分类模型,或者是不同模型之间的简单融合,没有进行足够的优化。本文受随机森林的自助采样法(Bootstrap Sampling)启发,提出一种基于自助采样法的Stacking优化集成BS-Stacking(Bootstrap Sampling Stacking)方法,并对最优的分类器组合进行了探究。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>2 Stacking集成学习方法</b></h3>
                <div class="p1">
                    <p id="48">Stacking集成学习方法是Wolpert<citation id="116" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>在1992年提出的一种综合学习方法。它采用特殊的组合策略,与Bagging和Boosting集成方法只可以集成同类算法不同,它可以组合多种不同的分类算法。给定数据集{<i><b>x</b></i><sub><i>i</i></sub>,<i>y</i><sub><i>i</i></sub>} (<i>i</i>= 1,…,<i>n</i>),其中<i><b>x</b></i><sub><i>i</i></sub>是输入空间<b>R</b><sup><i>D</i></sup>中的1个向量,<i>y</i><sub><i>i</i></sub>∈{<i>C</i><sub>1</sub>,<i>C</i><sub>2</sub>,…,<i>C</i><sub><i>k</i></sub>}表示类别标签。Stacking一般包括2阶段任务:(1)基于训练数据训练基分类器(<i>BM</i><sub>1</sub>,<i>BM</i><sub>2</sub>,…,<i>BM</i><sub><i>z</i></sub>);(2)将基分类器的输出(〈<i>y</i>′<sub>(</sub><sub><i>t</i></sub><sub>,1)</sub>,…,<i>y</i>′<sub>(</sub><sub><i>t</i></sub><sub>,</sub><sub><i>n</i></sub><sub>)</sub>〉,<i>t</i>=1,…,<i>z</i>)作为下一层分类器MM(Meta-level Model)的输入,预测步骤与训练一致。本文只研究两层模型,多层模型在实际中使用较少且复杂。图1给出了简单Stacking集成的框架图。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911017_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Stacking集成框架" src="Detail/GetImg?filename=images/JSJK201911017_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Stacking集成框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911017_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Stacking ensemble algorithm framework</p>

                </div>
                <h4 class="anchor-tag" id="49" name="49"><b>2.1 基分类器的改进</b></h4>
                <div class="p1">
                    <p id="50">Stacking通过使用前一阶段预测结果作为特征进行后续训练来获得关于问题空间的更多信息,旨在减少泛化误差,每个基分类器学到得越多,Stacking集成后的模型泛化能力越好。本文主要对图1的虚线框部分进行改进。为了尽可能提升基分类器的分类准确率,受随机森林算法的启发,对每一个基分类器都进行<i>T</i>次拷贝,并使用自助采样法得到的数据子集对基分类器的副本进行训练,该基分类器的最终预测结果由该基分类器的所有副本投票决定。</p>
                </div>
                <div class="p1">
                    <p id="51">基分类器改进算法伪代码如下所示:</p>
                </div>
                <div class="p1">
                    <p id="52"><b>输入</b>:基分类器<i>BM</i><sub><i>i</i></sub>;数据集<i>D</i><sub><i>n</i></sub><sub>×</sub><sub><i>m</i></sub>(其中,<i>n</i>为样本数,<i>m</i>为特征数);最大样本采样比例<i>MS</i>;最大特征采样比例<i>MF</i>。</p>
                </div>
                <div class="p1">
                    <p id="53"><b>输出</b>:基分类器的决策函数。</p>
                </div>
                <div class="p1">
                    <p id="54"><b>Step 1</b> 得到基分类器的<i>T</i>个副本<i>BM</i><sub><i>i</i></sub>={<i>BM</i><sub><i>i</i></sub><sub>1</sub>,<i>BM</i><sub><i>i</i></sub><sub>2</sub>,…,<i>BM</i><sub><i>iT</i></sub>};</p>
                </div>
                <div class="p1">
                    <p id="55"><b>Step 2</b> 对数据集<i>D</i><sub><i>n</i></sub><sub>×</sub><sub><i>m</i></sub>进行<i>T</i>次自助采样,得到<i>T</i>个样本子集<i>D</i><sub><i>i</i></sub>={<i>D</i><sub><i>i</i></sub><sub>1</sub>,<i>D</i><sub><i>i</i></sub><sub>2</sub>,…,<i>D</i><sub><i>iT</i></sub>},其中每个样本子集有<i>MS</i>*<i>n</i>个样本,每个样本有<i>MF</i>*<i>m</i>个特征;</p>
                </div>
                <div class="p1">
                    <p id="56"><b>Step 3</b> 对每个基分类器副本进行训练<i>BM</i><sub><i>it</i></sub>(<i>D</i><sub><i>it</i></sub>),<i>t</i>=1,2,…,<i>T</i>;</p>
                </div>
                <div class="p1">
                    <p id="57"><b>Step 4</b> 若∑<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></msubsup></mrow></math></mathml>Ⅱ(<i>BM</i><sub><i>it</i></sub>(<i>D</i><sub><i>it</i></sub>)=<i>y</i>)&gt;<i>T</i>/2,则进行下一个样本的训练,反之,arg max<sub><i>y</i></sub><sub>∈</sub><sub><i>Y</i></sub>∑<mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></msubsup></mrow></math></mathml>Ⅱ(<i>BM</i><sub><i>it</i></sub>(<i>D</i><sub><i>it</i></sub>)=<i>y</i>),其中<i>y</i>表示样本正确的标签,<i>Y</i>表示样本标签集合。</p>
                </div>
                <div class="p1">
                    <p id="58"><b>Step 5</b> 输出<i>BM</i><sub><i>i</i></sub>。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>2.2 基分类器的组合方式探究</b></h4>
                <div class="p1">
                    <p id="60">基分类器的组合方式同样对集成模型的最终表现有很大影响。对于每个基分类器都按基分类器改进算法的步骤进行训练后,输入测试集中的1个样本(<i><b>x</b></i><sub><i>j</i></sub>,<i>y</i>)(其中<i>y</i>∈<i>Y</i>,<i>Y</i>为标签集合),元分类器得到的输入为<i><b>I</b></i>={<i>y</i>′<sub><i>j</i></sub><sub>,1</sub>,<i>y</i>′<sub><i>j</i></sub><sub>,2</sub>,…,<i>y</i>′<sub><i>j</i></sub><sub>,</sub><sub><i>z</i></sub>}(其中<i>y</i>′<sub><i>j</i></sub><sub>,</sub><sub><i>z</i></sub>∈<i>Y</i>,<i>Y</i>为标签集合)。若元分类器为线性分类器,由线性分类器的一般表达式<i>f</i>(<i><b>I</b></i>)=<i><b>w</b></i><sup>T</sup><i><b>I</b></i>,其中<i><b>w</b></i>为样本权值,由元分类学习得到。从这个意义上来说,线性元分类器的作用是找到最佳的基分类器组合方式,当<i><b>w</b></i>全取1时,Stacking集成方法退化成多分类器的简单投票算法。如果基分类器间差异过小,例如均为线性分类器时,当其中1个分类器对于1个样本进行了错误的分类后,其它相似分类器在此样本上极有可能犯相同的错误,多个基分类器分类错误会误导元分类器,最终对该样本分类错误。当采用非线性分类器作为元分类器时,元分类器与基分类器之间的关系往往会较为复杂。</p>
                </div>
                <div class="p1">
                    <p id="61">假设数据集的形状为(<i>n</i>,<i>m</i>),基分类器个数为<i>z</i>,则所有基分类器的输出组成的数据集形状为(<i>n</i>,<i>z</i>)。一般有<i>z</i>&lt;&lt;<i>m</i>,所形成的新的数据维度会大大减小,训练开销也会小得多。因此在实践中,通常采用人为设计基分类器的组合方式。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>3 数据准备与评价指标</b></h3>
                <h4 class="anchor-tag" id="63" name="63"><b>3.1 问题描述</b></h4>
                <div class="p1">
                    <p id="64">流失用户与活跃用户在时间轴上的活动规律有明显不同。活跃用户有连续的活动记录,而对于有流失倾向的用户在某一时间段后活动频率开始降低甚至不再活动。基于这一特点,我们根据从某1个时间节点开始至此时间节点之后7天内有无活动记录确定用户是否为流失用户。本文设置时间间隔为7天,将在时间节点之后7天内没有活动记录的用户记为流失用户。</p>
                </div>
                <h4 class="anchor-tag" id="65" name="65"><b>3.2 数据集选择和特征提取</b></h4>
                <div class="p1">
                    <p id="66">本文选用的数据集来源于一个竞赛项目<citation id="117" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>公开的部分数据。数据集由4个日志文件构成,主要记录了用户注册信息、应用启动信息、用户互动信息和用户上传视频信息。详细字段有用户<i>ID</i>、注册日期、注册类型、应用启动日期、用户互动日期、活动类型、视频创建日期等。特征提取阶段,主要原则是所提取的特征要有一定的实际意义。特征提取的主要思路有如下3点:</p>
                </div>
                <div class="p1">
                    <p id="67">(1)用户活动时间间隔,如应用启动时间间隔、互动时间间隔、视频上传时间间隔等;</p>
                </div>
                <div class="p1">
                    <p id="68">(2)在最后7天内用户是否有活动记录;</p>
                </div>
                <div class="p1">
                    <p id="69">(3)用户是否是在周末注册。</p>
                </div>
                <div class="p1">
                    <p id="70">某种程度上,用户活动时间间隔是描述用户流失倾向程度的最好特征。时间间隔越长,表示用户活跃程度越弱。针对第(2)项,经过统计发现,用户的活动有一定的黏性,即用户在某一天活动后,接下来几天有很大概率会再次活动,所以用户是否在截止时间节点前的几天内有活动记录也是1个重要特征。在统计用户注册时间与活跃程度时发现,在工作日注册的用户比在周末注册的用户每天平均多活动34.9次。用户注册时间与用户的活动有一定的相关性。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>3.3 特征选择</b></h4>
                <div class="p1">
                    <p id="72">特征选择的主要目的是过滤冗余特征,构造更快、消耗更低的预测模型<citation id="118" type="reference"><link href="25" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">11</a>]</sup></citation>。本文通过计算特征列与标签列的互信息来进行特征提取。互信息的公式为:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>Ι</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">C</mi><mo>,</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>c</mi></munder><mspace width="0.25em" /></mstyle><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mi>p</mi></mstyle><mo stretchy="false">(</mo><mi>c</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mi>log</mi><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>c</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">其中,<i><b>C</b></i>为特征列,<i><b>Y</b></i>为标签列,<i>c</i>和<i>y</i>分别为<i><b>C</b></i>,<i><b>Y</b></i>的分量。<i>p</i>(<i>c</i>,<i>y</i>)为<i>y</i>与<i>c</i>的联合概率密度函数,<i>p</i>(<i>y</i>)和<i>p</i>(<i>c</i>)分别是<i>y</i>和<i>c</i>的边缘概率密度函数。互信息用来度量2个变量之间的相关性。互信息绝对值越大,表示2个变量间的相关性越大<citation id="119" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>。通过分别计算每个特征与标签列的互信息,并按照从大到小排序,按比例选取前<i>N</i>个特征,完成特征选择。特征提取过程中,共提取了170+维特征,按<i>MI</i>值由大到小排列保留前60%的特征。数据集的最终形状为(37446,106)。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>3.4 评价指标</b></h4>
                <div class="p1">
                    <p id="76">模型结果采用流失用户的<i>F</i>1值和预测准确率为评价指标。式(2)～式(4)分别给出了召回率、<i>F</i>1-<i>score</i>和准确率的计算公式:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>F</mi><mn>1</mn><mo>-</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mo>*</mo><mi>Ρ</mi><mo>*</mo><mi>R</mi></mrow><mrow><mo stretchy="false">(</mo><mi>Ρ</mi><mo>+</mo><mi>R</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>a</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo stretchy="false">(</mo><mi>y</mi><mo>,</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mn>Ⅱ</mn></mstyle><mo stretchy="false">(</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">召回率(<i>R</i>)的计算公式中,<i>FN</i>表示被错分的负例数量,<i>TP</i>是正确分类的正例数量。<i>F</i>1-<i>score</i>的计算公式中,<i>P</i>为精确度,<i>P</i>=<i>TP</i>/(<i>TP</i>+<i>FP</i>),其中<i>FP</i>表示被错误分类的正例数量。一般来说,<i>P</i>和<i>R</i>是1对相互矛盾的量,如果1个升高,则另1个就会下降。<i>F</i>1-<i>score</i>是<i>P</i>和<i>R</i>的调和平均值<citation id="120" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。准确率的计算公式中<i>y</i><sub><i>i</i></sub>表示正确的样本标签,<mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>表示对应样本的预测值。</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>4 实验分析</b></h3>
                <h4 class="anchor-tag" id="80" name="80"><b>4.1 基分类器预测得分</b></h4>
                <div class="p1">
                    <p id="81">我们使用1个月的用户活动数据来检验评估本文方法的性能。经过特征提取和特征筛选后,数据集的形状为(37446,106)。为了方便验证模型的效果,数据集按2∶1的比例划分出训练集和验证集。实验过程中选取的基分类器有朴素贝叶斯NB(Naive Bayesian)、随机森林RF(Random Forest)、AB(AdaBoost)、LGBM(LightGBM)、逻辑回归LR(Logistic Regression)和支持向量机SVM(Support Vector Machine)等6种分类模型(由于SVM在高维的数据集上训练时太过耗时,所以此次实验SVM仅作为元分类器使用)。理想的实验结果是改进后的集成方法得分好于简单集成和仅使用单一基分类器时的最好得分。</p>
                </div>
                <div class="p1">
                    <p id="83">表1给出了未进行优化的基分类器在验证集上的流失用户预测的召回率、<i>F</i>1-<i>score</i>和准确率,得分最高的基模型为LGBM。前面说过,集成后的方法得分应高于取得最好得分的基分类器的,所以这里将LGBM的得分定为基础得分,分别为:基础召回率0.842 9,基础<i>F</i>1-<i>score</i> 0.820 7,基础准确率0.812 7。</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit"><b>表1 单一分类器验证集得分</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Performance of single base learner on test set</b></p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td><br /></td><td>NB</td><td>RF</td><td>AB</td><td>LGBM</td><td>LR</td><td>SVM</td></tr><tr><td><br />召回率</td><td>0.889 8</td><td>0.823 8</td><td>0.837 5</td><td>0.842 9</td><td>0.831 9</td><td>—</td></tr><tr><td><br /><i>F</i>1-<i>score</i></td><td>0.806 6</td><td>0.769 1</td><td>0.818 3</td><td>0.820 7</td><td>0.819 0</td><td>—</td></tr><tr><td><br />准确率</td><td>0.783 0</td><td>0.783 2</td><td>0.810 8</td><td>0.812 7</td><td>0.810 8</td><td>—</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>4.2 不同分类器组合的模型得分</b></h4>
                <div class="p1">
                    <p id="86">基分类器的组合方式对于Stacking集成的最终效果有很大的影响,不同的组合方式往往得分会大不相同。我们根据基分类器的不同原理,设计了6种组合方式,如表2所示。其中“●”代表基分类器,“○”代表元分类器。</p>
                </div>
                <div class="area_img" id="87">
                    <p class="img_tit"><b>表2 不同的基分类器组合方式</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Different combinations of base classifiers</b></p>
                    <p class="img_note"></p>
                    <table id="87" border="1"><tr><td><br />组合方式</td><td>NB</td><td>RF</td><td>AB</td><td>LGBM</td><td>LR</td><td>SVM</td></tr><tr><td><br />Type 1</td><td>●</td><td>●</td><td>●</td><td>●</td><td>●</td><td>○</td></tr><tr><td><br />Type 2</td><td>●</td><td>●</td><td>●</td><td>●</td><td>○</td><td></td></tr><tr><td><br />Type 3</td><td>●</td><td>○</td><td>●</td><td>●</td><td>●</td><td></td></tr><tr><td><br />Type 4</td><td></td><td>●</td><td>●</td><td>●</td><td>○</td><td></td></tr><tr><td><br />Type 5</td><td></td><td>●</td><td>●</td><td>●</td><td></td><td>○</td></tr><tr><td><br />Type 6</td><td>●</td><td>●</td><td>○</td><td>●</td><td>●</td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="88">最大样本采样比例<i>MS</i>和最大特征采样比例<i>MF</i>控制着自助采样时样本子集的大小。<i>MS</i>和<i>MF</i>取值过小可能会导致数据集中部分样本无法被取到;取值过大会导致样本子集间的差异性减小。综合考虑下,<i>MS</i>取值定为50%,75%,100%;<i>MF</i>取值定为50%,70%,90%。图2～图4分别给出了表2中6种组合方式的3项指标的对比。横坐标为不同的<i>MS</i>和<i>MF</i>参数取值组合,纵坐标为对应的指标值。横坐标的最后1个点为经典Stacking集成的指标得分。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911017_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 召回率对比" src="Detail/GetImg?filename=images/JSJK201911017_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 召回率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911017_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Comparison ofrecall rate</p>

                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911017_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 F1-score对比" src="Detail/GetImg?filename=images/JSJK201911017_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 <i>F</i>1-<i>score</i>对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911017_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 Comparison of <i>F</i>1-<i>score</i></p>

                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201911017_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 分类准确率对比" src="Detail/GetImg?filename=images/JSJK201911017_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 分类准确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201911017_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 Comparison of classification accuracy rate</p>

                </div>
                <div class="p1">
                    <p id="93">通过比较图2～图4,除Type  3外,其它组合方式的得分接近,且有相同的变化趋势;通过与经典Stacking集成相比,本文方法的表现优于经典Stacking集成方法的。通过比较表3～表5可以发现,Type 3在召回率、<i>F</i>1-<i>score</i>、准确率3项评价指标上均有较好的表现,且较稳定。其它组合方式表现差于基础得分,属于集成后效果变差的情况。</p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表3 不同组合方式的召回率最高得分与基础分的比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Comparison of the highest recall rate with the base recall rate</b></p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td><br />组合方式</td><td>得分比较</td><td>组合方式</td><td>得分比较</td></tr><tr><td><br />Type 1</td><td>-0.008 9</td><td>Type 5</td><td>-0.011 7</td></tr><tr><td><br />Type 2</td><td>-0.013 4</td><td>Type 6</td><td>-0.013 3</td></tr><tr><td><br />Type 3</td><td>+<b>0.001 4</b></td><td>基础召回率</td><td>0.842 9</td></tr><tr><td><br />Type 4</td><td>-0.009 8</td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="92">
                    <p class="img_tit"><b>表4 不同组合方式的</b><i><b>F</b></i><b>1-</b><i><b>score</b></i><b>最高得分与基础分的比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Comparison of the highest </b><i><b>F</b></i><b>1-score with the base </b><i><b>F</b></i><b>1-score</b></p>
                    <p class="img_note"></p>
                    <table id="92" border="1"><tr><td><br />组合方式</td><td>得分比较</td><td>组合方式</td><td>得分比较</td></tr><tr><td><br />Type 1</td><td>-0.005 8</td><td>Type 5</td><td>-0.005 2</td></tr><tr><td><br />Type 2</td><td>-0.006 7</td><td>Type 6</td><td>-0.006 4</td></tr><tr><td><br />Type 3</td><td>+<b>0.001 3</b></td><td>基础<i>F</i>1-<i>score</i></td><td>0.820 7</td></tr><tr><td><br />Type 4</td><td>-0.005 0</td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="94">
                    <p class="img_tit"><b>表5 不同组合方式的准确率最高得分与基础分的比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Comparison of the highest accuracy with the base accuracy</b></p>
                    <p class="img_note"></p>
                    <table id="94" border="1"><tr><td><br />组合方式</td><td>得分比较</td><td>组合方式</td><td>得分比较</td></tr><tr><td><br />Type 1</td><td>-0.004 3</td><td>Type 5</td><td>-0.003 9</td></tr><tr><td><br />Type 2</td><td>-0.005 5</td><td>Type 6</td><td>-0.005 0</td></tr><tr><td><br />Type 3</td><td>+<b>0.001 3</b></td><td>基础准确率</td><td>0.812 7</td></tr><tr><td><br />Type 4</td><td>-0.004 1</td><td></td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="96">经过实验验证,Type 3具有最高的预测准确率和<i>F</i>1-<i>score</i>。为了验证本文方法的有效性,使用长短期记忆网络LSTM(Long Short-Term Memory)和K-means聚类算法在相同的训练集和验证集上训练和验证,并比较验证集得分。表6给出了对比得分。</p>
                </div>
                <div class="area_img" id="97">
                    <p class="img_tit"><b>表6 BS-Stacking与其它模型的比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 6 Comparison of BS-Stacking and other models</b></p>
                    <p class="img_note"></p>
                    <table id="97" border="1"><tr><td><br />分类模型</td><td>召回率</td><td><i>F</i>1-<i>score</i></td><td>准确率</td></tr><tr><td><br />BS-Stacking</td><td>0.844 4</td><td><b>0.822 2</b></td><td><b>0.814 3</b></td></tr><tr><td><br />LSTM</td><td>0.828 5</td><td>0.812 7</td><td>0.805 8</td></tr><tr><td><br />K-means</td><td><b>0.989 8</b></td><td>0.699 4</td><td>0.567 4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="98">通过比较,本文提出的BS-Stacking在<i>F</i>1-<i>score</i>和预测准确率上均好于LSTM和K-means模型的;虽然K-means具有最高的召回率得分,但其<i>F</i>1-<i>score</i>和预测准确率2项指标远低于BS-Stacking的。</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="100">用户流失现象广泛存在,因其涉及的行业广泛,一定程度上造成了预测方法难以通用。本文针对移动应用领域的用户流失现象,提出了一种改进的Stacking集成方法,并在文献<citation id="121" type="reference">[<a class="sup">10</a>]</citation>提供的数据上进行了移动应用的用户流失预测。实验结果表明,本文方法可以准确预测流失用户,且具有较高的预测准确率。基于实验结果,可以得到以下3点结论:</p>
                </div>
                <div class="p1">
                    <p id="101">(1)本文针对移动应用数据集的特征提取方法是有效的;</p>
                </div>
                <div class="p1">
                    <p id="102">(2)本文提出的基分类器改进方法可以有效提高基分类器的分类准确率;</p>
                </div>
                <div class="p1">
                    <p id="103">(3)基分类器和元分类器的选择对于Stacking集成的最终结果有很大影响。</p>
                </div>
                <div class="p1">
                    <p id="104">基分类器的组合方式多种多样,人工设计组合方式费时费力。如何利用算法快速地找到最优的分类器组合将是下一步主要的研究工作。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="126" type="formula" href="images/JSJK201911017_12600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">叶成</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="5">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Customer churn in mobile markets:a comparison of techniques">

                                <b>[1]</b> Hassouna M,Tarhini A,Elyas T,et al.Customer churn in mobile markets:A comparison of techniques[J].International Business Research,2015,8(6):224-237.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analysis and prediction of churn customers for telecommunication industry">

                                <b>[2]</b> Tiwari A,Sam R,Shaikh S.Analysis and prediction of churn customers for telecommunication industry[C]//Proc of 2017 International Conference on I-SMAC (IoT in Social,Mobile,Analytics and Cloud)(I-SMAC),2017:218-222.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Customer relationship management mechanisms:A systematic review of the state of the art literature and recommendations for future research">

                                <b>[3]</b> Soltani Z,Navimipour N J.Customer relationship management mechanisms:A systematic review of the state of the art literature and recommendations for future research[J].Computers in Human Behavior,2016,61:667-688.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Story Behind Successful Customer Relations Management">

                                <b>[4]</b> Gillies C,Rigby D,Reichheld F.The story behind successful customer relations management[J].European Business Journal,2002,14(2):73-77.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 Zhu Zhi-yong,Xu Chang-mei,Liu Zhi-bing,et al.Research of customer churn analysis based on the Bayesian network[J].Computer Engineering &amp; Science,2013,35(3):155-158.(in Chinese)
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analysis of customer churn prediction in telecom industry using decision trees and logistic regression">

                                <b>[6]</b> Dalvi P K,Khandge S K,Deomore A,et al.Analysis of customer churn prediction in telecom industry using decision trees and logistic regression[C]//Proc of 2016 Symposium on Colossal Data Analysis and Networking (CDAN),2016:1-4.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient hybrid clustering to predict the risk of customer churn">

                                <b>[7]</b> Dulhare U N,Ghori I.An efficient hybrid clustering to predict the risk of customer churn[C]//Proc of 2018 2nd International Conference on Inventive Systems and Control (ICISC),2018:673-677.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mobile phone customers churn prediction using elman and Jordan recurrent neural network">

                                <b>[8]</b> Kasiran Z,Ibrahim Z,Ribuan M S M.Mobile phone customers churn prediction using elman and Jordan recurrent neural network[C]//Proc of International Conference on Computing &amp; Convergence Technology,2013:673-678.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked generalization">

                                <b>[9]</b> Wolpert D H.Stacked generalization[J].Neural Networks,1992,5(2):241-259.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_10" target="_blank" href="">

                                <b>[10]</b> www.kesci.com/landing/bdc2018.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 Yao Xu,Wang Xiao-dan,Zhang Yu-xi,et al.Summary of feature selection algorithms [J].Control and Decision,2012,27(2):161-166.(in Chinese)
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201812030&amp;v=MDkxNzdyL0JMejdCYjdHNEg5bk5yWTlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnkvZ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Peng Xiao-bing,Zhu Yu-quan.Weighted support vector machine algorithm based on inner-correlations and mutual information of features [J].Computer Science,2018,45(12):182-186.(in Chinese)
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 Cheng Yu-sheng,Li Yu,Wang Yi-bin,et al.Streaming feature selection with weighted fuzzy mutual information based on dynamic sliding window[J].Journal of Nanjing University(Natural Sciences),2018,54(5):974-985.(in Chinese)
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 Zheng Hong,Li Hai-bin,Lu Xing-jian,et al.A multiple kernel learning approach for air quality prediction[J].Advances in Meteorology,2018,2018:Article ID.3506394.附中文参考文献:
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201303031&amp;v=MTM1Njc0SDlMTXJJOUdaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIvQkx6N0JaYkc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 朱志勇,徐长梅,刘志兵,等.基于贝叶斯网络的客户流失分析研究[J].计算机工程与科学,2013,35(3):155-158.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201202002&amp;v=MTU5MTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeS9nVXIvQkxqZlNiYkc0SDlQTXJZOUZab1E=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 姚旭,王晓丹,张玉玺,等.特征选择方法综述[J].控制与决策,2012,27(2):161-166.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 彭晓冰,朱玉全.基于特征内相关和互信息的加权SVM算法[J].计算机科学,2018,45(12):182-186.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NJDZ201805013&amp;v=MjI1MDhIOW5NcW85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5L2dVci9CS3lmUGRMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 程玉胜,李雨,王一宾,等.动态滑动窗口加权互信息流特征选择[J].南京大学学报(自然科学版),2018,54(5):974-985.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201911017" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201911017&amp;v=MDA1NzdCdEdGckNVUkxPZVplUm1GeS9nVXIvQkx6N0JaYkc0SDlqTnJvOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFQ3cmEvcXIxT0wrTHhvaVdCNFNyZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
