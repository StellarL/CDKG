<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637132371012998750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJSJK201907010%26RESULT%3d1%26SIGN%3dODSq33v2C1fWgzKYuYPaJKuNlR4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JSJK201907010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907010&amp;v=Mjg5OTZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc3SUx6N0JaYkc0SDlqTXFJOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;1 引言&lt;/b&gt; "><b>1 引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="&lt;b&gt;2 相关工作&lt;/b&gt; "><b>2 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="&lt;b&gt;2.1 LBP与SLBP&lt;/b&gt;"><b>2.1 LBP与SLBP</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;2.2 SIFT特征提取&lt;/b&gt;"><b>2.2 SIFT特征提取</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;2.3 LE流形学习&lt;/b&gt;"><b>2.3 LE流形学习</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;2.4 支持向量机&lt;/b&gt;"><b>2.4 支持向量机</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="&lt;b&gt;3 基于流形学习的SAR图像分类算法&lt;/b&gt; "><b>3 基于流形学习的SAR图像分类算法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#131" data-title="&lt;b&gt;4 实验及结果分析&lt;/b&gt; "><b>4 实验及结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#137" data-title="&lt;b&gt;4.1 实验数据&lt;/b&gt;"><b>4.1 实验数据</b></a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;4.2 实验结果及分析&lt;/b&gt;"><b>4.2 实验结果及分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#150" data-title="&lt;b&gt;5 结束语&lt;/b&gt; "><b>5 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="图1 传统LBP与SLBP特征编码">图1 传统LBP与SLBP特征编码</a></li>
                                                <li><a href="#76" data-title="图2 SIFT特征提取流程图">图2 SIFT特征提取流程图</a></li>
                                                <li><a href="#101" data-title="图3 SIFT特征点描述子">图3 SIFT特征点描述子</a></li>
                                                <li><a href="#112" data-title="图4 LE降维效果">图4 LE降维效果</a></li>
                                                <li><a href="#122" data-title="图5 基于流形学习的SAR图像分类算法流程图">图5 基于流形学习的SAR图像分类算法流程图</a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表1 Satellite数据集上的分类精度&lt;/b&gt;"><b>表1 Satellite数据集上的分类精度</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;表2 Satellite数据集上的分类精度混淆矩阵&lt;/b&gt;"><b>表2 Satellite数据集上的分类精度混淆矩阵</b></a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表3 Satellite数据集上的分类时间对比&lt;/b&gt;"><b>表3 Satellite数据集上的分类时间对比</b></a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;表4 NWPU数据集上的分类精度&lt;/b&gt;"><b>表4 NWPU数据集上的分类精度</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;表5 UCMerced数据集上的分类精度&lt;/b&gt;"><b>表5 UCMerced数据集上的分类精度</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="166">


                                    <a id="bibliography_1" title=" Lurie J B, Irvin E M.Remote sensing technology and applications[J].Optical Engineering, 2002, 41 (9) :2075-2076." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Remote sensing technology and applications">
                                        <b>[1]</b>
                                         Lurie J B, Irvin E M.Remote sensing technology and applications[J].Optical Engineering, 2002, 41 (9) :2075-2076.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_2" title=" Ojala T, Pietik&#228;inen M, Harwood D.Performance evaluation of texture measures with classification based on Kullback discrimination of distributions[C]//Proc of the 12th IAPR International Conference on Pattern Recognition (ICPR 1994) , 1994:582-585." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Performance evaluation of texture measures with classification based on Kullback discrimination of distributions">
                                        <b>[2]</b>
                                         Ojala T, Pietik&#228;inen M, Harwood D.Performance evaluation of texture measures with classification based on Kullback discrimination of distributions[C]//Proc of the 12th IAPR International Conference on Pattern Recognition (ICPR 1994) , 1994:582-585.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_3" title=" Lowe D G.Object recognition from local scale-invariant features[C]//Proc of International Conference on Computer Vision, 1999:1150-1157." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object Recognition from Local Scale-Invariant Features">
                                        <b>[3]</b>
                                         Lowe D G.Object recognition from local scale-invariant features[C]//Proc of International Conference on Computer Vision, 1999:1150-1157.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_4" title=" Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjI3OTRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ0RsVmJ6TUlWND1OajdCYXJPNEh0&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_5" title=" Dalal N, Triggs B.Histograms of oriented gradients for human detection[C]//Proc of International Conference on Computer Vision &amp;amp; Pattern Recognition (CVPR’05) , 2005:886-893." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Histograms of Oriented Gradients for Human Detection">
                                        <b>[5]</b>
                                         Dalal N, Triggs B.Histograms of oriented gradients for human detection[C]//Proc of International Conference on Computer Vision &amp;amp; Pattern Recognition (CVPR’05) , 2005:886-893.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_6" title=" Liu Jing, Zhao Feng-yu.Research progress of dimensionality reduction technology on high-dimensional data [J].Electronic Science &amp;amp; Technology, 2018, 31 (3) :36-38. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201803011&amp;v=MTMxNThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bVY3N0lJVGZBWmJHNEg5bk1ySTlFWlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Liu Jing, Zhao Feng-yu.Research progress of dimensionality reduction technology on high-dimensional data [J].Electronic Science &amp;amp; Technology, 2018, 31 (3) :36-38. (in Chinese) 
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_7" title=" Ma Fa-min, Zhang Lin, Wang Jin-biao.Introduction of the dimensionality reduction algorithm[J].Software Engineering, 2017, 20 (8) :7-13. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGC201708003&amp;v=MTY3NTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJUHlyTWJiRzRIOWJNcDQ5Rlo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Ma Fa-min, Zhang Lin, Wang Jin-biao.Introduction of the dimensionality reduction algorithm[J].Software Engineering, 2017, 20 (8) :7-13. (in Chinese) 
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_8" title=" Li Song, Wei Zhong-hao, Zhang Bing-chen, et al.Target recognition using the transfer learning-based deep convolutional neural networks for SAR images [J].Journal of University of Chinese Academy of Sciences, 2018, 35 (1) :76-83. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKYB201801010&amp;v=MDIzODNVUkxPZVplUm1GeTdtVjc3SVB5YlNiTEc0SDluTXJvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Li Song, Wei Zhong-hao, Zhang Bing-chen, et al.Target recognition using the transfer learning-based deep convolutional neural networks for SAR images [J].Journal of University of Chinese Academy of Sciences, 2018, 35 (1) :76-83. (in Chinese) 
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_9" title=" Peng Yi-jin.Manifold learning based SAR image target classification[J].Computer and Digital Engineering, 2017, 45 (12) :2489-2493. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201712035&amp;v=MTYyMjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJTHo3WWFiRzRIOWJOclk5R1lZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Peng Yi-jin.Manifold learning based SAR image target classification[J].Computer and Digital Engineering, 2017, 45 (12) :2489-2493. (in Chinese) 
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_10" title=" Hong Tao.Specific object detection and recognition in optical remote sensing images[D].Chengdu:University of Electronic Science and Technology of China, 2018. (in Chinese) " target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Specific object detection and recognition in optical remote sensing images">
                                        <b>[10]</b>
                                         Hong Tao.Specific object detection and recognition in optical remote sensing images[D].Chengdu:University of Electronic Science and Technology of China, 2018. (in Chinese) 
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_11" title=" Sanchez V D.Advanced support vector machines and kernel methods[J].Neurocomputing, 2003, 55 (1-2) :5-20." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501914228&amp;v=MDIzNThud1plWnVIeWptVUxmSUpsMFFheEk9TmlmT2ZiSzdIdEROcW85RWJlb0xEbjR4b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Sanchez V D.Advanced support vector machines and kernel methods[J].Neurocomputing, 2003, 55 (1-2) :5-20.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_12" title=" Ying Zi-lu, Cai Lin-bo, Liu Zhao-yi.Face recognition with Laplacian eigenmaps on local binary pattern[J].Signal Processing, 2010, 26 (8) :1230-1233. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201008020&amp;v=MjY4MTZWNzdJUFRYSVlMRzRIOUhNcDQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N20=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Ying Zi-lu, Cai Lin-bo, Liu Zhao-yi.Face recognition with Laplacian eigenmaps on local binary pattern[J].Signal Processing, 2010, 26 (8) :1230-1233. (in Chinese) 
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_13" title=" Zhang Wei-kun, Ye Wei, Lao Guo-chao.Research on aircraft target matching classification method based on SIFT feature for SAR image [J].Foreign Electronic Measurement Technology, 2016, 35 (8) :19-21. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWCL201608005&amp;v=MjAzNTZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc3SUlqcklZckc0SDlmTXA0OUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Zhang Wei-kun, Ye Wei, Lao Guo-chao.Research on aircraft target matching classification method based on SIFT feature for SAR image [J].Foreign Electronic Measurement Technology, 2016, 35 (8) :19-21. (in Chinese) 
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     Yang Shi-pei, Chen Jie, Zhou Li, et al.Image feature matching method based on SIFT [J].Electronic Measurement Technology, 2014, 37 (6) :50-53. (in Chinese) </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_15" title=" Shen Jie, Ji Chun-mei, Wang Zheng-qun, et al.Face recognition based on supervised Laplacian eigenmap algorithm[J].Journal of Yancheng Institute of Technology (Natural Science Edition) , 2016, 29 (4) :16-20. (in Chinese) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YCGZ201604005&amp;v=MDU1NjdlWmVSbUZ5N21WNzdJUEM3TWRMRzRIOWZNcTQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Shen Jie, Ji Chun-mei, Wang Zheng-qun, et al.Face recognition based on supervised Laplacian eigenmap algorithm[J].Journal of Yancheng Institute of Technology (Natural Science Edition) , 2016, 29 (4) :16-20. (in Chinese) 
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_16" title=" Tu Shang-tan, Chen Jia-yu, Yang Wen, et al.Laplacian eigenmaps-based polarimetric dimensionality reduction for SAR image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2012, 50 (1) :170-179." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Laplacian eigenmaps-based polarimetric dimensionality reduction for SAR image classification">
                                        <b>[16]</b>
                                         Tu Shang-tan, Chen Jia-yu, Yang Wen, et al.Laplacian eigenmaps-based polarimetric dimensionality reduction for SAR image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2012, 50 (1) :170-179.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     Niu Xin, Dou Yong, Zhang Peng, et al.Airport and flight recognition on optical remote sensing data by deep learning[J].Big Data Research, 2016, 2 (5) :54-67. (in Chinese) </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     Ji Xiao-fei, Qin Ning-li.Design and implementation of multi-target detection and recognition algorithm for optical remote sensing image[J].Journal of Computer Applications, 2015, 35 (11) :3302-3307. (in Chinese) </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     刘靖, 赵逢禹.高维数据降维技术及研究进展[J].电子科技, 2018, 31 (3) :36-38.</a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     马发民, 张林, 王锦彪.维数约简算法简述[J].软件工程, 2017, 20 (8) :7-13.</a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     李松, 魏中浩, 张冰尘, 等.深度卷积神经网络在迁移学习模式下的SAR目标识别[J].中国科学院大学学报, 2018, 35 (1) :76-83.</a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     彭易锦.基于流形学习的SAR图像目标分类[J].计算机与数字工程, 2017, 45 (12) :2489-2493.</a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_10" title=" 洪韬.基于光学遥感影像的特定目标检测及识别[D].成都:电子科技大学, 2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018991422.nh&amp;v=Mjk1NDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc3SVZGMjZGcnF4SDlYT3JaRWJQSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         洪韬.基于光学遥感影像的特定目标检测及识别[D].成都:电子科技大学, 2018.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     应自炉, 蔡淋波, 刘召义.基于LBP的拉普拉斯特征映射人脸识别[J].信号处理, 2010, 26 (8) :1230-1233.</a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     张维坤, 叶伟, 劳国超.基于SIFT特征的SAR图像飞机目标匹配分类方法研究[J].国外电子测量技术, 2016, 35 (8) :19-21.</a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_14" title=" 杨世沛, 陈杰, 周莉, 等.一种基于SIFT的图像特征匹配方法[J].电子测量技术, 2014, 37 (6) :50-53." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201406013&amp;v=MTA2Mzc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJSVRmSVlyRzRIOVhNcVk5RVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         杨世沛, 陈杰, 周莉, 等.一种基于SIFT的图像特征匹配方法[J].电子测量技术, 2014, 37 (6) :50-53.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     沈杰, 嵇春梅, 王正群, 等.基于监督拉普拉斯特征映射算法的人脸识别[J].盐城工学院学报 (自然科学版) , 2016, 29 (4) :16-20.</a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_17" title=" 牛新, 窦勇, 张鹏, 等.基于深度学习的光学遥感机场与飞行器目标识别技术[J].大数据, 2016, 2 (5) :54-67." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSJU201605007&amp;v=MTQ2Mzg3SUlUN0JlN0c0SDlmTXFvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         牛新, 窦勇, 张鹏, 等.基于深度学习的光学遥感机场与飞行器目标识别技术[J].大数据, 2016, 2 (5) :54-67.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_18" title=" 姬晓飞, 秦宁丽.光学遥感图像多目标检测及识别算法设计与实现[J].计算机应用, 2015, 35 (11) :3302-3307." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201511061&amp;v=MjE5NzNvOURaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc3SUx6N0JkN0c0SDlUTnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         姬晓飞, 秦宁丽.光学遥感图像多目标检测及识别算法设计与实现[J].计算机应用, 2015, 35 (11) :3302-3307.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JSJK" target="_blank">计算机工程与科学</a>
                2019,41(07),1212-1219 DOI:10.3969/j.issn.1007-130X.2019.07.010            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于流形学习的光学遥感图像分类</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">王云艳</a>
                                <a href="javascript:;">罗冷坤</a>
                                <a href="javascript:;">王重阳</a>
                </h2>
                    <h2>

                    <span>湖北工业大学电气与电子工程学院</span>
                    <span>太阳能高效利用及储能运行控制湖北省重点实验室</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着光学遥感图像技术的快速发展与广泛应用, 对光学遥感图像的准确分类具有深远的研究意义。传统特征提取方式提取的高维特征中夹杂着许多冗余信息, 分类过程可能导致过拟合现象, 针对传统的线性降维算法不足以保持原始数据的内部结构, 容易造成数据失真这一问题, 提出基于流形学习的光学遥感图像分类算法。该算法首先提取出图像的SIFT特征, 然后将流形学习运用于特征降维, 最后结合支持向量机进行训练和识别。实验结果表明, 在Satellite、NWPU和UCMerced实验数据中, 冰川、建筑群和海滩分类精度得到了有效提高, 达到85%左右;针对沙漠、岩石、水域等特殊环境遥感图像, 分类精度提高了10%左右。总而言之, 基于流形学习的分类算法对通过降维之后的数据能够保持在原高维空间中的拓扑结构, 相似特征点能得到有效聚合, 预防了“维数灾难”, 减少了计算量, 保证了分类精度。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">流形学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王云艳 (1981-) , 女, 湖北武汉人, 博士, 副教授, 研究方向为模式识别和SAR图像处理。E-mail:510496148@qq.com通信地址:430068湖北省武汉市湖北工业大学电气与电子工程学院;
                                </span>
                                <span>
                                    罗冷坤 (1995-) , 男, 湖北武汉人, 硕士生, 研究方向为模式识别和SAR图像处理。E-mail:1051369814@qq.com通信地址:430068湖北省武汉市湖北工业大学电气与电子工程学院;
                                </span>
                                <span>
                                    王重阳 (1996-) , 男, 河南驻马店人, 硕士生, 研究方向为模式识别和SAR图像处理。E-mail:819133912@qq.com通信地址:430068湖北省武汉市湖北工业大学电气与电子工程学院;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (41601394);</span>
                                <span>湖北工业大学博士启动基金 (BSQD2016010);</span>
                    </p>
            </div>
                    <h1><b>Optical remote sensing image classification based on manifold learning</b></h1>
                    <h2>
                    <span>WANG Yun-yan</span>
                    <span>LUO Leng-kun</span>
                    <span>WANG Chong-yang</span>
            </h2>
                    <h2>
                    <span>School of Electrical and Electronic Engineering, Hubei University of Technology</span>
                    <span>Key Laboratory of Solar Energy Efficient Utilization and Energy Storage Operation Control in Hubei Province</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the rapid development and wide application of optical remote sensing image technology, accurate classification of optical remote sensing images has far-reaching research significance. The high-dimensional features extracted by traditional feature extraction methods are mixed with much redundant information, and the classification process can lead to over-fitting. The traditional linear dimension reduction algorithm cannot maintain the internal structure of the original data, and is easy to cause data distortion. We propose an optical remote sensing image classification algorithm based on manifold learning. Firstly, the SIFT features of the image are extracted, and the manifold learning is applied to feature dimension reduction. Finally, the support vector machine is used for training and recognition. Experimental results show that the classification accuracy of glaciers, buildings and beaches is effectively improved on the experimental data of Satellite, NWPU and UC Merced, reaching about 85%. For remote sensing images of desert, rock and water, the classification accuracy is improved by about 10%. In summary, the data based on manifold learning can maintain the topological structure in the original high-dimensional space through the dimension reduction algorithm. Similar feature points can effectively aggregate, which prevents the "dimensional disaster", reduces the calculation amount and guarantees classification accuracy.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=manifold%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">manifold learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=remote%20sensing%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">remote sensing image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=support%20vector%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">support vector machine;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WANG Yun-yan, born in 1981, PhD, associate professor, her research interests include pattern recognition, and SAR image processing.Address:School of Electrical and Electronic Engineering, Hubei University of Technology, Wuhan 430068, Hubei, P.R.China;
                                </span>
                                <span>
                                    LUO Leng-kun, born in 1995, MS candidate, his research interests include pattern recognition, and SAR image processing.Address:School of Electrical and Electronic Engineering, Hubei University of Technology, Wuhan 430068, Hubei, P.R.China;
                                </span>
                                <span>
                                    WANG Chong-yang, born in 1996, MS candidate, his research interests include pattern recognition, and SAR image processing.Address:School of Electrical and Electronic Engineering, Hubei University of Technology, Wuhan 430068, Hubei, P.R.China;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-12</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="61" name="61" class="anchor-tag"><b>1 引言</b></h3>
                <div class="p1">
                    <p id="62">光学遥感技术 (Optical Remote Sensing Technology) <citation id="224" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>在城市规划、军事侦察、资源勘探以及农业生产等众多领域扮演着越来越重要的角色, 受到各国研究人员的广泛关注。它不受光照和气候条件的限制, 具有全天时工作、覆盖范围广的特点, 成像的分辨率也在不断提高。在不断发展的遥感图像处理领域, 研究光学遥感图像的有效分类具有十分重要的意义。</p>
                </div>
                <div class="p1">
                    <p id="63">根据图像中提取的特征来分类是目前最常用的方法, 主要的特征包括图像的纹理特征、形状特征和灰度特征等。Ojala等<citation id="225" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>于1996年提出的原始局部二值模式LBP (Local Binary Patterns) 、Lowe<citation id="227" type="reference"><link href="170" rel="bibliography" /><link href="172" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>于1999年提出、2004年完善总结的尺度不变特征变换SIFT (Scale-Invariant Feature Transform) 以及Dalal等<citation id="226" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>于2005年提出的方向梯度直方图HOG (Histogram of Oriented Gradient) 特征等都可以提取出图像的底层特征。许多图像特征易受到光照、噪声以及自身的旋转、缩放的影响。相比之下, SIFT特征是图像的局部特征, 对平移、转动、亮度和尺度变换等具有不变性, 同时对噪声也能保持一定的稳定性, 是一种非常可靠的特征, 有着非常广泛的应用。因此, 针对光学遥感图像中的显著性不够明显的地物类别, 选用SIFT特征来作为分类依据, 能有效提高分类精度。</p>
                </div>
                <div class="p1">
                    <p id="64">由于通常底层特征的维数较高, 存在很多冗余和不相干的特征, 大大增加了计算量, 甚至会出现“维数灾难”<citation id="228" type="reference"><link href="176" rel="bibliography" /><link href="202" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">6</a>]</sup></citation>。为了解决这一系列问题, 将高维特征映射到低维空间中是非常值得研究的问题。主成分分析PCA (Principal Component Analysis) 、线性判别分析LDA (Linear Discriminant Analysis) 是常用的线性降维算法;而局部线性嵌入LLE (Locally Linear Embedding) 、拉普拉斯特征映射LE (Laplacian Eigenmaps) 和等距映射 (Isomap) 等是非线性流形降维算法<citation id="229" type="reference"><link href="178" rel="bibliography" /><link href="204" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">7</a>]</sup></citation>, 这些算法都可以将图像特征从<i>D</i>维降低到<i>d</i>维 (<i>d</i>&lt;<i>D</i>) 。其中, 线性降维需要处理的数据之间的关系是线性的, 否则不能很好地保持数据间的结构, 容易出现错误的投影, 使原始数据的信息失真;而非线性的流形学习算法可使降维后的数据保持原来的拓扑结构, 可有效地克服线性降维算法的不足, 完成非线性数据的降维。</p>
                </div>
                <div class="p1">
                    <p id="65">本文针对上述光学遥感图像分类中的一系列问题<citation id="231" type="reference"><link href="180" rel="bibliography" /><link href="182" rel="bibliography" /><link href="184" rel="bibliography" /><link href="206" rel="bibliography" /><link href="208" rel="bibliography" /><link href="210" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 提出了一种基于流形学习的光学遥感图像分类算法, 将流形学习算法融入图像分类中。首先提取光学遥感图像的底层SIFT特征, 然后利用非线性流形学习降维来优化特征向量, 最后结合支持向量机SVM (Support Vector Machine) <citation id="230" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>进行训练和测试。该算法在减少计算量的同时有效地保持了原始数据的流形结构, 一定程度上提高了分类精度。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag"><b>2 相关工作</b></h3>
                <h4 class="anchor-tag" id="67" name="67"><b>2.1 LBP与SLBP</b></h4>
                <div class="p1">
                    <p id="68">本文引入了几组不同的实验做对比, 如图1所示为传统的LBP特征提取编码方式与改进型SLBP (Super Local Binary Patterns) 编码方式。</p>
                </div>
                <div class="p1">
                    <p id="69">传统LBP特征编码方式, 以图像中的像素点为中心取3*3的窗口, 将相邻的8个点与中心点相比较, 若大于中心点像素值标记为1, 否则标记为0。这样相邻的8个点就可产生1个8位二进制数, 即表示该中心点的LBP特征值, 图1中所示的中心点的LBP特征值为 (01101101) <sub>2</sub>=109。将图像划为若干个小cell, 计算每个cell的LBP特征直方图, 然后将每个cell的直方图连接起来就可得到整幅图的LBP特征向量<citation id="232" type="reference"><link href="188" rel="bibliography" /><link href="212" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 传统LBP与SLBP特征编码" src="Detail/GetImg?filename=images/JSJK201907010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 传统LBP与SLBP特征编码  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 1 Traditional LBP and SLBP feature coding</p>

                </div>
                <div class="p1">
                    <p id="71">SLBP为改进型的LBP, SLBP使用 3*3窗口内9个点像素值中的最大值与最小值的平均值作为阈值, 所以图1中SLBP算子的阈值为 (20+234) ÷2=127。然后将窗口内的9个点与阈值相比, 得到1个9位二进制数, 即为该中心点的SLBP特征值。如图1所示的中心点的SLBP特征值为 (001011010) <sub>2</sub>=2+8+16+64=90。</p>
                </div>
                <div class="p1">
                    <p id="72">相比传统的LBP特征编码方式, 针对编码过程中特征块中心位置信息编码缺失问题, SLBP编码方式能有效地填补中心缺乏信息, 使特征信息相对完善, 现实中通过多组数据的分类测试表明, 使用SLBP编码方式能够提高5%左右的分类精度。</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>2.2 SIFT特征提取</b></h4>
                <div class="p1">
                    <p id="74">尺度不变特征转换, 即SIFT特征提取算法<citation id="233" type="reference"><link href="190" rel="bibliography" /><link href="192" rel="bibliography" /><link href="214" rel="bibliography" /><link href="216" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。该算法的流程图如图2所示, 简单来讲可以分为2大部分:首先在样本空间中确定特征点所在位置;其次是根据特征点以及周围区域生成描述算子, 用以描述特征点。首先通过图像与高斯函数卷积来建立高斯金字塔, 二维图像尺度空间的定义如式 (1) 所示:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>G</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>*</mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907010_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SIFT特征提取流程图" src="Detail/GetImg?filename=images/JSJK201907010_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 SIFT特征提取流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907010_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 2 Flow chart of SIFT feature extraction</p>

                </div>
                <div class="p1">
                    <p id="77">其中, <i>G</i><sub><i>i</i></sub> (<i>x</i>, <i>y</i>, <i>σ</i>) 是高斯函数, <i>x</i>、<i>y</i>代表图像中某一像素点的坐标值, <i>σ</i>决定图像的尺度。将原图长宽扩大1倍, 面积变为原先的4倍, 并将其作为高斯金字塔的最底层。自底层向上, 每组图像的长宽依次缩小1倍, 大小变为原先的1/4, 同时高斯函数与每层图像卷积的<i>σ</i>值依次扩大<i>k</i>倍, 即可构建高斯金字塔。然后, 由高斯金字塔的第1组第2层减第1组第1层得到差分金字塔的第1组第1层。以此类推, 可生成一个差分金字塔, 用函数<i>F</i><sub><i>i</i></sub> (<i>x</i>, <i>y</i>, <i>σ</i>) 表示, 定义如式 (2) 所示:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>L</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>k</mi><mi>σ</mi><mo stretchy="false">) </mo><mo>-</mo><mi>L</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">2.2.1 获取精确特征点</h4>
                <div class="p1">
                    <p id="80">将每个采样点与26个相邻点进行比较 (包含不同层) , 若为相邻点中的极大值或极小值, 初步可以认定为特征点。考虑到采样的过程是离散采样, 非真正极值点需要舍去。获取精确特征点具体步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="81"><b>步骤1</b> 消除虚假极值。</p>
                </div>
                <div class="p1">
                    <p id="82">将空间尺度函数进行泰勒展开, 如式 (3) 所示:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">F</mi><mo>+</mo><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">F</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">X</mi></mrow></mfrac><mi mathvariant="bold-italic">X</mi><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi mathvariant="bold-italic">F</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi mathvariant="bold-italic">X</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">其中, <b><i>X</i></b>表示特征点矩阵, <b><i>F</i></b>代表向量。</p>
                </div>
                <div class="p1">
                    <p id="85">对式 (3) 进行求导并使方程等于0, 得到<b><i>X</i></b>的值如式 (4) 所示, 并将其代入<i>F</i> (<b><i>X</i></b>) , 得到结果如式 (5) 所示, 并根据结果去掉对比度较低的特征点。</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>˜</mo></mover><mo>=</mo><mo>-</mo><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi mathvariant="bold-italic">F</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>*</mo><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">F</mi></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">X</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>F</mi><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>˜</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold-italic">F</mi><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mspace width="0.25em" /><mfrac><mrow><mo>∂</mo><mi mathvariant="bold-italic">F</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mrow><mrow><mo>∂</mo><mi mathvariant="bold-italic">X</mi></mrow></mfrac><mo>*</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>˜</mo></mover><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">经过多次实验测试得到最优结果, 保存|<i>F</i> (<b><i>X</i></b>) |≥0.03的采样点为特征点, 消除虚假极值点的效果最好。</p>
                </div>
                <div class="p1">
                    <p id="88"><b>步骤2</b> 消除边缘响应。</p>
                </div>
                <div class="p1">
                    <p id="89">边缘梯度方向的主曲率值较大, 因此边缘上的特征点会有过强的响应, 从而会出现边缘效应过强的现象。对于边缘效应过强的特征点, 利用主曲率比值来判断是否需要舍弃。通过海森矩阵来求出特征点处的主曲率, 滤除主曲率比值大于一定阈值的点, 能够消除边缘响应。</p>
                </div>
                <div class="p1">
                    <p id="90">令海森矩阵为<b><i>Hs</i></b>, </p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Η</mi><mi mathvariant="bold-italic">s</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>X</mi></mrow></msub></mtd><mtd><mi>F</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>Y</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>Y</mi></mrow></msub></mtd><mtd><mi>F</mi><msub><mrow></mrow><mrow><mi>Y</mi><mi>Y</mi></mrow></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">其中, <i>F</i><sub><i>XX</i></sub>、<i>F</i><sub><i>XY</i></sub>、<i>F</i><sub><i>YY</i></sub>为各个方向上的偏导数, 令<i>F</i><sub><i>XX</i></sub>=<i>a</i>, <i>F</i><sub><i>YY</i></sub>=<i>b</i>, <i>F</i><sub><i>XX</i></sub>=<i>x</i>*<i>F</i><sub><i>YY</i></sub>。设Trace (<b><i>Hs</i></b>) 为海森矩阵的迹, |<b><i>Hs</i></b>|为海森矩阵的行列式, 则定义<i>S</i>为:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>S</mi><mo>=</mo><mfrac><mrow><mtext>Τ</mtext><mtext>r</mtext><mtext>a</mtext><mtext>c</mtext><mtext>e</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><mi mathvariant="bold-italic">s</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Η</mi><mi mathvariant="bold-italic">s</mi><mo stretchy="false">|</mo></mrow></mfrac><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>F</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>X</mi></mrow></msub><mo>+</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>Y</mi><mi>Y</mi></mrow></msub></mrow><mrow><mi>F</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>X</mi></mrow></msub><mi>F</mi><msub><mrow></mrow><mrow><mi>Y</mi><mi>Y</mi></mrow></msub><mo>-</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>Y</mi></mrow></msub><mi>F</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>Y</mi></mrow></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>a</mi><mo>*</mo><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mi>x</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">其中, <i>a</i>、<i>b</i>为设定的未知数, <i>S</i>为判定指标。<b><i>F</i></b>的主曲率和<b><i>Hs</i></b>的特征值成正比, <i>S</i>在<i>a</i>=<i>b</i>时最小, <i>S</i>越大特征值之间的比值也就越大。本文能够通过去除主曲率比值大于一定阈值的点来减弱边缘效应, 主曲率比值取值问题转化为求<i>S</i>值问题, <i>S</i>&lt; (<i>x</i>+1) <sup>2</sup>/<i>x</i>时保留特征点, 否则滤除特征点, 经过多组实验测试得知, 在<i>x</i>=10时消除边缘效应的效果最好。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95">2.2.2 为特征点添加描述信息</h4>
                <div class="p1">
                    <p id="96">为特征点添加描述信息分为计算特征点方向、生成特征点描述子2个步骤, 具体步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="97"><b>步骤1</b> 计算特征点方向。利用特征点邻域像素方向分布特性, 为每个特征点指定方向参数, 从而使描述子对图像具有旋转不变性。</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>h</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>θ</mi><mo>=</mo><mi>tan</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo>[</mo><mrow><mfrac><mrow><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>i</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">利用式 (7) 和式 (8) 求出像素点的梯度幅值以及方向, 利用特征点以及周围样本点统计方向直方图, 直方图中的最大值是特征点的主方向。根据 Lowe<citation id="234" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出的特征点信息描述观点, 本文选取大于0.8倍最大值的峰值的方向作为辅助方向。</p>
                </div>
                <div class="p1">
                    <p id="100"><b>步骤2</b> 生成特征点描述子。在完成特征点的计算后得到了特征点的位置等信息, 可以通过一组向量来完成特征点的描述。描述子包含特征点以及影响特征点的邻域点。将特征点周围区域划分为独立区域, 大小不固定, 计算块内梯度直方图, 生成具有独特性的向量。Lowe的实验结果表明:描述子采用4*4*8=128维向量时效果最好。描述子确定过程如下所示: (1) 确定计算描述子所需的图像区域半径; (2) 将坐标轴<i>x</i>方向移至特征点主方向; (3) 对图像半径区域内所有样本点求梯度幅值与方向, 如图3所示。</p>
                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907010_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 SIFT特征点描述子" src="Detail/GetImg?filename=images/JSJK201907010_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 SIFT特征点描述子  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907010_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 3 SIFT feature point descriptor</p>

                </div>
                <h4 class="anchor-tag" id="102" name="102"><b>2.3 LE流形学习</b></h4>
                <div class="p1">
                    <p id="103">拉普拉斯特征映射LE是从局部处理数据, 其基本思想是希望相似度较高的样本点在降维后的空间里距离较近<citation id="235" type="reference"><link href="194" rel="bibliography" /><link href="196" rel="bibliography" /><link href="218" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">15</a>]</sup></citation>。其实现步骤如下所示:</p>
                </div>
                <div class="p1">
                    <p id="104"><b>步骤1</b> 构造近邻图。首先连接样本点, 连接每个点最近的<i>k</i>个点。<i>k</i>值是事先设定的。</p>
                </div>
                <div class="p1">
                    <p id="105"><b>步骤2</b> 利用热核函数来确定相邻点之间权重, 其表达式如式 (9) 所示:</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>=</mo><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mi>t</mi></mfrac></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">其中, <b><i>x</i></b><sub>1</sub>与<b><i>x</i></b><sub>2</sub>为相邻点, <i>t</i>为热核宽度。此外可以采用默认设定权重值, <b><i>x</i></b><sub>1</sub>与<b><i>x</i></b><sub>2</sub>两点不连接时权重值设为1, <b><i>x</i></b><sub>1</sub>与<b><i>x</i></b><sub>2</sub>两点相连时权重值设为0。</p>
                </div>
                <div class="p1">
                    <p id="108"><b>步骤3</b> 使相似的样本点在降维后的空间中距离较近。首先构建优化目标函数<i>f</i> (<i>x</i>) , 如式 (10) 所示:</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi mathvariant="bold-italic">a</mi><mo>, </mo><mi mathvariant="bold-italic">b</mi></mrow></msub><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi mathvariant="bold-italic">a</mi></msub><mo>-</mo><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi mathvariant="bold-italic">b</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mi>W</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">其中, <b><i>y</i></b><sub><b><i>a</i></b></sub>、<b><i>y</i></b><sub><b><i>b</i></b></sub>分别是特征点<b><i>a</i></b>、<b><i>b</i></b>在<i>m</i>维空间中的列向量;权重值<i>weight</i>可由步骤2得到。</p>
                </div>
                <div class="p1">
                    <p id="111">其次计算图拉普拉斯矩阵<b><i>L</i></b>的特征向量<b><i>Y</i></b>与特征值<i>λ</i>:<b><i>LY</i></b>=<i>λ</i><b><i>DY</i></b>, 拉普拉斯矩阵<b><i>L</i></b>= <b><i>D</i></b>-<b><i>W</i></b><sub>adj</sub>, <b><i>D</i></b>为图的度矩阵, <b><i>W</i></b><sub>adj</sub>为图的邻接矩阵。对图拉普拉斯矩阵进行特征值分解, 使用最小的<i>m</i>个特征值 (非零) 对应的特征向量作为降维后的结果<citation id="236" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。降维效果如图4所示。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907010_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 LE降维效果" src="Detail/GetImg?filename=images/JSJK201907010_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 LE降维效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907010_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 4 LE dimension reduction effect</p>

                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>2.4 支持向量机</b></h4>
                <div class="p1">
                    <p id="114">支持向量机SVM, 通俗来讲, 是一种二类分类模型, 其基本模型定义为特征空间上的间隔最大的线性分类器, 其学习策略便是间隔最大化, 最终可转化为一个凸二次规划问题的求解。经典求解方法为Lagrange乘子法, 如式 (11) 所示:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mo>, </mo><mi>c</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">W</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">{</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mo>〈</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">W</mi><mo>〉</mo><mo>+</mo><mi>d</mi><mo stretchy="false">) </mo><mo>-</mo><mn>1</mn><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">其中, <b><i>W</i></b>为系数向量, <i>d</i>为常数。</p>
                </div>
                <div class="p1">
                    <p id="117">对<b><i>W</i></b>和<i>d</i>求偏导得到式 (12) :</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>max</mi><mspace width="0.25em" /><mi mathvariant="bold-italic">Η</mi><mo stretchy="false"> (</mo><mi>c</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>c</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mspace width="0.25em" /></mstyle><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mi>c</mi><msub><mrow></mrow><mi>j</mi></msub><mo>〈</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>j</mi></msub><mo>〉</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="119">求解该方程得到向量<b><i>W</i></b><sup>*</sup>, 结果如式 (13) 所示:</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>*</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">其中, <i>y</i><sub><i>i</i></sub>、<i>y</i><sub><i>j</i></sub>表示第<i>i</i>、<i>j</i>点的纵坐标, <i>c</i><sub><i>i</i></sub>、<i>c</i><sub><i>j</i></sub>表示第<i>i</i>、<i>j</i>点的偏移量, <b><i>X</i></b><sub><i>i</i></sub>和<b><i>X</i></b><sub><i>j</i></sub>为图像特征像素点, <b><i>H</i></b> (<i>c</i>) 为得到的判别矩阵。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JSJK201907010_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于流形学习的SAR图像分类算法流程图" src="Detail/GetImg?filename=images/JSJK201907010_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 基于流形学习的SAR图像分类算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JSJK201907010_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Figure 5 Flow chart of the SAR image classification algorithm based on manifold learning</p>

                </div>
                <div class="p1">
                    <p id="123">求解最优<i>c</i><sup>*</sup> 、<i>d</i><sup>*</sup>值以及最优判别函数。最优<i>c</i><sup>*</sup>由约束条件式 (14) 所确定, <i>c</i><sup>*</sup>和<b><i>W</i></b><sup>*</sup>可由二次规划算法求得, 然后选取一个支持向量<b><i>X</i></b><sub><i>i</i></sub>, 可求得<i>d</i><sup>*</sup>的值, 如式 (15) 所示, 最终得到最优判别函数如式 (16) 所示。</p>
                </div>
                <div class="p1">
                    <p id="124" class="code-formula">
                        <mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>c</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">[</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mo>〈</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mo>*</mo></msup><mo>⋅</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>〉</mo><mo>+</mo><mi>d</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">) </mo><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo stretchy="false">]</mo><mo>=</mo><mn>0</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>d</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mo>〈</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mo>*</mo></msup><mo>⋅</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>〉</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">X</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>*</mo><mo>〈</mo><mi mathvariant="bold-italic">X</mi><mo>⋅</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>〉</mo><mo>+</mo><mi>d</mi><msup><mrow></mrow><mo>*</mo></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="125">其中, <b><i>W</i></b><sup>*</sup>为求导后的矩阵, <i>c</i><sup>*</sup>为最优偏移量, <i>d</i><sup>*</sup>为求得的最优矫正值。</p>
                </div>
                <div class="p1">
                    <p id="126">针对数据集在低维平面难以找到相应的分类超平面, 本文引入核函数来将数据转换到高维平面, 有利于找到更加有效的分类面。</p>
                </div>
                <h3 id="127" name="127" class="anchor-tag"><b>3 基于流形学习的SAR图像分类算法</b></h3>
                <div class="p1">
                    <p id="128">基于流形学习的<i>SAR</i>图像分类算法流程如图5所示。本文将<i>SIFT</i>特征提取算法与流形学习方法相结合对图像进行处理, 算法主要分为3个步骤。首先提取图像<i>SIFT</i>特征, 然后利用<i>LE</i>流形学习降低样本的高维特征, 最后通过训练样本集训练<i>SVM</i>分类器。</p>
                </div>
                <div class="p1">
                    <p id="129"><i>SIFT</i>算法实现的具体过程如下所示:首先检测图像中的特征点, 经过筛选排除掉虚假极值点以及消除边缘效应之后得到准确的关键点, 最后利用关键点周围区域生成128维向量描述子。利用<i>SIFT</i>算法提取的特征有以下优点:除了对缩放、旋转保持不变性外, 同时可以减轻光照影响, 拥有良好的鉴别性。<i>SIFT</i>算法提取特征之后仍然会出现维数过高、数据量过大难以处理的问题, 对此使用流形学习方法进行降维, 在降低数据维度的同时尽可能地减少图像信息的丢失。本文采用拉普拉斯特征映射 (<i>LE</i>) 算法进行降维, 拉普拉斯特征映射从局部的角度处理数据, 通过构建相似关系图来重构数据流形的局部结构特征, 使相似度较高的两个样本点在降维后的空间中距离较近。拉普拉斯特征映射降维后的低维数据仍然能够完好地保留原先的拓扑关系。对于降维后的数据利用<i>SVM</i>进行分类, 避免了维数灾难的问题, 有效地解决了数据冗余的问题, 且具有良好的鲁棒性。</p>
                </div>
                <div class="p1">
                    <p id="130">本文结合<i>SIFT</i>特征提取算法和流行学习方法, 并使用支持向量机对处理后的数据进行分类, 能够有效地降低运算量, 从而提高分类速度, 同时保持数据的结构特征, 最后使用支持向量机进行分类, 得到了良好的分类效果。</p>
                </div>
                <h3 id="131" name="131" class="anchor-tag"><b>4 实验及结果分析</b></h3>
                <div class="p1">
                    <p id="132">为了验证上述算法的有效性, 本文选取真实的光学遥感图像进行多组比较实验。除了本文提到的算法, 还引入了4种方法做对比。对比方法分别为:</p>
                </div>
                <div class="p1">
                    <p id="133"> (1) <i>LBP</i>+<i>SVM</i>:提取样本的<i>LBP</i>特征, 然后利用<i>SVM</i>分类器进行训练和测试;</p>
                </div>
                <div class="p1">
                    <p id="134"> (2) <i>SLBP</i>+<i>SVM</i>:<i>SLBP</i>为本文改进版的<i>LBP</i>, 分类器同为<i>SVM</i>;</p>
                </div>
                <div class="p1">
                    <p id="135"> (3) <i>SIFT</i>+<i>LE</i>+<i>KNN</i>:首先提取<i>SIFT</i>特征, 利用<i>LE</i>降维, 通过<i>KNN</i>分类器训练测试;</p>
                </div>
                <div class="p1">
                    <p id="136"> (4) <i>SIFT</i>+<i>LE</i>+<i>RCF</i>:提取<i>SIFT</i>特征, <i>LE</i>降维后通过<i>RCF</i>分类器训练测试。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137"><b>4.1 实验数据</b></h4>
                <div class="p1">
                    <p id="138">本文分别在<i>Satellite</i>、<i>NWPU</i>-<i>FACC</i>45和<i>UC Merced Land Use Dataset</i> 3组数据集上进行实验。</p>
                </div>
                <div class="p1">
                    <p id="139">从<i>Satellite</i>数据集中选取冰川、岩石、城市、水域、农田和森林6类样本, 每类训练集800幅图像, 测试集200幅图像。<i>NWPU</i>-<i>FACC</i>45数据集是西北工业大学 (<i>NWPU</i>) 创建的遥感图像场景分类 (电阻抗) 的一个公开的基准。该数据集包含31 500幅图像, 覆盖45个场景类, 每个类中有700幅图像;本文实验选取海滩、建筑群、沙漠、森林、湖泊和山区6类样本, 每类训练集500幅图像, 测试集200幅图像。<i>UC Merced Land Use Dataset</i>是一个21级的土地利用图像数据集, 常用于研究。每类有100幅图像, 这些图像是从美国地质勘探局国家地图城市地区的大型图像中手工提取出来的;本文实验选取海滩、建筑群、沙漠、森林、湖泊和山区6类样本, 每类训练集80幅图像, 测试集20幅图像。</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140"><b>4.2 实验结果及分析</b></h4>
                <div class="p1">
                    <p id="141">从表1的<i>Satellite</i>数据集上的实验结果可以看出, 相对于其它几种方法, 本文提出的算法对于每类样本测试集的分类精度大部分都有提高, 对于总测试集的分类精度更是达到了74.33%, 对比<i>LBP</i>+<i>SVM</i>、<i>SLBP</i>+<i>SVM</i>这些传统的方法提高了10%～15%, 相比<i>PCA</i>降维方式的特征工程算法也有一定提高。</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表1 Satellite数据集上的分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Classification accuracy on Satellite dataset</b></p>
                    <p class="img_note">%</p>
                    <table id="142" border="1"><tr><td><br />方法</td><td>冰川</td><td>岩石</td><td>城市</td><td>水域</td><td>农田</td><td>森林</td><td>总体</td></tr><tr><td><br />LBP+<br />SVM</td><td>63.00</td><td>66.00</td><td>75.00</td><td>46.50</td><td>49.00</td><td>67.00</td><td>61.00</td></tr><tr><td><br />SLBP+<br />SVM</td><td>71.50</td><td>67.50</td><td>75.00</td><td>58.50</td><td>53.50</td><td>65.50</td><td>65.25</td></tr><tr><td><br />SIFT+<br />PCA+SVM</td><td>73.50</td><td>68.50</td><td>78.00</td><td>59.00</td><td>59.00</td><td>68.00</td><td>67.67</td></tr><tr><td><br />SIFT+<br />LE+SVM</td><td>83.50</td><td>78.50</td><td>82.50</td><td>65.00</td><td>64.00</td><td>72.50</td><td>74.33</td></tr><tr><td><br />SIFT+<br />LE+KNN</td><td>81.50</td><td>68.00</td><td>81.50</td><td>61.50</td><td>64.50</td><td>70.50</td><td>71.25</td></tr><tr><td><br />SIFT+<br />LE+RCF</td><td>80.00</td><td>75.00</td><td>80.00</td><td>60.50</td><td>65.00</td><td>75.00</td><td>72.58</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="143">表2为本文算法在Satellite数据集上的分类精度混淆矩阵, 分别表示每一类的分类精度以及被误分类的百分比。表3针对在Satellite数据集上的实验结果记录4种分类方式的分类时间, 由此分析本文提出的算法不仅在分类精度上有所提高, 而且相比PCA降维速度更快一点, 用来对光学遥感数据集分类更为合适。表4和表5分别为在NWPU数据集和UCMerced数据集上的分类精度结果, 引入多个数据集进行实验使结果更有说服力。</p>
                </div>
                <div class="area_img" id="144">
                    <p class="img_tit"><b>表2 Satellite数据集上的分类精度混淆矩阵</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Confusion matrix of classification accuracy on Satellite dataset</b></p>
                    <p class="img_note"></p>
                    <table id="144" border="1"><tr><td><br />类别</td><td>冰川</td><td>岩石</td><td>城市</td><td>水域</td><td>农田</td><td>森林</td></tr><tr><td><br />冰川</td><td>83.50</td><td>1.50</td><td>0.00</td><td>5.50</td><td>4.50</td><td>5.00</td></tr><tr><td><br />岩石</td><td>1.50</td><td>78.50</td><td>15.00</td><td>3.50</td><td>0.00</td><td>1.50</td></tr><tr><td><br />城市</td><td>3.00</td><td>6.00</td><td>82.50</td><td>2.00</td><td>1.00</td><td>5.50</td></tr><tr><td><br />水域</td><td>3.00</td><td>15.00</td><td>2.00</td><td>65.00</td><td>10.00</td><td>5.00</td></tr><tr><td><br />农田</td><td>1.00</td><td>0.00</td><td>0.00</td><td>20.00</td><td>64.00</td><td>15.00</td></tr><tr><td><br />森林</td><td>5.00</td><td>5.50</td><td>6.50</td><td>0.50</td><td>10.00</td><td>72.50</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表3 Satellite数据集上的分类时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Comparison of classification time on Satellite dataset</b></p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td><br />分类<br />方法</td><td>LBP+<br />SVM</td><td>SLBP+<br />SVM</td><td>SIFT+<br />PCA+SVM</td><td>SIFT+<br />LE+SVM</td></tr><tr><td><br />时间/s</td><td>30</td><td>60</td><td>600</td><td>360</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="146">
                    <p class="img_tit"><b>表4 NWPU数据集上的分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Classification accuracy on NWPU dataset</b></p>
                    <p class="img_note">%</p>
                    <table id="146" border="1"><tr><td><br />方法</td><td>海滩</td><td>建筑群</td><td>沙漠</td><td>森林</td><td>湖泊</td><td>山区</td><td>总体</td></tr><tr><td><br />LBP+<br />SVM</td><td>60.00</td><td>78.50</td><td>64.00</td><td>82.50</td><td>79.50</td><td>74.00</td><td>73.08</td></tr><tr><td><br />SLBP+<br />SVM</td><td>73.00</td><td>84.00</td><td>62.50</td><td>85.50</td><td>83.00</td><td>76.50</td><td>77.40</td></tr><tr><td><br />SIFT+<br />PCA+SVM</td><td>75.00</td><td>83.00</td><td>65.50</td><td>87.50</td><td>84.50</td><td>80.00</td><td>79.25</td></tr><tr><td><br />SIFT+<br />LE+SVM</td><td>83.00</td><td>85.00</td><td>75.00</td><td>90.00</td><td>85.00</td><td>86.50</td><td>84.08</td></tr><tr><td><br />SIFT+<br />LE+KNN</td><td>82.00</td><td>82.50</td><td>74.60</td><td>90.00</td><td>84.50</td><td>83.00</td><td>82.77</td></tr><tr><td><br />SIFT+<br />LE+RCF</td><td>80.50</td><td>83.50</td><td>73.50</td><td>88.50</td><td>80.00</td><td>79.50</td><td>80.92</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="147">
                    <p class="img_tit"><b>表5 UCMerced数据集上的分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 5 Classification accuracy on UCMerced dataset</b></p>
                    <p class="img_note">%</p>
                    <table id="147" border="1"><tr><td><br />方法</td><td>海滩</td><td>建筑群</td><td>沙漠</td><td>森林</td><td>河水</td><td>稀疏<br />住宅区</td><td>总体</td></tr><tr><td><br />LBP+<br />SVM</td><td>50.00</td><td>55.00</td><td>70.00</td><td>100.00</td><td>95.00</td><td>75.00</td><td>74.17</td></tr><tr><td><br />SLBP+<br />SVM</td><td>30.00</td><td>75.00</td><td>90.00</td><td>100.00</td><td>95.00</td><td>80.00</td><td>78.30</td></tr><tr><td><br />SIFT+<br />PCA+SVM</td><td>65.50</td><td>78.00</td><td>88.00</td><td>100.00</td><td>96.00</td><td>81.00</td><td>84.75</td></tr><tr><td><br />SIFT+<br />LE+SVM</td><td>85.00</td><td>78.00</td><td>85.00</td><td>100.00</td><td>96.00</td><td>82.00</td><td>87.67</td></tr><tr><td><br />SIFT+<br />LE+KNN</td><td>75.00</td><td>80.00</td><td>75.00</td><td>100.00</td><td>93.00</td><td>78.00</td><td>83.50</td></tr><tr><td><br />SIFT+<br />LE+RCF</td><td>81.50</td><td>82.50</td><td>75.00</td><td>100.00</td><td>98.00</td><td>75.00</td><td>85.33</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="148">结合表1、表4和表5不难看出, 对于森林这种纹理特征丰富的样本, 其它方法也可达到较好的分类效果。但是, 对于海滩、沙漠这种特征较少的样本, 另外4组方法的分类精度就比较低了, 而使用本文的分类算法可以有效地提高分类精度。</p>
                </div>
                <div class="p1">
                    <p id="149">本文实验结果表明, LE降维可以很好地提取出高维数据中的有用信息, 使用非线性流形学习在降维的同时, 可在低维空间保持数据原来的结构, 从而在减少计算量的同时, 提高分类精度。</p>
                </div>
                <h3 id="150" name="150" class="anchor-tag"><b>5 结束语</b></h3>
                <div class="p1">
                    <p id="151">本文提出了一种基于流形学习的光学遥感图像分类算法。该算法首先提取光学遥感图像的SIFT高维特征, 然后通过流形学习 (拉普拉斯特征映射) 降维, 最后利用支持向量机进行训练分类和测试。高维特征中存在着不利于分类的冗余信息和无用信息, 这不仅增加了很多无用的计算, 还降低了图像分类的精度。从本文实验结果可以看出, 特别是对于沙漠、海滩和水域这种样本特征点比较少的图像, 本文算法利用流形学习可有效地将相似的特征点聚合, 从而得到比较高的分类精度。同时, 从对比实验还可以看出, 本文算法的分类精度相比其它方法都有提高。</p>
                </div>
                <div class="p1">
                    <p id="152">近些年十分火热的深度学习相比传统的机器学习算法的分类效果有显著的提高, 可以达到比较理想的效果, 美中不足的是, 深度学习算法对硬件有相应的要求, 需要的训练样本量大、耗时较长, 这对实际工程是不利的, 很多学者还在研究算法优化, 力求减少训练耗时;相比深度学习, 本文算法对硬件要求没那么高, 实现比较简单、耗时短, 同时还能保证较高的分类精度。所以, 本文提出的基于流形学习的分类算法是有效的, 在光学遥感图像分类的应用与研究中是十分有意义的。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="238" type="formula" href="images/JSJK201907010_23800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">王云艳</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="240" type="formula" href="images/JSJK201907010_24000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">罗冷坤</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="242" type="formula" href="images/JSJK201907010_24200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">王重阳</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="166">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Remote sensing technology and applications">

                                <b>[1]</b> Lurie J B, Irvin E M.Remote sensing technology and applications[J].Optical Engineering, 2002, 41 (9) :2075-2076.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Performance evaluation of texture measures with classification based on Kullback discrimination of distributions">

                                <b>[2]</b> Ojala T, Pietikäinen M, Harwood D.Performance evaluation of texture measures with classification based on Kullback discrimination of distributions[C]//Proc of the 12th IAPR International Conference on Pattern Recognition (ICPR 1994) , 1994:582-585.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object Recognition from Local Scale-Invariant Features">

                                <b>[3]</b> Lowe D G.Object recognition from local scale-invariant features[C]//Proc of International Conference on Computer Vision, 1999:1150-1157.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MTQzODZkdEZDRGxWYnpNSVY0PU5qN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Lowe D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Histograms of Oriented Gradients for Human Detection">

                                <b>[5]</b> Dalal N, Triggs B.Histograms of oriented gradients for human detection[C]//Proc of International Conference on Computer Vision &amp; Pattern Recognition (CVPR’05) , 2005:886-893.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZKK201803011&amp;v=MjIzNTZxQnRHRnJDVVJMT2VaZVJtRnk3bVY3N0lJVGZBWmJHNEg5bk1ySTlFWllRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Liu Jing, Zhao Feng-yu.Research progress of dimensionality reduction technology on high-dimensional data [J].Electronic Science &amp; Technology, 2018, 31 (3) :36-38. (in Chinese) 
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGC201708003&amp;v=MDY1NzVxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJUHlyTWJiRzRIOWJNcDQ5Rlo0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Ma Fa-min, Zhang Lin, Wang Jin-biao.Introduction of the dimensionality reduction algorithm[J].Software Engineering, 2017, 20 (8) :7-13. (in Chinese) 
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZKYB201801010&amp;v=MjM1NTh0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJUHliU2JMRzRIOW5Ncm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Li Song, Wei Zhong-hao, Zhang Bing-chen, et al.Target recognition using the transfer learning-based deep convolutional neural networks for SAR images [J].Journal of University of Chinese Academy of Sciences, 2018, 35 (1) :76-83. (in Chinese) 
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSSG201712035&amp;v=MzI0NDBGckNVUkxPZVplUm1GeTdtVjc3SUx6N1lhYkc0SDliTnJZOUdZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Peng Yi-jin.Manifold learning based SAR image target classification[J].Computer and Digital Engineering, 2017, 45 (12) :2489-2493. (in Chinese) 
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Specific object detection and recognition in optical remote sensing images">

                                <b>[10]</b> Hong Tao.Specific object detection and recognition in optical remote sensing images[D].Chengdu:University of Electronic Science and Technology of China, 2018. (in Chinese) 
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501914228&amp;v=MDE5NjhheEk9TmlmT2ZiSzdIdEROcW85RWJlb0xEbjR4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGZJSmwwUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Sanchez V D.Advanced support vector machines and kernel methods[J].Neurocomputing, 2003, 55 (1-2) :5-20.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201008020&amp;v=MjAyMzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJUFRYSVlMRzRIOUhNcDQ5SFo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Ying Zi-lu, Cai Lin-bo, Liu Zhao-yi.Face recognition with Laplacian eigenmaps on local binary pattern[J].Signal Processing, 2010, 26 (8) :1230-1233. (in Chinese) 
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWCL201608005&amp;v=MjkxNDRSTE9lWmVSbUZ5N21WNzdJSWpySVlyRzRIOWZNcDQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Zhang Wei-kun, Ye Wei, Lao Guo-chao.Research on aircraft target matching classification method based on SIFT feature for SAR image [J].Foreign Electronic Measurement Technology, 2016, 35 (8) :19-21. (in Chinese) 
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 Yang Shi-pei, Chen Jie, Zhou Li, et al.Image feature matching method based on SIFT [J].Electronic Measurement Technology, 2014, 37 (6) :50-53. (in Chinese) 
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YCGZ201604005&amp;v=MzI3MDFDN01kTEc0SDlmTXE0OUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc3SVA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Shen Jie, Ji Chun-mei, Wang Zheng-qun, et al.Face recognition based on supervised Laplacian eigenmap algorithm[J].Journal of Yancheng Institute of Technology (Natural Science Edition) , 2016, 29 (4) :16-20. (in Chinese) 
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Laplacian eigenmaps-based polarimetric dimensionality reduction for SAR image classification">

                                <b>[16]</b> Tu Shang-tan, Chen Jia-yu, Yang Wen, et al.Laplacian eigenmaps-based polarimetric dimensionality reduction for SAR image classification[J].IEEE Transactions on Geoscience and Remote Sensing, 2012, 50 (1) :170-179.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 Niu Xin, Dou Yong, Zhang Peng, et al.Airport and flight recognition on optical remote sensing data by deep learning[J].Big Data Research, 2016, 2 (5) :54-67. (in Chinese) 
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 Ji Xiao-fei, Qin Ning-li.Design and implementation of multi-target detection and recognition algorithm for optical remote sensing image[J].Journal of Computer Applications, 2015, 35 (11) :3302-3307. (in Chinese) 
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 刘靖, 赵逢禹.高维数据降维技术及研究进展[J].电子科技, 2018, 31 (3) :36-38.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 马发民, 张林, 王锦彪.维数约简算法简述[J].软件工程, 2017, 20 (8) :7-13.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 李松, 魏中浩, 张冰尘, 等.深度卷积神经网络在迁移学习模式下的SAR目标识别[J].中国科学院大学学报, 2018, 35 (1) :76-83.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 彭易锦.基于流形学习的SAR图像目标分类[J].计算机与数字工程, 2017, 45 (12) :2489-2493.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018991422.nh&amp;v=MDQyMDZxeEg5WE9yWkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJtRnk3bVY3N0lWRjI2RnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 洪韬.基于光学遥感影像的特定目标检测及识别[D].成都:电子科技大学, 2018.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 应自炉, 蔡淋波, 刘召义.基于LBP的拉普拉斯特征映射人脸识别[J].信号处理, 2010, 26 (8) :1230-1233.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 张维坤, 叶伟, 劳国超.基于SIFT特征的SAR图像飞机目标匹配分类方法研究[J].国外电子测量技术, 2016, 35 (8) :19-21.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201406013&amp;v=MDYwNjJmSVlyRzRIOVhNcVk5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJSVQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 杨世沛, 陈杰, 周莉, 等.一种基于SIFT的图像特征匹配方法[J].电子测量技术, 2014, 37 (6) :50-53.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 沈杰, 嵇春梅, 王正群, 等.基于监督拉普拉斯特征映射算法的人脸识别[J].盐城工学院学报 (自然科学版) , 2016, 29 (4) :16-20.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSJU201605007&amp;v=MjM3MTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc3SUlUN0JlN0c0SDlmTXFvOUZZNFE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 牛新, 窦勇, 张鹏, 等.基于深度学习的光学遥感机场与飞行器目标识别技术[J].大数据, 2016, 2 (5) :54-67.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201511061&amp;v=MTA2MjI3QmQ3RzRIOVROcm85RFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbUZ5N21WNzdJTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 姬晓飞, 秦宁丽.光学遥感图像多目标检测及识别算法设计与实现[J].计算机应用, 2015, 35 (11) :3302-3307.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JSJK201907010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201907010&amp;v=Mjg5OTZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm1GeTdtVjc3SUx6N0JaYkc0SDlqTXFJOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY2UXI4RUJreUIrY05aSWZBQVJmWT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
