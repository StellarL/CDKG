<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133357489815000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dWXYJ201911009%26RESULT%3d1%26SIGN%3dA41N8PrSfqVPyCSJBn%252fS5SvvbkI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201911009&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201911009&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201911009&amp;v=MTk3MTVxcUJ0R0ZyQ1VSTE9lWmVWdkZDbmdXNzdCTWpYU1pMRzRIOWpOcm85RmJZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#23" data-title="1 &lt;b&gt;引言&lt;/b&gt; ">1 <b>引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#27" data-title="2 &lt;b&gt;离群因子检测方法&lt;/b&gt; ">2 <b>离群因子检测方法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="3 &lt;b&gt;聚类算法优化&lt;/b&gt; ">3 <b>聚类算法优化</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="3.1 &lt;b&gt;相似性度量&lt;/b&gt;">3.1 <b>相似性度量</b></a></li>
                                                <li><a href="#59" data-title="3.2 &lt;b&gt;初始聚类中心点的选取&lt;/b&gt;">3.2 <b>初始聚类中心点的选取</b></a></li>
                                                <li><a href="#66" data-title="3.3 &lt;b&gt;聚类中心的迭代优化&lt;/b&gt;">3.3 <b>聚类中心的迭代优化</b></a></li>
                                                <li><a href="#78" data-title="3.4 &lt;b&gt;优化算法总体描述&lt;/b&gt;">3.4 <b>优化算法总体描述</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#115" data-title="4 &lt;b&gt;优化算法的性能分析&lt;/b&gt; ">4 <b>优化算法的性能分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#126" data-title="5 &lt;b&gt;实验结果分析&lt;/b&gt; ">5 <b>实验结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#129" data-title="5.1 &lt;b&gt;初始化&lt;/b&gt;">5.1 <b>初始化</b></a></li>
                                                <li><a href="#136" data-title="5.2 &lt;i&gt;LOF&lt;/i&gt;&lt;b&gt;算法参数对准确性的影响&lt;/b&gt;">5.2 <i>LOF</i><b>算法参数对准确性的影响</b></a></li>
                                                <li><a href="#140" data-title="5.3 &lt;b&gt;改进算法的有效性&lt;/b&gt;">5.3 <b>改进算法的有效性</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#145" data-title="6 &lt;b&gt;结束语&lt;/b&gt; ">6 <b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#114" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;该算法操作的整体流程图&lt;/b&gt;"><b>图</b>1 <b>该算法操作的整体流程图</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;测试数据集信息&lt;/b&gt;"><b>表</b>1 <b>测试数据集信息</b></a></li>
                                                <li><a href="#131" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;最大最小值初始化&lt;/b&gt;"><b>图</b>2 <b>最大最小值初始化</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;图&lt;/b&gt;3 &lt;i&gt;FCM&lt;/i&gt;&lt;b&gt;算法初始化&lt;/b&gt;"><b>图</b>3 <i>FCM</i><b>算法初始化</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;图&lt;/b&gt;4 &lt;i&gt;OFMMK&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;&lt;b&gt;算法初始化&lt;/b&gt;"><b>图</b>4 <i>OFMMK</i>-<i>means</i><b>算法初始化</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;图&lt;/b&gt;5 &lt;b&gt;优化算法初始化&lt;/b&gt;"><b>图</b>5 <b>优化算法初始化</b></a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;图&lt;/b&gt;6 &lt;b&gt;参数&lt;/b&gt;k_&lt;i&gt;dist&lt;/i&gt;&lt;b&gt;的取值&lt;/b&gt;"><b>图</b>6 <b>参数</b>k_<i>dist</i><b>的取值</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;样本数据在不同算法上的平均准确率&lt;/b&gt;"><b>表</b>2 <b>样本数据在不同算法上的平均准确率</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;样本数据在不同算法上的运行时间&lt;/b&gt;"><b>表</b>3 <b>样本数据在不同算法上的运行时间</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" &lt;i&gt;XIAO H H&lt;/i&gt;.&lt;i&gt;Flower pollination algorithm combination with gauss mutation and powell search method&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Frontiers of Computer and Technology&lt;/i&gt;,2017,11(3):478-490." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201703017&amp;v=MTI0OTJySTlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNuZ1c3N0JMalhmZmJHNEg5Yk0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         &lt;i&gt;XIAO H H&lt;/i&gt;.&lt;i&gt;Flower pollination algorithm combination with gauss mutation and powell search method&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Frontiers of Computer and Technology&lt;/i&gt;,2017,11(3):478-490.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" &lt;i&gt;NIKOLAOS TSAPANOS&lt;/i&gt;.&lt;i&gt;A distributed framework for trimmed Kernel K&lt;/i&gt;-&lt;i&gt;Means clustering&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Pattern Recognition&lt;/i&gt;,2015,48(8):2685-2698." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300162525&amp;v=MTI3MThmT2ZiSzlIOVBPckk5RlplME5DWDQ4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYjdMSVZzY2F4cz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         &lt;i&gt;NIKOLAOS TSAPANOS&lt;/i&gt;.&lt;i&gt;A distributed framework for trimmed Kernel K&lt;/i&gt;-&lt;i&gt;Means clustering&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Pattern Recognition&lt;/i&gt;,2015,48(8):2685-2698.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 海沫.大数据聚类算法综述[&lt;i&gt;J&lt;/i&gt;].计算机科学,2016,43(&lt;i&gt;Z&lt;/i&gt;6):380-383." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2016S1092&amp;v=MDg3Njk5ZXZybzlNWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNuZ1c3N0JMejdCYjdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         海沫.大数据聚类算法综述[&lt;i&gt;J&lt;/i&gt;].计算机科学,2016,43(&lt;i&gt;Z&lt;/i&gt;6):380-383.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" &lt;i&gt;BAOJU ZHANG&lt;/i&gt;.&lt;i&gt;Data stream clustering based on fuzzy C&lt;/i&gt;-&lt;i&gt;Mean algorithm and entropy theory&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Signal Processing&lt;/i&gt;,2016,126(2):111-116." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122400156048&amp;v=MjAyNDFNbndaZVp1SHlqbVViN0xJVnNjYXhzPU5pZk9mYks5SDlQT3E0OUZaZTRKREhneG9CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         &lt;i&gt;BAOJU ZHANG&lt;/i&gt;.&lt;i&gt;Data stream clustering based on fuzzy C&lt;/i&gt;-&lt;i&gt;Mean algorithm and entropy theory&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Signal Processing&lt;/i&gt;,2016,126(2):111-116.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 高红艳,刘飞.基于局部相似性的&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt; 谱聚类算法[&lt;i&gt;J&lt;/i&gt;].小型微型计算机系统,2014,35(5):1133 -1136." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201405042&amp;v=MDExNDc0SDlYTXFvOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGQ25nVzc3QlBUWGNkckc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         高红艳,刘飞.基于局部相似性的&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt; 谱聚类算法[&lt;i&gt;J&lt;/i&gt;].小型微型计算机系统,2014,35(5):1133 -1136.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 唐东凯,王红梅,胡明,等.优化初始聚类中心的改进&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;算法[&lt;i&gt;J&lt;/i&gt;].小型微型计算机系统,2018,39(8):1819-1823." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201808036&amp;v=MTkwMzVHWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNuZ1c3N0JQVFhjZHJHNEg5bk1wNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         唐东凯,王红梅,胡明,等.优化初始聚类中心的改进&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;算法[&lt;i&gt;J&lt;/i&gt;].小型微型计算机系统,2018,39(8):1819-1823.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 贾瑞玉,李玉功.类簇数目和初始中心点自确定的&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;算法[&lt;i&gt;J&lt;/i&gt;].计算机工程与应用,2018,54(7):152-158." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201807024&amp;v=MTQ2Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGQ25nVzc3Qkx6N01hYkc0SDluTXFJOUhZSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         贾瑞玉,李玉功.类簇数目和初始中心点自确定的&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;算法[&lt;i&gt;J&lt;/i&gt;].计算机工程与应用,2018,54(7):152-158.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 张杰,卓灵,朱韵攸.一种&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;聚类算法的改进与应用[&lt;i&gt;J&lt;/i&gt;].电子技术应用,2015,41(1):125-131." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY201501040&amp;v=MDQ2MDNVUkxPZVplVnZGQ25nVzc3QklUZkJkN0c0SDlUTXJvOUJaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         张杰,卓灵,朱韵攸.一种&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;聚类算法的改进与应用[&lt;i&gt;J&lt;/i&gt;].电子技术应用,2015,41(1):125-131.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 杨玉梅.基于信息熵改进的&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;动态聚类算法[&lt;i&gt;J&lt;/i&gt;].重庆邮电大学学报(自然科学版),2016,28(2):254-259." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CASH201602018&amp;v=MDg2NzA1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNuZ1c3N0JKaXpZWnJHNEg5Zk1yWTlFYklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         杨玉梅.基于信息熵改进的&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;动态聚类算法[&lt;i&gt;J&lt;/i&gt;].重庆邮电大学学报(自然科学版),2016,28(2):254-259.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 曹永春,蔡正琦,邵亚斌.基于&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;的改进人工蜂群聚类算法[&lt;i&gt;J&lt;/i&gt;].计算机应用,2014,34(1):204-207." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201401048&amp;v=MTc2ODNVUkxPZVplVnZGQ25nVzc3Qkx6N0JkN0c0SDlYTXJvOUJiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         曹永春,蔡正琦,邵亚斌.基于&lt;i&gt;K&lt;/i&gt;-&lt;i&gt;means&lt;/i&gt;的改进人工蜂群聚类算法[&lt;i&gt;J&lt;/i&gt;].计算机应用,2014,34(1):204-207.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=WXYJ" target="_blank">微电子学与计算机</a>
                2019,36(11),43-48             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于改进的局部异常因子检测的优化聚类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">张丹丹</a>
                                <a href="javascript:;">游子毅</a>
                                <a href="javascript:;">郑建</a>
                                <a href="javascript:;">陈世国</a>
                </h2>
                    <h2>

                    <span>贵州师范大学物理与电子科学学院</span>
                    <span>贵州省农村信用社联合社</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>聚类分析在无监督学习领域中一直备受国内外学者关注.针对K-means聚类算法对初始聚类中心点敏感、簇内数据相关性差以及收敛到局部最优的缺点,提出了一种基于离群因子的优化聚类算法.该算法采用信息熵加权欧式距离作为相似性度量依据,以更明显地区分数据对象间的差异,然后利用k距离参数自调整的局部异常因子检测算法计算出各数据点的离群因子并筛选出初始聚类中心的候选集,最后根据其离群因子加权距离法优化聚类中心.通过在UCI数据集上的实验测试结果表明,优化算法的准确率比K-means++算法、OFMMK-means算法、FCM算法更高,运行速度比FCM算法更快.该算法能够更好地应用于入侵行为检测、信用风险评估以及多故障诊断等领域.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kmeans&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kmeans;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E6%9D%83%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加权欧式距离;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LOF%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LOF算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">优化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张丹丹 女，（1994-），硕士研究生．研究方向为智能信息处理与传输技术．;
                                </span>
                                <span>
                                    *游子毅（通讯作者）男，（1982-），博士，教授．研究方向为智能控制算法、网络技术．E-mail:357534271@qq.com．;
                                </span>
                                <span>
                                    郑建 男，（1979-），博士，副教授．研究方向为机器学习与数据挖掘．;
                                </span>
                                <span>
                                    陈世国 男，（1967-），博士，教授．研究方向为信号处理．;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61462015);</span>
                                <span>贵州师范大学研究生创新基金项目(YC[2018]016);</span>
                                <span>贵州省科技计划项目(黔科合LH字[2016]7223号);</span>
                    </p>
            </div>
                    <h1><b>Optimal clustering algorithm based on modified local outlier factor detection</b></h1>
                    <h2>
                    <span>ZHANG Dan-dan</span>
                    <span>YOU Zi-yi</span>
                    <span>ZHENG Jian</span>
                    <span>CHEN Shi-guo</span>
            </h2>
                    <h2>
                    <span>School of Physics and Electronic Sciences,Guizhou Normal University</span>
                    <span>Guizhou Rural Credit Cooperative Association</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Cluster analysis has been concerned by scholars at home and abroad in the field of unsupervised learning. Aiming at the disadvantages of K-means clustering algorithm for initial clustering center point sensitivity, poor data correlation in clusters and convergence to local optimization, an optimized clustering algorithm based on outlier factor is proposed in this paper. The algorithm firstly takes the information entropy weighted European distance as the basis of similarity measurement, in order to distinguish the difference between the data objects more obviously, then calculates the outlier factor of each data point by using the k distance parameter self-adjusting of the Local Outlier Factor algorithm and selects the candidate set of the initial clustering center, and finally optimizes the clustering center according to the outlier factor weighted distance method. The experimental results on UCI DataSet show that the accuracy of the optimization algorithm is higher than that of k-means++ algorithm, OFMMK-means algorithm and FCM algorithm, and its running speed is faster than the FCM algorithm. The algorithm can be better used in intrusion behavior detection, credit risk assessment and multi-fault diagnosis.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Kmeans&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Kmeans;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=weighted%20european%20distance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">weighted european distance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LOF%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LOF algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">optimization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-01</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="23" name="23" class="anchor-tag">1 <b>引言</b></h3>
                <div class="p1">
                    <p id="24">目前,聚类分析已成为数据挖掘领域中必不可少的技术,在商业、保险行业、生物学、电子商务等领域具有广泛的应用前景<citation id="147" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="25">聚类算法种类繁多,包括基于距离划分的K-means算法、基于隶属度划分的FCM模糊聚类等<citation id="154" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>.其中K-means算法具有思路简单、易于实现且聚类速度快的优点,但其聚类中心易受离群点和异常点的影响而导致聚类陷入局部最优<citation id="148" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.该算法的优化与应用一直备受关注.在已见报道中,唐东凯等<citation id="149" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>针对初始聚类中心的优化提出了改进方案. 该方案利用各数据的离群因子缩小初始聚类中心的候选集,缓减了离群点对选取初始聚类中心的干扰.贾瑞玉等<citation id="150" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>给出了样本对象密度的新定义,运用残差分析的方法自动获取初始聚类中心.张杰等<citation id="151" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>利用类内与类间的相异度对k值进行改进,并通过数据中的每一个点到其他点之间的距离及距离均和来删除孤立点和噪声点.杨玉梅<citation id="152" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>运用信息熵对聚类数据间的距离进行修正以筛选出质量较高的初始聚类中心点.曹永春<citation id="153" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>等将改进的人工蜂群(ABC)算法和K-means算法相结合,避免了K-means陷入局部最优的可能性.但是,以上针对K-means算法的优化均没有考虑到簇内数据的相关性,往往导致聚类结果准确率不够稳定从而达不到预期要求.</p>
                </div>
                <div class="p1">
                    <p id="26">在文献<citation id="155" type="reference">[<a class="sup">6</a>,<a class="sup">8</a>,<a class="sup">9</a>]</citation>的基础上对K-means算法进一步优化.本文的贡献主要在于以下两点:①为避免离群点对初始聚类中心准确性产生影响,引入自适应调整k距离参数的局部离群因子检测(LOF)算法筛选出离群因子较小的数据作为初始聚类中心的候选集.②在优化聚类中心迭代阶段,利用离群因子加权距离方法提高对聚类中心定位以及簇划分的精确度.实践证明了优化算法的有效性.</p>
                </div>
                <h3 id="27" name="27" class="anchor-tag">2 <b>离群因子检测方法</b></h3>
                <div class="p1">
                    <p id="28">针对原始K-means算法在选取聚类中心点时的缺陷,提出了依据数据集中每个数据点的离群因子来排除离群点的方法.</p>
                </div>
                <div class="p1">
                    <p id="29"><b>定义</b>1 第<i>k</i>距离</p>
                </div>
                <div class="p1">
                    <p id="30">在数据空间中,对象<i>p</i>的第<i>k</i>距离记作<i>k</i>-<i>dis</i>(<i>p</i>),<i>k</i>为正整数.把对象<i>p</i>与对象<i>o</i>之间的距离记作<i>d</i>(<i>p</i>,<i>o</i>),如果满足以下的两个条件,则<i>k</i>-dis=<i>d</i>(<i>p</i>,<i>o</i>).</p>
                </div>
                <div class="p1">
                    <p id="31">(1)在数据对象中,至少存在<i>k</i>个对象<i>s</i>,使得<i>d</i>(<i>p</i>,<i>s</i>)≤<i>d</i>(<i>p</i>,<i>o</i>).</p>
                </div>
                <div class="p1">
                    <p id="32">(2)在数据对象中,至多存在<i>k</i>-1个对象<i>s</i>,使得<i>d</i>(<i>p</i>,<i>s</i>)≤<i>d</i>(<i>p</i>,<i>o</i>).</p>
                </div>
                <div class="p1">
                    <p id="33"><b>定义</b>2 第<i>k</i>距离领域</p>
                </div>
                <div class="p1">
                    <p id="34">将<i>p</i>的第<i>k</i>距离以内的所有点,包括第<i>k</i>距离,称为对象<i>p</i>的第<i>k</i>距离领域,记作<i>N</i><sub><i>k</i></sub>(<i>p</i>),且|<i>N</i><sub><i>k</i></sub>(<i>p</i>)|≥<i>k</i>.</p>
                </div>
                <div class="p1">
                    <p id="35"><b>定义</b>3 可达距离</p>
                </div>
                <div class="p1">
                    <p id="36">点<i>o</i>到<i>p</i>的第<i>k</i>可达距离可用公式(1)</p>
                </div>
                <div class="p1">
                    <p id="37">定义为:</p>
                </div>
                <div class="p1">
                    <p id="38">rdist<sub><i>k</i></sub>(<i>p</i>,0)=max{<i>k</i>,dis(0),<i>d</i>(<i>p</i>,0)}      (1)</p>
                </div>
                <div class="p1">
                    <p id="39">指定点<i>o</i>到<i>p</i>的可达距离是点<i>o</i>与<i>p</i>的真实距离,或者是<i>o</i>的第<i>k</i>距离.因此,可认为点<i>o</i>到距离最近的<i>k</i>个点的距离相等.</p>
                </div>
                <div class="p1">
                    <p id="40"><b>定义</b>4 局部可达密度</p>
                </div>
                <div class="p1">
                    <p id="41">点<i>p</i>的局部可达密度计算如公式(2):</p>
                </div>
                <div class="p1">
                    <p id="42" class="code-formula">
                        <mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>l</mtext><mtext>r</mtext><mtext>d</mtext><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>Ν</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>o</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></munder><mtext>r</mtext></mstyle><mtext>d</mtext><mtext>i</mtext><mtext>s</mtext><mtext>t</mtext><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo>,</mo><mi>o</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="43">为点<i>p</i>的第<i>k</i>领域内点到<i>p</i>的平均可达距离的倒数.</p>
                </div>
                <div class="p1">
                    <p id="44">综上,可得出离群因子的计算公式(3)如下:</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>L</mtext><mtext>Ο</mtext><mtext>F</mtext><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>o</mi><mo>∈</mo><mi>Ν</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></munder><mtext>l</mtext></mstyle><mtext>r</mtext><mtext>d</mtext><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">|</mo><mi>Ν</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mo>×</mo><mtext>l</mtext><mtext>r</mtext><mtext>d</mtext><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">表示为点<i>p</i>的领域点<i>N</i><sub><i>k</i></sub>(<i>p</i>)的局部可达密度与点<i>p</i>的局部可达密度之比的平均值.</p>
                </div>
                <div class="p1">
                    <p id="47">如果LOF值趋向1,说明<i>p</i>与其领域点的密度相近,<i>p</i>与该领域属于同一簇的可能性大.LOF越小于1,说明<i>p</i>的密度高于其领域点密度,即<i>p</i>为密集点;相反,LOF越大于1,则<i>p</i>越可能是异常点.</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">3 <b>聚类算法优化</b></h3>
                <h4 class="anchor-tag" id="49" name="49">3.1 <b>相似性度量</b></h4>
                <div class="p1">
                    <p id="50">信息熵加权距离方法能够准确地反应数据之间的真实距离.其实现步骤分为三步.</p>
                </div>
                <div class="p1">
                    <p id="51"><i>Step</i>1:对数据集的每一个属性如公式(4)进行初步的预处理.</p>
                </div>
                <div class="p1">
                    <p id="52">X<sub>ij</sub>=x<sub>ij</sub>/<i>max</i>(x<sub>ij</sub>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="53"><i>max</i>(x<sub>ij</sub>)表示数据第j列的最大值.</p>
                </div>
                <div class="p1">
                    <p id="54"><i>Step</i>2:分别根据公式(5)和(6)计算出数据中每个属性的熵值与权值.</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>X</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mi>ln</mi></mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>/</mo><mrow><mi>ln</mi></mrow><mi>m</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>W</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>E</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false">(</mo></mstyle><mn>1</mn><mo>-</mo><mi>E</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">m表示数据集的个数;n表示数据集的维度.</p>
                </div>
                <div class="p1">
                    <p id="57"><i>Step</i>3:根据公式(7)计算出来的权值计算加权欧式距离.</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>d</mtext><mtext>i</mtext><mtext>s</mtext><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>p</mi></msub><mo>,</mo><mi>x</mi><msub><mrow></mrow><mi>q</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>W</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">3.2 <b>初始聚类中心点的选取</b></h4>
                <div class="p1">
                    <p id="60">挑选出距离聚类中心点较近的部分数据作为初始聚类中心的候选集,具体步骤如下.</p>
                </div>
                <div class="p1">
                    <p id="61"><i>Step</i>1:由公式(3)计算出数据中每个数据点的离群因子,并按离群因子值从小到大进行排列形成数据集记为D<sub>L</sub>.</p>
                </div>
                <div class="p1">
                    <p id="62"><i>Step</i>2:在D<sub>L</sub>上选取前a*N(0&lt;a≤1,N为数据集的大小)个数据对象作为初始聚类中心的候选集F(a的大小可自适应调整).</p>
                </div>
                <div class="p1">
                    <p id="63"><i>Step</i>3: 计算数据集F中所有数据的中心点c<sub>0</sub>,利用3.1节相似性度量,找到距离c<sub>0</sub>最远的数据点c<sub>1</sub>,把c<sub>1</sub>记作第一个初始聚类中心点.再次找到距离c<sub>1</sub>最远的点c<sub>2</sub>,将c<sub>2</sub>记作第二个初始聚类中心点,建立集合C={c<sub>1</sub>,c<sub>2</sub>}.</p>
                </div>
                <div class="p1">
                    <p id="64"><i>Step</i>4:计算剩余数据对象x<sub>j</sub>分别到集合C={c<sub>1</sub>,c<sub>2</sub>}的加权距离,记作<i>dis</i>c<sub>1</sub>,<i>dis</i>c<sub>2</sub>,…,<i>dis</i>c<sub>i</sub>,找到点c<sub>i</sub>+1=<i>max</i>{<i>min</i>(<i>dis</i>c<sub>j1</sub>,<i>dis</i>c<sub>j2</sub>,…,<i>dis</i>c<sub>ji</sub>),i+1≤k,x<sub>j</sub>∈F},将c<sub>i+1</sub>记为第i+1个初始聚类中心点,即C={c<sub>1</sub>,c<sub>2</sub>,…,c<sub>i+1</sub>}</p>
                </div>
                <div class="p1">
                    <p id="65"><i>Step</i>5:重复步骤4,直到找到k个初始聚类中心点.</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">3.3 <b>聚类中心的迭代优化</b></h4>
                <div class="p1">
                    <p id="67">采用离群因子对数据间距离进行加权,具体实现过程如下.</p>
                </div>
                <div class="p1">
                    <p id="68"><i>Step</i>1: 将当前轮k个聚类中心点加入到候选集F中形成新集合F′,计算出F′中每一个对象的离群因子r<sub>i</sub>(i∈F′),并找出r<sub>i</sub>的最大值与最小值.</p>
                </div>
                <div class="p1">
                    <p id="69"><i>Step</i>2: 利用离差标准化对数据间的离群因子进行标准化,使得新离群因子<i>new</i>_r<sub>i</sub>的取值范围为大于等于1,具体计算见公式(8).</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext><mo>_</mo><mi>r</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mfrac><mrow><mtext>Μ</mtext><mtext>a</mtext><mtext>r</mtext><mo>_</mo><mi>r</mi><mo>-</mo><mtext>Μ</mtext><mtext>i</mtext><mtext>n</mtext><mo>_</mo><mi>r</mi></mrow><mrow><mtext>Μ</mtext><mtext>a</mtext><mtext>x</mtext><mo>_</mo><mi>r</mi><mo>-</mo><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71">在公式(8)中,Max_<i>r</i>表示离群因子最大值,Min_<i>r</i>表示离群因子最小值.</p>
                </div>
                <div class="p1">
                    <p id="72">Step3: 计算<i>F</i>′中每一个对象<i>x</i><sub><i>j</i></sub>到聚类中心<i>c</i><sub><i>i</i></sub>的加权距离dis<i>w</i>(<i>x</i><sub><i>j</i></sub>,<i>c</i><sub><i>i</i></sub>),然后与离群因子new_<i>r</i><sub><i>i</i></sub>相乘,见公式(9).</p>
                </div>
                <div class="p1">
                    <p id="73"><i>D</i><sub><i>ji</i></sub>=disw(<i>x</i><sub><i>j</i></sub>,<i>c</i><sub><i>i</i></sub>)×new_<i>r</i><sub><i>i</i></sub>      (9)</p>
                </div>
                <div class="p1">
                    <p id="74">式中,<i>D</i><sub><i>ji</i></sub>即作为数据对象<i>x</i><sub><i>j</i></sub>到聚类中心点<i>c</i><sub><i>i</i></sub>的真实距离.显然, new_<i>r</i><sub><i>i</i></sub>值越小,点<i>c</i><sub><i>i</i></sub>与其他数据点的相关性就越大,因此公式(9)中<i>D</i><sub><i>ji</i></sub>就越小,<i>x</i><sub><i>j</i></sub>仍会被分到相同的类中;相反,则<i>D</i><sub><i>ji</i></sub>值越大,就可能会被分到不同的类中.</p>
                </div>
                <div class="p1">
                    <p id="75">Step4:计算每个对象<i>x</i><sub><i>j</i></sub>到聚类中心集<i>C</i>={<i>c</i><sub>1</sub>,<i>c</i><sub>2</sub>,…,<i>c</i><sub><i>k</i></sub>}中各点的最小真实距离Min_<i>D</i><sub><i>ji</i></sub>,并将对象<i>x</i><sub><i>j</i></sub>归为<i>c</i><sub><i>i</i></sub>的类中.</p>
                </div>
                <div class="p1">
                    <p id="76">Step5:计算同一簇中所有对象的均值作为新的聚类中心,更新聚类中心集<i>C</i>′={<i>c</i>′<sub><i>i</i></sub>,<i>c</i>′<sub><i>i</i></sub>,…,<i>c</i>′<sub>3</sub>}.</p>
                </div>
                <div class="p1">
                    <p id="77">Step6:重复Step1～Step 5直到聚类中心不再发生变化.</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78">3.4 <b>优化算法总体描述</b></h4>
                <div class="area_img" id="160">
                                <img alt="" src="Detail/GetImg?filename=images/WXYJ201911009_16000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="160">
                                <img alt="" src="Detail/GetImg?filename=images/WXYJ201911009_16001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="113">图1为该算法操作的整体流程图.</p>
                </div>
                <div class="area_img" id="114">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201911009_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 该算法操作的整体流程图" src="Detail/GetImg?filename=images/WXYJ201911009_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>该算法操作的整体流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201911009_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="115" name="115" class="anchor-tag">4 <b>优化算法的性能分析</b></h3>
                <div class="p1">
                    <p id="116">所提出聚类算法对<i>K</i>-<i>means</i>算法的优化主要集中体现在以下几个方面.</p>
                </div>
                <div class="p1">
                    <p id="117">(1)用信息熵对数据间距离进行加权,通过数据对象每一维属性的信息量来衡量数据之间的距离,更能真实地反映数据之间的关系.</p>
                </div>
                <div class="p1">
                    <p id="118">(2)利用公式(10)挑选出初始聚类中心点.</p>
                </div>
                <div class="p1">
                    <p id="119"><i>centroid</i>=<i>max</i>_<i>min</i>_<i>d</i>(<i>datalof</i>×<i>a</i>)      (10)</p>
                </div>
                <div class="p1">
                    <p id="120">式中,<i>max</i>_<i>min</i>_<i>d</i>表示利用最大最小距离方法.<i>datalof</i>表示按从小到大顺序排列的每一个数据点的离群因子;a选取初始候选集的参数.</p>
                </div>
                <div class="p1">
                    <p id="121">离群因子越小,该点与其他数据的相关性就越大.通过公式(10)选取的初始聚类中心更加接近真实的聚类中心点.</p>
                </div>
                <div class="p1">
                    <p id="122">(3)利用公式(9)优化初始聚类中心.D<sub>ji</sub>的值就越小,数据点x<sub>j</sub>与c<sub>i</sub>的相关性就越好,越容易被分到同一簇中.这样能够更快速、更准确地找到聚类中心.</p>
                </div>
                <div class="p1">
                    <p id="123">(4)<i>LOF</i>算法的k距离参数由如下公式自适应调整.</p>
                </div>
                <div class="p1">
                    <p id="124">k_<i>dist</i>=β×<i>num</i>(<i>dataset</i>)      (11)</p>
                </div>
                <div class="p1">
                    <p id="125">式中,<i>num</i>(<i>dataset</i>)表示集合<i>dataset</i>的数据对象个数.β值可根据实际经验确定,本文切合实际地设置为0.03,有助于提高初始聚类中心选取的准确性.</p>
                </div>
                <h3 id="126" name="126" class="anchor-tag">5 <b>实验结果分析</b></h3>
                <div class="p1">
                    <p id="127">实验环境为<i>Window</i>10系统下的<i>python</i>3.6,处理器为<i>AMD Ryzen</i> 5 2500<i>U with Radeon Vega Mobile Gfx</i> 2.00 <i>GHz</i>,内存为8 <i>GB</i>.选取<i>UCI</i>数据库中的<i>Iris</i>、<i>Wine</i> 、<i>Seeds</i>、<i>Wifi Localization</i>、<i>CMC</i>、<i>Abalone</i>六个公共数据集,分别对<i>K</i>-<i>means</i>++、<i>FCM</i><citation id="156" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、<i>OFMMK</i>-<i>means</i><citation id="157" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>以及优化的算法进行了测试.所用数据集的具体描述如表1所示.</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表</b>1 <b>测试数据集信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td><br />数据名称</td><td>样本数</td><td>属性数</td><td>类别数</td></tr><tr><td><br /><i>Iris</i></td><td>150</td><td>4</td><td>3</td></tr><tr><td><br /><i>Wine</i></td><td>178</td><td>13</td><td>3</td></tr><tr><td><br /><i>Seeds</i></td><td>210</td><td>7</td><td>3</td></tr><tr><td><br /><i>Wifi Localization</i></td><td>2 000</td><td>7</td><td>4</td></tr><tr><td><br /><i>CMC</i></td><td>1 473</td><td>9</td><td>3</td></tr><tr><td><br /><i>Abalone</i></td><td>4 771</td><td>8</td><td>3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="129" name="129">5.1 <b>初始化</b></h4>
                <div class="p1">
                    <p id="130">分别用最大最小值初始化、<i>FCM</i><citation id="158" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>算法初始化、<i>OFMMK</i>-<i>means</i><citation id="159" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>初始化、优化算法初始化对<i>Iris</i>数据集进行了实验测试,实验结果如图2～图5所示.</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201911009_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 最大最小值初始化" src="Detail/GetImg?filename=images/WXYJ201911009_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>最大最小值初始化</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201911009_131.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201911009_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 FCM算法初始化" src="Detail/GetImg?filename=images/WXYJ201911009_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 <i>FCM</i><b>算法初始化</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201911009_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201911009_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 OFMMK-means算法初始化" src="Detail/GetImg?filename=images/WXYJ201911009_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>4 <i>OFMMK</i>-<i>means</i><b>算法初始化</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201911009_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="134">由图2可看出,最大最小值初始化方法选取的初始聚类中心点部分分布在数据的边缘位置,这样很容易导致聚类中心点偏移,使得聚类结果的准确性比较低.由图3、图4可看出,<i>FCM</i>算法、<i>OFMMK</i>-<i>means</i>算法初始化方法选取的初始聚类中心点相比最大最小值法有所改善,但是,并不是所有类的初始聚类中心全都分布在各类数据的中心位置.从图5可看出,优化算法选取的初始聚类中心点最接近真实的聚类中心点,对之后聚类准确性的提高起了很大作用.</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201911009_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 优化算法初始化" src="Detail/GetImg?filename=images/WXYJ201911009_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>5 <b>优化算法初始化</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201911009_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="136" name="136">5.2 <i>LOF</i><b>算法参数对准确性的影响</b></h4>
                <div class="p1">
                    <p id="137">在<i>LOF</i>算法中,参数k_<i>dist</i>表示检测的邻域点数量.该值越大,所选取的样本点越多,聚类的准确性越容易受到<i>LOF</i>值的影响.本文利用以上六个数据集对参数k_<i>dist</i>的取值做了以下实验,如图6所示.</p>
                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201911009_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 参数k_dist的取值" src="Detail/GetImg?filename=images/WXYJ201911009_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>6 <b>参数</b>k_<i>dist</i><b>的取值</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201911009_138.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="139">由图6可看出,当检测的邻域点数占样本总数的3%时,所有数据集的准确率都达到最优.</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140">5.3 <b>改进算法的有效性</b></h4>
                <div class="p1">
                    <p id="141">将<i>K</i>-<i>means</i>++算法、<i>FCM</i>算法、<i>OFMMK</i>-<i>means</i>算法以及所提出的优化算法在样本数据集<i>Iris</i>、<i>Wine</i>、<i>Seeds</i>、<i>Wifi Localization</i>、<i>CMC</i>及<i>Abalone</i>上运行十次,分别将运行结果的平均准确率与时间进行比较,其结果如表2和表3所示.</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表</b>2 <b>样本数据在不同算法上的平均准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td><br />数据集</td><td><i>K</i>-<i>mean</i><br /><i>s</i>++</td><td><i>FCM</i></td><td><i>OFMMK</i>-<br /><i>kmeans</i></td><td>改进算法</td></tr><tr><td><br /><i>Iris</i></td><td>0.841</td><td>0.893</td><td>0.936</td><td>0.960</td></tr><tr><td><br /><i>Wine</i></td><td>0.513</td><td>0.685</td><td>0.714</td><td>0.905</td></tr><tr><td><br /><i>Seed</i></td><td>0.784</td><td>0.875</td><td>0.784</td><td>0.881</td></tr><tr><td><br /><i>Wifi Localization</i></td><td>0.697</td><td>0.891</td><td>0.709</td><td>0.972</td></tr><tr><td><br /><i>CMC</i></td><td>0.365</td><td>0.392</td><td>0.410</td><td>0.456</td></tr><tr><td><br /><i>Abalone</i></td><td>0.469</td><td>0.490</td><td>0.492</td><td>0.522</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="143">
                    <p class="img_tit"><b>表</b>3 <b>样本数据在不同算法上的运行时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="143" border="1"><tr><td><br />样本<br />数据</td><td><i>K</i>-<i>measn</i><br /><i>s</i>++</td><td><i>FCM</i></td><td><i>OFMMK</i><br />-<i>means</i></td><td>改进<br />算法</td></tr><tr><td><br /><i>Iris</i></td><td>0.13 <i>s</i></td><td>8.65 <i>s</i></td><td>0.97 <i>s</i></td><td>0.99 <i>s</i></td></tr><tr><td><br /><i>Wine</i></td><td>0.13 <i>s</i></td><td>14.62 <i>s</i></td><td>0.98 <i>s</i></td><td>1.04 <i>s</i></td></tr><tr><td><br /><i>Seeds</i></td><td>0.13 <i>s</i></td><td>12.76 <i>s</i></td><td>0.94 <i>s</i></td><td>1.00 <i>s</i></td></tr><tr><td><br /><i>Wifi Localization</i></td><td>0.64 <i>s</i></td><td>157.88 <i>s</i></td><td>1.67 <i>s</i></td><td>2.17 <i>s</i></td></tr><tr><td><br /><i>CMC</i></td><td>0.27 <i>s</i></td><td>90.62<i>s</i></td><td>1.30 <i>s</i></td><td>1.73 <i>s</i></td></tr><tr><td><br /><i>Abalone</i></td><td>0.36 <i>s</i></td><td>210.67 <i>s</i></td><td>1.56 <i>s</i></td><td>1.95 <i>s</i></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="144">由表2可看出,优化算法在各个数据集中聚类的准确率都高于<i>K</i>-<i>means</i>++算法、<i>FCM</i>算法及<i>OFMMK</i>-<i>means</i>算法.如表3所示,由于优化算法要计算每个数据点的信息熵与离群因子,所以运行时间相比<i>K</i>-<i>means</i>++算法和<i>OFMMK</i>-<i>means</i>算法略长一些,但是明显低于<i>FCM</i>算法.综上,优化算法在提高准确率的同时,耗时相对减少,得以证明该算法的有效性.</p>
                </div>
                <h3 id="145" name="145" class="anchor-tag">6 <b>结束语</b></h3>
                <div class="p1">
                    <p id="146">本文对基于离散因子的<i>K</i>-<i>means</i>优化算法进行了详细的描述,其新颖之处在于,在局部因子离群检测算法中引入自适应调整k距离参数方法确定初始聚类中心;利用离群因子加权距离进一步优化初始聚类中心并完成簇区划分.就本文提出的优化算法与<i>K</i>-<i>means</i>++、<i>OFMMK</i>-<i>means</i>与<i>FCM</i>算法分别在<i>Iris</i>、<i>Wine</i>、<i>Seeds</i>、<i>Wifi Localization</i>、<i>CMC</i>及<i>Abalone</i>样本数据集上进行分析比较,结果表明优化算法在提高准确率的同时,其耗时也相对降低,能够更好的用于无监督学习的多分类应用场景.该算法的不足之处在于初始聚类中心候选集的抽样参数需要依靠经验值来确定,因此,如何根据不同类型的数据自适应的设置参数值是今后的研究重点.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201703017&amp;v=MTY1ODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNuZ1c3N0JMalhmZmJHNEg5Yk1ySTlFWTRRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> <i>XIAO H H</i>.<i>Flower pollination algorithm combination with gauss mutation and powell search method</i>[<i>J</i>].<i>Journal of Frontiers of Computer and Technology</i>,2017,11(3):478-490.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300162525&amp;v=MTczNzNIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViN0xJVnNjYXhzPU5pZk9mYks5SDlQT3JJOUZaZTBOQ1g0OG9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> <i>NIKOLAOS TSAPANOS</i>.<i>A distributed framework for trimmed Kernel K</i>-<i>Means clustering</i>[<i>J</i>].<i>Pattern Recognition</i>,2015,48(8):2685-2698.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2016S1092&amp;v=MDk1ODZPZVplVnZGQ25nVzc3Qkx6N0JiN0c0SDlldnJvOU1ab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 海沫.大数据聚类算法综述[<i>J</i>].计算机科学,2016,43(<i>Z</i>6):380-383.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122400156048&amp;v=MDYxMjRmYks5SDlQT3E0OUZaZTRKREhneG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVWI3TElWc2NheHM9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> <i>BAOJU ZHANG</i>.<i>Data stream clustering based on fuzzy C</i>-<i>Mean algorithm and entropy theory</i>[<i>J</i>].<i>Signal Processing</i>,2016,126(2):111-116.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201405042&amp;v=MTMyNDllVnZGQ25nVzc3QlBUWGNkckc0SDlYTXFvOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 高红艳,刘飞.基于局部相似性的<i>K</i>-<i>means</i> 谱聚类算法[<i>J</i>].小型微型计算机系统,2014,35(5):1133 -1136.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201808036&amp;v=MDcwNzg3QlBUWGNkckc0SDluTXA0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGQ25nVzc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 唐东凯,王红梅,胡明,等.优化初始聚类中心的改进<i>K</i>-<i>means</i>算法[<i>J</i>].小型微型计算机系统,2018,39(8):1819-1823.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201807024&amp;v=MTI4NTVIWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNuZ1c3N0JMejdNYWJHNEg5bk1xSTk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 贾瑞玉,李玉功.类簇数目和初始中心点自确定的<i>K</i>-<i>means</i>算法[<i>J</i>].计算机工程与应用,2018,54(7):152-158.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY201501040&amp;v=MTcwMTJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZDbmdXNzdCSVRmQmQ3RzRIOVRNcm85QlpJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 张杰,卓灵,朱韵攸.一种<i>K</i>-<i>means</i>聚类算法的改进与应用[<i>J</i>].电子技术应用,2015,41(1):125-131.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CASH201602018&amp;v=MDY2MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZDbmdXNzdCSml6WVpyRzRIOWZNclk5RWJJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 杨玉梅.基于信息熵改进的<i>K</i>-<i>means</i>动态聚类算法[<i>J</i>].重庆邮电大学学报(自然科学版),2016,28(2):254-259.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201401048&amp;v=MTIxNDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZDbmdXNzdCTHo3QmQ3RzRIOVhNcm85QmJJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 曹永春,蔡正琦,邵亚斌.基于<i>K</i>-<i>means</i>的改进人工蜂群聚类算法[<i>J</i>].计算机应用,2014,34(1):204-207.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="WXYJ201911009" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201911009&amp;v=MTk3MTVxcUJ0R0ZyQ1VSTE9lWmVWdkZDbmdXNzdCTWpYU1pMRzRIOWpOcm85RmJZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
