<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133367502315000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dWXYJ201910014%26RESULT%3d1%26SIGN%3dA320odpTQItgPjpuCfUC%252bRx%252fXKA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201910014&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201910014&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201910014&amp;v=MTY5NDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFNalhTWkxHNEg5ak5yNDlFWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="1 &lt;b&gt;引言&lt;/b&gt; ">1 <b>引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#34" data-title="2 &lt;b&gt;基于稀疏表示的图像超分辨率重建&lt;/b&gt; ">2 <b>基于稀疏表示的图像超分辨率重建</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#35" data-title="2.1 &lt;b&gt;稀疏表示基本理论&lt;/b&gt;">2.1 <b>稀疏表示基本理论</b></a></li>
                                                <li><a href="#37" data-title="2.2 &lt;b&gt;稀疏表示基本思想&lt;/b&gt;">2.2 <b>稀疏表示基本思想</b></a></li>
                                                <li><a href="#45" data-title="2.3 &lt;b&gt;字典学习&lt;/b&gt;">2.3 <b>字典学习</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="3 &lt;b&gt;基于稀疏表示的图像超分辨率重建算法设计&lt;/b&gt; ">3 <b>基于稀疏表示的图像超分辨率重建算法设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="3.1 &lt;b&gt;单幅图像超分辨率重建流程&lt;/b&gt;">3.1 <b>单幅图像超分辨率重建流程</b></a></li>
                                                <li><a href="#56" data-title="3.2 &lt;b&gt;基于稀疏表示的自然图像超分辨率重建处理&lt;/b&gt;">3.2 <b>基于稀疏表示的自然图像超分辨率重建处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="4 &lt;b&gt;实验与分析&lt;/b&gt; ">4 <b>实验与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="5 &lt;b&gt;结束语&lt;/b&gt; ">5 <b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;字典&lt;/b&gt;&lt;i&gt;D&lt;/i&gt;&lt;b&gt;与原子&lt;/b&gt;&lt;i&gt;K&lt;/i&gt;&lt;b&gt;和信号维度&lt;/b&gt;&lt;i&gt;N&lt;/i&gt;&lt;b&gt;的关系&lt;/b&gt;"><b>图</b>1 <b>字典</b><i>D</i><b>与原子</b><i>K</i><b>和信号维度</b><i>N</i><b>的关系</b></a></li>
                                                <li><a href="#55" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;图像的超分辨率重建过程&lt;/b&gt;"><b>图</b>2 <b>图像的超分辨率重建过程</b></a></li>
                                                <li><a href="#130" data-title="图3 实验中采用的测试图像">图3 实验中采用的测试图像</a></li>
                                                <li><a href="#131" data-title="图4 不同方法对plant图像的重建结果">图4 不同方法对plant图像的重建结果</a></li>
                                                <li><a href="#132" data-title="图5 不同方法对girl图像的重建结果">图5 不同方法对girl图像的重建结果</a></li>
                                                <li><a href="#133" data-title="图6 不同方法对leaf图像的重建结果">图6 不同方法对leaf图像的重建结果</a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;实验图像重建后项指标数据&lt;/b&gt;"><b>表</b>1 <b>实验图像重建后项指标数据</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="134">


                                    <a id="bibliography_1" title=" WANG G,YE J C,MUELLER K,et al.Image Reconstruction is a New Frontier of Machine Learning[J].IEEE Transactions on Medical Imaging,2018,37(6):1289-1296." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image reconstruction is a new frontier of machine learning">
                                        <b>[1]</b>
                                         WANG G,YE J C,MUELLER K,et al.Image Reconstruction is a New Frontier of Machine Learning[J].IEEE Transactions on Medical Imaging,2018,37(6):1289-1296.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_2" title=" LI B,ZHAO F,SU Z,et al.Example-based Image Colorization using Locality Consistent Sparse Representation[J].IEEE Transactions on Image Processing,2017,26(11):5188-5202." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Example-based Image Colorization Using Locality Consistent Sparse Representation">
                                        <b>[2]</b>
                                         LI B,ZHAO F,SU Z,et al.Example-based Image Colorization using Locality Consistent Sparse Representation[J].IEEE Transactions on Image Processing,2017,26(11):5188-5202.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_3" title=" 江静,张雪松.图像超分辨率重建算法综述[J].红外技术,2012,34(1):24-30." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201201006&amp;v=MzI0MzlHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFMVHJCZmJHNEg5UE1ybzlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         江静,张雪松.图像超分辨率重建算法综述[J].红外技术,2012,34(1):24-30.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_4" title=" 曾凯,丁世飞.图像超分辨率重建的研究进展[J].计算机工程与应用,2017,53(16):29-35." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201716004&amp;v=MjQ2MjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZDamtWN3JBTHo3TWFiRzRIOWJOcVk5RllJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         曾凯,丁世飞.图像超分辨率重建的研究进展[J].计算机工程与应用,2017,53(16):29-35.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_5" title=" 高媛,刘志,秦品乐,等.基于深度残差生成对抗网络的医学影像超分辨率算法[J].计算机应用,2018,38(9):2689-2695." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201809043&amp;v=MTEzMjNVUkxPZVplVnZGQ2prVjdyQUx6N0JkN0c0SDluTXBvOUJaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         高媛,刘志,秦品乐,等.基于深度残差生成对抗网络的医学影像超分辨率算法[J].计算机应用,2018,38(9):2689-2695.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_6" title=" 孔玲莉,黄华,齐春.图像超分辨率研究的最新进展[J].光学技术,2014,30(3):374-377." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJS200403036&amp;v=MDU1MzdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZDamtWN3JBSWpYQmZiRzRIdFhNckk5R1k=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         孔玲莉,黄华,齐春.图像超分辨率研究的最新进展[J].光学技术,2014,30(3):374-377.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_7" title=" YANG J,WRIGHT J,HUANG T S,et al.Image super-resolution via sparse representation.[J].IEEETransactions on Image Processing,2010,19(11):2861-2873." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution via sparse representation">
                                        <b>[7]</b>
                                         YANG J,WRIGHT J,HUANG T S,et al.Image super-resolution via sparse representation.[J].IEEETransactions on Image Processing,2010,19(11):2861-2873.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_8" title=" DONG W,ZHANG L,SHI G,et al.Image Deblurring and Super-resolution by Adaptive Sparse Domain Selection and Adaptive Regularization[J].IEEETransactions on Image Processing,2011,20(7):1837-1857." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization">
                                        <b>[8]</b>
                                         DONG W,ZHANG L,SHI G,et al.Image Deblurring and Super-resolution by Adaptive Sparse Domain Selection and Adaptive Regularization[J].IEEETransactions on Image Processing,2011,20(7):1837-1857.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_9" title=" 马杰,武利涛,张晓严.一种改进的组稀疏表示图像去噪方法[J].微电子学与计算机,2017,34(6):99-103." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201706021&amp;v=MjE1MzhyQU1qWFNaTEc0SDliTXFZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGQ2prVjc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         马杰,武利涛,张晓严.一种改进的组稀疏表示图像去噪方法[J].微电子学与计算机,2017,34(6):99-103.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_10" title=" LIU S,JIA J,ZHANG Y D,et al.Image Reconstruction in Electrical Impedance Tomography Based on Structure-Aware Sparse Bayesian Learning[J].IEEE Transactions on Medical Imaging,2018,37(9):2090-2101." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Reconstruction in Electrical Impedance Tomography Based on Structure-Aware Sparse Bayesian Learning">
                                        <b>[10]</b>
                                         LIU S,JIA J,ZHANG Y D,et al.Image Reconstruction in Electrical Impedance Tomography Based on Structure-Aware Sparse Bayesian Learning[J].IEEE Transactions on Medical Imaging,2018,37(9):2090-2101.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_11" title=" 隋昊,周萍,沈昊,等.基于混沌序列的压缩感知语音增强算法[J].微电子学与计算机,2018,35(1):96-99." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201801019&amp;v=MTYxMTh0R0ZyQ1VSTE9lWmVWdkZDamtWN3JBTWpYU1pMRzRIOW5Ncm85RWJZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         隋昊,周萍,沈昊,等.基于混沌序列的压缩感知语音增强算法[J].微电子学与计算机,2018,35(1):96-99.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_12" title=" 孙玉宝,韦志辉,肖亮,等.基于稀疏表示的图像超分辨率重建快速算法[J].系统工程与电子技术,2010,32(12):2696-2700." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYD201012040&amp;v=MDIwODJDVVJMT2VaZVZ2RkNqa1Y3ckFQVG5TYXJHNEg5SE5yWTlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         孙玉宝,韦志辉,肖亮,等.基于稀疏表示的图像超分辨率重建快速算法[J].系统工程与电子技术,2010,32(12):2696-2700.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_13" title=" 胡长胜,詹曙,吴从中.基于深度特征学习的图像超分辨率重建[J].自动化学报,2017,43(5):814-821." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201705013&amp;v=MjI5Mjk5Yk1xbzlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFLQ0xmWWJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         胡长胜,詹曙,吴从中.基于深度特征学习的图像超分辨率重建[J].自动化学报,2017,43(5):814-821.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_14" title=" FREEMAN W T,JONES T R,PASZTOR E C.Example-Based Super-Resolution[J].IEEE Computer Graphics and Applications,2002,22(2):56-65." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Example-based super-resolution">
                                        <b>[14]</b>
                                         FREEMAN W T,JONES T R,PASZTOR E C.Example-Based Super-Resolution[J].IEEE Computer Graphics and Applications,2002,22(2):56-65.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=WXYJ" target="_blank">微电子学与计算机</a>
                2019,36(10),68-72             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于稀疏表示的图像超分辨率重建算法设计</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%9F%B3%E7%BF%A0%E8%90%8D&amp;code=24130139&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">石翠萍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%99%B4&amp;code=41218302&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王晴</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%BD%90%E9%BD%90%E5%93%88%E5%B0%94%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E7%94%B5%E5%AD%90%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0257048&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">齐齐哈尔大学通信与电子工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为解决一般重建方法效果欠佳的问题,使重建后的图像具有良好的清晰度,本文依据稀疏表示原理等内容,设计了一种新的超分辨率重建算法,实现了超分辨率最优解问题.对一幅低分辨率图像,分割后进行特征提取,得到的图像特征块可在字典的低分辨率部分生成一组权重系数.在字典的高分辨率部分,用高分辨率特征块乘以所得系数,可以重新构造出高分辨率图像块,并将它们组合起来得到一幅完备的高分辨率图像.实验结果表明,与双三次插值方法相比,本文算法重构的高分辨率图像具有更好的质量.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超分辨率重建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E8%A1%A8%E7%A4%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏表示;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%97%E5%85%B8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">字典学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    石翠萍,女,(1980-),博士,博士后,副教授,硕士生导师.研究方向为数字图像处理、模式识别与人工智能方向的研究.E-mail:scp1980@126.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-13</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金青年基金(41701479);</span>
                                <span>黑龙江省科学基金项目(QC2018045);</span>
                                <span>中国博士后科学基金项目(2017M621246);</span>
                                <span>黑龙江省博士后科学基金项目(LBH-Z17052);</span>
                                <span>黑龙江省省属高等学校基本科研业务费科研项目(135309342);</span>
                                <span>2018年国家级大学生创新创业训练计划资助项目(201810232018);</span>
                    </p>
            </div>
                    <h1><b>Design of image super-resolution reconstruction algorithm based on sparse representation</b></h1>
                    <h2>
                    <span>SHI Cui-ping</span>
                    <span>WANG Qing</span>
            </h2>
                    <h2>
                    <span>College of Communication and Electronic Engineering, Qiqihar university</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to solve the problem of high complexity and poor reconstruction effect of traditional reconstruction methods and make the super-resolution reconstruction images have good clarity, a new super-resolution reconstruction algorithm based on learning is studied based on sparse representation principle. The super-resolution optimal solution is realized. By inputting a low-resolution image, the corresponding image feature block can be obtained by bicubic interpolation. A set of sparse representation coefficients can be obtained in the low resolution part of the dictionary(DL). According to the set of sparse representation coefficients, the high resolution image blocks are reconstructed by reverse projection on the high resolution dictionary(Dh), and the complete high resolution images are obtained by combining them together. The simulation results show that compared with the bicubic interpolation method, the reconstructed image of this algorithm has better quality.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=super%20resolution%20reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">super resolution reconstruction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20representation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse representation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dictionary%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dictionary learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-13</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag">1 <b>引言</b></h3>
                <div class="p1">
                    <p id="32">研究表明,人类从图像信号所获信息约占人类总信息量的80%<citation id="162" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.数字图像处理技术已被广泛应用于图像传输、通讯技术、遥感技术及气象学等领域<citation id="163" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.其中,由于图像超分辨率重建技术能以较低的代价获得高质量的图像,已经成为广泛应用的技术之一.近年来,针对图像超分辨率技术的研究工作也日益增多.所谓超分辨率重建就是将一幅或多幅具有互补信息的低分辨率图像组合在一起重建出一幅或者多幅高分辨率图像<citation id="164" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>.如果输入一幅低分辨率图像,则可以在生成字典的图像库中寻找到有效的信息,通过这些信息和低分辨率图像进行融合,生成超分辨率图像.</p>
                </div>
                <div class="p1">
                    <p id="33">超分辨率重建从实现角度上大体上可分为三类算法<citation id="165" type="reference"><link href="140" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>.其中,基于插值效果较好的一种算法是双三次插值法,但其缺点是由于算法较简单,本身的低通滤波性会损失图像的高频部分,因而使图像模糊甚至出现锯齿现象<citation id="166" type="reference"><link href="142" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.基于学习过程来获得先验知识的方法是先通过设计算法来识别类别功能,再将得到的先验知识用于超分辨率重建<citation id="167" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>.这种方法给本文研究带入了新思路,基于学习的超分辨率重建的前提是需要有一个拥有极多样本的图像训练集.受Yang<citation id="168" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>及Dong<citation id="169" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等人提出的方法启发,本文先构造出具有低分辨率和高分辨率特征块的字典,再将训练好的字典用于低分辨率图像块,完成图像超分辨率重建.</p>
                </div>
                <h3 id="34" name="34" class="anchor-tag">2 <b>基于稀疏表示的图像超分辨率重建</b></h3>
                <h4 class="anchor-tag" id="35" name="35">2.1 <b>稀疏表示基本理论</b></h4>
                <div class="p1">
                    <p id="36">稀疏表示可以根据信号本身的特性自适应的选择字典<citation id="170" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>.选择稀疏表示方法,在大量低分辨率图像和高分辨率图像的稀疏表示和字典训练下,实现超分辨率在学习样本空间的整体最优解<citation id="171" type="reference"><link href="152" rel="bibliography" /><link href="154" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>.这样保证了足够的先验知识,减少了所需的数据,提高了稀疏表示效率.</p>
                </div>
                <h4 class="anchor-tag" id="37" name="37">2.2 <b>稀疏表示基本思想</b></h4>
                <div class="p1">
                    <p id="38">让<i><b>D</b></i>∈<i>R</i><sup><i>n</i></sup><sup>×</sup><sup><i>K</i></sup>作为<i>K</i>原子<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi>Κ</mi><mo>&gt;</mo><mi>n</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>的过完备字典,假设信号<i>x</i>∈<i>Rn</i>经过矩阵<mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">D</mi><mo>=</mo><mo stretchy="false">[</mo><mi>d</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>d</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>d</mi><msub><mrow></mrow><mn>3</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>d</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mrow><mi>R</mi><mi>n</mi><mo>×</mo><mi>Κ</mi></mrow><mrow><mo>(</mo><mrow><mi>Κ</mi><mo>&gt;</mo><mi>n</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>,信号<i>x</i>和字典<i><b>D</b></i>的关系式为:<i>x</i>=<i><b>D</b></i><i>α</i>,其中<i>α</i>∈<i>R</i><sup><i>K</i></sup>是一个只有极少数非零项的向量,其他向量均为零,则称<i>α</i>是<i>K</i>稀疏的.字典<i><b>D</b></i>与原子<i>K</i>和信号维度<i>n</i>的关系有三种:冗余、完整性、超完整性(过完整性),如图1所示.</p>
                </div>
                <div class="area_img" id="39">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910014_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 字典D与原子K和信号维度N的关系" src="Detail/GetImg?filename=images/WXYJ201910014_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>字典</b><i>D</i><b>与原子</b><i>K</i><b>和信号维度</b><i>N</i><b>的关系</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910014_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="40">图1可以这样理解,稀疏表示可以写成</p>
                </div>
                <div class="p1">
                    <p id="41" class="code-formula">
                        <mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>min</mi></mrow><mo>#</mo><mrow><mo>{</mo><mrow><mi>t</mi><mo>:</mo><mi>x</mi><mi>t</mi><mo>≠</mo><mn>0</mn></mrow><mo>}</mo></mrow><mo>,</mo><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mi>x</mi><mo>=</mo><mi mathvariant="bold-italic">D</mi><mi>α</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="42">或下面的形式</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>min</mi><mrow><mo>|</mo><mi>α</mi><mo>|</mo></mrow></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mi>x</mi><mo>=</mo><mi mathvariant="bold-italic">D</mi><mi>α</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">式中,<i>α</i>是<i>x</i>的稀疏表示,<i>α</i>被称作稀疏表示系数;<mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>|</mo><mi>α</mi><mo>|</mo></mrow></mrow><msub><mrow></mrow><mn>0</mn></msub></mrow></math></mathml>为<i>α</i>的稀疏度,用来表示<i>α</i>中非零向量的个数<citation id="172" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.</p>
                </div>
                <h4 class="anchor-tag" id="45" name="45">2.3 <b>字典学习</b></h4>
                <div class="p1">
                    <p id="46">假设有一组图像块<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>X</mi><msup><mrow></mrow><mi>h</mi></msup><mo>,</mo><mrow><mi>Y</mi><msup><mrow></mrow><mi>l</mi></msup></mrow></mrow><mo>}</mo></mrow></mrow></math></mathml>,其中<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>X</mi><msup><mrow></mrow><mi>h</mi></msup></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>x</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>是高分辨率图像块的集合,<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>Y</mi><msup><mrow></mrow><mi>i</mi></msup></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>y</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>y</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>是低分辨率图像块的集合,<i>x</i><sub><i>i</i></sub>是高分辨率图像块的高频成分,<i>y</i><sub><i>i</i></sub>是低分辨率图像特征块<citation id="173" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.其中</p>
                </div>
                <div class="p1">
                    <p id="47" class="code-formula">
                        <mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mrow><mo>{</mo><mrow><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub><mo>,</mo><mi>Ζ</mi></mrow><mo>}</mo></mrow></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>X</mi><msup><mrow></mrow><mi>h</mi></msup><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>D</mi><msub><mrow></mrow><mi>l</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mrow><mo>{</mo><mrow><mi>D</mi><msub><mrow></mrow><mi>l</mi></msub><mo>,</mo><mi>Ζ</mi></mrow><mo>}</mo></mrow></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>Y</mi><msup><mrow></mrow><mi>l</mi></msup><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>l</mi></msub><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="48">假如把式(3)和式(4)组合起来,用相同的编码来表示高分辨率图像块和低分辨率图像块,可表示为</p>
                </div>
                <div class="p1">
                    <p id="49" class="code-formula">
                        <mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mrow><mo>{</mo><mrow><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mi>l</mi></msub><mo>,</mo><mi>Ζ</mi></mrow><mo>}</mo></mrow></mrow></munder><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mrow><mo stretchy="false">∥</mo><mi>X</mi><msup><mrow></mrow><mi>h</mi></msup><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mfrac><mn>1</mn><mi>Μ</mi></mfrac><mrow><mo stretchy="false">∥</mo><mi>Y</mi><msup><mrow></mrow><mi>l</mi></msup><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>l</mi></msub><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mi>λ</mi><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mi>Μ</mi></mfrac></mrow><mo>)</mo></mrow><mrow><mo stretchy="false">∥</mo><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="50">公式(5)中<i>N</i>和<i>M</i>分别是高分辨率和低分辨率图像块向量形式的维度,公式(5)也可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mrow><mo>{</mo><mrow><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub><mo>,</mo><mi>D</mi><msub><mrow></mrow><mi>l</mi></msub><mo>,</mo><mi>Ζ</mi></mrow><mo>}</mo></mrow></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>X</mi><msub><mrow></mrow><mi>c</mi></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>c</mi></msub><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo>(</mo><mrow><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mi>Μ</mi></mfrac></mrow><mo>)</mo></mrow><mrow><mo stretchy="false">∥</mo><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>X</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mfrac><mn>1</mn><mrow><msqrt><mi>Ν</mi></msqrt></mrow></mfrac><mi>X</mi><msup><mrow></mrow><mi>h</mi></msup></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><msqrt><mi>Μ</mi></msqrt></mrow></mfrac><mi>Y</mi><msup><mrow></mrow><mi>l</mi></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>,</mo><mi>D</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mfrac><mn>1</mn><mrow><msqrt><mi>Ν</mi></msqrt></mrow></mfrac><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><msqrt><mi>Μ</mi></msqrt></mrow></mfrac><mi>D</mi><msub><mrow></mrow><mi>l</mi></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">3 <b>基于稀疏表示的图像超分辨率重建算法设计</b></h3>
                <h4 class="anchor-tag" id="53" name="53">3.1 <b>单幅图像超分辨率重建流程</b></h4>
                <div class="p1">
                    <p id="54">本文提出的超分辨率重建方法,在原有方法基础上加入了字典学习的步骤,经过训练后的高分辨率字典乘以稀疏表示系数,重新构造出高分辨率图像块,组成高分辨率图像.对于一幅给定图像,其超分辨率重建过程如图2所示.</p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910014_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 图像的超分辨率重建过程" src="Detail/GetImg?filename=images/WXYJ201910014_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>图像的超分辨率重建过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910014_055.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="56" name="56">3.2 <b>基于稀疏表示的自然图像超分辨率重建处理</b></h4>
                <h4 class="anchor-tag" id="57" name="57">3.2.1 基于稀疏表示的局部模型</h4>
                <div class="p1">
                    <p id="58">图像块的稀疏表示系数可表示为</p>
                </div>
                <div class="p1">
                    <p id="59">min‖<i>α</i>‖<sub>0</sub> s.t.‖<i>F</i><i><b>D</b></i><sub><i>l</i></sub><i>α</i>-<i>Fy</i>‖<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>≤<i>ε</i>      (8)</p>
                </div>
                <div class="p1">
                    <p id="60">式(8)中图像块<i>x</i>和<i>y</i>的稀疏表示系数一致,<i>F</i>被当做一个线性特征提取算子,它是在式(8)中提供一个在感知上有意义的约束,系数<i>α</i>必须十分逼近<i>y</i>.尽管优化问题在一般情况下都属于NP(non-deterministic polynomial)困难问题,但是只要系数<i>α</i>足够稀疏,就可以通过最小化<i>l</i><sub>1</sub>范数得到恢复,即</p>
                </div>
                <div class="p1">
                    <p id="61">min‖<i>α</i>‖<sub>1</sub> s.t.‖<i>F</i><i><b>D</b></i><sub><i>l</i></sub><i>α</i>-<i>Fy</i>‖<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>≤<i>ε</i>      (9)</p>
                </div>
                <div class="p1">
                    <p id="62">拉格朗日乘子法提供了一个等价的公式</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>α</mi></munder><mrow><mo stretchy="false">∥</mo><mi>F</mi><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>l</mi></msub><mi>α</mi><mo>-</mo><mi>F</mi><mi>y</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>α</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">式(10)中的系数<i>λ</i>是为了平衡一定的稀疏度和对<i>y</i>估计的精准度.这本质上是一种线性回归,在计算的过程中,<i>l</i><sub>1</sub>范数作为惩罚约束把某些待估系数精准地缩小到零.</p>
                </div>
                <div class="p1">
                    <p id="65">对每个局部图像块单独求解公式(10),并不能保证相邻图像块之间的一致性,可使用类似的单通道算法来强化相邻图像块间的一致性<citation id="174" type="reference"><link href="160" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>.图像块在图像中以左上角为开始处,以从左到右、从上到下的水平扫描顺序完成对整个图像块的扫描处理,优化公式(10),使得图像块的超分辨率重建约束为与先前计算的相邻高分辨率图像块相一致.</p>
                </div>
                <div class="p1">
                    <p id="66">min‖<i>α</i>‖<sub>1</sub> s.t.‖<i>F</i><i><b>D</b></i><sub><i>l</i></sub><i>α</i>-<i>Fy</i>‖<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>≤<i>ε</i><sub>1</sub>‖<i>F</i><i><b>D</b></i><sub><i>h</i></sub><i>α</i>-<i>ω</i>‖<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>≤<i>ε</i><sub>2</sub>      (11)</p>
                </div>
                <div class="p1">
                    <p id="68">式(11)表示的是想要的图像块和原始的高分辨率图像所重叠的部分,该式也可表述为</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>α</mi></munder><mrow><mo stretchy="false">∥</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>∼</mo></mover><mi>α</mi><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mo>∼</mo></mover><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>α</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">式(12)中,<image id="129" type="formula" href="images/WXYJ201910014_12900.jpg" display="inline" placement="inline"><alt></alt></image>,β是为了保持高分辨率图像块匹配低分辨率输入和邻域之间的一致性,实验过程中,假设<i>β</i>=1得到最佳系数<i>α</i><sup>*</sup>,则重构后:<i><b>x</b></i>=<i><b>D</b></i><sub><i>h</i></sub><i>α</i><sup>*</sup>.</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">3.2.2 增强全局约束</h4>
                <div class="p1">
                    <p id="74">在实际操作中通常<i><b>y</b></i>≠<i><b>D</b></i><sub><i>l</i></sub><i>α</i>,故式(9)和(11)不强求低分辨率图象块<i>y</i>与其重构<i><b>D</b></i><sub><i>l</i></sub><i>α</i>之间百分百相等.加上噪声<i>m</i>的原因,由前一部分的稀疏表示方法产生的高分辨率图像<i>X</i><sub>0</sub>可能不能完全满足重建约束.为了解决上述情况,可以将<i>X</i><sub>0</sub>反向投影到<i>SHX</i>=<i>Y</i>的解空间,得到</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">X</mi></munder><mrow><mo stretchy="false">∥</mo><mi>S</mi><mi>Η</mi><mi>X</mi><mo>-</mo><mi>Y</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>c</mi><mrow><mo stretchy="false">∥</mo><mi>X</mi><mo>-</mo><mi>X</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">对(13)进行最小化求偏导,多次求解,即可求得最优解,即</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi>ν</mi><mrow><mo>[</mo><mrow><mi>Η</mi><msup><mrow></mrow><mi>Τ</mi></msup><mi>S</mi><msup><mrow></mrow><mi>Τ</mi></msup><mrow><mo>(</mo><mrow><mi>Y</mi><mo>-</mo><mi>S</mi><mi>Η</mi><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mo>)</mo></mrow><mo>+</mo><mi>c</mi><mrow><mo>(</mo><mrow><mi>X</mi><mo>-</mo><mi>X</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">式中,<i>X</i><sub><i>t</i></sub>是高分辨率图像在第<i>t</i>次迭代后的预测结果;<i>ν</i>是梯度下降的步长,是每一步沿梯度负方向走的距离.多次累加后的结果当成对高分辨率图像的最优解<i>X</i><sup>*</sup>.</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">3.2.3 基于稀疏表示的自然图像超分辨率重建算法</h4>
                <div class="p1">
                    <p id="80">稀疏表示的自然图像超分辨率重建算法分为以下四个步骤:</p>
                </div>
                <div class="p1">
                    <p id="81">步骤一、输入训练字典<i>D</i>_<i>h</i>和<i>D</i>_<i>l</i>,一幅低分辨率图像<i>Y</i>;</p>
                </div>
                <div class="p1">
                    <p id="82">步骤二、对每一个由低分辨率图像<i>Y</i>生成的图像块<i>y</i>进行如下操作:</p>
                </div>
                <div class="p1">
                    <p id="83">(1)计算图像块<i>y</i>的像素均值;</p>
                </div>
                <div class="p1">
                    <p id="84">(2)求最佳解问题:<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>min</mi></mrow><msub><mrow></mrow><mi>α</mi></msub><mrow><mo stretchy="false">∥</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>D</mi></mstyle><mo>∼</mo></mover><mi>α</mi><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>y</mi></mstyle><mo>∼</mo></mover><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>α</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>;</p>
                </div>
                <div class="p1">
                    <p id="85">(3)生成一个新的高分辨率图像块<i>x</i>=<i>D</i><sub><i>h</i></sub><i>α</i><sup>*</sup>,将图像块<i>x</i>+<i>m</i>放入<i>X</i><sub>0</sub>中;</p>
                </div>
                <div class="p1">
                    <p id="86">步骤三、利用反向投影法,找到满足重建约束</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></mstyle><mi>X</mi></munder><mrow><mo stretchy="false">∥</mo><mi>S</mi><mi>Η</mi><mi>X</mi><mo>-</mo><mi>Y</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>c</mi><mrow><mo stretchy="false">∥</mo><mi>X</mi><mo>-</mo><mi>X</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">且最近似<i>X</i><sub>0</sub>的图像;</p>
                </div>
                <div class="p1">
                    <p id="89">步骤四、输出超分辨图像<i>X</i><sup>*</sup>,即</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>X</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>X</mi><mo>,</mo><mrow><mo>{</mo><mrow><mi>α</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mo>}</mo></mrow></mrow></munder><mrow><mo>{</mo><mrow><mrow><mo stretchy="false">∥</mo><mi>S</mi><mi>Η</mi><mi>X</mi><mo>-</mo><mi>Y</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><mrow></mrow></mstyle><mrow><mo stretchy="false">∥</mo><mi>α</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mi>γ</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></munder><mrow></mrow></mstyle><mrow><mo stretchy="false">∥</mo><mi>D</mi><msub><mrow></mrow><mi>h</mi></msub><mi>α</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>X</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>τ</mi><mi>ρ</mi><mrow><mo>(</mo><mi>X</mi><mo>)</mo></mrow></mrow><mo>}</mo></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h3 id="91" name="91" class="anchor-tag">4 <b>实验与分析</b></h3>
                <div class="p1">
                    <p id="92">为了证明本文方法的有效性,在实验中,选择传统方法中效果较好的双三次插值方法与本文方法进行比较,并给出相同条件下的主观质量和客观质量对比.</p>
                </div>
                <div class="p1">
                    <p id="93">在图3中,图3(<i>a</i>)-(<i>c</i>)为不同场景下的低分辨率图像,图3(<i>d</i>)-(<i>f</i>)是对应的高分辨率图像.对这些测试图像,分别采用双三次插值和本文方法进行实验仿真,得到的超分辨率重建结果如图4-6所示.</p>
                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910014_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 实验中采用的测试图像" src="Detail/GetImg?filename=images/WXYJ201910014_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 实验中采用的测试图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910014_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910014_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同方法对plant图像的重建结果" src="Detail/GetImg?filename=images/WXYJ201910014_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同方法对plant图像的重建结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910014_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>
                                <p class="img_note">a）双三次插值方法b）本文方法</p>

                </div>
                <div class="p1">
                    <p id="100">图4-图6中,<i>a</i>)均是采用双三次插值方法,<i>b</i>)均是采用本文提出的方法.可见,采用本文方法能得到视觉效果更好的超分辨率图像.为更全面的对算法进行评价,下面将从客观指标的角度,对双三次插值方法和本文方法进行比较.对每幅测试图像,分别采用双三次插值方法及本文方法,得到的均方根误差(<i>Root mean square error</i>, <i>RMSE</i>)和峰值信噪比(<i>Peak signal to noise ratio</i>, <i>PSNR</i>)结果见表1.</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910014_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同方法对girl图像的重建结果" src="Detail/GetImg?filename=images/WXYJ201910014_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同方法对girl图像的重建结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910014_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>
                                <p class="img_note">a）双三次插值方法b）本文方法</p>

                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910014_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同方法对leaf图像的重建结果" src="Detail/GetImg?filename=images/WXYJ201910014_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同方法对leaf图像的重建结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910014_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>
                                <p class="img_note">a）双三次插值方法b）本文方法</p>

                </div>
                <div class="area_img" id="101">
                    <p class="img_tit"><b>表</b>1 <b>实验图像重建后项指标数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="101" border="1"><tr><td><br />测试图像</td><td colspan="2">双三次插值法</td><td colspan="2">本文方法</td></tr><tr><td><br />客观指标</td><td><i>RMSE</i></td><td><i>PSNR</i></td><td><i>RMSE</i></td><td><i>PSNR</i></td></tr><tr><td><br /><i>plant</i></td><td>4.19</td><td>35.71</td><td>4.16</td><td>35.75</td></tr><tr><td><br /><i>girl</i></td><td>8.47</td><td>29.57</td><td>8.10</td><td>29.96</td></tr><tr><td><br /><i>leaf</i></td><td>12.68</td><td>26.07</td><td>12.22</td><td>26.39</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="102">由图4-图6,以及表1可知,将两种方法的重建结果进行比较,不管是主观视觉效果,还是客观指标的均方根误差和峰值信噪比,均可以看出,本文方法能获得更好的超分辨率重建图像质量.</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">5 <b>结束语</b></h3>
                <div class="p1">
                    <p id="104">本文通过使用低、高分辨率特征块进行字典训练,再将训练得到的系数应用于低分辨率图像块中,从而完成图像的超分辨率重建的过程,较好地解决了传统算法易导致重建图像边缘模糊、效果差的问题.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="134">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image reconstruction is a new frontier of machine learning">

                                <b>[1]</b> WANG G,YE J C,MUELLER K,et al.Image Reconstruction is a New Frontier of Machine Learning[J].IEEE Transactions on Medical Imaging,2018,37(6):1289-1296.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Example-based Image Colorization Using Locality Consistent Sparse Representation">

                                <b>[2]</b> LI B,ZHAO F,SU Z,et al.Example-based Image Colorization using Locality Consistent Sparse Representation[J].IEEE Transactions on Image Processing,2017,26(11):5188-5202.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWJS201201006&amp;v=MTY1NDFyQ1VSTE9lWmVWdkZDamtWN3JBTFRyQmZiRzRIOVBNcm85RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 江静,张雪松.图像超分辨率重建算法综述[J].红外技术,2012,34(1):24-30.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201716004&amp;v=MDQ4MzMzenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFMejdNYWJHNEg5Yk5xWTlGWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 曾凯,丁世飞.图像超分辨率重建的研究进展[J].计算机工程与应用,2017,53(16):29-35.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201809043&amp;v=MzExMTVxcUJ0R0ZyQ1VSTE9lWmVWdkZDamtWN3JBTHo3QmQ3RzRIOW5NcG85Qlo0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 高媛,刘志,秦品乐,等.基于深度残差生成对抗网络的医学影像超分辨率算法[J].计算机应用,2018,38(9):2689-2695.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXJS200403036&amp;v=MDQ2MzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGQ2prVjdyQUlqWEJmYkc0SHRYTXJJOUdZb1E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 孔玲莉,黄华,齐春.图像超分辨率研究的最新进展[J].光学技术,2014,30(3):374-377.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution via sparse representation">

                                <b>[7]</b> YANG J,WRIGHT J,HUANG T S,et al.Image super-resolution via sparse representation.[J].IEEETransactions on Image Processing,2010,19(11):2861-2873.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization">

                                <b>[8]</b> DONG W,ZHANG L,SHI G,et al.Image Deblurring and Super-resolution by Adaptive Sparse Domain Selection and Adaptive Regularization[J].IEEETransactions on Image Processing,2011,20(7):1837-1857.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201706021&amp;v=Mjk2NThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFNalhTWkxHNEg5Yk1xWTlIWlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 马杰,武利涛,张晓严.一种改进的组稀疏表示图像去噪方法[J].微电子学与计算机,2017,34(6):99-103.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Reconstruction in Electrical Impedance Tomography Based on Structure-Aware Sparse Bayesian Learning">

                                <b>[10]</b> LIU S,JIA J,ZHANG Y D,et al.Image Reconstruction in Electrical Impedance Tomography Based on Structure-Aware Sparse Bayesian Learning[J].IEEE Transactions on Medical Imaging,2018,37(9):2090-2101.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201801019&amp;v=MjI3MDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFNalhTWkxHNEg5bk1ybzlFYllRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 隋昊,周萍,沈昊,等.基于混沌序列的压缩感知语音增强算法[J].微电子学与计算机,2018,35(1):96-99.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYD201012040&amp;v=MDk5MzA1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFQVG5TYXJHNEg5SE5yWTlCWklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 孙玉宝,韦志辉,肖亮,等.基于稀疏表示的图像超分辨率重建快速算法[J].系统工程与电子技术,2010,32(12):2696-2700.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201705013&amp;v=MTM5Nzc3ckFLQ0xmWWJHNEg5Yk1xbzlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 胡长胜,詹曙,吴从中.基于深度特征学习的图像超分辨率重建[J].自动化学报,2017,43(5):814-821.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Example-based super-resolution">

                                <b>[14]</b> FREEMAN W T,JONES T R,PASZTOR E C.Example-Based Super-Resolution[J].IEEE Computer Graphics and Applications,2002,22(2):56-65.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="WXYJ201910014" />
        <input id="dpi" type="hidden" value="800" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201910014&amp;v=MTY5NDR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3ckFNalhTWkxHNEg5ak5yNDlFWUlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
