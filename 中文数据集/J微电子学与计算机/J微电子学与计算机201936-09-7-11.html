<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133836670568750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dWXYJ201909002%26RESULT%3d1%26SIGN%3d%252fYrYn7KvNdE%252fxRnZo9uwlqqbfZU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201909002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201909002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201909002&amp;v=MTQ2NzlHRnJDVVJMT2VaZVZ1Rnlua1ZickJNalhTWkxHNEg5ak1wbzlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#25" data-title="1 &lt;b&gt;引言&lt;/b&gt; ">1 <b>引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="2 MobileNet&lt;b&gt;结构思想原理&lt;/b&gt; ">2 MobileNet<b>结构思想原理</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="3 &lt;b&gt;加速器设计方案&lt;/b&gt; ">3 <b>加速器设计方案</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="3.1 CNN&lt;b&gt;结构框架&lt;/b&gt;">3.1 CNN<b>结构框架</b></a></li>
                                                <li><a href="#61" data-title="3.2 &lt;b&gt;系统硬件结构&lt;/b&gt;">3.2 <b>系统硬件结构</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#91" data-title="4 &lt;b&gt;实验结果及分析&lt;/b&gt; ">4 <b>实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#92" data-title="4.1 &lt;b&gt;实验环境&lt;/b&gt;">4.1 <b>实验环境</b></a></li>
                                                <li><a href="#97" data-title="4.2 &lt;b&gt;实验结果&lt;/b&gt;">4.2 <b>实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="5 &lt;b&gt;结束语&lt;/b&gt; ">5 <b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#29" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;主流&lt;/b&gt;CNN&lt;b&gt;结构的计算量和参数量&lt;/b&gt;"><b>表</b>1 <b>主流</b>CNN<b>结构的计算量和参数量</b></a></li>
                                                <li><a href="#37" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;传统卷积过程和深度可分离卷积过程&lt;/b&gt;"><b>图</b>1 <b>传统卷积过程和深度可分离卷积过程</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;常规网络结构&lt;/b&gt;"><b>图</b>2 <b>常规网络结构</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;图&lt;/b&gt;3 &lt;b&gt;改进网络结构&lt;/b&gt;"><b>图</b>3 <b>改进网络结构</b></a></li>
                                                <li><a href="#63" data-title="&lt;b&gt;图&lt;/b&gt;4 &lt;b&gt;常规网络硬件框图&lt;/b&gt;"><b>图</b>4 <b>常规网络硬件框图</b></a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;图&lt;/b&gt;5 &lt;b&gt;第二层卷积计算模块一分为二&lt;/b&gt;"><b>图</b>5 <b>第二层卷积计算模块一分为二</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;图&lt;/b&gt;6 &lt;b&gt;窗口产生模块&lt;/b&gt;"><b>图</b>6 <b>窗口产生模块</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;图&lt;/b&gt;7 &lt;b&gt;卷积计算模块&lt;/b&gt;"><b>图</b>7 <b>卷积计算模块</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;图&lt;/b&gt;8 &lt;b&gt;全连接模块&lt;/b&gt;"><b>图</b>8 <b>全连接模块</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;表&lt;/b&gt;2 FPGA&lt;b&gt;资源消耗对比&lt;/b&gt;"><b>表</b>2 FPGA<b>资源消耗对比</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;不同平台不同结构下&lt;/b&gt;CNN&lt;b&gt;的运行速度对比&lt;/b&gt;"><b>表</b>3 <b>不同平台不同结构下</b>CNN<b>的运行速度对比</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;表&lt;/b&gt;4 FPGA&lt;b&gt;功耗对比&lt;/b&gt;"><b>表</b>4 FPGA<b>功耗对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" YU K,JIA L,CHEN Y,et al.Deep learning:yesterday,today,and tomorrow[J].Journal of computer Research and Development,2013,50(9):1799-1804." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201309002&amp;v=MDA4MTE0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5rVmJyQkx5dlNkTEc0SDlMTXBvOUZab1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         YU K,JIA L,CHEN Y,et al.Deep learning:yesterday,today,and tomorrow[J].Journal of computer Research and Development,2013,50(9):1799-1804.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" >
                                        <b>[2]</b>
                                     SIMONYAN K,ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].Computer Science - Computer Vision and Pattern Recognition ,arXiv preprint arXiv:1409.1556,2014.</a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.Boston,IEEE,2015:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">
                                        <b>[3]</b>
                                         SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.Boston,IEEE,2015:1-9.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C]/ /Proceedings of the IEEE conference on computer vision and pattern recognition.Las Vegas:IEEE,2016:770 778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">
                                        <b>[4]</b>
                                         HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C]/ /Proceedings of the IEEE conference on computer vision and pattern recognition.Las Vegas:IEEE,2016:770 778.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 陈雯柏.人工神经网络原理与实践[M].西安:西安电子科技大学出版社,2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787560639338000&amp;v=MzIzNThFOWZidm5LcmlmWnU5dUZDcmxVNzdKSmxzZFhGcXpHYmErSHRmUHBveEdiT3NQREJNOHp4VVNtRGQ5U0g3bjN4&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         陈雯柏.人工神经网络原理与实践[M].西安:西安电子科技大学出版社,2016.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" LACEY G,TAYLOR G W,AREIBI S.Deep learning on fpgas:past,present,and future[J].arXiv preprint arXiv:1602.04283,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning on fpgas:past,present,and future">
                                        <b>[6]</b>
                                         LACEY G,TAYLOR G W,AREIBI S.Deep learning on fpgas:past,present,and future[J].arXiv preprint arXiv:1602.04283,2016.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" JIA Y,SHELHAMER E,DONAHUE J,et al.Caffe:convolutional architecture for fast feature embedding[C]// Proceedings of the 22nd ACM international conference on Multimedia.Orlando,Florida:ACM,2014:675-678." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Caffe:convolutional architecture for fast feature embedding">
                                        <b>[7]</b>
                                         JIA Y,SHELHAMER E,DONAHUE J,et al.Caffe:convolutional architecture for fast feature embedding[C]// Proceedings of the 22nd ACM international conference on Multimedia.Orlando,Florida:ACM,2014:675-678.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" QIU J,WANG J,YAO S,et al.Going deeper with embedded fpga platform for convolutional neural network[C]// Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.Monterey:ACM,2016:26-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with embedded FPGA platform for convolutional neural network">
                                        <b>[8]</b>
                                         QIU J,WANG J,YAO S,et al.Going deeper with embedded fpga platform for convolutional neural network[C]// Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.Monterey:ACM,2016:26-35.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" HOWARD A G,ZHU M,CHEN B,et al.Mobilenets:efficient convolutional neural networks for mobile vision applications[J].arXiv preprint arXiv:1704.04861,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mobilenets:efficient convolutional neural networks for mobile vision applications">
                                        <b>[9]</b>
                                         HOWARD A G,ZHU M,CHEN B,et al.Mobilenets:efficient convolutional neural networks for mobile vision applications[J].arXiv preprint arXiv:1704.04861,2017.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 方睿,刘加贺,薛志辉,等.卷积神经网络的FPGA并行加速方案设计[J].计算机工程与应用,2015,51(8):32-36." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201508008&amp;v=MjEyNDF6N01hYkc0SDlUTXA0OUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5rVmJyQkw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         方睿,刘加贺,薛志辉,等.卷积神经网络的FPGA并行加速方案设计[J].计算机工程与应用,2015,51(8):32-36.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" LECUN Y L,BOTTOU L,BENGIO Y,et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE,1998,86(11):2278-2324." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gradient-based learning applied to document recognition">
                                        <b>[11]</b>
                                         LECUN Y L,BOTTOU L,BENGIO Y,et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE,1998,86(11):2278-2324.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=WXYJ" target="_blank">微电子学与计算机</a>
                2019,36(09),7-11             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种移动卷积神经网络的FPGA实现</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%82%B3%E8%BE%B0&amp;code=42764123&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李炳辰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E9%B2%81&amp;code=09505043&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄鲁</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E5%BE%AE%E7%94%B5%E5%AD%90%E5%AD%A6%E9%99%A2&amp;code=0002522&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学技术大学微电子学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>卷积神经网络是深度学习的一种重要模型,广泛应用于图像处理等领域.常用的神经网络模型因结构复杂,参数众多,不适于放在移动端运行.本文基于模块化和硬件复用的思想,给出了一种基于FPGA的手写数字字符识别网络的硬件实现,基于MobileNet的原理改进结构,在实现了算法硬件加速的同时,有效地降低了网络的参数数量和整体运算量.基于MNIST数据集的实验结果表明,对比传统结构的神经网络,改进结构的参数量减少了23.26%,计算量减少了31.32%,在保持速度不变的前提下,用更少的资源和更低的功耗实现了整个网络.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=FPGA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">FPGA;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">硬件加速;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=MobileNet&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">MobileNet;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A7%BB%E5%8A%A8%E7%AB%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">移动端;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李炳辰,男,(1995-),硕士.研究方向为FPGA算法加速.E-mail:hnlibc@mail.ustc.edu.cn.;
                                </span>
                                <span>
                                    黄鲁,男,(1961-),硕士,副教授.研究方向为数模混合高速接口集成电路设计.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然基金面上项目(61874102);</span>
                    </p>
            </div>
                    <h1><b>Hardware implementation of a convolutional neural network for mobile terminal based on FPGA</b></h1>
                    <h2>
                    <span>LI Bing-chen</span>
                    <span>HUANG Lu</span>
            </h2>
                    <h2>
                    <span>School of Microelectronics, University of Science and Technology of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Convolutional neural networks are an important model of deep learning and are widely used in image processing and other fields. The commonly used neural network model is complex and has many parameters, which is not suitable for running on the mobile end. Based on the idea of modularization and hardware reuse, this paper presents a hardware implementation of handwritten digital character recognition network based on FPGA. Based on the principle of MobileNet, the structure is improved, and the algorithm hardware acceleration is realized, and the number of parameters of the network and the overall calculation amount are effectively reduced. The experimental results based on the MNIST dataset show that compared with the traditional neural network, the parameter size of the improved structure is reduced by 23.26%, and the calculation amount is reduced by 31.32%. The entire network is implemented with less resources and lower power consumption while maintaining the same speed.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=FPGA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">FPGA;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=hardware%20acceleration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">hardware acceleration;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=MobileNet&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">MobileNet;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=mobile%20terminal&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">mobile terminal;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-20</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="25" name="25" class="anchor-tag">1 <b>引言</b></h3>
                <div class="p1">
                    <p id="26">卷积神经网络(CNN)是深度学习的一种重要模型,因其高度的适应性和出色的识别能力,广泛应用于分类识别、目标检测、目标跟踪等领域<citation id="107" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.目前最常用的CNN结构有VGG<citation id="108" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、GoogleNet<citation id="109" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、ResNet<citation id="110" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等.</p>
                </div>
                <div class="p1">
                    <p id="27">CNN的成功崛起得益于自身结构的优势,以及处理器性能的提升.CNN采用权值共享的结构,降低了模型的复杂度,减少了权值的数量,提高了网络的整体性能<citation id="111" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>;处理器性能的提升,让CNN向更深的层次、更大的结构迈进,从而使其能够胜任更多更复杂的场景.</p>
                </div>
                <div class="p1">
                    <p id="28">虽然基于FPGA实现CNN的相关研究进展很多<citation id="112" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>,但目前CNN依然主要部署在CPU或GPU集群上<citation id="113" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>.传统结构的CNN在计算量、存储空间以及能耗方面的巨大需求<citation id="114" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>,令移动和车载终端难以承受,如表1所示.</p>
                </div>
                <div class="area_img" id="29">
                    <p class="img_tit"><b>表</b>1 <b>主流</b>CNN<b>结构的计算量和参数量</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="29" border="1"><tr><td><br />模型</td><td>GoogleNet</td><td>VGG16</td><td>ResNet50</td></tr><tr><td><br />计算量</td><td>1.58G</td><td>15.5G</td><td>3.86G</td></tr><tr><td><br />参数量</td><td>6.99M</td><td>138M</td><td>25.5M</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="30">基于以上原因,一些团队和个人着手进行网络结构小型化的研究工作.其中谷歌提出的MobileNet结构<citation id="115" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,在几乎不影响准确度的情况下,理论上能实现卷积参数量近90%的减少,为CNN在终端的普及找出了一种实用的技术方案.</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag">2 MobileNet<b>结构思想原理</b></h3>
                <div class="p1">
                    <p id="32">MobileNet的核心思想是使用深度可分离卷积(depth-wise separable convolution)结构来代替传统的3D卷积,该结构进一步减少了参数的冗余度,网络的计算量和参数量明显下降,使得卷积网络可以更广泛的应用在移动端平台上.</p>
                </div>
                <div class="p1">
                    <p id="33">深度可分离卷及结构的思想如下:</p>
                </div>
                <div class="p1">
                    <p id="34">(1)如图1(<i>a</i>)所示,传统卷积结构,假设<i>M</i>为输入的通道数,<i>D</i><sub><i>F</i></sub>为输出的宽和高,<i>D</i><sub><i>K</i></sub>为卷积核的宽和高,那么<i>N</i>个卷积核处理完全部输入后总的计算量为</p>
                </div>
                <div class="p1">
                    <p id="35"><i>D</i><sub><i>K</i></sub>×<i>D</i><sub><i>K</i></sub>×<i>M</i>×<i>N</i>×<i>D</i><sub><i>F</i></sub>×<i>D</i><sub><i>F</i></sub>      (1)</p>
                </div>
                <div class="p1">
                    <p id="36">(2)如图1(<i>b</i>)所示,深度可分离卷积结构,先用一组二维的卷积核进行卷积计算,每个卷积核处理一个输入通道的数据,此步骤的计算量为</p>
                </div>
                <div class="area_img" id="37">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_037.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 传统卷积过程和深度可分离卷积过程" src="Detail/GetImg?filename=images/WXYJ201909002_037.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>传统卷积过程和深度可分离卷积过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_037.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="38">D<sub>K</sub>×D<sub>K</sub>×M×1×D<sub>F</sub>×D<sub>F</sub>      (2)</p>
                </div>
                <div class="p1">
                    <p id="39">第一步处理完之后,再用一组三维的1*1卷积核来处理前一步的结果,最终实现和传统卷积相同的输出,则此步骤的计算量为</p>
                </div>
                <div class="p1">
                    <p id="40">1×1×M×N×D<sub>F</sub>×D<sub>F</sub>      (3)</p>
                </div>
                <div class="p1">
                    <p id="41">所以深度可分离卷积结构总的计算量为</p>
                </div>
                <div class="p1">
                    <p id="42">D<sub>K</sub>×D<sub>K</sub>×M×D<sub>F</sub>×D<sub>F</sub>+M×N×D<sub>F</sub>×D<sub>F</sub>      (4)</p>
                </div>
                <div class="p1">
                    <p id="43">(3)综上可得,深度可分离卷积结构的计算量是传统卷积结构的</p>
                </div>
                <div class="p1">
                    <p id="44" class="code-formula">
                        <mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mtext>D</mtext><msub><mrow></mrow><mtext>Κ</mtext></msub><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>Κ</mtext></msub><mo>×</mo><mtext>Μ</mtext><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>F</mtext></msub><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>F</mtext></msub><mo>+</mo><mtext>Μ</mtext><mo>×</mo><mtext>Ν</mtext><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>F</mtext></msub><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>F</mtext></msub></mrow><mrow><mtext>D</mtext><msub><mrow></mrow><mtext>Κ</mtext></msub><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>Κ</mtext></msub><mo>×</mo><mtext>Μ</mtext><mo>×</mo><mtext>Ν</mtext><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>F</mtext></msub><mo>×</mo><mtext>D</mtext><msub><mrow></mrow><mtext>F</mtext></msub></mrow></mfrac><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mtext>Ν</mtext></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mtext>D</mtext><msubsup><mrow></mrow><mtext>Κ</mtext><mn>2</mn></msubsup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="45">根据上述结论可知,卷积网络的通道数越多、卷积核越大,计算量减少的越明显.</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag">3 <b>加速器设计方案</b></h3>
                <h4 class="anchor-tag" id="47" name="47">3.1 CNN<b>结构框架</b></h4>
                <div class="p1">
                    <p id="48">本文采用的CNN结构如下:</p>
                </div>
                <div class="p1">
                    <p id="49">Input layer: 28 × 28;</p>
                </div>
                <div class="p1">
                    <p id="50">Conv1: 3 kernels, size 5×5, padding = 0, stride = 1;</p>
                </div>
                <div class="p1">
                    <p id="51">Maxpooling1 : size 2 × 2 , stride = 2;</p>
                </div>
                <div class="p1">
                    <p id="52">Conv2: 6 kernels, size 5×5, padding = 0, stride = 1;</p>
                </div>
                <div class="p1">
                    <p id="53">Maxpooling2 : size 2 × 2 , stride = 2;</p>
                </div>
                <div class="p1">
                    <p id="54">Fc: 10 parameters;</p>
                </div>
                <div class="p1">
                    <p id="55">Softmax: classification result;</p>
                </div>
                <div class="p1">
                    <p id="56">具体模型如图2所示.</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 常规网络结构" src="Detail/GetImg?filename=images/WXYJ201909002_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>常规网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_057.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="58">图3是改进后的结构.因为第一个卷积层的输入通道数是1,不需要进行改进,所以只把第二个卷积层改成了深度可分离卷积结构.</p>
                </div>
                <div class="p1">
                    <p id="59">经过改进,进行单次分类识别时,整个卷积网络的参数量从1 522个减少为1 168个,减少了23.26%;计算量从72 960次减少为50 112次,减少了31.32%,效果十分显著.</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 改进网络结构" src="Detail/GetImg?filename=images/WXYJ201909002_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 <b>改进网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_060.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="61" name="61">3.2 <b>系统硬件结构</b></h4>
                <div class="p1">
                    <p id="62">本文采用模块化的方式来实现卷积神经网络的总体硬件架构,包括窗口产生模块、卷积计算模块、激活和池化模块、全连接模块以及softmax模块.具体的实现如图4所示.</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_063.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 常规网络硬件框图" src="Detail/GetImg?filename=images/WXYJ201909002_063.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>4 <b>常规网络硬件框图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_063.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="64">图4中箭头代表着数据的流向;图中第一行各个模块组成第一层卷积层,第二行各个模块组成第二层卷积层;部分模块堆叠在一起,代表着它们之间是并行处理的关系.</p>
                </div>
                <div class="p1">
                    <p id="65">改进结构是在此基础上把第二层的卷积计算模块一分为二,具体变动如图5所示.</p>
                </div>
                <div class="area_img" id="66">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_066.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 第二层卷积计算模块一分为二" src="Detail/GetImg?filename=images/WXYJ201909002_066.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>5 <b>第二层卷积计算模块一分为二</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_066.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="67">使用模块化的设计方案,能够根据框架调整,方便快捷的调用相应的模块,而不再需要重新编写整个网络,从而大大减小开发周期.这将在下面针对各个模块的详细介绍中体现出来.</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68">3.2.1 窗口产生模块</h4>
                <div class="p1">
                    <p id="69">顾名思义,窗口产生模块用来产生卷积滑动窗口.它主要由4位宽为16的FIFO组成,用以把串行输入的图像数据,变成5×5并行窗口数据.该模块的具体结构如图6所示.</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 窗口产生模块" src="Detail/GetImg?filename=images/WXYJ201909002_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>6 <b>窗口产生模块</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_070.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="71">第一层的窗口产生模块中FIFO的深度为28,第二层的窗口产生模块中FIFO的深度为12.</p>
                </div>
                <div class="p1">
                    <p id="72">本文把窗口产生模块和卷积计算模块拆开,共有两个好处:一是结构适应性强,改进结构能直接复用模块.二是改进结构包含大量1×1的卷积计算,其计算过程和全连接计算相同,把窗口模块和计算模块分开,就能复用1×1卷积计算模块和全连接计算模块,进一步简化了工作.</p>
                </div>
                <h4 class="anchor-tag" id="73" name="73">3.2.2 卷积计算模块</h4>
                <div class="p1">
                    <p id="74">卷积计算模块是整个网络的核心模块.图7是单个卷积核的内部结构.该结构由25个乘法器和24个加法器组成,每个时钟周期输入5×5都能输出一个卷积计算结果.</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_075.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 卷积计算模块" src="Detail/GetImg?filename=images/WXYJ201909002_075.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>7 <b>卷积计算模块</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_075.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="76">该结构的优点很明显,串行处理器实现一个5×5的卷积计算至少需要49个周期,该结构只需一个时钟周期,利用面积换速度的方法实现了硬件加速.</p>
                </div>
                <div class="p1">
                    <p id="77">在Conv2层,数据在到来之前经过了一个池化层,所以该模块每两个时钟周期才到来一组窗口数据.本文将到来的数据平分到这两个周期中计算,硬件采用分时复用的方式,既不会对网络的运行速度造成影响,又节约了一半的乘法器.</p>
                </div>
                <div class="p1">
                    <p id="78">经过计算,该方案在常规网络中节约了225个乘法器,在改进网络中节约了46个乘法器.</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79">3.2.3 激活函数和池化模块</h4>
                <div class="p1">
                    <p id="80">本文采用最大池化,并用relu函数作为激活函数,relu的表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd><mn>0</mn><mo>,</mo></mtd><mtd><mi>x</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>x</mi><mo>,</mo></mtd><mtd><mi>x</mi><mo>≥</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">从式(6)可以看出,一个比较器就能完成激活运算.因此本文将激活函数和最大池化放到了一个模块里,用3个比较器完成了激活池化运算.</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83">3.2.4 全连接模块</h4>
                <div class="p1">
                    <p id="84">全连接模块也是重点设计的一个模块.全连接层要到来4×4×6一共96个数据,每个数据需要进行10次乘法运算.文献<citation id="116" type="reference">[<a class="sup">10</a>]</citation>使用了960个乘法器来完成这些运算.</p>
                </div>
                <div class="p1">
                    <p id="85">但仔细分析数据流就能发现,数据在到达全连接层之前经过了两个池化层,因此每4时钟个周期到来一组数据,分4×4次到来,即全部数据需要64个周期才能全部到来.文献<citation id="117" type="reference">[<a class="sup">11</a>]</citation>使用的960个乘法器在64个周期中只计算一次,因此存在很大的优化空间.本文基于数据流的这种规律,设计了图8所示的全连接模块,一共使用15个乘法器,采用分时复用的方式,在全部的64个周期都进行处理分批次到来的数据,在不影响整个网络的运行速度的前提下,用1/64的乘法器达到了和文献<citation id="118" type="reference">[<a class="sup">10</a>]</citation>同样的效果,极大地节省了资源.</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201909002_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 全连接模块" src="Detail/GetImg?filename=images/WXYJ201909002_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>8 <b>全连接模块</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201909002_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="87" name="87">3.2.5 softmax模块</h4>
                <div class="p1">
                    <p id="88">几乎所有多分类(识别种类在两个以上)网络的最后都是softmax层,softmax的公式如下</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>e</mi><msup><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><mi>e</mi></mstyle><msup><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">对于<i>n</i>分类网络,一个前项传播过程要输出<i>n</i>个结果,分别和<i>n</i>个种类一一对应.softmax的作用就是把这些输出归一化为[0,1]之间的实数,让它们的和为1,即概率之和为1.softmax层能很好的提高反向传播时的训练效率,但是在前向传播时则没有必要.实质上前向传播分类时,只需找出值最大的那一项就能确定网络最终的输出,因此本文用比较器阵列取代了复杂的指数运算,实现最终的输出.</p>
                </div>
                <h3 id="91" name="91" class="anchor-tag">4 <b>实验结果及分析</b></h3>
                <h4 class="anchor-tag" id="92" name="92">4.1 <b>实验环境</b></h4>
                <div class="p1">
                    <p id="93">本文实验使用Xlinx公司Spartan6系列xc6slx45芯片作为硬件平台,使用ISE14.7软件和Verilog语言进行开发和测试.</p>
                </div>
                <div class="p1">
                    <p id="94">本文实验采用MNIST数据集作为手写数字字符识别的输入图像<citation id="119" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,该数据集包含60 000张训练图像和10 000张测试图像,每张图像为单通道灰度图像,大小为28*28,每个像素的取值在 0～255 的整数范围,在实验进行前,对该数据集进行了初始化,使得输入的数值范围变为 [0,1].</p>
                </div>
                <div class="p1">
                    <p id="95">在通用CPU平台上用软件实现了与FPGA完全一致的CNN模型,用于对比.CPU采用Intel Core i5-7500四核处理器,主频为3.4 GHz.软件开发环境是在基于Python的Keras库,该环境专门针对简易和快速的原型设计进行了优化.</p>
                </div>
                <div class="p1">
                    <p id="96">FPGA上只完成前向传播过程,即只分类,不训练.整个网络是在CPU上用Keras来训练的,训练完成后,将权重进行16位定点化并下载到FPGA板上RAM中,供FPGA使用.</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">4.2 <b>实验结果</b></h4>
                <div class="p1">
                    <p id="98">表2列出了FPGA的资源使用情况.本文通过资源复用,用更少的乘法器(315对1 485)和Register资源达到了文献<citation id="120" type="reference">[<a class="sup">10</a>]</citation>同样的效果;由于本文使用的FPGA中的DSP资源较少,需要用LUT综合出乘法器,所以使用了较多的LUT资源.</p>
                </div>
                <div class="area_img" id="99">
                    <p class="img_tit"><b>表</b>2 FPGA<b>资源消耗对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td rowspan="2"><br />模块</td><td colspan="3"><br />资源使用数</td></tr><tr><td><br />文献网络</td><td>本文常规网络</td><td>本文改进网络</td></tr><tr><td><br />Registers</td><td>64 364</td><td>4 665</td><td>4 775</td></tr><tr><td><br />LUTs</td><td>10 078</td><td>14 089</td><td>10 355</td></tr><tr><td><br />RAM</td><td>23</td><td>27</td><td>27</td></tr><tr><td><br />DSPs</td><td>1 485</td><td>58</td><td>58</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="100">表3是不同平台不同结构下CNN运行速度的对比.本文常规网络在CPU上运行了61.33秒,约是文献<citation id="121" type="reference">[<a class="sup">10</a>]</citation>的两倍,速度差距与CPU性能差距相同.本文FPGA的工作频率为50 MHz,与文献<citation id="122" type="reference">[<a class="sup">10</a>]</citation>相同,但本文方案在FPGA上运行的时间更短.改进网络在FPGA上的运行速度和常规网络一致,与预期相符.</p>
                </div>
                <div class="area_img" id="101">
                    <p class="img_tit"><b>表</b>3 <b>不同平台不同结构下</b>CNN<b>的运行速度对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="101" border="1"><tr><td><br />平台</td><td>图像/迭代</td><td>时间/s</td></tr><tr><td><br />参考文献 CPU</td><td rowspan="6">60 000</td><td><br />34.02</td></tr><tr><td><br />参考文献FPGA</td><td><br />4.33</td></tr><tr><td><br />本文 CPU &amp; 常规网络</td><td><br />61.33</td></tr><tr><td><br />本文 CPU &amp; 改进网络</td><td><br />97.52</td></tr><tr><td><br />本文FPGA &amp; 常规网络</td><td><br />2.37</td></tr><tr><td><br />本文FPGA &amp; 改进网络</td><td><br />2.53</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="102">本文使用Xilinx公司提供的Xilinx Power Estimator(XPE)工具来估测FPGA芯片的功耗,具体表现如表4.文献<citation id="123" type="reference">[<a class="sup">10</a>]</citation>的功耗达到了60 W,本文的两种网络都不到2 W,这里只对比本文的两种网络.可以看到,在只改进一层卷积层的情况下,改进网络就有6.74%的功耗降低,将应用到更大规模的网络上将有更好的表现,这对将神经网络移植到移动设备上有重大意义.</p>
                </div>
                <div class="area_img" id="103">
                    <p class="img_tit"><b>表</b>4 FPGA<b>功耗对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="103" border="1"><tr><td><br />平台</td><td>功耗/W</td></tr><tr><td><br />参考文献</td><td>60</td></tr><tr><td><br />常规网络</td><td>1.78</td></tr><tr><td><br />改进网络</td><td>1.66</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="104">综上,本文所提出的网络,在资源消耗、运行速度和能耗方面都有着优于文献<citation id="124" type="reference">[<a class="sup">10</a>]</citation>的表现.</p>
                </div>
                <h3 id="105" name="105" class="anchor-tag">5 <b>结束语</b></h3>
                <div class="p1">
                    <p id="106">本文提出了一种基于FPGA的卷积神经网络硬件实现方案.实验结果表明,针对输入大小为28*28的手写数字字符识别,该方案充分发挥FPGA硬件平台的并行执行优势,并且兼顾硬件资源的复用.相比参考文献,该方案充分挖掘CNN的结构特点,优化数据流程,复用硬件电路,以更少的资源和更低的功耗实现了更快的分类识别.该方案采取模块化设计,对FPGA实现卷积神经网络得加速具有一定的通用性和重要意义.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201309002&amp;v=MjA3NzNvOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5rVmJyQkx5dlNkTEc0SDlMTXA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> YU K,JIA L,CHEN Y,et al.Deep learning:yesterday,today,and tomorrow[J].Journal of computer Research and Development,2013,50(9):1799-1804.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" >
                                    <b>[2]</b>
                                 SIMONYAN K,ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J].Computer Science - Computer Vision and Pattern Recognition ,arXiv preprint arXiv:1409.1556,2014.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">

                                <b>[3]</b> SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.Boston,IEEE,2015:1-9.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">

                                <b>[4]</b> HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C]/ /Proceedings of the IEEE conference on computer vision and pattern recognition.Las Vegas:IEEE,2016:770 778.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787560639338000&amp;v=MTQwNTN4RTlmYnZuS3JpZlp1OXVGQ3JsVTc3Skpsc2RYRnF6R2JhK0h0ZlBwb3hHYk9zUERCTTh6eFVTbURkOVNIN24z&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 陈雯柏.人工神经网络原理与实践[M].西安:西安电子科技大学出版社,2016.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning on fpgas:past,present,and future">

                                <b>[6]</b> LACEY G,TAYLOR G W,AREIBI S.Deep learning on fpgas:past,present,and future[J].arXiv preprint arXiv:1602.04283,2016.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Caffe:convolutional architecture for fast feature embedding">

                                <b>[7]</b> JIA Y,SHELHAMER E,DONAHUE J,et al.Caffe:convolutional architecture for fast feature embedding[C]// Proceedings of the 22nd ACM international conference on Multimedia.Orlando,Florida:ACM,2014:675-678.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with embedded FPGA platform for convolutional neural network">

                                <b>[8]</b> QIU J,WANG J,YAO S,et al.Going deeper with embedded fpga platform for convolutional neural network[C]// Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.Monterey:ACM,2016:26-35.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mobilenets:efficient convolutional neural networks for mobile vision applications">

                                <b>[9]</b> HOWARD A G,ZHU M,CHEN B,et al.Mobilenets:efficient convolutional neural networks for mobile vision applications[J].arXiv preprint arXiv:1704.04861,2017.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201508008&amp;v=MTA1MDc0SDlUTXA0OUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeW5rVmJyQkx6N01hYkc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 方睿,刘加贺,薛志辉,等.卷积神经网络的FPGA并行加速方案设计[J].计算机工程与应用,2015,51(8):32-36.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gradient-based learning applied to document recognition">

                                <b>[11]</b> LECUN Y L,BOTTOU L,BENGIO Y,et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE,1998,86(11):2278-2324.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="WXYJ201909002" />
        <input id="dpi" type="hidden" value="800" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201909002&amp;v=MTQ2NzlHRnJDVVJMT2VaZVZ1Rnlua1ZickJNalhTWkxHNEg5ak1wbzlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bFF0dU9NTmdMQ0V1SURuSmxZZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
