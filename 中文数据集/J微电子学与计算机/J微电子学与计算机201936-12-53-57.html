<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133314836533750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dWXYJ201912011%26RESULT%3d1%26SIGN%3dRJBxvvAxLy4EulG%252fNzjhXB0B6Pw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201912011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201912011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201912011&amp;v=MDAwNDFyQ1VSTE9lWmVWdkZ5RG5XcjdLTWpYU1pMRzRIOWpOclk5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="1 &lt;b&gt;引言&lt;/b&gt; ">1 <b>引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#34" data-title="2 &lt;b&gt;非均匀光照对比度增强技术&lt;/b&gt; ">2 <b>非均匀光照对比度增强技术</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#35" data-title="2.1 &lt;b&gt;模糊变换&lt;/b&gt;">2.1 <b>模糊变换</b></a></li>
                                                <li><a href="#48" data-title="2.2 &lt;b&gt;对比度增强算法&lt;/b&gt;">2.2 <b>对比度增强算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#64" data-title="3 &lt;b&gt;实验结果和分析&lt;/b&gt; ">3 <b>实验结果和分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#68" data-title="3.1 &lt;b&gt;主观分析&lt;/b&gt;">3.1 <b>主观分析</b></a></li>
                                                <li><a href="#73" data-title="3.2 &lt;b&gt;客观分析&lt;/b&gt;">3.2 <b>客观分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="4 &lt;b&gt;结束语&lt;/b&gt; ">4 <b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#37" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;模糊变换流程示意图&lt;/b&gt;"><b>图</b>1 <b>模糊变换流程示意图</b></a></li>
                                                <li><a href="#47" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;参数&lt;/b&gt;r&lt;b&gt;修正的三角形隶属度函数&lt;/b&gt;"><b>图</b>2 <b>参数</b>r<b>修正的三角形隶属度函数</b></a></li>
                                                <li><a href="#51" data-title="&lt;b&gt;图&lt;/b&gt;3 &lt;i&gt;LUV&lt;/i&gt;&lt;b&gt;和&lt;/b&gt;&lt;i&gt;HSV&lt;/i&gt;&lt;b&gt;颜色空间的纹理细节&lt;/b&gt;"><b>图</b>3 <i>LUV</i><b>和</b><i>HSV</i><b>颜色空间的纹理细节</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;图&lt;/b&gt;4 &lt;b&gt;模糊变换使用不同核参数&lt;/b&gt;&lt;i&gt;r&lt;/i&gt;&lt;b&gt;时的平滑图像&lt;/b&gt;"><b>图</b>4 <b>模糊变换使用不同核参数</b><i>r</i><b>时的平滑图像</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;图&lt;/b&gt;5 &lt;b&gt;不同算法在雾天图像时的性能特征&lt;/b&gt;"><b>图</b>5 <b>不同算法在雾天图像时的性能特征</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;图&lt;/b&gt;6 &lt;b&gt;不同算法在光源图像时的性能特征&lt;/b&gt;"><b>图</b>6 <b>不同算法在光源图像时的性能特征</b></a></li>
                                                <li><a href="#72" data-title="&lt;b&gt;图&lt;/b&gt;7 &lt;b&gt;不同算法在海报图像时的性能特征&lt;/b&gt;"><b>图</b>7 <b>不同算法在海报图像时的性能特征</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;图&lt;/b&gt;8 &lt;b&gt;不同算法获得的&lt;/b&gt;&lt;i&gt;NIQE&lt;/i&gt;、&lt;i&gt;NIQMC&lt;/i&gt;&lt;b&gt;和&lt;/b&gt;&lt;i&gt;DE&lt;/i&gt;&lt;b&gt;值&lt;/b&gt;"><b>图</b>8 <b>不同算法获得的</b><i>NIQE</i>、<i>NIQMC</i><b>和</b><i>DE</i><b>值</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 智宁,毛善君,李梅.基于相对梯度正则化的&lt;i&gt;Retinex&lt;/i&gt;变分模型及其应用[&lt;i&gt;J&lt;/i&gt;].通信学报,2017,38(11):69-79." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201711007&amp;v=MTg0NjdlWmVWdkZ5RG5XcjdLTVRYVGJMRzRIOWJOcm85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         智宁,毛善君,李梅.基于相对梯度正则化的&lt;i&gt;Retinex&lt;/i&gt;变分模型及其应用[&lt;i&gt;J&lt;/i&gt;].通信学报,2017,38(11):69-79.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" &lt;i&gt;KANSAL S&lt;/i&gt; ,&lt;i&gt;PURWAR S&lt;/i&gt; ,&lt;i&gt;TRIPATHI R K&lt;/i&gt; .&lt;i&gt;Image contrast enhancement using unsharp masking and histogram equalization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Multimedia Tools and Applications&lt;/i&gt;,2018,77(20):26919-26938." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image contrast enhancement using unsharp masking and histogram equalization">
                                        <b>[2]</b>
                                         &lt;i&gt;KANSAL S&lt;/i&gt; ,&lt;i&gt;PURWAR S&lt;/i&gt; ,&lt;i&gt;TRIPATHI R K&lt;/i&gt; .&lt;i&gt;Image contrast enhancement using unsharp masking and histogram equalization&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Multimedia Tools and Applications&lt;/i&gt;,2018,77(20):26919-26938.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" &lt;i&gt;LIU C&lt;/i&gt;,&lt;i&gt;CHENG I&lt;/i&gt;,&lt;i&gt;ZHANG Y&lt;/i&gt;,&lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Enhancement of low visibility aerial images using histogram truncation and an explicit Retinex representation for balancing contrast and color consistency&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Isprs Journal of Photogrammetry&lt;/i&gt; &amp;amp; &lt;i&gt;Remote Sensing&lt;/i&gt;,2017,128:16-26." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES02A61FF644802588616E422D9EC154DF&amp;v=MDYzMzRRMzVkbGh6THEyd2FvPU5pZk9mYk82YjlmTjJmbERZTzhIREg0OHh4NFY2emtJVEgzZzJCdEFDck9SUWM3cENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         &lt;i&gt;LIU C&lt;/i&gt;,&lt;i&gt;CHENG I&lt;/i&gt;,&lt;i&gt;ZHANG Y&lt;/i&gt;,&lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Enhancement of low visibility aerial images using histogram truncation and an explicit Retinex representation for balancing contrast and color consistency&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Isprs Journal of Photogrammetry&lt;/i&gt; &amp;amp; &lt;i&gt;Remote Sensing&lt;/i&gt;,2017,128:16-26.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" &lt;i&gt;KHOURY J E&lt;/i&gt;,&lt;i&gt;MOAN S L&lt;/i&gt;,&lt;i&gt;THOMAS J B&lt;/i&gt;,&lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Color and sharpness assessment of single image dehazing&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Multimedia Tools&lt;/i&gt; &amp;amp; &lt;i&gt;Applications&lt;/i&gt;,2017,77(8):1-22." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Color and sharpness assessment of single image dehazing">
                                        <b>[4]</b>
                                         &lt;i&gt;KHOURY J E&lt;/i&gt;,&lt;i&gt;MOAN S L&lt;/i&gt;,&lt;i&gt;THOMAS J B&lt;/i&gt;,&lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Color and sharpness assessment of single image dehazing&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Multimedia Tools&lt;/i&gt; &amp;amp; &lt;i&gt;Applications&lt;/i&gt;,2017,77(8):1-22.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" &lt;i&gt;TSAI Y W&lt;/i&gt;,&lt;i&gt;CHENG F C&lt;/i&gt;,&lt;i&gt;RUAN S J&lt;/i&gt;.&lt;i&gt;An efficient dynamic window size selection method for&lt;/i&gt; 2-&lt;i&gt;D histogram construction in contextual and variational contrast enhancement&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Multimedia Tools and Applications&lt;/i&gt;,2017,76(1):1121-1137." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An efficient dynamic window size selection method for 2-D histogram construction in contextual and variational contrast enhancement">
                                        <b>[5]</b>
                                         &lt;i&gt;TSAI Y W&lt;/i&gt;,&lt;i&gt;CHENG F C&lt;/i&gt;,&lt;i&gt;RUAN S J&lt;/i&gt;.&lt;i&gt;An efficient dynamic window size selection method for&lt;/i&gt; 2-&lt;i&gt;D histogram construction in contextual and variational contrast enhancement&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Multimedia Tools and Applications&lt;/i&gt;,2017,76(1):1121-1137.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 张红颖,胡文博.基于&lt;i&gt;Retinex&lt;/i&gt;灰度增强和颜色信息的时空上下文跟踪算法[&lt;i&gt;J&lt;/i&gt;].计算机辅助设计与图形学学报,2017,29(12):173-179." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201712020&amp;v=MjY1MDBGckNVUkxPZVplVnZGeURuV3I3S0x6N0JhTEc0SDliTnJZOUhaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         张红颖,胡文博.基于&lt;i&gt;Retinex&lt;/i&gt;灰度增强和颜色信息的时空上下文跟踪算法[&lt;i&gt;J&lt;/i&gt;].计算机辅助设计与图形学学报,2017,29(12):173-179.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" &lt;i&gt;ZHANG J&lt;/i&gt;,&lt;i&gt;ZHOU P&lt;/i&gt;,&lt;i&gt;ZHANG Q&lt;/i&gt;.&lt;i&gt;Low&lt;/i&gt;-&lt;i&gt;Light Image Enhancement Based on Iterative Multi&lt;/i&gt;-&lt;i&gt;Scale Guided Filter Retinex&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Graphics&lt;/i&gt;,2018,39(1):1-11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GCTX201801001&amp;v=MTkxNjlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5RG5XcjdLSWk3ZmRyRzRIOW5Ncm85RlpZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         &lt;i&gt;ZHANG J&lt;/i&gt;,&lt;i&gt;ZHOU P&lt;/i&gt;,&lt;i&gt;ZHANG Q&lt;/i&gt;.&lt;i&gt;Low&lt;/i&gt;-&lt;i&gt;Light Image Enhancement Based on Iterative Multi&lt;/i&gt;-&lt;i&gt;Scale Guided Filter Retinex&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Journal of Graphics&lt;/i&gt;,2018,39(1):1-11.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 左芝勇.一种空间自适应的&lt;i&gt;Retinex&lt;/i&gt;变分校正模型[&lt;i&gt;J&lt;/i&gt;].计算机应用研究,2018,35(5):1582-1585." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201805067&amp;v=MTU3MjRaTEc0SDluTXFvOURZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeURuV3I3S0x6N1M=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         左芝勇.一种空间自适应的&lt;i&gt;Retinex&lt;/i&gt;变分校正模型[&lt;i&gt;J&lt;/i&gt;].计算机应用研究,2018,35(5):1582-1585.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" &lt;i&gt;PUSHPA MAMORIA&lt;/i&gt;,&lt;i&gt;DEEPA RAJ&lt;/i&gt;.&lt;i&gt;Comparison of Mamdani Fuzzy Inference System for Multiple Membership Functions&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;I&lt;/i&gt;.&lt;i&gt;J&lt;/i&gt;.&lt;i&gt;Image&lt;/i&gt;,&lt;i&gt;Graphics and Signal Processing&lt;/i&gt;,2016,8(9):26-30." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJMS&amp;filename=SJMSDFFF33323A93A9093A50469762D634ED&amp;v=MTE0NzhPR1FsZkNwYlEzNWRsaHpMcTJ3YW89TmlmR2ZjZk9hS2ZQckl4SFo1b0dEdzB3eng4UW16cDlUSG5ycXhRM0RiU1hRYy9yQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         &lt;i&gt;PUSHPA MAMORIA&lt;/i&gt;,&lt;i&gt;DEEPA RAJ&lt;/i&gt;.&lt;i&gt;Comparison of Mamdani Fuzzy Inference System for Multiple Membership Functions&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;I&lt;/i&gt;.&lt;i&gt;J&lt;/i&gt;.&lt;i&gt;Image&lt;/i&gt;,&lt;i&gt;Graphics and Signal Processing&lt;/i&gt;,2016,8(9):26-30.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" &lt;i&gt;PERFILIEVA I&lt;/i&gt;,&lt;i&gt;SINGH A P&lt;/i&gt;,&lt;i&gt;TIWARI S P&lt;/i&gt;.&lt;i&gt;On the relationship among F&lt;/i&gt; -&lt;i&gt;transform&lt;/i&gt;,&lt;i&gt;fuzzy rough set and fuzzy topology&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Soft Computing&lt;/i&gt;,2017,21(13):3513-3523." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD6665FB50AF3B6842F38A3109F716681F&amp;v=MjkzNThTNjNZcEZGWjBNZm5veHl4Umw2VGNNUzM3aXBXUXllTFNTVGJ2cENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRsaHpMcTJ3YW89Tmo3QmFyVytHTg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         &lt;i&gt;PERFILIEVA I&lt;/i&gt;,&lt;i&gt;SINGH A P&lt;/i&gt;,&lt;i&gt;TIWARI S P&lt;/i&gt;.&lt;i&gt;On the relationship among F&lt;/i&gt; -&lt;i&gt;transform&lt;/i&gt;,&lt;i&gt;fuzzy rough set and fuzzy topology&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Soft Computing&lt;/i&gt;,2017,21(13):3513-3523.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" &lt;i&gt;GUO X&lt;/i&gt;,&lt;i&gt;LI Y&lt;/i&gt;,&lt;i&gt;LING H&lt;/i&gt;.&lt;i&gt;LIME&lt;/i&gt;:&lt;i&gt;Low&lt;/i&gt;-&lt;i&gt;Light Image Enhancement via Illumination Map Estimation&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;IEEE Transactions on Image Processing&lt;/i&gt;,2017,26(2):982-993." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LIME:Low-light image enhancement via illumination map estimation">
                                        <b>[11]</b>
                                         &lt;i&gt;GUO X&lt;/i&gt;,&lt;i&gt;LI Y&lt;/i&gt;,&lt;i&gt;LING H&lt;/i&gt;.&lt;i&gt;LIME&lt;/i&gt;:&lt;i&gt;Low&lt;/i&gt;-&lt;i&gt;Light Image Enhancement via Illumination Map Estimation&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;IEEE Transactions on Image Processing&lt;/i&gt;,2017,26(2):982-993.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" &lt;i&gt;THORNHILL C&lt;/i&gt;,&lt;i&gt;SMIRNOVA M&lt;/i&gt;.&lt;i&gt;Litigation and political transformation&lt;/i&gt;:&lt;i&gt;the case of Russia&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Theory and society&lt;/i&gt;,2018,47(5):559-593." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Litigation and political transformation:the case of Russia">
                                        <b>[12]</b>
                                         &lt;i&gt;THORNHILL C&lt;/i&gt;,&lt;i&gt;SMIRNOVA M&lt;/i&gt;.&lt;i&gt;Litigation and political transformation&lt;/i&gt;:&lt;i&gt;the case of Russia&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;Theory and society&lt;/i&gt;,2018,47(5):559-593.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" &lt;i&gt;YUE H&lt;/i&gt;,&lt;i&gt;YANG J&lt;/i&gt;,&lt;i&gt;SUN X&lt;/i&gt;,&lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Contrast Enhancement Based on Intrinsic Image Decomposition&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society&lt;/i&gt;,2017,26(8):3981-3994." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement based on intrinsic image decomposition">
                                        <b>[13]</b>
                                         &lt;i&gt;YUE H&lt;/i&gt;,&lt;i&gt;YANG J&lt;/i&gt;,&lt;i&gt;SUN X&lt;/i&gt;,&lt;i&gt;et al&lt;/i&gt;.&lt;i&gt;Contrast Enhancement Based on Intrinsic Image Decomposition&lt;/i&gt;[&lt;i&gt;J&lt;/i&gt;].&lt;i&gt;IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society&lt;/i&gt;,2017,26(8):3981-3994.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=WXYJ" target="_blank">微电子学与计算机</a>
                2019,36(12),53-57             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于参数模糊变换的非均匀照度图像增强算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%88%B4%E8%93%89&amp;code=24420078&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">戴蓉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E6%B0%91%E7%94%A8%E8%88%AA%E7%A9%BA%E9%A3%9E%E8%A1%8C%E5%AD%A6%E9%99%A2&amp;code=0264772&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国民用航空飞行学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对非均匀照度图像中对比度和清晰度低的问题,提出了一种基于参数模糊变换的图像对比度增强算法,能够极大改善图像的主观和客观品质.该算法首先将彩色图像从RGB空间转换成HSV和LUV颜色空间,其次在LUV空间上利用模糊变换平滑原始图像的亮度分布,为了增强图像的对比度和提高暗区的细节,在隶属度函数中引入一个与HSV空间值层有关的参数,然后在HSV空间值层中采用像素加权策略用来保留大量纹理信息,最后将平滑的图像与加权的图像在HSV空间上进行组合,并转换回RGB空间,得到保留有自然度的高质量增强图像.实验结果表明,所提方法能够有效增强非均匀照度图像对比度,且整体性能要优于其他算法.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像增强;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AF%B9%E6%AF%94%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">对比度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%82%E6%95%B0%E6%A8%A1%E7%B3%8A%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">参数模糊变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜色空间;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    戴蓉,女,(1977-),硕士,副教授.研究方向为计算机仿真、数据库技术、多媒体技术.E-mail:dengrur@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然基金民航联合基金(60879023);</span>
                    </p>
            </div>
                    <h1><b>Non-uniform illumination image enhancement algorithm based on parametric fuzzy transformation</b></h1>
                    <h2>
                    <span>DAI Rong</span>
            </h2>
                    <h2>
                    <span>Civil Aviation Flight University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of low contrast and low definition in non-uniform illumination images, an algorithm for enhancing image contrast using parametric fuzzy transform in luminance domain was proposed. The algorithm converts the color image from RGB space to HSV color space and LUV color space firstly, and secondly applies the fuzzy transform in the luminance domain of LUV to smooth the brightness distribution of the original image. In order to enhance the contrast of the image and improve the detail of the dark region, we introduce a parameter related to the HSV spatial value layer in the membership function. Then the proposed algorithm utilizes the pixel weighting strategy in the HSV spatial value layer to preserve a large amount of texture information. Finally, both the images are combined to form the enhanced image in HSV space and transformed to RGB space, which obtained a high quality image with naturalness preservation. The experimental results show that the overall performance of the proposed method is better than other algorithms. While effectively enhancing the contrast of non-uniform illumination images, the subjective and objective quality of the image is also greatly improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20enhancement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image enhancement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=contrast&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">contrast;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=parametric%20fuzzy%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">parametric fuzzy transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20space&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color space;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-20</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag">1 <b>引言</b></h3>
                <div class="p1">
                    <p id="30">在非均匀照度下拍摄的图像,大多数会产生强烈的背景噪声,使得图像的照度、对比度、灰度产生分布不均的现象<citation id="100" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.图像对比度增强技术可以减轻或消除这种失真,提高图像的质量,获得更好的视觉感知.目前,存在许多已成功应用于不同类型图像的对比度增强算法,但是,对于暴露在不均匀照度下的图像,大多数算法的增强效果不明显.</p>
                </div>
                <div class="p1">
                    <p id="31">基于直方图<citation id="101" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>和基于Retinex<citation id="102" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>的图像对比度增强算法可以很好地消除图像在非均匀照明条件下的失真问题.然而,在简单的亮度变换过程中,会产生图像亮区中的过度增强或光晕伪影现象.自适应HE<citation id="103" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>和动态HE<citation id="104" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>试图采取局部直方图均衡化使得一定程度上减少了这类现象的产生,但是利用这两类算法处理非均匀照度图像时,效果并不太好.由于单尺度Retinex算法<citation id="105" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和多尺度加权平均算法<citation id="106" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>在增强图像过程中会导致图像不自然和颜色失真现象,Retinex问题的变分模型和概率方法<citation id="107" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>得以快速发展.</p>
                </div>
                <div class="p1">
                    <p id="32">Hasikin和Isa<sup></sup><citation id="108" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了一种基于自适应模糊对比度因子的亮度保持图像增强技术,但是基于阈值的亮度保持技术在不均匀照明下会导致不期望的效果.Perfilieva<citation id="109" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将基于传统模糊规则的系统扩展到模糊变换(Fuzzy Transform,FT),使得模糊算法在图像处理中的计算效率方面更佳.</p>
                </div>
                <div class="p1">
                    <p id="33">针对非均匀照度条件下的图像对比度低和失真问题,提出了一种基于参数模糊变换(Parametric Fuzzy Transform,PFT)的图像对比度增强算法.该算法关注于亮度层(LUV颜色空间的L)和值层(HSV颜色空间的V)的修改.使用亮度层(L)进行图像平滑的优点是可以获得更好的可视性和清晰度,以及改善图像的对比度.为了保持亮区的纹理和增强暗区的图像细节,本文在模糊变换中提出了带有参数的隶属度函数,该参数可由HSV空间的值层平均值求解.除此之外,通过调整HSV空间的值层分布,不仅可以保留原始图像的颜色和自然度,还能捕获到图像更多的细节纹理.</p>
                </div>
                <h3 id="34" name="34" class="anchor-tag">2 <b>非均匀光照对比度增强技术</b></h3>
                <h4 class="anchor-tag" id="35" name="35">2.1 <b>模糊变换</b></h4>
                <div class="p1">
                    <p id="36">图像的模糊变换大致可以分为3步:提取图像模糊特征、修正隶属度函数和模糊域反变换,变换流程如图1所示.</p>
                </div>
                <div class="area_img" id="37">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模糊变换流程示意图" src="Detail/GetImg?filename=images/WXYJ201912011_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>模糊变换流程示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="38">模糊化是指根据隶属度函数从具体的输入得到对模糊集隶属度的过程.图像模糊化是将一幅大小为<i>M</i>×<i>N</i>的图像<i>X</i>表示为一个模糊矩阵:</p>
                </div>
                <div class="p1">
                    <p id="39" class="code-formula">
                        <mathml id="39"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">F</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mtable><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mn>1</mn></mrow></msub></mtd></mtr></mtable></mtd><mtd><mtable><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mn>2</mn></mrow></msub></mtd></mtr></mtable></mtd><mtd><mtable><mtr><mtd><mo>⋯</mo></mtd></mtr><mtr><mtd><mo>⋯</mo></mtd></mtr><mtr><mtd><mo>⋱</mo></mtd></mtr><mtr><mtd><mo>⋯</mo></mtd></mtr></mtable></mtd><mtd><mtable><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mn>1</mn><mi>Μ</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mn>2</mn><mi>Μ</mi></mrow></msub></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mi>Μ</mi></mrow></msub></mtd></mtr></mtable></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="40">模糊矩阵的组成元素<i>F</i><sub><i>kl</i></sub>可以表示为</p>
                </div>
                <div class="p1">
                    <p id="41" class="code-formula">
                        <mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>f</mi></mstyle></mrow></mstyle><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mi>B</mi><msub><mrow></mrow><mi>l</mi></msub><mrow><mo>(</mo><mrow><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>A</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mi>B</mi><msub><mrow></mrow><mi>l</mi></msub><mrow><mo>(</mo><mrow><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="42">式中,<i>f</i>表示在坐标<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo>∈</mo><mrow><mo>[</mo><mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow><mo>]</mo></mrow><mo>×</mo><mrow><mo>[</mo><mrow><mi>c</mi><mo>,</mo><mi>d</mi></mrow><mo>]</mo></mrow></mrow></math></mathml>处的像素点,<i>i</i>=1,…,<i>N</i>,<i>j</i>=1,…,<i>M</i>;<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>和<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><msub><mrow></mrow><mi>l</mi></msub><mrow><mo>(</mo><mrow><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>表示模糊变换的隶属度函数,</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>n</mi><mrow><mo>(</mo><mrow><mi>n</mi><mo>&lt;</mo><mi>Ν</mi></mrow><mo>)</mo></mrow><mo>,</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn><mo>,</mo></mrow><mo>⋯</mo><mo>,</mo><mi>m</mi><mrow><mo>(</mo><mrow><mi>m</mi><mo>&lt;</mo><mi>Μ</mi></mrow><mo>)</mo></mrow><mo>.</mo></mtd></mtr><mtr><mtd><mi>A</mi><mrow><mo>(</mo><mi>p</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mfrac><mrow><mi>r</mi><mrow><mo>(</mo><mrow><mi>p</mi><mo>-</mo><mi>a</mi></mrow><mo>)</mo></mrow></mrow><mrow><mi>m</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>a</mi></mrow></mfrac><mo>,</mo></mtd><mtd columnalign="left"><mi>a</mi><mo>≤</mo><mi>p</mi><mo>≤</mo><mi>m</mi><msub><mrow></mrow><mn>1</mn></msub></mtd></mtr><mtr><mtd columnalign="left"><mfrac><mrow><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mi>r</mi></mrow><mo>)</mo></mrow><mrow><mo>(</mo><mrow><mi>p</mi><mo>-</mo><mi>m</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>b</mi><mo>-</mo><mi>m</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>+</mo><mi>r</mi><mo>,</mo></mtd><mtd columnalign="left"><mi>m</mi><msub><mrow></mrow><mn>1</mn></msub><mo>≤</mo><mi>p</mi><mo>≤</mo><mi>b</mi></mtd></mtr><mtr><mtd columnalign="left"><mfrac><mrow><mrow><mo>(</mo><mrow><mi>r</mi><mo>-</mo><mn>1</mn></mrow><mo>)</mo></mrow><mrow><mo>(</mo><mrow><mi>p</mi><mo>-</mo><mi>m</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mi>m</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mi>b</mi></mrow></mfrac><mo>+</mo><mi>r</mi><mo>,</mo></mtd><mtd columnalign="left"><mi>b</mi><mo>≤</mo><mi>p</mi><mo>≤</mo><mi>m</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr><mtr><mtd columnalign="left"><mfrac><mrow><mi>r</mi><mrow><mo>(</mo><mrow><mi>p</mi><mo>-</mo><mi>c</mi></mrow><mo>)</mo></mrow></mrow><mrow><mi>m</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>,</mo></mtd><mtd columnalign="left"><mi>m</mi><msub><mrow></mrow><mn>2</mn></msub><mo>≤</mo><mi>p</mi><mo>≤</mo><mi>c</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>.</mo><mn>0</mn><mn>0</mn><mn>0</mn><mn>1</mn><mo>,</mo></mtd><mtd columnalign="left"><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">隶属度函数(membership function)是一种表征模糊集合的函数,描述了元素<i>p</i><sub><i>i</i></sub>对区域[<i>a</i>,<i>b</i>]上的一个模糊集合的隶属关系.常用的隶属度函数有三角形、梯形、<i>S</i>形、钟形等,本文采用参数<i>r</i>修正的三角形隶属度函数,其定义由(3)式给出,隶属度函数的图像如图2所示:</p>
                </div>
                <div class="p1">
                    <p id="45">模糊反变换即图像的去模糊化,是将模糊结论转化为具体的、精确输出的过程:</p>
                </div>
                <div class="p1">
                    <p id="46" class="code-formula">
                        <mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msubsup><mrow></mrow><mrow><mi>n</mi><mi>m</mi></mrow><mi>F</mi></msubsup><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>F</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow><mi>B</mi><msub><mrow></mrow><mi>l</mi></msub><mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 参数r修正的三角形隶属度函数" src="Detail/GetImg?filename=images/WXYJ201912011_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>参数</b>r<b>修正的三角形隶属度函数</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="48" name="48">2.2 <b>对比度增强算法</b></h4>
                <div class="p1">
                    <p id="49">首先,将原始彩色图像由<i>RGB</i>空间转换为<i>LUV</i>和<i>HSV</i>颜色空间.对于非均匀照度图像,本文通过修改<i>LUV</i>颜色空间的亮度层(<i>L</i>)和<i>HSV</i>颜色空间的值层(<i>V</i>)来增强图像的对比度.因为亮度层(<i>L</i>)能够在不保持饱和的情况下将原始图像解耦为亮度和色度,使用亮度层进行图像平滑的优点是可以获得更好的可视性和清晰度,图像的对比度也得到改善;而<i>HSV</i>空间的值层更适合捕获图像细节,获取更多的纹理信息.图3展示了每个色彩空间的特征.</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 LUV和HSV颜色空间的纹理细节" src="Detail/GetImg?filename=images/WXYJ201912011_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 <i>LUV</i><b>和</b><i>HSV</i><b>颜色空间的纹理细节</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_05100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="52">其次,将PFT方法应用于亮度层,得到模糊变换平滑后的图像<i>F</i><sub><i>L</i></sub>.为了改善图像亮度层的局部对比度和亮度,在考量PFT核参数<i>r</i>时,采用了<i>V</i>通道的平均值作为本文所有图像测试中亮度平滑的固定参数:</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo>=</mo><mrow><mo>|</mo><mrow><mi>χ</mi><mo>-</mo><mi>E</mi><mrow><mo>(</mo><mi>V</mi><mo>)</mo></mrow></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">式中,<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mrow><mo>(</mo><mi>V</mi><mo>)</mo></mrow></mrow></math></mathml>表示<i>V</i>通道的平均值;<i>χ</i>一般取值0.5.</p>
                </div>
                <div class="p1">
                    <p id="55">图4给出了模糊变换使用不同核参数<i>r</i>得到的平滑图像,从图中可以看出,采取与图像有关的<i>r</i>值可以有效地改善图像亮度层的对比度和局部区域的亮度.</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 模糊变换使用不同核参数r时的平滑图像" src="Detail/GetImg?filename=images/WXYJ201912011_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>4 <b>模糊变换使用不同核参数</b><i>r</i><b>时的平滑图像</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>
                                <p class="img_note">(<i>a</i>) 原始图像(<i>b</i>)图像无关的<i>r</i>值(<i>c</i>)图像有关的<i>r</i>值</p>

                </div>
                <div class="p1">
                    <p id="57">为了增强精细图像细节,基于像素邻域相似性来计算权重值<i>w</i><sub><i>ij</i></sub>的大小.根据方向滤波器在水平、垂直和对角线方向上计算的像素相异度,确定像素加权策略中的权重系数,其中最大不相似度的像素对应的权重被指定为1,其余权重依据相异度比例相应地减小.像素相异度<i>s</i>可由像素<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>q</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>和<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>q</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>的局部邻域窗<i>N</i><sub><i>x</i></sub>、<i>N</i><sub><i>y</i></sub>之间的欧式距离来定义:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msup><mrow></mrow><mn>2</mn></msup><mrow><mo>(</mo><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mo>)</mo></mrow><mo>=</mo><mrow><mo stretchy="false">∥</mo><mi>v</mi><mrow><mo>(</mo><mrow><mi>Ν</mi><msub><mrow></mrow><mi>x</mi></msub></mrow><mo>)</mo></mrow><mo>-</mo><mi>v</mi><mrow><mo>(</mo><mrow><mi>Ν</mi><msub><mrow></mrow><mi>y</mi></msub></mrow><mo>)</mo></mrow><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">然后将<i>V</i>通道的分量<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>和权重值<i>w</i><sub><i>ij</i></sub>应用Hadamard运算符(°),生成保留大量纹理信息的加权图像<i>V</i><sub><i>w</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><msub><mrow></mrow><mi>w</mi></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>w</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>°</mo><mi>V</mi><mrow><mo>(</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>q</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup><mi>w</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">将平滑后的亮度层与加权图像细节组合来形成增强图像的值层<i>I</i><sub><i>e</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="62"><i>I</i><sub><i>e</i></sub>=<i>F</i><sub><i>L</i></sub>+<i>V</i><sub><i>w</i></sub>      (8)</p>
                </div>
                <div class="p1">
                    <p id="63">最后,增强的<i>HSV</i>图像被转换回<i>RGB</i>颜色空间.由于色调和饱和度层不变,提出的方法有效地保留了原始图像的颜色和自然度.</p>
                </div>
                <h3 id="64" name="64" class="anchor-tag">3 <b>实验结果和分析</b></h3>
                <div class="p1">
                    <p id="65">从<i>NASA</i>和<i>Google</i>数据库中选择出50幅具有光照变化和对比度变化的测试图像,用以验证提出方法的性能,并且与其他先进的方法进行比较,如<i>LIME</i><citation id="110" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,<i>ECHR</i><citation id="111" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和<i>CEIID</i><sup></sup><citation id="112" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同算法在雾天图像时的性能特征" src="Detail/GetImg?filename=images/WXYJ201912011_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>5 <b>不同算法在雾天图像时的性能特征</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="68" name="68">3.1 <b>主观分析</b></h4>
                <div class="p1">
                    <p id="69">图5-7展示了不同方法的性能特征.<i>ECHR</i>,<i>LIME</i>,<i>CEIID</i>和提出的算法均可以生成保留自然度的增强图像,但是,本文方法在整体性能上要优于其他算法.当利用图5雾天图像测试算法时,除了本文方法和<i>CEIID</i>之外,其他方法都未能通过颜色恢复实现有希望的增强.然而,当测试图像中存在光源时(如图6),<i>CEIID</i>显露出明亮的斑块.从图像6中的光源以及图7的细节可以发现,<i>LIME</i>算法生成的明亮图像有时会导致图像特征丢失.并且在所处理的图像中,<i>LIME</i>的结果缺少其他标记的细节.图7细节充分说明<i>ECHR</i>方法在增强对比度的同时,产生了暗黑区域.</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法在光源图像时的性能特征" src="Detail/GetImg?filename=images/WXYJ201912011_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>6 <b>不同算法在光源图像时的性能特征</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_07100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法在海报图像时的性能特征" src="Detail/GetImg?filename=images/WXYJ201912011_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>7 <b>不同算法在海报图像时的性能特征</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>
                                <p class="img_note">(<i>a</i>)原图 (<i>b</i>)<i>ECHR</i> (<i>c</i>)<i>LIME</i> (<i>d</i>) <i>CEIID</i> (<i>e</i>)本文方法</p>

                </div>
                <h4 class="anchor-tag" id="73" name="73">3.2 <b>客观分析</b></h4>
                <div class="p1">
                    <p id="74">为了进一步验证,本文对上述算法进行客观评估,采用了自然图像质量评估(<i>NIQE</i>),对比度失真的无参考图像质量度量(<i>NIQMC</i>)和<i>Shannon</i>熵测量(<i>DE</i>)三个客观测量评价指标.</p>
                </div>
                <div class="p1">
                    <p id="75"><i>NIQE</i>指标评估了图像与原始图像之间的渐进自然度,该值越低,表示图像质量越好:</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mrow><mo>(</mo><mrow><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mtext>Σ</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mtext>Σ</mtext><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo>=</mo><msqrt><mrow><mfrac><mrow><mrow><mrow><mo>(</mo><mrow><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><msup><mrow></mrow><mi>Τ</mi></msup><mrow><mo>(</mo><mrow><mi>v</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mi>v</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mrow><mrow><mo>(</mo><mrow><mrow><mo>(</mo><mrow><mtext>Σ</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mtext>Σ</mtext><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo>/</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></mfrac></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">式中,<i>v</i><sub>1</sub>,<i>v</i><sub>2</sub>,Σ<sub>1</sub>,Σ<sub>2</sub>为自然图像和失真图像的MVG模型均值和方差矩阵.MVG模型定义如下:</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>f</mi><mrow><mo>(</mo><mrow><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>x</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo>)</mo></mrow><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>exp</mi><mrow><mo>(</mo><mrow><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mrow><mo>(</mo><mrow><mi>x</mi><mo>-</mo><mi>v</mi></mrow><mo>)</mo></mrow></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mtext>Σ</mtext><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo>(</mo><mrow><mi>x</mi><mo>-</mo><mi>v</mi></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mrow><mrow><mo>(</mo><mrow><mn>2</mn><mi>π</mi></mrow><mo>)</mo></mrow><msup><mrow></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><mrow><mo>|</mo><mtext>Σ</mtext><mo>|</mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">式中,<i>x</i><sub><i>i</i></sub>表示提取的图像特征;<i>v</i>和Σ可以通过最大似然估计法得到.</p>
                </div>
                <div class="p1">
                    <p id="80">NIQMC代表对比度增强质量,指标的高值表示更好的图像质量.</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ν</mtext><mtext>Ι</mtext><mtext>Q</mtext><mtext>Μ</mtext><mtext>C</mtext><mo>=</mo><mfrac><mrow><mi>Q</mi><msub><mrow></mrow><mi>L</mi></msub><mo>+</mo><mi>γ</mi><mi>Q</mi><msub><mrow></mrow><mi>G</mi></msub></mrow><mrow><mn>1</mn><mo>+</mo><mi>γ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">式中,<i>γ</i>是权重系数,表示局部和全局之间的相对比重;<i>Q</i><sub><i>L</i></sub>=max{<i>E</i><sub><i>l</i></sub><sub>1</sub>,<i>E</i><sub><i>l</i></sub><sub>2</sub>,…,<i>E</i><sub><i>l</i></sub><sub>5</sub>}和<mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><msub><mrow></mrow><mi>G</mi></msub><mo>=</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>J</mi><mi>S</mi></mrow></msub><mrow><mo>(</mo><mrow><mi>h</mi><mo>,</mo><mi>u</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>分别表示局部变量和全局变量;<i>E</i><sub><i>li</i></sub>表示像素<i>l</i><sub><i>i</i></sub>的熵值;<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mrow><mi>J</mi><mi>S</mi></mrow></msub><mrow><mo>(</mo><mrow><mi>h</mi><mo>,</mo><mi>u</mi></mrow><mo>)</mo></mrow></mrow></math></mathml>表示直方图<i>h</i>和像素<i>u</i>的<i>JS</i>散度.</p>
                </div>
                <div class="p1">
                    <p id="83">Shannon熵测量(DE)代表信息速率,其值越高,说明图像质量越好:</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mrow><mo>(</mo><mi>X</mi><mo>)</mo></mrow><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>Ρ</mi></mstyle><mrow><mo>(</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>Ρ</mi><mrow><mo>(</mo><mrow><mi>X</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">式中,<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mrow><mo>(</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>表示事件<i>X</i><sub><i>i</i></sub>发生的概率.</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201912011_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同算法获得的NIQE、NIQMC和DE值" src="Detail/GetImg?filename=images/WXYJ201912011_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>8 <b>不同算法获得的</b><i>NIQE</i>、<i>NIQMC</i><b>和</b><i>DE</i><b>值</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201912011_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="87">图8显示了不同方法对所有测试图像处理得到的客观测量值的平均值.从图8中可以看出,与所有其他方法相比,所提出的方法获得了最低的<i>NIQE</i>值,<i>ECHR</i>和<i>CEIID</i>方法的<i>NIQE</i>值较高,通常是因为图像区域中的过度增强导致的.同时,所提出的方法获得更高的<i>NIQMC</i>和<i>DE</i>平均值.由于<i>CEIID</i>算法在图像中生成明亮的补丁,也能得到较高的<i>NIQMC</i>和<i>DE</i>值,但是本文方法在暗区和亮区之间实现细节之间的最佳平衡.总的来说,尽管<i>ECHR</i>和<i>LIME</i>方法在一定程度上保留了自然度和图像细节,但是无法克服补丁中的不自然效应.<i>CEIID</i>虽然可以有效地改善图像的品质,但由于过度增强而未能保持自然度.因此,所提出的方法有效地增强了非均匀照度图像,具有极大改善图像主观和客观品质的性能.</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag">4 <b>结束语</b></h3>
                <div class="p1">
                    <p id="89">本文提出了一种基于参数模糊变换的图像对比度增强算法.利用参数模糊变换方法在<i>LUV</i>空间上进行亮度平滑,采用像素加权策略对<i>HSV</i>空间的值层进行调整,然后组合平滑的亮度层与加权值层,获得了保留原始图像纹理和色彩的高质量增强图像.所提出的方法的主要特征是图像对比度的增强能力和图像自然度和纹理细节保留能力.通过对多个图像的广泛实验,结果表明所提出的方法在主观和客观测量方面都优于现有的技术方法.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201711007&amp;v=MjY5NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeURuV3I3S01UWFRiTEc0SDliTnJvOUZZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 智宁,毛善君,李梅.基于相对梯度正则化的<i>Retinex</i>变分模型及其应用[<i>J</i>].通信学报,2017,38(11):69-79.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image contrast enhancement using unsharp masking and histogram equalization">

                                <b>[2]</b> <i>KANSAL S</i> ,<i>PURWAR S</i> ,<i>TRIPATHI R K</i> .<i>Image contrast enhancement using unsharp masking and histogram equalization</i>[<i>J</i>].<i>Multimedia Tools and Applications</i>,2018,77(20):26919-26938.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES02A61FF644802588616E422D9EC154DF&amp;v=MjQ0NjR6THEyd2FvPU5pZk9mYk82YjlmTjJmbERZTzhIREg0OHh4NFY2emtJVEgzZzJCdEFDck9SUWM3cENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRsaA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> <i>LIU C</i>,<i>CHENG I</i>,<i>ZHANG Y</i>,<i>et al</i>.<i>Enhancement of low visibility aerial images using histogram truncation and an explicit Retinex representation for balancing contrast and color consistency</i>[<i>J</i>].<i>Isprs Journal of Photogrammetry</i> &amp; <i>Remote Sensing</i>,2017,128:16-26.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Color and sharpness assessment of single image dehazing">

                                <b>[4]</b> <i>KHOURY J E</i>,<i>MOAN S L</i>,<i>THOMAS J B</i>,<i>et al</i>.<i>Color and sharpness assessment of single image dehazing</i>[<i>J</i>].<i>Multimedia Tools</i> &amp; <i>Applications</i>,2017,77(8):1-22.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An efficient dynamic window size selection method for 2-D histogram construction in contextual and variational contrast enhancement">

                                <b>[5]</b> <i>TSAI Y W</i>,<i>CHENG F C</i>,<i>RUAN S J</i>.<i>An efficient dynamic window size selection method for</i> 2-<i>D histogram construction in contextual and variational contrast enhancement</i>[<i>J</i>].<i>Multimedia Tools and Applications</i>,2017,76(1):1121-1137.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201712020&amp;v=MDU3MDVMRzRIOWJOclk5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5RG5XcjdLTHo3QmE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 张红颖,胡文博.基于<i>Retinex</i>灰度增强和颜色信息的时空上下文跟踪算法[<i>J</i>].计算机辅助设计与图形学学报,2017,29(12):173-179.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GCTX201801001&amp;v=MjgxNDVyRzRIOW5Ncm85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdkZ5RG5XcjdLSWk3ZmQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> <i>ZHANG J</i>,<i>ZHOU P</i>,<i>ZHANG Q</i>.<i>Low</i>-<i>Light Image Enhancement Based on Iterative Multi</i>-<i>Scale Guided Filter Retinex</i>[<i>J</i>].<i>Journal of Graphics</i>,2018,39(1):1-11.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201805067&amp;v=MjMyODF6N1NaTEc0SDluTXFvOURZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnZGeURuV3I3S0w=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 左芝勇.一种空间自适应的<i>Retinex</i>变分校正模型[<i>J</i>].计算机应用研究,2018,35(5):1582-1585.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJMS&amp;filename=SJMSDFFF33323A93A9093A50469762D634ED&amp;v=MTY4MjdoekxxMndhbz1OaWZHZmNmT2FLZlBySXhIWjVvR0R3MHd6eDhRbXpwOVRIbnJxeFEzRGJTWFFjL3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkbA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> <i>PUSHPA MAMORIA</i>,<i>DEEPA RAJ</i>.<i>Comparison of Mamdani Fuzzy Inference System for Multiple Membership Functions</i>[<i>J</i>].<i>I</i>.<i>J</i>.<i>Image</i>,<i>Graphics and Signal Processing</i>,2016,8(9):26-30.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD6665FB50AF3B6842F38A3109F716681F&amp;v=MDk5NjF4Umw2VGNNUzM3aXBXUXllTFNTVGJ2cENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRsaHpMcTJ3YW89Tmo3QmFyVytHTlM2M1lwRkZaME1mbm94eQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> <i>PERFILIEVA I</i>,<i>SINGH A P</i>,<i>TIWARI S P</i>.<i>On the relationship among F</i> -<i>transform</i>,<i>fuzzy rough set and fuzzy topology</i>[<i>J</i>].<i>Soft Computing</i>,2017,21(13):3513-3523.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LIME:Low-light image enhancement via illumination map estimation">

                                <b>[11]</b> <i>GUO X</i>,<i>LI Y</i>,<i>LING H</i>.<i>LIME</i>:<i>Low</i>-<i>Light Image Enhancement via Illumination Map Estimation</i>[<i>J</i>].<i>IEEE Transactions on Image Processing</i>,2017,26(2):982-993.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Litigation and political transformation:the case of Russia">

                                <b>[12]</b> <i>THORNHILL C</i>,<i>SMIRNOVA M</i>.<i>Litigation and political transformation</i>:<i>the case of Russia</i>[<i>J</i>].<i>Theory and society</i>,2018,47(5):559-593.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement based on intrinsic image decomposition">

                                <b>[13]</b> <i>YUE H</i>,<i>YANG J</i>,<i>SUN X</i>,<i>et al</i>.<i>Contrast Enhancement Based on Intrinsic Image Decomposition</i>[<i>J</i>].<i>IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society</i>,2017,26(8):3981-3994.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="WXYJ201912011" />
        <input id="dpi" type="hidden" value="800" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201912011&amp;v=MDAwNDFyQ1VSTE9lWmVWdkZ5RG5XcjdLTWpYU1pMRzRIOWpOclk5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sR00wSFZOZ1ZITVBhbjNuajd3OD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
