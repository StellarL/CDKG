<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134026996818750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dWXYJ201904010%26RESULT%3d1%26SIGN%3dNskx%252bor%252b03x1%252bLySYA4AyFmMHyM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201904010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201904010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201904010&amp;v=MTAwMDhaZVZ1Rnl6bVZydkFNalhTWkxHNEg5ak1xNDlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#15" data-title="1 &lt;b&gt;引言&lt;/b&gt; ">1 <b>引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#18" data-title="2 &lt;b&gt;神经网络&lt;/b&gt; ">2 <b>神经网络</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#22" data-title="2.1 &lt;b&gt;卷积神经网络&lt;/b&gt;">2.1 <b>卷积神经网络</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="3 &lt;b&gt;形变卷积神经网络&lt;/b&gt; ">3 <b>形变卷积神经网络</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="4 &lt;b&gt;实验&lt;/b&gt; ">4 <b>实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#49" data-title="4.1 &lt;b&gt;实验数据集&lt;/b&gt;">4.1 <b>实验数据集</b></a></li>
                                                <li><a href="#54" data-title="4.2 &lt;b&gt;实验训练细节&lt;/b&gt;">4.2 <b>实验训练细节</b></a></li>
                                                <li><a href="#58" data-title="4.3 &lt;b&gt;实验结果分析&lt;/b&gt;">4.3 <b>实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="5 &lt;b&gt;结束语&lt;/b&gt; ">5 <b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#24" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;卷积神经网络结构&lt;/b&gt;"><b>图</b>1 <b>卷积神经网络结构</b></a></li>
                                                <li><a href="#33" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;卷积核交叉移动过程&lt;/b&gt;"><b>图</b>2 <b>卷积核交叉移动过程</b></a></li>
                                                <li><a href="#37" data-title="&lt;b&gt;图&lt;/b&gt;3 &lt;b&gt;最大池化操作&lt;/b&gt;"><b>图</b>3 <b>最大池化操作</b></a></li>
                                                <li><a href="#40" data-title="&lt;b&gt;图&lt;/b&gt;4 3*3&lt;b&gt;规则卷积抽样和形变卷积抽样&lt;/b&gt;"><b>图</b>4 3*3<b>规则卷积抽样和形变卷积抽样</b></a></li>
                                                <li><a href="#46" data-title="&lt;b&gt;图&lt;/b&gt;5 3*3&lt;b&gt;形变卷积&lt;/b&gt;"><b>图</b>5 3*3<b>形变卷积</b></a></li>
                                                <li><a href="#51" data-title="&lt;b&gt;图&lt;/b&gt;6 &lt;b&gt;数据集图像表示结构&lt;/b&gt;"><b>图</b>6 <b>数据集图像表示结构</b></a></li>
                                                <li><a href="#52" data-title="&lt;b&gt;图&lt;/b&gt;7 MNIST&lt;b&gt;数据集部分手写体数字&lt;/b&gt;"><b>图</b>7 MNIST<b>数据集部分手写体数字</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;图&lt;/b&gt;8 &lt;b&gt;基于形变卷积神经网络结构&lt;/b&gt;"><b>图</b>8 <b>基于形变卷积神经网络结构</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;网络的具体设置&lt;/b&gt;"><b>表</b>1 <b>网络的具体设置</b></a></li>
                                                <li><a href="#60" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;形变卷积神经网络与其它方法比较&lt;/b&gt;"><b>表</b>2 <b>形变卷积神经网络与其它方法比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 陈岩, 李洋洋, 余乐, 等. 基于卷积神经网络的手写体数字识别系统[J]. 微电子学与计算机, 2018, 35 (2) :71-74." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201802015&amp;v=MzIzMzJGeXptVnJ2QU1qWFNaTEc0SDluTXJZOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         陈岩, 李洋洋, 余乐, 等. 基于卷积神经网络的手写体数字识别系统[J]. 微电子学与计算机, 2018, 35 (2) :71-74.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" KAREN SIONYAN, ANDREW ZISSERMAN. Very deep convolutional networks for large-scale image recognition[J]. Computer Science, 2014, arXiv preprint arXiv:1409.1556." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[2]</b>
                                         KAREN SIONYAN, ANDREW ZISSERMAN. Very deep convolutional networks for large-scale image recognition[J]. Computer Science, 2014, arXiv preprint arXiv:1409.1556.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 赵朋成, 冯玉田, 涂云轩. 基于高倍特征深度残差网络的手写数字识别[J]. 电子测量技术, 2018, 6 (41) :86-89." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201806016&amp;v=MDE2OTQ5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5em1WcnZBSVRmSVlyRzRIOW5NcVk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         赵朋成, 冯玉田, 涂云轩. 基于高倍特征深度残差网络的手写数字识别[J]. 电子测量技术, 2018, 6 (41) :86-89.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" YANG F, JIN L, YANG W, et al. Handwritten/Printed Receipt Classification Using Attention-Based Convolutional Neural Network[C]// International Conference on Frontiers in Handwriting Recognition. IEEE, 2017:384-389." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Handwritten/Printed Receipt Classification Using Attention-Based Convolutional Neural Network">
                                        <b>[4]</b>
                                         YANG F, JIN L, YANG W, et al. Handwritten/Printed Receipt Classification Using Attention-Based Convolutional Neural Network[C]// International Conference on Frontiers in Handwriting Recognition. IEEE, 2017:384-389.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" DAI JIFENG, et al. Deformable Convolutional Networks [C]// Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017:764-773." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deformable Convolutional Networks">
                                        <b>[5]</b>
                                         DAI JIFENG, et al. Deformable Convolutional Networks [C]// Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017:764-773.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" DENG J, DONG W, Socher R, et al. ImageNet: A large-scale hierarchical image database[C]//IEEE Conference on Computer Vision and Pattern Recognition, 2009:248-255." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet:A large-scale hierarchical image database">
                                        <b>[6]</b>
                                         DENG J, DONG W, Socher R, et al. ImageNet: A large-scale hierarchical image database[C]//IEEE Conference on Computer Vision and Pattern Recognition, 2009:248-255.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=WXYJ" target="_blank">微电子学与计算机</a>
                2019,36(04),47-51             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于形变卷积神经网络的手写体数字识别研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8C%B9%E6%99%93%E9%9D%92&amp;code=41465486&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">茹晓青</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%8E%E5%9B%BD%E5%85%89&amp;code=37017654&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华国光</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E4%B8%BD%E5%AE%8F&amp;code=07076888&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李丽宏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E8%8E%89&amp;code=38916557&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李莉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8C%97%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E4%B8%8E%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0096763&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河北工程大学信息与电气工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>本文引入形变卷积模块来增强网络对数字几何变换的建模能力, 提出了一种基于改进的形变卷积神经网络手写体数字识别框架, 在提高识别精度的同时, 还有效的减少了训练的参数量, 提高识别速度.本文在手写体数据集及变换后的数据集中进行验证.实验结果的分析以及与相应算法的比较, 证明了本算法是有效的.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%8B%E5%86%99%E4%BD%93%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">手写体数字识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%A2%E5%8F%98%E5%8D%B7%E7%A7%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">形变卷积;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    茹晓青 女, (1993-) , 硕士研究生.研究方向为图像处理、模式识别.;
                                </span>
                                <span>
                                    华国光 男, (1994-) , 硕士研究生.研究方向为计算机视觉、深度学习.;
                                </span>
                                <span>
                                    *李丽宏 (通讯作者) 女, (1974-) , 博士, 副教授.研究方向为图像处理、计算机视觉、深度学习.E-mail:lilihgg@163.com.;
                                </span>
                                <span>
                                    李莉 女, (1984-) , 女, 博士, 讲师.研究方向为像处理、计算机视觉、模式识别.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>河北省自然科学基金 (sF2015402150);</span>
                                <span>河北省教育厅资助项目 (ZD2015087);</span>
                                <span>邯郸市科学技术研究与发展计划项目 (1721203049-1);</span>
                    </p>
            </div>
                    <h1><b>Handwritten Digital Recognition Based on Deformable Convolutional Neural Network</b></h1>
                    <h2>
                    <span>RU Xiao-qing</span>
                    <span>HUA Guo-guang</span>
                    <span>LI Li-hong</span>
                    <span>LI Li</span>
            </h2>
                    <h2>
                    <span>School of information and electrical engineering, Hebei University of Engineering</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In this paper, the deformable convolution module is introduced to enhance the modeling ability of the network to digital geometric transformation, and an improved handwritten digital recognition framework based on deformable CNN is proposed. In addition to improving the recognition accuracy, the framework can effectively reduce the training parameters and improve the recognition speed. This paper demonstrate state-of-the-art performance competing methods on the handwritten dataset and the transformed dataset.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=handwritten%20digital%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">handwritten digital recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deformable%20convolution&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deformable convolution;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-07-28</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="15" name="15" class="anchor-tag">1 <b>引言</b></h3>
                <div class="p1">
                    <p id="16">光学字符识别 (Optical Character Recognition, OCR) , 是指对文本资料的图像文件进行分析识别处理, 获取文字及版面信息的过程.光学字符识别是图像处理、模式识别等领域的热点研究问题.而手写体数字识别技术作为其中重要的分支, 其目的在于快速识别图像中的数字并进行分析存储操作.传统手写体数字方法无法完成多变外观数字识别任务, 极大影响了手写体数字系统的识别精度.</p>
                </div>
                <div class="p1">
                    <p id="17">近年来, 卷积神经网络 (Convolutional Neural Networks, CNN) 在视觉识别任务中取得了巨大的成功, 能有效的解决手写体因个人因素造成的笔画粗细、断笔、粘连等导致特征提取不准确的问题<citation id="63" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 使得识别系统对不同的手写风格具有较强的鲁棒性.本文以VGG-16<citation id="64" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>卷积神经网络为基础, 提出了一种基于形变卷积结构的CNN, 通过在原有网络结构中附加卷积层学习图像特征中的偏移量, 使卷积核一局部、密集和自适应的变形方式适应输入的图像目标, 附加的卷积层仅仅增加了少量的参数, 并不会对其速度造成影响.这种形变卷积结构能很好地提升CNN适应几何变换的能力, 从而提高手写体数字的识别精度.为了进一步提升手写体数字识别的速度, 论文采用了较小的卷积核取代原有网络结构的卷积核.通过实验结果的分析, 以及与相应算法的比较, 证明了本文方法的有效性.</p>
                </div>
                <h3 id="18" name="18" class="anchor-tag">2 <b>神经网络</b></h3>
                <div class="p1">
                    <p id="19">据文献<citation id="65" type="reference">[<a class="sup">3</a>,<a class="sup">4</a>]</citation>可得, 现有的一些神经网络算法在手写体数字识别中取得了成功, 但这些神经网络算法采用的是全连接的邻接关系网络来完成识别工作, 将产生大量的参数, 极大的消耗了计算机的计算资源.以一个28*28的灰度图像为例:由神经网络的输出公式可得:以参数1表示当前层, <i>x</i>为输入参数, 则<i>Z</i>为激活函数的参数, <i>g</i>表示为激活函数, <i>b</i>表示偏置数.</p>
                </div>
                <div class="p1">
                    <p id="20" class="code-formula">
                        <mathml id="20"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ζ</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mi>w</mi><msup><mrow></mrow><mrow><mrow><mo>[</mo><mn>1</mn><mo>]</mo></mrow></mrow></msup><mi>x</mi><mo>+</mo><mi>b</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>A</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mi>g</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mrow><mo> (</mo><mrow><mi>Ζ</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="21">当输入一个大小为28*28像素的图像时, 则神经网络有784个输入神经元, 则网络输入参数个数为784.此时参数数量并不大, 神经网络能较快的输出结果, 但是若输入图像像素为1000*1000时, 参数数量将会很大, 参数过多无疑会影响算法的性能, 此时若继续采用全连接的神经网络显然是不合适的.并且使用全连接的网络对图像进行分析并不符合逻辑, 因为全连接的网络并不考虑图像的空间结构, 而是以完全相同的基础来对待相距很远和彼此接近的输入像素, 但是输入的目标字符是空间结构概念.为了解决神经网络收敛速度慢以及空间结构的问题, 论文将引入卷积神经网络, 利用卷积神经网络的稀疏连接、权值共享、多特征图的特性来有效的处理输入的手写体数字.</p>
                </div>
                <h4 class="anchor-tag" id="22" name="22">2.1 <b>卷积神经网络</b></h4>
                <div class="p1">
                    <p id="23">卷积神经网络是一类特殊的前馈神经网络, 主要由卷积层和池化层交替连接的.卷积神经网络对特征的提取和分类都是在卷积层和池化层中进行的, 所以对卷积层和层级的优化能提高特征提取的精度并优化分类效果.卷积神经网络普遍结构如图1所示, 图中包含了两层卷积层, 分别是C1和C2以及两层池化层, 分别为P1和P2, 将目标图像输入网络中, 将输出图像的特征, 特征数目通常是由任务决定.输出的特征通常会连接一层到两层的全连接层, 最后连接柔性最大化层进行分类.</p>
                </div>
                <div class="area_img" id="24">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_024.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 卷积神经网络结构" src="Detail/GetImg?filename=images/WXYJ201904010_024.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>卷积神经网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_024.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="25" name="25">2.1.1 卷积层</h4>
                <div class="p1">
                    <p id="26">卷积层可看做是一个局部感受野, 也就是网络的部分连接.在一幅图像中, 局部相邻近的部位相关性较强, 较远的位置相关性较弱.因此, 神经网络中的神经元与其上一层神经元就不必进行全连接, 也能较好的提取到局部的特征.前层网络只需要局部感知, 在更高层将局部的信息综合起来就得到了全局的信息.如上述提到的在全连接层的网络中, 输入被描述成一列神经元, 而在卷积神经网络中, 是将其看做28*28的矩阵输入.输入的目标图像的局部区域被视为神经元的局部感受野, 它是输入像素上的一个小窗口.通过在输入的目标图像中交叉移动局部感受野就可以提取出更上一层的特征.卷积核的操作过程具体如图2所示.卷积操作过程如下: (1) 在输入特征图像上使用网格<i>R</i>进行局部区域采样. (2) 对采样值进行加权求和.卷积操作通过网格R定义感受野的尺寸以及扩展率.如:设定卷积核的扩展率为1, 则卷积核的大小为3*3, 则网格的采用偏移量为:</p>
                </div>
                <div class="p1">
                    <p id="27" class="code-formula">
                        <mathml id="27"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mrow><mo>{</mo><mrow><mrow><mo> (</mo><mrow><mo>-</mo><mn>1</mn><mo>, </mo><mo>-</mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mo> (</mo><mrow><mo>-</mo><mn>1</mn><mo>, </mo><mn>0</mn></mrow><mo>) </mo></mrow><mo>, </mo><mo>⋯</mo><mo>, </mo><mrow><mo> (</mo><mrow><mn>0</mn><mo>, </mo><mn>1</mn></mrow><mo>) </mo></mrow><mo>, </mo><mrow><mo> (</mo><mrow><mn>1</mn><mo>, </mo><mn>1</mn></mrow><mo>) </mo></mrow></mrow><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="28">对于输出的特征图<i>y</i>上的任意局部位置采样的值为:</p>
                </div>
                <div class="p1">
                    <p id="29" class="code-formula">
                        <mathml id="29"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mrow><mo> (</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub><mo>∈</mo><mi>R</mi></mrow></munder><mi>w</mi></mstyle><mrow><mo> (</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>) </mo></mrow><mi>X</mi><mrow><mo> (</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="30">式中, <i>p</i><sub><i>n</i></sub>表示的是网格<i>R</i>上进行迭代的位置, 并且每个网格位置<i>p</i><sub><i>n</i></sub>同时对应着权重参数<mathml id="31"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><mrow><mo> (</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>) </mo></mrow><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="32">卷积层最大的特性是权值共享:即为权值参数与阈值的共享.如没有这个特性, 构造的神经网络会由于参数过多而损害算法的性能, 以由10个32*32*1的特征图组成的特征图为例, 即每个特征图上有1 024个神经元.每个神经元对应输入图像上一块5*5*3的区域, 即一个神经元和输入图像的这块区域有75个连接, 即75个权值参数, 则共有75*1 024*10=768 000个权值参数, 这是非常复杂的.因此卷积神经网络引入“权值”共享原则, 即一个特征图上每个神经元对应的75个权值参数被每个神经元共享, 这样则只需75*10=750个权值参数, 而每个特征图的阈值也共享, 即需要10个阈值, 则总共需要750+10=760个参数.</p>
                </div>
                <div class="area_img" id="33">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_033.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 卷积核交叉移动过程" src="Detail/GetImg?filename=images/WXYJ201904010_033.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>卷积核交叉移动过程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_033.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="34" name="34">2.1.2 池化层</h4>
                <div class="p1">
                    <p id="35">卷积神经网络除了使用卷积层, 也经常用到池化层来缩减模型的大小, 提高网络模型的运算速度, 同时提高所提取特征的鲁棒性.池化层的作用就是降低层的计算复杂度, 简化从卷积层输出的信息.池化层类型分为平均池化与最大池化, 常用到的是最大池化.最大池化过程中有一组超级参数, 即过滤器大小<i>f</i>及步长<i>s</i>, 其中常用参数值是<i>f</i>=2, <i>s</i>=2, 其效果是相当于长度和宽度各减一半.另外, 根据经验可得出, 当最大池化输入大小为<i>n</i>*<i>n</i>时, 设其填充p (padding) 为0, 则输出大小为<mathml id="36"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mfrac><mrow><mi>n</mi><mo>-</mo><mi>f</mi></mrow><mi>s</mi></mfrac><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>*</mo><mo stretchy="false"> (</mo><mfrac><mrow><mi>n</mi><mo>-</mo><mi>f</mi></mrow><mi>s</mi></mfrac><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>.以4*4灰度图像为例, 设其过滤器大小为2*2, 步长为3, 其最大池化过程如图3所示.</p>
                </div>
                <div class="area_img" id="37">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 最大池化操作" src="Detail/GetImg?filename=images/WXYJ201904010_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 <b>最大池化操作</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="38" name="38" class="anchor-tag">3 <b>形变卷积神经网络</b></h3>
                <div class="p1">
                    <p id="39">在手写体数字识别任务中的一大挑战是如何处理数字的几何变换 (包括尺度、位置、角度以及局部笔画的形变) .CNN因其固定的内在结构, 导致了CNN无法很好的处理出现在手写体数字中的几何变换.一般的解决办法是进行数据增强, 通过对数据集进行几何变化, 使得数据集尽可能多的包含手写体数字可能的几何变化情况.这一方法的基础在于手写体数字的几何变换是已知的, 对于未知的几何变换将无法很好的识别.为此, 本文引入形变卷积<citation id="66" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 使卷积层以自适应的变形方式适应输入的图像目标, 从而增强整体网络建模几何变换的能力.形变卷积核的本质是在原网格<i>R</i>的基础上加上偏移量, 所加偏移量使通过附加的卷积层学习得到, 具体如图4所示.</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 3*3规则卷积抽样和形变卷积抽样" src="Detail/GetImg?filename=images/WXYJ201904010_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>4 3*3<b>规则卷积抽样和形变卷积抽样</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="41">形变卷积的具体操作是在 (4) 式的基础上, 网格<i>R</i>的每一个位置<i>p</i><sub><i>n</i></sub>增加了对应的偏移量<mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>Δ</mi><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub><mrow><mo>|</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Ν</mi></mrow></mrow></mrow><mo>}</mo></mrow></mrow></math></mathml>, 其中<mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mo>=</mo><mrow><mo>|</mo><mi>R</mi><mo>|</mo></mrow></mrow></math></mathml>.因此, 形变卷积的输出结果为:</p>
                </div>
                <div class="p1">
                    <p id="44" class="code-formula">
                        <mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mrow><mo> (</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mo>) </mo></mrow><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub><mo>∈</mo><mi>R</mi></mrow></munder><mi>w</mi></mstyle><mrow><mo> (</mo><mrow><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>) </mo></mrow><mi>X</mi><mrow><mo> (</mo><mrow><mi>p</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub><mo>+</mo><mi>Δ</mi><mi>p</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="45">形变卷积操作实现的关键是偏移量的学习.假设现有的卷积核, 其大小为3*3, 为了学习到特征图的偏移量, 我们构建了另一大小为3*3的卷积核, 并用构建的卷积核处理输入的特征图, 其输出的偏移量图大小与特征图大小一致, 通道数为2*3*3, 分别表示了特征图上的网格R上对应采样点的水平方向和垂直方向的偏移.由于偏移量通常为非整数, 因此需要通过双线性采样获取有效的采样网格<i>R</i>, 配合卷积权重获取最终的结果, 并且经过双线性采样后, 在反向传播时能有效的求取梯度, 从而学习到相关权重.具体的实现示例如图5所示.</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 3*3形变卷积" src="Detail/GetImg?filename=images/WXYJ201904010_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>5 3*3<b>形变卷积</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="47" name="47" class="anchor-tag">4 <b>实验</b></h3>
                <div class="p1">
                    <p id="48">实验平台为python 3上进行.本文验证算法使用的数据集为MNIST手写数字识别数据集.</p>
                </div>
                <h4 class="anchor-tag" id="49" name="49">4.1 <b>实验数据集</b></h4>
                <div class="p1">
                    <p id="50">MNIST数据集来自美国国家标准与技术研究所 (National Institute of Standards and Technology, NIST) , 是一个已经进行标记的手写体数字识别数据集.这个数据集由来自250个不同人手写的数字构成, 其中50%是高中学生, 50%来自人口普查局的工作人员, 包含了0到9总共10类的手写体数字图像, 每个图像的大小为28*28像素, 像素是由0到1的浮点数构成的, 黑色越深表示数值越靠近1.具体如图6所示.数据集共有70 000张手写体数字样本, 其中60 000张为训练样本和10 000张为测试样本, 部分示例如图7所示.</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 数据集图像表示结构" src="Detail/GetImg?filename=images/WXYJ201904010_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>6 <b>数据集图像表示结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 MNIST数据集部分手写体数字" src="Detail/GetImg?filename=images/WXYJ201904010_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>7 MNIST<b>数据集部分手写体数字</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="53">为了验证本文提出方法的有效性, 通过仿射变换对MNIST数据句进行几何变换, 获取经过变换后的MNIST手写体数据集进行手写体数字识别实验.通过与现有算法在正常MNIST数据集和变形MNIST数据集上进行对比实验.</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54">4.2 <b>实验训练细节</b></h4>
                <div class="p1">
                    <p id="55">论文提出的基于形变卷积神经网路的总体结构如图8所示.本文以通过ImageNet<citation id="67" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>进行预训练的VGG-16网络为基础网络, 将学习到的参数迁移到修改后的网络中, 并进行修改.为了使网络获得能够适应手写体数字几何形变的能力, 本文引入形变卷积核, 取代VGG-16网络中的部分卷积核, 同时使用1*1卷积核替换部分原有卷积核.实验采用的反向传播优化算法为Adam优化算法.卷积神经网络的各项参数为:学习率设置为0.0001, 迭代的次数为10 000, 批量归一化的大小为32.具体而详细的网络结构被列在表1中 (表中卷积核表示为Conv, 形变卷积核表示为D-conv, 池化表示为Maxpool, 全连接表示为Fcn) .</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201904010_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 基于形变卷积神经网络结构" src="Detail/GetImg?filename=images/WXYJ201904010_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>8 <b>基于形变卷积神经网络结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201904010_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="57">
                    <p class="img_tit"><b>表</b>1 <b>网络的具体设置</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="57" border="1"><tr><td><br /></td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr><tr><td><br />结构名称</td><td>Conv1-1<br />Conv1-2</td><td>Maxpool</td><td>Conv3-1<br />Conv3-2</td><td>Maxpool</td><td>D-conv5-1<br />D-conv5-2</td></tr><tr><td><br />核大小</td><td> (3, 3) <br /> (3, 3) </td><td> (2, 2) </td><td> (3, 3) <br /> (1, 1) </td><td> (2, 2) </td><td> (3, 3) <br /> (3, 3) </td></tr><tr><td><br /></td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td><br />结构名称</td><td>Maxpool</td><td>D-conv7-1<br />D-conv7-2<br />D-conv7-3</td><td>Maxpool</td><td>Fcn-9</td><td>Fcn-10</td></tr><tr><td><br />核大小</td><td> (2, 2) </td><td> (3, 3) <br /> (3, 3) <br /> (1, 1) </td><td> (2, 2) </td><td>1024</td><td>10</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="58" name="58">4.3 <b>实验结果分析</b></h4>
                <div class="p1">
                    <p id="59">为了验证本文算法的有效性, 我们在MNIST数据集上进行方法的评估.训练过程进行了20代, 每次有1 875张训练样本, 处理没一张样本所用的平均时间为139ms示.本文所提算法与其它算法的定量分析如表2.本文提出算法在MNIST数据集中的准确率并不是最佳的, 但是仍然取得了较优的精度.更值得注意的是本实验通过仿射变换获取了形变的MNIST数据集, 并将基于VGG-16的常规卷积神经网络与基于形变卷积神经网络应用于形变的MNIST数据集, 可以发现基于形变卷积神经网络能够很好的适应手写体数字的几何变换, 在面对未知的变化时, 能够更好的进行识别, 并取得了0.9476的精度, 比基于VGG-16的常规卷积神经网络高出了0.3的精度, 这一结果表明了本文所提算法的有效性.</p>
                </div>
                <div class="area_img" id="60">
                    <p class="img_tit"><b>表</b>2 <b>形变卷积神经网络与其它方法比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="60" border="1"><tr><td><br />方法</td><td>MNIST</td><td>形变MNSIT</td></tr><tr><td><br />Lecun et al.[17]</td><td>0.9925</td><td>-</td></tr><tr><td><br />陈等人. [18]</td><td>0.9920</td><td>-</td></tr><tr><td><br />张等人. [19]</td><td>0.8900</td><td>-</td></tr><tr><td><br />王等人. [20]</td><td>0.9448</td><td>-</td></tr><tr><td><br />赵等人. [21]</td><td>0.9945</td><td>-</td></tr><tr><td><br />赵等人. [22]</td><td>0.9965</td><td>-</td></tr><tr><td><br />卷积神经网络</td><td>0.9972</td><td>0.6386</td></tr><tr><td><br />形变卷积神经网络</td><td>0.9948</td><td>0.9472</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="61" name="61" class="anchor-tag">5 <b>结束语</b></h3>
                <div class="p1">
                    <p id="62">学习和适应手写体数字的几何变换能使数字分类达到了更好的效果, 使得识别精度更高.因此, 本文通过引入形变卷积操作, 对VGG-16网络进行改进, 并使用MNIST数据集进行训练, 从而获取能有效提取和分类手写体数字的形变卷积神经网络.通过在MNIST数据集上进行实验, 并与现有的方法以及卷积神经网络进行比较.实验结果表明, 基于形变卷积神经网络的手写体数字方法具有较高的识别精度以及收敛速度, 也侧面证明了对几何变换的处理能有效的提高特征提取精度.同时, 本文的网络结构具有普适性, 能够很好的泛化到多任务中.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201802015&amp;v=MzEwNTE0TzN6cXFCdEdGckNVUkxPZVplVnVGeXptVnJ2QU1qWFNaTEc0SDluTXJZOUVZWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 陈岩, 李洋洋, 余乐, 等. 基于卷积神经网络的手写体数字识别系统[J]. 微电子学与计算机, 2018, 35 (2) :71-74.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[2]</b> KAREN SIONYAN, ANDREW ZISSERMAN. Very deep convolutional networks for large-scale image recognition[J]. Computer Science, 2014, arXiv preprint arXiv:1409.1556.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201806016&amp;v=MDc2ODc0SDluTXFZOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeXptVnJ2QUlUZklZckc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 赵朋成, 冯玉田, 涂云轩. 基于高倍特征深度残差网络的手写数字识别[J]. 电子测量技术, 2018, 6 (41) :86-89.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Handwritten/Printed Receipt Classification Using Attention-Based Convolutional Neural Network">

                                <b>[4]</b> YANG F, JIN L, YANG W, et al. Handwritten/Printed Receipt Classification Using Attention-Based Convolutional Neural Network[C]// International Conference on Frontiers in Handwriting Recognition. IEEE, 2017:384-389.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deformable Convolutional Networks">

                                <b>[5]</b> DAI JIFENG, et al. Deformable Convolutional Networks [C]// Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017:764-773.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet:A large-scale hierarchical image database">

                                <b>[6]</b> DENG J, DONG W, Socher R, et al. ImageNet: A large-scale hierarchical image database[C]//IEEE Conference on Computer Vision and Pattern Recognition, 2009:248-255.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="WXYJ201904010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201904010&amp;v=MTAwMDhaZVZ1Rnl6bVZydkFNalhTWkxHNEg5ak1xNDlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2U=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNJUGsvbURSNjZHaHV0MCsxOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
