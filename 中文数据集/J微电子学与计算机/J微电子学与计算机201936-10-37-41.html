<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133367026690000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dWXYJ201910008%26RESULT%3d1%26SIGN%3d7%252fpuQ6gVJBKIg1YbGQWYhe9%252bhzU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201910008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201910008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201910008&amp;v=MDYzMDNTWkxHNEg5ak5yNDlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3N0lNalg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#13" data-title="1 &lt;b&gt;引言&lt;/b&gt; ">1 <b>引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#17" data-title="2 &lt;b&gt;脉冲卷积神经网络背景知识&lt;/b&gt; ">2 <b>脉冲卷积神经网络背景知识</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#18" data-title="2.1  &lt;b&gt;脉冲神经元和卷积核工作原理&lt;/b&gt;">2.1  <b>脉冲神经元和卷积核工作原理</b></a></li>
                                                <li><a href="#26" data-title="2.2 &lt;b&gt;脉冲卷积神经网络转换算法原理&lt;/b&gt;">2.2 <b>脉冲卷积神经网络转换算法原理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#36" data-title="3 &lt;b&gt;脉冲卷积神经网络电路设计&lt;/b&gt; ">3 <b>脉冲卷积神经网络电路设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="3.1 &lt;b&gt;卷积层和全连接层脉冲神经元电路结构&lt;/b&gt;">3.1 <b>卷积层和全连接层脉冲神经元电路结构</b></a></li>
                                                <li><a href="#44" data-title="3.2 &lt;b&gt;池化层电路结构&lt;/b&gt;">3.2 <b>池化层电路结构</b></a></li>
                                                <li><a href="#47" data-title="3.3 &lt;b&gt;总体电路结构&lt;/b&gt;">3.3 <b>总体电路结构</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#52" data-title="4 &lt;b&gt;电路仿真和测试结果&lt;/b&gt; ">4 <b>电路仿真和测试结果</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="5 &lt;b&gt;结束语&lt;/b&gt; ">5 <b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#33" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;归一化算法流程&lt;/b&gt;"><b>图</b>1 <b>归一化算法流程</b></a></li>
                                                <li><a href="#40" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;脉冲神经元电路结构&lt;/b&gt;"><b>图</b>2 <b>脉冲神经元电路结构</b></a></li>
                                                <li><a href="#49" data-title="&lt;b&gt;图&lt;/b&gt;3 &lt;b&gt;实现手写体识别的脉冲卷积网络电路结构&lt;/b&gt;"><b>图</b>3 <b>实现手写体识别的脉冲卷积网络电路结构</b></a></li>
                                                <li><a href="#54" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;不同转换算法对网络性能的影响&lt;/b&gt;"><b>表</b>1 <b>不同转换算法对网络性能的影响</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;功耗结果对比&lt;/b&gt;"><b>表</b>2 <b>功耗结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" CAO Y,CHEN Y,KHOSLA D.Spiking deep convolutional neural networks for energy-efficient object recognition[J].International Journal of Computer Vision,2015,113(1):54-66." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition">
                                        <b>[1]</b>
                                         CAO Y,CHEN Y,KHOSLA D.Spiking deep convolutional neural networks for energy-efficient object recognition[J].International Journal of Computer Vision,2015,113(1):54-66.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" DIEHL P U,NEIL D,BINAS J,et al.Fast-classifying,high-accuracy spiking deep networks through weight and threshold balancing[C]//2015 International Joint Conference on Neural Networks (IJCNN).IEEE,2015:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast-classifying,high-accuracy spiking deep networks through weight and threshold balancing">
                                        <b>[2]</b>
                                         DIEHL P U,NEIL D,BINAS J,et al.Fast-classifying,high-accuracy spiking deep networks through weight and threshold balancing[C]//2015 International Joint Conference on Neural Networks (IJCNN).IEEE,2015:1-8.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" LECUN Y,JACKEL L D,BOTTOU L,et al.Learning algorithms for classification:A comparison on handwritten digit recognition[J].Neural networks:the statistical mechanics perspective,1995,261:276." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning algorithms for classification:a comparison on handwritten digit recognition">
                                        <b>[3]</b>
                                         LECUN Y,JACKEL L D,BOTTOU L,et al.Learning algorithms for classification:A comparison on handwritten digit recognition[J].Neural networks:the statistical mechanics perspective,1995,261:276.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" ANWAR S,HWANG K,SUNG W.Fixed point optimization of deep convolutional neural networks for object recognition[C]//2015 IEEE International Conference on Acoustics,Speech and Signal Processing (ICASSP).IEEE,2015:1131-1135." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fixed point optimization of deep convolutional neural networks for object recognition">
                                        <b>[4]</b>
                                         ANWAR S,HWANG K,SUNG W.Fixed point optimization of deep convolutional neural networks for object recognition[C]//2015 IEEE International Conference on Acoustics,Speech and Signal Processing (ICASSP).IEEE,2015:1131-1135.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     JIA Y,SHELHAMER E,DONAHUE J,et al.Caffe:Convolutional architecture for fast feature embedding[C]//Proceedings of the 22nd ACM international conference on Multimedia.ACM,2014:675-678.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=WXYJ" target="_blank">微电子学与计算机</a>
                2019,36(10),37-41             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种脉冲卷积神经网络VLSI硬件架构设计</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%96%9B%E5%A4%A9%E5%BF%97&amp;code=42324031&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">薛天志</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E7%99%BE%E6%88%90&amp;code=42943870&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘百成</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%9D%BE&amp;code=17730595&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈松</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6&amp;code=0002522&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学技术大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>本文设计了一种识别手写体数字的脉冲卷积神经网络数字电路,使用脉冲神经元代替卷积核,并分别对卷积层和池化层设计相应的电路结构,实现全流水线并行.相比于传统的卷积神经网络,在识别MNIST数据集时,卷积神经网络的精确度为98.61%时,脉冲卷积神经网络的精度能达到98.04%.与相同流水线结构的卷积神经网络相比,脉冲神经网络平均能耗减少约50%.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%84%89%E5%86%B2%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%94%B5%E8%B7%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">脉冲卷积神经网络电路;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%8B%E5%86%99%E4%BD%93%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">手写体识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E5%AD%97%E9%9B%86%E6%88%90%E7%94%B5%E8%B7%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数字集成电路;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    薛天志,男,(1993),硕士研究生.研究方向为数字集成电路设计.E-mail:qtqtyyy@mail.ustc.edu.cn;
                                </span>
                                <span>
                                    刘百成,男,(1994),硕士研究生．研究方向为数字集成电路设计．;
                                </span>
                                <span>
                                    陈松,男,(1979),博士,副教授．研究方向为高能效计算,VLSI计算机辅助设计．;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金(61732020);</span>
                    </p>
            </div>
                    <h1><b>A hardware implementation of a spiking convolutional neural network</b></h1>
                    <h2>
                    <span>XUE Tian-zhi</span>
                    <span>LIU Bai-cheng</span>
                    <span>CHEN Song</span>
            </h2>
                    <h2>
                    <span>University of Science and Technology of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>This paper designed a digital circuit of spiking convolutional neural network for recognizing handwriting number. Spiking neurons are used to replace the convolution kernels in CNN. Corresponding circuit structures are designed for convolution layer and pooling layer respectively to achieve full pipeline parallelism. Compared with the traditional convolutional neural network, when recognizing the MNIST dataset, the accuracy of the two is 98.61% and 98.04% respectively. Compared with CNN that has similar pipeline architecture, spiking convolutional neural network has a 50% reduction in average energy consumption.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=spiking%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">spiking neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=handwriting%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">handwriting recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Digital%20IC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Digital IC;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="13" name="13" class="anchor-tag">1 <b>引言</b></h3>
                <div class="p1">
                    <p id="14">近年来,随着计算能力的提升,神经网络在众多研究领域引起关注,其中发展较为迅速的是卷积神经网络(CNN),但是卷积神经网络的工作方式和人体内的神经传递方式完全不同,所以另一种更接近生物神经元信息传导方式的脉冲神经网络(SCNN)<citation id="61" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>逐渐开始发展起来.脉冲神经网络相比于卷积神经网络,具有更少的计算量,由此带来了高能效,但是由于缺乏有效的训练算法,所以目前并没有很好的应用场景.目前脉冲神经网络的应用之一是处理卷积神经网络的计算任务,以此来降低功耗,提升能效.</p>
                </div>
                <div class="p1">
                    <p id="15">相比于卷积神经网络,脉冲神经网络的理论计算量能减少两个数量级左右<citation id="62" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,所以使用脉冲神经网络处理卷积神经网络的计算任务是一种很有前景的高能效移动端解决方案.一种实现脉冲神经网络的思路是借用卷积神经网的训练方法,训练好网络后将网络权重转换为脉冲神经元之间的连接强度,由此得到一个脉冲卷积神经网络.转换后会伴随着网络识别率的下降,如何降低网络性能的下降是转换算法的关键问题,一种常用的算法是对网络的权重进行归一化<citation id="63" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,这样在网络中的脉冲分布会更均衡一些,从而使性能的下降不会过大.</p>
                </div>
                <div class="p1">
                    <p id="16">在卷积神经网络中,卷积层和池化层是主要的组成部分,设计更适合进行卷积和池化的硬件加速电路对卷积神经网络的硬件性能有重要的作用.同理,在设计脉冲卷积神经网络的时候,如何实现相对应的卷积层和池化层也是重要的研究问题.</p>
                </div>
                <h3 id="17" name="17" class="anchor-tag">2 <b>脉冲卷积神经网络背景知识</b></h3>
                <h4 class="anchor-tag" id="18" name="18">2.1  <b>脉冲神经元和卷积核工作原理</b></h4>
                <div class="p1">
                    <p id="19">为了能实现脉冲神经元和卷积核的一一对应,对卷积核和神经元都要进行一定的约束,卷积核的计算可以表示成下面的公式:</p>
                </div>
                <div class="p1">
                    <p id="20" class="code-formula">
                        <mathml id="20"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ζ</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>m</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>n</mi></munder><mi>x</mi></mstyle></mrow></mstyle><mo stretchy="false">(</mo><mi>i</mi><mo>+</mo><mi>m</mi><mo>,</mo><mi>j</mi><mo>+</mo><mi>n</mi><mo stretchy="false">)</mo><mi>w</mi><mo stretchy="false">(</mo><mi>m</mi><mo>,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="21">脉冲神经元功能可以表示成下面的公式:</p>
                </div>
                <div class="p1">
                    <p id="22" class="code-formula">
                        <mathml id="22"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>f</mi></munder><mi>w</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>s</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>,</mo><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mi>V</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>h</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>s</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>,</mo><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>&gt;</mo><mi>V</mi><msub><mrow></mrow><mrow><mi>t</mi><mi>h</mi></mrow></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="23">卷积核的功能是将输入<i>x</i>和卷积核权重<i>w</i>对应相乘,并加上偏置值后输出到下一级.而脉冲神经元的功能则是在接收到突触前神经元发射过来的脉冲后,将自身的膜电位<i>V</i>(<i>t</i>-1)依据突触权重改变相应的值,若膜电位超过了阈值电压<i>V</i><sub><i>th</i></sub>,则会向下一级脉冲神经元发射脉冲,否则不发射脉冲.</p>
                </div>
                <div class="p1">
                    <p id="24">对比两个结构的公式,脉冲神经元中不含偏置项;脉冲神经元的工作方式决定了输出只能是正值,所以对输出含有负值的卷积核需要双倍的神经元来实现功能.为了避免过高的硬件代价和精度损失,对卷积神经网络模型需要进行约束:(1)取消偏置项;(2)使用ReLU激活函数.</p>
                </div>
                <div class="p1">
                    <p id="25">在池化层中,由于脉冲神经元很难单独实现最大化池化,所以池化层只能使用平均值池化的方式,这样用单个脉冲神经元即可完成池化功能.</p>
                </div>
                <h4 class="anchor-tag" id="26" name="26">2.2 <b>脉冲卷积神经网络转换算法原理</b></h4>
                <div class="p1">
                    <p id="27">由卷积神经网络转换成脉冲卷积神经网络的算法有两种,一种是直接进行转换的方法,这种方法对小规模的网络效果很好,而且速度较快.但是在网络规模变大时,精度会迅速下降.另一种算法是基于归一化的思想,对每一层的神经元权重进行归一化,这样在网络中主要的信息会更容易通过脉冲传递到下一层.</p>
                </div>
                <div class="p1">
                    <p id="28">进行直接转换时,脉冲神经元会产生过激活和欠激活.过激活是指脉冲神经元很容易发射脉冲,在同一时刻,网络中有数量较多的脉冲,关键的信息淹没在大量不重要的信息中,这既导致网络的精度收到影响,也使网络有很多无意义的能耗产生.而欠激活则是指神经元要经过很长的时间才能发射脉冲,当网络的层数很大时,这种时延影响是按指数增长的,导致网络的识别时间过长甚至无法识别,也导致在硬件实现的时候,静态功耗占比过大,整个网络的能效反而很低.这二者均是严重影响脉冲卷积神经网络性能的原因.归一化算法则能很好的降低这二者的影响,在延迟不是很大的情况下,能达到和卷积神经网络相差不大的精确度.</p>
                </div>
                <div class="p1">
                    <p id="29">由于直接转换的方法太不稳定,以至于在手写体规模的网络上精度即开始大幅度下降,所以我们采用归一化的方法来进行卷积核权重到脉冲神经元连接强度的转换,归一化算法如图1所示,可以简单的描述如下:</p>
                </div>
                <div class="p1">
                    <p id="30">(1)求出卷积神经网络某一层中每一个卷积核的正权重和,并选出其中最大的和.</p>
                </div>
                <div class="p1">
                    <p id="31">(2)将这一层的权重均除以第一步得到的最大权重和.</p>
                </div>
                <div class="p1">
                    <p id="32">(3)将转换后的权重作为对应的脉冲神经元的突触权重.</p>
                </div>
                <div class="area_img" id="33">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910008_033.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 归一化算法流程" src="Detail/GetImg?filename=images/WXYJ201910008_033.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>归一化算法流程</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910008_033.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="34">进行归一化算法后,把脉冲神经元的阈值电压设为1,即能保证一个时钟周期最多只能发射一个脉冲,与卷积神经网络相比传递的数据的损失不大,对分类有重要作用的脉冲更易早一些发射出来,而不重要的脉冲则晚一些才会发射,对精度有很大的提升.</p>
                </div>
                <div class="p1">
                    <p id="35">这种归一化算法只和训练好的网络模型有关,还有一种思路是按照数据集来进行归一化,即网络模型训练好后,对数据集进行一次识别,统计在识别时每一层能达到的最大值,并以这个值代替原归一化算法中的权重和最大值,进行归一化.这种改进的归一化算法虽然在测试集上能有较好的性能,但是在识别非数据集的数据时,稳定性并不如原始的归一化算法,所以在本文中,采用的算法是更有稳定性的原始的归一化算法.</p>
                </div>
                <h3 id="36" name="36" class="anchor-tag">3 <b>脉冲卷积神经网络电路设计</b></h3>
                <div class="p1">
                    <p id="37">本文所用到的网络模型为手写体数字识别的经典模型LeNet-5<citation id="64" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>的简化模型,以其为基础进行脉冲卷积神经网络转换.网络的基本结构:第一层由6个卷积核组成;第二层为2*2池化;第三层是部分连接层,由60个卷积核进行部分连接,最终产生16个输出;第四层为2*2池化;第五层是全连接卷积层,有120个输出,最后一层为全连接层,直接连接到10个输出.下面将分别从基本的神经元电路和总体电路来介绍本文的脉冲卷积神经网络电路架构.</p>
                </div>
                <h4 class="anchor-tag" id="38" name="38">3.1 <b>卷积层和全连接层脉冲神经元电路结构</b></h4>
                <div class="p1">
                    <p id="39">脉冲神经元的电路结构如图2所示,整个神经元的权重采用分布式存储的方式,将每个通道的权重分别存在一个小的片上存储器中.在电路工作的时候,对应通道的神经元突触权值暂存在寄存器w1-w25中,有脉冲输入时,二选一选择器会选通,将权值经过加法树累加,和上一时刻的膜电位V(t-1)相加,得到新的膜电位.若新的膜电位大于阈值V<sub>th</sub>,则发射脉冲(outspike),同时将膜电位重置为V<sub>r</sub>,否则不发射脉冲,保留新的膜电位.更新后的膜电位将存储到片上存储器中,在下一次该神经元进行动作的时候作为旧的膜电位缓存到V(t-1).</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910008_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 脉冲神经元电路结构" src="Detail/GetImg?filename=images/WXYJ201910008_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>脉冲神经元电路结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910008_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="41">采用分布式存储可以很容易的对硬件进行分时复用,从而在有限的硬件资源上实现大量的脉冲神经元.处理完数据后,将w1-w25的值清零,并重新在存储器中读取新的权重,V(t-1)也同时读取对应的上一时刻神经元膜电位,即可实现多个神经元共享相同的硬件资源.</p>
                </div>
                <div class="p1">
                    <p id="42">在卷积神经网络中,全连接层也是一个重要的组成部分,全连接层的特点通常是输入数目很大,但是对数据没有复用,我们仍可以使用这种结构来处理,通过对w1-w25寄存器的值进行配置,每个周期处理全连接层的一部分数据,然后重新读取权重到w1-w25中,用多个时钟周期来实现全连接层的功能.</p>
                </div>
                <div class="p1">
                    <p id="43">在脉冲卷积神经网络中,并没有乘法操作,只有膜电位的加减,为了简化电路,降低电路的功耗,一种方法是将浮点的权重进行定点化,根据前人的研究<citation id="65" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>,8 bit数定点化对网络精确度的影响可以忽略不计.另一种办法是采用补码运算,通过补码的方式可以将加法和减法的操作统一起来,对加法器的要求降低,从而降低加法器电路的复杂度,进而降低电路的功耗.</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44">3.2 <b>池化层电路结构</b></h4>
                <div class="p1">
                    <p id="45">卷积神经网络中有两种常见的池化方式:最大值池化和平均值池化.最大值池化的特点是选择区域内最大的值传到下一层,即将对分类关键的信息传送到下一层.在脉冲神经网络中,实现类似的功能需要将最早发出脉冲的脉冲序列发送到下一级.但是在实际测试中,当采用最大值池化的方式时,将在一定程度上影响整个网络的精确度.</p>
                </div>
                <div class="p1">
                    <p id="46">所以采用平均值池化的方式在电路上更容易设计,实现电路和卷积层的电路相似,但是可以进一步简化,以2*2池化为例,一个池化电路只需要有四个输入,每个输入的权重为1,当膜电位超过4后即向下一层发射一个脉冲.在池化的时候权重并不需要变动,但是相应的膜电位还是要进行存储以便于分时处理.</p>
                </div>
                <h4 class="anchor-tag" id="47" name="47">3.3 <b>总体电路结构</b></h4>
                <div class="p1">
                    <p id="48">为了在网络中实现数据的复用,需要一些中间电路来对数据进行缓存,在用LeNet-5网络处理MNIST数据集时,输入端首先要缓存好五行数据,然后处理前五列数据,处理后丢掉第一列数据,并读入一列新数据,中间四列在下次处理还会用到.当处理完一行数据后,同样将第一行的数据丢掉,读入新的一行,中间的四行仍需要复用.在总体图中的数据输入部分的电路就是实现这个功能的.通过五行首位相连的FIFO对输入数据进行缓存,这样在处理数据的同时,会将数据写入到下一个FIFO.在数据缓存好后,从五个FIFO同步读数据到卷积层,缓存好25个数据后脉冲神经元开始工作.当一行数据都处理完之后,要先缓存五个新的数据,神经元才能再次工作.</p>
                </div>
                <div class="area_img" id="49">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201910008_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 实现手写体识别的脉冲卷积网络电路结构" src="Detail/GetImg?filename=images/WXYJ201910008_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 <b>实现手写体识别的脉冲卷积网络电路结构</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201910008_049.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="50">神经网络的第一层处理过的脉冲序列将发送到一个缓存结构中,缓存一行加2个数据后,池化层开始工作,池化层的输出经过一个缓存结构后再通过一个部分连接网络,输入到第三层,将信号给不同的神经元处理,输出的结果再经过池化层,然后经过两次全连接层,最后哪个输出端先发出脉冲,图像就被识别为哪一类.脉冲卷积网络电路和结构图如图3.</p>
                </div>
                <div class="p1">
                    <p id="51">在框图靠右侧的通路是控制通路,输入是图像的行有效信号,每当来一行新的数据,需要第五个周期才会工作.开始工作的时候,有限状态机FSM_1决定何时缓存从第一层传入的数据,当从第一层缓存的数据可以开始进行池化时,控制池化电路工作和下一层进行缓存.状态机功能都是类似的.</p>
                </div>
                <h3 id="52" name="52" class="anchor-tag">4 <b>电路仿真和测试结果</b></h3>
                <div class="p1">
                    <p id="53">本文的脉冲卷积神经网络电路基于SMIC40nm工艺库,采用高阈值库来降低静态功耗,对MNIST数据集进行识别,将统计到的翻转率导入Syonpsys Design Compiler中,在时钟频率为200 MHz的情况下进行功耗分析.结果与相同结构的卷积神经网络进行对比.</p>
                </div>
                <div class="area_img" id="54">
                    <p class="img_tit"><b>表</b>1 <b>不同转换算法对网络性能的影响</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="54" border="1"><tr><td><br />转换算法</td><td>精确度(%)</td><td>网络中脉冲数(k)</td></tr><tr><td><br />CNN</td><td>98.61</td><td>0</td></tr><tr><td><br />直接转换算法</td><td>89.12</td><td>9</td></tr><tr><td><br />归一化算法</td><td>98.04</td><td>19</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="55">表1显示的是不同转换算法对精度的影响,利用Caffe<citation id="66" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>训练平台进行训练,模型采用lenet-5,并将模型中的卷积核偏置项置零,将池化方式都改为平均值池化,训练后的精确度相比原始模型有0.4%的下降.然后将权重提取出来,放入用C语言搭建好的SCNN测试平台.最后通过WTA(winner takes all)的决策方法进行分类,即哪个通道先发出脉冲,就将分类结果定为哪一类.直接转换算法的测试结果相比于训练好的CNN下降了9.49%.而将权重归一化后,网络的精确度只下降0.57%.归一化后,网络中的脉冲数增加了一倍多,传递了更多的信息,所以分类结果更精确.</p>
                </div>
                <div class="area_img" id="56">
                    <p class="img_tit"><b>表</b>2 <b>功耗结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">(单位:mW)</p>
                    <table id="56" border="1"><tr><td><br />网络</td><td>动态功耗</td><td>静态功耗</td><td>总功耗</td></tr><tr><td><br />卷积神经网络</td><td>75.3</td><td>2.2</td><td>77.5</td></tr><tr><td><br />脉冲神经网络</td><td>0.166</td><td>0.304</td><td>0.47</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="57">通过DC分析,脉冲神经网络的面积约为3.31 mm<sup>2</sup>,而卷积神经网路的面积只有1.42 mm<sup>2</sup>,这是因为在脉冲神经网络中进行神经元复用的时候,所有的膜电位都需要额外的存储空间.但是由于电路中运算较少,亚阈值电流造成的功耗降低很多,同时采用SMIC40nm高阈值工艺库进一步降低静态功耗,实际静态功耗反而比卷积神经网络要小.而卷积神经网络中运算量很大,若采取相同的措施来降低静态功耗,动态功耗反而会上升的更多,所以卷积神经网络电路主要采用标准的SMIC40 nm工艺库对动态功耗进行优化.</p>
                </div>
                <div class="p1">
                    <p id="58">表2给出了两种不同类型的网络在SMIC040工艺下的功耗对比.卷积神经网络中有很多的乘累加计算,在电路中动态功耗很大,而脉冲网络中的脉冲神经元只有接收到脉冲才会动作,网络中的脉冲数很少,所以动态功耗很低,相比之下静态功耗的占比显著提高.对识别一幅图的平均能耗进行分析,采用脉冲率编码对图像编码后,脉冲网络处理一幅图的时间大约是卷积网络的80倍,但由于脉冲神经网络中的运算数明显少于卷积神经网络,所以在MNIST数据集上平均识别一幅图的能耗大概是卷积网络的50%,有很明显的能效优势.</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag">5 <b>结束语</b></h3>
                <div class="p1">
                    <p id="60">介绍了脉冲神经网络的基本原理,重点介绍了脉冲神经网络的硬件电路实现.设计一种可以时分复用的脉冲神经元电路来实现卷积层和全连接层,并针对不同的池化方式设计了池化层电路.在SMIC40nm工艺库下,本文介绍的脉冲卷积神经网络硬件电路相比于卷积神经网络电路能耗降低50%左右.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition">

                                <b>[1]</b> CAO Y,CHEN Y,KHOSLA D.Spiking deep convolutional neural networks for energy-efficient object recognition[J].International Journal of Computer Vision,2015,113(1):54-66.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast-classifying,high-accuracy spiking deep networks through weight and threshold balancing">

                                <b>[2]</b> DIEHL P U,NEIL D,BINAS J,et al.Fast-classifying,high-accuracy spiking deep networks through weight and threshold balancing[C]//2015 International Joint Conference on Neural Networks (IJCNN).IEEE,2015:1-8.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning algorithms for classification:a comparison on handwritten digit recognition">

                                <b>[3]</b> LECUN Y,JACKEL L D,BOTTOU L,et al.Learning algorithms for classification:A comparison on handwritten digit recognition[J].Neural networks:the statistical mechanics perspective,1995,261:276.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fixed point optimization of deep convolutional neural networks for object recognition">

                                <b>[4]</b> ANWAR S,HWANG K,SUNG W.Fixed point optimization of deep convolutional neural networks for object recognition[C]//2015 IEEE International Conference on Acoustics,Speech and Signal Processing (ICASSP).IEEE,2015:1131-1135.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 JIA Y,SHELHAMER E,DONAHUE J,et al.Caffe:Convolutional architecture for fast feature embedding[C]//Proceedings of the 22nd ACM international conference on Multimedia.ACM,2014:675-678.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="WXYJ201910008" />
        <input id="dpi" type="hidden" value="800" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201910008&amp;v=MDYzMDNTWkxHNEg5ak5yNDlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ2RkNqa1Y3N0lNalg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVC9sRzVOZlY0eG5jQ2MrRjhjT2RFVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
