<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637133885599943750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dWXYJ201905016%26RESULT%3d1%26SIGN%3dGyiwjoXCFPIKCjOjaVeMZMZYWuk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201905016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=WXYJ201905016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201905016&amp;v=MjYwMDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5am1XN3pJTWpYU1pMRzRIOWpNcW85RVlvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="1 &lt;b&gt;引言&lt;/b&gt; ">1 <b>引言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="2 &lt;b&gt;基本理论&lt;/b&gt; ">2 <b>基本理论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#78" data-title="3 &lt;b&gt;决策理论粗糙集的新属性约简&lt;/b&gt; ">3 <b>决策理论粗糙集的新属性约简</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#150" data-title="4 &lt;b&gt;实验分析&lt;/b&gt; ">4 <b>实验分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#163" data-title="5 &lt;b&gt;结束语&lt;/b&gt; ">5 <b>结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#90" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;信息系统&lt;/b&gt;"><b>表</b>1 <b>信息系统</b></a></li>
                                                <li><a href="#152" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;实验数据集&lt;/b&gt;"><b>表</b>2 <b>实验数据集</b></a></li>
                                                <li><a href="#154" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;属性约简结果&lt;/b&gt;"><b>表</b>3 <b>属性约简结果</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表&lt;/b&gt;4 CART&lt;b&gt;分类精度&lt;/b&gt;/%"><b>表</b>4 CART<b>分类精度</b>/%</a></li>
                                                <li><a href="#158" data-title="&lt;b&gt;表&lt;/b&gt;5 SVM&lt;b&gt;分类精度&lt;/b&gt;/%"><b>表</b>5 SVM<b>分类精度</b>/%</a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;各个数据集在不同算法下属性约简时间比较&lt;/b&gt;"><b>图</b>1 <b>各个数据集在不同算法下属性约简时间比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="180">


                                    <a id="bibliography_1" title=" PAWLAK Z.Rough set[J].International Journal of Computer &amp;amp; Information Sciences, 1982, 11 (5) :341-356." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rough Sets Int">
                                        <b>[1]</b>
                                         PAWLAK Z.Rough set[J].International Journal of Computer &amp;amp; Information Sciences, 1982, 11 (5) :341-356.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_2" title=" 蒲国林.基于粗糙集与信息增益的情感特征选择方法[J].微电子学与计算机, 2016, 33 (1) :96-99." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201601021&amp;v=MjE5MzR6cXFCdEdGckNVUkxPZVplVnVGeWptVzd6SU1qWFNaTEc0SDlmTXJvOUhaWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         蒲国林.基于粗糙集与信息增益的情感特征选择方法[J].微电子学与计算机, 2016, 33 (1) :96-99.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_3" title=" MA J M, ZOU C J, PAN X C.Structured probabilistic rough set approximations[J].International Journal of Approximate Reasoning, 2017 (90) :319-332." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES6E8DC966AEF72BBFE5B17230741BEA80&amp;v=MTY4NDFiWE5GcVcvcG9sREZaNTVDMzVMdldCbTcwMThUMzNockJVeGVNRGhOTEtmQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeEx1M3c2Zz1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         MA J M, ZOU C J, PAN X C.Structured probabilistic rough set approximations[J].International Journal of Approximate Reasoning, 2017 (90) :319-332.
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_4" title=" HU J, PEDRYCZ W, WANG G, et al.Rough sets in distributed decision information systems[J].Knowledge-Based Systems, 2016 (94) :13-22." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES864879F76306FD23E751EDE41C8941AA&amp;v=MjIxMTJQUXVYcUJOR2NidVFSTXZ1Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeEx1M3c2Zz1OaWZPZmJ1K0d0bkxwdmxDWXVnUENncE56UlZtN1RwOA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         HU J, PEDRYCZ W, WANG G, et al.Rough sets in distributed decision information systems[J].Knowledge-Based Systems, 2016 (94) :13-22.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_5" title=" FAN X, ZHAO W, WANG C, et al.Attribute reduction based on max-decision neighborhood rough set model[J].Knowledge-Based Systems, 2018, 151 (1) :16-23." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1F4809FDB75C665048C5D73E2C802C95&amp;v=MDkwNDZ4NFBIamgyUkJHY2JLV05yT2FDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh4THUzdzZnPU5pZk9mYkxPR3RuTXB2a3hGdXdLZjNvL3loWVg0aw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         FAN X, ZHAO W, WANG C, et al.Attribute reduction based on max-decision neighborhood rough set model[J].Knowledge-Based Systems, 2018, 151 (1) :16-23.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_6" title=" 王婷, 徐章艳, 陈宇文, 等.基于不完备决策表的正区域属性约简的压缩差别矩阵方法[J].计算机科学, 2014, 41 (suppl) :377-382." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2014S1094&amp;v=MDcxNTF2cm85TVlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5am1XN3pJTHo3QmI3RzRIOVc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         王婷, 徐章艳, 陈宇文, 等.基于不完备决策表的正区域属性约简的压缩差别矩阵方法[J].计算机科学, 2014, 41 (suppl) :377-382.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_7" title=" JIANG F, SUI Y, ZHOU L.A relative decision entropy-based feature selection approach[J].Pattern Recognition, 2015, 48 (7) :2151-2163." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300162504&amp;v=MjE2NjdRVE1ud1plWnVIeWptVWIvSUlGMGNhUkk9TmlmT2ZiSzlIOVBPckk5RlplME5DWHc5b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         JIANG F, SUI Y, ZHOU L.A relative decision entropy-based feature selection approach[J].Pattern Recognition, 2015, 48 (7) :2151-2163.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_8" title=" 姚晟, 徐风, 赵鹏, 等.基于自适应邻域空间粗糙集模型的直觉模糊熵特征选择[J].计算机研究与发展, 2018, 55 (4) :802-814." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201804013&amp;v=MTY0NDc0SDluTXE0OUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeWptVzd6SUx5dlNkTEc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         姚晟, 徐风, 赵鹏, 等.基于自适应邻域空间粗糙集模型的直觉模糊熵特征选择[J].计算机研究与发展, 2018, 55 (4) :802-814.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_9" title=" 姚晟, 徐风, 赵鹏, 等.基于邻域量化容差关系粗糙集模型的特征选择算法[J].模式识别与人工智能, 2017, 30 (5) :416-428." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201705004&amp;v=MDEyMDZHNEg5Yk1xbzlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlqbVc3eklLRDdZYkw=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         姚晟, 徐风, 赵鹏, 等.基于邻域量化容差关系粗糙集模型的特征选择算法[J].模式识别与人工智能, 2017, 30 (5) :416-428.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_10" title=" LI F, ZHANG Z, JIN C.Feature selection with partition differentiation entropy for large-scale data sets[J].Information Sciences, 2016 (329) :690-700." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDB0E43655B8B9C100DB6AABAEFE369FF&amp;v=MDIwODI3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhMdTN3Nmc9TmlmT2ZjZktIcVRJcklsQVlaa0hmblZLemhZVG5rMTdPUTZRM1dkRERMR1NUTXpwQ09OdkZTaVdXcg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         LI F, ZHANG Z, JIN C.Feature selection with partition differentiation entropy for large-scale data sets[J].Information Sciences, 2016 (329) :690-700.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_11" title=" ZHANG X, MEI C, CHEN D, et al.Feature selection in mixed data:A method using a novel fuzzy rough set-based information entropy[J].Pattern Recognition, 2016, 56 (1) :1-15." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB657B2C0AABFF66CCB31050798010F04&amp;v=MDU5NzR1M3c2Zz1OaWZPZmNHK0c5YStyZnhGRlpwOWVnby95V1ZnbUR4OFNIcmlxeHM5ZWJPVU03cWJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh4TA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         ZHANG X, MEI C, CHEN D, et al.Feature selection in mixed data:A method using a novel fuzzy rough set-based information entropy[J].Pattern Recognition, 2016, 56 (1) :1-15.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_12" title=" LIANG D, LIU D, KOBINA A.Three-way group decisions with decision-theoretic rough sets[J].Information Sciences, 2016 (345) :46-64." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8B78FC3AC213E01BF03781BA58D90E7D&amp;v=MTQ3MTk9TmlmT2ZidktHZG02M0l3MEYra09Ed2s1em1SbDZqeDZRSDZRM1JjOURidVVNTDNyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeEx1M3c2Zw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         LIANG D, LIU D, KOBINA A.Three-way group decisions with decision-theoretic rough sets[J].Information Sciences, 2016 (345) :46-64.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_13" title=" GAO C, LAI Z, ZHOU J, et al.Maximum decision entropy-based attribute reduction in decision-theoretic rough set model[J].Knowledge-Based Systems, 2018 (143) :179-191." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC7530AE7B18994F070534F64B7809F63&amp;v=MjAyNjM5dVJZVTZqcCtUQW5rcUdBeWNiS2RNN3ljQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeEx1M3c2Zz1OaWZPZmNDL0c5TE0zdnBDRnVvSEJYVQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         GAO C, LAI Z, ZHOU J, et al.Maximum decision entropy-based attribute reduction in decision-theoretic rough set model[J].Knowledge-Based Systems, 2018 (143) :179-191.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_14" title=" 常红岩, 蒙祖强.一种新的决策粗糙集启发式属性约简算法[J].计算机科学, 2016, 43 (6) :218-222." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201606046&amp;v=MDYwMDZHNEg5Zk1xWTlCWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlqbVc3eklMejdCYjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         常红岩, 蒙祖强.一种新的决策粗糙集启发式属性约简算法[J].计算机科学, 2016, 43 (6) :218-222.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_15" title=" QIAN J, DANG C, YUE X, et al.Attribute reduction for sequential three-way decisions under dynamic granulation[J].International Journal of Approximate Reasoning, 2017 (85) :196-216." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES36B8B724A953C5F64C43B9CE183F8B81&amp;v=MjcwNDlpZk9mYkMrYk5tK3FJMUJGZUlLRHc4OHVSQVhtVHQrT25hUjJSTTllc1NjTjdLZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhMdTN3Nmc9Tg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         QIAN J, DANG C, YUE X, et al.Attribute reduction for sequential three-way decisions under dynamic granulation[J].International Journal of Approximate Reasoning, 2017 (85) :196-216.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=WXYJ" target="_blank">微电子学与计算机</a>
                2019,36(05),76-81             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于决策理论粗糙集的一种新属性约简方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%9A%E6%99%9F&amp;code=06138025&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姚晟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E7%85%A7%E7%8E%89&amp;code=41388632&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴照玉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E8%8F%8A&amp;code=37208818&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈菊</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E7%BB%B4&amp;code=06506809&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王维</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%AE%89%E5%BE%BD%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0062694&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">安徽大学计算机科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A7%E8%BF%9E%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=0222286&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大连理工大学软件学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>决策理论粗糙集是一种对噪声数据具有很好容忍效果的粗糙集模型, 然而由于该模型正区域的非单调性, 因此传统的属性约简无法直接构造.本文将在决策理论粗糙集模型中提出一种新的属性约简方法, 首先给出属性约简一种新的定义, 即属性约简的正区域必须不小于属性全集的正区域, 然后根据这一定义提出了相应的属性约简算法, 最后进行一系列的仿真实验, 通过属性约简的大小、属性约简集的分类精度以及算法效率三个方法证明了该算法的有效性和优越性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%86%B3%E7%AD%96%E7%90%86%E8%AE%BA%E7%B2%97%E7%B3%99%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">决策理论粗糙集;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%9E%E6%80%A7%E7%BA%A6%E7%AE%80&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">属性约简;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AD%A3%E5%8C%BA%E5%9F%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">正区域;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB%E6%80%A7%E8%83%BD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类性能;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    姚晟, 女, (1979-) , 博士, 副教授.研究方向为粗糙集理论.;
                                </span>
                                <span>
                                    *吴照玉 (通讯作者) , 女, (1995-) , 硕士研究生.研究方向为机器学习.E-mail:15755355765@163.com.;
                                </span>
                                <span>
                                    陈菊, 女, (1993-) , 硕士研究生.研究方向为不确定性推理.;
                                </span>
                                <span>
                                    王维, 男, (1992-) , 博士研究生.研究方向为稀疏编码和迁移学习.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金 (61602004, 61300057);</span>
                                <span>安徽省自然科学基金项目 (1508085MF127);</span>
                                <span>安徽省高等学校自然科学研究重点项目 (KJ2016A041);</span>
                                <span>安徽大学信息保障技术协同创新中心公开招标课题 (ADXXBZ20145, ADXXBZ20146) ;安徽大学博士科研启动基金项目 (J10113190072);</span>
                    </p>
            </div>
                    <h1><b>A new attribute reduction method based on decision-theoretic rough set</b></h1>
                    <h2>
                    <span>YAO Sheng</span>
                    <span>WU Zhao-yu</span>
                    <span>CHEN Ju</span>
                    <span>WANG Wei</span>
            </h2>
                    <h2>
                    <span>School of computer science and technology, Anhui University</span>
                    <span>School of software, Dalian University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Decision-theoretic rough set is a rough set model with good tolerance to noise data. However, due to the non monotonicity of the positive region, the traditional attribute reduction can not be directly constructed. In this paper, we propose a new attribute reduction method in decision-theoretic rough set. Firstly, a new definition of attribute reduction is given, that is, the positive region of attribute reduction must not be less than the positive region of the complete set of attributes, and then a corresponding reduction algorithm is proposed based on this definition. Finally, a series of simulation experiments are carried out to prove the effectiveness and superiority of the algorithm by three methods, the size of attribute reduction, the classification accuracy of attribute reduction set and the efficiency of algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=decision-theoretic%20rough%20set&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">decision-theoretic rough set;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=attribute%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">attribute reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=positive%20region&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">positive region;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=classification%20performance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">classification performance;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-08-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag">1 <b>引言</b></h3>
                <div class="p1">
                    <p id="34">粗糙集理论<citation id="210" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>是机器学习和知识发现领域中一种重要的数学工具, 它通过对数据进行粒化与逼近的方法来挖掘不确定性数据中潜在有用的信息, 经过几十年的研究和探索, 传统的粗糙集理论已进行不断的改进和推广<citation id="211" type="reference"><link href="182" rel="bibliography" /><link href="184" rel="bibliography" /><link href="186" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>, 使得具有更为广泛的运用.</p>
                </div>
                <div class="p1">
                    <p id="35">属性约简<citation id="212" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>是粗糙集理论的核心研究问题, 它的目的是在不降低数据分类能力的前提下去删除数据中不相关的特征和属性, 提高数据的挖掘性能.在粗糙集理论中, 目前已有多种的属性约简方法被提出, 这些方法主要归结为两大类, 例如基于正区域的属性约简<citation id="213" type="reference"><link href="188" rel="bibliography" /><link href="190" rel="bibliography" /><link href="192" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>和基于熵的属性约简<citation id="214" type="reference"><link href="194" rel="bibliography" /><link href="196" rel="bibliography" /><link href="198" rel="bibliography" /><link href="200" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>.他们的主要思想是通过正区域和熵来作为属性子集分类能力的评估, 当选择出属性子集的正区域和熵值与属性全集的正区域和熵值达到相等时, 那么该属性子集即为属性约简.</p>
                </div>
                <div class="p1">
                    <p id="36">然而, 现实环境下的数据可能包含了很多噪声数据, 传统的属性约简方法通过一致性来诱导属性约简<citation id="216" type="reference"><link href="188" rel="bibliography" /><link href="190" rel="bibliography" /><link href="192" rel="bibliography" /><link href="194" rel="bibliography" /><link href="196" rel="bibliography" /><link href="198" rel="bibliography" /><link href="200" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>, 这可能对含噪声的数据不具有较好的约简结果.近年来, 针对含噪声数据, 学者提出了一种改进的粗糙集模型——决策理论粗糙集模型<citation id="215" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 该模型通过设定阈值的方式提高了噪声环境下的数据处理效果, 然而由于该模型中正区域的非单调性, 传统的属性约简算法无法构造.</p>
                </div>
                <div class="p1">
                    <p id="37">在本文, 我们针对决策理论粗糙集模型, 提出一种新的属性约简定义方式, 即设定最终约简结果的正区域不必和属性全集的正区域相等, 而是使得约简的正区域尽量高于属性全集的正区域, 这样就避免了噪声数据对正区域的影响, 根据这一思想, 本文设计了一种新的属性约简算法.仿真实验结果也证明了该算法的有效性和优越性.</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag">2 <b>基本理论</b></h3>
                <div class="p1">
                    <p id="39">决策理论粗糙集 (DTRS) 是在概率粗糙集 (PRS) 的基础上, 通过引入贝叶斯决策理论的方法提出的一种新的模型.</p>
                </div>
                <div class="p1">
                    <p id="40"><b>定义</b>1<citation id="217" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.令<i>S</i>={<i>U</i>, <i>C</i>∪<i>D</i>, <i>V</i>}是一个决策信息系统, 其中<i>U</i>为对象的非空有限集合, <i>C</i>称为条件属性集, <i>D</i>称为决策属性集, <i>V</i>是<i>C</i>和<i>D</i>属性集下的属性值集合, 设<i>B</i>⊆<i>C</i>, 参数满足0≤<i>β</i>≤<i>α</i>≤1, 那么<i>X</i>⊆<i>U</i>关于 (<i>α</i>, <i>β</i>) 的概率上近似和概率下近似分别定义为:</p>
                </div>
                <div class="p1">
                    <p id="41" class="code-formula">
                        <mathml id="41"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mover accent="true"><mrow><mtext>a</mtext><mtext>p</mtext><mtext>r</mtext></mrow><mo stretchy="true">¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msup></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><mo>∈</mo><mi>U</mi><mo stretchy="false">|</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">|</mo><mrow><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">) </mo><mo>&gt;</mo><mi>β</mi><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr><mtr><mtd><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>p</mtext><mtext>r</mtext></mrow></mstyle><mo>_</mo></munder><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msup></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><mo>∈</mo><mi>U</mi><mo stretchy="false">|</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">|</mo><mrow><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">) </mo><mo>≥</mo><mi>α</mi><mo stretchy="false">}</mo><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="42">在定义1中, [<i>x</i>]<sub><i>B</i></sub>表示<i>x</i>∈<i>U</i>在<i>B</i>下的等价类, 即</p>
                </div>
                <div class="area_img" id="43">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/WXYJ201905016_04300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="44"><image id="179" type="formula" href="images/WXYJ201905016_17900.jpg" display="inline" placement="inline"><alt></alt></image>表示<i>X</i>在等价类[<i>x</i>]<sub><i>B</i></sub>下的条件概率, 即<mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>X</mi><mrow><mo>|</mo><mrow><mrow><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mi>B</mi></msub></mrow></mrow><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>X</mi><mstyle displaystyle="true"><mo>∩</mo><mrow><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo></mrow></mstyle><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mrow><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">|</mo></mrow></mfrac><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="46">在定义 1的基础上, 我们可以得到目标对象集<i>X</i>关于 (<i>α</i>, <i>β</i>) 概率近似的三个近似区域, 即正区域、边界域和负区域.</p>
                </div>
                <div class="p1">
                    <p id="47"><b>定义</b>2<citation id="218" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.令<i>S</i>={<i>U</i>, <i>C</i>∪<i>D</i>, <i>V</i>}是一个决策表, <i>B</i>⊆<i>C</i>且0≤<i>β</i>≤<i>α</i>≤1, 则<i>X</i>⊆<i>U</i>关于<i>B</i>的子集<i>X</i>的正区域、边界域和负区域分别定义为:</p>
                </div>
                <div class="p1">
                    <p id="48">POS<mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml> (<i>X</i>) ={<i>x</i>∈<i>U</i>|<i>P</i> (<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) ≥<i>α</i>}</p>
                </div>
                <div class="p1">
                    <p id="50">BUN<mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml> (<i>X</i>) ={<i>x</i>∈<i>U</i>|<i>β</i>&lt;<i>P</i> (<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) &lt;<i>α</i>}</p>
                </div>
                <div class="p1">
                    <p id="52">NEG<mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml> (<i>X</i>) ={<i>x</i>∈<i>U</i>|<i>P</i> (<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) ≤<i>β</i>}</p>
                </div>
                <div class="p1">
                    <p id="54">同时, 决策属性集<i>D</i>关于条件属性集<i>B</i>的正区域、边界域和负区域分别定义为:</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∪</mo><mrow><mi>X</mi><mo>∈</mo><mi>U</mi><mo>/</mo><mi>D</mi></mrow></munder><mtext>Ρ</mtext></mstyle><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56" class="code-formula">
                        <mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>B</mtext><mtext>U</mtext><mtext>Ν</mtext><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∪</mo><mrow><mi>X</mi><mo>∈</mo><mi>U</mi><mo>/</mo><mi>D</mi></mrow></munder><mtext>B</mtext></mstyle><mtext>Ν</mtext><mtext>D</mtext><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ν</mtext><mtext>E</mtext><mtext>G</mtext><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∪</mo><mrow><mi>X</mi><mo>∈</mo><mi>U</mi><mo>/</mo><mi>D</mi></mrow></munder><mtext>Ν</mtext></mstyle><mtext>E</mtext><mtext>G</mtext><msubsup><mrow></mrow><mi>B</mi><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>, </mo><mi>β</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">在DTRS模型中, 阈值参数 (<i>α</i>, <i>β</i>) 通过最小化错误分类的代价来确定.设<mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ω</mtext><mo>=</mo><mrow><mo>{</mo><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>w</mi><msub><mrow></mrow><mi>s</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>表示<i>s</i>个状态的有限集合, <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mo>=</mo><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>m</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>表示<i>m</i>个可能动作构成的有限集合, <i>P</i> (<i>w</i><sub><i>j</i></sub>|[<i>x</i>]) ) 表示一个对象<i>x</i>处于状态<i>w</i><sub><i>j</i></sub>的条件概率, 假定该对象由等价类[<i>x</i>]<sub><i>B</i></sub>进行描述.令<i>λ</i> (<i>a</i><sub><i>i</i></sub>|<i>w</i><sub><i>j</i></sub>) 表示当状态为<i>w</i><sub><i>j</i></sub>时采用决策<i>a</i><sub><i>i</i></sub>的代价.对于给定描述[<i>x</i>], 假设决策<i>a</i><sub><i>i</i></sub>被采用.则预期的代价可计算为:</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><mi>λ</mi></mstyle><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">[</mo><mi>x</mi><mo stretchy="false">]</mo><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62">为了简化, 假设状态由<mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ω</mtext><mo>=</mo><mrow><mo>{</mo><mrow><mi>X</mi><mo>, </mo><mo>⇁</mo><mi>X</mi></mrow><mo>}</mo></mrow></mrow></math></mathml>构成, 决策由<mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Α</mtext><mo>=</mo><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>B</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>Ν</mi></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>构成, 它分别表示将对象明确地分类为<i>X</i>或⇁<i>X</i>三个区域所对应的三种决策.这三种决策记为POS (<i>X</i>) , BUN (<i>X</i>) 和NEG (<i>X</i>) .我们用<i>λ</i><sub><i>PP</i></sub>, <i>λ</i><sub><i>BP</i></sub>和<i>λ</i><sub><i>NP</i></sub>表示对象实际属于<i>X</i>而分别采取决策<i>a</i><sub><i>P</i></sub>, <i>a</i><sub><i>B</i></sub>, <i>a</i><sub><i>N</i></sub>的成本.类似地, 用<i>λ</i><sub><i>PN</i></sub>, <i>λ</i><sub><i>BN</i></sub>和<i>λ</i><sub><i>NN</i></sub>表示当对象实际上属于⇁<i>X</i>而分别采取决策<i>a</i><sub><i>P</i></sub>, <i>a</i><sub><i>B</i></sub>, <i>a</i><sub><i>N</i></sub>的成本.那么采每个决策的预期代价<i>R</i> (<i>a</i><sub><i>i</i></sub>|[<i>x</i>]<sub><i>B</i></sub>) 可以计算为:</p>
                </div>
                <div class="p1">
                    <p id="65"><i>R</i> (<i>a</i><sub><i>P</i></sub>|[<i>x</i>]<sub><i>B</i></sub>) =<i>λ</i><sub><i>PP</i></sub><i>P</i> (<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) +<i>λ</i><sub><i>PN</i></sub><i>P</i> (⇁<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="66"><i>R</i> (<i>a</i><sub><i>N</i></sub>|[<i>x</i>]<sub><i>B</i></sub>) =<i>λ</i><sub><i>NP</i></sub><i>P</i> (<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) +<i>λ</i><sub><i>NN</i></sub><i>P</i> (⇁<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="67"><i>R</i> (<i>a</i><sub><i>B</i></sub>|[<i>x</i>]<sub><i>B</i></sub>) =<i>λ</i><sub><i>BP</i></sub><i>P</i> (<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) +<i>λ</i><sub><i>BN</i></sub><i>P</i> (⇁<i>X</i>|[<i>x</i>]<sub><i>B</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="68">基于贝叶斯决策理论, 设</p>
                </div>
                <div class="p1">
                    <p id="69"><i>λ</i><sub><i>PP</i></sub>≤<i>λ</i><sub><i>BP</i></sub>≤<i>λ</i><sub><i>NP</i></sub>, <i>λ</i><sub><i>NN</i></sub>≤<i>λ</i><sub><i>BN</i></sub>≤<i>λ</i><sub><i>PN</i></sub>, </p>
                </div>
                <div class="p1">
                    <p id="70"> (<i>λ</i><sub><i>PN</i></sub>-<i>λ</i><sub><i>BN</i></sub>) (<i>λ</i><sub><i>NP</i></sub>-<i>λ</i><sub><i>BP</i></sub>) &gt; (<i>λ</i><sub><i>BP</i></sub>-<i>λ</i><sub><i>PP</i></sub>) (<i>λ</i><sub><i>BN</i></sub>-<i>λ</i><sub><i>NN</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="71">我们引入以下决策规则:</p>
                </div>
                <div class="p1">
                    <p id="72">若<i>P</i> (<i>X</i>|[<i>x</i>]) ≥<i>α</i>, 设定<i>x</i>∈POS (<i>X</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="73">若<i>P</i> (<i>X</i>|[<i>x</i>]) ≥<i>β</i>, 设定<i>x</i>∈NEG (<i>X</i>) ;</p>
                </div>
                <div class="p1">
                    <p id="74">若<i>β</i>&lt;<i>P</i> (<i>X</i>|[<i>x</i>]) &lt;<i>α</i>, 设定<i>x</i>∈BUN (<i>X</i>) .</p>
                </div>
                <div class="p1">
                    <p id="75">式中, </p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>α</mi><mo>=</mo><mfrac><mrow><mi>λ</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mi>Ν</mi></mrow></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ν</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mi>Ν</mi></mrow></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ν</mi></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mo stretchy="false"> (</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mi>Ρ</mi></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi>β</mi><mo>=</mo><mfrac><mrow><mi>λ</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ν</mi></mrow></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mi>Ν</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ν</mi></mrow></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mi>Ν</mi></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mo stretchy="false"> (</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>Ν</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ρ</mi></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">在决策理论粗糙集模型中, 对象属于或不属于正区域取决于条件概率和阈值, 并且根据贝叶斯理论通过最小风险决策规则来预先计算阈值.</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag">3 <b>决策理论粗糙集的新属性约简</b></h3>
                <div class="p1">
                    <p id="79">属性约简是粗糙集理论中最重要的应用, 它可以选择出信息系统中具有高分类能力的属性.在粗糙集理论的研究中, 属性约简有多种定义形式, 其中基于正区域的约简被广泛关注.</p>
                </div>
                <div class="p1">
                    <p id="80">正区域之所以能够作为信息系统的属性约简, 是由于正区域满足属性递增的单调性<citation id="219" type="reference"><link href="194" rel="bibliography" /><link href="196" rel="bibliography" /><link href="198" rel="bibliography" /><link href="200" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>, 即整个属性全集的正区域最大的, 如果一个属性子集的正区域与属性全集的正区域相等, 且这个属性子集的任意子集都不满足这个条件, 那么这个属性子集即为整个信息系统的约简.然而在决策粗糙集理论中, 正区域并不是随属性增加而单调变化的, 因此传统的正区域属性约简不能直接运用于决策理论粗糙集模型中, 因此本文将针对决策理论粗糙集模型提出一种新的属性约简方法.</p>
                </div>
                <div class="p1">
                    <p id="81"><b>定义</b>3设S={U, C∪D}是一个决策信息系统, 若B⊆C同时满足如下 (1) (2) 条件, 那么我们称B为该信息系统的决策粗糙集属性约简:</p>
                </div>
                <div class="p1">
                    <p id="82"> (1) |POS<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>B</mtext><mtext>α</mtext></msubsup></mrow></math></mathml> (D) |≥|POS<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>C</mtext><mtext>α</mtext></msubsup></mrow></math></mathml> (D) |</p>
                </div>
                <div class="p1">
                    <p id="85"> (2) |POS<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mtext>B</mtext><mo>-</mo><mo stretchy="false">{</mo><mtext>a</mtext><mo stretchy="false">}</mo></mrow><mtext>α</mtext></msubsup></mrow></math></mathml> (D) |&lt;|POS<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>B</mtext><mtext>α</mtext></msubsup></mrow></math></mathml> (D) |, ∀a∈B</p>
                </div>
                <div class="p1">
                    <p id="88">在定义3中, 当属性数量减少时, 允许正区域扩大而不是保持正域不变, 当删除约简中的任何属性时, 正区域将收缩, 这样是为了保证极小性原则.对于定义3给出的属性约简定义, 首先约简集与整个属性全集相比, 具有更高或至少相同的分类能力, 从而在整个属性全集中删除一些冗余属性时可以保留分类信息.其次, 约简属性集应该满足极小性, 这意味着我们不能删除约简属性集中的任何属性, 否则会使分类能力下降.因此, 我们所定义的属性约简是合理的.</p>
                </div>
                <div class="p1">
                    <p id="89">例1. 表1所示的是一个信息系统, 其中属性约简全集为<i>C</i>={<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>, <i>a</i><sub>3</sub>}, 决策属性<i>D</i>={<i>d</i>}.</p>
                </div>
                <div class="area_img" id="90">
                    <p class="img_tit"><b>表</b>1 <b>信息系统</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="90" border="1"><tr><td><br /><i>U</i></td><td><i>a</i><sub>1</sub></td><td><i>a</i><sub>2</sub></td><td><i>a</i><sub>3</sub></td><td><i>d</i></td></tr><tr><td><br /><i>x</i><sub>1</sub></td><td><i>A</i></td><td>1</td><td><i>e</i></td><td>-</td></tr><tr><td><br /><i>x</i><sub>2</sub></td><td><i>A</i></td><td>1</td><td><i>f</i></td><td>+</td></tr><tr><td><br /><i>x</i><sub>3</sub></td><td><i>A</i></td><td>1</td><td><i>g</i></td><td>+</td></tr><tr><td><br /><i>x</i><sub>4</sub></td><td><i>B</i></td><td>1</td><td><i>e</i></td><td>-</td></tr><tr><td><br /><i>x</i><sub>5</sub></td><td><i>B</i></td><td>2</td><td><i>f</i></td><td>-</td></tr><tr><td><br /><i>x</i><sub>6</sub></td><td><i>B</i></td><td>1</td><td><i>g</i></td><td>+</td></tr><tr><td><br /><i>x</i><sub>7</sub></td><td><i>B</i></td><td>2</td><td><i>f</i></td><td>+</td></tr><tr><td><br /><i>x</i><sub>8</sub></td><td><i>B</i></td><td>1</td><td><i>g</i></td><td>-</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="91">根据定义2可以得到</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>}</mo></mrow></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>3</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>4</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>5</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>6</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>7</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>8</mn></msub><mo stretchy="false">}</mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">POS<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">}</mo></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup></mrow></math></mathml> (<i>D</i>) ={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>, <i>x</i><sub>6</sub>, <i>x</i><sub>8</sub>}, </p>
                </div>
                <div class="p1">
                    <p id="95">POS<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup></mrow></math></mathml> (<i>D</i>) ={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>}.</p>
                </div>
                <div class="p1">
                    <p id="97">因此有<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>}</mo></mrow></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo>&gt;</mo><mo stretchy="false">|</mo><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow></math></mathml>, 并且满足<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>}</mo></mrow></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>⊇</mo><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo></mrow></math></mathml>, 所以属性集<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>同时满足条件 (1) 和条件 (2) , 即它是约简.</p>
                </div>
                <div class="p1">
                    <p id="101">同时决策粗糙集的正区域约简是不唯一的.例如在表1中, 由属性集<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>和{<i>a</i><sub>1</sub>, <i>a</i><sub>3</sub>}分别可以得到:</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>U</mi><mo>/</mo><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>}</mo></mrow><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>4</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>5</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>7</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>3</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>6</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>8</mn></msub><mo stretchy="false">}</mo><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>U</mi><mo>/</mo><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>4</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>5</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>7</mn></msub><mo stretchy="false">}</mo><mo>, </mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>6</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>8</mn></msub><mo stretchy="false">}</mo><mo stretchy="false">}</mo><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="104">设<i>α</i>=0.6, 并根据定义2计算正域:</p>
                </div>
                <div class="p1">
                    <p id="105"> (1) 对于属性值<mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>:</p>
                </div>
                <div class="p1">
                    <p id="107"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>1</sub>]) =1, </p>
                </div>
                <div class="p1">
                    <p id="108"><i>P</i> (<i>d</i>=2|[<i>x</i><sub>1</sub>]) =0, </p>
                </div>
                <div class="p1">
                    <p id="109"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>2</sub>]) =0.333, </p>
                </div>
                <div class="p1">
                    <p id="110"><i>P</i> (<i>d</i>=2|[<i>x</i><sub>2</sub>]) =0.667, </p>
                </div>
                <div class="p1">
                    <p id="111"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>3</sub>]) =0.333, </p>
                </div>
                <div class="p1">
                    <p id="112"><i>P</i> (<i>d</i>=2|[<i>x</i><sub>3</sub>]) =0.667.</p>
                </div>
                <div class="p1">
                    <p id="113"> (2) 属性值{<i>a</i><sub>1</sub>, <i>a</i><sub>3</sub>}:</p>
                </div>
                <div class="p1">
                    <p id="114"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>1</sub>]) =1, <i>P</i> (<i>d</i>=2|[<i>x</i><sub>1</sub>]) =0, </p>
                </div>
                <div class="p1">
                    <p id="115"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>2</sub>]) =0, <i>P</i> (<i>d</i>=2|[<i>x</i><sub>2</sub>]) =1, </p>
                </div>
                <div class="p1">
                    <p id="116"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>3</sub>]) =0, <i>P</i> (<i>d</i>=2|[<i>x</i><sub>3</sub>]) =1, </p>
                </div>
                <div class="p1">
                    <p id="117"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>4</sub>]) =1, <i>P</i> (<i>d</i>=2|[<i>x</i><sub>4</sub>]) =0, </p>
                </div>
                <div class="p1">
                    <p id="118"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>5</sub>]) =0.5, <i>P</i> (<i>d</i>=2|[<i>x</i><sub>5</sub>]) =0.5, </p>
                </div>
                <div class="p1">
                    <p id="119"><i>P</i> (<i>d</i>=1|[<i>x</i><sub>6</sub>]) =0.5, <i>P</i> (<i>d</i>=2|[<i>x</i><sub>6</sub>]) =0.5.</p>
                </div>
                <div class="p1">
                    <p id="120">因此</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>}</mo></mrow></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>3</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>4</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>5</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>6</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>7</mn></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mn>8</mn></msub><mo stretchy="false">}</mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">POS<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup></mrow></math></mathml> (<i>D</i>) ={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>}, </p>
                </div>
                <div class="p1">
                    <p id="124">POS<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">}</mo></mrow><mrow><mn>0</mn><mo>.</mo><mn>6</mn></mrow></msubsup></mrow></math></mathml> (<i>D</i>) ={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, <i>x</i><sub>3</sub>, <i>x</i><sub>4</sub>}.</p>
                </div>
                <div class="p1">
                    <p id="126">所以<mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>也是一个约简.因此, 我们得到两个不同的约简<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>和<mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mrow><mi>a</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mo>}</mo></mrow></mrow></math></mathml>, 这表明约简不是唯一的.</p>
                </div>
                <div class="p1">
                    <p id="130">一般而言, 对于一个给定的条件属性集合<i>C</i>, 找出所有约简可以通过穷举地检查<i>C</i>的所有子集来完全搜索出来.然而, 已经证明搜索所有约简的问题是NP难问题, 因此这很难运用于实际应用中.目前, 通过启发式搜索来寻找约简是一种较为流行的方法<citation id="220" type="reference"><link href="194" rel="bibliography" /><link href="196" rel="bibliography" /><link href="198" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>.因此, 本文将通过启发式搜索的方法提出相应的属性约简算法, 具体如算法1所示.</p>
                </div>
                <div class="p1">
                    <p id="131">算法1:决策粗糙集的正区域属性约简</p>
                </div>
                <div class="p1">
                    <p id="132">输入:信息系统<i>S</i>={<i>U</i>, <i>C</i>∪<i>D</i>, <i>V</i>}, 阈值<i>α</i>.</p>
                </div>
                <div class="p1">
                    <p id="133">输出:属性约简<i>R</i></p>
                </div>
                <div class="p1">
                    <p id="134">步骤1:初始化<i>R</i>=∅</p>
                </div>
                <div class="p1">
                    <p id="135">步骤2:计算<i>C</i>中每个属性的属性重要度</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><msubsup><mrow></mrow><mi>a</mi><mi>α</mi></msubsup><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mtext>Ρ</mtext><mtext>Ο</mtext><mtext>S</mtext><msubsup><mrow></mrow><mrow><mrow><mo>{</mo><mi>a</mi><mo>}</mo></mrow></mrow><mi>α</mi></msubsup><mo stretchy="false"> (</mo><mi>D</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mrow><mrow><mrow><mo>|</mo><mi>U</mi><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">步骤3:将所有的属性按照属性重要度排序, 记有序集为<i>K</i>, 其中第一个元素属性重要度最大</p>
                </div>
                <div class="p1">
                    <p id="138">步骤4:选择<i>K</i>中第一个元素<i>a</i>, 进行</p>
                </div>
                <div class="p1">
                    <p id="139"><i>R</i>=<i>R</i>∪{<i>a</i>}, <i>K</i>=<i>K</i>-{<i>a</i>}</p>
                </div>
                <div class="p1">
                    <p id="140">步骤5:分别计算正区域POS<mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>R</mi><mi>α</mi></msubsup></mrow></math></mathml> (<i>D</i>) 和POS<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>C</mi><mi>α</mi></msubsup></mrow></math></mathml> (<i>D</i>) , 若|POS<mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>R</mi><mi>α</mi></msubsup></mrow></math></mathml> (<i>D</i>) |≥|POS<mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>C</mi><mi>α</mi></msubsup></mrow></math></mathml> (<i>D</i>) |, 那么转入步骤6, 否则进入步骤4.</p>
                </div>
                <div class="p1">
                    <p id="145">步骤6:对于∀<i>b</i>∈<i>R</i>, 如果满足|POS<mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>R</mi><mo>-</mo><mo stretchy="false">{</mo><mi>b</mi><mo stretchy="false">}</mo></mrow><mi>α</mi></msubsup></mrow></math></mathml> (<i>D</i>) |≥|POS<mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>R</mi><mi>α</mi></msubsup></mrow></math></mathml> (<i>D</i>) |, 则<i>R</i>=<i>R</i>-{<i>b</i>}.</p>
                </div>
                <div class="p1">
                    <p id="148">步骤7:返回属性约简<i>R</i>.</p>
                </div>
                <div class="p1">
                    <p id="149">在算法1中, 步骤2的时间复杂度为<i>O</i> (|<i>C</i>||<i>U</i>|) , 步骤3至步骤5在最坏的情况下, 其时间复杂度为<i>O</i> (|<i>C</i>|<sup>2</sup>|<i>U</i>|) .类似地, 步骤6的时间复杂度也为<i>O</i> (|<i>C</i>|<sup>2</sup>|<i>U</i>|) , 因此整个算法2的时间复杂度为<i>O</i> (|<i>C</i>||<i>U</i>|) +<i>O</i> (|<i>C</i>|<sup>2</sup>|<i>U</i>|) +<i>O</i> (|<i>C</i>|<sup>2</sup>|<i>U</i>|) , 即<i>O</i> (|<i>C</i>|<sup>2</sup>|<i>U</i>|) .</p>
                </div>
                <h3 id="150" name="150" class="anchor-tag">4 <b>实验分析</b></h3>
                <div class="p1">
                    <p id="151">在本节我们将通过进行实验来验证本文所提出算法的有效性和优越性.所有实验均在表2中列出的5个数据集上进行, 这些数据集均取自UCI机器学习库.同时为了进行实验比较, 本实验中选取了近年来提出的属性约简算法, 分别为: (1) 决策粗糙集的最大决策熵属性约简算法<citation id="221" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation> (算法A) , (2) 一种改进的决策粗糙集的属性约简算法<citation id="222" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation> (算法B) , (3) 基于决策粗糙集的动态粒属性约简算法<citation id="223" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation> (算法C) .然后将这三种算法与本文算法分别对表2的数据集进行属性约简, 通过比较他们的属性约简结果来分析算法的优劣.</p>
                </div>
                <div class="area_img" id="152">
                    <p class="img_tit"><b>表</b>2 <b>实验数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="152" border="1"><tr><td><br />编号</td><td>数据集</td><td>样本</td><td>属性</td><td>类</td></tr><tr><td><br />1</td><td>Kr-vs-kp</td><td>3 196</td><td>36</td><td>2</td></tr><tr><td><br />2</td><td>Soybean</td><td>683</td><td>35</td><td>19</td></tr><tr><td><br />3</td><td>Zoo</td><td>101</td><td>16</td><td>7</td></tr><tr><td><br />4</td><td>Mushroom</td><td>8 124</td><td>22</td><td>2</td></tr><tr><td><br />5</td><td>Breast</td><td>699</td><td>22</td><td>2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="153">表3所示的是5个数据集在各个属性约简算法下的属性约简中属性数量的比较结果, 观察表3的结果可以看出, 本文所提出的属性约简算法在各个数据集下得到了更少的属性, 这主要是由于该属性约简方法的约简集是不降低正区域的大小, 在决策理论粗糙集模型中, 有些更少的属性集可能使得正区域增大, 因此这样的得到的属性更加具有区分能力.</p>
                </div>
                <div class="area_img" id="154">
                    <p class="img_tit"><b>表</b>3 <b>属性约简结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="154" border="1"><tr><td><br />数据集</td><td>算法A</td><td>算法B</td><td>算法C</td><td>本文算法</td></tr><tr><td><br />Kr-vs-kp</td><td>12</td><td>14</td><td>12</td><td>9</td></tr><tr><td><br />Soybean</td><td>10</td><td>12</td><td>11</td><td>10</td></tr><tr><td><br />Zoo</td><td>7</td><td>8</td><td>6</td><td>4</td></tr><tr><td><br />Mushroom</td><td>12</td><td>12</td><td>12</td><td>9</td></tr><tr><td><br />Breast</td><td>9</td><td>9</td><td>8</td><td>6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="155">由于属性子集对于整个数据集的分类性能是评估属性约简结果好坏的一个重要指标, 因此表4和表5分别所示的是各个属性约简结果在CART分类器和SVM分类器下的分类精度结果.</p>
                </div>
                <div class="area_img" id="156">
                    <p class="img_tit"><b>表</b>4 CART<b>分类精度</b>/% <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="156" border="1"><tr><td><br />数据集</td><td>算法A</td><td>算法B</td><td>算法C</td><td>本文算法</td></tr><tr><td><br />Kr-vs-kp</td><td>90.12</td><td>89.45</td><td>91.28</td><td>92.53</td></tr><tr><td><br />Soybean</td><td>82.53</td><td>83.64</td><td>81.77</td><td>82.95</td></tr><tr><td><br />Zoo</td><td>90.47</td><td>91.38</td><td>89.51</td><td>93.83</td></tr><tr><td><br />Mushroom</td><td>95.21</td><td>94.75</td><td>94.75</td><td>96.74</td></tr><tr><td><br />Breast</td><td>85.33</td><td>85.33</td><td>84.36</td><td>86.84</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="157">观察表4的CART分类精度结果可以看出, 本文所提出的决策理论粗糙集模型属性约简结果在大部分数据集中具有更高的分类精度, 观察表5的SVM分类精度结果也可以看出, 所得到的属性约简结果同样在多数数据集中具有更高的分类精度.这主要是由于本文的属性约简定义所决定的, 其余三种算法在定义属性约简时, 要求属性子集的正区域或者熵信息量与整个属性全集一致, 而本文的是要求属性子集的正区域不低于属性全集的正区域, 并且是尽量最大化正区域, 由于数据集噪声数据的存在, 本文算法得到的属性子集对应的正区域一般会大于属性全集的正区域, 因此本文算法得到约简具有更高的分类性能, 从而具有更高的分类精度.</p>
                </div>
                <div class="area_img" id="158">
                    <p class="img_tit"><b>表</b>5 SVM<b>分类精度</b>/% <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="158" border="1"><tr><td><br />数据集</td><td>算法A</td><td>算法B</td><td>算法C</td><td>本文算法</td></tr><tr><td><br />Kr-vs-kp</td><td>87.24</td><td>86.54</td><td>88.26</td><td>87.47</td></tr><tr><td><br />Soybean</td><td>75.74</td><td>77.26</td><td>74.19</td><td>78.48</td></tr><tr><td><br />Zoo</td><td>85.25</td><td>86.16</td><td>85.37</td><td>88.69</td></tr><tr><td><br />Mushroom</td><td>91.78</td><td>90.36</td><td>89.49</td><td>93.60</td></tr><tr><td><br />Breast</td><td>88.35</td><td>86.93</td><td>87.63</td><td>89.26</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="159">最后将比较这4种属性约简算法的约简效率.图1所示的是4种算法在各个数据集下的属性约简时间比较柱状图, 其中每个子图代表了对应数据集的结果, 每个子图的横坐标表示4种算法, 纵坐标表示时间, 单位为秒.</p>
                </div>
                <div class="area_img" id="160">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/WXYJ201905016_160.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 各个数据集在不同算法下属性约简时间比较" src="Detail/GetImg?filename=images/WXYJ201905016_160.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>各个数据集在不同算法下属性约简时间比较</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/WXYJ201905016_160.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="161">观察所有实验结果可以发现, 算法A在每个数据集下都具有较高的属性约简时耗, 而本文所提出的算法在每个数据集下具有较小的时间结果, 这主要是由于本文算法的搜索策略决定的, 其余算法的终止条件是满足正区域或者熵度量的一致性, 而本文算法的是满足正区域最大化, 并不需要满足正区域一致性, 因此会比其他算法提前结束搜索, 从而提高了算法的效率.</p>
                </div>
                <div class="p1">
                    <p id="162">综合以上实验结果可以证明本文所提出的决策理论粗糙集模型的属性约简算法具有更高的属性约简性能.</p>
                </div>
                <h3 id="163" name="163" class="anchor-tag">5 <b>结束语</b></h3>
                <div class="p1">
                    <p id="164">决策理论粗糙集模型是在传统粗糙集理论上的进一步推广, 模型通过设定阈值的方式来提高容噪性能, 由于决策理论粗糙集模型正区域的非单调性, 因此传统的属性约简方法无法直接构造, 在本文, 我们将定义一种新的属性约简方法, 即得到的约简结果正区域不低于属性全集的正区域, 通过实验证明了所提出属性约简的有效性与优越性.在接下来的研究中, 我们将进一步研究所提出属性约简方法的增量式更新问题.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="180">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rough Sets Int">

                                <b>[1]</b> PAWLAK Z.Rough set[J].International Journal of Computer &amp; Information Sciences, 1982, 11 (5) :341-356.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201601021&amp;v=MjM3NzNvOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeWptVzd6SU1qWFNaTEc0SDlmTXI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 蒲国林.基于粗糙集与信息增益的情感特征选择方法[J].微电子学与计算机, 2016, 33 (1) :96-99.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES6E8DC966AEF72BBFE5B17230741BEA80&amp;v=MTc0ODJmT2ZiWE5GcVcvcG9sREZaNTVDMzVMdldCbTcwMThUMzNockJVeGVNRGhOTEtmQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeEx1M3c2Zz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> MA J M, ZOU C J, PAN X C.Structured probabilistic rough set approximations[J].International Journal of Approximate Reasoning, 2017 (90) :319-332.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES864879F76306FD23E751EDE41C8941AA&amp;v=MDM5OTB1WHFCTkdjYnVRUk12dUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhMdTN3Nmc9TmlmT2ZidStHdG5McHZsQ1l1Z1BDZ3BOelJWbTdUcDhQUQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> HU J, PEDRYCZ W, WANG G, et al.Rough sets in distributed decision information systems[J].Knowledge-Based Systems, 2016 (94) :13-22.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1F4809FDB75C665048C5D73E2C802C95&amp;v=MDY4ODlkaGh4THUzdzZnPU5pZk9mYkxPR3RuTXB2a3hGdXdLZjNvL3loWVg0a3g0UEhqaDJSQkdjYktXTnJPYUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> FAN X, ZHAO W, WANG C, et al.Attribute reduction based on max-decision neighborhood rough set model[J].Knowledge-Based Systems, 2018, 151 (1) :16-23.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA2014S1094&amp;v=MDcwNDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlqbVc3eklMejdCYjdHNEg5V3ZybzlNWUlRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 王婷, 徐章艳, 陈宇文, 等.基于不完备决策表的正区域属性约简的压缩差别矩阵方法[J].计算机科学, 2014, 41 (suppl) :377-382.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122300162504&amp;v=MTMxNzBud1plWnVIeWptVWIvSUlGMGNhUkk9TmlmT2ZiSzlIOVBPckk5RlplME5DWHc5b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> JIANG F, SUI Y, ZHOU L.A relative decision entropy-based feature selection approach[J].Pattern Recognition, 2015, 48 (7) :2151-2163.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201804013&amp;v=MjMwNzJPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5am1XN3pJTHl2U2RMRzRIOW5NcTQ5RVo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 姚晟, 徐风, 赵鹏, 等.基于自适应邻域空间粗糙集模型的直觉模糊熵特征选择[J].计算机研究与发展, 2018, 55 (4) :802-814.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201705004&amp;v=MTAxMjNVUkxPZVplVnVGeWptVzd6SUtEN1liTEc0SDliTXFvOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 姚晟, 徐风, 赵鹏, 等.基于邻域量化容差关系粗糙集模型的特征选择算法[J].模式识别与人工智能, 2017, 30 (5) :416-428.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDB0E43655B8B9C100DB6AABAEFE369FF&amp;v=MDUxNDh3Nmc9TmlmT2ZjZktIcVRJcklsQVlaa0hmblZLemhZVG5rMTdPUTZRM1dkRERMR1NUTXpwQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeEx1Mw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> LI F, ZHANG Z, JIN C.Feature selection with partition differentiation entropy for large-scale data sets[J].Information Sciences, 2016 (329) :690-700.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB657B2C0AABFF66CCB31050798010F04&amp;v=MTc1MDVXVmdtRHg4U0hyaXF4czllYk9VTTdxYkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhMdTN3Nmc9TmlmT2ZjRytHOWErcmZ4RkZacDllZ28veQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> ZHANG X, MEI C, CHEN D, et al.Feature selection in mixed data:A method using a novel fuzzy rough set-based information entropy[J].Pattern Recognition, 2016, 56 (1) :1-15.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES8B78FC3AC213E01BF03781BA58D90E7D&amp;v=MTM0MDBJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh4THUzdzZnPU5pZk9mYnZLR2RtNjNJdzBGK2tPRHdrNXptUmw2ang2UUg2UTNSYzlEYnVVTUwzckNPTnZGU2lXV3I3Sg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> LIANG D, LIU D, KOBINA A.Three-way group decisions with decision-theoretic rough sets[J].Information Sciences, 2016 (345) :46-64.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC7530AE7B18994F070534F64B7809F63&amp;v=MzEyNTBwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhoeEx1M3c2Zz1OaWZPZmNDL0c5TE0zdnBDRnVvSEJYVTl1UllVNmpwK1RBbmtxR0F5Y2JLZE03eWNDT052RlNpV1dyN0pJRg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> GAO C, LAI Z, ZHOU J, et al.Maximum decision entropy-based attribute reduction in decision-theoretic rough set model[J].Knowledge-Based Systems, 2018 (143) :179-191.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201606046&amp;v=MjQ2MjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnlqbVc3eklMejdCYjdHNEg5Zk1xWTlCWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 常红岩, 蒙祖强.一种新的决策粗糙集启发式属性约简算法[J].计算机科学, 2016, 43 (6) :218-222.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES36B8B724A953C5F64C43B9CE183F8B81&amp;v=MjQ0MDI4OHVSQVhtVHQrT25hUjJSTTllc1NjTjdLZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNWRoaHhMdTN3Nmc9TmlmT2ZiQytiTm0rcUkxQkZlSUtEdw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> QIAN J, DANG C, YUE X, et al.Attribute reduction for sequential three-way decisions under dynamic granulation[J].International Journal of Approximate Reasoning, 2017 (85) :196-216.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="WXYJ201905016" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201905016&amp;v=MjYwMDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5am1XN3pJTWpYU1pMRzRIOWpNcW85RVlvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09jT0lPUUo3bEY3Zm5LZEo2VXlXemZUQTF2RT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
