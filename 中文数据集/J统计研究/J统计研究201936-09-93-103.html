<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140112979193750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dTJYJ201909008%26RESULT%3d1%26SIGN%3dhdMxkuADlnGUnxd3V6UZlpaAG3Q%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJYJ201909008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJYJ201909008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJYJ201909008&amp;v=MDM3NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeS9tV3IvUE1TZlNaTEc0SDlqTXBvOUZiSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#51" data-title="一、引言 ">一、引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="二、基本思路 ">二、基本思路</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#56" data-title="(&lt;b&gt;一)入样概率的建模推断&lt;/b&gt;">(<b>一)入样概率的建模推断</b></a></li>
                                                <li><a href="#58" data-title="(&lt;b&gt;二)目标变量的建模推断&lt;/b&gt;">(<b>二)目标变量的建模推断</b></a></li>
                                                <li><a href="#60" data-title="(&lt;b&gt;三)入样概率与目标变量的双重建模推断&lt;/b&gt;">(<b>三)入样概率与目标变量的双重建模推断</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="三、具体方法的讨论 ">三、具体方法的讨论</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="(&lt;b&gt;一)基于广义&lt;/b&gt;Boosted&lt;b&gt;模型的倾向得分推断理论&lt;/b&gt;">(<b>一)基于广义</b>Boosted<b>模型的倾向得分推断理论</b></a></li>
                                                <li><a href="#81" data-title="(&lt;b&gt;二)基于广义&lt;/b&gt;Boosted&lt;b&gt;模型的倾向得分估计算法&lt;/b&gt;">(<b>二)基于广义</b>Boosted<b>模型的倾向得分估计算法</b></a></li>
                                                <li><a href="#96" data-title="(&lt;b&gt;三)基于广义&lt;/b&gt;Boosted&lt;b&gt;模型总体估计的理论性质&lt;/b&gt;">(<b>三)基于广义</b>Boosted<b>模型总体估计的理论性质</b></a></li>
                                                <li><a href="#115" data-title="(&lt;b&gt;四)模拟分析&lt;/b&gt;">(<b>四)模拟分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#136" data-title="四、总结与启示 ">四、总结与启示</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="&lt;b&gt;图1 回归树&lt;/b&gt;"><b>图1 回归树</b></a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;表1 基于GBM总体均值估计的模拟结果&lt;/b&gt;"><b>表1 基于GBM总体均值估计的模拟结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title="Svensson J.Web Panel Surveys-Can They be Designed and Used in a Scientifically Sound Way?[R].Hong Kong:International Association of Survey Statisticians,2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Web Panel Surveys-Can They be Designed and Used in a Scientifically Sound Way?">
                                        <b>[1]</b>
                                        Svensson J.Web Panel Surveys-Can They be Designed and Used in a Scientifically Sound Way?[R].Hong Kong:International Association of Survey Statisticians,2013.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title="Lee S.Propensity Score Adjustment as a Weighting Scheme for Volunteer Panel Web Surveys[J].Journal of Official Statistics,2006,22(2):329-349." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Propensity Score Adjustment as a Weighting Scheme for Volunteer Panel WebSurveys,&amp;quot;">
                                        <b>[2]</b>
                                        Lee S.Propensity Score Adjustment as a Weighting Scheme for Volunteer Panel Web Surveys[J].Journal of Official Statistics,2006,22(2):329-349.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title="Valliant R,Dever J A.Estimating Propensity Adjustments for Volunteer Web Surveys[J].Sociological Methods &amp;amp; Research,2011,40(1):105-137." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Estimating propensity adjustments for volunteer web surveys">
                                        <b>[3]</b>
                                        Valliant R,Dever J A.Estimating Propensity Adjustments for Volunteer Web Surveys[J].Sociological Methods &amp;amp; Research,2011,40(1):105-137.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title="Brick J M.Explorations in Non-probability Sampling Using the Web[C].Proceedings of Statistics Canada Symposium,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Explorations in Non-probability Sampling Using the Web">
                                        <b>[4]</b>
                                        Brick J M.Explorations in Non-probability Sampling Using the Web[C].Proceedings of Statistics Canada Symposium,2014.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title="金勇进,刘展.大数据背景下非概率抽样的统计推断问题[J].统计研究,2016(3):11-17." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJYJ201603002&amp;v=MDMyODFyQ1VSN3FmWnVab0Z5L21Xci9PTVNmU1pMRzRIOWZNckk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        金勇进,刘展.大数据背景下非概率抽样的统计推断问题[J].统计研究,2016(3):11-17.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title="刘展,金勇进.网络访问固定样本调查的统计推断研究[J].统计与信息论坛,2017(2):3-10." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201702001&amp;v=MzIyOTBiTXJZOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeS9tV3IvT01TZkhlckc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        刘展,金勇进.网络访问固定样本调查的统计推断研究[J].统计与信息论坛,2017(2):3-10.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title="牛成英,孙秋碧.基于倾向值加权的网络调查总体参数Horvitz-Thompson估计[J].统计与信息论坛,2015(4):15-20." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201504003&amp;v=MjEwODlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci9PTVNmSGVyRzRIOVRNcTQ5Rlo0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        牛成英,孙秋碧.基于倾向值加权的网络调查总体参数Horvitz-Thompson估计[J].统计与信息论坛,2015(4):15-20.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title="Mercer A W,Kreuter F,Keeter S,et al.Theory and Practice in Non-probability Surveys[J].Public Opinion Quarterly,2017,81,special Issue:250-279." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Theory and Practice in nonprobability surveys">
                                        <b>[8]</b>
                                        Mercer A W,Kreuter F,Keeter S,et al.Theory and Practice in Non-probability Surveys[J].Public Opinion Quarterly,2017,81,special Issue:250-279.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title="Tibshirani R J.Regression Shrinkage and Selection Via the Lasso[J].Journal of the Royal Statistical Society,Ser.B,1996,58:267-288." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603924782&amp;v=MjI4NDlpZlllcks4SDlQTXFZOUdiZWtMQzNRN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJuSUoxMGRhaFE9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Tibshirani R J.Regression Shrinkage and Selection Via the Lasso[J].Journal of the Royal Statistical Society,Ser.B,1996,58:267-288.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title="Chen K T.Using LASSO to Calibrate Non-probability Samples Using Probability Samples[D].Michigan:The University of Michigan,2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using LASSO to Calibrate Non-probability Samples Using Probability Samples">
                                        <b>[10]</b>
                                        Chen K T.Using LASSO to Calibrate Non-probability Samples Using Probability Samples[D].Michigan:The University of Michigan,2016.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title="Valliant R,Dorfman A H,Royall R M.Finite Population Sampling and Inference:A Prediction Approach[M].New York:John Wiley &amp;amp; Sons,2000." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Finite Population Sampling and Inference:A Prediction Approach">
                                        <b>[11]</b>
                                        Valliant R,Dorfman A H,Royall R M.Finite Population Sampling and Inference:A Prediction Approach[M].New York:John Wiley &amp;amp; Sons,2000.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title="Chambers R L,Clark R G.An Introduction to Model-based Survey Sampling with Applications[M].Oxford:Oxford University Press,2012." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Introduction to Model-based Survey Sampling with Applications">
                                        <b>[12]</b>
                                        Chambers R L,Clark R G.An Introduction to Model-based Survey Sampling with Applications[M].Oxford:Oxford University Press,2012.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title="Pfeffermann D,Rao C R.Handbook of Statistics Sample Surveys:Inference and Analysis[M].Oxford:Elsevier B.V.,Vol 29B,2009." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Handbook of Statistics Sample Surveys:Inference and Analysis">
                                        <b>[13]</b>
                                        Pfeffermann D,Rao C R.Handbook of Statistics Sample Surveys:Inference and Analysis[M].Oxford:Elsevier B.V.,Vol 29B,2009.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title="Baker R,Brick J M,Bates N A,et al.Summary Report of the AAPOR Task Force on Non-probability Sampling[J].Journal of Survey Statistics and Methodology,2013,1(2):90-143." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;#39;&amp;#39;Summary report of the AAPOR task force on non-probability sampling&amp;#39;&amp;#39;">
                                        <b>[14]</b>
                                        Baker R,Brick J M,Bates N A,et al.Summary Report of the AAPOR Task Force on Non-probability Sampling[J].Journal of Survey Statistics and Methodology,2013,1(2):90-143.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title="Cooper D,Greenaway M.Non-probability Survey Sampling in Official Statistics[R].ONS Methodology Working Paper Series,No.4,2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Non-probability Survey Sampling in Official Statistics">
                                        <b>[15]</b>
                                        Cooper D,Greenaway M.Non-probability Survey Sampling in Official Statistics[R].ONS Methodology Working Paper Series,No.4,2015.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title="Elliott M R,Valliant R.Inference for Non-probability Samples[J].Statistical Science,2017,32(2):249-264." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Inference for Nonprobability Samples.&amp;quot;">
                                        <b>[16]</b>
                                        Elliott M R,Valliant R.Inference for Non-probability Samples[J].Statistical Science,2017,32(2):249-264.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title="Dayan Y.A Structured Approach to Web Panel Surveys[D].London:The London School of Economics,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Structured Approach to Web Panel Surveys">
                                        <b>[17]</b>
                                        Dayan Y.A Structured Approach to Web Panel Surveys[D].London:The London School of Economics,2014.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title="Stahl G,Saarela S,Schnell S,et al.Use of Models in Large-area Forest Surveys:Comparing Model-assisted,Model-based and Hybrid Estimation[J].Forest Ecosystems,2016,3(2):153-163." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BLDX201602006&amp;v=MDEzNDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci9PSnlIUGRyRzRIOWZNclk5RllvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                        Stahl G,Saarela S,Schnell S,et al.Use of Models in Large-area Forest Surveys:Comparing Model-assisted,Model-based and Hybrid Estimation[J].Forest Ecosystems,2016,3(2):153-163.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title="B&#252;hlmann P,Yu B.Boosting with the L2 Loss:Regression and Classification[J].Journal of the American Statistical Association,2003(98):324-339." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800007006&amp;v=MDc0NjRGaW5sVXJuSUoxMGRhaFE9TmpuQmFySzdIdGZPcDQ5RlpPc0lESHcvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                        B&#252;hlmann P,Yu B.Boosting with the L2 Loss:Regression and Classification[J].Journal of the American Statistical Association,2003(98):324-339.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title="Lee S,Valliant R.Estimation for Volunteer Panel Web Surveys Using Propensity Score Adjustment and Calibration Adjustment[J].Sociological Methods &amp;amp; Research,2009,37(3):319-343." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Estimation for Volunteer Panel Web Surveys Using Propensity Score Adjustment and Calibration Adjustment">
                                        <b>[20]</b>
                                        Lee S,Valliant R.Estimation for Volunteer Panel Web Surveys Using Propensity Score Adjustment and Calibration Adjustment[J].Sociological Methods &amp;amp; Research,2009,37(3):319-343.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title="Breiman L,Friedman J H,Olshen R A,et al.Classification and Regression Trees[M].Belmont,CA:Wadsworth International Group,1984." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification and Regression Trees">
                                        <b>[21]</b>
                                        Breiman L,Friedman J H,Olshen R A,et al.Classification and Regression Trees[M].Belmont,CA:Wadsworth International Group,1984.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title="McCaffrey D F,Ridgeway G,Morral A R.Propensity Score Estimation with Boosted Regression for Evaluating Causal Effects in Observational Studies[J].Psychological Methods,2004,9(4):403-425." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Propensity score estimation with boosted regression for evaluating causal effects in observational studies">
                                        <b>[22]</b>
                                        McCaffrey D F,Ridgeway G,Morral A R.Propensity Score Estimation with Boosted Regression for Evaluating Causal Effects in Observational Studies[J].Psychological Methods,2004,9(4):403-425.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title="Zhu Y Y,Ghosh D,Mitra N,et al.A Data-adaptive Strategy for Inverse Weighted Estimation of Causal Effects[J].Health Services and Outcomes Research Methodology,2014,14:69-91." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14101300026855&amp;v=MTA0MjlCTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJuSUoxMGRhaFE9Tmo3QmFySzhIOUhOckk5RlpPa0pCSGs4bw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                        Zhu Y Y,Ghosh D,Mitra N,et al.A Data-adaptive Strategy for Inverse Weighted Estimation of Causal Effects[J].Health Services and Outcomes Research Methodology,2014,14:69-91.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title="S&#228;rndal C E,Swensson B,Wretman J.Model Assisted Survey Sampling[M].New York:Springer-Verlag,1992." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Model Assisted Survey Sampling">
                                        <b>[24]</b>
                                        S&#228;rndal C E,Swensson B,Wretman J.Model Assisted Survey Sampling[M].New York:Springer-Verlag,1992.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=TJYJ" target="_blank">统计研究</a>
                2019,36(09),93-103 DOI:10.19343/j.cnki.11-1302/c.2019.09.008            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>大数据背景下网络调查样本的建模推断问题研究</b>——以广义Boosted模型的倾向得分推断为例</span>
 <span class="shoufa"></span>                                     </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%B1%95&amp;code=11572890&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘展</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%BD%98%E8%8E%B9%E4%B8%BD&amp;code=42173694&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">潘莹丽</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B9%96%E5%8C%97%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0234810&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">湖北大学数学与统计学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着大数据和网络的不断发展,网络调查越来越广泛,大部分网络调查样本属于非概率样本,难以采用传统的抽样推断理论进行推断,如何解决网络调查样本的推断问题是大数据背景下网络调查发展的迫切需求。本文首次从建模的角度提出了解决该问题的基本思路:一是入样概率的建模推断,可以考虑构建基于机器学习与变量选择的倾向得分模型来估计入样概率推断总体;二是目标变量的建模推断,可以考虑直接对目标变量建立参数、非参数或半参数超总体模型进行估计;三是入样概率与目标变量的双重建模推断,可以考虑进行倾向得分模型与超总体模型的加权估计与混合推断。最后,以基于广义Boosted模型的入样概率建模推断为例演示了具体解决方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%A7%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BD%91%E7%BB%9C%E8%B0%83%E6%9F%A5%E6%A0%B7%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">网络调查样本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%A5%E6%A0%B7%E6%A6%82%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">入样概率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E5%8F%98%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标变量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BB%BA%E6%A8%A1%E6%8E%A8%E6%96%AD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">建模推断;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘展,女,湖北大学数学与统计学学院副教授、硕士生导师。研究方向为抽样推断、缺失数据、分布式优化方法。;
                                </span>
                                <span>
                                    潘莹丽,女,湖北大学数学与统计学学院讲师。研究方向为生存分析、分布式优化方法、抽样推断。;
                                </span>
                    </p>
                
                    <p>

                            <b>基金：</b>
                                                        <span>国家社会科学基金一般项目“大数据背景下网络调查样本的模型推断研究”(18BTJ022)的资助;</span>
                    </p>
            </div>
                    <h1><b>Research on the Modeling Inference of Web Survey Samples In the Context of Big Data: Taking Propensity Score Inference of Generalized Boosted Model as an Example</b></h1>
                    <h2>
                    <span>Liu Zhan</span>
                    <span>Pan Yingli</span>
            </h2>
                                    <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the development of big data and internet, web surveys are becoming more and more extensive. However, most of web survey samples belong to non-probability samples. It is difficult to apply the traditional inference theory of probability sampling to web survey samples. Therefore, how to solve inference problems of web survey samples is the urgent need for the development of web surveys in the context of big data. The research proposes some basic ideas to solve this problem from the perspective of modeling for the first time. First, inclusion probabilities can be estimated via modeling for inference. That is, propensity score models based on machine learning and variable selection can be constructed to estimate inclusion probabilities. Second, target variables can be estimated via modeling for inference. It can be considered to establish parametric, non-parametric or semi-parametric superpopulation models of target variables for estimating the population. Third, both inclusion probabilities and target variables can be estimated via modeling for inference. The weighted estimation and hybrid inference of propensity score models and superpopulation models can be considered. Finally, the modeling inference method of inclusion probabilities based on generalized boosted model is taken as an example to discuss concrete solutions to the modeling inference problem of web survey samples.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Big%20Data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Big Data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Web%20Survey%20Samples&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Web Survey Samples;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Inclusion%20Probability&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Inclusion Probability;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Target%20Variables&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Target Variables;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Modeling%20Inference&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Modeling Inference;</a>
                </p>
            </div>
        

        <!--brief start-->
                        <h3 id="51" name="51" class="anchor-tag">一、引言</h3>
                <div class="p1">
                    <p id="52">在当今的大数据时代,各行各业都面临着大数据所带来的机遇,大数据的突出特点是多样性、大量性、高速性、易变性和价值性,在这样的数据背景以及网络的不断发展下,网络调查被越来越多的人所使用,已成为大数据背景下一种重要的抽样调查方法,其中最为突出的就是候选者数据库网络调查。网络调查的候选者数据库,简称网络候选者数据库,指自愿完成网络调查的网络访问人群,若他们在以后的数据收集中被选择为调查对象,将愿意完成网络调查(<citation id="192" type="reference"><link href="3" rel="bibliography" />Svensson,2013</citation>)<citation id="191" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。网络候选者数据库的现实特征主要有三点:一是大量性,由于各调查公司往往采用多种不同的方法,比如通过网站、杂志、电视节目等进行宣传,在广大范围内招募志愿者,所以网络候选者数据库所包含的对象数量往往比较多。二是网络性,即网络候选者数据库成员能非常方便的接触到电脑并能进行网络访问,这在网络迅猛发展的当下是很容易实现的。三是自愿性,即网络候选者数据库成员是自愿加入并愿意完成调查的人,通常各调查公司会采取一些措施比如现金、商品的积分兑换等来激励志愿者。候选者数据库网络调查是指从网络候选者数据库中抽取样本进行网络调查,其获得的样本为网络候选者数据库的调查样本。一方面,候选者数据库网络调查能在很短的时间内,以相对较低的成本,高效地从大量受访者那里获得调查数据;另一方面,无回答率不断上升、抽样框覆盖不全等问题,使得概率样本的调查难度增大、成本增高,因此候选者数据库网络调查被广泛的应用于市场研究、政府调研、民意调查以及学术研究之中,引起了人们越来越多的关注与重视。然而,候选者数据库网络调查样本本质上属于非概率样本,无法采用传统的抽样推断理论进行推断。因此,如何解决网络调查样本特别是候选者数据库网络调查样本的推断问题,是大数据背景下网络调查发展的迫切需求。</p>
                </div>
                <div class="p1">
                    <p id="53">本文对网络调查样本特别是候选者数据库网络调查样本的推断问题进行思考,首次从建模的角度进行系统分析,提出解决网络调查样本推断问题的基本思路,并以其中一种思路为例讨论具体的解决方法,逐步搭建网络调查样本的模型推断体系,这对丰富抽样领域的问题研究,具有重要的理论价值。同时,大数据背景下网络调查样本很多属于非概率样本,如何更好的利用网络调查数据,发挥抽样推断的功能,就需要对网络调查样本的推断问题进行研究,这有利于促进网络调查的进一步发展,也为其他非概率抽样如滚雪球抽样的统计推断,以及大数据的处理与分析提供一定的启示,具有广泛的应用价值。</p>
                </div>
                <h3 id="54" name="54" class="anchor-tag">二、基本思路</h3>
                <div class="p1">
                    <p id="55">对网络调查样本进行建模推断可从三种思路来考虑:入样概率建模、目标变量建模、入样概率与目标变量双重建模。第一种思路是,由于候选者数据库网络调查样本的入样概率未知,考虑估计样本单元的入样概率,对入样概率进行建模估计,利用估计的入样概率(伪入样概率)与传统的概率抽样推断理论来求得总体估计,即准随机方法(Quasi-randomization approach),也称为基于伪设计的估计。第二种思路是不估计入样概率,而直接对目标变量<i>Y</i>进行建模估计,假定目标变量<i>Y</i>是一个服从某一分布的随机变量,根据样本建立关于<i>Y</i>的模型来预测总体中不在样本中的单元,从而得到总体的估计,即超总体模型方法(Superpopulation model approach),也称为基于模型的估计。第三种思路是将前两种方法结合,即对入样概率与目标变量同时建模对总体进行推断,获得总体的双重稳健估计。下文具体探讨这三种基本思路。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56">(<b>一)入样概率的建模推断</b></h4>
                <div class="p1">
                    <p id="57">对于第一种思路,建立怎样的模型来估计候选者数据库网络调查样本的入样概率,获得样本的权数,成为众多研究者讨论的关键问题。倾向得分调整是应用最多的估计入样概率推断总体的方法。倾向得分为在给定协变量的条件下个体接受处理(参与或者回答)的条件概率,最初是Rosenbaum和Rubin于1983年在因果推断中为了对观察性研究中处理组与控制组之间的差异进行控制而提出的,随后在20世纪90年代末被Harris Interactive研究机构引入网络调查中。Harris Interactive首次基于一个随机的电话调查样本与一个候选者数据库网络调查样本,建立Logistic回归模型估计了受访者参与网络调查的倾向得分,将倾向得分估计视为入样概率的估计,并利用估计的倾向得分对网络调查样本进行加权调整来推断总体。<citation id="203" type="reference"><link href="5" rel="bibliography" />Lee(2006)</citation><citation id="193" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>提出在建立Logistic回归模型估计出倾向得分之后,根据估计的倾向得分进行分组计算候选者数据库网络调查样本单元的权数,从而实现对总体的估计。<citation id="204" type="reference"><link href="7" rel="bibliography" />Valliant和Dever(2011)</citation><citation id="194" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出将倾向得分估计的逆作为调整权数,根据倾向得分估计分组在每组中求倾向得分估计均值的逆作为调整权数等方法来估计总体。<citation id="205" type="reference"><link href="9" rel="bibliography" />Brick(2014)</citation><citation id="195" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出先分层后建立模型估计网络调查样本的倾向得分,然后进行校准调整来估计总体。国内学者在这方面的研究相对比较匮乏,仅有<citation id="206" type="reference"><link href="11" rel="bibliography" />金勇进和刘展(2016)</citation><citation id="196" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>,刘展和金勇进(2017)<citation id="197" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>,<citation id="207" type="reference"><link href="15" rel="bibliography" />牛成英和孙秋碧(2015)</citation><citation id="198" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等做过这方面的研究。以上研究在估计倾向得分时大多建立Logistic或Probit回归模型来估计,然而如果有大量的混杂变量或者哪些协变量是混杂因素未知,此时Logistic或Probit回归模型就不再适用,机器学习方法如Boosting、随机森林等可以拟合高维的倾向得分模型(<citation id="208" type="reference"><link href="17" rel="bibliography" />Mercer等,2017</citation>)<citation id="199" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。事实上,倾向得分起源于因果推断,而因果推断已经有处理选择偏差的理论基础和一些新的方法,如Bagging或Boosting、递归分割或基于树的方法、随机森林与神经网络,这些方法已经被用于因果推断中倾向得分的估计并经过了检验,值得引入网络调查中进行探索(<citation id="209" type="reference"><link href="9" rel="bibliography" />Brick,2014</citation>)<citation id="200" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。此外,<citation id="210" type="reference"><link href="19" rel="bibliography" />Tibshirani(1996)</citation><citation id="201" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出的一种变量选择降维方法LASSO,已经被应用于调查估计之中(<citation id="211" type="reference"><link href="21" rel="bibliography" />Chen,2016</citation>)<citation id="202" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>,也给倾向得分的模型推断开拓了思路。可以看到,候选者数据库网络调查样本的推断在倾向得分模型的构建方面还有很大的探索空间,尤其是高维协变量倾向得分模型的建立和总体估计值得进一步探索。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58">(<b>二)目标变量的建模推断</b></h4>
                <div class="p1">
                    <p id="59">对于第二种思路,对目标变量Y进行建模即超总体模型方法,目标变量模型的构建和检验成为最主要的问题。事实上,<citation id="221" type="reference"><link href="23" rel="bibliography" />Valliant等在2000</citation>年已经提出了经典的广义线性模型预测的超总体模型推断框架(<citation id="222" type="reference"><link href="23" rel="bibliography" />Valliant,2000</citation>)<citation id="212" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。Chamber和Clark(2012)<citation id="213" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>在此基础上探讨和发展了关于调查设计与估计的超总体模型方法,还有一些研究者将超总体模型推断理论应用于总体规模的估计、缺失数据的插补与方差计算、复杂调查数据的设计与分析、调查权数的调整以及小域估计之中。然而,以上的研究是在概率抽样下来探讨超总体模型的推断方法,对于非概率样本特别是候选者数据库网络调查样本,超总体模型方法是否适用还未涉及。<citation id="223" type="reference"><link href="27" rel="bibliography" />Pfeffermann和Rao(2009)</citation><citation id="214" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>对超总体模型方法在什么样的条件下抽样方法可以忽略,而可以作出仍然有效的推断进行了探讨。<citation id="224" type="reference"><link href="29" rel="bibliography" />Baker等(2013)</citation><citation id="215" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>在AAPOR的报告中提出非概率样本的估计方法,其中就包括基于模型的估计。<citation id="225" type="reference"><link href="31" rel="bibliography" />Cooper和 Greenaway(2015)</citation><citation id="216" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>明确指出对于非概率抽样,传统的基于设计的估计方法已不再适用,主要的替代方法就是基于模型的估计。<citation id="226" type="reference"><link href="33" rel="bibliography" />Elliott和Valliant(2017)</citation><citation id="217" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出了针对非概率样本的广义线性模型的超总体模型推断方法。目前超总体模型方法在非概率样本中的使用与研究才刚刚起步,还没有广泛的应用于候选者数据库网络调查之中(<citation id="227" type="reference"><link href="35" rel="bibliography" />Dayan,2014</citation>)<citation id="218" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>,对候选者数据库网络调查样本的超总体模型推断方法还需要进一步的研究。需要注意的是,超总体模型方法需要对模型进行一些假定,如正态性、模型形式的设定,样本单元与非样本单元(总体中不在样本中的单元)的模型形式是否相同等,以便于产生有效的估计,然而如果模型的一些假定不满足,则超总体模型方法可能会产生不准确或错误的结果(<citation id="228" type="reference"><link href="29" rel="bibliography" />Baker等,2013 </citation><citation id="219" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>;<citation id="229" type="reference"><link href="31" rel="bibliography" />Cooper 和 Greenaway,2015 </citation><citation id="220" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>)。虽然超总体模型的方法已经确立,但是一个非概率样本的模型是否也适合整个总体的模型假定的诊断方法还没有确立,如何验证超总体模型的假定是一个值得研究的问题。此外,以往一些相关研究中讨论的超总体模型大多属于参数模型,需要验证参数模型的各个假定,检验过程较复杂,而非参数模型、半参数模型以及机器学习的一些方法对模型的假定条件有所放松,适用性更广,能够在参数模型假定不符时改进估计的效率,也为候选者数据库网络调查样本的超总体模型推断提供了新的思路。</p>
                </div>
                <h4 class="anchor-tag" id="60" name="60">(<b>三)入样概率与目标变量的双重建模推断</b></h4>
                <div class="p1">
                    <p id="61">超总体模型方法的样本选择机制可分为可忽略的选择机制和不可忽略的选择机制。如果总体单元进入样本的概率不依赖于<i>Y</i>,则为可忽略的选择机制,否则为不可忽略的选择机制。当一些非概率样本是不可忽略的样本选择机制时,就不能根据样本数据直接建立<i>Y</i>与<i>X</i>的模型来推断总体,此时可以将准随机方法和超总体模型方法结合(<citation id="233" type="reference"><link href="33" rel="bibliography" />Elliott 和Valliant,2017</citation>)<citation id="230" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>,即对入样概率与目标变量同时建模推断。那么,如何将两种方法结合对网络调查样本进行推断,目前国内没有这方面的研究,国外在这方面的研究也才刚刚开始,仅有<citation id="234" type="reference"><link href="35" rel="bibliography" />Dayan(2014)</citation><citation id="231" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>等做过这方面的探讨。此外,混合推断(<citation id="235" type="reference"><link href="37" rel="bibliography" />Stahl等,2016</citation>)<citation id="232" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>根据目标变量缺失的概率样本以及另一个与该概率样本独立的样本,对目标变量<i>Y</i>建立超总体模型,然后利用该模型预测出概率样本的目标变量值,并将其与概率样本的基础权数结合来推断总体,该推断方法已经在小域估计中发展并使用,其思想也对网络调查样本的准随机和超总体方法结合推断有一定的启发作用。</p>
                </div>
                <div class="p1">
                    <p id="62">综上所述,国外关于候选者数据库网络调查样本的推断,对入样概率建模进行推断的研究多一些,对目标变量建模进行推断,以及对入样概率与目标变量同时建模推断的研究相对较少,国内的相关研究就更少,并且已有的入样概率建模推断研究主要集中于较少协变量或混杂变量的Logistic或Probit倾向得分建模推断,目标变量建模推断研究大多局限于模型假设较多的参数超总体模型推断,检验过程较复杂。因此,如何拟合高维倾向得分模型;如何检验参数超总体模型假定,建立非参数与半参数超总体模型;如何将倾向得分模型与超总体模型结合等问题都值得进一步的研究。</p>
                </div>
                <h3 id="63" name="63" class="anchor-tag">三、具体方法的讨论</h3>
                <div class="p1">
                    <p id="64">解决网络调查样本推断问题的思路有多种,本文以入样概率的倾向得分建模推断为例,探讨具体的解决方法。在因果推断中,Boosting方法已经被证明在预测误差方面比其他的一些方法更好,当模型涉及到大量的协变量时特别有效(Bühlmann和Yu,2003)<citation id="236" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。作为Boosting的一种变式,广义Boosted模型(Generalized boosted model,简记为GBM)与其他Boosting方法实现不同,可以被调整以产生良好校准概率估计的模型,被广泛的应用于因果推断中估计因果效应,然而还未见其在网络调查中有相关探讨。此部分将探讨基于广义Boosted模型的网络调查样本推断问题。</p>
                </div>
                <div class="p1">
                    <p id="65">假定网络候选者数据库的调查样本是从网络候选者数据库中随机抽取的样本,记为<i>S</i><sub><i>w</i></sub>,网络候选者数据库记为<i>V</i>,则网络候选者数据库的调查样本可近似视为一个二阶段抽取的样本,第一阶段从总体<i>U</i>中非概率抽取网络候选者数据库<i>V</i>,第二阶段从网络候选者数据库<i>V</i>中随机抽取样本<i>S</i><sub><i>w</i></sub>。由于第一阶段抽样不是随机抽样,这种非随机性使得最终得到的网络候选者数据库的调查样本<i>S</i><sub><i>w</i></sub>属于非概率样本,其入样概率未知,从而无法采用传统的概率抽样推断理论来推断总体。现考虑对入样概率进行估计,设网络候选者数据库的调查样本中第<i>i</i>个单元的目标变量为<i>Y</i><sub><i>i</i></sub>,协变量为<i>X</i><sub><i>i</i></sub><sub>1</sub>,<i>X</i><sub><i>i</i></sub><sub>2</sub>,…,<i>X</i><sub><i>ip</i></sub>,<i>i</i>=1,…,<i>n</i><sub><i>s</i></sub>,<i>p</i>为协变量个数(可能是高维的,即<i>p</i>非常大),记<i>X</i><sub><i>i</i></sub>为<i>X</i><sub><i>i</i></sub><sub>1</sub>,<i>X</i><sub><i>i</i></sub><sub>2</sub>,…,<i>X</i><sub><i>ip</i></sub>中任意个协变量组成的向量,则单元<i>i</i>进入网络候选者数据库的调查样本<i>S</i><sub><i>w</i></sub>的概率(包含概率或入样概率)为:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>π</mtext><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">其中,<mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>为从网络候选者数据库<i>V</i>中随机抽取样本单元<i>i</i>(<i>i</i>∈<i>S</i><sub><i>w</i></sub>)的概率,该概率已知;<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>为给定<i>X</i><sub><i>i</i></sub>的条件下单元<i>i</i>自愿加入网络候选者数据库<i>V</i>的概率,该概率未知。因此,要估计网络候选者数据库的调查样本<i>S</i><sub><i>w</i></sub>的入样概率只需要估计<mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>即可。</p>
                </div>
                <div class="p1">
                    <p id="68">设存在一个相关的参考样本<i>S</i><sub><i>r</i></sub>,该参考样本一般为一个概率样本,能代表目标总体,且与网络候选者数据库<i>V</i>有相同的协向量<i>X</i>,其目标变量<i>Y</i>未知。现实中参考样本通常是通过参考调查获得的,而参考调查要求比网络调查有更好的抽样框覆盖、随机抽样性质以及较高的回答率。例如,参考调查可以是采用传统调查模式如Harris Interactive调查中的随机数字拨号电话调查方法进行的调查,也可以是现有的调查如美国的当前人口调查(Current Population Survey,CPS)、全国健康访谈调查(National Health Interview Survey,NHIS)等,或者是与网络调查目的更密切相关的较小规模的调查。特别是像CPS和NHIS这样的调查已经在网上提供了公开、免费且覆盖了所有家庭人口的数据,为参考样本的获取带来了极大的便利性(<citation id="238" type="reference"><link href="41" rel="bibliography" />Lee和Valliant,2009</citation>)<citation id="237" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation></p>
                </div>
                <div class="p1">
                    <p id="69">考虑将参考样本<i>S</i><sub><i>r</i></sub>与网络候选者数据库<i>V</i>结合构建广义Boosted模型来估计<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>。设<i>W</i><sub><i>i</i></sub>为一个二值示性变量,若单元<i>i</i>在网络候选者数据库<i>V</i>中,则<i>W</i><sub><i>i</i></sub>=1;若单元<i>i</i>在参考样本<i>S</i><sub><i>r</i></sub>中,则<i>W</i><sub><i>i</i></sub>=0。因此,<mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>本质上为倾向得分。现考虑构建广义Boosted模型对倾向得分<mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>进行估计。</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70">(<b>一)基于广义</b>Boosted<b>模型的倾向得分推断理论</b></h4>
                <div class="p1">
                    <p id="71">记<mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>W</mi><mo>=</mo><mn>1</mn><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>,令log(<i>p</i>(<i>X</i>)/(1-<i>p</i>(<i>X</i>)))=<i>g</i>(<i>X</i>),则只需估计出<i>g</i>(<i>X</i>),即可得到<i>p</i>(<i>X</i>)=1/(1+exp(-<i>g</i>(<i>X</i>)))的估计。以往对倾向得分<i>p</i>(<i>X</i>)的估计大多采用Logistic回归模型,其中<i>g</i>(<i>X</i>)=<i>X</i><sup><i>T</i></sup><i>β</i>为线性回归模型,然而当存在大量协变量时该模型就不再适用,此时考虑对<i>g</i>(<i>X</i>)采用Boosting方法进行估计,即允许<i>g</i>(<i>X</i>)是一个灵活的函数族中的一个函数,并使用Boosting来选择这个函数。根据<i>W</i>服从概率为<i>p</i>(<i>X</i>)的两点分布,其log似然函数<i>l</i>(<i>p</i>)的期望为:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable><mtr><mtd columnalign="left"><mi>E</mi><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><mi>W</mi><mtext>l</mtext><mtext>o</mtext><mtext>g</mtext><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>W</mi><mo stretchy="false">)</mo><mi>log</mi><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd columnalign="left"><mspace width="0.25em" /><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><mi>W</mi><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>-</mo><mi>log</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">Boosting为一种求最大似然估计的算法。基本思路就是:假设有一个使得<i>E</i>(<i>l</i>(<i>g</i>))最大的函数估计,记为<mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>,进一步通过对<mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>增加一个小的调整项来改进估计,即寻找一个<i>h</i>(<i>X</i>)使得<mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo>+</mo></mrow></math></mathml><i>λ</i><mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>&gt;</mo><mi>E</mi><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></mathml>,其中λ为参数,这一新的改进使得期望的log似然函数有所增加,从而得到更新的<i>g</i>(<i>X</i>)估计,即<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>←</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo></mrow></math></mathml><i>λh</i>(<i>X</i>),这一过程不断迭代,最终得到<i>g</i>(<i>X</i>)的最优估计,那么如何寻找<i>h</i>(<i>X</i>)就成为一个关键问题。广义Boosted模型使用回归树算法(<citation id="240" type="reference"><link href="43" rel="bibliography" />Breiman等,1984</citation>)<citation id="239" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>来估计<i>h</i>(<i>X</i>),从而得到一个稳健的非参数预测模型,这也是广义Boosted模型最大的特色。</p>
                </div>
                <div class="p1">
                    <p id="74">回归树是使用迭代算法来估计一个函数,该函数用于描述多个自变量和一个因变量之间的关系。回归树算法首先从完整的数据集开始,根据一个输入变量的值将数据集划分为两个区域,根据另一个输入变量又可将已划分的每个区域进一步的划分为两个新的区域,依次做下去,直到达到允许的划分数为止,最终可将数据集划分为<i>K</i>个区域<i>R</i><sub>1</sub>,<i>R</i><sub>2</sub>,…,<i>R</i><sub><i>K</i></sub>,从而生成一棵回归树,见图1。事实上,在所有可能的划分中,回归树算法选择使得预测误差最小的那种划分。在最终划分的某一区域内,估计的函数就等于落在该区域单元目标变量<i>Y</i>的样本均值,即当协向量<i>X</i>的值落在哪个区域,最终函数<i>Y</i>=<i>h</i>(<i>X</i>)的估计值就等于该区域所有观测的均值。利用回归树算法可获得<i>h</i>(<i>X</i>)的估计,从而得到<i>g</i>(<i>X</i>)的估计<mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJYJ201909008_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 回归树" src="Detail/GetImg?filename=images/TJYJ201909008_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 回归树</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJYJ201909008_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="76">在获得<i>g</i>(<i>X</i>)的估计<mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>之后,也就得到倾向得分<mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>W</mi><mo>=</mo><mn>1</mn><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>的估计<mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>p</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>W</mi><mo>=</mo><mn>1</mn><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></mathml>,其中<mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow></math></mathml>表示对<i>P</i>(·)的估计。将其代入式(1),从而得到网络候选者数据库的调查样本<i>S</i><sub><i>w</i></sub>的入样概率估计:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo>=</mo><mover accent="true"><mi>p</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo>=</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo><mo>/</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">进一步将入样概率估计的倒数作为权数,结合网络候选者数据库的调查样本<i>S</i><sub><i>w</i></sub>对总体均值进行估计,即有:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable><mtr><mtd columnalign="left"><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mrow><mi>Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mover accent="true"><mi>π</mi><mo>⌢</mo></mover></mrow></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mrow><mn>1</mn><mo>/</mo><mover accent="true"><mi>π</mi><mo>⌢</mo></mover></mrow></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mi>Y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mn>1</mn></mstyle><mo>/</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr><mtr><mtd columnalign="left"><mspace width="0.25em" /><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mo stretchy="false">(</mo></mstyle><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi>Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mo stretchy="false">(</mo></mstyle><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>/</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">从而通过建立广义Boosted模型估计出倾向得分,进一步估计出网络候选者数据库的调查样本的入样概率,并利用概率抽样的推断理论对总体的参数如均值进行推断。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">(<b>二)基于广义</b>Boosted<b>模型的倾向得分估计算法</b></h4>
                <div class="p1">
                    <p id="82">根据广义Boosted模型的基础理论,本文在<citation id="242" type="reference"><link href="45" rel="bibliography" />McCaffrey等(2004)</citation><citation id="241" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>提出算法的基础上,提出结合参考样本<i>S</i><sub><i>r</i></sub>与网络候选者数据库<i>V</i>估计倾向得分的广义Boosted算法。具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="83">首先,将参考样本<i>S</i><sub><i>r</i></sub>(<i>W</i>=0)与网络候选者数据库<i>V</i>(<i>W</i>=1)结合为<i>S</i>=<i>S</i><sub><i>r</i></sub>∪<i>V</i>,计算<mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>W</mi><mo>¯</mo></mover><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>r</mi></msub><mstyle displaystyle="true"><mo>∪</mo><mi>V</mi></mstyle></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mo stretchy="false">(</mo><mi>n</mi><msub><mrow></mrow><mi>r</mi></msub><mo>+</mo><mi>n</mi><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>n</mi><msub><mrow></mrow><mi>w</mi></msub><mo>/</mo><mo stretchy="false">(</mo><mi>n</mi><msub><mrow></mrow><mi>r</mi></msub><mo>+</mo><mi>n</mi><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>,将初始函数估计设为<mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>log</mi></mrow><mo stretchy="false">(</mo><mover accent="true"><mi>W</mi><mo>¯</mo></mover><mo>/</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mover accent="true"><mi>W</mi><mo>¯</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></mathml>,其中<i>n</i><sub><i>r</i></sub>为参考样本<i>S</i><sub><i>r</i></sub>的样本量,<i>n</i><sub><i>w</i></sub>为网络候选者数据库<i>V</i>的单元个数。这里假定参考样本<i>S</i><sub><i>r</i></sub>与网络候选者数据库<i>V</i>没有重叠,事实上即使两者有重叠,由于通常情况下网络候选者数据库<i>V</i>非常大,所以重叠部分相对<i>V</i>来说较小,可以忽略不计。</p>
                </div>
                <div class="p1">
                    <p id="84">然后,对<i>m</i>=1,2,…,<i>M</i>,做如下的迭代计算:</p>
                </div>
                <div class="p1">
                    <p id="85">(1)计算<mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>,构建回归树模型拟合<i>Y</i>′<sub><i>i</i></sub>,根据<i>X</i>(单元所具有的特征)将<i>S</i>=<i>S</i><sub><i>r</i></sub>∪<i>V</i>的所有单元划分为<i>K</i>个区域<i>R</i><sub>1</sub>,<i>R</i><sub>2</sub>,…,<i>R</i><sub><i>K</i></sub>。具体回归树算法如下:</p>
                </div>
                <div class="p1">
                    <p id="86">①选择最优的切分变量<i>X</i><sub>·</sub><sub><i>j</i></sub>(<i>j</i>=1,2,…,<i>p</i>)和切分点<i>s</i>,求解:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>j</mi><mo>,</mo><mi>s</mi></mrow></munder><mrow><mo>[</mo><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></munder><mo stretchy="false">(</mo></mstyle><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></munder><mo stretchy="false">(</mo></mstyle><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">其中,<mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mo>⋅</mo><mi>j</mi></mrow></msub><mo>≤</mo><mi>s</mi></mrow></mrow><mo stretchy="false">}</mo><mo>,</mo><mi>R</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mo>⋅</mo><mi>j</mi></mrow></msub><mo>&gt;</mo><mi>s</mi></mrow></mrow><mo stretchy="false">}</mo><mo>,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>n</mi><msub><mrow></mrow><mi>r</mi></msub><mo>+</mo><mi>n</mi><msub><mrow></mrow><mi>w</mi></msub><mo>,</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></munder><mo stretchy="false">(</mo></mstyle><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>c</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>,</mo><mi>l</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn></mrow></math></mathml>为平方误差表示回归树的预测误差,且<mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>c</mi><mo>⌢</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi>a</mi><mi>v</mi><mi>e</mi><mo stretchy="false">(</mo><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo><mo>,</mo><mover accent="true"><mi>c</mi><mo>⌢</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mi>a</mi><mi>v</mi><mi>e</mi><mo stretchy="false">(</mo><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo>,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>分别为<i>c</i><sub>1</sub>、<i>c</i><sub>2</sub>的估计。遍历<i>j</i>=1,2,…,<i>p</i>,对固定的切分变量<i>X</i><sub>·</sub><sub><i>j</i></sub>扫描切分点<i>s</i>,选择使式(5)达到最小值的切分变量<i>X</i><sub>·</sub><sub><i>j</i></sub><sub>′</sub>和切分点<i>s</i>′。</p>
                </div>
                <div class="p1">
                    <p id="89">②用选定的切分变量<i>X</i><sub>·</sub><sub><i>j</i></sub><sub>′</sub>和切分点<i>s</i>′划分区域:<mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><msup><mi>j</mi><mo>′</mo></msup><mo>,</mo><msup><mi>s</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><msup><mi>j</mi><mo>′</mo></msup></mrow></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mo>⋅</mo><msup><mi>j</mi><mo>′</mo></msup></mrow></msub><mo>≤</mo><msup><mi>s</mi><mo>′</mo></msup></mrow></mrow><mo stretchy="false">}</mo><mo>,</mo><mi>R</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><msup><mi>j</mi><mo>′</mo></msup><mo>,</mo><msup><mi>s</mi><mo>′</mo></msup><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><msup><mi>j</mi><mo>′</mo></msup></mrow></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mo>⋅</mo><msup><mi>j</mi><mo>′</mo></msup></mrow></msub><mo>&gt;</mo><msup><mi>s</mi><mo>′</mo></msup></mrow></mrow><mo stretchy="false">}</mo><mo>,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>n</mi><msub><mrow></mrow><mi>r</mi></msub><mo>+</mo><mi>n</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="90">③继续对划分的两个区域调用①、②,即对每个区域重复上述划分过程,直到满足停止条件为止,从而生成一棵回归树(最小二乘回归树),最终也将<i>S</i>中所有单元分成了<i>K</i>个区域<i>R</i><sub>1</sub>,<i>R</i><sub>2</sub>,…,<i>R</i><sub><i>K</i></sub>,整个回归树所选择的最优切分变量组成的向量记为<i>X</i>。这里停止条件是指所划分区域中样本单元个数小于预定阈值,或样本<i>S</i>的预测误差<mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mo stretchy="false">(</mo></mstyle></mrow></mstyle><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>小于预定阈值,其中<mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mover accent="true"><mi>C</mi><mo>^</mo></mover></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi>Ι</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>,</mo><mover accent="true"><mi>C</mi><mo>^</mo></mover><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mi>a</mi><mi>v</mi><mi>e</mi><mo stretchy="false">(</mo><msup><mi>Y</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>n</mi><msub><mrow></mrow><mi>r</mi></msub><mo>+</mo><mi>n</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="91">(2)在每一个区域中计算<i>h</i><sub><i>k</i></sub>,即:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>h</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext></mrow></mstyle><mi>θ</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mo stretchy="false">[</mo></mstyle><mi>W</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>-</mo><mrow><mi>log</mi></mrow><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo>≈</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mrow><mrow><mo>[</mo><mrow><mi>W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>]</mo></mrow></mrow></mstyle></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mrow><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow></mstyle><mrow><mo>[</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>]</mo></mrow></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mspace width="0.25em" /><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mrow><mrow><mo>[</mo><mrow><mi>W</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>]</mo></mrow></mrow></mstyle></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>R</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mrow><mfrac><mrow><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mrow><mo stretchy="false">[</mo><mn>1</mn><mo>+</mo><mi>exp</mi><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow></mstyle></mrow></mfrac></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">其中<i>k</i>=1,2,…,<i>K</i>,式(6)中的第二行是基于二阶泰勒展开近似得到的。<i>h</i><sub><i>k</i></sub>为在每个区域对<mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>的最优调整项,即当<i>S</i>=<i>S</i><sub><i>r</i></sub>∪<i>V</i>单元落入第<i>k</i>个区域时,调整项就是<i>h</i><sub><i>k</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="94">(3)更新<i>g</i>(<i>X</i>)的估计:<mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>←</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mi>h</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></msub></mrow></math></mathml>,其中<i>k</i>(<i>X</i>)确定了具有特征<i>X</i>的单元属于哪个区域,<i>h</i><sub><i>k</i></sub><sub>(</sub><sub><i>X</i></sub><sub>)</sub>则为落入该区域的调整项。</p>
                </div>
                <div class="p1">
                    <p id="95">以上步骤不断迭代,最终迭代停止后得到<i>g</i>(<i>X</i>)的估计<mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>,也就得到了倾向得分的估计<mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>p</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>W</mi><mo>=</mo><mn>1</mn><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></mathml>,进一步将其代入式(4)即可获得总体均值的估计。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96">(<b>三)基于广义</b>Boosted<b>模型总体估计的理论性质</b></h4>
                <div class="p1">
                    <p id="97">在构建广义Boosted模型估计倾向得分,并利用倾向得分估计获得了总体均值的估计后,进一步探索总体均值估计的性质。记:</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable><mtr><mtd columnalign="left"><mi>A</mi><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>X</mi><mo>,</mo><mi>W</mi><msup><mrow></mrow><mo>*</mo></msup></mrow></msub><mtext>ϕ</mtext><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>,</mo><mi>W</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd columnalign="left"><mspace width="0.25em" /><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><mi>log</mi><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>e</mi><msup><mrow></mrow><mrow><mo>-</mo><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mi>W</mi><msup><mrow></mrow><mo>*</mo></msup></mrow></msup><mo stretchy="false">)</mo><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd columnalign="left"><mspace width="0.25em" /><mo>=</mo><mo>-</mo><mi>E</mi><mo stretchy="false">(</mo><mi>W</mi><mtext>l</mtext><mtext>o</mtext><mtext>g</mtext><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>W</mi><mo stretchy="false">)</mo><mi>log</mi><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>p</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd columnalign="left"><mspace width="0.25em" /><mo>=</mo><mo>-</mo><mi>E</mi><mo stretchy="false">(</mo><mi>l</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">其中ϕ(<i>g</i>(<i>X</i>),<i>W</i><sup>*</sup>)=log(1+<i>e</i><sup>-</sup><sup><i>g</i></sup><sup>(</sup><sup><i>X</i></sup><sup>)</sup><sup><i>W</i></sup><sup>*</sup>),<i>W</i><sup>*</sup>=2<i>W</i>-1。构建广义Boosted模型估计<i>g</i>(<i>X</i>)实际上就是求如下的一个优化问题的解:inf<sub><i>g</i></sub><sub>∈</sub><sub><i>span</i></sub><sub>(</sub><sub><i>G</i></sub><sub>)</sub><i>A</i>(<i>g</i>),其中<mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>p</mi><mi>a</mi><mi>n</mi><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>w</mi></mstyle><msup><mrow></mrow><mi>j</mi></msup><mi>g</mi><msup><mrow></mrow><mi>j</mi></msup></mrow></math></mathml>:<i>g</i><sup><i>j</i></sup>∈<i>G</i>,<i>w</i><sup><i>j</i></sup>∈<i>R</i>,<i>L</i>∈<i>Z</i><sup>+</sup>}为一个线性函数空间,<i>G</i>={<i>I</i><sub>(-∞,</sub><sub><i>a</i></sub><sub>1]×…×(-∞,</sub><sub><i>ap</i></sub><sub>]</sub>:<i>a</i><sub>1</sub>,…,<i>a</i><sub><i>p</i></sub>∈<i>R</i>}。<i>g</i>(<i>X</i>)就是由回归树构成的基本函数的可加模型来拟合,广义Boosted模型算法就是在第<i>m</i>-1步拟合得到<mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow></math></mathml>,进一步的找到 <i>λ</i>和<i>h</i>(<i>X</i>)得到<mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>+</mo></mrow></math></mathml><i>λh</i>(<i>X</i>),使得<i>A</i>(<i>g</i>)接近最小。事实上,<citation id="244" type="reference"><link href="47" rel="bibliography" />Zhu等(2014)</citation><citation id="243" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>已经证明了如下定理。</p>
                </div>
                <div class="p1">
                    <p id="100">定理1:假设</p>
                </div>
                <div class="p1">
                    <p id="101">(A1)存在一个唯一的<i>g</i><sup>*</sup>使得<i>A</i>(<i>g</i><sup>*</sup>)=inf<sub><i>g</i></sub><sub>∈</sub><sub><i>span</i></sub><sub>(</sub><sub><i>G</i></sub><sub>)</sub><i>A</i>(<i>g</i>)。</p>
                </div>
                <div class="p1">
                    <p id="102">(A2)对任何的函数序列<i>g</i><sub><i>n</i></sub>,若<mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mo stretchy="false">(</mo><mi>g</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo><mover><mo stretchy="true" symmetric="false">→</mo><mi>p</mi></mover><mi>A</mi><mo stretchy="false">(</mo><mi>g</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">)</mo></mrow></math></mathml>,则有<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>n</mi></msub><mover><mo stretchy="true" symmetric="false">→</mo><mi>p</mi></mover><mi>g</mi><msup><mrow></mrow><mo>*</mo></msup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="103">(A3)存在两个独立实数序列<i>k</i><sub><i>n</i></sub>和<i>β</i><sub><i>n</i></sub>,满足<mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>lim</mi></mrow></mstyle><mrow><mi>n</mi><mo>→</mo><mi>∞</mi></mrow></munder><mi>k</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mi>∞</mi><mo>,</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>lim</mi></mrow></mstyle><mrow><mi>n</mi><mo>→</mo><mi>∞</mi></mrow></munder><mi>β</mi><msub><mrow></mrow><mi>n</mi></msub><mi>R</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow></math></mathml>,其中<mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>G</mi><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>D</mi><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup></mrow></msub><mi>R</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>G</mi><mo>,</mo><mi>D</mi><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>D</mi><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup></mrow></msub><mi>E</mi><msub><mrow></mrow><mi>σ</mi></msub><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>sup</mi></mrow></mstyle><mrow><mi>g</mi><mo>∈</mo><mi>G</mi></mrow></munder><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>σ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>W</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">)</mo><mo>,</mo><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo>±</mo><mn>1</mn></mrow></math></mathml>且概率为<mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo>/</mo><mn>2</mn><mo>,</mo><mi>R</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>G</mi><mo>,</mo><mi>D</mi><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mi>σ</mi></msub><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>sup</mi></mrow></mstyle><mrow><mi>g</mi><mo>∈</mo><mi>G</mi></mrow></munder><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>σ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>g</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>W</mi><msubsup><mrow></mrow><mi>i</mi><mo>*</mo></msubsup><mo stretchy="false">)</mo></mrow></math></mathml>为函数空间<i>G</i>的Rademacher复杂度,<i>R</i><sub><i>n</i></sub>(<i>G</i>)是广义Boosted模型的Rademacher复杂度的期望,<i>D</i><mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup></mrow></math></mathml>={(<i>X</i><sub><sup>1</sup></sub>,<i>W</i><sup>*</sup><sub>1</sub>),(<i>X</i><sub>2</sub>,<i>W</i><sup>*</sup><sub>2</sub>),…,(<i>X</i><sub><sup><i>n</i></sup></sub>,<i>W</i><sup>*</sup><sub><i>n</i></sub>)}为数据集。在网络调查的背景下,<i>D</i><mathml id="177"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>n</mi></msubsup></mrow></math></mathml>指的是参考样本<i>S</i><sub><i>r</i></sub>与网络候选者数据库<i>V</i>的结合样本数据。假设广义Boosted模型算法在第<mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>m</mi><mo>⌢</mo></mover></math></mathml>步停止迭代,且满足<mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover><mo>≥</mo><mi>k</mi><msub><mrow></mrow><mi>n</mi></msub><mo>,</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo stretchy="false">∥</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover></msub><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mrow><mi>inf</mi></mrow><mrow><mo>{</mo><mrow><mrow><mo stretchy="false">∥</mo><mi>w</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mo>;</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>w</mi></mstyle><msup><mrow></mrow><mi>j</mi></msup><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msubsup><mrow></mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover><mi>j</mi></msubsup><mo>:</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msubsup><mrow></mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover><mi>j</mi></msubsup><mo>∈</mo><mi>G</mi><mo>,</mo><mi>L</mi><mo>∈</mo><mi>Ζ</mi><msup><mrow></mrow><mo>+</mo></msup></mrow><mo>}</mo></mrow><mo>≤</mo><mi>β</mi><msub><mrow></mrow><mi>n</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">在以上三个假设条件下,可得当<i>n</i>→∞时,</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>p</mi><mo>⌢</mo></mover><msub><mrow></mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>/</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mover accent="true"><mi>g</mi><mo>⌢</mo></mover><msub><mrow></mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mover><mo stretchy="true" symmetric="false">→</mo><mi>p</mi></mover><mi>p</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">其中<i>p</i><sup>*</sup>(<i>X</i>)=1/(1+exp(-<i>g</i><sup>*</sup>(<i>X</i>)))。</p>
                </div>
                <div class="p1">
                    <p id="108">由定理1可见,本质上<i>p</i><sup>*</sup>(<i>X</i>)为<i>p</i>(<i>X</i>)的极大似然估计,从而有当<i>n</i>→∞时,</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mi>X</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>p</mi><mo>⌢</mo></mover><msub><mrow></mrow><mover accent="true"><mi>m</mi><mo>⌢</mo></mover></msub><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo><mover><mo stretchy="true" symmetric="false">→</mo><mi>p</mi></mover><mi>p</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><mo>,</mo><mi>V</mi></mrow></mrow><mo stretchy="false">)</mo><mover><mo stretchy="true" symmetric="false">→</mo><mi>p</mi></mover><mi>π</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">进一步根据(Särndal等,1992)<citation id="245" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>的研究可得:当<i>n</i>→∞时,</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false">(</mo><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mi>E</mi><mrow><mo>(</mo><mrow><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mi>Y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mn>1</mn></mstyle><mo>/</mo><mover accent="true"><mi>Ρ</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></mfrac></mrow><mo>)</mo></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mo>→</mo><mi>E</mi></mrow></mstyle><mi>p</mi></mover><mrow><mo>(</mo><mrow><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mi>Y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mn>1</mn></mstyle><mo>/</mo><mi>π</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mo>→</mo><mover accent="true"><mi>Y</mi><mo>¯</mo></mover></mrow></mstyle><mi>p</mi></mover><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">即基于广义Boosted模型的总体均值估计<mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover></mrow></math></mathml>为总体均值<mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover></math></mathml>的渐近无偏估计。总体估计的一个方差估计为:</p>
                </div>
                <div class="p1">
                    <p id="113" class="code-formula">
                        <mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>V</mi><mo>⌢</mo></mover><mo stretchy="false">(</mo><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mover accent="true"><mi>Ν</mi><mo>⌢</mo></mover><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mstyle displaystyle="true"><mo>∑</mo><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></msub><mover accent="true"><mi>Δ</mi><mo>⌣</mo></mover></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mrow><mo>(</mo><mrow><mfrac><mrow><mi>Y</mi><msub><mrow></mrow><mi>k</mi></msub><mo>-</mo><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover></mrow><mrow><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>k</mi></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mi>Y</mi><msub><mrow></mrow><mi>l</mi></msub><mo>-</mo><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover></mrow><mrow><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>l</mi></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="114">其中<mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Ν</mi><mo>⌢</mo></mover><mo>=</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>S</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></msub><mn>1</mn></mstyle><mo>/</mo><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>k</mi></msub><mo>,</mo><mover accent="true"><mi>Δ</mi><mo>⌣</mo></mover><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo>-</mo><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>k</mi></msub><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">)</mo><mo>/</mo><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub><mo>,</mo><mover accent="true"><mi>π</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>k</mi><mi>l</mi></mrow></msub></mrow></math></mathml>为二阶包含概率。此外,总体估计的方差还可采取重抽样的方法,如Bootstrap、Jackknife等进行估计。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115">(<b>四)模拟分析</b></h4>
                <div class="p1">
                    <p id="116">现采用蒙特卡罗模拟来验证所提方法的效果。在模拟中考虑高维的情况,即协变量维数大于样本量的情况,首先产生一个规模为10000(<i>N</i>=10000)的有限总体,其中协变量共有210(<i>p</i>=210)个,(<i>X</i><sub>1</sub>,…,<i>X</i><sub>200</sub>)服从一个多维正态分布,均值为0<sub>(200×1)</sub>,协方差矩阵为∑<sup>200</sup>,具体形式如下:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mn>0</mn><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mn>2</mn><mn>0</mn><mn>0</mn><mo>×</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mo>⋮</mo></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow><msub><mrow></mrow><mrow><mo stretchy="false">(</mo><mn>2</mn><mn>0</mn><mn>0</mn><mo>×</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>,</mo><msup><mstyle mathsize="140%" displaystyle="true"><mo>∑</mo></mstyle><mrow><mn>2</mn><mn>0</mn><mn>0</mn></mrow></msup><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mi>ρ</mi></mtd><mtd><mi>ρ</mi><msup><mrow></mrow><mn>2</mn></msup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>ρ</mi><msup><mrow></mrow><mrow><mn>1</mn><mn>9</mn><mn>9</mn></mrow></msup></mtd></mtr><mtr><mtd><mi>ρ</mi></mtd><mtd><mn>1</mn></mtd><mtd><mi>ρ</mi></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>ρ</mi><msup><mrow></mrow><mrow><mn>1</mn><mn>9</mn><mn>8</mn></mrow></msup></mtd></mtr><mtr><mtd><mi>ρ</mi><msup><mrow></mrow><mn>2</mn></msup></mtd><mtd><mi>ρ</mi></mtd><mtd><mn>1</mn></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>ρ</mi><msup><mrow></mrow><mrow><mn>1</mn><mn>9</mn><mn>7</mn></mrow></msup></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd><mo>⋱</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>ρ</mi><msup><mrow></mrow><mrow><mn>1</mn><mn>9</mn><mn>9</mn></mrow></msup></mtd><mtd><mi>ρ</mi><msup><mrow></mrow><mrow><mn>1</mn><mn>9</mn><mn>8</mn></mrow></msup></mtd><mtd><mi>ρ</mi><msup><mrow></mrow><mrow><mn>1</mn><mn>9</mn><mn>7</mn></mrow></msup></mtd><mtd><mo>⋯</mo></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>,</mo></mtd></mtr><mtr><mtd><mi>c</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>X</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>ρ</mi><msup><mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>i</mi><mo>-</mo><mi>j</mi></mrow><mo>|</mo></mrow></mrow></msup><mo>,</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mn>2</mn><mn>0</mn><mn>0</mn><mo>,</mo><mi>ρ</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>6</mn></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118"><i>X</i><sub>201</sub>,…,<i>X</i><sub>210</sub>的分布如下:</p>
                </div>
                <div class="p1">
                    <p id="119"><i>X</i><sub>201</sub>～<i>B</i>(1,0.3),<i>X</i><sub>202</sub>～<i>B</i>(1,0.7),<i>X</i><sub>203</sub>～<i>B</i>(1,0.5),<i>X</i><sub>204</sub>～<i>Pois</i>(2),</p>
                </div>
                <div class="p1">
                    <p id="120"><i>X</i><sub>205</sub>～<i>Pois</i>(0.9),<i>X</i><sub>206</sub>～<i>unif</i>[0,1],<i>X</i><sub>207</sub>～<i>unif</i>[1,2],<i>X</i><sub>208</sub>～exp(3),</p>
                </div>
                <div class="p1">
                    <p id="121"><i>X</i><sub>209</sub>～<i>chisq</i>(4),<i>X</i><sub>210</sub>～exp(5)</p>
                </div>
                <div class="p1">
                    <p id="122">感兴趣的目标变量<i>Y</i>由如下线性回归模型来生成:</p>
                </div>
                <div class="p1">
                    <p id="123"><i>Y</i>=6.1+<i>β</i><sub>1</sub><i>Z</i><sub>1</sub>+<i>β</i><sub>2</sub><i>Z</i><sub>2</sub>+<i>β</i><sub>3</sub><i>Z</i><sub>3</sub>+<i>β</i><sub>4</sub><i>Z</i><sub>4</sub>+<i>β</i><sub>5</sub><i>Z</i><sub>5</sub>+<i>β</i><sub>6</sub><i>Z</i><sub>6</sub>+<i>β</i><sub>7</sub><i>Z</i><sub>7</sub>+<i>β</i><sub>8</sub><i>Z</i><sub>8</sub>+0.51<i>X</i><sub>201</sub>+0.52<i>X</i><sub>203</sub>+0.53<i>X</i><sub>205</sub>+0.54<i>X</i><sub>207</sub>+0.55<i>X</i><sub>209</sub>+<i>ε</i></p>
                </div>
                <div class="p1">
                    <p id="125">其中,<i>ε</i>～<i>N</i>(0,1),<i>β</i><sub>1</sub>=(0.10,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19),<i>β</i><sub>2</sub>=(0.20,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29),<i>β</i><sub>3</sub>=(0.30,0.31,0.32,0.33,0.34,0.35,0.36,0.37,0.38,0.39),<i>β</i><sub>4</sub>=(0.40,0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48,0.49),<i>β</i><sub>5</sub>=(0.50,0.51,0.52,0.53,0.54,0.55,0.56,0.57,0.58,0.59),<i>β</i><sub>6</sub>=(0.60,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.69),<i>β</i><sub>7</sub>=(0.70,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79),<i>β</i><sub>8</sub>=(0.80,0.81,0.82,0.83,0.84,0.85,0.86,0.87,0.88,0.89),<i>Z</i><sub>1</sub>=(<i>X</i><sub>1</sub>,<i>X</i><sub>2</sub>,…,<i>X</i><sub>10</sub>)<sup><i>T</i></sup>,<i>Z</i><sub>2</sub>=(<i>X</i><sub>11</sub>,<i>X</i><sub>12</sub>,…,<i>X</i><sub>20</sub>)<sup><i>T</i></sup>,<i>Z</i><sub>3</sub>=(<i>X</i><sub>21</sub>,<i>X</i><sub>22</sub>,…,<i>X</i><sub>30</sub>)<sup><i>T</i></sup>,<i>Z</i><sub>4</sub>=(<i>X</i><sub>31</sub>,<i>X</i><sub>32</sub>,…,<i>X</i><sub>40</sub>)<sup><i>T</i></sup>,<i>Z</i><sub>5</sub>=(<i>X</i><sub>41</sub>,<i>X</i><sub>42</sub>,…,<i>X</i><sub>50</sub>)<sup><i>T</i></sup>,<i>Z</i><sub>6</sub>=(<i>X</i><sub>51</sub>,<i>X</i><sub>52</sub>,…,<i>X</i><sub>60</sub>)<sup><i>T</i></sup>,<i>Z</i><sub>7</sub>=(<i>X</i><sub>61</sub>,<i>X</i><sub>62</sub>,…,<i>X</i><sub>70</sub>)<sup><i>T</i></sup>,<i>Z</i><sub>8</sub>=(<i>X</i><sub>71</sub>,<i>X</i><sub>72</sub>,…,<i>X</i><sub>80</sub>)<sup><i>T</i></sup>。</p>
                </div>
                <div class="p1">
                    <p id="126">从而有:</p>
                </div>
                <div class="p1">
                    <p id="127"><i>E</i>(<i>Y</i>)=6.1+0.51<i>E</i>(<i>X</i><sub>201</sub>)+0.52<i>E</i>(<i>X</i><sub>203</sub>)+0.53<i>E</i>(<i>X</i><sub>205</sub>)+0.54<i>E</i>(<i>X</i><sub>207</sub>)+0.55<i>E</i>(<i>X</i><sub>209</sub>)</p>
                </div>
                <div class="p1">
                    <p id="128">=6.1+0.51×0.3+0.52×0.5+0.53×0.9+0.54×1.5+0.55×4</p>
                </div>
                <div class="p1">
                    <p id="129">=10</p>
                </div>
                <div class="p1">
                    <p id="130">真实的倾向得分<mathml id="183"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>采用Logistic回归模型来产生,首先生成<i>p</i><sub><i>i</i></sub>=1/(1+exp(-0.5+0.4<i>X</i><sub>201</sub>-0.2<i>X</i><sub>202</sub>+0.3<i>X</i><sub>204</sub>+0.1<i>X</i><sub>208</sub>))(<i>i</i>=1,2,…,<i>N</i>),然后计算调整的<mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>p</mi><mo>′</mo></msup><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mi>n</mi><msub><mrow></mrow><mi>w</mi></msub><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>。最后采用单元入样概率为<i>p</i>′<sub><i>i</i></sub>的泊松抽样从总体中抽取大小为200(<i>n</i><sub><i>w</i></sub>=200&lt;<i>p</i>=210)的样本视为网络候选者数据库<i>V</i>,并假设该网络候选者数据库<i>V</i>中单元的入样概率在实际中是未知的,即该网络候选者数据库<i>V</i>中单元是非随机选取的。进一步从网络候选者数据库<i>V</i>中采用简单随机抽样抽取样本量为100(<i>n</i><sub><i>s</i></sub>=100)的样本,即为网络候选者数据库的调查样本<i>S</i><sub><i>w</i></sub>。由于网络候选者数据库<i>V</i>中单元是非随机选取的,从中抽取的调查样本的入样概率是未知的,因此网络候选者数据库的调查样本也为非概率样本。同时,采用简单随机抽样从总体中抽取一个样本量为50(<i>n</i><sub><i>r</i></sub>=50)的样本,视其为参考样本<i>S</i><sub><i>r</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="131">将网络候选者数据库<i>V</i>与参考样本<i>S</i><sub><i>r</i></sub>结合,采用常用的Logistic回归模型和本文提出的GBM方法来估计倾向得分<mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>∈</mo><mi>V</mi><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mrow><mo stretchy="false">)</mo></mrow></math></mathml>,在估计倾向得分时建立正确的Logistic回归模型,在估计出倾向得分后结合网络候选者数据库的调查样本<i>S</i><sub><i>w</i></sub>的数据,根据式(4)计算出总体均值的估计,这两种方法估计的总体均值分别记为<mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msub><mrow></mrow><mrow><mi>L</mi><mi>R</mi></mrow></msub></mrow></math></mathml>和<mathml id="187"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msub><mrow></mrow><mrow><mi>G</mi><mi>B</mi><mi>Μ</mi></mrow></msub></mrow></math></mathml>。重复上述过程500(<i>B</i>=500)次,再分别计算500组蒙特卡罗模拟样本上<mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msub><mrow></mrow><mrow><mi>L</mi><mi>R</mi></mrow></msub></mrow></math></mathml>和<mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msub><mrow></mrow><mrow><mi>G</mi><mi>B</mi><mi>Μ</mi></mrow></msub></mrow></math></mathml>的相对偏差(Relative Bias,RB)、方差(Variance)和均方误差(Mean Square Error,MSE),其中相对偏差(%)和均方误差分别为:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>B</mi><mo>=</mo><mfrac><mn>1</mn><mi>B</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mfrac><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msup><mo>-</mo><mi>E</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></mstyle><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn></mtd></mtr><mtr><mtd><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mi>B</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><mrow><mo stretchy="false">(</mo><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msup><mo>-</mo><mi>E</mi><mo stretchy="false">(</mo><mi>Y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中,<mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msup></mrow></math></mathml>为在第<i>b</i>组模拟样本上计算的总体均值估计,结果见表1。</p>
                </div>
                <div class="area_img" id="134">
                    <p class="img_tit"><b>表1 基于GBM总体均值估计的模拟结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="134" border="1"><tr><td><br /></td><td>相对偏差(%)</td><td>方差</td><td>均方误差</td></tr><tr><td><br /><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msub><mrow></mrow><mrow><mi>L</mi><mi>R</mi></mrow></msub></mrow></math></td><td>-0.8907</td><td>1.0501</td><td>1.0559</td></tr><tr><td><br /><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mover accent="true"><mi>Y</mi><mo>¯</mo></mover><mo stretchy="true">⌢</mo></mover><msub><mrow></mrow><mrow><mi>G</mi><mi>B</mi><mi>Μ</mi></mrow></msub></mrow></math></td><td>-0.8617</td><td>1.0195</td><td>1.0248</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="135">由表1可见,基于广义Boosted模型的总体均值估计的相对偏差绝对值要低于基于 Logistic回归模型的总体均值估计,说明基于广义Boosted模型的总体均值估计偏差更小,几乎是无偏的。在方差与均方误差方面,基于广义Boosted模型的总体均值估计均小于基于Logistic回归模型的总体均值估计,表明基于广义Boosted模型的总体均值估计效率更高。从偏差、方差和均方误差三个方面来看,相对于基于 Logistic回归模型的总体均值估计,基于广义Boosted模型的总体均值估计更为稳健,估计效果更好。可以看到,在高维情况下,即使Logistic回归模型建立正确,基于广义Boosted模型的总体均值估计的效果更好。在Logistic回归模型建立错误时,基于广义Boosted模型的总体均值估计的效果要远好于基于Logistic回归模型的总体均值估计,模拟结果不在此一一展示。</p>
                </div>
                <h3 id="136" name="136" class="anchor-tag">四、总结与启示</h3>
                <div class="p1">
                    <p id="137">本文针对大数据背景下网络调查样本的推断问题,从建模的角度提出入样概率的建模推断、目标变量的建模推断、入样概率与目标变量的双重建模推断三种解决问题的基本思路。入样概率的建模推断方面可以探索Bagging、Boosting、随机森林等机器学习的方法以及构建Logistic LASSO模型来估计入样概率推断总体;目标变量的建模推断方面可以考虑构建放松假定条件的非参数与半参数超总体模型直接对总体进行估计;入样概率与目标变量的双重建模推断方面可以考虑将倾向得分模型与超总体模型加权平均,或者结合倾向得分模型与超总体模型的优势进行混合推断。最后,以基于广义Boosted模型的入样概率建模推断为例演示了具体的解决方法。</p>
                </div>
                <div class="p1">
                    <p id="138">以往建立倾向得分模型估计入样概率的研究局限于较少协变量或混杂变量的情况,当协变量或混杂变量增多如何降维选择变量估计倾向得分是关键;而对目标变量建立的超总体模型大多为参数模型,模型假定较多,如何验证超总体模型的假定以及构建假定相对较少的非参数和半参数超总体模型形成两条估计路径。当入样概率模型与目标变量模型假定检验困难或假定不符时,将入样概率建模与目标变量建模有机结合获得的总体估计应该更为稳健,那么如何将两者有机结合值得探讨。此外,无论是入样概率建模还是目标变量建模,在模型估计中使用调查权数的效果如何也值得进一步探索。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Web Panel Surveys-Can They be Designed and Used in a Scientifically Sound Way?">

                                <b>[1]</b>Svensson J.Web Panel Surveys-Can They be Designed and Used in a Scientifically Sound Way?[R].Hong Kong:International Association of Survey Statisticians,2013.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Propensity Score Adjustment as a Weighting Scheme for Volunteer Panel WebSurveys,&amp;quot;">

                                <b>[2]</b>Lee S.Propensity Score Adjustment as a Weighting Scheme for Volunteer Panel Web Surveys[J].Journal of Official Statistics,2006,22(2):329-349.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Estimating propensity adjustments for volunteer web surveys">

                                <b>[3]</b>Valliant R,Dever J A.Estimating Propensity Adjustments for Volunteer Web Surveys[J].Sociological Methods &amp; Research,2011,40(1):105-137.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Explorations in Non-probability Sampling Using the Web">

                                <b>[4]</b>Brick J M.Explorations in Non-probability Sampling Using the Web[C].Proceedings of Statistics Canada Symposium,2014.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJYJ201603002&amp;v=MjIzMDdmWnVab0Z5L21Xci9PTVNmU1pMRzRIOWZNckk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>金勇进,刘展.大数据背景下非概率抽样的统计推断问题[J].统计研究,2016(3):11-17.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201702001&amp;v=MTQwNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci9PTVNmSGVyRzRIOWJNclk5RlpZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>刘展,金勇进.网络访问固定样本调查的统计推断研究[J].统计与信息论坛,2017(2):3-10.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201504003&amp;v=MzE1MzZxQnRHRnJDVVI3cWZadVpvRnkvbVdyL09NU2ZIZXJHNEg5VE1xNDlGWjRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>牛成英,孙秋碧.基于倾向值加权的网络调查总体参数Horvitz-Thompson估计[J].统计与信息论坛,2015(4):15-20.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Theory and Practice in nonprobability surveys">

                                <b>[8]</b>Mercer A W,Kreuter F,Keeter S,et al.Theory and Practice in Non-probability Surveys[J].Public Opinion Quarterly,2017,81,special Issue:250-279.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14120603924782&amp;v=MjE4NTg0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybklKMTBkYWhRPU5pZlllcks4SDlQTXFZOUdiZWtMQzNRN29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Tibshirani R J.Regression Shrinkage and Selection Via the Lasso[J].Journal of the Royal Statistical Society,Ser.B,1996,58:267-288.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using LASSO to Calibrate Non-probability Samples Using Probability Samples">

                                <b>[10]</b>Chen K T.Using LASSO to Calibrate Non-probability Samples Using Probability Samples[D].Michigan:The University of Michigan,2016.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Finite Population Sampling and Inference:A Prediction Approach">

                                <b>[11]</b>Valliant R,Dorfman A H,Royall R M.Finite Population Sampling and Inference:A Prediction Approach[M].New York:John Wiley &amp; Sons,2000.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Introduction to Model-based Survey Sampling with Applications">

                                <b>[12]</b>Chambers R L,Clark R G.An Introduction to Model-based Survey Sampling with Applications[M].Oxford:Oxford University Press,2012.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Handbook of Statistics Sample Surveys:Inference and Analysis">

                                <b>[13]</b>Pfeffermann D,Rao C R.Handbook of Statistics Sample Surveys:Inference and Analysis[M].Oxford:Elsevier B.V.,Vol 29B,2009.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;#39;&amp;#39;Summary report of the AAPOR task force on non-probability sampling&amp;#39;&amp;#39;">

                                <b>[14]</b>Baker R,Brick J M,Bates N A,et al.Summary Report of the AAPOR Task Force on Non-probability Sampling[J].Journal of Survey Statistics and Methodology,2013,1(2):90-143.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Non-probability Survey Sampling in Official Statistics">

                                <b>[15]</b>Cooper D,Greenaway M.Non-probability Survey Sampling in Official Statistics[R].ONS Methodology Working Paper Series,No.4,2015.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Inference for Nonprobability Samples.&amp;quot;">

                                <b>[16]</b>Elliott M R,Valliant R.Inference for Non-probability Samples[J].Statistical Science,2017,32(2):249-264.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Structured Approach to Web Panel Surveys">

                                <b>[17]</b>Dayan Y.A Structured Approach to Web Panel Surveys[D].London:The London School of Economics,2014.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BLDX201602006&amp;v=MDcyMjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci9PSnlIUGRyRzRIOWZNclk5RllvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b>Stahl G,Saarela S,Schnell S,et al.Use of Models in Large-area Forest Surveys:Comparing Model-assisted,Model-based and Hybrid Estimation[J].Forest Ecosystems,2016,3(2):153-163.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800007006&amp;v=MTA0NzZhcks3SHRmT3A0OUZaT3NJREh3L29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJuSUoxMGRhaFE9TmpuQg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b>Bühlmann P,Yu B.Boosting with the L2 Loss:Regression and Classification[J].Journal of the American Statistical Association,2003(98):324-339.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Estimation for Volunteer Panel Web Surveys Using Propensity Score Adjustment and Calibration Adjustment">

                                <b>[20]</b>Lee S,Valliant R.Estimation for Volunteer Panel Web Surveys Using Propensity Score Adjustment and Calibration Adjustment[J].Sociological Methods &amp; Research,2009,37(3):319-343.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification and Regression Trees">

                                <b>[21]</b>Breiman L,Friedman J H,Olshen R A,et al.Classification and Regression Trees[M].Belmont,CA:Wadsworth International Group,1984.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Propensity score estimation with boosted regression for evaluating causal effects in observational studies">

                                <b>[22]</b>McCaffrey D F,Ridgeway G,Morral A R.Propensity Score Estimation with Boosted Regression for Evaluating Causal Effects in Observational Studies[J].Psychological Methods,2004,9(4):403-425.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14101300026855&amp;v=MzE0NThxUVRNbndaZVp0RmlubFVybklKMTBkYWhRPU5qN0Jhcks4SDlITnJJOUZaT2tKQkhrOG9CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b>Zhu Y Y,Ghosh D,Mitra N,et al.A Data-adaptive Strategy for Inverse Weighted Estimation of Causal Effects[J].Health Services and Outcomes Research Methodology,2014,14:69-91.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Model Assisted Survey Sampling">

                                <b>[24]</b>Särndal C E,Swensson B,Wretman J.Model Assisted Survey Sampling[M].New York:Springer-Verlag,1992.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="TJYJ201909008" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJYJ201909008&amp;v=MDM3NDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeS9tV3IvUE1TZlNaTEc0SDlqTXBvOUZiSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
