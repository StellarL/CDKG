<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140112947475000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dTJYJ201909007%26RESULT%3d1%26SIGN%3dgEikHtdBP3ToNHnX1fPq2gM7OZc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJYJ201909007&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJYJ201909007&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJYJ201909007&amp;v=MDExOTlQTVNmU1pMRzRIOWpNcG85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#64" data-title="一、引言 ">一、引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#70" data-title="二、BCT算法的理论背景与基本过程 ">二、BCT算法的理论背景与基本过程</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="(&lt;b&gt;一&lt;/b&gt;)BCT&lt;b&gt;算法的理论背景&lt;/b&gt;">(<b>一</b>)BCT<b>算法的理论背景</b></a></li>
                                                <li><a href="#77" data-title="(&lt;b&gt;二&lt;/b&gt;)BCT&lt;b&gt;算法的基本过程&lt;/b&gt;">(<b>二</b>)BCT<b>算法的基本过程</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="三、BCT算法的实际应用 ">三、BCT算法的实际应用</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#98" data-title="(&lt;b&gt;一)数据集介绍&lt;/b&gt;">(<b>一)数据集介绍</b></a></li>
                                                <li><a href="#101" data-title="(&lt;b&gt;二)实验设计&lt;/b&gt;">(<b>二)实验设计</b></a></li>
                                                <li><a href="#106" data-title="(&lt;b&gt;三)实验结果分析&lt;/b&gt;">(<b>三)实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#114" data-title="四、关于算法参数的进一步讨论 ">四、关于算法参数的进一步讨论</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#115" data-title="(&lt;b&gt;一)子分类器个数&lt;/b&gt;&lt;i&gt;N&lt;/i&gt;&lt;b&gt;对性能的影响&lt;/b&gt;">(<b>一)子分类器个数</b><i>N</i><b>对性能的影响</b></a></li>
                                                <li><a href="#123" data-title="(&lt;b&gt;二)分类阈值对性能的影响&lt;/b&gt;">(<b>二)分类阈值对性能的影响</b></a></li>
                                                <li><a href="#132" data-title="(&lt;b&gt;三)最大迭代次数对性能的影响&lt;/b&gt;">(<b>三)最大迭代次数对性能的影响</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#137" data-title="五、总结 ">五、总结</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#100" data-title="&lt;b&gt;表1 数据集概况&lt;/b&gt;"><b>表1 数据集概况</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;表2 不同拒绝比例下7种信用评分模型的平均AUC值&lt;/b&gt;"><b>表2 不同拒绝比例下7种信用评分模型的平均AUC值</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;图1 基于中国大陆数据集下子分类器个数
对AUC的影响&lt;/b&gt;"><b>图1 基于中国大陆数据集下子分类器个数
对AUC的影响</b></a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;图2 基于中国台湾数据集下子分类器个数
对AUC的影响&lt;/b&gt;"><b>图2 基于中国台湾数据集下子分类器个数
对AUC的影响</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;图3 基于中国大陆数据集下分类阈值对
AUC的影响&lt;/b&gt;"><b>图3 基于中国大陆数据集下分类阈值对
AUC的影响</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;图4 基于中国台湾数据集下分类阈值对
AUC的影响&lt;/b&gt;"><b>图4 基于中国台湾数据集下分类阈值对
AUC的影响</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;图5 基于中国大陆数据集下迭代次数对
AUC的影响&lt;/b&gt;"><b>图5 基于中国大陆数据集下迭代次数对
AUC的影响</b></a></li>
                                                <li><a href="#136" data-title="&lt;b&gt;图6 基于中国台湾数据集下迭代次数对
AUC的影响&lt;/b&gt;"><b>图6 基于中国台湾数据集下迭代次数对
AUC的影响</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="13">


                                    <a id="bibliography_1" title="Joanes D N.Reject Inference Applied to Logistic Regression for Credit Scoring [J].IMA Journal of Management Mathematics,1993 (1):35-43." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reject inference applied to logistic regression for credit scoring">
                                        <b>[1]</b>
                                        Joanes D N.Reject Inference Applied to Logistic Regression for Credit Scoring [J].IMA Journal of Management Mathematics,1993 (1):35-43.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_2" title="B&#252;cker M,van Kampen M,Kr&#228;mer W.Reject Inference in Consumer Credit Scoring with Nonignorable Missing Data [J].Journal of Banking and Finance,2013 (3):1040-1045." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100568938&amp;v=MDEwMDJadEZpbmxVcm5JSjEwZGFoVT1OaWZPZmJLN0h0RE9ybzlGWWUwSEJYOHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        B&#252;cker M,van Kampen M,Kr&#228;mer W.Reject Inference in Consumer Credit Scoring with Nonignorable Missing Data [J].Journal of Banking and Finance,2013 (3):1040-1045.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_3" title="Parnitzke T.Credit Scoring and the Sample Selection Bias [J].Working Paper,2005." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Credit Scoring and the Sample Selection Bias">
                                        <b>[3]</b>
                                        Parnitzke T.Credit Scoring and the Sample Selection Bias [J].Working Paper,2005.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_4" title="Kiefer N M,Larson C E.Specification and Informational Issues in Credit Scoring [Z].CAE Working Paper,2006." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Specification and Informational Issues in Credit Scoring">
                                        <b>[4]</b>
                                        Kiefer N M,Larson C E.Specification and Informational Issues in Credit Scoring [Z].CAE Working Paper,2006.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_5" title="Zeng G,Zhao Q.A Rule of Thumb for Reject Inference in Credit Scoring [J].Mathematical Finance Letters,2014,(2):1-13." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Rule of Thumb for Reject Inference in Credit Scoring">
                                        <b>[5]</b>
                                        Zeng G,Zhao Q.A Rule of Thumb for Reject Inference in Credit Scoring [J].Mathematical Finance Letters,2014,(2):1-13.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_6" title="Heckman J J.Sample Selection Bias as a Specification Error [J].Econometrica,1979 (1):153-161." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sample selection bias as a specification error">
                                        <b>[6]</b>
                                        Heckman J J.Sample Selection Bias as a Specification Error [J].Econometrica,1979 (1):153-161.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_7" title="Wu I D,Hand D J.Handling Selection Bias When Choosing Actions in Retail Credit Applications [J].European Journal of Operational Research,2007 (3):1560-1568." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100623312&amp;v=Mjc2NTBxUVRNbndaZVp0RmlubFVybklKMTBkYWhVPU5pZk9mYks3SHRET3JvOUZZdWtNRDMwN29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        Wu I D,Hand D J.Handling Selection Bias When Choosing Actions in Retail Credit Applications [J].European Journal of Operational Research,2007 (3):1560-1568.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_8" title="张景肖,魏秋萍,姜玉霞,等.基于两阶段思想处理拒绝推断的信用评分模型[J].数理统计与管理,2012 (6):1049-1060." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SLTJ201206015&amp;v=MTI4MTdCdEdGckNVUjdxZlp1Wm9GeS9tV3IvUE5pSGZaTEc0SDlQTXFZOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        张景肖,魏秋萍,姜玉霞,等.基于两阶段思想处理拒绝推断的信用评分模型[J].数理统计与管理,2012 (6):1049-1060.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_9" title="Chen G G,&#197;stebro T.Bound and Collapse Bayesian Reject Inference for Credit Scoring [J].Journal of the Operational Research Society,2012 (10):1374-1387." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD13101700119316&amp;v=MDU1ODM3SDlITnFJOUZaZW9HRDMwL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJuSUoxMGRhaFU9TmozYWFySw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Chen G G,&#197;stebro T.Bound and Collapse Bayesian Reject Inference for Credit Scoring [J].Journal of the Operational Research Society,2012 (10):1374-1387.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_10" title="Maldonado S,Paredes G.A Semi-Supervised Approach for Reject Inference in Credit Scoring Using SVMs[C].Industrial Conference on Data Mining.Berlin:Springer,2010:558-571." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Semi-supervised Approach for Reject Inference in Credit Scoring Using SVMs">
                                        <b>[10]</b>
                                        Maldonado S,Paredes G.A Semi-Supervised Approach for Reject Inference in Credit Scoring Using SVMs[C].Industrial Conference on Data Mining.Berlin:Springer,2010:558-571.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_11" title="Huang S C,Tang Y C,Lee C W,et al.Kernel Local Fisher Discriminant Analysis Based Manifold-Regularized SVM Model for Financial Distress Predictions [J].Expert Systems with Applications,2012 (3):3855-3861." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638227&amp;v=MzAyMTZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybklKMTBkYWhVPU5pZk9mYks3SHRETnFvOUVZdWdIRG40Kw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        Huang S C,Tang Y C,Lee C W,et al.Kernel Local Fisher Discriminant Analysis Based Manifold-Regularized SVM Model for Financial Distress Predictions [J].Expert Systems with Applications,2012 (3):3855-3861.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_12" title="Li Z,Tian Y,Li K,et al.Reject Inference in Credit Scoring Using Semi-Supervised Support Vector Machines [J].Expert Systems with Applications,2017(74):105-114." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEA24040D2463BF78E766FCA676E208DD&amp;v=Mjc1MDc9TmlmT2ZjYkpITlhNcTQ4eFp1OEpEdzVQeUI1bTdUbDdQZ3lUcWhVekRMQ1VUYzdyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDVodzd1MndLOA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Li Z,Tian Y,Li K,et al.Reject Inference in Credit Scoring Using Semi-Supervised Support Vector Machines [J].Expert Systems with Applications,2017(74):105-114.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_13" title="Blum A,Mitchell T.Combining Labeled and Unlabeled Data with Co-Training[C].Proceedings of Eleventh Annual Conference on Computational Learning Theory,1998:92-100." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Combining Labeled and Unlabeled Data with Co-Training">
                                        <b>[13]</b>
                                        Blum A,Mitchell T.Combining Labeled and Unlabeled Data with Co-Training[C].Proceedings of Eleventh Annual Conference on Computational Learning Theory,1998:92-100.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_14" title="Zhou Zhihua,Li Ming.Tri-training:Exploiting Unlabeled Data Using Three Classifiers [J].IEEE Transactions on Knowledge and Data Engineering,2005 (11):1529-1541." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tri-training: Exploiting unlabeled data using three classifiers">
                                        <b>[14]</b>
                                        Zhou Zhihua,Li Ming.Tri-training:Exploiting Unlabeled Data Using Three Classifiers [J].IEEE Transactions on Knowledge and Data Engineering,2005 (11):1529-1541.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_15" title="王娇,罗四维,曾宪华.基于随机子空间的半监督协同训练算法[J].电子学报,2008(12):60-65." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU2008S1010&amp;v=MjQ0NzlQSVRmVGU3RzRIdG12cm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        王娇,罗四维,曾宪华.基于随机子空间的半监督协同训练算法[J].电子学报,2008(12):60-65.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_16" title="肖进,薛书田,黄静,等.客户信用评估半监督协同训练模型研究[J].中国管理科学,2016 (6):124-131." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGK201606016&amp;v=MDA0NDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci9QUHlyTVpiRzRIOWZNcVk5RVlvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        肖进,薛书田,黄静,等.客户信用评估半监督协同训练模型研究[J].中国管理科学,2016 (6):124-131.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_17" title="Miller D J,Uyar H S.A Mixture of Experts Classifier with Learning Based on both Labelled and Unlabelled Data[C].Advances in Neural Information Processing Systems.1997:571-577." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A mixture of experts classifier with learning based on both labeled and unlabelled data">
                                        <b>[17]</b>
                                        Miller D J,Uyar H S.A Mixture of Experts Classifier with Learning Based on both Labelled and Unlabelled Data[C].Advances in Neural Information Processing Systems.1997:571-577.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_18" title="Blum A,Chawla S.Learning from Labeled and Unlabeled Data using Graph Mincuts [C].Proceedings of the Eighteenth International Conference on Machine Learning (ICML 2001).Morgan Kaufmann Publishers Inc.,2001." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning from Labeled and Unlabeled Data Using Graph Min-cuts">
                                        <b>[18]</b>
                                        Blum A,Chawla S.Learning from Labeled and Unlabeled Data using Graph Mincuts [C].Proceedings of the Eighteenth International Conference on Machine Learning (ICML 2001).Morgan Kaufmann Publishers Inc.,2001.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_19" title="Joachims T.Transductive Inference for Text Classification using Support Vector Macines[C].International Conference on Machine Learning (ICML),Morgan Kaufmann Publishers Inc.,1999:200-209." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Transductive inference for text classification using support vector machines">
                                        <b>[19]</b>
                                        Joachims T.Transductive Inference for Text Classification using Support Vector Macines[C].International Conference on Machine Learning (ICML),Morgan Kaufmann Publishers Inc.,1999:200-209.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_20" title="Louppe G,Geurts P.Ensembles on Random Patches[C].Joint European Conference on Machine Learning and Knowledge Discovery in Databases.Berlin:Springer,2012:346-361." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ensembles on Random Patches">
                                        <b>[20]</b>
                                        Louppe G,Geurts P.Ensembles on Random Patches[C].Joint European Conference on Machine Learning and Knowledge Discovery in Databases.Berlin:Springer,2012:346-361.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_21" title="周志华.机器学习[M].北京:清华大学出版社,2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=Mjc1NDhtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5qVTdqTEtWNFRYRnF6R2JDNEhOWE9ySTFOWStzUERCTTh6eFVT&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                        周志华.机器学习[M].北京:清华大学出版社,2016.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_22" title="Vinciotti V,Hand D J.Scorecard Construction with Unbalanced Class Sizes[J].Journal of the Iranian Statistical Society,2003 (2):189-205." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scorecard Construction with Unbalanced Class Sizes">
                                        <b>[22]</b>
                                        Vinciotti V,Hand D J.Scorecard Construction with Unbalanced Class Sizes[J].Journal of the Iranian Statistical Society,2003 (2):189-205.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_23" title="Prechelt L.Early Stopping-But When?[M].Neural Networks:Tricks of the trade.Springer,Berlin,Heidelberg,1998:53-67." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Early stopping But when">
                                        <b>[23]</b>
                                        Prechelt L.Early Stopping-But When?[M].Neural Networks:Tricks of the trade.Springer,Berlin,Heidelberg,1998:53-67.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_24" title="Nigam K,Ghani R.Analyzing the Effectiveness and Applicability of Co-Training[C].Proceedings of the Ninth International Conference on Information and Knowledge Management,2000:86-93." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analyzing the effectiveness and applicability of co-training">
                                        <b>[24]</b>
                                        Nigam K,Ghani R.Analyzing the Effectiveness and Applicability of Co-Training[C].Proceedings of the Ninth International Conference on Information and Knowledge Management,2000:86-93.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_25" title="Siddiqi N.Credit Risk Scorecards:Developing and Implementing Intelligent Credit Scoring [M].New York:John Wiley &amp;amp; Sons Inc.,2005." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Credit Risk Scorecards:Developing and Implementing Intelligent Credit Scoring">
                                        <b>[25]</b>
                                        Siddiqi N.Credit Risk Scorecards:Developing and Implementing Intelligent Credit Scoring [M].New York:John Wiley &amp;amp; Sons Inc.,2005.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=TJYJ" target="_blank">统计研究</a>
                2019,36(09),82-92 DOI:10.19343/j.cnki.11-1302/c.2019.09.007            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>信用评分模型中拒绝推断问题研究:基于半监督协同训练法的改进</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%8E%E6%98%A5&amp;code=09172145&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黎春</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E6%8C%AF%E5%AE%87&amp;code=41715852&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周振宇</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8D%97%E8%B4%A2%E7%BB%8F%E5%A4%A7%E5%AD%A6%E7%BB%9F%E8%AE%A1%E5%AD%A6%E9%99%A2%E3%80%81%E4%B8%AD%E5%9B%BD%E7%A4%BE%E4%BC%9A%E7%BB%8F%E6%B5%8E%E7%BB%9F%E8%AE%A1%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=0004819&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西南财经大学统计学院、中国社会经济统计研究中心</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E9%9B%86%E5%9B%A2%E5%95%86%E4%B8%9A%E6%99%BA%E8%83%BD%E9%83%A8&amp;code=0901782&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">阿里巴巴集团商业智能部</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着我国金融市场的蓬勃发展,信用评价中的拒绝推断问题越来越受到重视。针对信用评分模型中存在的有类别标签的样本占比低,并且样本中的类别分布不平衡等问题,本文在半监督学习技术与集成学习理论的基础上,提出了一种新的算法——BCT算法。该算法通过使用动态Bagging生成多个子分类器,引入分类阈值参数来解决样本类别分布不平衡问题,以及设定早停止条件来避免算法迭代过程中存在的过拟合风险,以此对传统半监督协同训练法进行改进。通过在5个真实数据集上的实证分析发现,在不同数据集与不同拒绝比例下,BCT算法的性能均优于其他6种有监督学习和半监督学习算法的信用评分模型,显示了BCT算法具有良好的模型泛化性能和更高的模型评价能力。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8B%92%E7%BB%9D%E6%8E%A8%E6%96%AD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">拒绝推断;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%A1%E7%94%A8%E8%AF%84%E5%88%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信用评分;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%8D%8F%E5%90%8C%E8%AE%AD%E7%BB%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">半监督协同训练;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BCT%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BCT算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    黎春,女,西南财经大学统计学院、中国社会经济统计研究中心副教授,光华英才学者。研究方向为金融统计、经济统计与公司金融交叉。;
                                </span>
                                <span>
                                    周振宇,男,阿里巴巴集团商业智能部数据分析师。研究方向为数据分析。;
                                </span>
                    </p>
                
                    <p>

                            <b>基金：</b>
                                                        <span>国家社会科学基金一般项目“货币政策对企业财务非对称性传导效应研究”(16BGL059);国家社会科学基金重大项目“大数据背景下我国新经济新动能统计监测与评价研究”(18DZA124);国家社会科学基金重大项目“中国各地HDI指数的编制和研究”(16ZDA010);</span>
                                <span>国家自然科学基金青年项目“中国上市公司财务指数编制的理论、模型及其应用”(71102180);</span>
                                <span>西南财经大学项目“新时期宏观经济实时监测创新团队”(JBK190507);西南财经大学项目“上市公司财务指数与宏观经济景气预测创新团队”(JBK190506)的资助;</span>
                    </p>
            </div>
                    <h1><b>Research on Reject Inference in Credit Scoring Model: Based on the Improvement of Semi-Supervised Co-Training Method</b></h1>
                    <h2>
                    <span>Li Chun</span>
                    <span>Zhou Zhenyu</span>
            </h2>
                                    <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the vigorous development of financial market in China, the problem of reject inference in credit evaluation has been getting more and more attention. Aiming at the problem of low proportion of accepted samples and unbalanced distribution of sample categories existing in credit evaluation, this paper proposes a new algorithm, namely BCT(Bagging Co-Training with Optimized Threshold) algorithm, based on the semi-supervised learning technology and multi-classifier integration theory. The algorithm improves the traditional semi-supervised co-training method by using dynamic Bagging, introducing classification threshold parameters and setting early stop conditions. Through the empirical analysis on five real data sets, the BCT algorithm outperforms the other six supervised learning and semi-supervised learning algorithms in credit scoring models under different data sets and different rejection ratios and proves better performance in extented modeling and modeling evaluation.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Reject%20Inference&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Reject Inference;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Credit%20Scoring&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Credit Scoring;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Semi-Supervised%20Co-Training%20Method&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Semi-Supervised Co-Training Method;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BCT%20Algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BCT Algorithm;</a>
                </p>
            </div>
        

        <!--brief start-->
                        <h3 id="64" name="64" class="anchor-tag">一、引言</h3>
                <div class="p1">
                    <p id="65">在传统信用评价实践中,信用评分模型通常建立在曾经被授信的客户样本之上,被拒绝授予贷款的客户,由于缺乏贷后还款信息而被作为“拒绝样本”,无法应用于建模。然而,信用评分模型的对象应包括未来所有可能会申请贷款的客户,经过筛选后得到的接受样本显然无法代表模型应用的总体,由此引出拒绝推断问题,即由于人为选择导致因变量的部分观测值非随机缺失。为了更有效地建立信用评分模型,需要同时考虑接受样本和拒绝样本,进行拒绝推断。由于接受样本和拒绝样本的违约概率分布有着显著差异,在有偏的样本基础上建立的信用评分模型在应用过程中缺乏准确性和稳定性,会导致错误的结果(<citation id="142" type="reference"><link href="13" rel="bibliography" />Joanes,1993</citation>)<citation id="141" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。随着互联网金融的蓬勃发展,金融企业面临的客户群体越趋广泛与复杂,信用评分模型中的拒绝推断问题也越来越受到重视,即如何推断拒绝样本的好与坏属性,并将拒绝样本加入到建模样本中来,从而得到预测效果更优的信用评分模型。</p>
                </div>
                <div class="p1">
                    <p id="66">自20世纪70年代起,学术界开始基于传统的统计方法,以纠正模型训练样本和模型应用总体的分布偏差为主要目的,主要从三个方面对拒绝推断问题进行研究。第一类是调整权重法,以通过对拒绝样本赋予一定的权重来重构样本的分布(Bücker等,2013<citation id="143" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>;<citation id="153" type="reference"><link href="17" rel="bibliography" />Parnitzke,2005</citation><citation id="144" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>)。第二类是外推法,首先在接受样本基础上建立模型,再基于该模型判断拒绝样本信用状况,最后将拒接样本纳入建模样本来重新估计模型(<citation id="154" type="reference"><link href="19" rel="bibliography" />Kiefer和Larson,2006</citation><citation id="145" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>;<citation id="155" type="reference"><link href="21" rel="bibliography" />Zeng和Zhao,2014</citation><citation id="146" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>)。第三类是基于Heckman的两阶段模型法来处理由非随机选择带来的样本偏差问题(<citation id="156" type="reference"><link href="23" rel="bibliography" />Heckman,1979</citation><citation id="147" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>;<citation id="157" type="reference"><link href="25" rel="bibliography" />Wu和Hand,2007</citation><citation id="148" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>;<citation id="158" type="reference"><link href="27" rel="bibliography" />张景肖等,2012</citation><citation id="149" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>)。运用统计方法解决拒绝推断问题,目前已有了较多成果,但是学术界对这些方法的有效性仍然没有达成共识,对模型结果的稳定性和可靠性还存在着质疑(Parnitske,2005<citation id="150" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>;<citation id="159" type="reference"><link href="25" rel="bibliography" />Wu和Hand,2007</citation><citation id="151" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>;<citation id="160" type="reference"><link href="29" rel="bibliography" />Chen和Astebro,2012</citation><citation id="152" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>)。</p>
                </div>
                <div class="p1">
                    <p id="67">近几年随着机器学习的发展,学术界和信贷行业开始使用机器学习算法开发信用评分模型,特别是半监督学习(Semi-supervised Learning)理论得到广泛应用。该理论是指结合少量有标记样本和大量无标记样本来训练模型,利用无标记样本提升模型性能的方式。<citation id="164" type="reference"><link href="31" rel="bibliography" />Maldonado和Paredes(2010)</citation><citation id="161" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>使用Platt连接函数改进了支持向量机(SVM)模型,并基于半监督学习中自学习方法来预测被拒绝客户的违约概率,实证结果显示该方法的分类效果超过了直推式SVM和其他拒绝推断方法。<citation id="165" type="reference"><link href="33" rel="bibliography" />Huang等(2012)</citation><citation id="162" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>使用半监督SVM模型,通过结合有标记样本和无标记样本来预测金融危机的发生概率,发现机器学习方法在处理高维度和非线性分布的数据时表现出了超越传统统计方法的性能优势。<citation id="166" type="reference"><link href="35" rel="bibliography" />Li等(2017)</citation><citation id="163" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出一种半监督SVM模型来推断拒绝样本的好与坏属性,并将其应用于大型的真实数据集进行实证分析,在此基础上,将修改后的核函数应用于半监督SVM模型的迭代过程,实证结果表明,该方法能够显著提升模型的性能。</p>
                </div>
                <div class="p1">
                    <p id="68">以上的研究文献都是基于半监督SVM算法的单一分类模型来处理拒绝推断问题,由于信用评价中的接受样本和拒绝样本类别分布并不均衡,单一分类模型对拒绝样本标注的准确率往往有限。因此,有学者(<citation id="171" type="reference"><link href="37" rel="bibliography" />Blum和Mitchell,1998</citation><citation id="167" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>;<citation id="172" type="reference"><link href="39" rel="bibliography" />Zhou和Li,2005</citation><citation id="168" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>;<citation id="173" type="reference"><link href="41" rel="bibliography" />王娇等,2008</citation><citation id="169" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>;<citation id="174" type="reference"><link href="43" rel="bibliography" />肖进等,2016</citation><citation id="170" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>)将半监督技术与集成学习相结合,结合二者的优势来解决信用评分模型的拒绝推断问题:一方面利用集成学习对多个分类器进行集成,有效提升了模型在拒绝样本上的标注准确率;另一方面还可以根据业务需要选择不同的机器学习算法作为基模型,使算法在实践中更加易于使用。但是此类研究文献数量有限,并且都没有考虑接受样本与拒绝样本分布的不均衡性,因而模型结果并不令人满意。</p>
                </div>
                <div class="p1">
                    <p id="69">综上所述,学术界对于拒绝推断的研究大量集中于传统的统计方法,但传统统计方法对于拒绝推断缺乏显著的效果。近年来,机器学习和半监督学习理论开始被应用于信用评分模型中的拒绝推断问题,尽管研究文献数量有限,但模型结果表现出了一定的优良性。在现有的基于半监督理论的拒绝推断研究中,大部分采用单一分类模型,同时由于将基模型限制为SVM,也有着灵活性不足、应用场景有限等问题。有部分文献考虑将半监督理论与集成学习相结合,虽然弥补了单一分类模型的不足,但是也存在一些明显的缺陷。因此,有必要结合信用评价的拒绝推断问题的具体特性,对半监督学习进行因地制宜的改进。基于此,本文在半监督学习和集成学习的理论基础上提出了一种新的算法——Bagging Co-Training with Optimized Threshold算法,简称BCT算法。该算法通过使用动态Bagging,引入分类阈值参数和设定早停止条件3个步骤,利用半监督学习来挖掘拒绝样本中蕴含的信息,通过集成学习来提高算法标记拒绝样本时的准确率,从而提升模型处理拒绝推断问题的准确性。</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag">二、BCT算法的理论背景与基本过程</h3>
                <h4 class="anchor-tag" id="71" name="71">(<b>一</b>)BCT<b>算法的理论背景</b></h4>
                <div class="p1">
                    <p id="72">本文设计的BCT算法,基本思想是通过引入集成学习理论,对半监督学习下的信用评分模型进行改进,来解决“如何提升对拒绝样本的标注准确率,从而得到性能更优的信用评分模型”这一问题。</p>
                </div>
                <div class="p1">
                    <p id="73">典型的半监督学习算法包括三类:第一类是将无标记样本的标记视为生成式模型的缺失参数,通过EM算法进行极大似然估计求解模型缺失参数的生成式方法(<citation id="178" type="reference"><link href="45" rel="bibliography" />Miller和Uyar, 1997</citation>)<citation id="175" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>;第二类是将数据集映射为一个图,基于样本之间的相似度来给无标记样本打标记的图半监督学习(<citation id="179" type="reference"><link href="47" rel="bibliography" />Blum和Chawla, 2001</citation>)<citation id="176" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>;第三类是将支持向量机应用于半监督学习的方法(<citation id="180" type="reference"><link href="49" rel="bibliography" />Joachims, 1999</citation>)<citation id="177" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。上述的三类方法都是基于单一分类器的半监督学习方法。在拒绝推断问题中,基于接受样本上建立的单一分类器,对拒绝样本进行分类的准确率往往很低。</p>
                </div>
                <div class="p1">
                    <p id="74"><citation id="183" type="reference"><link href="37" rel="bibliography" />Blum和Mitchell(1998)</citation><citation id="181" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了协同训练,则是一种基于多个子分类器的半监督学习方法,通过多个子分类器的集成来提高对无标记数据的标记准确率。协同训练的运用前提是数据集至少拥有2个充分且条件独立的特征子集,即这2个特征子集都包含足以产生最优分类器的信息,且在给定类别标记的条件下互相独立。在此基础上,协同训练可以利用无标记样本显著提升分类器的性能。然而,现实问题中这一前提很难被满足,因而逐渐发展出了其他协同训练的变体算法,如Zhou和Li(2007)<citation id="182" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出的Co-Forest算法,其核心思想是使用某种策略来生成多个差异显著的子分类器,通过对这些子分类器进行集成,来对无标记样本进行标记,从而将其加入到模型的训练样本中。</p>
                </div>
                <div class="p1">
                    <p id="75">然而,信用评分模型的拒绝推断问题,具有接受样本占比低、样本类别比例不平衡等特性,以上的半监督协同训练模型均没有考虑样本类别分布的不均衡性。<citation id="185" type="reference"><link href="43" rel="bibliography" />肖进等(2016)</citation><citation id="184" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>在此基础上,将半监督协同训练与随机子空间相结合,提出了一种新的半监督协同训练模型来处理类别不平衡情况下的拒绝推断问题。但是该模型采用重抽样技术来处理样本类别分布不平衡的问题,没有考虑到接受样本和拒绝样本的分布差异,而是假设接受样本和拒绝样本的分布是一致的,这也与实际特征不符,在实际的信贷风控中拒绝样本中坏样本的比例通常显著高于接受样本。</p>
                </div>
                <div class="p1">
                    <p id="76">综上所述,半监督学习算法需要与集成学习理论相结合,通过将多个子分类器结合起来完成学习任务,才能显著地提升单一模型的预测能力和泛化能力。同时,还需要考虑样本类别分布的不均衡问题对模型估计的影响。因此,本文提出的BCT算法包括3个阶段,分别是:①采用动态Bagging集成方法来生成多个子分类器,以此提高半监督学习过程中对无标记样本的标记准确率;②通过分类阈值参数的引入,来解决样本类别分布不平衡问题;③设定早停止条件,来避免算法迭代过程中存在的过拟合风险。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77">(<b>二</b>)BCT<b>算法的基本过程</b></h4>
                <div class="p1">
                    <p id="78">设<i>D</i><sub><i>l</i></sub>={(<i>x</i><sub>1</sub>,<i>y</i><sub>1</sub>),…,(<i>x</i><sub><i>l</i></sub>,<i>y</i><sub><i>l</i></sub>)}为拒绝推断问题中的接受样本,<i>D</i><sub><i>u</i></sub>={<i>x</i><sub><i>l</i></sub><sub>+1</sub>,…,<i>x</i><sub><i>l</i></sub><sub>+</sub><sub><i>u</i></sub>}为拒绝样本,<i>D</i><sub><i>t</i></sub>={<i>x</i><sub><i>l</i></sub><sub>+</sub><sub><i>u</i></sub><sub>+1</sub>,…,<i>x</i><sub><i>l</i></sub><sub>+</sub><sub><i>u</i></sub><sub>+</sub><sub><i>t</i></sub>}为测试集。BCT算法的建模过程如下:</p>
                </div>
                <div class="p1">
                    <p id="79">步骤1:使用Random Patches(<citation id="187" type="reference"><link href="51" rel="bibliography" />Louppe和Geurts, 2012</citation>)<citation id="186" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>方法,对<i>D</i><sub><i>l</i></sub>在样本上进行有放回地重抽样,在特征上无放回地随机抽取<i>f</i>维的子特征,得到训练子集<i>D</i><sub><i>l</i></sub><sub>,</sub><sub><i>j</i></sub>,在这个训练子集上用基模型训练子分类器<i>h</i><sub><i>j</i></sub>。将这一抽样后训练子分类器的过程重复<i>N</i>次,得到<i>N</i>个有差异的子分类器。</p>
                </div>
                <div class="p1">
                    <p id="80">步骤2:使用<i>N</i>个子分类器分别对<i>D</i><sub><i>u</i></sub>中的所有样本输出预测概率值,根据分类阈值λ确定类别。对<i>D</i><sub><i>u</i></sub>中的每个样本<i>x</i><sub><i>u</i></sub>,考察子分类器做出的多数一致分类<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>⌢</mo></mover><msub><mrow></mrow><mrow><mi>x</mi><msub><mrow></mrow><mi>u</mi></msub></mrow></msub></mrow></math></mathml>,计算做出该分类结果的子分类器在全部子分类器中的占比。当这一占比超过置信阈值θ,则对该拒绝样本打上多数一致的分类标记后从<i>D</i><sub><i>u</i></sub>转移至<i>D</i><sub><i>l</i></sub>中,并测量此时算法在交叉验证或测试集上的性能。</p>
                </div>
                <div class="p1">
                    <p id="81">步骤3:反复迭代步骤1～2,直至算法的性能在<i>S</i>轮迭代中没有提升,或者迭代次数达到<i>T</i>次。</p>
                </div>
                <div class="p1">
                    <p id="82">BCT算法即是在以上三个步骤中,通过使用动态Bagging生成多个子分类器,引入分类阈值参数划分样本类别,以及设定早停止条件来确定迭代次数,以此完成对算法的改进,具体思路如下。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83">1.动态Bagging的使用。</h4>
                <div class="p1">
                    <p id="84">Bagging是并行式集成学习方法中的代表,其基本做法是基于自助采样法得到<i>N</i>个独立的训练子集,在训练子集上建立<i>N</i>个独立的子学习器,再将这些子学习器进行结合。可以证明随着集成中子分类器个数的增加,集成后模型的预测错误率呈指数级下降。所以,Bagging思想的引入会有效的提升BCT模型对拒绝样本的标注准确率。</p>
                </div>
                <div class="p1">
                    <p id="85">Bagging算法过程中,子分类器的生成机制是决定效果的一个关键因素。要得到泛化能力强的集成,子学习器应尽可能的相互独立。本文采用Random Patches的方法,对样本进行有放回的重抽样的同时,在特征上无放回的随机抽取<i>f</i>维的特征,使得每个训练样本子集之间的差异性尽可能的大,以保证每个子分类器都有尽可能大的差异,从而发挥出集成学习的效果。</p>
                </div>
                <div class="p1">
                    <p id="86">对于子分类器的集成,分类问题通常采用投票法的结合策略。Bagging投票法的选择,主要有相对多数投票法、绝对多数投票法和加权投票法。相对多数投票法是用<i>N</i>个子分类器对样本进行分类,并以样本被打标记中数量最多的那一类为最终分类结果。绝对多数投票法是当<i>N</i>个子分类器中,做出第<i>j</i>类分类的子分类器占比超过置信度阈值<i>θ</i>时,才对样本进行标记。加权投票法需要对业务足够熟悉才能为每个子分类器的预测结果设定合适的权重。在拒绝推断问题中,需要尽可能地提高对拒绝样本的标记准确率,因此本文选择采用绝对多数投票法,以保证样本标记的置信度。</p>
                </div>
                <div class="p1">
                    <p id="87">对于Bagging的时机,可以有2种选择:一是静态Bagging,在算法开始迭代之前,采用Random Patches的方法一次性生成多个子分类器;二是动态Bagging,即在算法的每一次迭代过程中,都采用Random Patches的方法重新生成子分类器。考虑到在全部特征中,有效的特征可能非常稀疏,静态Bagging在迭代开始之前一次性生成特征子空间,很多子分类器有较大可能被分配到了大量的无效特征,将导致算法难以充分发挥集成学习的优势,降低了迭代过程中的标注准确率。而动态Bagging在每一次迭代过程中都会重新生成特征子空间,增加了子分类器生成过程中的随机性,强化了子分类器的多样性,同时也防止部分子分类器由于一次Bagging的失败而导致预测效果一直很差。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88">2.分类阈值参数的引入。</h4>
                <div class="p1">
                    <p id="89">通常而言,统计方法和机器学习算法均要求训练集和测试集由同一个数据生成机制生成,即服从于同一个分布,在此条件下,分类阈值设定为0.5可以使模型的预测效果最优。然而,拒绝推断问题中的训练集并不是真实总体的无偏抽样,且信用评分模型的样本又是类别比例极度不平衡的数据,一般而言,坏样本占比5%～10%,这种情况下必然会导致模型性能较差。</p>
                </div>
                <div class="p1">
                    <p id="90">一个比较简单且有效的解决方法是,基于原始的不平衡数据集训练模型,但是在使用模型输出的预测值进行分类时对阈值进行移动,让移动后的阈值来适应预测值和真实几率(<citation id="190" type="reference"><link href="53" rel="bibliography" />周志华, 2016</citation>)<citation id="188" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>。在接受样本上训练多个子分类器并对拒绝样本进行预测时,当某个子分类器对样本的预测值高于分类阈值时,就将这个子分类器对该样本的分类结果判定为正例,即坏样本。这种调整分类阈值的方法,是提升类别不平衡数据集预测准确率的最直接有效的方法(<citation id="191" type="reference"><link href="55" rel="bibliography" />Vinciotti和Hand, 2003</citation>)<citation id="189" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="91">基于上述分析,BCT算法中引入分类阈值参数<i>λ</i>。具体思路是,用动态Bagging生成的<i>N</i>个子分类器分别对<i>D</i><sub><i>u</i></sub>中所有的拒绝样本预测违约概率值,如果某一子分类器输出的违约概率大于分类阈值<i>λ</i>,则记录该子分类器对该样本的分类结果为坏样本,反之为好样本。对<i>D</i><sub><i>u</i></sub>中的每个样本<i>x</i><sub><i>u</i></sub>,分别计算做出好、坏样本分类的子分类器个数,和在全部<i>N</i>个子分类器中的占比。如果做出一致分类的子分类器占比超过了事先设定的置信阈值<i>θ</i>,那么可认为子分类器集成对该样本做出的分类是可信的,因此对该样本打上多数一致的分类标记后,将其从<i>D</i><sub><i>u</i></sub>转移至<i>D</i><sub><i>l</i></sub>中。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92">3.早停止条件的设置。</h4>
                <div class="p1">
                    <p id="93">模型的过拟合也是制约模型效果的重要因素。半监督学习首先要在接受样本上建立一个初始模型,再通过某种标记策略给拒绝样本打上标记,最后利用打上了标记的拒绝样本对原来的模型进行优化。由于接受样本、拒绝样本和总体的分布均不一致,在有样本偏差问题的接受样本上建立的初始模型本身就带有缺陷。用这样的初始模型给拒绝样本进行标记时会产生错误,并在算法反复迭代的过程中不断累积错误,导致模型在接受样本上逐渐过拟合。在迭代之初,模型的性能会得到提升,但是如果任由迭代进行下去,不断累积的标记错误可能反而会降低模型的性能。</p>
                </div>
                <div class="p1">
                    <p id="94">降低模型过拟合程度的一个有效方法是为模型设置早停止条件(<citation id="193" type="reference"><link href="57" rel="bibliography" />Prechelt, 1998</citation>)<citation id="192" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>,使模型对训练样本过拟合之前主动终止迭代的过程。具体的思路是在每次迭代后,都对模型在训练集上进行交叉验证或者在测试集上进行验证,测试模型在当前轮次下的性能。当模型在第<i>S</i>次迭代中性能都没有提升,就主动停止算法的迭代过程。</p>
                </div>
                <div class="p1">
                    <p id="95">综上所述,BCT算法通过使用动态Bagging、引入分类阈值参数和设置早停止条件,实现了对半监督协同训练法在拒绝推断问题应用的改进<citation id="200" type="note"><link href="3" rel="footnote" /><sup>(1)</sup></citation>。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag">三、BCT算法的实际应用</h3>
                <div class="p1">
                    <p id="97">为了验证本研究提出的BCT算法的性能,本文基于5个真实的信贷数据集,选择了两类共6种信用评分模型,与BCT算法的性能在不同的拒绝比例下进行综合对比。对比的6种信用评分模型分别是:第一类是作为对比基准的4种有监督学习算法模型,包括Logistic回归(LR)、决策树(DT)、随机森林(RF)、梯度提升树(GBM);第二类是2种半监督学习算法模型,包括协同训练算法(Co-training)和自学习算法(Self-training)。</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98">(<b>一)数据集介绍</b></h4>
                <div class="p1">
                    <p id="99">实验所使用的数据集来源于德国、澳大利亚、中国台湾、中国大陆和美国的真实借贷数据。前3个数据集来自UCI机器学习数据库,后2个数据集分别来自中国大陆和美国的竞赛网站。表1记录了这5个数据集的情况,包括样本量、特征数、类别个数和坏样本占比。这5个数据集中,样本量最多的有12万个样本,最少的仅有690个,特征数为10到24不等。特征变量中包含了客户的性别、年龄、婚姻、工作年限、收入等基础信息,以及贷记卡、信用卡账户的余额、支付、借款、逾期等交易信息和信用记录。数据集中的类别型变量都被编码为数值型变量,使数据集可以适用于各类机器学习算法。数据集中的全部样本被划分为逾期的坏样本和未逾期的好样本,5个数据集都属于坏样本占比低的类别不平衡数据集。</p>
                </div>
                <div class="area_img" id="100">
                    <p class="img_tit"><b>表1 数据集概况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="100" border="1"><tr><td><br />数据集</td><td>样本量</td><td>特征数</td><td>类别个数</td><td>坏样本占比</td></tr><tr><td><br />澳大利亚</td><td>690</td><td>14</td><td>2</td><td>44%</td></tr><tr><td><br />德国</td><td>1000</td><td>24</td><td>2</td><td>30%</td></tr><tr><td><br />中国台湾</td><td>30000</td><td>24</td><td>2</td><td>22%</td></tr><tr><td><br />中国大陆</td><td>15000</td><td>20</td><td>2</td><td>10%</td></tr><tr><td><br />美国</td><td>120000</td><td>10</td><td>2</td><td>7%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="101" name="101">(<b>二)实验设计</b></h4>
                <div class="p1">
                    <p id="102">首先,将5个数据集随机划分为三个子集:测试集<i>T</i>、有标记训练集<i>L</i>和无标记训练集<i>U</i>,其中有标记训练集<i>L</i>代表信贷审批实践中的接受样本,无标记训练集<i>U</i>代表拒绝样本。为了模拟信贷审批的真实情况,本文按以下方式对数据集进行划分:第一,按类别标记分层随机抽取20%的样本作为测试集<i>Test</i>,剩余80%样本作为训练集<i>Train</i>,从而保证<i>Test</i>和<i>Train</i>中好坏样本比例一致;第二,为了模拟拒绝推断问题中拒绝样本和接受样本的产生机制,在训练集上用Logistic回归模型建立信用评分模型,并对训练集上的所有样本预测违约的概率,分别取违约概率最高的前80%、60%、40%、20%样本作为拒绝样本(无标记训练集<i>U</i>),其余样本作为接受样本(有标记训练集<i>L</i>)。在4种不同的拒绝比例下,拒绝样本中的坏样本占比大约是接受样本的3～6倍。</p>
                </div>
                <div class="p1">
                    <p id="103">其次,作为对比的基准,在接受样本<i>L</i>上训练Logistic回归、决策树、随机森林和梯度提升树4种有监督学习算法,以其能够达到的最高预测精度作为参照,计算BCT算法通过利用拒绝样本<i>U</i>,对预测精度的提升程度。更进一步地,在补充了真实标记信息的拒绝样本<i>U</i>和接受样本<i>L</i>上(即拒绝比例为0%)训练有监督学习算法,并与BCT算法性能进行比较。</p>
                </div>
                <div class="p1">
                    <p id="104">同时,在接受样本<i>L</i>和拒绝样本<i>U</i>上训练另外2种常见的半监督学习算法Co-training和Self-training,以对比考察BCT算法的性能。通常而言,Co-training要求数据集可以被划分为2个特征子集,并且每个特征子集都必须包含预测样本标记的充分、冗余信息。然而根据<citation id="195" type="reference"><link href="59" rel="bibliography" />Nigam和Ghani(2000)</citation><citation id="194" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>的证明,将全部特征随机划分为2个不重叠的子集,在大部分情况下也可以满足Co-training算法的要求。因而在本次实验中,每个数据集中的特征都会被划分为2个同样维度的集合,供Co-training算法在<i>L</i>和<i>U</i>上训练模型。Self-training在有标记样本上学习模型,并对无标记样本进行预测,选择预测置信度最高的样本,连同预测标记放回有标记样本中。通过不断重复上述过程,从而达到利用无标记数据的目的。本文选择分类预测精度最高的GBM模型作为Co-training、Self-training和BCT算法的基模型,且基模型的参数保持一致。为了保证比较的客观性,4种有监督学习算法和3种半监督学习算法在不同的数据集上都会进行参数调优,以保证所有算法在测试集上达到最高的分类预测性能。</p>
                </div>
                <div class="p1">
                    <p id="105">最后,对以上7种算法,以其在各数据集上的AUC值来衡量模型性能。为了降低单次实验带来的偶然性,在不同的数据集和不同的拒绝比例下,实验都将重复20次,并对每次实验得到的模型AUC值进行平均,以综合评估模型的性能。</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106">(<b>三)实验结果分析</b></h4>
                <div class="p1">
                    <p id="107">表2记录了在不同拒绝比例下,7种信用评分模型分别对5个数据集的平均AUC值<citation id="201" type="note"><link href="5" rel="footnote" /><sup>(2)</sup></citation>。</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表2 不同拒绝比例下7种信用评分模型的平均AUC值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td><br />拒绝比例</td><td>LR</td><td>DT</td><td>RF</td><td>GBM</td><td>Self-training</td><td>Co-training</td><td>BCT</td></tr><tr><td><br />80%</td><td>0.545</td><td>0.545</td><td>0.629</td><td>0.656</td><td>0.583</td><td>0.603</td><td>0.754</td></tr><tr><td><br />60%</td><td>0.592</td><td>0.597</td><td>0.683</td><td>0.723</td><td>0.659</td><td>0.647</td><td>0.794</td></tr><tr><td><br />40%</td><td>0.712</td><td>0.608</td><td>0.713</td><td>0.750</td><td>0.725</td><td>0.732</td><td>0.802</td></tr><tr><td><br />20%</td><td>0.749</td><td>0.625</td><td>0.737</td><td>0.781</td><td>0.771</td><td>0.772</td><td>0.808</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="109">通过对详细实验结果的分析,可以得到如下结论:</p>
                </div>
                <div class="p1">
                    <p id="110">(1)在所有的数据集和拒绝比例下,BCT算法都取得了最高的AUC值,显示出BCT算法模型的良好性能。在仅使用接受样本的情况下,BCT算法的初始AUC值在绝大多数数据集和拒绝比例下,超过了4种有监督学习算法模型的性能。这是因为BCT算法以性能最优的GBM为基模型,且算法内部利用Bagging的方法对多个GBM进行了集成,从而能够得到比单个GBM模型更优的预测效果。在拒绝比例为20%的情况下,BCT算法的预测结果甚至优于拒绝比例为0%时基准模型的预测结果。在更高的拒绝比例下,BCT算法在某些数据集上的性能也超过了拒绝比例为0%时基准模型的性能。</p>
                </div>
                <div class="p1">
                    <p id="111">(2)与另外2种半监督学习算法模型相比,通过对拒绝样本的利用, BCT算法的AUC值较初始模型的提升比例最高,并且随着拒绝比例的提高,算法性能的提升更加明显:从20%拒绝比例下AUC提升3.5%,增加到80%拒绝比例下AUC提升8.3%。这一结果说明BCT算法可以有效地识别出拒绝样本中的坏样本,并将其补充进接受样本中,在Bagging的基础上进一步提升了模型的性能,并且在拒绝比例越高、接受样本和拒绝样本坏样本占比倍数越大,接受样本和测试集样本分布差距越大的情况下,BCT算法的性能提升幅度越大。</p>
                </div>
                <div class="p1">
                    <p id="112">(3)结果显示,Co-training和Self-training对拒绝样本的利用反而降低了模型的性能,在全部数据集和拒绝比例下,Co-training和Self-training的AUC值分别下降了2.6%和5.8%。Self-training的迭代过程中只有一个分类器,这个分类器在迭代之初就建立在与测试集分布偏差极大的接受样本上,后续的自学习过程会导致模型的偏差不断累积,性能快速下降。Co-training性能下降的主要原因在于,数据集中缺乏包含了预测标记充分、冗余信息的特征子集,在这样的特征子集上分别训练的2个子分类器,性能往往较差,在迭代过程中会对拒绝样本做出同样的错误预测,向训练样本中加入标记错误的拒绝样本,从而降低了模型的性能。</p>
                </div>
                <div class="p1">
                    <p id="113">综上所述,BCT算法较其他算法模型,能够更加充分地利用拒绝样本,并且在不同的数据集和拒绝比例上都有着超出其他有监督学习和半监督学习算法的性能,具备了较好的模型泛化性能和良好的信用评价能力。</p>
                </div>
                <h3 id="114" name="114" class="anchor-tag">四、关于算法参数的进一步讨论</h3>
                <h4 class="anchor-tag" id="115" name="115">(<b>一)子分类器个数</b><i>N</i><b>对性能的影响</b></h4>
                <div class="p1">
                    <p id="116">不同的子分类器个数<i>N</i>,会影响BCT算法发挥集成学习作用时子分类器的多样性,进而影响模型对拒绝样本打标记的准确度,从而在很大程度上影响了模型最终的性能。因而,有必要进一步研究子分类器个数<i>N</i>(<i>N</i>=3,…,10,20,50,100)在不同取值下,BCT算法的性能变化情况。图1和图2展示了就中国大陆和中国台湾数据集上,不同子分类器个数下得到BCT算法相对于初始GBM模型的AUC值的提升比例<citation id="202" type="note"><link href="7" rel="footnote" /><sup>(3)</sup></citation>。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJYJ201909007_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于中国大陆数据集下子分类器个数
对AUC的影响" src="Detail/GetImg?filename=images/TJYJ201909007_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 基于中国大陆数据集下子分类器个数
对AUC的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJYJ201909007_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJYJ201909007_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于中国台湾数据集下子分类器个数
对AUC的影响" src="Detail/GetImg?filename=images/TJYJ201909007_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 基于中国台湾数据集下子分类器个数
对AUC的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJYJ201909007_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="119">通过对所有数据集结果的分析,可以得到以下结论:</p>
                </div>
                <div class="p1">
                    <p id="120">(1)当<i>N</i>的取值为6～10时,BCT的AUC提升比例相对较高。例如,当拒绝比例为60%时,BCT在5个数据集上取得最高AUC提升比例时,参数<i>N</i>取值分别为6、10、9、6、10。</p>
                </div>
                <div class="p1">
                    <p id="121">(2)当<i>N</i>的取值过小时,由于子分类器的个数太少,难以发挥集成学习的优势,AUC提升比例相对较小,甚至会导致BCT算法的效果差于GBM模型。例如,在德国数据集上,当拒绝比例为40%且N的取值为3～6时,AUC的提升比例为负。</p>
                </div>
                <div class="p1">
                    <p id="122">(3)当<i>N</i>的取值超过10(<i>N</i>=20,50,100)时, 由于子分类器个数过多,会成倍地延长模型训练的时间。并且由于数据集的特征数有限,子分类器抽取到相同特征的几率变大,会有大量的子分类器抽取到同样的特征,从而降低了集成学习的多样性。这些抽取到同样特征的子分类器,可能会对拒绝样本做出同样的错误分类,从而导致算法引入了大量错误标记的拒绝样本,降低了模型的最终性能。因此,过多的子分类器,不但不会增加BCT算法的AUC提升比例,甚至会降低模型的性能,并延长模型的训练时间。因此,在最终设计BCT算法时,本文将子分类器个数<i>N</i>的默认值设置为10,在该默认值下,算法往往能够取得较好的效果。在使用算法进行拒绝推断时,可以在该默认值的附近,通过交叉验证等方式进行参数调优。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123">(<b>二)分类阈值对性能的影响</b></h4>
                <div class="p1">
                    <p id="124">在信贷审批实践中,接受样本中的坏样本占比往往低于10%,而拒绝样本中的坏样本占比通常为接受样本的2～4倍(<citation id="197" type="reference"><link href="61" rel="bibliography" />Siddiqi,2005</citation>)<citation id="196" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。由于无法获知拒绝样本和样本总体中坏样本的真实几率,所以既不能基于真实几率对模型输出的预测值进行调整,也无法确切地计算出应该将分类阈值设置为多少。在实践中,往往通过交叉验证或者在测试集上进行验证的方式,来对分类阈值λ进行参数调整。下面通过实验的方式,来观察不同的分类阈值<i>λ</i>(<i>λ</i>=0,0.05,0.1,…,1)对BCT算法性能的影响。图3和图4列示了就中国大陆和中国台湾数据集上,不同分类阈值下BCT算法相对于初始GBM模型的AUC值提升比例<citation id="203" type="note"><link href="9" rel="footnote" /><sup>(4)</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="125">通过对所有数据集结果的分析,可以得到以下结论:</p>
                </div>
                <div class="p1">
                    <p id="126">(1)在同一个数据集上,不同拒绝比例下的AUC 提升比例呈现出相同的变化趋势,总体而言,拒绝比例越高,在相同分类阈值下的AUC提升比例也越高。同一个数据集所代表的样本总体,其背后的真实几率相同,因此在不同拒绝比例下,最优的分类阈值应该是接近的。拒绝比例越高,由于拒绝样本缺失带来的信息损失越大,作为基准模型的GBM模型的效果越差,BCT算法通过利用拒绝样本中信息带来的模型性能提升也就越明显。</p>
                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJYJ201909007_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于中国大陆数据集下分类阈值对
AUC的影响" src="Detail/GetImg?filename=images/TJYJ201909007_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 基于中国大陆数据集下分类阈值对
AUC的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJYJ201909007_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJYJ201909007_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于中国台湾数据集下分类阈值对
AUC的影响" src="Detail/GetImg?filename=images/TJYJ201909007_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 基于中国台湾数据集下分类阈值对
AUC的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJYJ201909007_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="130">(2)在分类阈值<i>λ</i>较低时,AUC提升比例呈倒U型的变化趋势,在0.05～0.3之间达到峰值。在信贷审批实践中,坏样本占比通常小于10%,因此最优的分类阈值应该在0.1附近,此时AUC提升比例达到峰值。随着分类阈值的进一步提高,越来越多的拒绝样本被打上错误的标记后添加到接受样本中,导致模型的AUC开始不断下降。当分类阈值大过模型对所有拒绝样本输出的预测值后,继续提高阈值,会导致BCT算法在迭代过程中将所有的拒绝样本都判为负例,此时可以观察到AUC提升比例下降到一定程度后不再继续下降。</p>
                </div>
                <div class="p1">
                    <p id="131">考虑到信用评分模型的应用,本文在最终设计算法时,将分类阈值λ的默认值设定为0.1。理论上,BCT算法也适用于其他类别不平衡的数据集的部分样本标记缺失问题,使用者可以根据不同的类别占比来调整分类阈值λ的参数取值,然后通过交叉验证或在测试集上验证的方式对参数进行调优。</p>
                </div>
                <h4 class="anchor-tag" id="132" name="132">(<b>三)最大迭代次数对性能的影响</b></h4>
                <div class="p1">
                    <p id="133">为了更好地了解迭代次数对BCT算法性能的影响,本文分别计算3种半监督学习算法在每轮迭代后的AUC均值,并以GBM模型的AUC作为比较基准。为了体现BCT算法的早停止条件的作用,每个数据集的迭代次数都记录到最优迭代次数之后的一轮。图5和图6展示了在中国大陆和中国台湾数据集上,在不同迭代次数下3种半监督学习算法与基准模型GBM的AUC均值的折线图<citation id="204" type="note"><link href="11" rel="footnote" /><sup>(5)</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="134">通过对所有数据集结果的分析,可以看到BCT算法的AUC始终高于Co-training、Self-training和GBM模型。迭代开始后,BCT算法AUC的折线虽有波动,但总体呈上升趋势,且到达早停止轮次后开始下降。随着BCT算法对拒绝样本的不断利用,AUC值持续上升,并在3～8轮后快速收敛。由于早停止轮次非常小(一般小于10次),BCT算法可以在很短的时间内完成训练。这一优点使BCT算法非常适合用于开发信用评分模型,在实践中,可以将参数设置为一个非常大的值,使算法在达到最大迭代次数之前就因为满足早停止条件而停止迭代,从而得到预测效果最优的模型。</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJYJ201909007_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于中国大陆数据集下迭代次数对
AUC的影响" src="Detail/GetImg?filename=images/TJYJ201909007_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 基于中国大陆数据集下迭代次数对
AUC的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJYJ201909007_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJYJ201909007_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 基于中国台湾数据集下迭代次数对
AUC的影响" src="Detail/GetImg?filename=images/TJYJ201909007_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 基于中国台湾数据集下迭代次数对
AUC的影响</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJYJ201909007_136.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="137" name="137" class="anchor-tag">五、总结</h3>
                <div class="p1">
                    <p id="138">本文基于半监督协同训练法提出的BCT算法,具体来说,算法的优良性主要体现在以下三个方面。第一,拒绝推断的根本问题在于接受样本、拒绝样本和样本总体的分布不一致,基于接受样本得到的初始模型在对拒绝样本进行标注时准确度往往不高。BCT算法在迭代过程中运用动态Bagging的方法批量生成子分类器,降低了模型的泛化误差,同时,动态Bagging也增加了子分类器生成过程中的随机性,可以防止部分子分类器由于一次Bagging的失败而导致预测效果一直很差,进而提高了算法对拒绝样本标注的准确率。第二,在拒绝推断问题中往往面临坏样本占比极低,接受样本和拒绝样本分布不一致的问题。通常的做法是对数据集进行重采样,使样本中的好、坏样本比例接近。然而,实践证明由于过采样会给数据集添加过多噪音,重抽样方法通常难以取得较好的效果。BCT算法通过引入分类阈值参数来应对类别不平衡问题,克服了重抽样对于添加噪音或丢失信息的两难选择,并且通过分类阈值参数的调优来缓解类别不平衡问题,这也是最直接有效提升类别分布不平衡数据集的预测准确率的方法(<citation id="199" type="reference"><link href="55" rel="bibliography" />Vinciotti和Hand, 2003</citation>)<citation id="198" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>。第三,基于接受样本得到的初始模型在标注拒绝样本时的准确率不高,且随着算法的迭代,标注错误会不断累积,模型在接受样本上会逐渐过拟合。BCT算法设置了早停止条件,在迭代过程中不断进行交叉验证或在验证集上进行验证。当模型的性能在一定迭代次数内无法得到提升时,会自动终止迭代过程。实验证明,早停止轮次一般非常小(实验结果显示在10次以内),表明BCT算法可以在较短时间内完成训练,特别适用于开发信用评分模型。</p>
                </div>
                <div class="p1">
                    <p id="139">BCT算法也存在一定的局限,未来还可以在以下几个方面进行改进:首先,BCT算法通过对某一种基模型进行Bagging来批量生成子分类器,导致子分类器之间的差异性有限,在一定程度上制约了集成学习提升标注准确率的效果,未来可以测试利用多种基模型生成子分类器的效果,在算法复杂性和有效性之间取得平衡;其次,算法中特征子集维数、置信度阈值等参数的设定也具有一定主观色彩,未来有必要进一步分析这些参数对算法的影响机制,以及提出参数调优的具体策略;最后,本研究仅仅测试了BCT算法应用于信贷领域的拒绝推断问题的效果,未来可以在更多数据集上测试BCT算法的效果,如邮件识别、情感分类、图像识别等场景,以探索该算法在应用领域上的拓展性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="13">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reject inference applied to logistic regression for credit scoring">

                                <b>[1]</b>Joanes D N.Reject Inference Applied to Logistic Regression for Credit Scoring [J].IMA Journal of Management Mathematics,1993 (1):35-43.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100568938&amp;v=MDYzMjliSzdIdERPcm85RlllMEhCWDh4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcm5JSjEwZGFoVT1OaWZPZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Bücker M,van Kampen M,Krämer W.Reject Inference in Consumer Credit Scoring with Nonignorable Missing Data [J].Journal of Banking and Finance,2013 (3):1040-1045.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Credit Scoring and the Sample Selection Bias">

                                <b>[3]</b>Parnitzke T.Credit Scoring and the Sample Selection Bias [J].Working Paper,2005.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Specification and Informational Issues in Credit Scoring">

                                <b>[4]</b>Kiefer N M,Larson C E.Specification and Informational Issues in Credit Scoring [Z].CAE Working Paper,2006.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Rule of Thumb for Reject Inference in Credit Scoring">

                                <b>[5]</b>Zeng G,Zhao Q.A Rule of Thumb for Reject Inference in Credit Scoring [J].Mathematical Finance Letters,2014,(2):1-13.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sample selection bias as a specification error">

                                <b>[6]</b>Heckman J J.Sample Selection Bias as a Specification Error [J].Econometrica,1979 (1):153-161.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100623312&amp;v=MzI1MTZybzlGWXVrTUQzMDdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybklKMTBkYWhVPU5pZk9mYks3SHRETw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>Wu I D,Hand D J.Handling Selection Bias When Choosing Actions in Retail Credit Applications [J].European Journal of Operational Research,2007 (3):1560-1568.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SLTJ201206015&amp;v=MTQ4OTZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeS9tV3IvUE5pSGZaTEc0SDlQTXFZOUU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>张景肖,魏秋萍,姜玉霞,等.基于两阶段思想处理拒绝推断的信用评分模型[J].数理统计与管理,2012 (6):1049-1060.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD13101700119316&amp;v=MjI5NjZadEZpbmxVcm5JSjEwZGFoVT1OajNhYXJLN0g5SE5xSTlGWmVvR0QzMC9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Chen G G,Åstebro T.Bound and Collapse Bayesian Reject Inference for Credit Scoring [J].Journal of the Operational Research Society,2012 (10):1374-1387.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Semi-supervised Approach for Reject Inference in Credit Scoring Using SVMs">

                                <b>[10]</b>Maldonado S,Paredes G.A Semi-Supervised Approach for Reject Inference in Credit Scoring Using SVMs[C].Industrial Conference on Data Mining.Berlin:Springer,2010:558-571.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638227&amp;v=MzAzMjlpZk9mYks3SHRETnFvOUVZdWdIRG40K29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJuSUoxMGRhaFU9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>Huang S C,Tang Y C,Lee C W,et al.Kernel Local Fisher Discriminant Analysis Based Manifold-Regularized SVM Model for Financial Distress Predictions [J].Expert Systems with Applications,2012 (3):3855-3861.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEA24040D2463BF78E766FCA676E208DD&amp;v=MDg5MjdPZmNiSkhOWE1xNDh4WnU4SkR3NVB5QjVtN1RsN1BneVRxaFV6RExDVVRjN3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0NWh3N3Uyd0s4PU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Li Z,Tian Y,Li K,et al.Reject Inference in Credit Scoring Using Semi-Supervised Support Vector Machines [J].Expert Systems with Applications,2017(74):105-114.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Combining Labeled and Unlabeled Data with Co-Training">

                                <b>[13]</b>Blum A,Mitchell T.Combining Labeled and Unlabeled Data with Co-Training[C].Proceedings of Eleventh Annual Conference on Computational Learning Theory,1998:92-100.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tri-training: Exploiting unlabeled data using three classifiers">

                                <b>[14]</b>Zhou Zhihua,Li Ming.Tri-training:Exploiting Unlabeled Data Using Three Classifiers [J].IEEE Transactions on Knowledge and Data Engineering,2005 (11):1529-1541.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU2008S1010&amp;v=MzA2MDRlN0c0SHRtdnJvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeS9tV3IvUElUZlQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>王娇,罗四维,曾宪华.基于随机子空间的半监督协同训练算法[J].电子学报,2008(12):60-65.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGK201606016&amp;v=MDE1NTVtV3IvUFB5ck1aYkc0SDlmTXFZOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeS8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>肖进,薛书田,黄静,等.客户信用评估半监督协同训练模型研究[J].中国管理科学,2016 (6):124-131.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A mixture of experts classifier with learning based on both labeled and unlabelled data">

                                <b>[17]</b>Miller D J,Uyar H S.A Mixture of Experts Classifier with Learning Based on both Labelled and Unlabelled Data[C].Advances in Neural Information Processing Systems.1997:571-577.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning from Labeled and Unlabeled Data Using Graph Min-cuts">

                                <b>[18]</b>Blum A,Chawla S.Learning from Labeled and Unlabeled Data using Graph Mincuts [C].Proceedings of the Eighteenth International Conference on Machine Learning (ICML 2001).Morgan Kaufmann Publishers Inc.,2001.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Transductive inference for text classification using support vector machines">

                                <b>[19]</b>Joachims T.Transductive Inference for Text Classification using Support Vector Macines[C].International Conference on Machine Learning (ICML),Morgan Kaufmann Publishers Inc.,1999:200-209.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ensembles on Random Patches">

                                <b>[20]</b>Louppe G,Geurts P.Ensembles on Random Patches[C].Joint European Conference on Machine Learning and Knowledge Discovery in Databases.Berlin:Springer,2012:346-361.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MDk4MDBITlhPckkxTlkrc1BEQk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVadkZ5bmpVN2pMS1Y0VFhGcXpHYkM0&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b>周志华.机器学习[M].北京:清华大学出版社,2016.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scorecard Construction with Unbalanced Class Sizes">

                                <b>[22]</b>Vinciotti V,Hand D J.Scorecard Construction with Unbalanced Class Sizes[J].Journal of the Iranian Statistical Society,2003 (2):189-205.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Early stopping But when">

                                <b>[23]</b>Prechelt L.Early Stopping-But When?[M].Neural Networks:Tricks of the trade.Springer,Berlin,Heidelberg,1998:53-67.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analyzing the effectiveness and applicability of co-training">

                                <b>[24]</b>Nigam K,Ghani R.Analyzing the Effectiveness and Applicability of Co-Training[C].Proceedings of the Ninth International Conference on Information and Knowledge Management,2000:86-93.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Credit Risk Scorecards:Developing and Implementing Intelligent Credit Scoring">

                                <b>[25]</b>Siddiqi N.Credit Risk Scorecards:Developing and Implementing Intelligent Credit Scoring [M].New York:John Wiley &amp; Sons Inc.,2005.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="3" href="javascript:void(0)">
                            <b>1</b>限于篇幅,整个算法流程的伪代码以附图1展示,见《统计研究》网站所列附件。下同。
                        </span>
                    </p>
                    <p>
                        <span id="5" href="javascript:void(0)">
                            <b>2</b>不同拒绝比例和不同数据集下7种信用评分模型的AUC值及其他相关结果见附表1～6。
                        </span>
                    </p>
                    <p>
                        <span id="7" href="javascript:void(0)">
                            <b>3</b>其他3个数据集的子分类器个数对AUC的影响效果见附图2～4。
                        </span>
                    </p>
                    <p>
                        <span id="9" href="javascript:void(0)">
                            <b>4</b>其他3个数据集的分类阈值对AUC的影响效果见附图5～7。
                        </span>
                    </p>
                    <p>
                        <span id="11" href="javascript:void(0)">
                            <b>5</b>其他3个数据集的迭代次数对AUC的影响效果见附图8～10。
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="TJYJ201909007" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJYJ201909007&amp;v=MDExOTlQTVNmU1pMRzRIOWpNcG85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5L21Xci8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZNczVwMDZGR0d6Yk0xaUg1WWF1cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
