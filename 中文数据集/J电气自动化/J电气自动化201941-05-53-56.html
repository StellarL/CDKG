

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138402355783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDQZD201905016%26RESULT%3d1%26SIGN%3d6Vtd9kLlT2nroQgsJuZ9W0UIoic%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DQZD201905016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DQZD201905016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQZD201905016&amp;v=MzIwNTVFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpxRnkvaFZiekxJVHpSYXJHNEg5ak1xbzk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#15" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#19" data-title="&lt;b&gt;1 背景知识&lt;/b&gt; "><b>1 背景知识</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#20" data-title="&lt;b&gt;1.1 卷积神经网络&lt;/b&gt;"><b>1.1 卷积神经网络</b></a></li>
                                                <li><a href="#39" data-title="&lt;b&gt;1.2 二值神经网络&lt;/b&gt;"><b>1.2 二值神经网络</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;2 系统流程&lt;/b&gt; "><b>2 系统流程</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;2.1 网络结构&lt;/b&gt;"><b>2.1 网络结构</b></a></li>
                                                <li><a href="#51" data-title="&lt;b&gt;2.2 模型训练&lt;/b&gt;"><b>2.2 模型训练</b></a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;2.3 硬件实现&lt;/b&gt;"><b>2.3 硬件实现</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#69" data-title="&lt;b&gt;3 实际测试&lt;/b&gt; "><b>3 实际测试</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#78" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#29" data-title="&lt;b&gt;图1 神经网络结构示意图&lt;/b&gt;"><b>图1 神经网络结构示意图</b></a></li>
                                                <li><a href="#34" data-title="&lt;b&gt;图2 卷积计算过程示意图&lt;/b&gt;"><b>图2 卷积计算过程示意图</b></a></li>
                                                <li><a href="#35" data-title="&lt;b&gt;图3 最大池化过程示意图&lt;/b&gt;"><b>图3 最大池化过程示意图</b></a></li>
                                                <li><a href="#42" data-title="&lt;b&gt;图4 全连接二值神经网络示例&lt;/b&gt;"><b>图4 全连接二值神经网络示例</b></a></li>
                                                <li><a href="#50" data-title="&lt;b&gt;图5 CNV网络结构示意图&lt;/b&gt;"><b>图5 CNV网络结构示意图</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;图6 反向传播原理示意图&lt;/b&gt;"><b>图6 反向传播原理示意图</b></a></li>
                                                <li><a href="#71" data-title="&lt;b&gt;图7 图片测试效果图&lt;/b&gt;"><b>图7 图片测试效果图</b></a></li>
                                                <li><a href="#72" data-title="&lt;b&gt;图8 图片测试效果图&lt;/b&gt;"><b>图8 图片测试效果图</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;图9 实物测试效果图&lt;/b&gt;"><b>图9 实物测试效果图</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;图10 实物测试效果图&lt;/b&gt;"><b>图10 实物测试效果图</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="100">


                                    <a id="bibliography_1" title=" KRIZHEVSKY A,SUTSKEVER I,HINTON G E.ImageNet classification with deep convolutional neural networks[C]// International Conference on Neural Information Processing Systems.Red Hook,NY:Curran Associates,NY,2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">
                                        <b>[1]</b>
                                         KRIZHEVSKY A,SUTSKEVER I,HINTON G E.ImageNet classification with deep convolutional neural networks[C]// International Conference on Neural Information Processing Systems.Red Hook,NY:Curran Associates,NY,2012:1097-1105.
                                    </a>
                                </li>
                                <li id="102">


                                    <a id="bibliography_2" title=" HINTON G,DENG L,YU D,et al.Deep neural networks for acoustic modeling in speech recognition:The shared views of four research groups[J].IEEE Signal Processing Magazine,2012,29(6):82-97." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups">
                                        <b>[2]</b>
                                         HINTON G,DENG L,YU D,et al.Deep neural networks for acoustic modeling in speech recognition:The shared views of four research groups[J].IEEE Signal Processing Magazine,2012,29(6):82-97.
                                    </a>
                                </li>
                                <li id="104">


                                    <a id="bibliography_3" title=" BAHDANAU D,CHO K,BENGIO Y.Neural machine translation by jointly learning to align and translate[J].arXiv e-prints,2014:abs/1409.0473." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">
                                        <b>[3]</b>
                                         BAHDANAU D,CHO K,BENGIO Y.Neural machine translation by jointly learning to align and translate[J].arXiv e-prints,2014:abs/1409.0473.
                                    </a>
                                </li>
                                <li id="106">


                                    <a id="bibliography_4" title=" SUNG W,SHIN S,HWANG K.Resiliency of deep neural networks under quantization[J].Computer Science,2015:229-233." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Resiliency of deep neural networks under quantization">
                                        <b>[4]</b>
                                         SUNG W,SHIN S,HWANG K.Resiliency of deep neural networks under quantization[J].Computer Science,2015:229-233.
                                    </a>
                                </li>
                                <li id="108">


                                    <a id="bibliography_5" title=" RASTEGARI M,ORDONEZ V,REDMON J,et al.Xnor-net:Imagenet classification using binary convolutional neural networks[C]//European Conference on Computer Vision.Springer International Publishing,Cham,2016:525-542." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Xnor-net:Imagenet classification using binary convolutional neural networks">
                                        <b>[5]</b>
                                         RASTEGARI M,ORDONEZ V,REDMON J,et al.Xnor-net:Imagenet classification using binary convolutional neural networks[C]//European Conference on Computer Vision.Springer International Publishing,Cham,2016:525-542.
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_6" title=" COURBARIAUX M,HUBARA I,SOUDRY D,et al.Binarized neural networks:Training neural networks with weights and activations constrained to+ 1 or-1[J].arXiv e-prints,2016:abs/1602.02830." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Binarized neural networks:Training neural networks with weights and activations constrained to+ 1 or-1">
                                        <b>[6]</b>
                                         COURBARIAUX M,HUBARA I,SOUDRY D,et al.Binarized neural networks:Training neural networks with weights and activations constrained to+ 1 or-1[J].arXiv e-prints,2016:abs/1602.02830.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DQZD" target="_blank">电气自动化</a>
                2019,41(05),53-56 DOI:10.3969/j.issn.1000-3886.2019.05.016            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于PYNQ开发板的二值神经网络分类模型研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B4%94%E6%AF%85&amp;code=08517660&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">崔毅</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AE%B3%E5%9B%BD%E5%8D%8E&amp;code=08536633&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">殳国华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E4%B8%B9&amp;code=08517375&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李丹</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E4%B8%8E%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0054402&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海交通大学电子信息与电气工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>对人工神经网络(artificial neural network,ANN)、卷积神经网络(convolutional neural network,CNN)以及二值神经网络(binary neural network,BNN)模型的原理进行了深入研究,对二值神经网络的特点和优势进行了说明。为了应用在PYNQ开发板上,首先根据传统卷积神经网络的结构搭建了具有适当规模的网络模型,分别在现有的公开数据集如MNIST、CIFAR10、SVHN上进行了训练,取得了良好的分类效果。硬件方面,首先通过HLS综合生成PYNQ开发板可调用的硬件库,再将训练完的权重生成二进制文件进行移植并在开发板上进行分类的预测。测试结果表明,分类模型能在计算资源有限的情况下较为理想地完成分类任务。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%8E%B0%E5%9C%BA%E5%8F%AF%E7%BC%96%E7%A8%8B%E9%97%A8%E9%98%B5%E5%88%97(FPGA)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">现场可编程门阵列(FPGA);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=PYNQ%E5%BC%80%E5%8F%91%E6%9D%BF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">PYNQ开发板;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%8C%E5%80%BC%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">二值神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    崔毅(1994-),男,湖北武汉人,研究生,研究方向:深度学习、计算机视觉。;
                                </span>
                                <span>
                                    殳国华(1969-),男,浙江海宁人,副教授,研究方向:电力电子、计算机控制技术及嵌入式系统应用。;
                                </span>
                                <span>
                                    李丹(1971-),女,贵州兴义人,博士,高级工程师,研究方向:嵌入式系统运用。;
                                </span>
                    </p>
                
            </div>
                    <h1><b>Research on Binary Neural Network Classification Models Based on the PYNQ Development Board</b></h1>
                    <h2>
                    <span>Cui Yi</span>
                    <span>Shu Guohua</span>
                    <span>Li Dan</span>
            </h2>
                    <h2>
                    <span>College of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>A thorough research was made on the principle of models of artificial neural network(ANN), convolutional neural network(CNN) and binary neural network(BNN). The features and advantages of the binary neural network were explained. For the purpose of applying it to PYNQ development board, firstly, a network model of a proper scale was set up according to the structure of the traditional convolutional neural network. Then, the model was trained on public datasets such as MNIST, CIFAR10 and SVHN with excellent classification results. In the respect of hardware, firstly, HLS was used to synthesize a hardware library which PYNQ development board could call. Then, trained weight-generated binary files were transplanted and classification prediction was made on the development board. Test results indicated that the classification model could fulfill its classification task with good performance under the condition of limited computational resources.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=field%20programmable%20gate%20array(FPGA)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">field programmable gate array(FPGA);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=PYNQ%20development%20board&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">PYNQ development board;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=binary%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">binary neural network;</a>
                </p>
            </div>
        

        <!--brief start-->
                        <h3 id="15" name="15" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="16">深度神经网络在近年人工智能的发展中起到了关键的作用,被广泛应用于图像识别<citation id="112" type="reference"><link href="100" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、语音识别<citation id="113" type="reference"><link href="102" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>和自然语言处理<citation id="114" type="reference"><link href="104" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等领域。其中卷积神经网络在处理图像时因其权值共享的特点,使之更类似于生物神经网络,降低了网络模型的复杂度,可减少计算量和参数量,并获得鲁棒性较高的特征,是目前应用最多,效果最好的算法。</p>
                </div>
                <div class="p1">
                    <p id="17">传统的卷积神经网络在前向传播和反向传播中使用浮点参数进行计算,其训练过程也通常需要高效图像处理单元(graphics processing unit,GPU)和较长的时间,因此在低电压和计算资源有限的情况下(例如移动便携式设备),使用和性能都会受到限制。最新的研究表明,神经网络仅使用一位或两位量化的权重和激活值也可以准确地完成分类任务<citation id="115" type="reference"><link href="106" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>,这样一来可以大大降低对存储空间和计算量的需求从而达到小型场景的应用目的。现场可编程门阵列(field programmable gate Array,FPGA)在二进制运算上具有快速、高效和占用存储空间小等优点,非常适用于低精度、小容量的使用场景。</p>
                </div>
                <div class="p1">
                    <p id="18">本文参考了二值神经网络(binary neural network,BNN)的实现方法,在不同的公开数据集上进行训练。将网络结构综合为PYNQ开发板可以调用的IP核,并用训练完成的权重生成二进制文件后进行移植,从而实现了高效计算,并能够通过摄像头实时检测和标识物体的分类模型。</p>
                </div>
                <h3 id="19" name="19" class="anchor-tag"><b>1 背景知识</b></h3>
                <h4 class="anchor-tag" id="20" name="20"><b>1.1 卷积神经网络</b></h4>
                <div class="p1">
                    <p id="21">人工神经网络(artificial neural network,ANN)是受生物大脑神经系统的启发,模仿其结构提出的一种计算系统,其主要目的是找到一种映射,将训练样本的输入与相应的标签对应起来。它的主要结构包括一个输入层和一个输出层,中间由若干个隐藏层相连,每一层均包含一定数量的神经元,上一层的输出作为下一层的输入,从而完成正向的计算。用数学语言可以表示如下:</p>
                </div>
                <div class="p1">
                    <p id="22"><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mo>=</mo><mi>σ</mi><mrow><mo>(</mo><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>l</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></msubsup><mi>w</mi></mstyle><msubsup><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mi>s</mi></mrow><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mi>a</mi><msubsup><mrow></mrow><mi>s</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msubsup><mo>+</mo><mi>b</mi><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow><mo>)</mo></mrow></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="23">式中:<i>a</i><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow></math></mathml>为第<i>l</i>层第<i>n</i>个神经元的输出值;<i>S</i><sub><i>l</i></sub><sub>-1</sub>为第<i>l</i>-1层的神经元个数;<i>w</i><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>n</mi><mo>,</mo><mi>s</mi></mrow><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow></math></mathml>为第<i>l</i>-1层的第<i>s</i>个神经元连接到第<i>l</i>层的第<i>n</i>个神经元的权重值;<i>b</i><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow></math></mathml>为第<i>l</i>层第<i>n</i>个神经元的偏差值;<i>σ</i>为激活函数,加入激活函数的目的是将线性运算变为非线性运算,因为从本质上讲如果不加入激活函数,使用再多的隐藏层原映射依然是线性运算的组合,无法进行非线性的分类。常用的激活函数包括双曲正切函数<i>σ</i>(<i>x</i>)=tanh(<i>x</i>),ReLU函数<i>σ</i>(<i>x</i>)=max(<i>x</i>,0),sigmoid函数<i>σ</i>(<i>x</i>)=1/(1+<i>e</i><sup>-</sup><sup><i>x</i></sup>)。</p>
                </div>
                <div class="p1">
                    <p id="24">运算以矩阵表示为:</p>
                </div>
                <div class="p1">
                    <p id="25"><i>a</i><mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow></math></mathml>=<i>σ</i>(<i>W</i><sup>[</sup><sup><i>l</i></sup><sup>]</sup><i>a</i><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msubsup></mrow></math></mathml>+<i>b</i><sup>[</sup><sup><i>l</i></sup><sup>]</sup>)      (2)</p>
                </div>
                <div class="area_img" id="122">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DQZD201905016_12200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="28">其结构示意图如图1所示。</p>
                </div>
                <div class="area_img" id="29">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_029.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 神经网络结构示意图" src="Detail/GetImg?filename=images/DQZD201905016_029.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 神经网络结构示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_029.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="30">上层神经元对输入进行激活后通过权重和偏置传递到下一层,每一层的神经元均与下一层所有神经元相连,因此又称为全连接层。</p>
                </div>
                <div class="p1">
                    <p id="31">卷积神经网络可以视作传统网络的一种变形,其最重要的部分就是卷积层。与普通的全连接层相比,卷积层的每个卷积核只与输入的一小部分相连,因此它更多地关注局部特征,这样做的好处是无论输入图片尺寸多大,参数的数量只与卷积核的大小和个数有关,极大减少了运算量。同时,卷积核的参数对全局是共享的,掌握了一种局部特征后在图片的其他位置也能提取出相应的特征,多个卷积核则能学习到多个特征。卷积用数学语言描述如下:</p>
                </div>
                <div class="p1">
                    <p id="32"><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>n</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub><mo>=</mo><mi>σ</mi><mrow><mo>(</mo><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>S</mi><msub><mrow></mrow><mi>l</mi></msub></mrow></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>h</mi></msubsup><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>w</mi></msubsup><mi>w</mi></mstyle></mrow></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>n</mi><mo>,</mo><mi>s</mi><mo>,</mo><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mi>p</mi><msub><mrow></mrow><mrow><mi>l</mi><mo>-</mo><mn>1</mn><mo>,</mo><mi>s</mi><mo>,</mo><mi>x</mi><mo>-</mo><mi>i</mi><mo>,</mo><mi>y</mi><mo>-</mo><mi>j</mi></mrow></msub></mrow><mo>)</mo></mrow></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="33">式中:<i>p</i><sub><i>l</i></sub><sub>,</sub><sub><i>n</i></sub><sub>,</sub><sub><i>x</i></sub><sub>,</sub><sub><i>y</i></sub>为第<i>l</i>层第<i>n</i>个神经元在点(<i>x</i>, <i>y</i>)处的值;<i>w</i><sub><i>l</i></sub><sub>,</sub><sub><i>n</i></sub><sub>,</sub><sub><i>s</i></sub><sub>,</sub><sub><i>i</i></sub><sub>,</sub><sub><i>j</i></sub>为第<i>l</i>层第<i>n</i>个神经元对第<i>s</i>个输入图像在点(<i>x</i>, <i>y</i>)处的权重;<i>h</i>, <i>w</i>为对应卷积核的长和宽;<i>S</i><sub><i>l</i></sub>为第<i>l</i>层的神经元个数;<i>σ</i>为激活函数。对卷积较为直观的理解是先将卷积核上下、左右翻转,再与输入作内积,而每个卷积核的输出等于该卷积核分别与前一层所有的输入作相应的卷积后求和。以单个卷积核,移动步长等于1为例,其计算过程可以用示意图表示如图2所示。</p>
                </div>
                <div class="area_img" id="34">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 卷积计算过程示意图" src="Detail/GetImg?filename=images/DQZD201905016_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 卷积计算过程示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_034.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="35">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_035.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 最大池化过程示意图" src="Detail/GetImg?filename=images/DQZD201905016_035.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 最大池化过程示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_035.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="36">可以看出输出图的每个值都是输入图的一小部分与卷积核卷积的结果。</p>
                </div>
                <div class="p1">
                    <p id="37">一般来说,卷积层之后都会连接一层批规范化(batch normalization,BN)层和池化(pooling)层。BN层进行的操作是在输入前将数据规范化,也就是使其平均值为0,标准差为1。这样使得数据量级相差不大,在训练时更容易收敛。池化的目的是减少图像的空间大小和训练参数的数量,通常采用最大池化,即在原图像上取长宽分别为<i>h</i>、<i>w</i>的一小块,取这些数据的最大值作为输出。用示意图表示如图3所示。</p>
                </div>
                <div class="p1">
                    <p id="38">以2×2最大池化为例,输出图的每个值都是输入图的2×2方块中的最大值,相当于保留了原图最显著的信息,对其进行了降维处理的一种压缩方法。</p>
                </div>
                <h4 class="anchor-tag" id="39" name="39"><b>1.2 二值神经网络</b></h4>
                <div class="p1">
                    <p id="40">二值神经网络,是指在普通浮点型神经网络的基础上,将其权重矩阵中的权重值和各个激活函数值同时进行二值化得到的神经网络。相比之下它有两个主要的优点:①只需用一个比特便可存储二值化的权重,与浮点型权重矩阵相比,理论上网络模型的占用空间是原来的三十二分之一,因此二值化神经网络在模型压缩上具有很大的优势;②当权重值和激活函数值同时进行二值化之后,原来32个浮点型数的乘加运算,可以通过一次异或运算(Xnor)和一次位运算解决<citation id="116" type="reference"><link href="108" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>,在模型加速上具有很大的潜力。</p>
                </div>
                <div class="p1">
                    <p id="41">由于二值神经网络的这些优点,它对于压缩模型和加速计算具有巨大的帮助。针对嵌入式或移动设备等计算和储存资源有限的场景,二值神经网络可以有效地解决浮点型网络模型过大、运算过多等问题。二值神经网络的结构示意图如图4所示。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 全连接二值神经网络示例" src="Detail/GetImg?filename=images/DQZD201905016_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 全连接二值神经网络示例</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="44">与普通神经网络的不同在于对权重和神经元的激活值进行了二值化。常用的二值化方法是直接使用符号函数决定值的正负<citation id="117" type="reference"><link href="110" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>,即:</p>
                </div>
                <div class="area_img" id="123">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DQZD201905016_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>2 系统流程</b></h3>
                <h4 class="anchor-tag" id="48" name="48"><b>2.1 网络结构</b></h4>
                <div class="p1">
                    <p id="49">本文采用的网络结构是名为CNV的一种卷积神经网络,它的输入图片大小为32×32×3,输出分类的数量根据样本种类数决定。中间主要包含6个卷积层和2个全连接层,每层之后都与一个批规范化层相连。卷积核的个数分别为64, 64, 128, 128, 256, 256,全连接层的神经元个数为512,其结构示意图如图5所示。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 CNV网络结构示意图" src="Detail/GetImg?filename=images/DQZD201905016_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 CNV网络结构示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="51" name="51"><b>2.2 模型训练</b></h4>
                <div class="p1">
                    <p id="52">模型的训练主要是利用反向传播的原理,首先根据预测值与实际值的误差定义一个损失函数来反映模型的拟合效果,误差越小表明训练效果越好,常用的损失函数有平方差损失函数和交叉熵损失函数等。然后通过损失函数对权重的梯度依次反向计算各隐藏层以及输入层的误差,从而推测各层权重参数的变化。其四个基本方程表示如下:</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>δ</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>L</mi><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mo>∇</mo><msub><mrow></mrow><mi>a</mi></msub><mi>C</mi><mo>×</mo><msup><mi>σ</mi><mo>′</mo></msup><mo stretchy="false">(</mo><mi>z</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>L</mi><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>δ</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mo stretchy="false">[</mo><mrow><mo stretchy="false">(</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>δ</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>+</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">]</mo><mo>×</mo><msup><mi>σ</mi><mo>′</mo></msup><mo stretchy="false">(</mo><mi>z</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>l</mi><mo>&lt;</mo><mi>L</mi><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>C</mi></mrow><mrow><mo>∂</mo><mi>b</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow></mfrac><mo>=</mo><mi>δ</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>C</mi></mrow><mrow><mo>∂</mo><mi>w</mi><msubsup><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup></mrow></mfrac><mo>=</mo><mi>a</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></msubsup><mi>δ</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false">[</mo><mi>l</mi><mo stretchy="false">]</mo></mrow></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">式中:<i>δ</i><sup>[</sup><sup><i>l</i></sup><sup>]</sup>为第<i>l</i>层的误差;<i>L</i>为总层数;<i>C</i>为损失函数;<i>z</i><sup>[</sup><sup><i>l</i></sup><sup>]</sup>为第<i>l</i>层的输入;<i>σ</i>为激活函数;<i>a</i><sup>[</sup><sup><i>l</i></sup><sup>]</sup>为第<i>l</i>层的输出;<i>w</i><sup>[</sup><sup><i>l</i></sup><sup>]</sup>、<i>b</i><sup>[</sup><sup><i>l</i></sup><sup>]</sup>分别为第<i>l</i>层的权重和偏置。</p>
                </div>
                <div class="p1">
                    <p id="55">最基本的优化算法是随机梯度下降法(stochastic gradient descent,SGD),即根据函数值沿着梯度方向下降最快的原理,首先用链式法则计算出损失函数对各层相应权重的梯度,再乘上一定的学习率对参数进行更新。在梯度下降法的基础上还有许多改良的算法,使训练可以更快更有效地收敛。诸如Momentum算法、适应性梯度下降法(adagrad)、RMSProp算法以及最常使用、效果最好的Adam算法。反向传播的原理如图6所示。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 反向传播原理示意图" src="Detail/GetImg?filename=images/DQZD201905016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图6 反向传播原理示意图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="58">以图6的三层网络为例,从输出层误差<i>δ</i><citation id="118" type="reference"><link href="104" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>=<i>a</i><citation id="119" type="reference"><link href="104" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>-<i>y</i>反向计算隐藏层的误差,根据式(6)可以得出:</p>
                </div>
                <div class="p1">
                    <p id="59"><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo>=</mo><mrow><mo stretchy="false">(</mo><mi>W</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>δ</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow></msup><mo>×</mo><mfrac><mrow><mo>∂</mo><mi>g</mi><mo stretchy="false">(</mo><mi>z</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup><mo stretchy="false">)</mo></mrow><mrow><mo>∂</mo><mi>z</mi><msup><mrow></mrow><mrow><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow></msup></mrow></mfrac></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="60">同理可以由隐藏层误差<i>δ</i><citation id="120" type="reference"><link href="102" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>计算输入层误差<i>δ</i><citation id="121" type="reference"><link href="100" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>从而完成反向传播,得到误差后根据式(6)即可求得权重和偏置的梯度,再利用相应优化算法对参数进行更新即完成一次迭代。</p>
                </div>
                <div class="p1">
                    <p id="61">二值神经网络的反向传播稍有不同,无法直接对二值权重求梯度,因此需要对Sign函数进行松弛处理</p>
                </div>
                <div class="p1">
                    <p id="62"><i>q</i>=Sign(<i>r</i>)</p>
                </div>
                <div class="p1">
                    <p id="63"><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>r</mi></msub><mo>=</mo><mi>g</mi><msub><mrow></mrow><mi>q</mi></msub><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>r</mi><mo>|</mo></mrow><mo>≤</mo><mn>1</mn></mrow></msub></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="64"><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>|</mo><mi>r</mi><mo>|</mo></mrow><mo>≤</mo><mn>1</mn></mrow></msub></mrow></math></mathml>为当<i>r</i>的绝对值小于等于1时取1,否则取0。由此可知,二值神经网络先求得各层权重的浮点数对应的梯度以及激活值的浮点数对应的误差,然后用优化算法进行权重的更新并不断迭代。</p>
                </div>
                <div class="p1">
                    <p id="65">用CIFAR-10数据集训练完成后最终测试的准确率大约为80.09%,同时也在自定义的数据集上(例如:电商衣物图片、车辆图片)进行了训练,训练样本均为:训练集700张图片,验证集200张图片,测试集100张图片。最终测试的准确率均在76%左右。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66"><b>2.3 硬件实现</b></h4>
                <div class="p1">
                    <p id="67">PYNQ-Z1 开发板支持 PYNQ 项目,这是一个新的开源框架,使嵌入式编程人员能够在无需设计可编程逻辑电路的情况下即可充分发挥 Xilinx Zynq All Programmable SoC(APSoC)的功能。与常规方式不同的是,通过 PYNQ,用户可以使用 Python 进行 APSoC 编程,并且代码可直接在 PYNQ-Z1 上进行开发和测试。通过 PYNQ,可编程逻辑电路将作为硬件库导入并通过其 API 进行编程,其方式与导入和编程软件库基本相同。</p>
                </div>
                <div class="p1">
                    <p id="68">训练完成后可以得到网络中每一层的浮点型权重值,为了在PYNQ开发板上进行导入,需要先将它们二值化并打包为二进制文件,之后将文件放置在PYNQ开发板内置的Linux系统中的相应位置,此后可在运行时载入权重。分类模型则是通过生成overlay来加速,它是一种可编程和配置的FPGA设计,能将应用程序从PYNQ的处理系统扩展到可编程逻辑,原理是:PYNQ通过接口,允许在处理系统中运行的Python控制可编程逻辑中的overlay。使用与软件库类似,可以根据需要动态地在FPGA上进行加载。</p>
                </div>
                <h3 id="69" name="69" class="anchor-tag"><b>3 实际测试</b></h3>
                <div class="p1">
                    <p id="70">首先直接在PYNQ开发板中读取图片进行测试,分别随机抽取20张图片对Cifar10模型和自定义的车辆识别模型进行了测试。Cifar10的准确率为85%,车辆识别模型的准确率为80%,其中两次试验效果如图7和图8所示。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 图片测试效果图" src="Detail/GetImg?filename=images/DQZD201905016_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图7 图片测试效果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 图片测试效果图" src="Detail/GetImg?filename=images/DQZD201905016_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图8 图片测试效果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="73">从图7、图8中可以看出,classifier对象即为二值化CNV模型,通过对两张测试图片分别调用classify_image函数得到了相应的类别,分别为airplane和bus,符合实际结果。</p>
                </div>
                <div class="p1">
                    <p id="74">然后通过连接摄像头图像源输入进行实时测试,由于系统的识别速度大约为11张/秒,故在实时获取画面时每次识别20帧图像,选出20个识别结果中出现频率最高的作为最终分类结果。对车辆识别模型进行测试的结果为准确率在75%上下,其中两次的试验效果如图9、图10所示。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 实物测试效果图" src="Detail/GetImg?filename=images/DQZD201905016_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图9 实物测试效果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201905016_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 实物测试效果图" src="Detail/GetImg?filename=images/DQZD201905016_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图10 实物测试效果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201905016_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="77">从图9和图10中可以看出,分别用摄像头拍摄实物SUV和ofo小黄车,模型输出的识别类别分别为SUV和bicycle,符合实际结果。</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="79">本文分析了人工神经网络、卷积神经网络及二值神经网络的工作原理,搭建并训练了分类模型,对系统流程进行了详尽的描述,生成了PYNQ开发板相应的overlay,对训练权重进行了移植,实现了高效的分类识别模型。分别用图片和摄像头图像输入进行了多次试验,结果表明,该系统能在一定准确率的基础上,实时快速地完成分类任务。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="100">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">

                                <b>[1]</b> KRIZHEVSKY A,SUTSKEVER I,HINTON G E.ImageNet classification with deep convolutional neural networks[C]// International Conference on Neural Information Processing Systems.Red Hook,NY:Curran Associates,NY,2012:1097-1105.
                            </a>
                        </p>
                        <p id="102">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups">

                                <b>[2]</b> HINTON G,DENG L,YU D,et al.Deep neural networks for acoustic modeling in speech recognition:The shared views of four research groups[J].IEEE Signal Processing Magazine,2012,29(6):82-97.
                            </a>
                        </p>
                        <p id="104">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">

                                <b>[3]</b> BAHDANAU D,CHO K,BENGIO Y.Neural machine translation by jointly learning to align and translate[J].arXiv e-prints,2014:abs/1409.0473.
                            </a>
                        </p>
                        <p id="106">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Resiliency of deep neural networks under quantization">

                                <b>[4]</b> SUNG W,SHIN S,HWANG K.Resiliency of deep neural networks under quantization[J].Computer Science,2015:229-233.
                            </a>
                        </p>
                        <p id="108">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Xnor-net:Imagenet classification using binary convolutional neural networks">

                                <b>[5]</b> RASTEGARI M,ORDONEZ V,REDMON J,et al.Xnor-net:Imagenet classification using binary convolutional neural networks[C]//European Conference on Computer Vision.Springer International Publishing,Cham,2016:525-542.
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Binarized neural networks:Training neural networks with weights and activations constrained to+ 1 or-1">

                                <b>[6]</b> COURBARIAUX M,HUBARA I,SOUDRY D,et al.Binarized neural networks:Training neural networks with weights and activations constrained to+ 1 or-1[J].arXiv e-prints,2016:abs/1602.02830.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DQZD201905016" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQZD201905016&amp;v=MzIwNTVFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpxRnkvaFZiekxJVHpSYXJHNEg5ak1xbzk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

