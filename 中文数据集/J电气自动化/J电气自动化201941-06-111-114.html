

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637138388916565000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dDQZD201906032%26RESULT%3d1%26SIGN%3dbKWS6p15M%252f0VRTVoQPrZb4zhvqI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DQZD201906032&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DQZD201906032&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQZD201906032&amp;v=MDcwODhIOWpNcVk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacUZ5L25WcnZCSVR6UmFyRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#19" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#23" data-title="&lt;b&gt;1&lt;/b&gt; AKAZE&lt;b&gt;特征提取算法&lt;/b&gt; "><b>1</b> AKAZE<b>特征提取算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#25" data-title="&lt;b&gt;1.1 构建非线性尺度空间&lt;/b&gt;"><b>1.1 构建非线性尺度空间</b></a></li>
                                                <li><a href="#42" data-title="&lt;b&gt;1.2 特征点检测和定位&lt;/b&gt;"><b>1.2 特征点检测和定位</b></a></li>
                                                <li><a href="#46" data-title="&lt;b&gt;1.3 M-LDB特征描述子生成&lt;/b&gt;"><b>1.3 M-LDB特征描述子生成</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#48" data-title="&lt;b&gt;2 KD-Tree和PROSAC融合匹配算法&lt;/b&gt; "><b>2 KD-Tree和PROSAC融合匹配算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;2.1 随机KD-Tree进行粗匹配&lt;/b&gt;"><b>2.1 随机KD-Tree进行粗匹配</b></a></li>
                                                <li><a href="#55" data-title="&lt;b&gt;2.2 预筛选次优匹配集&lt;/b&gt;"><b>2.2 预筛选次优匹配集</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;2.3 PROSAC算法搜索最优匹配集&lt;/b&gt;"><b>2.3 PROSAC算法搜索最优匹配集</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;2.4 融合匹配算法性能测试&lt;/b&gt;"><b>2.4 融合匹配算法性能测试</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="&lt;b&gt;3 试验分析&lt;/b&gt; "><b>3 试验分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;4 结束语&lt;/b&gt; "><b>4 结束语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;图1 暴力匹配与本文算法效果对比图&lt;/b&gt;"><b>图1 暴力匹配与本文算法效果对比图</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;图2 本文算法测试效果&lt;/b&gt;"><b>图2 本文算法测试效果</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;表1 四种算法测试数据&lt;/b&gt;"><b>表1 四种算法测试数据</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;图3 四种算法平均准确度对比&lt;/b&gt;"><b>图3 四种算法平均准确度对比</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;图4 四种算法平均匹配时间对比&lt;/b&gt;"><b>图4 四种算法平均匹配时间对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="106">


                                    <a id="bibliography_1" title=" DUFOURNAUD Y,SCHMID C,HORAUD R.Matching images with different resolutions[J].Proceedings of the Computer Vision &amp;amp; Pattern Recognition,2000,1(1):612-618." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Matching Images with different resolutions">
                                        <b>[1]</b>
                                         DUFOURNAUD Y,SCHMID C,HORAUD R.Matching images with different resolutions[J].Proceedings of the Computer Vision &amp;amp; Pattern Recognition,2000,1(1):612-618.
                                    </a>
                                </li>
                                <li id="108">


                                    <a id="bibliography_2" title=" LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjEyNzdqOTlTWHFScnhveGNNSDdSN3FkWitadUZpemxWTDNOSkZjPU5qN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_3" title=" BAY H,ESS A,TUYTELAARS T,et al.Speeded-up robust features[J].Computer Vision &amp;amp; Image Understanding,2008,110(3):404-417." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Speeded-Up Robust Features (SURF)">
                                        <b>[3]</b>
                                         BAY H,ESS A,TUYTELAARS T,et al.Speeded-up robust features[J].Computer Vision &amp;amp; Image Understanding,2008,110(3):404-417.
                                    </a>
                                </li>
                                <li id="112">


                                    <a id="bibliography_4" title=" RUBLEE E,RABAUD V,KONOLIGE K,et al.ORB:An efficient alternative to SIFT or SURF[C]//Barcelona,Spain:Computer Vision (ICCV),2011 IEEE international conference on.IEEE,2011:2564-2571." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ORB:an efficient alternative to SIFT or SURF">
                                        <b>[4]</b>
                                         RUBLEE E,RABAUD V,KONOLIGE K,et al.ORB:An efficient alternative to SIFT or SURF[C]//Barcelona,Spain:Computer Vision (ICCV),2011 IEEE international conference on.IEEE,2011:2564-2571.
                                    </a>
                                </li>
                                <li id="114">


                                    <a id="bibliography_5" title=" ALCANTARILLA P F,SOLUTIONS T.Fast explicit diffusion for accelerated features in nonlinear scale spaces[J].IEEE Trans.Patt.Anal.Mach.Intell,2011,34(7):1281-1298." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast explicit diffusion for accelerated features in nonlinear scale spaces">
                                        <b>[5]</b>
                                         ALCANTARILLA P F,SOLUTIONS T.Fast explicit diffusion for accelerated features in nonlinear scale spaces[J].IEEE Trans.Patt.Anal.Mach.Intell,2011,34(7):1281-1298.
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_6" title=" MUJA M,LOWE D G.Scalable nearest neighbor algorithms for high dimensional data[J].Pattern Analysis &amp;amp; Machine Intelligence IEEE Transactions on,2014,36(11):2227-2240." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scalable nearest neighbor algorithms for high dimensional data">
                                        <b>[6]</b>
                                         MUJA M,LOWE D G.Scalable nearest neighbor algorithms for high dimensional data[J].Pattern Analysis &amp;amp; Machine Intelligence IEEE Transactions on,2014,36(11):2227-2240.
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_7" title=" SILPA-ANAN C,HARTLEY R.Optimised KD-trees for fast image descriptor matching[C]//Anchorage,AK,USA:Computer Vision and Pattern Recognition,2008.CVPR 2008.IEEE Conference on.IEEE,2008:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimised KD-trees for fast image descriptor matching">
                                        <b>[7]</b>
                                         SILPA-ANAN C,HARTLEY R.Optimised KD-trees for fast image descriptor matching[C]//Anchorage,AK,USA:Computer Vision and Pattern Recognition,2008.CVPR 2008.IEEE Conference on.IEEE,2008:1-8.
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_8" title=" JIANG G,LIU L,ZHU W,et al.A 127 fps in full hd accelerator based on optimized AKAZE with efficiency and effectiveness for image feature extraction[C]//San Francisco,CA:Proceedings of the 52nd Annual Design Automation Conference,ACM,2015:87." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A 127 fps in full HD accelerator based on optimized AKAZE with efficiency and effectiveness for image feature extraction">
                                        <b>[8]</b>
                                         JIANG G,LIU L,ZHU W,et al.A 127 fps in full hd accelerator based on optimized AKAZE with efficiency and effectiveness for image feature extraction[C]//San Francisco,CA:Proceedings of the 52nd Annual Design Automation Conference,ACM,2015:87.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DQZD" target="_blank">电气自动化</a>
                2019,41(06),111-114 DOI:10.3969/j.issn.1000-3886.2019.06.032            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于AKAZE特征提取与融合匹配算法的研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%92%9F%E6%B0%B8%E5%AE%89&amp;code=43436799&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">钟永安</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%86%B2&amp;code=06677737&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈冲</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A6%8F%E5%B7%9E%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0094575&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">福州大学电气工程与自动化学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>图像匹配算法是很多计算机视觉应用的重要组成部分,其中算法的匹配准确度和匹配损耗时间是衡量匹配算法性能的重要指标。针对目前的图像特征匹配算法无法同时获得高匹配准确度和低匹配损耗时间的特点,提出了基于AKAZE算法特征提取与融合匹配算法相结合的匹配策略。通过AKAZE算法计算待匹配图像的特征描述子,融合匹配算法首先利用KD-Tree进行粗匹配,然后再结合PROSAC算法分两个阶段剔除误匹配特征点。通过试验测试,在获得高的匹配准确度的同时,保持低的匹配损耗时间。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%9E%8D%E5%90%88%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">融合匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=AKAZE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">AKAZE;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=KD-Tree&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">KD-Tree;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=PROSAC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">PROSAC;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    钟永安(1992-),男,山西人,研究生,专业:模式识别与智能系统。;
                                </span>
                    </p>
                
            </div>
                    <h1><b>Research on a Matching Strategy Based on AKAZE Feature Extraction and Fusion Matching Algorithm</b></h1>
                    <h2>
                    <span>Zhong Yongan</span>
                    <span>Chen Chong</span>
            </h2>
                    <h2>
                    <span>College of Electrical Engineering and Automation, Fuzhou University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Image matching algorithm is an important component of many computer vision applications, whereby the matching accuracy and match loss time of the algorithm are major indicators for the measurement of the performance of the matching algorithm. Considering that current image feature matching algorithm cannot have high matching accuracy and low matching loss time at the same time, a matching strategy based on AKAZE algorithm feature extraction and fusion matching algorithm was proposed in this paper. The AKAZE algorithm was used to calculate the feature descriptors of the image to be matched. According to the fusion matching algorithm, firstly, the KD-tree was used to complete rough matching. Then, the PROSAC algorithm was used to eliminate mismatched feature points in two stages. Experimental results showed that the algorithm proposed in this paper could not only achieve high matching accuracy, but also maintain a low matching loss time.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fusion%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fusion matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=AKAZE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">AKAZE;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=KD-Tree&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">KD-Tree;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=PROSAC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">PROSAC;</a>
                </p>
            </div>
        

        <!--brief start-->
                        <h3 id="19" name="19" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="20">图像特征点的提取和匹配是目标跟踪、三维重建等计算机视觉应用中一个非常重要的组成部分,同时也是一个极具挑战性的问题。</p>
                </div>
                <div class="p1">
                    <p id="21">图像匹配是指通过一定的匹配算法在两个或多个图像之间识别同名点的技术<citation id="122" type="reference"><link href="106" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。目前按照匹配机理主要分为基于灰度和基于特征两种方法。前者一般不具有旋转不变性和尺度空间不变性,只适用于相近视角的连续图像。基于特征的匹配变换适合在存在大量运动或者表现变化的情况下,比如拼接全景图像、目标识别等应用领域。1999年,Lowe提出SIFT算法<citation id="123" type="reference"><link href="108" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,算法通过采用金字塔分层方式获取特征点,缺点是运算速度慢。2006年,Bay等基于Fast-Harris的改进检测子,提出了SURF算法<citation id="124" type="reference"><link href="110" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>,提高了SIFT算法的速度和准确率,但存在误匹配的问题。2012年,Rublee等提出了ORB算法<citation id="125" type="reference"><link href="112" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>,该算法采用FAST算子极大地提高了算法效率,缺点是算法表现不稳定。2013年, Alcantarilla等提出了基于快速显示扩散检测算子和改进局部二值差分(M-LDB)描述子的加速KAZE(AKAZE)算法<citation id="126" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>,该算法通过在金字塔尺度框架中嵌入FED算子,具有良好的尺度和旋转不变性。搜索与高维向量的相似匹配一直是许多计算机视觉算法中计算量最昂贵的部分,最近邻算法是目前最有效的匹配算法之一。KD树(KD-Tree)和K均值树(K-Means-Tree)是目前提出的表现最优秀两种最近邻算法<citation id="127" type="reference"><link href="116" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="22">本文利用AKAZE算法优秀的尺度不变性、旋转不变性、光照不变性和速度等优势,结合随机KD-Tree匹配算子,提出了AKAZE特征检测算子与融合KD-Tree<citation id="128" type="reference"><link href="118" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>和PROSAC算法相结合的图像匹配算法。通过测试表明,本文算法在保证图像匹配的准确度的情况下,能够保持很高的运行速度。</p>
                </div>
                <h3 id="23" name="23" class="anchor-tag"><b>1</b> AKAZE<b>特征提取算法</b></h3>
                <div class="p1">
                    <p id="24">目前常用的多尺度特征检测和描述算法如SIFT和SURF都是通过构建高斯尺度空间实现的。由于高斯滤波的各向同性特性,这两种算法都有很明显的缺点:尺度空间不能保留图像的边界,甚至会平滑与噪声相似的重要细节信息,导致特征点的定位准确性和差异性削弱。AKAZE算法通过利用各向异性的非线性滤波构建尺度空间,有效地克服了这个问题。AKAZE 算法可以划分为三个步骤。</p>
                </div>
                <h4 class="anchor-tag" id="25" name="25"><b>1.1 构建非线性尺度空间</b></h4>
                <div class="p1">
                    <p id="26">非线性扩散滤波器描述了图像在不同尺度空间,由于流函数的差异而表现出亮度的变化,可以表示为以下公式:</p>
                </div>
                <div class="p1">
                    <p id="27"><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>t</mi></mrow></mfrac><mo>=</mo><mtext>d</mtext><mtext>i</mtext><mtext>v</mtext></mrow></math></mathml>[<i>c</i>(<i>x</i>,<i>y</i>,<i>t</i>)·∇<i>L</i>]       (1)</p>
                </div>
                <div class="p1">
                    <p id="28">式中:div为散度算子;∇为梯度算子;<i>L</i>为图像亮度;<i>c</i>(<i>x</i>,<i>y</i>,<i>t</i>)为扩散传导函数;<i>t</i>为尺度参数。传导函数可以表示为如下形式:</p>
                </div>
                <div class="p1">
                    <p id="29"><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mi>g</mi><mrow><mo>(</mo><mrow><mrow><mo>|</mo><mrow><mo>∇</mo><mi>L</mi><msub><mrow></mrow><mi>σ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow><mo>)</mo></mrow></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="30">式中:∇<i>L</i><sub><i>σ</i></sub>为原始图像<i>L</i>经过高斯平滑滤波后的梯度图像;<i>g</i>可以根据不同的处理需求进行定义。</p>
                </div>
                <div class="p1">
                    <p id="31">非线性尺度空间基于金字塔模型,由<i>O</i>组图像组成,其中每组图像包含<i>S</i>个子层级,<i>O</i>和<i>S</i>分别由相应的离散指数<i>o</i>和<i>s</i>标识。本文算法中各层的分辨率与原始图像保持一致,<i>o</i>和<i>s</i>与高斯滤波的尺度参数<i>σ</i><sub><i>i</i></sub>有如下映射关系:</p>
                </div>
                <div class="area_img" id="32">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DQZD201906032_03200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="34">式中:<i>σ</i><sub>0</sub>为初始的尺度参数;<i>M</i>=<i>O</i>×<i>S</i> 为全部的滤波图像数量。非线性扩散滤波以时间为单位因子执行运算,因此需要将以像素为单位的尺度参<i>σ</i><sub><i>i</i></sub>映射到以时间为单位的尺度参数<i>t</i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="35"><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><msup><mrow></mrow><mn>2</mn></msup><mspace width="0.25em" /><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>⋯</mo><mi>Μ</mi><mo stretchy="false">]</mo></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="36">由于非线性扩散滤波无解析解,只能通过数值方法求近似解。据Jiang等的试验数据<citation id="129" type="reference"><link href="120" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>,非线性尺度空间的构建占据了AKAZE算法43.73%的时间损耗。本文利用加速显示扩散(FED)嵌入到金字塔框架中的方法求解非线性扩散滤波解。FED通过方框滤波去近似高斯核,该算法可以简要地表示为以下形式:</p>
                </div>
                <div class="area_img" id="105">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DQZD201906032_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="39">式中:<i>I</i>为单位矩阵;<i>τ</i><sub><i>j</i></sub>为每个循环的时间步长;<i>P</i>为图像<i>L</i><sup><i>i</i></sup>的传导矩阵;<i>L</i><sup><i>i</i></sup><sup>+1,</sup><sup><i>j</i></sup>为执行显示扩散的步数。其中<i>τ</i><sub><i>j</i></sub>的表达形式如下:</p>
                </div>
                <div class="p1">
                    <p id="40"><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>τ</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub></mrow><mrow><mn>2</mn><mtext>π</mtext><mrow><mi>c</mi><mi>o</mi><mi>s</mi></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">(</mo><mn>2</mn><mi>j</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>/</mo><mo stretchy="false">(</mo><mn>4</mn><mi>n</mi><mo>+</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="41">式中:<i>τ</i><sub>max</sub>为不破坏迭代过程稳定性的最大迭代步数。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42"><b>1.2 特征点检测和定位</b></h4>
                <div class="p1">
                    <p id="43">算法利用通过式(5)得到非线性尺度空间的滤波图像<i>L</i>[<i>i</i>∈(1…<i>M</i>)]<sup><i>i</i></sup> ,计算每幅图像在不同尺度归一化的海森(Hession)行列式,这里融入基于非线性尺度空间每个特定图像组的归一化因子<i>σ</i><sub><i>i</i></sub><sub>,norm</sub>:</p>
                </div>
                <div class="p1">
                    <p id="44"><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msubsup><mrow></mrow><mrow><mtext>Η</mtext><mtext>e</mtext><mtext>s</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext></mrow><mi>i</mi></msubsup><mo>=</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mtext>n</mtext><mtext>o</mtext><mtext>r</mtext><mtext>m</mtext></mrow></msub><mrow><mo>(</mo><mrow><mi>L</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow><mi>i</mi></msubsup><mi>L</mi><msubsup><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow><mi>i</mi></msubsup><mo>-</mo><mi>L</mi><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mi>i</mi></msubsup><mi>L</mi><msubsup><mrow></mrow><mrow><mi>y</mi><mi>x</mi></mrow><mi>i</mi></msubsup></mrow><mo>)</mo></mrow></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="45">式中:<i>L</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>和<i>L</i><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>分别为第<i>i</i>幅图像水平方向和垂直方向的二阶偏导数;<i>L</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>和<i>L</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>y</mi><mi>x</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>分别为第<i>i</i>幅图像水平方向和垂直方向的二阶混合偏导数。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46"><b>1.3 M-LDB特征描述子生成</b></h4>
                <div class="p1">
                    <p id="47">特征点检测检测完成后,需要进一步对特征点进行描述。AKAZE算法基于局部二值微分算法(LDB),提出了改进的M-LDB算法。LDB算法具有很高的计算效率,但是不具有旋转不变性和尺度不变性。M-LDB利用非线性空间提取的梯度和强度信息,在旋转不变性和尺度不变性具有很强的鲁棒性。</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag"><b>2 KD-Tree和PROSAC融合匹配算法</b></h3>
                <div class="p1">
                    <p id="49">在图像配准和图像拼接等计算机视觉影响中,特征点匹配的准确性和速度是影响图像处理性能最重要的因素之一。一般认为,仅仅局部描述子的一次性比较无法避免误匹配。由于深度不连续性和重复模式等现象造成的不匹配,可以通过鲁棒性的方法来检测和去除,找到满足全局一致性约束的最优匹配集。本文特征点匹配算法主要分为三个步骤。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50"><b>2.1 随机KD-Tree进行粗匹配</b></h4>
                <div class="p1">
                    <p id="51">在大数据集中执行一种有效的快速近邻匹配算法的可以给应用的运算速度带来几个数量级的提升。目前应用最多的最近邻算法主要有两种KD-Tree和K-Means-Tree,针对匹配和准确度又提出了很多相关的改进算法。经典的KD-Tree在低维空间具有很高的计算效率,但是在高维数据的处理方面性能表现迅速降低。多重随机KD-Tree算法(multiple randomized KD trees)是KD-Tree算法的改进算法,是目前为止公认的高维数据匹配中最有效的算法之一。本文算法目的是通过在不同的树上进行同步独立的搜索,来解决高维数据计算时收益递减的问题。主要搜索步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="52">(1)创建<i>m</i>个具有不同结构的KD-Tree, 这样不同树的搜索过程将在很大程度上独立进行。</p>
                </div>
                <div class="p1">
                    <p id="53">(2)限制搜索节点的个数为<i>n</i>,将搜索过程分解为在<i>m</i>个树的同步搜索。</p>
                </div>
                <div class="p1">
                    <p id="54">(3)使用主成分析(PCA)方法来旋转数据,使其矩轴与坐标轴对齐。然后,数据将通过垂直于主轴的超平面在树中分裂。</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55"><b>2.2 预筛选次优匹配集</b></h4>
                <div class="p1">
                    <p id="56">通过测试发现,通过KD-Tree算法匹配得到的匹配特征点存在很多的误匹配。而这些误匹配会对匹配的准确率产生不良的影响。本文考虑利用匹配点的汉明距离对误匹配进行初步剔除,具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="57">(1)首先根据匹配点的汉明距离对匹配点进行排序,得到最小的汉明距离<i>d</i><sub>min</sub>和最大和汉明距离<i>d</i><sub>max</sub>。</p>
                </div>
                <div class="p1">
                    <p id="58">(2)设置阈值<i>d</i>=<i>n</i>×<i>d</i><sub>min</sub>,遍历所有的特征匹配点,将每个特征匹配点的汉明距离与阈值<i>d</i>进行比较,汉明距离小于<i>d</i>的特征匹配点对被视为次优匹配点返回并保存。这里<i>n</i>的数值需要根据不同特征检测算法匹配特征点进行相应的调整。对于SIFT和ORB算法,<i>n</i>∈(2,5) ;对于SURF,AKAZE算法,<i>n</i>∈(5,10)。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>2.3 PROSAC算法搜索最优匹配集</b></h4>
                <div class="p1">
                    <p id="60">本文通过PROSAC(progressive sample consensus)算法进一步剔除误匹配特征点。不同于RANSAC算法无差别对待所有的相关匹配点,并且均匀地在完整集合中抽取随机样本。PROSAC算法利用相似度函数对临时建立的集合中的相关匹配点进行线性排序,提取排名质量最高的<i>n</i>个样本作为假设子集。PROSAC算法在匹配准确度和速度方面都获得了优于RANSAC算法的性能。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61"><b>2.4 融合匹配算法性能测试</b></h4>
                <div class="p1">
                    <p id="62">本文分别采用SIFT,SURF,ORB和AKAZE算法对VGG(visual geometry group)标准图片库中的graf图片组进行特征检测。对暴力匹配与本文融合的算法匹配结果进行对比,测试匹配算法性能。测试结果如图1所示。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201906032_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 暴力匹配与本文算法效果对比图" src="Detail/GetImg?filename=images/DQZD201906032_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 暴力匹配与本文算法效果对比图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201906032_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="64">图1(a)、图1(c)、图1(e)和图1(g)分别代表四种特征提取算法结合暴力匹配算法的测试结果,图1(b)、图1(d)、图1(f)和图1(h)分别代表四种特征提取算法结合本文匹配算法的测试结果。</p>
                </div>
                <div class="p1">
                    <p id="65">对比图1两组测试结果,与暴力匹配算法相比本文融合匹配算法能够有效地剔除明显的误匹配,并获得足够数量和高准确率的最优匹配集。四种算法使用暴力匹配的平均耗时为0.636 ms,使用本文融合匹配算法的平均耗时为0.642 ms,表明本文算法在获得优秀的匹配集的同时,时间损耗并没有明显的增加。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag"><b>3 试验分析</b></h3>
                <div class="p1">
                    <p id="67">本文首先利用SIFT、SURF、ORB和AKAZE四种方法构建图像的特征描述子。为了保证试验的一致性,对上述四种算法得到的特征描述子都使用本文提出的融合匹配算法进行匹配测试。测试的指标为最优匹配点数量、配准正确率<i>C</i>和配准损耗时间<i>T</i>。配准正确度<i>C</i>的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="68"><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo>=</mo><mfrac><mrow><mtext>Ι</mtext><mtext>Ρ</mtext></mrow><mrow><mtext>Μ</mtext><mtext>Ρ</mtext></mrow></mfrac></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="69">式中:MP(match point)为最优匹配集的匹配点数量;IP(inliers point)为最优匹配集的内点数量,通过RANSAC算法计算得到。配准损耗时间<i>T</i>的计算利用以下公式:</p>
                </div>
                <div class="p1">
                    <p id="70"><i>T</i>=DT+MT      (9)</p>
                </div>
                <div class="p1">
                    <p id="71">式中:DT(detect time)和MT(match time)分别为检测特征描述子的时间损耗和获取最优匹配集的匹配时间损耗。</p>
                </div>
                <div class="p1">
                    <p id="72">本文算法的测试结果是在英特尔<sup>TM</sup> i7-6700HQ 处理器平台得到的。为了验证算法在不同真实条件下的鲁棒性,本文分别选取了四组共4×6张具有不同变化属性的VGG标准图像样本boat(变焦旋转)、leuven(亮度改变)、bike (清晰度改变)和ubc(压缩改变)进行测试,测试结果如图2所示。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201906032_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文算法测试效果" src="Detail/GetImg?filename=images/DQZD201906032_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 本文算法测试效果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201906032_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="74">图2(a)、图2(b)、图2(c)和图2(d)分别代表本文算法在四种不同图像变化场景的测试结果。</p>
                </div>
                <div class="p1">
                    <p id="75">四种算法的测试数据见表1。</p>
                </div>
                <div class="area_img" id="76">
                    <p class="img_tit"><b>表1 四种算法测试数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="76" border="1"><tr><td>scene</td><td>algorithm</td><td>MP</td><td>IP</td><td>DT</td><td>MT</td></tr><tr><td><br /></td><td>sift</td><td>211</td><td>207</td><td>0.438</td><td>0.032</td></tr><tr><td><br /></td><td>surf</td><td>228</td><td>225</td><td>0.179</td><td>0.031</td></tr><tr><td><br />boat<br /></td><td>orb</td><td>214</td><td>206</td><td>0.049</td><td>0.001</td></tr><tr><td><br /></td><td>paper</td><td>222</td><td>219</td><td>0.160</td><td>0.031</td></tr><tr><td><br /></td><td>sift</td><td>121</td><td>114</td><td>0.444</td><td>0.006</td></tr><tr><td><br /></td><td>surf</td><td>219</td><td>213</td><td>0.160</td><td>0.014</td></tr><tr><td><br />leuven</td><td>orb</td><td>118</td><td>110</td><td>0.037</td><td>0.005</td></tr><tr><td><br /></td><td>paper</td><td>212</td><td>207</td><td>0.131</td><td>0.012</td></tr><tr><td><br /></td><td>sift</td><td>167</td><td>155</td><td>0.451</td><td>0.006</td></tr><tr><td><br /></td><td>surf</td><td>248</td><td>244</td><td>0.185</td><td>0.012</td></tr><tr><td><br />bike</td><td>orb</td><td>181</td><td>167</td><td>0.043</td><td>0.001</td></tr><tr><td><br /></td><td>paper</td><td>244</td><td>243</td><td>0.167</td><td>0.013</td></tr><tr><td><br /></td><td>sift</td><td>223</td><td>206</td><td>0.408</td><td>0.010</td></tr><tr><td><br /></td><td>surf</td><td>312</td><td>305</td><td>0.177</td><td>0.025</td></tr><tr><td><br />ubc</td><td>orb</td><td>176</td><td>172</td><td>0.037</td><td>0.001</td></tr><tr><td><br /></td><td>paper</td><td>332</td><td>330</td><td>0.154</td><td>0.019</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201906032_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 四种算法平均准确度对比" src="Detail/GetImg?filename=images/DQZD201906032_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 四种算法平均准确度对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201906032_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="78">表1中MP、IP、DT(ms)、MT(ms)分别代表匹配点数量、内点数量、特征检测时间损耗和描述子匹配时间损耗。boat、leuven、bike和ubc分别代表四种典型的图像属性变化场景(scene)。</p>
                </div>
                <div class="p1">
                    <p id="79">图3为四种算法平均准确度对比。</p>
                </div>
                <div class="p1">
                    <p id="80">图3中accuracy rate代表配准准确度<i>C</i>,scene代表四种图像变化场景。</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DQZD201906032_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 四种算法平均匹配时间对比" src="Detail/GetImg?filename=images/DQZD201906032_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 四种算法平均匹配时间对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DQZD201906032_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="82">图4为四种算法平均匹配时间对比。</p>
                </div>
                <div class="p1">
                    <p id="83">图4中:<i>T</i>代表配准损耗时间;scene代表四种图像变化场景。</p>
                </div>
                <div class="p1">
                    <p id="84">通过图3和图4的统计结果表明,相较于其他三种算法,本文算法能够在获得数量的优秀匹配点数量的情况下,平均配准准确度明显优于其他三种算法,平均配准损耗时间比SURF算法降低了12%,仅高于ORB算法。</p>
                </div>
                <h3 id="85" name="85" class="anchor-tag"><b>4 结束语</b></h3>
                <div class="p1">
                    <p id="86">本文通过对AKAZE算法的深入研究,针对目前的特征匹配算法无法在保证高的匹配准确度的同时保持较低的匹配时间损耗的问题,提出了AKAZE算法与KD-Tree和PROSAC融合匹配算法相结合的特征匹配算法。试验结果表明,本文提出的算法在不同图像里表现变化的情况都具有良好的鲁棒性,算法在保证足够数量最优匹配点和匹配准确度的情况下,降低了匹配损耗时间,有效地提高了算法的实时性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="106">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Matching Images with different resolutions">

                                <b>[1]</b> DUFOURNAUD Y,SCHMID C,HORAUD R.Matching images with different resolutions[J].Proceedings of the Computer Vision &amp; Pattern Recognition,2000,1(1):612-618.
                            </a>
                        </p>
                        <p id="108">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjczMzU0SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXpsVkwzTkpGYz1OajdCYXJP&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision,2004,60(2):91-110.
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Speeded-Up Robust Features (SURF)">

                                <b>[3]</b> BAY H,ESS A,TUYTELAARS T,et al.Speeded-up robust features[J].Computer Vision &amp; Image Understanding,2008,110(3):404-417.
                            </a>
                        </p>
                        <p id="112">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ORB:an efficient alternative to SIFT or SURF">

                                <b>[4]</b> RUBLEE E,RABAUD V,KONOLIGE K,et al.ORB:An efficient alternative to SIFT or SURF[C]//Barcelona,Spain:Computer Vision (ICCV),2011 IEEE international conference on.IEEE,2011:2564-2571.
                            </a>
                        </p>
                        <p id="114">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast explicit diffusion for accelerated features in nonlinear scale spaces">

                                <b>[5]</b> ALCANTARILLA P F,SOLUTIONS T.Fast explicit diffusion for accelerated features in nonlinear scale spaces[J].IEEE Trans.Patt.Anal.Mach.Intell,2011,34(7):1281-1298.
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scalable nearest neighbor algorithms for high dimensional data">

                                <b>[6]</b> MUJA M,LOWE D G.Scalable nearest neighbor algorithms for high dimensional data[J].Pattern Analysis &amp; Machine Intelligence IEEE Transactions on,2014,36(11):2227-2240.
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimised KD-trees for fast image descriptor matching">

                                <b>[7]</b> SILPA-ANAN C,HARTLEY R.Optimised KD-trees for fast image descriptor matching[C]//Anchorage,AK,USA:Computer Vision and Pattern Recognition,2008.CVPR 2008.IEEE Conference on.IEEE,2008:1-8.
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A 127 fps in full HD accelerator based on optimized AKAZE with efficiency and effectiveness for image feature extraction">

                                <b>[8]</b> JIANG G,LIU L,ZHU W,et al.A 127 fps in full hd accelerator based on optimized AKAZE with efficiency and effectiveness for image feature extraction[C]//San Francisco,CA:Proceedings of the 52nd Annual Design Automation Conference,ACM,2015:87.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DQZD201906032" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQZD201906032&amp;v=MDcwODhIOWpNcVk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVacUZ5L25WcnZCSVR6UmFyRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMwT2dHRXdIOG9tYjAvZ2pUVkRaVT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

