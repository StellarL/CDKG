<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141589472631250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJXYD201906015%26RESULT%3d1%26SIGN%3dCq7OkqN9BQxrdKMmiD7eByR%252bH2g%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JXYD201906015&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JXYD201906015&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXYD201906015&amp;v=MTkwNjhadVptRmlEbVc3N05MelhTYXJHNEg5ak1xWTlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#25" data-title="0 引言 ">0 引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#30" data-title="1 基于改进BING模型的行人候选窗口分割方法 ">1 基于改进BING模型的行人候选窗口分割方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#31" data-title="1.1 BING似物模型">1.1 BING似物模型</a></li>
                                                <li><a href="#41" data-title="1.2 改进的BING似物性模型">1.2 改进的BING似物性模型</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="2 基于边缘信息的行人候选框位置矫正 ">2 基于边缘信息的行人候选框位置矫正</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="2.1 图像预处理">2.1 图像预处理</a></li>
                                                <li><a href="#62" data-title="2.2 候选框位置矫正">2.2 候选框位置矫正</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="3 基于改进BING模型和边缘信息的行人检测算法 ">3 基于改进BING模型和边缘信息的行人检测算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#74" data-title="4 结果与分析 ">4 结果与分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="图1 改进模型与原始模型检测结果对比">图1 改进模型与原始模型检测结果对比</a></li>
                                                <li><a href="#56" data-title="图2 候选框偏移示意">图2 候选框偏移示意</a></li>
                                                <li><a href="#61" data-title="图3 扩大后的候选区域处理前后效果">图3 扩大后的候选区域处理前后效果</a></li>
                                                <li><a href="#68" data-title="图4 边缘响应值与图像位置关系">图4 边缘响应值与图像位置关系</a></li>
                                                <li><a href="#70" data-title="图5 候选框位置更新前后示意">图5 候选框位置更新前后示意</a></li>
                                                <li><a href="#73" data-title="图6 本文行人检测算法流程">图6 本文行人检测算法流程</a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;表1 正样本实验结果对比&lt;/b&gt;"><b>表1 正样本实验结果对比</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;表2 负样本实验结果对比&lt;/b&gt;"><b>表2 负样本实验结果对比</b></a></li>
                                                <li><a href="#83" data-title="图7 本文算法部分检测结果">图7 本文算法部分检测结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Papageorgiou C P, Oren M, Poggio T.A general framework for object detection[C]//Sixth International Conference on Computer Vision.Washington:IEEE, 1998:555-562." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A general framework for object detection">
                                        <b>[1]</b>
                                         Papageorgiou C P, Oren M, Poggio T.A general framework for object detection[C]//Sixth International Conference on Computer Vision.Washington:IEEE, 1998:555-562.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Mu Y, Yan S, Liu Y, et al.Discriminative local binary patterns for human detection in personal album[C]// IEEE Conference on Computer Vision and Pattern Recognition.Washington:IEEE, 2008:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative local binary patterns for human detection in personal album">
                                        <b>[2]</b>
                                         Mu Y, Yan S, Liu Y, et al.Discriminative local binary patterns for human detection in personal album[C]// IEEE Conference on Computer Vision and Pattern Recognition.Washington:IEEE, 2008:1-8.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Wang X, Han T X, Yan S.An HOG-LBP human detector with partial occlusion handling[C]//IEEE 12th International Conference on Computer Vision.Washington:IEEE, 2009:32-39." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An HOG-LBP human detector w ith partial occlusion handling">
                                        <b>[3]</b>
                                         Wang X, Han T X, Yan S.An HOG-LBP human detector with partial occlusion handling[C]//IEEE 12th International Conference on Computer Vision.Washington:IEEE, 2009:32-39.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Dalal N, Triggs B.Histograms of oriented gradients for human detection[C]// IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington:IEEE, 2005:886-893." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented gradients for human detection">
                                        <b>[4]</b>
                                         Dalal N, Triggs B.Histograms of oriented gradients for human detection[C]// IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington:IEEE, 2005:886-893.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Doll&#225;r P, Tu Z, Perona P, et al.Integral channel features[C] //British Machine Vision Conference, 2009:556-567." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Integral Channel Features">
                                        <b>[5]</b>
                                         Doll&#225;r P, Tu Z, Perona P, et al.Integral channel features[C] //British Machine Vision Conference, 2009:556-567.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Felzenszwalb P F, Girshick R B, McAllester D.Cascade object detection with deformable part models[C]// IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .Washington:IEEE, 2010:2241-2248." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cascade object detection with deformable part models">
                                        <b>[6]</b>
                                         Felzenszwalb P F, Girshick R B, McAllester D.Cascade object detection with deformable part models[C]// IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .Washington:IEEE, 2010:2241-2248.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 陈锐, 王敏, 陈肖.基于PCA降维的HOG与LBP融合的行人检测[J].信息技术, 2015 (2) :101-105." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201502029&amp;v=MTg3MjFTblJaTEc0SDlUTXJZOUhiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GaURtVzc3Tkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         陈锐, 王敏, 陈肖.基于PCA降维的HOG与LBP融合的行人检测[J].信息技术, 2015 (2) :101-105.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Prasanna D, Prabhakar M.An effiecient human tracking system using Haar-like and hog feature extraction[J].Cluster Computing, 2018 (11) :1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An effiecient human tracking system using Haar-like and hog feature extraction">
                                        <b>[8]</b>
                                         Prasanna D, Prabhakar M.An effiecient human tracking system using Haar-like and hog feature extraction[J].Cluster Computing, 2018 (11) :1-8.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Cheng M M, Zhang Z, Lin W Y, et al.BING:Binarized normed gradients for objectness estimation at 300fps[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014:3286-3293." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Binarized normed gradients for objectnessestimation at 300fps">
                                        <b>[9]</b>
                                         Cheng M M, Zhang Z, Lin W Y, et al.BING:Binarized normed gradients for objectness estimation at 300fps[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014:3286-3293.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 罗诗途, 罗飞路, 张玘, 等.基于梯度调整的矩不变自动阈值图像分割算法[J].电子技术应用, 2004, 30 (6) :11-13." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY200406004&amp;v=MTE4ODFUZkJkN0c0SHRYTXFZOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GaURtVzc3Tkk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         罗诗途, 罗飞路, 张玘, 等.基于梯度调整的矩不变自动阈值图像分割算法[J].电子技术应用, 2004, 30 (6) :11-13.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 赵文清, 严海, 邵绪强.改进的非极大值抑制算法的目标检测[J].中国图象图形学报, 2018, 23 (11) :1676-1685." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201811005&amp;v=MTMwODBQeXJmYkxHNEg5bk5ybzlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRmlEbVc3N04=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         赵文清, 严海, 邵绪强.改进的非极大值抑制算法的目标检测[J].中国图象图形学报, 2018, 23 (11) :1676-1685.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JXYD" target="_blank">机械与电子</a>
                2019,37(06),59-63             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于改进</b>BING<b>模型和边缘信息的行人检测算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E5%A4%A9%E6%98%8E&amp;code=39995286&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱天明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%87%AF&amp;code=10736544&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘凯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E8%B1%AA%E5%BF%97&amp;code=41150513&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘豪志</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%A4%A7%E5%AD%A6%E6%9C%BA%E7%94%B5%E5%AD%A6%E9%99%A2&amp;code=0014291&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京航空航天大学机电学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对行人检测中传统多尺度滑动窗口遍历搜索计算量大, 计算速度慢的问题, 提出了一种基于改进BING模型和边缘信息的行人检测算法。首先, 通过样本采样规则的确定、样本阈值的选择和搜索尺度空间的优化对BING似物检测模型进行了改进;然后, 针对提取的候选框存在偏移的问题, 提出了基于边缘信息的候选框位置矫正方法;最后, 利用经典的HOG-SVM行人检测算法, 对提取的行人候选框进行最终的行人识别。实验结果表明, 该算法在保证行人检测率的前提下有效提高了行人检测的实时性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A1%8C%E4%BA%BA%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">行人检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BING%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BING模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BE%B9%E7%BC%98%E4%BF%A1%E6%81%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">边缘信息;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HOG%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HOG特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    朱天明 (1992-) , 男, 江苏泰州人, 硕士研究生, 研究方向为机器视觉、数字图像处理等;;
                                </span>
                                <span>
                                    *刘凯 (1981-) , 男, 江苏淮安人, 博士, 副教授, 研究方向为仿生机器人、数控技术等。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-18</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (51405229);</span>
                                <span>江苏省自然科学基金资助项目 (BK20151470);</span>
                    </p>
            </div>
                    <h1><b>Pedestrian Detection Algorithm Based on Improved BING Model and Edge Information</b></h1>
                    <h2>
                    <span>ZHU Tianming</span>
                    <span>LIU Kai</span>
                    <span>LIU Haozhi</span>
            </h2>
                    <h2>
                    <span>College of Mechanical and Electronic Engineering, Nanjing University of Aeronautics and Astronautics</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem of large computational complexity and slow calculation speed in traditional multi-scale sliding window traversal search in pedestrian detection, a pedestrian detection algorithm based on improved BING model and edge information was proposed. Firstly, the BING similarity detection model was improved through the determination of sampling rules, the selection of sample thresholds and the optimization of search scale space. Then, aiming at the problem of the offset of the extracted candidate box, a method of correcting the position of the candidate box based on edge information was proposed. Finally, the final pedestrian recognition was performed on the extracted pedestrian candidate frame by using the classical HOG-SVM pedestrian detection algorithm. The experimental results show that the proposed algorithm can effectively improve the real-time performance of pedestrian detection on the premise of ensuring the pedestrian detection rate.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=pedestrian%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">pedestrian detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BING%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BING model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=edge%20information&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">edge information;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HOG%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HOG feature;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-18</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="25" name="25" class="anchor-tag">0 引言</h3>
                <div class="p1">
                    <p id="26">行人检测能够对视频图像序列中的行人进行识别和定位。在人机交互、智能交通和智能驾驶辅助系统等领域有着广泛的应用前景。但是由于行人姿态的多样性、行人存在的遮挡现象, 以及光照背景的复杂多变导致行人检测的效果仍然不够理想。此外, 行人检测的实时性也面临较大的挑战。</p>
                </div>
                <div class="p1">
                    <p id="27">目前, 基于视觉传感器的行人检测方法主要以基于统计学习的方法为主, 该方法主要通过行人特征描述算子提取行人的特征, 然后利用训练的行人分类器对其进行分类识别。常见的行人特征描述算子主要有Harr小波特征<citation id="88" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、LBP特征<citation id="91" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>、HOG (histograms of oriented gradients) 特征<citation id="89" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>和ICF (integral channel features) <citation id="90" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等, 分类器则以SVM、AdaBoost和决策树为主。HOG特征是由<citation id="93" type="reference"><link href="9" rel="bibliography" />Dalal等于2005</citation>年提出的, 它是行人检测领域中最经典的特征描述算子, HOG-SVM检测算法是行人检测中最为经典的检测框架, 至今很多行人检测算法<citation id="92" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>都是以HOG特征为基础的。</p>
                </div>
                <div class="p1">
                    <p id="28">上述方法从原理上讲都采用了传统的多尺度滑动窗口遍历搜索法来依次提取不同的行人候选窗口, 然后分别对这些窗口进行特征提取和识别。这种方法虽然简单直接, 但是需要进行全局搜索, 计算大量不必要的非行人窗口, 从而导致检测效率低下, 对于一幅<i>N</i>×<i>N</i>大小图像, 其分割的候选窗口数量达到<i>N</i><sup>4</sup>级别。程明明等<citation id="94" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出的二值化规范梯度 (BING) 似物模型检测算法, 可以凭借一些简单的原子操作快速地实现图像候选区域的搜索, 在使用1 000个候选窗口和颜色空间的情况下其候选框分割准确度能够达到99.5%, 并且在一个简单的桌面CPU上运行速度达到了300 fps。</p>
                </div>
                <div class="p1">
                    <p id="29">基于此, 提出了一种基于改进BING似物模型的行人候选框分割方法, 通过在行人前景分割阶段引入改进的BING似物检测模型来取代传统的多尺度滑动窗口遍历搜索法, 快速定位可能存在行人的候选框, 然后根据行人的垂直边缘信息对初步定位的行人候选框进行位置矫正, 最后采用HOG-SVM行人检测算法实现对候选框中行人的快速检测, 从而达到提高检测实时性的目的。</p>
                </div>
                <h3 id="30" name="30" class="anchor-tag">1 基于改进BING模型的行人候选窗口分割方法</h3>
                <h4 class="anchor-tag" id="31" name="31">1.1 BING似物模型</h4>
                <div class="p1">
                    <p id="32">BING似物模型检测算法将所有检测窗口均缩放归一化为8像素×8像素大小, 然后计算每个窗口的梯度从而得到1个64维的梯度值, 即规范梯度 (NG) 特征。该特征对于窗口内的一般性物体, 其目标的位置、尺度和横纵比都具有良好的稳定性。BING算法巧妙地对NG特征做了近似运算进行加速处理, 计算公式为</p>
                </div>
                <div class="p1">
                    <p id="33" class="code-formula">
                        <mathml id="33"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>l</mi></msub><mo>=</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>g</mi></msub></mrow></msubsup><mn>2</mn></mstyle><msup><mrow></mrow><mrow><mn>8</mn><mo>-</mo><mi>k</mi></mrow></msup><mspace width="0.25em" /><mi>b</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>l</mi></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="34"><i>b</i><sub><i>k</i>, <i>l</i></sub>为BING特征的提取值;<i>g</i><sub><i>l</i></sub>为BING特征提取值前 <i>N</i><sub><i>g</i></sub>位的近似值, 即BING特征。</p>
                </div>
                <div class="p1">
                    <p id="35">BING似物模型采用一个二级级联结构的支持向量机, 对提取的BING特征进行筛选并检测图像中的所有物体。先利用第1级的SVM线性模型<i>w</i>∈<i>R</i><sup>64</sup>计算所有扫描窗口的得分, 分数越高表示其包含物体的可能性更大, 计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="36" class="code-formula">
                        <mathml id="36"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>s</mi><msub><mrow></mrow><mi>l</mi></msub><mo>=</mo><mo>&lt;</mo><mi>w</mi><mo>, </mo><mi>g</mi><msub><mrow></mrow><mi>l</mi></msub><mo>&gt;</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>l</mi><mo>=</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="37"><i>s</i><sub><i>l</i></sub>为过滤得分;<i>g</i><sub><i>l</i></sub>为NG特征;<i>l</i>为坐标;<i>i</i>为尺度; (<i>x</i>, <i>y</i>) 为窗口位置。</p>
                </div>
                <div class="p1">
                    <p id="38">因为各个大小的窗口其所对应的包含物体的概率值也不相同, BING算法采用了第2级的SVM分类器对上一步中提取的所有候选窗口的似物性得分进行计算, 各个尺寸下的似物得分为</p>
                </div>
                <div class="p1">
                    <p id="39" class="code-formula">
                        <mathml id="39"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>o</mi><msub><mrow></mrow><mi>l</mi></msub><mo>=</mo><mspace width="0.25em" /><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>×</mo><mi>s</mi><msub><mrow></mrow><mi>l</mi></msub><mo>+</mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="40"><i>v</i><sub><i>i</i></sub>, <i>t</i><sub><i>i</i></sub>∈<i>R</i>, 针对不同尺度<i>i</i>的窗口, 得到不同的学习系数。最后, 对所窗口的似物得分进行排序, 并选择得分排名靠前的一些窗口作为似物候选窗口。</p>
                </div>
                <h4 class="anchor-tag" id="41" name="41">1.2 改进的BING似物性模型</h4>
                <div class="p1">
                    <p id="42">BING似物性模型是针对所有一般性物体候选框的提取方法, 如果直接采用原始BING似物模型, 在分割出行人候选框的同时还会分割出大量非行人目标候选框, 从而增加了行人检测阶段的计算量, 影响检测算法的实时性。因此, 为了使检测模型更具有针对性, 本文选取INRIA行人样本库作为模型的训练样本, 在此基础上通过正负样本采样规则的制定、正负样本阈值的选择, 以及搜索尺度空间的优化对BING似物性模型进行了改进, 主要工作如下所述。</p>
                </div>
                <h4 class="anchor-tag" id="43" name="43">1.2.1 正负样本采样规则确定</h4>
                <div class="p1">
                    <p id="44">对INRIA行人库中的正样本进行多尺度采样, 在16像素×16像素至128像素×128像素尺度内, 以8像素×8像素大小递增共16种尺度, 对行人库中含有行人图片的正样本进行随机采样, 若采样尺度<i>S</i>与对应的行人标注框<i>B</i><sub><i>gt</i></sub>满足如式 (5) 所示的面积交比要求, 则将<i>S</i>定义为正例。</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>S</mi><mstyle displaystyle="true"><mo>∩</mo><mi>B</mi></mstyle><msub><mrow></mrow><mrow><mi>g</mi><mi>t</mi></mrow></msub></mrow><mrow><mi>S</mi><mo>+</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>g</mi><mi>t</mi></mrow></msub><mo>-</mo><mi>S</mi><mstyle displaystyle="true"><mo>∩</mo><mi>B</mi></mstyle><msub><mrow></mrow><mrow><mi>g</mi><mi>t</mi></mrow></msub></mrow></mfrac><mo>&gt;</mo><mn>0</mn><mo>.</mo><mn>6</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">相反, 若采样尺度与标注框面积交比小于0.4, 则将该采样图像视为负例。与此同时, 为了增加负样本的丰富性, 在INRIA行人库的不含行人的负样本图片中随机截取一定数量的图像作为负样本的补充。</p>
                </div>
                <h4 class="anchor-tag" id="47" name="47">1.2.2 正负样本阈值优化</h4>
                <div class="p1">
                    <p id="48">原始BING模型将与正样本相交比例超过0.5的图像采样定义为正例, 这在一定程度上会导致过多的检测结果, 也容易导致正样本的定位偏移过大。但是如果将阈值调整得过大, 会导致似物模型分割的正确率降低。因此, 对阈值进行了微调, 将正样本的阈值调整为0.6, 负样本的阈值调整为0.4。</p>
                </div>
                <h4 class="anchor-tag" id="49" name="49">1.2.3 搜索尺度空间优化</h4>
                <div class="p1">
                    <p id="50">BING似物模型能检测出所有一般性物体, 包括实际环境中汽车、自行车等尺寸宽度明显大于高度的物体, 这与行人的外形特征明显不符合。原始BING模型预先设定了36种不同大小的尺度{ (<i>W</i>, <i>H</i>) |<i>W</i>, <i>H</i>∈ (10, 20, 40, 80, 160, 320) }, 这些尺度的图像中最有可能包含各种完整的物体, 考虑到行人较为固定的长宽比, 本文对原始模型进行了相应的简化, 挑选了21种搜索尺度{ (<i>W</i>, <i>H</i>) |<i>W</i>≥<i>H</i>, <i>W</i>, <i>H</i>∈ (10, 20, 40, 80, 160, 320) }。</p>
                </div>
                <div class="p1">
                    <p id="51">本文通过 INRIA行人样本库测试集对改进的BING似物模型进行验证, 并与原始模型进行对比, 检测结果如图1所示。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JXYD201906015_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 改进模型与原始模型检测结果对比" src="Detail/GetImg?filename=images/JXYD201906015_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 改进模型与原始模型检测结果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JXYD201906015_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="53">由图1可知, 改进模型相对于原始模型其提取的行人候选框数量大大减少, 并且候选框的分割更具有针对性, 但是原始模型和改进模型提取的候选框分割质量却参差不齐, 存在一定的偏移现象, 需要对候选框位置进行矫正。</p>
                </div>
                <h3 id="54" name="54" class="anchor-tag">2 基于边缘信息的行人候选框位置矫正</h3>
                <div class="p1">
                    <p id="55">提取的行人候选框一般会发生不同程度的偏移, 通常可分为垂直偏移和水平偏移, 如图2所示。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JXYD201906015_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 候选框偏移示意" src="Detail/GetImg?filename=images/JXYD201906015_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 候选框偏移示意  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JXYD201906015_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="57">对于位置偏移程度较大的候选框, 一旦送入下一阶段的行人识别, 分类器很容易发生误判, 从而导致漏检。</p>
                </div>
                <div class="p1">
                    <p id="58">鉴于此, 考虑到行人在垂直方向具有明显的边缘特征, 提出了基于边缘信息的行人候选框位置偏移矫正方法。该方法由2部分组成, 分别为图像预处理和候选框位置矫正。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59">2.1 图像预处理</h4>
                <div class="p1">
                    <p id="60">通过将改进BING模型分割的候选框向其四周扩大1.4～1.8倍, 然后对扩大的图像区域进行中值滤波去除噪声干扰, 利用Sobel算子垂直卷积提取该区域垂直方向的边缘信息, 最后采用基于矩不变的边缘阈值分割<citation id="95" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>进一步过滤非前景目标的边缘信息。图2a中行人候选区域的处理结果如图3所示。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JXYD201906015_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 扩大后的候选区域处理前后效果" src="Detail/GetImg?filename=images/JXYD201906015_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 扩大后的候选区域处理前后效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JXYD201906015_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="62" name="62">2.2 候选框位置矫正</h4>
                <div class="p1">
                    <p id="63">为了确定行人候选框的正确位置, 分别在边缘阈值分割后的图像的水平方向和竖直方向进行边缘投影, 其计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mi>x</mi><mo>&lt;</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mi>y</mi><mo>&lt;</mo><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mi>G</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>G</mi><msub><mrow></mrow><mi>v</mi></msub><mspace width="0.25em" /><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mo>, </mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>≥</mo><mi>Τ</mi><msub><mrow></mrow><mi>v</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn><mo>, </mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>&lt;</mo><mi>Τ</mi><msub><mrow></mrow><mi>v</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65"><i>S</i> (<i>x</i>, <i>y</i>) 为边缘响应值;<i>T</i><sub><i>v</i></sub>为边缘阈值分割得到的阈值;<i>x</i><sub><i>i</i></sub>, <i>x</i><sub><i>j</i></sub>分别为滑动窗口的左右边界;<i>y</i><sub><i>i</i></sub> , <i>y</i><sub><i>j</i></sub>分别为滑动窗口的上下边界, 且满足如式 (8) 的约束条件。</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>w</mi></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>h</mi></mtd></mtr><mtr><mtd><mi>x</mi><msub><mrow></mrow><mi>a</mi></msub><mo>≤</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>≤</mo><mi>x</mi><msub><mrow></mrow><mi>b</mi></msub></mtd></mtr><mtr><mtd><mi>y</mi><msub><mrow></mrow><mi>a</mi></msub><mo>≤</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>&lt;</mo><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo>≤</mo><mi>y</mi><msub><mrow></mrow><mi>b</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67"><i>w</i>, <i>h</i>分别为滑动窗口的宽度和高度;<i>x</i><sub><i>a</i></sub>, <i>x</i><sub><i>b</i></sub>分别为尺寸扩大后的候选区域的左右边界;<i>y</i><sub><i>a</i></sub>, <i>y</i><sub><i>b</i></sub>分别为上下边界。将提取出的行人候选框在扩大后的图像候选区域的垂直方向和水平方向分别进行平移滑动, 计算其在各个方向坐标下的边缘投影累计响应值。计算得到的边缘响应值与图像的位置关系如图4所示。</p>
                </div>
                <div class="area_img" id="68">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JXYD201906015_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 边缘响应值与图像位置关系" src="Detail/GetImg?filename=images/JXYD201906015_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 边缘响应值与图像位置关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JXYD201906015_068.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="69">本文通过 INRIA行人样本库测试集, 对改进的BING似物模型提取的部分行人候选框进行位置矫正验证。由图4可知, 在图像候选区域的第76列处垂直边缘响应值最大, 第89行处水平边缘响应值最大。因此将候选框的中心位置移动至候选区域坐标 (76, 89) 处, 更新前后的候选框位置如图5所示, 可以看出更新后的候选框正确覆盖了行人。</p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JXYD201906015_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 候选框位置更新前后示意" src="Detail/GetImg?filename=images/JXYD201906015_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 候选框位置更新前后示意  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JXYD201906015_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="71" name="71" class="anchor-tag">3 基于改进BING模型和边缘信息的行人检测算法</h3>
                <div class="p1">
                    <p id="72">基于上文提出的改进BING模型和基于边缘信息的行人候选框矫正方法, 构建了一种快速的行人检测算法, 算法流程如图6所示。该算法主要由训练阶段和检测阶段2部分组成。训练阶段主要负责训练上文改进的BING似物模型和HOG-SVM行人检测模型;在算法的检测阶段依次进行基于改进BING模型的行人候选框分割、行人候选框非极大值抑制<citation id="96" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、基于行人边缘信息矫正行人候选框, 以及加载HOG-SVM模型对矫正的候选框进行最终的行人检测。</p>
                </div>
                <div class="area_img" id="73">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JXYD201906015_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 本文行人检测算法流程" src="Detail/GetImg?filename=images/JXYD201906015_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 本文行人检测算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JXYD201906015_073.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="74" name="74" class="anchor-tag">4 结果与分析</h3>
                <div class="p1">
                    <p id="75">实验平台为个人PC, 处理器Intel i5-2430M, 3.2 GHz, 8 GB内存;开发环境为OpenCV2.4.11和Visual Studio2010。本文选取公开的INRIA行人数据库的训练集, 训练改进的BING模型和HOG-SVM行人检测模型。同时, 为了提高行人检测SVM分类器的性能, 引入困难样本训练机制。</p>
                </div>
                <div class="p1">
                    <p id="76">实验分别选取3种不同尺寸大小的行人测试集, 分别为76像素×134像素共1 126张、96像素×160像素共2 416张、110像素×180像素共2 416张。其中, 负样本大小不一共1 218张。主要从召回率和平均检测时间2项指标来评估算法性能, 召回率可由下式求得:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78"><i>TP</i>为检测为正例实际为正例的样本, 即召回的样本数;<i>FN</i>为检测为负例实际为正例的样本, 即漏检的样本数。</p>
                </div>
                <div class="p1">
                    <p id="79">本文选取的正样本测试结果如表1所示, 其中, HOG-SVM指代传统多尺度滑动窗口算法, BHOG-SVM指代本文算法。为了测试2种算法在负样本上的检测性能, 选取了INRIA中大小不一的453张不含行人的样本图像, 其中图片最小尺寸为320像素×240像素, 最大尺寸为640像素×480像素, 测试结果如表2所示。</p>
                </div>
                <div class="area_img" id="80">
                    <p class="img_tit"><b>表1 正样本实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="80" border="1"><tr><td><br />检测算法</td><td>测试集<br />/像素</td><td>召回<br />样本</td><td>召回率<br />/%</td><td>平均用时<br />/ (ms/张) </td></tr><tr><td><br />HOG-SVM</td><td>76×134</td><td>989</td><td>87.8</td><td>3.8</td></tr><tr><td><br />BHOG-SVM</td><td>76×134</td><td>998</td><td>88.6</td><td>2.2</td></tr><tr><td><br />HOG-SVM</td><td>96×160</td><td>2 138</td><td>88.5</td><td>12.1</td></tr><tr><td><br />BHOG-SVM</td><td>96×160</td><td>2 208</td><td>91.4</td><td>5.7</td></tr><tr><td><br />HOG-SVM</td><td>110×180</td><td>2 239</td><td>92.7</td><td>16.9</td></tr><tr><td><br />BHOG-SVM</td><td>110×180</td><td>2 259</td><td>93.5</td><td>6.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="81">
                    <p class="img_tit"><b>表2 负样本实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="81" border="1"><tr><td><br />检测算法</td><td>误检数目</td><td>误检率/%</td><td>平均用时/ (ms/张) </td></tr><tr><td><br />HOG+SVM</td><td>216</td><td>17.7</td><td>138</td></tr><tr><td><br />BHOG+SVM</td><td>132</td><td>10.8</td><td>32</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="82">由表1可以看出, 本文算法的检测率相比多尺度滑动窗口算法改善不大, 略优于传统算法。这主要由于本文算法和传统算法在最终的行人检测阶段都采用同一个行人分类器。但是本文算法在检测速度方面却明显优于多尺度滑动窗口算法。随着图像尺寸的增大, 本文算法的检测速度优势逐渐明显, 对于110像素×180像素大小的测试图像, 本文算法的检测速度接近传统算法的3倍, 而表2中负样本的检测速度达到了传统算法的4倍多。此外, 由表2可以看出, 本文算法的误检率比传统滑动窗口法降低了6.9%, 更加有效地抑制了虚警, 这主要由于本文采用的改进BING检测机制更有针对性地提取候选窗口。本文算法在INRIA行人样本库测试集中的部分检测结果如图7所示。</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JXYD201906015_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 本文算法部分检测结果" src="Detail/GetImg?filename=images/JXYD201906015_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 本文算法部分检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JXYD201906015_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="84">由图7可知, 在各个场景下本文算法都能够较好地定位出行人的位置, 能够满足一般场景下的行人检测和定位要求。</p>
                </div>
                <h3 id="85" name="85" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="86">为了提高行人检测的实时性, 引入了BING似物性检测机制, 并针对行人这个特定的研究对象对该模型进行了针对性的改进, 从而达到快速分割行人候选窗口的目的。</p>
                </div>
                <div class="p1">
                    <p id="87">为了改善模型提取出的候选窗口的质量, 提出一种基于行人边缘信息的候选框位置矫正方法, 改善了候选窗口存在偏移的问题。实验表明, 该方法不仅提高了行人检测的实时性, 而且还有效抑制了检测系统的虚警率。在后续的研究中, 可以考虑将该候选窗口分割方法移植到更加高效的行人检测框架, 以提高行人的检测率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A general framework for object detection">

                                <b>[1]</b> Papageorgiou C P, Oren M, Poggio T.A general framework for object detection[C]//Sixth International Conference on Computer Vision.Washington:IEEE, 1998:555-562.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative local binary patterns for human detection in personal album">

                                <b>[2]</b> Mu Y, Yan S, Liu Y, et al.Discriminative local binary patterns for human detection in personal album[C]// IEEE Conference on Computer Vision and Pattern Recognition.Washington:IEEE, 2008:1-8.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An HOG-LBP human detector w ith partial occlusion handling">

                                <b>[3]</b> Wang X, Han T X, Yan S.An HOG-LBP human detector with partial occlusion handling[C]//IEEE 12th International Conference on Computer Vision.Washington:IEEE, 2009:32-39.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Histograms of oriented gradients for human detection">

                                <b>[4]</b> Dalal N, Triggs B.Histograms of oriented gradients for human detection[C]// IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington:IEEE, 2005:886-893.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Integral Channel Features">

                                <b>[5]</b> Dollár P, Tu Z, Perona P, et al.Integral channel features[C] //British Machine Vision Conference, 2009:556-567.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cascade object detection with deformable part models">

                                <b>[6]</b> Felzenszwalb P F, Girshick R B, McAllester D.Cascade object detection with deformable part models[C]// IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .Washington:IEEE, 2010:2241-2248.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201502029&amp;v=MTYxMDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRmlEbVc3N05MU25SWkxHNEg5VE1yWTlIYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 陈锐, 王敏, 陈肖.基于PCA降维的HOG与LBP融合的行人检测[J].信息技术, 2015 (2) :101-105.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An effiecient human tracking system using Haar-like and hog feature extraction">

                                <b>[8]</b> Prasanna D, Prabhakar M.An effiecient human tracking system using Haar-like and hog feature extraction[J].Cluster Computing, 2018 (11) :1-8.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Binarized normed gradients for objectnessestimation at 300fps">

                                <b>[9]</b> Cheng M M, Zhang Z, Lin W Y, et al.BING:Binarized normed gradients for objectness estimation at 300fps[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014:3286-3293.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJY200406004&amp;v=MjY1MjhIdFhNcVk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZpRG1XNzdOSVRmQmQ3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 罗诗途, 罗飞路, 张玘, 等.基于梯度调整的矩不变自动阈值图像分割算法[J].电子技术应用, 2004, 30 (6) :11-13.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201811005&amp;v=MzE3NDJyZmJMRzRIOW5Ocm85RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZpRG1XNzdOUHk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 赵文清, 严海, 邵绪强.改进的非极大值抑制算法的目标检测[J].中国图象图形学报, 2018, 23 (11) :1676-1685.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JXYD201906015" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXYD201906015&amp;v=MTkwNjhadVptRmlEbVc3N05MelhTYXJHNEg5ak1xWTlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVRrR1ZNakRMQkZrb2lIQ3ZpNFBEdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
