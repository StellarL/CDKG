

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140168625888750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dTJLT201905010%26RESULT%3d1%26SIGN%3d0GiDdseNVfA8NPgoIFZz8ZrGzoQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJLT201905010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJLT201905010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201905010&amp;v=MDc1MzR6cXFCdEdGckNVUjdxZlp1Wm9GeUhrVTc3Tk1TZkhlckc0SDlqTXFvOUVaSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="一、引 言 ">一、引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="二、模型介绍 ">二、模型介绍</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title=" (&lt;b&gt;一) 广义线性模型&lt;/b&gt; (GLM) "> (<b>一) 广义线性模型</b> (GLM) </a></li>
                                                <li><a href="#54" data-title=" (&lt;b&gt;二) 支持向量机&lt;/b&gt; (SVM) "> (<b>二) 支持向量机</b> (SVM) </a></li>
                                                <li><a href="#59" data-title=" (&lt;b&gt;三) 随机森林&lt;/b&gt; (Random Forest) "> (<b>三) 随机森林</b> (Random Forest) </a></li>
                                                <li><a href="#68" data-title=" (&lt;b&gt;四) 神经网络&lt;/b&gt; (ANN) &lt;b&gt;和深度神经网络&lt;/b&gt; (DNN) &lt;b&gt;模型&lt;/b&gt;"> (<b>四) 神经网络</b> (ANN) <b>和深度神经网络</b> (DNN) <b>模型</b></a></li>
                                                <li><a href="#76" data-title=" (&lt;b&gt;五) 梯度提升算法&lt;/b&gt; (Gradient Boosting) "> (<b>五) 梯度提升算法</b> (Gradient Boosting) </a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="三、数据介绍 ">三、数据介绍</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title=" (&lt;b&gt;一) 数据集&lt;/b&gt;AutoClaim"> (<b>一) 数据集</b>AutoClaim</a></li>
                                                <li><a href="#87" data-title=" (&lt;b&gt;二) 数据集&lt;/b&gt;Tangshan"> (<b>二) 数据集</b>Tangshan</a></li>
                                                <li><a href="#89" data-title=" (&lt;b&gt;三) 数据预处理&lt;/b&gt;"> (<b>三) 数据预处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="四、实证结果分析 ">四、实证结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#97" data-title=" (&lt;b&gt;一) 各种方法的最优模型和最优参数&lt;/b&gt;"> (<b>一) 各种方法的最优模型和最优参数</b></a></li>
                                                <li><a href="#100" data-title=" (&lt;b&gt;二) 各种方法的比较分析&lt;/b&gt;"> (<b>二) 各种方法的比较分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#122" data-title="五、结 论 ">五、结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#128" data-title="&lt;b&gt;附录&lt;/b&gt;:有序Lorenz曲线和Gini系数及其计算方法。 "><b>附录</b>:有序Lorenz曲线和Gini系数及其计算方法。</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="&lt;b&gt;图&lt;/b&gt;1 &lt;b&gt;神经元结构图&lt;/b&gt;"><b>图</b>1 <b>神经元结构图</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;数据集汇总表&lt;/b&gt;"><b>表</b>1 <b>数据集汇总表</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;数据集&lt;/b&gt;AutoClaim&lt;b&gt;的变量信息表&lt;/b&gt;"><b>表</b>2 <b>数据集</b>AutoClaim<b>的变量信息表</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;数据集&lt;/b&gt;Tangshan&lt;b&gt;的变量信息表&lt;/b&gt;"><b>表</b>3 <b>数据集</b>Tangshan<b>的变量信息表</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;数据集&lt;/b&gt;Tangshan&lt;b&gt;连续性变量描述性统计分析表&lt;/b&gt;"><b>表</b>4 <b>数据集</b>Tangshan<b>连续性变量描述性统计分析表</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;表&lt;/b&gt;5 &lt;b&gt;数据集&lt;/b&gt;Tangshan&lt;b&gt;中分类变量描述性统计分析表&lt;/b&gt;"><b>表</b>5 <b>数据集</b>Tangshan<b>中分类变量描述性统计分析表</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;表&lt;/b&gt;6 &lt;b&gt;各方法与广义线性模型的&lt;/b&gt;MSE&lt;b&gt;比较表&lt;/b&gt;"><b>表</b>6 <b>各方法与广义线性模型的</b>MSE<b>比较表</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;不同方法结果比较图&lt;/b&gt;"><b>图</b>2 <b>不同方法结果比较图</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;表&lt;/b&gt;7 &lt;b&gt;各方法与广义线性模型的&lt;/b&gt;MAE&lt;b&gt;比较表&lt;/b&gt;"><b>表</b>7 <b>各方法与广义线性模型的</b>MAE<b>比较表</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表&lt;/b&gt;8 &lt;b&gt;各方法与广义线性模型的&lt;/b&gt;Gini&lt;b&gt;系数比较表&lt;/b&gt;"><b>表</b>8 <b>各方法与广义线性模型的</b>Gini<b>系数比较表</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;图&lt;/b&gt;3 Lorenz&lt;b&gt;曲线示例&lt;/b&gt;:Car&lt;b&gt;数据集与&lt;/b&gt;GLM&lt;b&gt;方法图&lt;/b&gt;"><b>图</b>3 Lorenz<b>曲线示例</b>:Car<b>数据集与</b>GLM<b>方法图</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="171">


                                    <a id="bibliography_1" title=" 李扬, 许文甫, 马双鸽.污染数据的稳健稀疏成组变量选择方法研究[J].统计与信息论坛, 2018 (6) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201806005&amp;v=Mjg5MzZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeUhrVTc3Tk1TZkhlckc0SDluTXFZOUY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李扬, 许文甫, 马双鸽.污染数据的稳健稀疏成组变量选择方法研究[J].统计与信息论坛, 2018 (6) .
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_2" title=" 张儒斌, 刘树林, 张超锋, 等.互联网环境下基于消费者搜索的酒店入住率预测研究[J].统计与信息论坛, 2018 (5) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201803014&amp;v=MDQyMDBNU2ZIZXJHNEg5bk1ySTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlIa1U3N04=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         张儒斌, 刘树林, 张超锋, 等.互联网环境下基于消费者搜索的酒店入住率预测研究[J].统计与信息论坛, 2018 (5) .
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     戴之遥.梯度Boosting算法在车险定价中的应用[D].北京:中国人民大学, 2017.</a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_4" title=" 孟生旺, 李天博, 高光远.基于机器学习算法的车险索赔概率与累积赔款预测[J].保险研究, 2017 (10) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201710005&amp;v=MDMxMTZVNzdOSnpYU1pMRzRIOWJOcjQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVab0Z5SGs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         孟生旺, 李天博, 高光远.基于机器学习算法的车险索赔概率与累积赔款预测[J].保险研究, 2017 (10) .
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_5" title=" 孟生旺, 黄一凡.驾驶行为保险的风险预测模型研究[J].保险研究, 2018 (8) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201808003&amp;v=MjA5NzA1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlIa1U3N05KelhTWkxHNEg5bk1wNDlGWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         孟生旺, 黄一凡.驾驶行为保险的风险预测模型研究[J].保险研究, 2018 (8) .
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_6" title=" Guelman L.Gradient Boosting Trees for Auto Insurance Loss Cost Modeling and Prediction[J].Expert Systems with Applications, 2012, 39 (3) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638247&amp;v=MTY3NjhlcnFRVE1ud1plWnRGaW5sVXJuSUtWOFVheGM9TmlmT2ZiSzdIdEROcW85RVl1Z0hEbmcrb0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Guelman L.Gradient Boosting Trees for Auto Insurance Loss Cost Modeling and Prediction[J].Expert Systems with Applications, 2012, 39 (3) .
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_7" title=" Yang Y, Qian W, Zou H.Insurance Premium Prediction via Gradient Tree-Boosted Tweedie Compound Poisson Models[J].Journal of Business &amp;amp; Economic Statistics, 2018, 36 (3) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDC9B2134966D9EB540CE7527B13523BE4&amp;v=MTEzODdHUWxmQnJMVTA1dDVoemJtL3dhMD1Oam5CYXNDeGJOUE5ySXRNWXUxN0JRbEx5aElUbVVwNlRYM2wzaE0yZkxDWE44K2JDT052RlNpV1dyN0pJRnBtYUJ1SFlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Yang Y, Qian W, Zou H.Insurance Premium Prediction via Gradient Tree-Boosted Tweedie Compound Poisson Models[J].Journal of Business &amp;amp; Economic Statistics, 2018, 36 (3) .
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_8" title=" Sakthivel K M, Rajitha C S.A Comparative Study of Zero-Inflated, Hurdle Models with Artificial Neural Network in Claim Count Modeling[J].International Journal of Statistics and Systems, 2017, 12 (2) ." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Comparative Study of Zero-Inflated,Hurdle Models with Artificial Neural Network in Claim Count Modeling">
                                        <b>[8]</b>
                                         Sakthivel K M, Rajitha C S.A Comparative Study of Zero-Inflated, Hurdle Models with Artificial Neural Network in Claim Count Modeling[J].International Journal of Statistics and Systems, 2017, 12 (2) .
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_9" title=" Sakthivel K M, Rajitha C S.Artificial Intelligence for Estimation of Future Claim Frequency in Non-Life Insurance[J].Global Journal of Pure and Applied Mathematics, 2017, 13 (6) ." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Artificial Intelligence for Estimation of Future Claim Frequency in Non-Life Insurance">
                                        <b>[9]</b>
                                         Sakthivel K M, Rajitha C S.Artificial Intelligence for Estimation of Future Claim Frequency in Non-Life Insurance[J].Global Journal of Pure and Applied Mathematics, 2017, 13 (6) .
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_10" title=" Lee S C K, Lin S.Delta Boosting Machine with Application to General Insurance[J].North American Actuarial Journal, 2018, 22 (3) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDC91F2B1251FCA1617DB254CD5E643488&amp;v=MDI1MDFlcDVmdzA0eVJjVW5rMS9UWHVSMkJkQWY3YVhRYktYQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDVoemJtL3dhMD1Oam5CYXNDeEg2Zk8zWTVIWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Lee S C K, Lin S.Delta Boosting Machine with Application to General Insurance[J].North American Actuarial Journal, 2018, 22 (3) .
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_11" title=" 薛薇.R语言数据挖掘方法及应用[M].北京:电子工业出版社, 2016:199-202." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121283277000&amp;v=Mjk5MjQzeEU5ZmJ2bktyaWZaZVp2RnlualU3YkpJRjhSWEZxekdiSzZIOVBFckkxQ1krc1BEQk04enhVU21EZDlTSDdu&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         薛薇.R语言数据挖掘方法及应用[M].北京:电子工业出版社, 2016:199-202.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_12" title=" Breiman L, Friedman J H, Olshen R A, et al.Classification and Regression Trees[M].Boston:Wadsworth International Group, 1984:342-346." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification and regression trees">
                                        <b>[12]</b>
                                         Breiman L, Friedman J H, Olshen R A, et al.Classification and Regression Trees[M].Boston:Wadsworth International Group, 1984:342-346.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_13" title=" Breiman L.Random Forests[J].Machine Learning, 2001, 45 (1) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MjA4NjY3QmFyTzRIdEhOckl0Rlp1d09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpN2xXcjdJSVZzPU5q&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Breiman L.Random Forests[J].Machine Learning, 2001, 45 (1) .
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_14" title=" Mcculloch W S, Walter P.ALogical Calculus of the Ideas Immanent in Nervous Activity[J].The Bulletin of Mathematical Biophysics, 1943, 5 (4) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001082082&amp;v=MTE0OTk3UjdxZForWnVGaTdsV3I3SUlWcz1OajdCYXJPNEh0SE5yNGRIWk9NTlkzazV6QmRoNGo5OVNYcVJyeG94Y01I&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Mcculloch W S, Walter P.ALogical Calculus of the Ideas Immanent in Nervous Activity[J].The Bulletin of Mathematical Biophysics, 1943, 5 (4) .
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_15" title=" 李航.统计学习方法[M].北京:清华大学出版社, 2011:137-138." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302275954001&amp;v=MDk1NTJZT3NQRFJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5qVTdiSklGOFJYRnF6R2JDNEhOUExxb1pB&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         李航.统计学习方法[M].北京:清华大学出版社, 2011:137-138.
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_16" title=" De Jong P, Heller G Z.Generalized Linear Models for Insurance Data[M].Cambridge:Cambridge University Press, 2009:34-49." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generalized Linear Models for Insurance Data">
                                        <b>[16]</b>
                                         De Jong P, Heller G Z.Generalized Linear Models for Insurance Data[M].Cambridge:Cambridge University Press, 2009:34-49.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_17" title=" Frees E W, Valdez E A.Hierarchical Insurance Claims Modeling[J].Journal of the American Statistical Association, 2008, 103 (484) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800005870&amp;v=MTY2MjFUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcm5JS1Y4VWF4Yz1Oam5CYXJLN0h0Zk9wNDlGWk9zS0JIczVvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Frees E W, Valdez E A.Hierarchical Insurance Claims Modeling[J].Journal of the American Statistical Association, 2008, 103 (484) .
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_18" title=" Hallin M, Ingenbleek J F.The Swedish Automobile Portfolio in 1977:A Statistical Study[J].Scandinavian Actuarial Journal, 1983, (1) ." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Swedish Automobile Portfolio in 1977:A Statistical Study">
                                        <b>[18]</b>
                                         Hallin M, Ingenbleek J F.The Swedish Automobile Portfolio in 1977:A Statistical Study[J].Scandinavian Actuarial Journal, 1983, (1) .
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_19" title=" Frees E W, Meyers G, Cummings A D.Summarizing Insurance Scores Using a Gini Index[J].Journal of the American Statistical Association, 2011, 106 (495) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800005468&amp;v=MTI3MDdJS1Y4VWF4Yz1Oam5CYXJLN0h0Zk9wNDlGWk9zS0NIb3hvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Frees E W, Meyers G, Cummings A D.Summarizing Insurance Scores Using a Gini Index[J].Journal of the American Statistical Association, 2011, 106 (495) .
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_20" title=" Qian W, Yang Y, Zou H.Tweedie&#39;s Compound Poisson Model with Grouped Elastic Net[J].Journal of Computational and Graphical Statistics, 2016, 25 (2) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD2033BE39835FB869F68B66303DFFF3D2&amp;v=MjQzMzJSczZkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDVoemJtL3dhMD1Oam5CYXJHNEhkSysyb3hNYk9nS2VnNHh5UjlsN0RjUFRubmhyQkZCRDhUaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         Qian W, Yang Y, Zou H.Tweedie&#39;s Compound Poisson Model with Grouped Elastic Net[J].Journal of Computational and Graphical Statistics, 2016, 25 (2) .
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=TJLT" target="_blank">统计与信息论坛</a>
                2019,34(05),69-78             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于机器学习的车险索赔频率预测</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E5%AE%87%E5%93%B2&amp;code=40051797&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曾宇哲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E5%AB%92%E5%8D%9A&amp;code=40329041&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴嫒博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E5%AE%8F%E8%BF%9C&amp;code=15219092&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑宏远</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BD%97%E6%9D%A5%E5%A8%9F&amp;code=40329042&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">罗来娟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E5%A4%A7%E5%AD%A6%E7%BB%9F%E8%AE%A1%E5%AD%A6%E9%99%A2&amp;code=0198015&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国人民大学统计学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>近年来, 广义线性模型已被广泛用于车险定价, 而一些研究结果显示机器学习在某些方面优于广义线性模型, 但这些结果都只是基于某个单一数据集。为了更全面地比较广义线性模型与机器学习方法在车险索赔频率预测问题上的效果, 对7个车险数据集进行了比较测试, 包括深度学习、随机森林、支持向量机、XGboost等机器学习方法;基于相同的训练集, 建立不同的广义线性模型预测索赔频率, 根据最小信息准则 (AIC) 选取最优的广义线性模型;通过交叉验证调参获得机器学习最佳参数和模型。研究结果显示:在所有的数据集上XGboost的预测效果一致地优于广义线性模型;对于某些自变量较多、变量间相关性强的数据集, 神经网络、深度学习和随机森林的预测效果比广义线性模型更好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B1%BD%E8%BD%A6%E4%BF%9D%E9%99%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汽车保险;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B4%A2%E8%B5%94%E9%A2%91%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">索赔频率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">梯度提升;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    曾宇哲, 男, 湖南郴州人, 硕士生, 研究方向:大数据分析;;
                                </span>
                                <span>
                                    吴嫒博, 女, 湖北宜昌人, 硕士生, 研究方向:车险;;
                                </span>
                                <span>
                                    郑宏远, 男, 四川乐山人, 硕士生, 研究方向:风险管理;;
                                </span>
                                <span>
                                    罗来娟, 女, 江西宜春人, 硕士生, 研究方向:风险管理。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-11</p>

                    <p>

                            <b>基金：</b>
                                                        <span>教育部人文社会科学重点研究基地重大项目《基于大数据的精算统计模型与风险管理问题研究》 (16JJD910001);</span>
                                <span>中国人民大学2018年度中央高校建设世界一流大学 (学科) 和特色发展引导专项资金;</span>
                    </p>
            </div>
                    <h1><b>Claim Frequency Modeling and Prediction via Machine Learning</b></h1>
                    <h2>
                    <span>ZENG Yu-zhe</span>
                    <span>WU Ai-bo</span>
                    <span>ZHENG Hong-yuan</span>
                    <span>LUO Lai-juan</span>
            </h2>
                    <h2>
                    <span>School of Statistics, Renmin University of China</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Generalized linear models (GLM) are traditionally widest used model in auto claim modelling.In recent years some scholars have applied machine learning algorithms to auto claim data, and their study has shown that methods based on machine learning prevail over traditional GLM models in some perspectives, but these results mainly ground on certain datasets.We compare GLM and machine learning algorithms over 7 datasets and mainly focus on frequency prediction.Based on same training sets, we develop several GLM models, and choose the best in the AIC criteria view.Also, we choose the best fitted machine learning method with its parameters through cross validation.Our study shows that XGboost model have a better performance than GLM in all datasets.In the situation of larger number of predictors, higher dependence between variables, Neural Network (NN) and Deep Neural Network (DNN) models are better than GLM models.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=auto%20insurance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">auto insurance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=claim%20frequency&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">claim frequency;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=machine%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">machine learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=gradient%20promotion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">gradient promotion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep neural network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-11</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag">一、引 言</h3>
                <div class="p1">
                    <p id="44">目前, 国内车险业务占非寿险保费的70%左右, 随着商车费率市场化的推进, 保险公司拥有更多的自主定价权, 行业竞争日益加剧。同时, 车联网的发展以及“互联网+”和大数据等新兴技术进入保险领域, 保险公司可以用来定价的数据维度越来越丰富, 数据量越来越大。大数据时代, 数据的高维性和复杂性对统计研究者提出了新的挑战, 而针对新问题传统的预测技术难以对其进行充分的刻画, 故需寻求更为有效的预测工具<citation id="211" type="reference"><link href="171" rel="bibliography" /><link href="173" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="45">当前, 全球已进入数字经济的时代, 新的技术和数据的发展对精算定价方法提出了新的要求。随着存储资源和计算资源成本的大幅下降和性能的大幅提升, 各类数字技术如物联网、云技术使得数据的采集、存储、分析和共享变得愈加可行且易于进行<citation id="212" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。互联网行业广泛使用的机器学习和数据挖掘方法开始引起了精算界的关注, 也已被尝试性地应用于车险费率的定价之中。</p>
                </div>
                <div class="p1">
                    <p id="46">目前, 国内已经有一些将机器学习应用于车险领域的研究成果。有学者将神经网络与车险索赔频率预测结合起来, 发现神经网络模型的预测效果通常要优于常用的广义线性模型;戴之遥探索了Boosting方法在车险定价中的应用场景, 提出机器学习与数据挖掘方法的效果明显优于传统广义线性模型, 机器学习方法可以处理变量间存在交互效应、非线性关系结构、存在缺失值和异常值的数据, 对原始数据预处理的要求比较低<citation id="213" type="reference"><link href="175" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>;孟生旺等人将支持向量机、神经网络和集成学习等机器学习算法应用于汽车保险的损失预测, 建立了索赔发生概率的预测模型和累积赔款的预测模型, 并与传统广义线性模型中的Logistic回归模型和伽马回归模型进行了比较, 发现机器学习算法的优点是不依赖于分布假设, 在一定程度上可以提高保险损失预测的精度, 而缺陷是比较耗时、建模过程中的人为干预较多, 并对使用者提出了更高的要求, 且输出结果的可解释性不及广义线性模型<citation id="214" type="reference"><link href="177" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>;在此基础上, 孟生旺和黄一凡又比较了Logistic回归与机器学习方法在出险概率预测中的效果, 并且认为XGboost方法对于出险概率的预测能力更优<citation id="215" type="reference"><link href="179" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="47">在国外, Guelman介绍了梯度提升算法, 认为梯度提升算法在处理车险数据的多分类变量、自变量相关和非线性特征等特点上更有优势, 对于数据的缺失和非清洁有较好的抗干扰效果, 并通过对某车险数据的拟合和预测得出梯度提升算法效果优于广义线性模型, 同时用相对重要性和偏相关性进行了变量重要性排序<citation id="216" type="reference"><link href="181" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>;Yang等探索了如何将广义线性模型与梯度提升方法结合起来, 提出了TDboost模型并且完善了对应的程序包和支持文件, 其主要思想是将广义线性模型中常用的Tweedie分布作为提升算法的弱学习器, 再用梯度提升算法估计参数, 在车险赔付预测中取得了较好的效果<citation id="217" type="reference"><link href="183" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>;Sakthivel和Rajitha探索了人工神经网络在车险中的应用, 通过数据验证得出神经网络模型比零膨胀泊松模型和零膨胀Hurdle模型更优、神经网络模型比贝叶斯信度模型更优的结论<citation id="219" type="reference"><link href="185" rel="bibliography" /><link href="187" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>;Lee等在某车险数据上应用了一种改良提升算法的Delta提升机, 并将结果与传统的梯度提升算法加以比较, 发现预测误差的差距较小, 而且没有显著的改善, 同时在某车险数据集上测试了广义线性模型 (GLM) 、广义可加模型 (GAM) 、梯度提升机 (GBM) 、Delta提升机 (DBM) 和分类回归树 (CART) , 并且比较了不同模型的效果<citation id="218" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="48">综上所述, 以上作者的成果都是基于某一特定的数据集, 因部分成果比较的方法较少, 较难支持机器学习优于广义线性模型的结论。因此, 本文收集了7个不同的数据集, 应用目前比较流行的5种机器学习方法, 包括支持向量机 (SVM) 、随机森林 (Random Forest) 、人工神经网络 (ANN) 、深度神经网络 (DNN) 、梯度提升 (XGboost) , 与广义线性模型 (GLM) 进行比较。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag">二、模型介绍</h3>
                <div class="p1">
                    <p id="50">此部分简要介绍6种算法模型, 包括广义线性模型和5种机器学习算法。理论上, 这6种算法都有非常丰富的内涵和很多改进算法, 而本文主要从工程应用角度出发, 通过一些常用的开源程序来进行计算比较, 因此不再详细解释这些算法的数学模型, 仅给出其基本思想、程序来源和主要参数。</p>
                </div>
                <h4 class="anchor-tag" id="51" name="51"> (<b>一) 广义线性模型</b> (GLM) </h4>
                <div class="p1">
                    <p id="52">目前, 广义线性模型已被普遍用于车险定价, 其优点是应用简便, 有很多统计软件可供使用, 而且可对参数估计结果进行直观解释, 但模型需要事先确定因变量和解释变量之间的函数关系, 函数形式比较有限, 实务中通常采取对数连接函数;广义线性模型不能自动识别解释变量之间的交互作用, 这也使得建模过程比较耗时;如果分布假设有误, 基于AIC选择的最优模型, 其拟合值的误差平方和可能并不是最小的。</p>
                </div>
                <div class="p1">
                    <p id="53">本文使用R中的gamlss包进行广义线性模型拟合, 建立线性回归、泊松回归、负二项回归、零膨胀泊松回归、零膨胀负二项和泊松逆高斯模型;建立模型后, 剔除不显著的协变量, 重新建模;然后比较各个最终模型的最小信息准则 (AIC) , 再选取AIC最小的模型作为最优的广义线性模型。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54"> (<b>二) 支持向量机</b> (SVM) </h4>
                <div class="p1">
                    <p id="55">SVM算法在解决高维特征的分类问题和回归问题很有效, 即使在特征维度大于样本数时依然有很好的效果, 特别是当样本量不是海量数据的时候, SVM分类准确率高, 泛化能力强。同时, SVM有大量的核函数可以使用, 从而可以很灵活地解决各种非线性的分类回归问题。但是, SVM也有一定缺点:在样本量非常大、核函数映射维度非常高时, 计算量过大, 不太适合使用;非线性问题的核函数的选择没有通用标准, 难以选择一个合适的核函数;SVM对缺失数据敏感<citation id="220" type="reference"><link href="191" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="56">本文使用Python软件sklearn包中的SVR函数对车险索赔频率进行预测, 其中涉及到两个重要的参数<i>C</i>与gamma。</p>
                </div>
                <div class="p1">
                    <p id="57">1.惩罚参数 (<i>C</i>) 是对误差的宽容度, 用于平衡模型复杂度和损失, 默认为1.0。<i>C</i>越大, 说明越不能容忍出现误差, 这种情况容易导致过拟合;<i>C</i>越小, 说明越能容忍出现误差, 这种情况容易导致欠拟合。因此, 参数<i>C</i>太大或太小都是不恰当的, 一般可通过<i>N</i>折交叉验证方式确定参数<i>C</i>。</p>
                </div>
                <div class="p1">
                    <p id="58">2.gamma是选择RBF函数 (径向基核函数) 作为kernel后该函数自带的一个参数, 隐含地决定了数据映射到新的特征空间后的分布。gamma值越大, 支持向量越少;gamma值越小, 支持向量越多。支持向量的个数会影响训练与预测的速度。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"> (<b>三) 随机森林</b> (Random Forest) </h4>
                <div class="p1">
                    <p id="60">20世纪80年代Breiman等发明了分类树的算法, 通过反复二分数据进行分类或回归<citation id="221" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。2001年Breiman把分类树组合成随机森林, 即在变量的使用和数据的使用上进行随机化, 生成很多分类树, 再汇总分类树的结果<citation id="222" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。随机森林在运算量没有显著提高的前提下提高了预测精度。</p>
                </div>
                <div class="p1">
                    <p id="61">本文使用Python软件sklearn包中的Random Forest Regressor函数对车险索赔频率进行预测, 其中涉及比较重要的参数包括最大特征数、子树的数量以及叶子节点最少样本数。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62">1.最大特征数 (max_features) 。</h4>
                <div class="p1">
                    <p id="63">随机森林允许单个决策树使用特征的最大数量, 默认是“None”, 意味着划分时考虑所有的特征数。增加max_features 一般能提高模型的性能, 因为在每个节点上有更多的选择可以考虑, 这同时也降低了单棵树的多样性, 进而有可能导致错误率增大, 而且max_features过大会降低算法的速度。一般来说, 如果样本特征数不多, 比如小于50, 默认选择“None”即可。</p>
                </div>
                <h4 class="anchor-tag" id="64" name="64">2.子树的数量 (n_estimators) 。</h4>
                <div class="p1">
                    <p id="65">在利用最大投票数或平均值预测之前, 需要建立子树的数量。较多的子树可以让模型有更好的性能, 但同时让代码变慢。在处理器能够承受的情况下, 考虑到随机森林的随机性, 应该选择尽可能高的值, 从而使预测更好更稳定。</p>
                </div>
                <h4 class="anchor-tag" id="66" name="66">3.叶子节点最少样本数 (min_samples_leaf) 。</h4>
                <div class="p1">
                    <p id="67">叶子节点最少样本数, 默认是1。该值限制了叶子节点最少的样本数, 如果某叶子节点数目小于样本数, 则会和兄弟节点一起被剪枝;如果样本量不大, 可以忽略该值;如果样本量非常大, 则推荐增大该值。较小的叶子使模型更容易捕捉训练数据中的噪声, 一般来说应该将最小叶子节点数目设置为50以上。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"> (<b>四) 神经网络</b> (ANN) <b>和深度神经网络</b> (DNN) <b>模型</b></h4>
                <div class="p1">
                    <p id="69">神经网络是受人类大脑中生物神经网络处理信息的方式所启发的计算模型, 由Mcculloch和Walter第一次提出<citation id="223" type="reference"><link href="197" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。神经网络在语音识别、计算机视觉和文本处理方面的许多突破性表现, 使得该方法已成为学界和业界研究及应用的热点。</p>
                </div>
                <div class="p1">
                    <p id="70">神经网络中的基本计算单位是神经元, 通常称为节点或单位。神经网络接收来自其它节点或来自外部源的输入, 并计算输出, 每个输入具有相关的权重 (<i>ω</i>) , 根据对其它输入的相对重要性来分配权重 (<i>ω</i>) 。该节点将函数<i>f</i>应用于其输入的加权和, 见图1。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201905010_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 神经元结构图" src="Detail/GetImg?filename=images/TJLT201905010_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 <b>神经元结构图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201905010_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72">上述网络采用数字输入<i>X</i><sub>1</sub>和<i>X</i><sub>2</sub>, 并具有与这些输入相关联的权重<i>ω</i><sub>1</sub>和<i>ω</i><sub>2</sub>。同时, 还有另一个输入1与权重<i>b</i> (称为偏差) 相关联。作用于输入值和权重的运算和上的函数被称为激活函数 (Activation Function) , 经过激活函数计算后的结果作为该神经元的输出, 而当将多个神经元组合起来并具有层次结构时, 就形成了神经网络模型。</p>
                </div>
                <div class="p1">
                    <p id="73">本文使用Python软件中Keras包搭建人工神经网络和深度神经网络, 用以拟合索赔频率, 其中对于每个数据集都进行了参数的调整, 以追求其结果的相对较优。对于人工神经网络, 设置3层:输入层、隐层、输出层;对于深度神经网络, 设置了7层:输入层、5个隐层、输出层。输入层神经元数量与样本变量数相同, 输出层神经元数量为1, 隐层神经元数量根据数据集的不同进行了调整。</p>
                </div>
                <div class="p1">
                    <p id="74">人工神经网络和深度神经网络模型均采用梯度下降作为优化器, MSE作为损失函数, 训练集中划分10%作为验证集, 隐层设置“RELU”激活函数, 设置3个回调函数:早停、储存最好的模型结果、学习率下降。根据每个数据集的样本量和数据集的特点, 设置学习率和相应的参数。</p>
                </div>
                <div class="p1">
                    <p id="75">深度神经网络由于隐层数量较多, 具有大量可以调节的参数, 其模型调参的复杂程度大大增加, 同时由于缺乏相关理论研究的支撑, 大多数情况下模型的设定和参数的选择都依赖于经验, 带有很大程度的随机性。对于较为复杂的模型, 可能会在特定数据集上达到很好的预测效果, 但是由于过拟合的问题, 在推广的过程中其精确性难以保证。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76"> (<b>五) 梯度提升算法</b> (Gradient Boosting) </h4>
                <div class="p1">
                    <p id="77">Boosting算法最早是由弱学习和强学习概念引出的, 其基本思想是用一系列的弱学习器去拟合样本数据, 每次迭代是对上一次迭代得到的模型预测值与数据差异的拟合, 这样即使每一次迭代中弱学习器的效果仅比随机猜测略好, 但是当有一定迭代次数之后都会得到较为理想的模型<citation id="224" type="reference"><link href="199" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="78">梯度提升算法是在Boosting的理论基础上, 针对可导的损失函数在每一次迭代时不对损失函数最小化, 而是拟合损失函数对上一次迭代模型的边际导数, 从而使得每次迭代都是沿着梯度下降, 而这种下降方式已被证明是在凸函数条件下最快的收敛方式。</p>
                </div>
                <div class="p1">
                    <p id="79">XGboost是eXtreme Gradient Boosting的缩写, 是基于梯度提升的一种算法变种。XGboost在Gradient Boosting的基础上做了许多改进, 其中最为重要的是引入了二阶导数, 用一阶与二阶导数逼近损失函数, 这样在优化过程中有更多的信息, 同时XGboost在损失函数中加入了正则项, 用于控制模型的复杂度, 使得模型更加简单, 降低了过拟合程度。</p>
                </div>
                <div class="p1">
                    <p id="80">本文中使用XGboost方法作为梯度提升算法的代表, 主要通过python中xgboost模块实现。在XGboost中重要的参数包括迭代次数、回归树的最大深度和学习率, 其中迭代次数和学习率有一定的替代关系。回归树的最大深度决定了回归树的枝桠个数, 当回归树较深但是变量相对少时, 会出现某些变量过多地重复出现在节点上, 可能会导致过拟合甚至对于变量重要性的误判。对于不同的变量个数和特征, 回归树的深度会极大地影响到模型效果;迭代次数和学习率在某种程度上是相互替代的关系, 一般而言学习率决定了每次迭代的步长, 当学习率较低时需要较高的迭代次数来保证得到足够的训练;当学习率较高, 即每次迭代步长都较大时, 会适当减少迭代次数以免过度拟合出现。</p>
                </div>
                <div class="p1">
                    <p id="81">在实际的模型训练中参数调整是一个较为麻烦的过程, 需要在不同的参数设定情况下进行比较, 因而各个机器学习方法的调参可能并不是全局最优, 而仅是在某一些参数范畴之内的最佳值, 这给机器学习算法留下了较大的可能性和改进空间。</p>
                </div>
                <h3 id="82" name="82" class="anchor-tag">三、数据介绍</h3>
                <div class="p1">
                    <p id="83">本文选取7个不同的车险数据集, 见表1。为了简洁, 本文不再一一列出各数据集的描述统计, 仅以数据集AutoClaim和Tangshan为例给出车险数据的常见变量类型。值得注意的是, 前6个数据都是散车业务, 而数据集Tangshan为车险团体客户数据, 与通常的散车业务有很大的不同, 即没有从人因子, 定价因素主要集中在车辆信息, 同一车队内的车辆索赔有相依关系 (组内不独立性) 等。一方面, 专门针对车队业务进行的定价研究相对较少;另一方面, 基于车队的车险业务在整个车险保费中约占30%, 有非常重要的实际意义。</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit"><b>表</b>1 <b>数据集汇总表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td>数据集名称</td><td>样本数</td><td>变量数</td><td>来源 (论文或提供者) </td><td>地点</td></tr><tr><td>car</td><td>67 856</td><td>8</td><td>De Jong和Heller<sup>[16]</sup></td><td>澳洲  </td></tr><tr><td><br />Claimslong</td><td>40 000×3年</td><td>4</td><td>De Jong和Heller<sup>[16]</sup></td><td>模拟数据<br /></td></tr><tr><td><br />Singapore</td><td>7 500</td><td>14</td><td>Frees和Valdez<sup>[17]</sup></td><td>新加坡 <br /></td></tr><tr><td><br />Ah<br /></td><td>48 668<br /></td><td>4<br /></td><td>北京市某财产险公司家庭自用车损险</td><td>中国  <br /></td></tr><tr><td><br />Swedish<br /></td><td>2 240<br /></td><td>5<br /></td><td>瑞典汽车保险风险溢价分析委员会汇编;Hallin and Ingenbleek<sup>[18]</sup></td><td>瑞典  <br /></td></tr><tr><td><br />AutoClaim<br /></td><td>10 296<br /></td><td>23<br /></td><td>SAS Enterprise Miner数据库;Yang, Qian, Zou<sup>[7]</sup></td><td>美国  <br /></td></tr><tr><td><br />Tangshan</td><td>17 651</td><td>16</td><td>人保财险唐山公司</td><td>中国  </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"> (<b>一) 数据集</b>AutoClaim</h4>
                <div class="p1">
                    <p id="86">该数据是从SAS Enterprise Miner数据库中检索的汽车保险数据集, 是由10 296条保单和29个变量组成的数据集, 数据包含的变量信息见表2。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"> (<b>二) 数据集</b>Tangshan</h4>
                <div class="p1">
                    <p id="88">该数据来自人保财险唐山公司, 共17 651份保单, 是车队保单。车队数据由于不包含从人因素, 大部分变量都是与车有关, 因而大部分都是无序分类变量, 如车型和客户群等;或者有序分类变量, 如车龄和座位数等, 同时变量间有较强的交互关系。数据包含的变量信息见表3, 其连续性解释变量和分类型解释变量的描述性统计结果见表4和表5。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89"> (<b>三) 数据预处理</b></h4>
                <div class="p1">
                    <p id="90">由于标准化之后的数据可以避免变量量纲带来的影响, 故对上述7个数据集中自变量的数值型变量进行标准化, 同时将字符型变量转化为哑变量, 对于数值型分类变量不做处理。需要注意的是, 在某些车险数据集中会有暴露数作为变量出现, 其含义为保单存续期, 在GLM中一般会将其作为模型中的OFFSET项处理, 基本思想是将不同暴露期的保单索赔折算到单位时期内的索赔次数。为保持一致, 本文在机器学习模型中将折算后的单位暴露时期内索赔次数作为因变量, 而不再将暴露数作为自变量加入模型。</p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit"><b>表</b>2 <b>数据集</b>AutoClaim<b>的变量信息表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="91" border="1"><tr><td>变量名称</td><td>变量解释</td><td>变量类型</td><td>水平</td></tr><tr><td>KIDSDRIV</td><td>车载儿童数</td><td>整型变量</td><td></td></tr><tr><td><br />TRAVTIME</td><td>上班距离</td><td>整型变量</td><td></td></tr><tr><td><br />CAR_USE</td><td>车辆用途</td><td>分类变量</td><td>Private表示私家车, Commercial表示商务车</td></tr><tr><td><br />BLUEBOOK</td><td>汽车价值</td><td>整型变量</td><td></td></tr><tr><td><br />RETAINED</td><td>作为客户年限</td><td>整型变量</td><td></td></tr><tr><td><br />NPOLICY</td><td>保单数目</td><td>整型变量</td><td></td></tr><tr><td><br />CAR_TYPE<br /></td><td>车辆类型<br /></td><td>分类变量<br /></td><td>Panel Truck、Pickup、Sedan、Sports Car、SUV、Van对应卡车、SUV等不同车辆类型</td></tr><tr><td><br />RED_CAR</td><td>车辆是否为红色</td><td>分类变量</td><td>Yes表示红色, no表示其它色</td></tr><tr><td><br />REVOLKED</td><td>是否在近7年内获得驾照</td><td>分类变量</td><td>Yes表示是, no表示否</td></tr><tr><td><br />MVR_PTS</td><td>违规记录</td><td>整型变量</td><td></td></tr><tr><td><br />AGE</td><td>驾驶人年龄</td><td>整型变量</td><td></td></tr><tr><td><br />HOMEKIDS</td><td>孩子数目</td><td>整型变量</td><td></td></tr><tr><td><br />YOJ</td><td>在职年限</td><td>整型变量</td><td></td></tr><tr><td><br />INCOME</td><td>年收入</td><td>整型变量</td><td></td></tr><tr><td><br />GENDER</td><td>性别</td><td>分类变量</td><td>F表示男性, M表示女性</td></tr><tr><td><br />MARRIED</td><td>是否婚配</td><td>分类变量</td><td>No表示未婚, yes表示已婚</td></tr><tr><td><br />PARENT1</td><td>是否单身</td><td>分类变量</td><td>Yes表示单身, no表示其它</td></tr><tr><td><br />JOBCLASS<br /></td><td>工作类型<br /></td><td>分类变量<br /></td><td>Unknown、Blue Collar、Clerical、Doctor、Home Maker、Lawyer、Manager、Professional、Student对应工人、医生等不同工作类型</td></tr><tr><td><br />MAX_EDUC<br /></td><td>最高学历<br /></td><td>分类变量<br /></td><td>High School、Bachelors、High School、Masters、PhD对应高中、本科、硕士、博士</td></tr><tr><td><br />HOME_VAL</td><td>住房价值</td><td>整型变量</td><td></td></tr><tr><td><br />SAMEHOME</td><td>现住址居住年限</td><td>整型变量</td><td></td></tr><tr><td><br />DENSITY</td><td>居住区域</td><td>分类变量</td><td>Highly Rural、Highly Urban、Rural、Urban对应城镇乡村等居住区域</td></tr><tr><td><br />CLM_FREQ5</td><td>近五年来索赔次数</td><td>因变量 </td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="92">
                    <p class="img_tit"><b>表</b>3 <b>数据集</b>Tangshan<b>的变量信息表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="92" border="1"><tr><td>变量名称</td><td>变量解释</td><td>变量类型</td><td>水平</td></tr><tr><td>premium</td><td>保费</td><td>连续变量</td><td></td></tr><tr><td><br />type</td><td>新转续保</td><td>无序分类变量</td><td>XINB表示“新保”, XUB表示“续保”, ZB表示“转保”</td></tr><tr><td><br />age<br /></td><td>车龄<br /></td><td>有序分类变量<br /></td><td>A:1年以下、B:1～2年、C:2～3年、D:3～4年、E:4～5年、F:5～6年、G:6～8年、H:8年及以上</td></tr><tr><td><br />Value<br /></td><td>车价<br /></td><td>有序分类变量<br /></td><td>A:5万元及以下、B:5～10万元、C:10～15万元、D:15～20万元、E:20～25万元、F:25～30万元、G:30～40万元、H:40～50万元、I:50～100万元、J:100万元及以上、K:未知车</td></tr><tr><td><br />seats</td><td>座位数</td><td>有序分类变量</td><td>1:6座以下、2:6～10座、3:10～20座、4:20～36座、5:36座以上、6:other</td></tr><tr><td><br />tonnage</td><td>吨位数</td><td>有序分类变量</td><td>1:2吨以下、2:2～5吨、3:5～10吨、4:10吨以上、5:其它</td></tr><tr><td><br />insurcomb</td><td>投保组合</td><td>无序分类变量</td><td>A:单保交强、B:交强车损、C:交强车损三者、D:交强三者</td></tr><tr><td><br />customer<br /></td><td>客户群<br /></td><td>无序分类变量<br /></td><td>A:家庭车、B:非营业客车、C:营业客车、D:非营业货车、E:营业货车、F:特种车、G:挂车</td></tr><tr><td><br />ratio<br /></td><td>车队整车近三年赔付率<br /></td><td>有序分类变量<br /></td><td>1:15%以下、2:15%～30%、3:30～40%、4:40～50%、5:50～55%、6:55～60%、7:60～70%、8:70～80%、9:80～100%、10:100%以上</td></tr><tr><td><br />Caramount</td><td>车队整车数量</td><td>连续变量</td><td></td></tr><tr><td><br />Avevalue</td><td>车队平均新车购置价</td><td>连续变量</td><td></td></tr><tr><td><br />Aveseats</td><td>车队平均座位数</td><td>连续变量</td><td></td></tr><tr><td><br />Avetonnage</td><td>车队平均吨位数</td><td>连续变量</td><td></td></tr><tr><td><br />Aveage</td><td>车队平均年龄</td><td>连续变量</td><td></td></tr><tr><td><br />Averatio</td><td>车队交强险近三年平均赔付率</td><td>分类变量</td><td>同ratio</td></tr><tr><td><br />Numclaim</td><td>已报告件数</td><td>因变量</td><td></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="93">
                    <p class="img_tit"><b>表</b>4 <b>数据集</b>Tangshan<b>连续性变量描述性统计分析表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="93" border="1"><tr><td><br />变量名称</td><td colspan="6">描述性统计分析</td></tr><tr><td><br />连续变量</td><td>最小</td><td>25%</td><td>中值</td><td>75%</td><td>最大</td><td>平均数</td></tr><tr><td><br />premium</td><td>1.82</td><td>800.00</td><td>950.00</td><td>1 200.00</td><td>5 824.00</td><td>1 370.05</td></tr><tr><td><br />Caramount</td><td>1.0</td><td>82.0</td><td>268.0</td><td>620.0</td><td>2 270.0</td><td>458.9</td></tr><tr><td><br />Avevalue</td><td>26 317</td><td>113 502</td><td>150 217</td><td>215 018</td><td>2 598 000</td><td>173 324</td></tr><tr><td><br />Aveseats</td><td>0.000</td><td>4.433</td><td>4.976</td><td>5.258</td><td>54.000</td><td>5.103</td></tr><tr><td><br />Avetonnage</td><td>0.000 0</td><td>0.247 2</td><td>2.279 0</td><td>5.487 5</td><td>38.525 0</td><td>5.102 9</td></tr><tr><td><br />Aveage</td><td>0.002 74</td><td>2.035 05</td><td>2.509 84</td><td>3.542 22</td><td>10.479 45</td><td>2.966 72</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="94">
                                            <p class="img_tit">
                                                <b>表</b>5 <b>数据集</b>Tangshan<b>中分类变量描述性统计分析表</b>
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201905010_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/TJLT201905010_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201905010_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 数据集Tangshan中分类变量描述性统计分析表" src="Detail/GetImg?filename=images/TJLT201905010_09400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="95">此外, 机器学习中有时会对数据不平衡问题进行干预, 本文中有的数据存在较为明显的不平衡数据问题, 即不索赔的保单占绝大多数的情况。针对这些数据集, 本文尝试了简单重抽样和SMOTE (Synthetic Minority Over-sampling Technique) 方法分别对数据进行预处理, 以达到索赔与不索赔保单数在同一数量级的效果, 但是处理后的拟合结果并未明显得到一致改善, 故最终在预处理中对不平衡数据问题不进行干预。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag">四、实证结果分析</h3>
                <h4 class="anchor-tag" id="97" name="97"> (<b>一) 各种方法的最优模型和最优参数</b></h4>
                <div class="p1">
                    <p id="98">以下将列出6种方法在不同数据集上的最优模型和最优参数。对于广义线性模型, 采用最小信息准则作为最优模型的选择标准, 其中泊松逆高斯模型是假定损失次数服从泊松分布, 而泊松分布的参数服从逆高斯分布;零膨胀模型是在基础模型上引入零膨胀参数进行回归。对于其它的机器学习算法, 本文采用交叉验证的方法来确定最优参数, 损失函数设置为均方误差。</p>
                </div>
                <div class="p1">
                    <p id="99">本文基于交叉验证数据建模, 以避免划分数据集导致的随机偏差。首先, 对总的样本进行无放回地随机抽取样本, 并将之等分为5份, 依次将各20%数据集作为测试集用于检验和评价模型的效果, 并将对应剩余80%的数据集合并作为训练集, 用于建立和修正模型;其次, 通过对5次建模的均方误差等指标进行平均, 得到最后结果。</p>
                </div>
                <h4 class="anchor-tag" id="100" name="100"> (<b>二) 各种方法的比较分析</b></h4>
                <div class="p1">
                    <p id="101">在比较不同模型效果时, 本文主要采用均方误差作为评价指标, 即:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>Μ</mtext><mtext>S</mtext><mtext>E</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>Y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">其中<i>y</i><sub><i>i</i></sub>为实际值, <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Y</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>为预测值。</p>
                </div>
                <div class="p1">
                    <p id="105">从表6和图2可以看到7个数据集在6种不同方法下的预测结果, 其中的变量个数是哑变量化后的变量个数。表6显示了以广义线性模型为基础 (设置为100%) , 不同机器学习方法预测的MSE与广义线性模型的MSE比较;图2展示了各种预测方法MSE的相对大小, 由于数据集差异难以进行绝对值的比较, 本文的展示方法是将柱状图上下两端分别固定在该数据集上效果最好与最差的方法, 其它方法按比例排布于两者之间, 从左至右按数据变量个数递增排列。</p>
                </div>
                <div class="area_img" id="106">
                    <p class="img_tit"><b>表</b>6 <b>各方法与广义线性模型的</b>MSE<b>比较表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="106" border="1"><tr><td rowspan="2">数据集</td><td rowspan="2">训练集<br />样本量</td><td rowspan="2">变量个数</td><td colspan="7"><br />各方法的MSE与GLM的MSE比值</td></tr><tr><td>GLM的MSE</td><td>GLM</td><td>ANN</td><td>DNN</td><td>Random Forest</td><td>SVM</td><td>XGboost</td></tr><tr><td>Claimlong</td><td>9 112</td><td>3</td><td>6.175 123</td><td>100%</td><td>100.06%</td><td>99.99%</td><td>104.75%</td><td>106.47%</td><td>99.97%</td></tr><tr><td><br />Swedish</td><td>1 790</td><td>5</td><td>0.006 36</td><td>100%</td><td>101.77%</td><td>101.16%</td><td>147.05%</td><td>127.05%</td><td>92.76%</td></tr><tr><td><br />ah</td><td>38 931</td><td>10</td><td>7.371 79</td><td>100%</td><td>97.44%</td><td>97.40%</td><td>97.15%</td><td>107.59%</td><td>90.22%</td></tr><tr><td><br />Singapore</td><td>6 006</td><td>21</td><td>0.731 27</td><td>100%</td><td>68.11%</td><td>68.08%</td><td>68.42%</td><td>68.62%</td><td>68.44%</td></tr><tr><td><br />Car</td><td>54 330</td><td>22</td><td>10.108 3</td><td>100%</td><td>82.10%</td><td>82.08%</td><td>83.13%</td><td>82.22%</td><td>84.71%</td></tr><tr><td><br />AutoClaim</td><td>8 251</td><td>38</td><td>0.054 34</td><td>100%</td><td>78.38%</td><td>77.93%</td><td>77.78%</td><td>81.68%</td><td>76.70%</td></tr><tr><td><br />Tangshan</td><td>14 163</td><td>39</td><td>0.091 84</td><td>100%</td><td>57.43%</td><td>56.68%</td><td>53.68%</td><td>67.55%</td><td>61.63%</td></tr><tr><td><br />平均值</td><td></td><td></td><td></td><td>100%</td><td>83.61%</td><td>83.33%</td><td>90.28%</td><td>91.60%</td><td>82.06%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201905010_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同方法结果比较图" src="Detail/GetImg?filename=images/TJLT201905010_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>不同方法结果比较图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201905010_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="108">对比各种方法在不同数据集上的表现, 可以看出:</p>
                </div>
                <div class="p1">
                    <p id="109"> (1) XGboost的预测效果最好, 在5个数据集上的预测效果均最优, 在所有的数据集上一致地优于广义线性模型, 具有很强的稳健型;广义线性模型的表现比较平庸。</p>
                </div>
                <div class="p1">
                    <p id="110"> (2) 在同一个数据集上, 大多数机器学习方法预测的MSE差距较小, 不同方法可能已经达到了相对较优的预测效果。</p>
                </div>
                <div class="p1">
                    <p id="111"> (3) DNN的预测效果均优于ANN, 隐层数量较多的神经网络体现出了比较明显的优势, 但是参数调节的过程会花费大量时间。</p>
                </div>
                <div class="p1">
                    <p id="112"> (4) 变量数量较多时机器学习算法均优于广义线性模型, 说明当数据集的变量较多时, 机器学习体现出了明显优势, 同时机器学习算法在面对数据量较大的数据集时并没有体现出特别明显的优势。</p>
                </div>
                <div class="p1">
                    <p id="113"> (5) 随机森林模型善于处理分类数据的优势在数据集Tangshan上得到了体现, 并在自变量几乎全部都是分类变量的情况下取得了最好的效果。</p>
                </div>
                <div class="p1">
                    <p id="114"> (6) 支持向量机的预测效果在大多数数据集上弱于其它机器学习方法, 但是当变量数增多时仍然会优于广义线性模型。</p>
                </div>
                <div class="p1">
                    <p id="115">从统计学角度而言, 当样本数目已经足够大时, 新增加的样本并不会额外提供太多的信息, 额外的样本可以被视为已有样本的某种重复, 特别是在车险数据中大部分的自变量是分类变量, 即只是某种标签, 某一类标签的样本可能会反复出现, 因而机器学习的结果并不会进一步改善;而当变量增多时, 可以提供额外的信息或分类标准, 但是多变量导致的复杂相关关系难以被广义线性模型揭示;从图2中可以看到, 当数据集按照变量数从小到大排列时, 在变量数较少的数据集Claimlong和Swedish上, 广义线性模型仍然会优于大多数模型, 而当变量数达到10以上时, 广义线性模型的表现就显著地弱于大部分机器学习模型了。</p>
                </div>
                <div class="p1">
                    <p id="116">同时, 本文也基于平均绝对误差和Gini系数对模型进行评判, 平均绝对误差 (MAE) 为:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>Μ</mtext><mtext>A</mtext><mtext>E</mtext><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>Y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">Gini系数由Frees等提出, 主要用于评价保险中的风险分割, 取值在-1～1之间, 详细计算方式可见文后附录。一般而言, Gini指数越大, 风险分割效果越好, 从而保险评分和基础统计模型越好。需要注意的是:Gini系数用于衡量模型对于风险的识别效果, 当预测值 (或者风险评分) 的序完全反映了对应真实投保人的索赔记录时 (本文中指索赔次数) , Gini系数越接近于1, 即当预测模型的结果在所有预测值中的相对位置排序与真实值的排序位置相近时, Gini系数的表现越好;但同时, Gini系数的缺点在于其只关注了风险区分, 即预测值的以序为代表的相对大小, 因而不一定与MSE等指标相一致。本文提供平均绝对误差和Gini系数的简要结果见表7和表8所示, 以此作为模型评价参考。</p>
                </div>
                <div class="area_img" id="119">
                    <p class="img_tit"><b>表</b>7 <b>各方法与广义线性模型的</b>MAE<b>比较表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="119" border="1"><tr><td rowspan="2"><br />数据集</td><td colspan="7"><br />各方法的MSE与GLM的MAE比值</td></tr><tr><td><br />GLM的MAE</td><td>GLM</td><td>ANN</td><td>DNN</td><td>RF</td><td>SVM</td><td>XGboost</td></tr><tr><td>Claimlong</td><td>6.175 123</td><td>100%</td><td>100.13%</td><td>99.78%</td><td>99.93%</td><td>74.05%</td><td>99.36%</td></tr><tr><td><br />Swedish</td><td>0.006 36</td><td>100%</td><td>104.46%</td><td>104.07%</td><td>107.73%</td><td>145.49%</td><td>92.74%</td></tr><tr><td><br />ah</td><td>7.371 79</td><td>100%</td><td>96.07%</td><td>96.01%</td><td>96.09%</td><td>91.04%</td><td>93.55%</td></tr><tr><td><br />Singapore</td><td>0.731 27</td><td>100%</td><td>70.30%</td><td>71.53%</td><td>71.33%</td><td>63.36%</td><td>77.51%</td></tr><tr><td><br />Car</td><td>10.108 3</td><td>100%</td><td>63.51%</td><td>63.36%</td><td>64.38%</td><td>47.69%</td><td>86.22%</td></tr><tr><td><br />AutoClaim</td><td>0.054 34</td><td>100%</td><td>82.01%</td><td>81.15%</td><td>80.83%</td><td>81.46%</td><td>81.40%</td></tr><tr><td><br />Tangshan</td><td>0.091 84</td><td>100%</td><td>69.33%</td><td>60.02%</td><td>53.58%</td><td>102.59%</td><td>74.67%</td></tr><tr><td><br />平均值</td><td></td><td>100%</td><td>83.69%</td><td>82.27%</td><td>81.98%</td><td>86.53%</td><td>86.49%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表</b>8 <b>各方法与广义线性模型的</b>Gini<b>系数比较表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td><br />Gini</td><td>glm</td><td>XGboost</td><td>RF</td><td>ANN</td><td>DNN</td><td>SVM</td></tr><tr><td><br />Swedish</td><td>0.236 57</td><td>0.272 97</td><td>0.196 63</td><td>0.220 86</td><td>0.218 25</td><td>0.129 35</td></tr><tr><td><br />Ah</td><td>0.174 77</td><td>0.237 61</td><td>0.196 82</td><td>0.183 4</td><td>0.184 27</td><td>0.178 24</td></tr><tr><td><br />Car</td><td>0.173 58</td><td>0.000 62</td><td>0.158 76</td><td>0.091 33</td><td>0.093 2</td><td>0.020 60</td></tr><tr><td><br />Tangshan</td><td>0.809 35</td><td>0.806 43</td><td>0.81174</td><td>0.811 7</td><td>0.807 59</td><td>0.804 81</td></tr><tr><td><br />Autoclaim</td><td>0.358 06</td><td>0.379 39</td><td>0.374 95</td><td>0.375 06</td><td>0.373 53</td><td>0.345 99</td></tr><tr><td><br />Claim slong</td><td>0.051 04</td><td>0.072 00</td><td>0.075 14</td><td>0.043 46</td><td>0.071 02</td><td>-0.01 00</td></tr><tr><td><br />Singapore</td><td>0.139 97</td><td>0.232 78</td><td>0.196 63</td><td>0.163 59</td><td>0.163 59</td><td>0.001 61</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="121">从表7表8可以看出, 平均绝对误差与均方误差的结果类似, 且XGboost方法一致地优于广义线性模型;大部分数据集上XGboost和随机森林的Gini指数最大, 超越了广义线性模型, 但是广义线性模型表现最为稳定, 其风险区分效果较好。</p>
                </div>
                <h3 id="122" name="122" class="anchor-tag">五、结 论</h3>
                <div class="p1">
                    <p id="123">本文使用了7组不同的数据集, 比较了广义线性模型和5种机器学习算法在预测索赔频率上的效果。尽管6种方法都存在很多种改良的途径, 对于精通某类模型的学者而言, 该方法的预测效果可以超越本文显示的情况, 但从工程应用角度出发, 通过一些常用的开源程序就可以达到商业的要求, 大大减少了建模成本, 是非常好的选择。因此, 本文的目的是从商业实用的角度, 兼顾模型的可实现性和效果而进行比较。</p>
                </div>
                <div class="p1">
                    <p id="124">本文结果显示:机器学习算法不亚于广义线性模型的表现, 并且XGboost算法能够在所有数据集上都一致地优于广义线性模型;机器学习算法在面对变量数较多的数据时, 预测效果相对更好。</p>
                </div>
                <div class="p1">
                    <p id="125">本文的不足在于只考虑了较为基础的广义线性模型, 未能对各个数据的特征进行进一步的研究, 如使用copula或者将变量间相互组合再作为新的变量加入模型。</p>
                </div>
                <div class="p1">
                    <p id="126">在实务中, 广义线性模型由于预测准确度高以及运行速度快, 被大量地应用于车险定价中。但是, 广义线性模型是建立在各种分布假设之上, 而实际的损失数有时可能难以满足这些分布假设, 进而有可能造成预测结果不准确。本文的结论为车险定价提供了一种新的思路:经过严格参数调整的机器学习算法能够获得比广义线性模型更优的预测结果。由于机器学习算法不需要基于一定的分布假设, 没有对变量取值的限制, 在方法的适用性上要优于广义线性模型, 并且在面对变量较多、数据量较大的数据时, 能够有更好的预测效果。</p>
                </div>
                <div class="p1">
                    <p id="127">机器学习模型也有其自身的劣势, 比如模型难以解释、运行时间过长等。保险公司为了提高定价的准确性, 为了更精确的模型而舍弃了可解释性和运行速率是可以接受的, 机器学习算法在车险定价中仍然具有广阔的前景, 并待以挖掘。</p>
                </div>
                <h3 id="128" name="128" class="anchor-tag"><b>附录</b>:有序Lorenz曲线和Gini系数及其计算方法。</h3>
                <div class="p1">
                    <p id="129">Frees等定义了有序Lorenz曲线 (Ordered Lorenz Curve) 和对应的Gini指数, 主要应用于保险中的风险分割和模型选择<citation id="225" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="130">定义一份保单的保险损失为<i>y</i>, 保费为<i>P</i> (<i>X</i>) , 且假设损失<i>y</i>和保费<i>P</i>都依赖于保单持有人的特征变量<i>X</i>。损失<i>y</i>的分布在0处有较大的概率堆积, 且尖峰后尾, 从而很难直接比较损失的分布和保费的分布。所以, 引入另一个变量<i>R</i>, 即相关度 (Relativity) 。</p>
                </div>
                <div class="p1">
                    <p id="131">给定样本集合{ (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) , <i>i</i>=1, 2, …, <i>n</i>}, 其中<i>x</i><sub><i>i</i></sub>表示与第<i>i</i>份保单有关的解释变量, <i>y</i><sub><i>i</i></sub>表示第<i>i</i>份保单的损失, 则保险人在<i>i</i>保单的净损失为<i>l</i> (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) =<i>y</i><sub><i>i</i></sub>-<i>P</i> (<i>x</i><sub><i>i</i></sub>) , 期望损失为:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>E</mi><mrow><mo>{</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>∈</mo><mi>A</mi><mo stretchy="false">) </mo><mi>l</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mo>}</mo></mrow></mtd></mtr><mtr><mtd><mtext> </mtext><mo>=</mo><mi>E</mi><msub><mrow></mrow><mi>x</mi></msub><mi>E</mi><msub><mrow></mrow><mrow><mi>y</mi><mo stretchy="false">|</mo><mi>x</mi></mrow></msub><mrow><mo>{</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>∈</mo><mi>A</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>y</mi><mo>-</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mo>}</mo></mrow></mtd></mtr><mtr><mtd><mtext> </mtext><mo>=</mo><mi>E</mi><msub><mrow></mrow><mi>x</mi></msub><mrow><mo>{</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>∈</mo><mi>A</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mo>}</mo></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中<i>m</i> (<i>x</i>) =<i>E</i> (<i>y</i>|<i>x</i>) 是回归函数, 而<i>A</i>集为某些保单集合, 使得净损失的均值为负, 即:</p>
                </div>
                <div class="p1">
                    <p id="134"><i>i</i>∈<i>A</i> ⇔ <i>m</i> (<i>x</i><sub><i>i</i></sub>) &lt;<i>P</i> (<i>x</i><sub><i>i</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="135">因而选择一个分数<i>s</i> (<i>x</i>) 作为<i>m</i> (<i>x</i>) 的近似值, 当<i>m</i> (<i>x</i><sub><i>i</i></sub>) &lt;<i>P</i> (<i>x</i><sub><i>i</i></sub>) 时, 保险人将会有一个正收益;相关度<i>R</i> (<i>x</i>) =<i>R</i> (<i>S</i> (<i>x</i>) , <i>P</i> (<i>x</i>) ) 用来衡量<i>s</i> (<i>x</i>) 小于<i>m</i> (<i>x</i>) 的程度, 通常定义:</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">其中<i>R</i>越小, 表示保险人在收取单位保费时承担的风险越小。假设当<i>R</i>=<i>R</i> (<i>x</i>) ≤<i>s</i>时, 保险人愿意承保。定义保费<i>P</i> (<i>x</i>) 的分布函数和经验分布函数分别为:</p>
                </div>
                <div class="p1">
                    <p id="138" class="code-formula">
                        <mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>F</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ε</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>R</mi><mo>≤</mo><mi>s</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mi>Ε</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mtd></mtr><mtr><mtd><mover accent="true"><mi>F</mi><mo>^</mo></mover><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo>[</mo><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>R</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>≤</mo><mi>s</mi><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow></mrow></mstyle></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="139">同理可得, 损失的分布函数和经验分布函数为:</p>
                </div>
                <div class="p1">
                    <p id="140" class="code-formula">
                        <mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>F</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ε</mi><mo stretchy="false"> (</mo><mi>y</mi><mi>Ι</mi><mo stretchy="false"> (</mo><mi>R</mi><mo>≤</mo><mi>s</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mi>Ε</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow></mfrac></mtd></mtr><mtr><mtd><mover accent="true"><mi>F</mi><mo>^</mo></mover><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mrow><mo>[</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mi>Ι</mi><mo stretchy="false"> (</mo><mi>R</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>≤</mo><mi>s</mi><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow></mrow></mstyle></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="141">有序Lorenz曲线是 (<mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>F</mi><mo>^</mo></mover></math></mathml><sub><i>P</i></sub> (<i>s</i>) , <mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>F</mi><mo>^</mo></mover></math></mathml><sub><i>L</i></sub> (<i>s</i>) ) 的曲线, 其中对角线是盈亏平衡线, 表示保费比例总是等于损失比例, 没有任何的风险区分, 于是呈现盈亏平衡情况。实际上, 保费和损失对于每一个进入样本的保单是确定和已知的, 不同的预测模型只会通过<i>s</i> (<i>x</i>) 来影响相关度, 因而影响保单在该曲线上出现的顺序, 即相关度越低则该保单越会出现在曲线前段, 从而体现了“有序”。同时, 由于其基于真实数据, 一方面有序Lorenz曲线能够提供跨方法的比较, 不同方法得出的风险区分可以在一幅图上被呈现和比较;另一方面该Lorenz曲线也会存在“隐性边界”, 即在样本数据的所有有限种排序中最优的情况。本文以Car数据集为例, 画出了GLM的有序Lorenz曲线 (见图3) , 由于假定对每个保单收取的保费都相同, 因而依据实际损失从小到大排序就成了该数据Lorenz曲线的“隐性边界”, 在图3中显示为最下方的曲线。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201905010_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 Lorenz曲线示例:Car数据集与GLM方法图" src="Detail/GetImg?filename=images/TJLT201905010_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 Lorenz<b>曲线示例</b>:Car<b>数据集与</b>GLM<b>方法图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201905010_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="145">在实际中, 不同方法的有序Lorenz可能会出现交叉, 为避免这种情形, Frees等建议使用基尼系数指标, 定义为有序Lorenz曲线与盈亏平衡线之间面积的两倍, 或以积分形式定义:</p>
                </div>
                <div class="p1">
                    <p id="146">Gini (<i>F</i><sub><i>P</i></sub>, <i>F</i><sub><i>L</i></sub>) =2∫<sup>∞</sup><sub>0</sub> (<i>F</i><sub><i>P</i></sub> (<i>s</i>) -<i>F</i><sub><i>L</i></sub> (<i>s</i>) ) d<i>F</i><sub><i>P</i></sub> (<i>s</i>) =1-2∫<sup>∞</sup><sub>0</sub><i>F</i><sub><i>L</i></sub> (<i>s</i>) d<i>F</i><sub><i>P</i></sub> (<i>s</i>) </p>
                </div>
                <div class="p1">
                    <p id="148">一般而言, Gini指数越大, 风险分割效果越好, 从而保险评分和基础统计模型越好。经典的Gini指数在<mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mn>0</mn><mo>, </mo><mn>1</mn></mrow><mo>]</mo></mrow></mrow></math></mathml>取值, 此处的Gini指数的取值范围扩展到了<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mo>-</mo><mn>1</mn><mo>, </mo><mn>1</mn></mrow><mo>]</mo></mrow></mrow></math></mathml>, 其中取负数的情况是由于对根据相关度排序的保单未能真正反映对应的风险, 即有序劳伦兹曲线折向对角线上方的情形。同样, 由于有序Lorenz曲线有其“隐性边界”存在, Gini系数有理论最大值, 即有序Lorenz曲线与对角线所围成最大面积的两倍。</p>
                </div>
                <div class="p1">
                    <p id="151">在本文中, 由于数据集中没有保费信息, 借鉴Qian等的方法<citation id="226" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>, 在计算Gini指数的时候将保费函数看做常数, 即<i>P</i> (·) ≡1, 则相关度为:</p>
                </div>
                <div class="p1">
                    <p id="152" class="code-formula">
                        <mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>=</mo><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>m</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>Ε</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="153">此处, 用预测值作为<i>E</i> (<i>y</i>|<i>x</i>) , 即根据预测值的结果得到序, 然后将实际值按照预测值的序进行排序, 进而画出有序Lorenz曲线, 并计算得到Gini指数。</p>
                </div>
                <div class="p1">
                    <p id="154">需要特别注意的是:由于各模型的预测值只起到了排序的作用, 可以理解为某一保单在所有预测值中的序与实际损失 (本文中指索赔频率) 的序越接近, 则有序Lorenz曲线越接近“隐性边界”, 因而对应的Gini系数值越大, 效果越好。通俗地说, 有序Lorenz曲线和Gini系数表现得好则意味着模型越能识别各保单的风险高低, 然而这种以序体现的在所有保单损失预测值中的相对大小, 并非与均方误差等度量预测值和实际损失值偏离程度的指标相一致。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="171">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201806005&amp;v=MTQ3NTg3Tk1TZkhlckc0SDluTXFZOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeUhrVTc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李扬, 许文甫, 马双鸽.污染数据的稳健稀疏成组变量选择方法研究[J].统计与信息论坛, 2018 (6) .
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201803014&amp;v=MDc0Mzg3Tk1TZkhlckc0SDluTXJJOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm9GeUhrVTc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 张儒斌, 刘树林, 张超锋, 等.互联网环境下基于消费者搜索的酒店入住率预测研究[J].统计与信息论坛, 2018 (5) .
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 戴之遥.梯度Boosting算法在车险定价中的应用[D].北京:中国人民大学, 2017.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201710005&amp;v=MDE1Njk5Yk5yNDlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlIa1U3N05KelhTWkxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 孟生旺, 李天博, 高光远.基于机器学习算法的车险索赔概率与累积赔款预测[J].保险研究, 2017 (10) .
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201808003&amp;v=MDI2MTA1NE8zenFxQnRHRnJDVVI3cWZadVpvRnlIa1U3N05KelhTWkxHNEg5bk1wNDlGWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 孟生旺, 黄一凡.驾驶行为保险的风险预测模型研究[J].保险研究, 2018 (8) .
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638247&amp;v=MDUyNjVUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcm5JS1Y4VWF4Yz1OaWZPZmJLN0h0RE5xbzlFWXVnSERuZytvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Guelman L.Gradient Boosting Trees for Auto Insurance Loss Cost Modeling and Prediction[J].Expert Systems with Applications, 2012, 39 (3) .
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDC9B2134966D9EB540CE7527B13523BE4&amp;v=Mjk4MTBuQmFzQ3hiTlBOckl0TVl1MTdCUWxMeWhJVG1VcDZUWDNsM2hNMmZMQ1hOOCtiQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDVoemJtL3dhMD1Oag==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Yang Y, Qian W, Zou H.Insurance Premium Prediction via Gradient Tree-Boosted Tweedie Compound Poisson Models[J].Journal of Business &amp; Economic Statistics, 2018, 36 (3) .
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Comparative Study of Zero-Inflated,Hurdle Models with Artificial Neural Network in Claim Count Modeling">

                                <b>[8]</b> Sakthivel K M, Rajitha C S.A Comparative Study of Zero-Inflated, Hurdle Models with Artificial Neural Network in Claim Count Modeling[J].International Journal of Statistics and Systems, 2017, 12 (2) .
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Artificial Intelligence for Estimation of Future Claim Frequency in Non-Life Insurance">

                                <b>[9]</b> Sakthivel K M, Rajitha C S.Artificial Intelligence for Estimation of Future Claim Frequency in Non-Life Insurance[J].Global Journal of Pure and Applied Mathematics, 2017, 13 (6) .
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJDC91F2B1251FCA1617DB254CD5E643488&amp;v=MjA0MjM9TmpuQmFzQ3hINmZPM1k1SFllcDVmdzA0eVJjVW5rMS9UWHVSMkJkQWY3YVhRYktYQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDVoemJtL3dhMA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Lee S C K, Lin S.Delta Boosting Machine with Application to General Insurance[J].North American Actuarial Journal, 2018, 22 (3) .
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121283277000&amp;v=MDk0ODYxQ1krc1BEQk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVadkZ5bmpVN2JKSUY4UlhGcXpHYks2SDlQRXJJ&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 薛薇.R语言数据挖掘方法及应用[M].北京:电子工业出版社, 2016:199-202.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification and regression trees">

                                <b>[12]</b> Breiman L, Friedman J H, Olshen R A, et al.Classification and Regression Trees[M].Boston:Wadsworth International Group, 1984:342-346.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDk5NDEzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1Rmk3bFdyN0lJVnM9Tmo3QmFyTzRIdEhOckl0Rlp1d09Z&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Breiman L.Random Forests[J].Machine Learning, 2001, 45 (1) .
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001082082&amp;v=MTM5MTk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaTdsV3I3SUlWcz1OajdCYXJPNEh0SE5yNGRIWk9NTlkzazV6QmRoNGo5&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Mcculloch W S, Walter P.ALogical Calculus of the Ideas Immanent in Nervous Activity[J].The Bulletin of Mathematical Biophysics, 1943, 5 (4) .
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302275954001&amp;v=MTUzNzdPc1BEUk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVadkZ5bmpVN2JKSUY4UlhGcXpHYkM0SE5QTHFvWkFZ&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 李航.统计学习方法[M].北京:清华大学出版社, 2011:137-138.
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generalized Linear Models for Insurance Data">

                                <b>[16]</b> De Jong P, Heller G Z.Generalized Linear Models for Insurance Data[M].Cambridge:Cambridge University Press, 2009:34-49.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800005870&amp;v=MzAwMTBzNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJuSUtWOFVheGM9TmpuQmFySzdIdGZPcDQ5RlpPc0tCSA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Frees E W, Valdez E A.Hierarchical Insurance Claims Modeling[J].Journal of the American Statistical Association, 2008, 103 (484) .
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Swedish Automobile Portfolio in 1977:A Statistical Study">

                                <b>[18]</b> Hallin M, Ingenbleek J F.The Swedish Automobile Portfolio in 1977:A Statistical Study[J].Scandinavian Actuarial Journal, 1983, (1) .
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13062800005468&amp;v=MzAwNjV0Zk9wNDlGWk9zS0NIb3hvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVybklLVjhVYXhjPU5qbkJhcks3SA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Frees E W, Meyers G, Cummings A D.Summarizing Insurance Scores Using a Gini Index[J].Journal of the American Statistical Association, 2011, 106 (495) .
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD2033BE39835FB869F68B66303DFFF3D2&amp;v=MDQ3MTV4eVI5bDdEY1BUbm5ockJGQkQ4VGlSczZkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dDVoemJtL3dhMD1Oam5CYXJHNEhkSysyb3hNYk9nS2VnNA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> Qian W, Yang Y, Zou H.Tweedie's Compound Poisson Model with Grouped Elastic Net[J].Journal of Computational and Graphical Statistics, 2016, 25 (2) .
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="TJLT201905010" />
        <input id="dpi" type="hidden" value="800" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201905010&amp;v=MDc1MzR6cXFCdEdGckNVUjdxZlp1Wm9GeUhrVTc3Tk1TZkhlckc0SDlqTXFvOUVaSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDMyc0JONkxiNVVrTHl2V3hMbXlkRT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

