

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140720214350000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dTJLT201909004%26RESULT%3d1%26SIGN%3dnK2vplp3nnBPCmXvraOhgp0Eygs%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJLT201909004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJLT201909004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201909004&amp;v=MTU2NDFyQ1VSN3FmWnVabkZpRG1Vci9BTVNmSGVyRzRIOWpNcG85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="一、引 言 ">一、引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#32" data-title="二、文献综述 ">二、文献综述</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="三、模型介绍 ">三、模型介绍</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title=" (&lt;b&gt;一&lt;/b&gt;) SBS&lt;b&gt;回归树模型&lt;/b&gt;"> (<b>一</b>) SBS<b>回归树模型</b></a></li>
                                                <li><a href="#44" data-title=" (&lt;b&gt;二&lt;/b&gt;) Boosting&lt;b&gt;算法&lt;/b&gt;"> (<b>二</b>) Boosting<b>算法</b></a></li>
                                                <li><a href="#46" data-title=" (&lt;b&gt;三) 泊松提升模型&lt;/b&gt;"> (<b>三) 泊松提升模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#103" data-title="四、实证分析 ">四、实证分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#104" data-title=" (&lt;b&gt;一) 数据描述&lt;/b&gt;"> (<b>一) 数据描述</b></a></li>
                                                <li><a href="#110" data-title=" (&lt;b&gt;二) 变量的描述性统计&lt;/b&gt;"> (<b>二) 变量的描述性统计</b></a></li>
                                                <li><a href="#113" data-title=" (&lt;b&gt;三) 实证结果&lt;/b&gt;"> (<b>三) 实证结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#156" data-title="五、结 论 ">五、结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#106" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;数据格式表&lt;/b&gt;"><b>表</b>1 <b>数据格式表</b></a></li>
                                                <li><a href="#109" data-title="表2 变量说明表">表2 变量说明表</a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;训练集和测试集的索赔次数和索赔频率情况表&lt;/b&gt;"><b>表</b>3 <b>训练集和测试集的索赔次数和索赔频率情况表</b></a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;图&lt;/b&gt;1 RT1&lt;b&gt;模型样本内损失减少情况图&lt;/b&gt;"><b>图</b>1 RT1<b>模型样本内损失减少情况图</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;图&lt;/b&gt;2 &lt;b&gt;模型&lt;/b&gt;RT2&lt;b&gt;和&lt;/b&gt;RT3&lt;b&gt;的&lt;/b&gt;10&lt;b&gt;折交叉验证情况图&lt;/b&gt;"><b>图</b>2 <b>模型</b>RT2<b>和</b>RT3<b>的</b>10<b>折交叉验证情况图</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表&lt;/b&gt;4 &lt;b&gt;三种回归树模型的样本表&lt;/b&gt; 单位:10"><b>表</b>4 <b>三种回归树模型的样本表</b> 单位:10</a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;表&lt;/b&gt;5 &lt;b&gt;三种泊松&lt;/b&gt;Boosting&lt;b&gt;算法模型和模型&lt;/b&gt;RT3&lt;b&gt;样本损失情况表&lt;/b&gt; 单位:10"><b>表</b>5 <b>三种泊松</b>Boosting<b>算法模型和模型</b>RT3<b>样本损失情况表</b> 单位:10</a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;图&lt;/b&gt;3 &lt;b&gt;三种不同泊松&lt;/b&gt;Boosting&lt;b&gt;算法模型和&lt;/b&gt;RT3&lt;b&gt;的样本内损失情况图&lt;/b&gt;"><b>图</b>3 <b>三种不同泊松</b>Boosting<b>算法模型和</b>RT3<b>的样本内损失情况图</b></a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;图&lt;/b&gt;4 &lt;b&gt;各个单变量预测结果图&lt;/b&gt;"><b>图</b>4 <b>各个单变量预测结果图</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Friedman J.Greedy Function Approximation:A Gradient Boosting Machine[J].The Annals of Statistics, 2001 (29) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14112600629087&amp;v=MjkzODFySzhIOURPcVk5Rll1a0dESFErb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJKS0YwVmFobz1OaWZZZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Friedman J.Greedy Function Approximation:A Gradient Boosting Machine[J].The Annals of Statistics, 2001 (29) .
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Guelman L.Gradient Boosting Trees for Auto Insurance Loss Cost Modeling and Prediction[J].Expert Systems with Applications, 2012, 39 (3) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638247&amp;v=MTE0MzRETnFvOUVZdWdIRG5nK29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJiSktGMFZhaG89TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Guelman L.Gradient Boosting Trees for Auto Insurance Loss Cost Modeling and Prediction[J].Expert Systems with Applications, 2012, 39 (3) .
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Liu Y, Wang B J, Lv S G.Using Multi-class AdaBoost Tree for Prediction Frequency of Auto Insurance[J].Journal of Applied Finance &amp;amp; Banking, 2014, 4 (5) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJSL&amp;filename=SJSL15032400000004&amp;v=MTg0MTF0RmlubFVyYkpLRjBWYWhvPU5pZllZcks5SHRMT3E0OUZaT3NQREh3OW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Liu Y, Wang B J, Lv S G.Using Multi-class AdaBoost Tree for Prediction Frequency of Auto Insurance[J].Journal of Applied Finance &amp;amp; Banking, 2014, 4 (5) .
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Z&#246;chbauer P.Data Science in Non-Life Pricing:Predicting Claims Frequencies Using Tree-Based Models[D].ETH Z&#252;rich:Department of Mathematics, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Data Science in Non-Life Pricing:Predicting Claims Frequencies Using Tree-Based Models">
                                        <b>[4]</b>
                                         Z&#246;chbauer P.Data Science in Non-Life Pricing:Predicting Claims Frequencies Using Tree-Based Models[D].ETH Z&#252;rich:Department of Mathematics, 2016.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" W&#252;thrich M V.Price Stability in Regression Tree Calibrations[E].2017 China International Conference on Insurance and Risk Management, July 19-22, 2017.Guilin, China, 749-762." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Price Stability in Regression Tree Calibrations">
                                        <b>[5]</b>
                                         W&#252;thrich M V.Price Stability in Regression Tree Calibrations[E].2017 China International Conference on Insurance and Risk Management, July 19-22, 2017.Guilin, China, 749-762.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Noll A, Salzmann R, Wuthrich M V.Case Study:French Motor Third-Party Liability Claims[J/OL].SSRN Electronic Journal, 2018.https://ssm.com/abstract=3164764." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Case Study:French Motor Third-Party Liability Claims">
                                        <b>[6]</b>
                                         Noll A, Salzmann R, Wuthrich M V.Case Study:French Motor Third-Party Liability Claims[J/OL].SSRN Electronic Journal, 2018.https://ssm.com/abstract=3164764.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 张连增, 谢厚谊.回归树方法在车险索赔频率预测建模中的应用[J].保险研究, 2018 (1) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201801010&amp;v=MjAwNDF6WFNaTEc0SDluTXJvOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURtVXIvQUo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         张连增, 谢厚谊.回归树方法在车险索赔频率预测建模中的应用[J].保险研究, 2018 (1) .
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 孟生旺, 黄一凡.驾驶行为保险的风险预测模型研究[J].保险研究, 2018 (8) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201808003&amp;v=MjMwMzgvQUp6WFNaTEc0SDluTXA0OUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURtVXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         孟生旺, 黄一凡.驾驶行为保险的风险预测模型研究[J].保险研究, 2018 (8) .
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 张连增, 王缔.大额索赔条件下的车险费率厘定[J].统计与信息论坛, 2019 (1) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201901009&amp;v=MDk0NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRG1Vci9BTVNmSGVyRzRIOWpNcm85RmJZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         张连增, 王缔.大额索赔条件下的车险费率厘定[J].统计与信息论坛, 2019 (1) .
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" W&#252;thrich M V, Buser C.Data Analytics for Non-Life Insurance Pricing[R].ETH Z&#252;rich, 2018:119-125.https://ssrn.com/abstract=2870308." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Data Analytics for Non-life Insurance Pricing">
                                        <b>[10]</b>
                                         W&#252;thrich M V, Buser C.Data Analytics for Non-Life Insurance Pricing[R].ETH Z&#252;rich, 2018:119-125.https://ssrn.com/abstract=2870308.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 周志华.机器学习[M].北京:清华大学出版社, 2016:173-177." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MjMyNzNidm5LcmlmWmVadkZ5bnNVcmZMSVY0Y1hGcXpHYkM0SE5YT3JJMU5ZK3NQREJNOHp4VVNtRGQ5U0g3bjN4RTlm&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         周志华.机器学习[M].北京:清华大学出版社, 2016:173-177.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Therneau T M, Atkinson E J, Foundation M.An Introduction to Recursive Partitioning Using the RPART Routines[R].Vignettes, 2015.https://cran:r-project.org/web/packages/rpart/vignetts/longintro.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Introduction to Recursive Partitioning Using the RPART Routines">
                                        <b>[12]</b>
                                         Therneau T M, Atkinson E J, Foundation M.An Introduction to Recursive Partitioning Using the RPART Routines[R].Vignettes, 2015.https://cran:r-project.org/web/packages/rpart/vignetts/longintro.pdf.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" James G, Witten D, Hastie T, Tibshirani R.An Introduction to Statistical Learning with Applications in R[M].Berlin:Springer, 2013:181-183." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Introduction to Statistical Learning with Applications in R">
                                        <b>[13]</b>
                                         James G, Witten D, Hastie T, Tibshirani R.An Introduction to Statistical Learning with Applications in R[M].Berlin:Springer, 2013:181-183.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=TJLT" target="_blank">统计与信息论坛</a>
                2019,34(09),27-34             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>泊松提升模型在中国车险索赔频率预测建模中的应用</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%BF%9E%E5%A2%9E&amp;code=08779781&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张连增</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%94%B3%E6%99%B4&amp;code=42272364&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">申晴</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E5%BC%80%E5%A4%A7%E5%AD%A6%E9%87%91%E8%9E%8D%E5%AD%A6%E9%99%A2&amp;code=0205377&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南开大学金融学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为研究泊松提升模型在中国车险定价中的应用, 将Boosting算法加入到SBS (Standardized binary split) 回归树中, 基于中国某公司2016年28个省份交强险保单数据, 以样本内外损失函数的最小化为标准, 对相关模型进行比较以选择相对较优的模型, 应用得到的模型对各个变量进行单变量预测。研究结果表明:泊松提升模型优于SBS回归树模型, 不存在过拟合的前提下, 泊松提升模型的预测效果会随着树的深度或者迭代次数的增大而变得更优, 确定了深度为3, 迭代次数为15的泊松提升模型 (即PBM3) 为最优模型。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Boosting%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Boosting算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%8A%E6%9D%BE%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">泊松提升模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%9E%E5%BD%92%E6%A0%91%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">回归树模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%A4%E5%BC%BA%E9%99%A9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">交强险;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B4%A2%E8%B5%94%E9%A2%91%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">索赔频率;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张连增, 男, 山东莱芜人, 教授, 博士生导师, 研究方向:精算与风险管理, 机器学习;;
                                </span>
                                <span>
                                    申晴, 男, 河南商丘人, 博士生, 研究方向:精算与风险管理, 机器学习。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金青年项目《基于相依结构的多元索赔准备金评估随机性方法研究》 (71401041);</span>
                                <span>南开大学基本科研业务费《机器学习在金融预测建模中的应用研究》 (63185010);</span>
                                <span>教育部人文社会科学重点研究基地重大项目《基于大数据的精算统计模型与风险管理问题研究》 (16JJD910001);</span>
                    </p>
            </div>
                    <h1><b>Predictive Modeling Applications of Poisson Boosting Model for Claims Frequencies of Auto Insurance in China</b></h1>
                    <h2>
                    <span>ZHANG Lian-zeng</span>
                    <span>SHEN Qing</span>
            </h2>
                    <h2>
                    <span>School of Finance, Nankai University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The application of Poisson Boosting Model in vehicle insurance pricing in China by adding the Boosting algorithm to the SBS (Standardized Binary Split) regression tree is mainly studied here.Based on the data of a company's compulsory traffic insurance policies from 28 provinces in 2016, choose the optimal model by comparing the relative models with the criterion of minimizing the in-sample and out-sample loss function and use the optimal model to predict each variable.The results show that the Poisson Boosting Model outperforms the SBS regression tree model, the predicted efficiency of the Poisson Boosting Model will become superior as the increase of depth of the tree or number of iterations without over-fitting, and it explains that the optimal model is the Poisson Boosting Model (PBM3) with the depth is 3 and number of iterations is 15.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=boosting%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">boosting algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Poisson%20Boosting%20Model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Poisson Boosting Model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=regression%20tree%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">regression tree model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=compulsory%20insurance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">compulsory insurance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=claim%20frequency&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">claim frequency;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-28</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag">一、引 言</h3>
                <div class="p1">
                    <p id="30">车险是非寿险的重要组成部分, 车险定价一直是一个复杂、困难并且重要的工作。自从20世纪90年代英国精算师把广义线性模型 (GLM) 应用到非寿险定价中, 非寿险产品得以科学定价的同时, GLM在精算中的应用也得到不断完善与发展。随着大数据时代的到来, 在车险产品定价过程中需要考虑的因素特别是数值型变量因素的不断增加, 传统GLM的局限性不断凸显, 主要表现为:随着变量的增多, 变量间的相关关系增强, GLM的预测能力不断下降。为此, 在建立GLM之前, 需要对样本中的数值型解释变量调整为分类变量, 而且为减少可能存在的具有相关关系的解释变量对GLM预测效果的影响, 在建立GLM时, 需要引入交互项。在互联网科技迅速发展的今天, 上述数据处理与操作可以轻松实现, 但是经过类似处理与操作后的模型有效性问题值得思考。</p>
                </div>
                <div class="p1">
                    <p id="31">为了克服GLM自身存在的局限性, 当前在车险产品定价中出现了很多模型与方法, 其中以回归树、支持向量机、神经网络和Boosting算法等为代表的机器学习方法, 近年来得到了快速的发展。本文将Boosting算法加入到SBS (Standardized Binary Split) 回归树模型中, 应用得到的模型对中国交强险索赔频率进行预测建模分析。然后将泊松提升模型与SBS回归树模型进行比较, 以损失函数的最小化为标准来选择相对较优的模型, 应用得到的较优模型对中国交强险保单中的各个变量进行单因素预测分析, 分别分析各个因素对索赔频率的影响。本研究为以后的相关研究和交强险定价提供一定的理论借鉴和参考。</p>
                </div>
                <h3 id="32" name="32" class="anchor-tag">二、文献综述</h3>
                <div class="p1">
                    <p id="33">本文中用到的泊松提升模型是Boosting算法与SBS回归树的结合, 关于Boosting算法和回归树方法在车险产品定价中应用的国内外相关研究成果主要有:</p>
                </div>
                <div class="p1">
                    <p id="34">Friedman最早提出了一种梯度提升法 (GBM) , 它通过对回归型问题的求解来扩展提升能力, 该算法成功地将可加性建模和极大似然等统计元素纳入建模中, 被认为是数据挖掘领域的重大突破<citation id="160" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。Guelman使用梯度提升树 (Gradient Boosted Trees, GBT) 对索赔频率和索赔强度分别进行建模, 该模型对索赔频率和索赔强度的预测效果比传统广义线性模型的预测效果要好<citation id="161" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。Liu等将一种称为多分类AdaBoost树方法用于车险索赔频率预测分析, 并将该模型与广义线性模型、神经网络模型与支持向量机模型进行比较, 最后证明多分类AdaBoost树方法具有更强的预测能力和可解释性<citation id="162" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。Zöchbauer认为回归树方法为构建具有相似风险特征的同质投资组合提供了一个有用的工具, 更先进的树集成方法, 如Bagging法和随机森林的预测能力超过了传统的广义线性模型<citation id="163" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。Wüthrich基于驾驶者行为数据对车险产品价格的稳定性进行研究, 认为使用经典的回归树或Boosting算法进行价格更新时, 所得到的价格波动较大, 为了使价格更新顺利进行, 建议使用以前的费率结构作为新产品的初始价格<citation id="164" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。Noll等基于第三方责任保险数据集, 比较了经典广义线性模型、回归树建模、助推器和神经网络方法在索赔频率预测建模中的表现, 研究表明:广义线性模型不能恰当地处理特征分量之间的交互作用, 而其他方法能够较好地处理这些交互影响<citation id="165" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="35">张连增等应用回归树方法对中国车险索赔频率进行预测建模分析, 并与广义线性模型进行比较, 得出单棵回归树的预测能力不如传统的广义线性模型, 但是通过Bagging法得到的回归树优于传统的广义线性模型<citation id="166" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。孟生旺等通过应用随机森林模型、神经网络模型和XGBoost模型对驾驶行为风险因子的出险概率进行分析研究, 并与传统的logistic回归模型进行比较, 结果表明XGBoost模型对于出险概率的预测能力更强<citation id="167" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="36">除此之外, 关于车险费率厘定还有其他一些研究成果, 例如, 张连增等在车险费率厘定时提出了一种处理大额索赔的频率—强度方法, 并通过分别对索赔频率和索赔强度进行建模分析实证检验了带有大额索赔的频率—强度模型在车险费率厘定中的优越性<citation id="168" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="37">总结国内外研究成果发现:第一, Boosting算法和回归树模型在车险定价应用的研究成果很多, 国内相关的研究成果则较少;第二, 国内外关于Boosting算法和回归树的研究大多侧重于二者在车险定价中的比较, 关于将Boosting算法加入到回归树模型中除了国外有少量研究外, 其他相关研究较少。鉴于此, 本文采用Boosting算法与SBS回归树相结合的方法对中国车险定价索赔频率进行预测分析研究。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag">三、模型介绍</h3>
                <div class="p1">
                    <p id="39">首先介绍索赔频率模型的一个基本假设:设<i>X</i>={<i>x</i>|<i>x</i>∈<i>R</i><sup><i>p</i></sup>}是特征变量取值范围, 选择一个函数<i>λ</i>:<i>X</i>→<i>R</i><sub>+</sub>, 在给定的一年内, 第<i>i</i>份保单的索赔次数<mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub><mover><mstyle mathsize="140%" displaystyle="true"><mo>∼</mo></mstyle><mrow><mtext>i</mtext><mtext>n</mtext><mtext>d</mtext><mo>.</mo></mrow></mover><mtext>Ρ</mtext><mtext>o</mtext><mtext>i</mtext><mo stretchy="false"> (</mo><mi>λ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, 其中<i>x</i><sub><i>i</i></sub>是第<i>i</i>份保单对应的特征向量, <i>v</i><sub><i>i</i></sub>是第<i>i</i>份保单的风险暴露数, 即对索赔次数进行泊松分布建模, 进而估计出能够反映期望索赔频率的回归函数<i>λ</i> (·) 。所有的样本可表示为{ (<i>N</i><sub><i>i</i></sub>, <i>x</i><sub><i>i</i></sub>, <i>v</i><sub><i>i</i></sub>) :<i>i</i>=1, 2, …, <i>n</i>}。</p>
                </div>
                <div class="p1">
                    <p id="41">本文应用泊松提升模型 (Poisson boosting model) 进行索赔频率建模。泊松提升模型是在以泊松偏差统计量为损失函数的SBS (Standardized binary split) 回归树模型中加入Boosting算法。具体步骤为:将一棵只有很少叶子的SBS回归树作为弱估计量, 以这个弱估计量的残差作为新的响应来构造下一个弱估计量, 以自适应的方式迭代此过程则将产生一个较强的估计量。以下重点介绍SBS回归树模型、Boosting 算法和泊松提升模型这三部分内容。</p>
                </div>
                <h4 class="anchor-tag" id="42" name="42"> (<b>一</b>) SBS<b>回归树模型</b></h4>
                <div class="p1">
                    <p id="43">SBS回归树模型就是在给定一个复杂性参数 (complexity parameter) 的条件下, 寻找对特征空间<i>X</i>的最优区分 (<i>X</i><sub><i>k</i></sub>) <sub><i>k</i>=1, 2, …, <i>K</i></sub>, 其中<i>K</i>表示叶子数。对特征空间的最优区分就是在所有的SBS中迭代寻找最优的分割<citation id="169" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44"> (<b>二</b>) Boosting<b>算法</b></h4>
                <div class="p1">
                    <p id="45">Boosting算法是一种将弱学习器 (weak learner) 提升为强学习器的算法<citation id="170" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46"> (<b>三) 泊松提升模型</b></h4>
                <h4 class="anchor-tag" id="47" name="47">1.模型介绍</h4>
                <div class="p1">
                    <p id="48">泊松提升模型将Boosting算法加入到SBS回归树模型中, 主要是通过自适应迭代的方法实现样本内损失函数的最小化, 其算法流程如下:</p>
                </div>
                <h4 class="anchor-tag" id="49" name="49"> (1) 初始化</h4>
                <div class="p1">
                    <p id="50">a.选择<i>K</i>≥2和固定<i>α</i>∈ (0, 1], 其中<i>K</i>表示叶子数, <i>α</i>表示收缩因子 (通常为1) 。</p>
                </div>
                <div class="p1">
                    <p id="51">b.设置初始的最大似然估计<mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>log</mi></mrow><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>/</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi>v</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, 其中, <i>N</i><sub><i>i</i></sub>表示索赔次数, <i>v</i><sub><i>i</i></sub>表示风险暴露数。</p>
                </div>
                <h4 class="anchor-tag" id="53" name="53"> (2) 重复。当<i>m</i>=1, 2, …, <i>M</i></h4>
                <div class="p1">
                    <p id="54">a.根据公式<mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mi>e</mi><msup><mrow></mrow><mrow><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></msup></mrow></math></mathml>设置相应的权重, 则样本数据为:</p>
                </div>
                <div class="p1">
                    <p id="56"><i>D</i><sup> (<i>m</i>) </sup>={ (<i>N</i><sub>1</sub>, <i>x</i><sub>1</sub>, <i>w</i><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) , (<i>N</i><sub>2</sub>, <i>x</i><sub>2</sub>, <i>w</i><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) , …, (<i>N</i><sub><i>n</i></sub>, <i>x</i><sub><i>n</i></sub>, <i>w</i><mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>) }      (1) </p>
                </div>
                <div class="p1">
                    <p id="60">其中<i>n</i>为样本个数。</p>
                </div>
                <div class="p1">
                    <p id="61">b.构建一个SBS泊松回归树估计</p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>t</mi><mo>∈</mo><mi>Τ</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msup></mrow></munder><mover accent="true"><mi>μ</mi><mo>¯</mo></mover></mstyle><msub><mrow></mrow><mi>t</mi></msub><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi><msubsup><mrow></mrow><mi>t</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63">其中<mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>Τ</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msup></mrow><mo>|</mo></mrow><mo>=</mo><mi>Κ</mi></mrow></math></mathml>表示样本数据<i>D</i><sup> (<i>m</i>) </sup>的叶子, <i>X</i><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>表示第<i>t</i>片叶子中的样本。</p>
                </div>
                <div class="p1">
                    <p id="66">c.更新估计值</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>→</mo><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>t</mi><mo>∈</mo><mi>Τ</mi><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></munder><mrow><mi>log</mi></mrow></mstyle><mo stretchy="false"> (</mo><mover accent="true"><mi>μ</mi><mo>¯</mo></mover><msubsup><mrow></mrow><mi>t</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi><msubsup><mrow></mrow><mi>t</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"> (3) 频率估计值</h4>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><mo>→</mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>exp</mi></mrow><mrow><mo>{</mo><mrow><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow></mrow><mi>Μ</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="70" name="70">2.模型估计</h4>
                <div class="p1">
                    <p id="71">将<i>K</i>=2作为Boosting算法的初始值, 则此时的回归树估计值表示为:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>}</mo></mrow></mrow></msub><mo>+</mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mo>}</mo></mrow></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sub><i>k</i></sub>由SBS回归树模型的参数估计得到。因为第一个回归树把特征空间<i>X</i>分了一次, 所以把第一个回归树估计值<mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (1) </sup>:<i>X</i>→<i>R</i><sub>+</sub>称为弱学习器。估计值<mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (1) </sup>初始化了泊松提升法, 则估计的泊松回归模型为:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub><mover><mstyle mathsize="140%" displaystyle="true"><mo>∼</mo></mstyle><mrow><mtext>i</mtext><mtext>n</mtext><mtext>d</mtext><mo>.</mo></mrow></mover><mtext>Ρ</mtext><mtext>o</mtext><mtext>i</mtext><mo stretchy="false"> (</mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mspace width="0.25em" /><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">其中<i>n</i>为样本数。接下来回测和修正这个模型, 进而用另一个回归函数来改善<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (1) </sup> (·) 。为此, 定义以下权重:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mspace width="0.25em" /><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">所以初始的索赔频率模型假设被替换为:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub><mover><mstyle mathsize="140%" displaystyle="true"><mo>∼</mo></mstyle><mrow><mtext>i</mtext><mtext>n</mtext><mtext>d</mtext><mo>.</mo></mrow></mover><mtext>Ρ</mtext><mtext>o</mtext><mtext>i</mtext><mo stretchy="false"> (</mo><mi>μ</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">回归函数被<i>K</i>=2的SBS回归树估计值重新进行估计, <i>w</i><mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>表示新的权重, 回归树估计量可以用以下形式表示:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi><msubsup><mrow></mrow><mn>1</mn><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></msub><mo>+</mo><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup><mn>1</mn><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>μ</mi><mo>^</mo></mover></math></mathml><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>可以用以下形式表示:</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mi>k</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mn>1</mn></mstyle><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>X</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></msub><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mn>1</mn></mstyle><msub><mrow></mrow><mrow><mrow><mo>{</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>X</mi><msubsup><mrow></mrow><mi>k</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow><mo>}</mo></mrow></mrow></msub><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msubsup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">改进的回归函数估计值<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (2) </sup>:<i>X</i>→<i>R</i><sub>+</sub>, 用以下形式表示:</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><mo>→</mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">因此, 以上回归函数估计值<mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (2) </sup> (·) 是两个弱学习器的组合。因此, 迭代<i>M</i>次时, 当<i>m</i>=3, …, <i>M</i>时的权重<i>w</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>可以用以下形式表示:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo>=</mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">弱学习器<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>μ</mi><mo>^</mo></mover></math></mathml><sup> (<i>m</i>) </sup>:<i>X</i>→<i>R</i><sub>+</sub>被一个权重为 (<i>w</i><sup> (<i>m</i>) </sup><sub><i>i</i></sub>) <sub><i>i</i>=1, 2, …, <i>n</i></sub>的SBS回归树分区, 并产生了<i>K</i>=2的新叶子。此时可以通过以下方式进行回归函数<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (<i>m</i>-1) </sup> (·) 的迭代更新:</p>
                </div>
                <div class="p1">
                    <p id="100" class="code-formula">
                        <mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mover accent="true"><mi>μ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>=</mo><mstyle displaystyle="true"><munder><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>2</mn></mrow></munder><mover accent="true"><mi>μ</mi><mo>^</mo></mover></mstyle><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="101">这个算法被称作泊松提升法, 最终估计值为<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (<i>M</i>) </sup>:<i>X</i>→<i>R</i><sub>+</sub>, 由<i>M</i>个弱学习器组成, 并且每个弱学习器均来自于<i>X</i>的一个分割。</p>
                </div>
                <h3 id="103" name="103" class="anchor-tag">四、实证分析</h3>
                <h4 class="anchor-tag" id="104" name="104"> (<b>一) 数据描述</b></h4>
                <div class="p1">
                    <p id="105">本文数据来源于国内某保险公司交通事故责任强制保险486 780条理赔数据, 数据的格式如表1所示。</p>
                </div>
                <div class="area_img" id="106">
                    <p class="img_tit"><b>表</b>1 <b>数据格式表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="106" border="1"><tr><td><br />区域</td><td>性别</td><td>年龄</td><td>车系</td><td>座位数</td><td>车重</td><td>车龄</td><td>转续保</td><td>NCD</td><td>暴露数</td><td>索赔次数</td></tr><tr><td><br />安徽</td><td><i>M</i></td><td>36</td><td><i>C</i></td><td>7</td><td>2.295</td><td>3.1</td><td>Ri</td><td>E1</td><td>0.4</td><td>0</td></tr><tr><td><br />广东</td><td><i>F</i></td><td>46</td><td><i>C</i></td><td>5</td><td>1.285</td><td>7.01</td><td>Rb</td><td><i>A</i></td><td>0.31</td><td>1</td></tr><tr><td><br />…</td><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td><td>…</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="107">关于数据中变量的说明如表2所示:</p>
                </div>
                <div class="p1">
                    <p id="108">从486 780条数据中随机抽取390 000条 (后面回归树建模分析中的参数minbucket=6 000, 这样可以保证训练集中至多可以分成65组) 样本作为训练集进行建模, 记为<i>L</i>={ (<i>N</i><sub><i>i</i></sub>, <i>x</i><sub><i>i</i></sub>, <i>v</i><sub><i>i</i></sub>) :<i>i</i>=1, 2, …, <i>n</i>}, 其中<i>x</i><sub><i>i</i></sub>表示训练集中各个变量, <i>n</i>=390 000, 用于模型的拟合和选择。剩余96 780条样本主要用于模型的预测分析, 记为<i>T</i>={ (<i>N</i><sub><i>t</i></sub>, <i>x</i><sub><i>t</i></sub>, <i>v</i><sub><i>t</i></sub>) :<i>t</i>=1, 2, …, <i>n</i><sup>′</sup>}, 其中<i>n</i><sup>′</sup>=96 780。</p>
                </div>
                <div class="area_img" id="109">
                    <p class="img_tit">表2 变量说明表 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="109" border="1"><tr><td><br />变量</td><td>类型</td><td>说明</td></tr><tr><td>区域<br /></td><td>分类<br /></td><td>不包括宁夏、西藏、青海、台湾、香港、澳门等。共有安徽 (<i>P</i><sub>34</sub>) 、北京 (<i>P</i><sub>11</sub>) 等28个省份。</td></tr><tr><td><br />性别</td><td>分类</td><td>女 (<i>F</i>) 、男 (<i>M</i>) 共两个等级</td></tr><tr><td><br />年龄</td><td>数值</td><td>{18, 19, …};单位:岁</td></tr><tr><td><br />车系</td><td>分类</td><td><i>A</i>～<i>E</i>共五个等级</td></tr><tr><td><br />座位数</td><td>数值</td><td>{2, 3, …};单位:个</td></tr><tr><td><br />车重</td><td>数值</td><td>&gt;0;单位:吨</td></tr><tr><td><br />车龄</td><td>数值</td><td>≥0;单位:年</td></tr><tr><td><br />转续保</td><td>分类</td><td>Nb (新保) 、Rb (续保) 和Ri (转保) 共三个等级</td></tr><tr><td><br />NCD<br /></td><td>分类<br /></td><td><i>A</i> (连续三个及以上年度未发生有责任事故) 、<i>B</i> (连续两年未发生有责任事故) 、<i>C</i> (上年度未发生有责任事故) 、<i>D</i> (过户) 、<i>E</i>1 (新保) 、<i>E</i>2 (新车) 、<i>F</i> (上年度发生一次有责任不涉及死亡的交通事故) 、<i>G</i> (上年度发生两次及两次以上有责任交通事故) 、<i>H</i> (上年度发生有责任道路交通死亡事故) </td></tr><tr><td><br />暴露数</td><td>数值</td><td> (0, 1];单位:车年</td></tr><tr><td><br />索赔次数</td><td>数值</td><td>{0, 1, 2, …};单位:次</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"> (<b>二) 变量的描述性统计</b></h4>
                <div class="p1">
                    <p id="111">由上部分可知, 本文将样本数据分为训练集和测试集。通过比较训练样本和测试样本的索赔次数和索赔频率, 我们发现二者是有区别的。具体情况如表3所示。表3反映了训练集和测试集在索赔次数和索赔频率方面的比较情况, 其中索赔次数分别为:0、1、2、3、4的样本数占训练集和测试集的比率各有不同, 具有一定的差异。在索赔频率方面:训练集的索赔频率为5.173 623%, 略低于测试集的索赔频率 (5.285 29%) 。训练集和测试集的索赔次数和索赔频率的差异会造成二者损失函数值的差异, 影响模型的效果, 具体如下节所示。</p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表</b>3 <b>训练集和测试集的索赔次数和索赔频率情况表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="112" border="1"><tr><td rowspan="2"><br />样本集</td><td colspan="5"><br />索赔次数</td><td rowspan="2">索赔频率</td></tr><tr><td><br />0</td><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>训练集 (L) </td><td>96.912 56%</td><td>3.025 897%</td><td>0.056 153 8%</td><td>0.003 846 154%</td><td>0.001 538 462%</td><td>5.173 623%</td></tr><tr><td><br />测试集 (T) </td><td>96.841 29%</td><td>3.096 714%</td><td>0.057 863 1%</td><td>0.004 133 085%</td><td>0</td><td>5.285 291%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"> (<b>三) 实证结果</b></h4>
                <h4 class="anchor-tag" id="114" name="114">1.SBS回归树模型</h4>
                <h4 class="anchor-tag" id="115" name="115"> (1) 树的生成。</h4>
                <div class="p1">
                    <p id="116">基于SBS回归树模型对训练集<i>L</i>进行建模, 该算法通过用R软件包中的rpart函数进行循环迭代来实现。关于函数rpart的相关参数首先进行简单介绍, 其中, minbucket表示生成的回归树中每片树叶至少应该包含的数据记录个数, 取minbucket的值为6 000<citation id="171" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。cp (complexity parameter) 为复杂性参数, 控制树的规模, 取值范围为 (0, 1], 其值越小则树的规模也就越大, 此处我们设置cp的初始值为0.000 5, 关于参数cp进行赋值的详细介绍参考Therneau等<citation id="172" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。我们称经过上述参数设定生成的模型为RT1, 生成的树为tree1, 树的生成通过运行summary函数可得:生成的SBS回归树一共有9片叶子和8次分割, 其中第一个分割考虑的是无赔款优待水平 (BonusMal) 是否为A、B、H类。通过观察图1, 可以发现第一个分割是最有效的分割, 因为第一个分割使样本内损失从0.225 667 6下降到0.222 932 3, 相对于其他分割来说, 第一个分割使样本内损失下降的最多。</p>
                </div>
                <div class="p1">
                    <p id="117">通过图1, 我们分析了cp值为0.000 5, 叶子数为9、分割次数为8的回归树模型及其样本内损失减少情况。接下来我们通过10折交叉验证方法来进一步决定树的最优规模和相应的样本内损失。</p>
                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201909004_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 RT1模型样本内损失减少情况图" src="Detail/GetImg?filename=images/TJLT201909004_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 RT1<b>模型样本内损失减少情况图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201909004_118.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="119" name="119"> (2) 最优子树。</h4>
                <div class="p1">
                    <p id="120">在交叉验证模型时, 10折交叉验证方法是统计学中广泛运用的方法, 这里的主要思路是把训练集<i>L</i>随机分成10个规模相等的子集<i>L</i><sub>1</sub>, <i>L</i><sub>2</sub>, …, <i>L</i><sub>10</sub>, 基于训练集<i>L</i>/<i>L</i><sub><i>v</i></sub>, <i>v</i>=1, 2, …, 10得到回归树估计值<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (-<i>v</i>) </sup>, 通过验证验证集<i>L</i><sub><i>v</i></sub>得到其样本外损失<citation id="173" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>:<image href="images/TJLT201909004_122.jpg" type="" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula">
                        <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mo stretchy="false"> (</mo><mi>L</mi><msub><mrow></mrow><mi>v</mi></msub><mo>, </mo><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>-</mo><mi>v</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mrow><mi>L</mi><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>L</mi><msub><mrow></mrow><mi>v</mi></msub></mrow></munder><mn>2</mn></mstyle><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mo>[</mo><mrow><mfrac><mrow><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>-</mo><mi>v</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>-</mo><mn>1</mn><mo>-</mo><mi>log</mi><mo stretchy="false"> (</mo><mfrac><mrow><mover accent="true"><mi>λ</mi><mo>^</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mo>-</mo><mi>v</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="124">重复上述过程, 可以得到10折交叉验证误差:</p>
                </div>
                <div class="p1">
                    <p id="125"><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>C</mtext><mtext>V</mtext><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mn>0</mn></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>v</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>1</mn><mn>0</mn></mrow></munderover><mrow></mrow></mstyle></mrow></math></mathml><image href="images/TJLT201909004_127.jpg" type="" display="inline" placement="inline"><alt></alt></image> (<i>L</i><sub><i>v</i></sub>, <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>λ</mi><mo>^</mo></mover></math></mathml><sup> (-<i>v</i>) </sup>) </p>
                </div>
                <div class="p1">
                    <p id="129">运用上述10折交叉验证原理, 我们首先设置cp=10<sup>-8</sup> (初始值设置尽可能小) 来生成一个规模较大的SBS回归树, 我们称这个回归树为tree2, 这个回归树一共有<i>K</i>=35片叶子。对tree2进行10折交叉验证, 根据最小交叉验证误差规则, 判断模型tree2是否为最优子树, 我们称这个模型为RT2。回归树tree2的交叉验证误差和相应的标准误差条如图2a所示:</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201909004_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 模型RT2和RT3的10折交叉验证情况图" src="Detail/GetImg?filename=images/TJLT201909004_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 <b>模型</b>RT2<b>和</b>RT3<b>的</b>10<b>折交叉验证情况图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201909004_13200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="133">通过观察图2a可以发现:交叉验证误差 (CV error) 在成本复杂性参数 (cost-complexity parameter) 接近-5时达到最小, 在-8时交叉验证误差不变, 因此RT2存在严重的过拟合问题。通过选择最小的交叉验证误差以及对应的cp值, 重新生成树tree3以及对应的最小交叉验证规则模型为RT3, 树tree3共有35片叶子, 如图2b所示, cp=2.520 53<sup>e-04</sup>时有最小的10折交叉验证误差, 也不存在过拟合现象, 可以认为RT3是最优子树。</p>
                </div>
                <div class="p1">
                    <p id="134">下面结合上一节所述的样本内和样本外损失函数的表达式, 我们分别计算RT1、RT2、RT3的样本内和样本外损失, 具体情况如表4所示:</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表</b>4 <b>三种回归树模型的样本表</b> 单位:10<sup>-2</sup> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td><br /></td><td>样本内损失</td><td>样本外损失</td></tr><tr><td><br />RT1 (9片叶子) </td><td>22.085 88</td><td>22.541 31</td></tr><tr><td><br />RT2 (35片叶子) </td><td>21.973 70</td><td>22.494 99</td></tr><tr><td><br />RT3 (35片叶子) </td><td>21.973 70</td><td>22.494 99</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="136">从上表我们发现模型RT2的样本内外损失和模型RT3的一样, 但都低于模型RT1的相关水平, 初步可以认为回归树规模越大 (即叶子数越多) , 则回归模型的样本偏差越小, 损失也就越小。虽然模型RT2的样本损失和模型RT3的相关损失一样, 但模型RT2设置的初始cp值过小, 可能会存在过拟合问题, 模型RT3是通过10折交叉验证方法验证得到的最优模型。理论上最优子树的选择很重要, 不仅能提高模型的效果, 也能减少过拟合问题。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137">2.泊松提升回归模型</h4>
                <div class="p1">
                    <p id="138">考虑用Poisson Boosting Machine Model (泊松提升模型) 进行索赔频率建模。泊松提升模型是基于以泊松偏差统计量为损失函数的SBS (Standardized Binary Split) 回归树算法。该算法通过用R软件包中的rpart函数进行循环迭代来实现。本文把<i>J</i>=1的泊松Boosting 算法模型称为模型PBM1, 通过编程计算得到模型PBM1的样本内外损失分别为:21.984 28×10<sup>-2</sup>和22.466 05×10<sup>-2</sup>, 此时模型PBM1的样本内损失高于模型RT3的样本内损失, 而模型PBM1的样本外损失却低于模型RT3的样本外损失。为了改善模型的样本内损失情况, 不仅可以增加迭代次数<i>M</i>, 而且还可以增加树的深度<i>J</i>, 或者两者同时增加, 从图3发现3个模型随着迭代次数的增加, 样本内损失减少的曲线比较平滑, 所以本文中主要分析增加树的深度对模型样本内损失的影响。在保证算法运行速度的前提下, 又不至于使模型出现过拟合的问题, 我们选择的迭代次数<i>M</i>值相对较小。同理, 我们把<i>J</i>=2, 3的泊松Boosting 算法模型分别称为模型PBM2, PBM3。汇总模型PBM1, PBM2, PBM3与RT3的各种样本内外损失情况如表5所示。</p>
                </div>
                <div class="area_img" id="139">
                    <p class="img_tit"><b>表</b>5 <b>三种泊松</b>Boosting<b>算法模型和模型</b>RT3<b>样本损失情况表</b> 单位:10<sup>-2</sup> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="139" border="1"><tr><td><br />模型    </td><td>样本内损失</td><td>样本外损失</td></tr><tr><td><br />PBM1 (<i>J</i>=1, <i>M</i>=10) </td><td>21.984 28</td><td>22.466 05</td></tr><tr><td><br />PBM2 (<i>J</i>=2, <i>M</i>=10) </td><td>21.898 98</td><td>22.462 03</td></tr><tr><td><br />PBM3 (<i>J</i>=3, <i>M</i>=15) </td><td>21.771 21</td><td>22.461 84</td></tr><tr><td><br />PBM3 (<i>J</i>=3, <i>M</i>=20) </td><td>21.728 72</td><td>22.502 94</td></tr><tr><td><br />RT3 (35片叶子) </td><td>21.973 70</td><td>22.494 99</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="140">通过表5发现:模型PBM3 (<i>J</i>=3, <i>M</i>=20) 的样本内损失低于模型PBM3 (<i>J</i>=3, <i>M</i>=15) 的样本内损失, 而该模型的样本外损失却高于模型PBM3 (<i>J</i>=3, <i>M</i>=15) 的样本外损失, 说明当迭代次数<i>M</i>=20时, 模型PBM3存在过拟合问题。所以PBM3的最大迭代次数<i>M</i>=15。在模型PBM1和模型PBM2不存在过拟合问题的前提下, 为了便于比较分析, 本文中确定模型PBM1和模型PBM2的迭代次数<i>M</i>=10。</p>
                </div>
                <div class="p1">
                    <p id="141">通过比较模型PBM1 (<i>J</i>=1, <i>M</i>=10) 与PBM2 (<i>J</i>=2, <i>M</i>=10) , 不难发现PBM2的样本内外损失低于PBM1的相关样本损失情况, 说明在迭代次数<i>M</i>保持不变的情况下, 随着树的深度<i>J</i>的增加, 模型的样本内外损失情况不断减小, 模型得到优化。同理, 通过比较模型PBM3 (<i>J</i>=3, <i>M</i>=15) 与PBM2 (<i>J</i>=2, <i>M</i>=10) , PBM1 (<i>J</i>=1, <i>M</i>=10) 的表现, 发现模型PBM3的样本内外损失情况低于PBM2与PBM1的相关样本损失情况, 说明在不存在过拟合问题的前提下, 该模型随着树的深度<i>J</i>和迭代次数<i>M</i>的同时增加, 模型的样本内外损失情况是不断减小的, 模型得到进一步的优化。相对于PBM1 (<i>J</i>=1, <i>M</i>=10) , PBM2 (<i>J</i>=2, <i>M</i>=10) 和RT3而言, PBM3 (<i>J</i>=3, <i>M</i>=15) 的样本内外损失是最小的, 模型PBM3是最优的模型。</p>
                </div>
                <div class="p1">
                    <p id="142">PBM1 (<i>J</i>=1, <i>M</i>=10) , PBM2 (<i>J</i>=2, <i>M</i>=10) , PBM3 (<i>J</i>=3, <i>M</i>=15) 和RT3的样本内损失情况如图3所示:</p>
                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201909004_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 三种不同泊松Boosting算法模型和RT3的样本内损失情况图" src="Detail/GetImg?filename=images/TJLT201909004_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 <b>三种不同泊松</b>Boosting<b>算法模型和</b>RT3<b>的样本内损失情况图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201909004_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="144">图3中三角形表示模型PBM1的样本内损失情况, 空心圆表示模型PBM2的样本内损失情况, 实心点表示模型PBM3的样本内损失情况, 实线表示模型RT3的样本内损失情况。通过观察上图发现, 虽然模型PBM1 (<i>J</i>=1, <i>M</i>=10) 的样本内损失随着迭代次数的增加而不断降低, 但是始终高于模型RT3的样本内损失。由于模型PBM1的深度和迭代次数较小, 使得模型PBM1的表现不如模型RT3。在保持模型PBM1的迭代次数<i>M</i>=10不变的情况下, 增加树的深度到<i>J</i>=2则得到模型PBM2。从上图容易发现模型PBM2在迭代到第5次时, 样本内损失已经低于模型RT3的样本内损失, 在保持迭代次数不变的情况下, 增加树的深度, 使模型的样本内损失不断减少, 模型得到优化。同理, 在树的深度增加到<i>J</i>=3以及迭代次数增加到<i>M</i>=15时得到模型PBM3, 相对于模型PBM1, PBM2而言, 随着每次迭代的进行, 模型PBM3的样本内损失减少的更快, 且在迭代到第4次时, 模型PBM3的样本内损失已经低于模型RT3的样本内损失情况。所以, 在模型PBM1、PBM2、PBM3和模型RT3四个模型中, 模型PBM3的样本内外损失最小, 模型PBM3是相对较优的模型。</p>
                </div>
                <h4 class="anchor-tag" id="145" name="145">3.模型的预测分析</h4>
                <div class="p1">
                    <p id="146">通过上述分析, 选择相对较优的泊松提升模型PBM3, 用测试集<i>T</i>对模型PBM3进行单变量预测分析。在进行预测分析之前, 确定不同变量在测试集中出现次数最多的数值或因素为各个变量的固定取值, 具体为:保单省份 (Region) 为P37, 驾驶员年龄 (DrivAge) 为50, 驾驶员性别 (Gender) 为<i>M</i>, 汽车座位数 (Seat) 为5, 汽车重量 (Weight) 为2, 汽车车龄 (VehAge) 为6, 无赔款优待水平 (BonusMalus) 为<i>A</i>, 转续保 (renew) 为Ri, 车系 (VehBrand) 为<i>C</i>。对某一变量 (例如变量Region) 进行单变量预测时, 该变量的数据为测试集中的观察值, 其他变量的数据则全部为对应变量设置的初始固定值。其中各个变量的预测情况如图4所示。上面各个图中, 横坐标表示对应各个变量的分组情况, 纵坐标表示各个变量不同分组对应的预测频率大小。</p>
                </div>
                <div class="p1">
                    <p id="147">从保单省份 (Region) 频率预测情况图中, 我们发现:在其他因素不变时, 各个省份的交强险索赔频率的预测值不同, 其中索赔频率最高的省份P43 (湖南省) 为0.078 5, 索赔频率最低的省份P50 (重庆市) 为0.029 1。由于各个地区社会、经济、文化、气候以及地理环境的差别, 使得各个省份的交强险索赔频率出现差异。所以, 在未来的交强险定价工作中, 也应将地区因素作为一个定价因子加以考虑。</p>
                </div>
                <div class="p1">
                    <p id="148">从汽车车龄 (VehAge) 频率预测情况图发现:在其他因素不变时, 索赔频率大体上随着汽车车龄的增加而增大。具体表现为:在汽车车龄为0～2时, 索赔频率为0.038 4, 达到了最小, 除了在汽车车龄为6时出现了较小的波动外, 其余的索赔频率总是随着汽车车龄的增加而增大的, 特别是当汽车车龄大于11时, 索赔频率达到了最大为0.065 6。说明在其他条件不变的情况, 新车由于机器设备性能较好, 此时驾驶的安全性较高, 出事故的概率则较小, 反之, 旧车随着机器设备的老化等原因使驾驶的危险性较高, 出事故的概率则较大。</p>
                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201909004_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 各个单变量预测结果图" src="Detail/GetImg?filename=images/TJLT201909004_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>4 <b>各个单变量预测结果图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201909004_149.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="150">从驾驶员车龄 (DrivAge) 频率预测情况图中, 我们发现:在其他因素不变时, 驾驶员年龄在18～46时, 索赔频率呈缓慢下降的趋势, 其中驾驶员年龄为18～24时索赔频率为0.073 5, 达到了最大, 年轻的驾驶员由于驾驶经验缺乏、年轻气盛、爱开“冲动车, 斗气车”等原因, 导致出事故的概率较大, 索赔频率较高。随着年龄以及驾驶经验的增加, 中年人出事故的概率较小, 索赔频率较小。另外, 驾驶员年龄在47～80时, 索赔频率又有增加的趋势, 特别是55～80的驾驶员, 随着年龄的增加, 应急能力下降, 导致出事故的概率增加, 索赔频率较大。</p>
                </div>
                <div class="p1">
                    <p id="151">从汽车座位数 (Seat) 频率预测情况图中, 我们发现:在其他因素不变时, 汽车座位数在小于6座时, 索赔频率为0.050 49, 相对较低, 在大于等于6座时, 索赔频率为0.054 5, 有所增大。</p>
                </div>
                <div class="p1">
                    <p id="152">从驾驶员性别 (Gender) 频率预测情况图中, 我们发现:在其他因素不变时, 男性的索赔频率 (0.050 486) 低于女性的索赔频率 (0.053 092 261) 。由于身体和心理原因使得女性出事故的概率大于男性, 索赔频率高于男性。同时, 相关研究表明:女性出小事故的概率高于男性, 但是男性出致死或较大损害事故的概率高于女性。</p>
                </div>
                <div class="p1">
                    <p id="153">从汽车重量 (Weight) 频率预测情况图中, 我们发现:在其他因素不变时, 索赔频率随汽车重量的增加而增大, 汽车重量低于0.5时, 索赔频率为0.030 3, 达到了最小;在汽车重量为1时, 索赔频率为0.035 2;当汽车重量大于等于2时, 索赔频率为0.039 7, 此时索赔频率达到了最大。</p>
                </div>
                <div class="p1">
                    <p id="154">从无赔款优待水平 (BonusMalus) 频率预测情况图中, 我们发现:在其他因素不变时, 无赔款优待水平越高, 即历史索赔次数越少, 则索赔频率越低。其中, 无赔款优待水平为<i>G</i> (上年度发生两次及两次以上有责任交通事故) 时, 索赔频率最高为0.108 3, 而无赔款优待水平为<i>H</i> (上年度发生有责任道路交通死亡事故) 时, 索赔频率最低为0.037 9, 主要是因为本文中<i>H</i>类的索赔保单的索赔次数都是0次, 所以本文预测的索赔频率相对较小。</p>
                </div>
                <div class="p1">
                    <p id="155">汽车类型 (Veh Brand) 所有不同分类的索赔频率都为0.050 485 767, 初步分析由于样本数据中<i>C</i>系车的样本数为89 908个, 占测试样本集的绝大部分, 文章中该车系的索赔频率影响了其他车系的索赔频率。同样, 转续保 (renew) 所有索赔频率一样, 都为0.050 485 767。</p>
                </div>
                <h3 id="156" name="156" class="anchor-tag">五、结 论</h3>
                <div class="p1">
                    <p id="157">本文将Boosting算法加入到SBS回归树模型中, 并且比较Boosting算法加入前后模型效果的变化情况, 得到相对较优的模型, 并用较优的模型对测试集进行单变量索赔频率预测分析。在模型选择和索赔频率预测分析的过程中总结得出以下结论:</p>
                </div>
                <div class="p1">
                    <p id="158">第一, 模型RT3是通过10折交叉验证方法得到的最优子树, 其表现优于模型RT1和RT2, 在回归树分析中, 剪枝等处理工作对确定最优子树很必要。在模型RT3中加入Boosting算法得到了泊松提升模型, 至于泊松提升模型, 在保证不存在过拟合问题的前提下, 随着树的深度和迭代次数二者中的其一或者二者同时增加, 则模型效果不断得到改进。基于本文中的训练集, 最终确定了深度为3, 迭代次数为15的模型PBM3为最优模型。</p>
                </div>
                <div class="p1">
                    <p id="159">第二, 通过用测试集对模型PBM3分别进行单变量预测分析我们得到:在其他因素不变的条件下, 由于各个省份 (Region) 社会、经济和自然环境的差异, 使得各个省份的交强险索赔频率各不相同;索赔频率大体上是随着汽车车龄 (VehAge) 的增加而增大的;驾驶员车龄 (Drivage) 为18～24时的索赔频率最高, 即年轻人的索赔频率最高, 老年人的索赔频率次高, 中年人的索赔频率最低;汽车座位数 (Seat) 小于6座的索赔频率低于汽车座位数 (Seat) 大于等于6座的索赔频率;男性的索赔频率低于女性的索赔频率;索赔频率随汽车重量 (Weight) 的增加而增大;无赔款优待水平 (BonusMalus) 越高, 即历史索赔次数越少, 索赔频率则越低。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14112600629087&amp;v=MDQ3ODZNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJKS0YwVmFobz1OaWZZZXJLOEg5RE9xWTlGWXVrR0RIUStvQg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Friedman J.Greedy Function Approximation:A Gradient Boosting Machine[J].The Annals of Statistics, 2001 (29) .
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638247&amp;v=MTczNzA0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyYkpLRjBWYWhvPU5pZk9mYks3SHRETnFvOUVZdWdIRG5nK29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Guelman L.Gradient Boosting Trees for Auto Insurance Loss Cost Modeling and Prediction[J].Expert Systems with Applications, 2012, 39 (3) .
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJSL&amp;filename=SJSL15032400000004&amp;v=MTMzODJubFVyYkpLRjBWYWhvPU5pZllZcks5SHRMT3E0OUZaT3NQREh3OW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Liu Y, Wang B J, Lv S G.Using Multi-class AdaBoost Tree for Prediction Frequency of Auto Insurance[J].Journal of Applied Finance &amp; Banking, 2014, 4 (5) .
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Data Science in Non-Life Pricing:Predicting Claims Frequencies Using Tree-Based Models">

                                <b>[4]</b> Zöchbauer P.Data Science in Non-Life Pricing:Predicting Claims Frequencies Using Tree-Based Models[D].ETH Zürich:Department of Mathematics, 2016.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Price Stability in Regression Tree Calibrations">

                                <b>[5]</b> Wüthrich M V.Price Stability in Regression Tree Calibrations[E].2017 China International Conference on Insurance and Risk Management, July 19-22, 2017.Guilin, China, 749-762.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Case Study:French Motor Third-Party Liability Claims">

                                <b>[6]</b> Noll A, Salzmann R, Wuthrich M V.Case Study:French Motor Third-Party Liability Claims[J/OL].SSRN Electronic Journal, 2018.https://ssm.com/abstract=3164764.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201801010&amp;v=Mjg0MjdmWnVabkZpRG1Vci9BSnpYU1pMRzRIOW5Ncm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 张连增, 谢厚谊.回归树方法在车险索赔频率预测建模中的应用[J].保险研究, 2018 (1) .
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BXYJ201808003&amp;v=MDUwMDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEbVVyL0FKelhTWkxHNEg5bk1wNDlGWjRRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 孟生旺, 黄一凡.驾驶行为保险的风险预测模型研究[J].保险研究, 2018 (8) .
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201901009&amp;v=MzE5MjhIOWpNcm85RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRG1Vci9BTVNmSGVyRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 张连增, 王缔.大额索赔条件下的车险费率厘定[J].统计与信息论坛, 2019 (1) .
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Data Analytics for Non-life Insurance Pricing">

                                <b>[10]</b> Wüthrich M V, Buser C.Data Analytics for Non-Life Insurance Pricing[R].ETH Zürich, 2018:119-125.https://ssrn.com/abstract=2870308.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MzIxNDFJMU5ZK3NQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5zVXJmTElWNGNYRnF6R2JDNEhOWE9y&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 周志华.机器学习[M].北京:清华大学出版社, 2016:173-177.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Introduction to Recursive Partitioning Using the RPART Routines">

                                <b>[12]</b> Therneau T M, Atkinson E J, Foundation M.An Introduction to Recursive Partitioning Using the RPART Routines[R].Vignettes, 2015.https://cran:r-project.org/web/packages/rpart/vignetts/longintro.pdf.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Introduction to Statistical Learning with Applications in R">

                                <b>[13]</b> James G, Witten D, Hastie T, Tibshirani R.An Introduction to Statistical Learning with Applications in R[M].Berlin:Springer, 2013:181-183.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="TJLT201909004" />
        <input id="dpi" type="hidden" value="800" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201909004&amp;v=MTU2NDFyQ1VSN3FmWnVabkZpRG1Vci9BTVNmSGVyRzRIOWpNcG85RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

