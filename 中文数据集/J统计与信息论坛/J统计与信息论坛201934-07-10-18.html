

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637140714831537500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dTJLT201907002%26RESULT%3d1%26SIGN%3d69VERXfK2WqbZbprHukWWe%252bOL8A%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJLT201907002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=TJLT201907002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201907002&amp;v=MzE2Mjk5ak1xSTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEbFU3ekpNU2ZIZXJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#1" data-title="一、引言 ">一、引言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#7" data-title="二、结构张量空间模型 ">二、结构张量空间模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#8" data-title=" (一) 向量空间模型到张量空间模型"> (一) 向量空间模型到张量空间模型</a></li>
                                                <li><a href="#14" data-title=" (二) 结构张量空间模型"> (二) 结构张量空间模型</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#44" data-title="三、基于STSM的文本分类 ">三、基于STSM的文本分类</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title=" (一) STM分类模型的一般形式"> (一) STM分类模型的一般形式</a></li>
                                                <li><a href="#54" data-title=" (二) 基于交替优化的高阶STM学习算法"> (二) 基于交替优化的高阶STM学习算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="四、实验结果与分析 ">四、实验结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title=" (一) 实验环境"> (一) 实验环境</a></li>
                                                <li><a href="#60" data-title=" (二) 实验语料"> (二) 实验语料</a></li>
                                                <li><a href="#68" data-title=" (三) 实验结果分析"> (三) 实验结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="五、结束语 ">五、结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#10" data-title="图1 向量空间模型图">图1 向量空间模型图</a></li>
                                                <li><a href="#12" data-title="图2 VSM到TSM的映射图">图2 VSM到TSM的映射图</a></li>
                                                <li><a href="#17" data-title="图3 文本的分层表示模型图">图3 文本的分层表示模型图</a></li>
                                                <li><a href="#39" data-title="图4 基于分层表示的结构张量空间模型图">图4 基于分层表示的结构张量空间模型图</a></li>
                                                <li><a href="#63" data-title="表1 搜狗语料类别以及数量表">表1 搜狗语料类别以及数量表</a></li>
                                                <li><a href="#66" data-title="表2 复旦语料类别以及数量表">表2 复旦语料类别以及数量表</a></li>
                                                <li><a href="#73" data-title="表3 层次实验结果表">表3 层次实验结果表</a></li>
                                                <li><a href="#80" data-title="图5 实验A结果比较图">图5 实验A结果比较图</a></li>
                                                <li><a href="#84" data-title="表4 实验A分类结果比较表">表4 实验A分类结果比较表</a></li>
                                                <li><a href="#85" data-title="图6 实验B结果比较图">图6 实验B结果比较图</a></li>
                                                <li><a href="#86" data-title="表5 实验B分类结果比较表">表5 实验B分类结果比较表</a></li>
                                                <li><a href="#92" data-title="图7 复旦语料下的分类实验图">图7 复旦语料下的分类实验图</a></li>
                                                <li><a href="#93" data-title="表6 实验C分类结果比较表">表6 实验C分类结果比较表</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>
                                    <dd class="subnode">
                                        <h6>
                                            <a href="#a_footnote">注释</a>

                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="100">


                                    <a id="bibliography_1" title="Salton G, Wong A, Yang C S.A Vector Space Model for Automatic Indexing[J].Communications of the ACM, 1975, 18 (11) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000024403&amp;v=MDQ3NjBOaWZJWTdLN0h0ak5yNDlGWk9rTENIdzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyYkpLRjRVYVJNPQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        Salton G, Wong A, Yang C S.A Vector Space Model for Automatic Indexing[J].Communications of the ACM, 1975, 18 (11) .
                                    </a>
                                </li>
                                <li id="102">


                                    <a id="bibliography_2" title="王婷婷, 韩满, 王宇.基于&quot;21世纪海上丝绸之路&quot;文献的文本挖掘研究[J].统计与信息论坛, 2017, 32 (11) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201711011&amp;v=MzE2MzZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURsVTd6Sk1TZkhlckc0SDliTnJvOUU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        王婷婷, 韩满, 王宇.基于&quot;21世纪海上丝绸之路&quot;文献的文本挖掘研究[J].统计与信息论坛, 2017, 32 (11) .
                                    </a>
                                </li>
                                <li id="104">


                                    <a id="bibliography_3" title="刘怀亮, 杜坤, 秦春秀.基于知网语义相似度的中文文本分类研究[J].现代图书情报技术, 2015, 31 (2) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDTQ201502007&amp;v=MjA1MzQ5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGxVN3pKUFNuZmY3RzRIOVRNclk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                        刘怀亮, 杜坤, 秦春秀.基于知网语义相似度的中文文本分类研究[J].现代图书情报技术, 2015, 31 (2) .
                                    </a>
                                </li>
                                <li id="106">


                                    <a id="bibliography_4" title="Liu H, Bao H, Xu D.Concept Vector for Semantic Similarity and Relatedness Based on WordNet Structure[J].Journal of Systems and Software, 2012, 85 (2) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300675447&amp;v=MDU1NjVyYkpLRjRVYVJNPU5pZk9mYks3SHRET3JJOUZZdXdLQ0hnK29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        Liu H, Bao H, Xu D.Concept Vector for Semantic Similarity and Relatedness Based on WordNet Structure[J].Journal of Systems and Software, 2012, 85 (2) .
                                    </a>
                                </li>
                                <li id="108">


                                    <a id="bibliography_5" title="Cai D, He X, Han J.Learning with Tensor Representation.Department of Computer Science Technical Report[R].Urbana:University of Illinois at Urbana-Champaign, 2006." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning with tensor representation">
                                        <b>[5]</b>
                                        Cai D, He X, Han J.Learning with Tensor Representation.Department of Computer Science Technical Report[R].Urbana:University of Illinois at Urbana-Champaign, 2006.
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_6" title="俞炯, 刘功申.基于支持张量机的文本分类研究[J].信息技术, 2016 (9) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201609003&amp;v=MjU2ODNSWkxHNEg5Zk1wbzlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEbFU3ekpMU24=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        俞炯, 刘功申.基于支持张量机的文本分类研究[J].信息技术, 2016 (9) .
                                    </a>
                                </li>
                                <li id="112">


                                    <a id="bibliography_7" title="何伟, 胡学钢, 谢飞.基于张量空间模型的中文文本分类[J].合肥工业大学学报:自然科学版, 2010, 33 (12) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEFE201012013&amp;v=MDc4NjZHNEg5SE5yWTlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEbFU3ekpMU2pOYTc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                        何伟, 胡学钢, 谢飞.基于张量空间模型的中文文本分类[J].合肥工业大学学报:自然科学版, 2010, 33 (12) .
                                    </a>
                                </li>
                                <li id="114">


                                    <a id="bibliography_8" title="Tao D, Li X, Hu W, et al.Supervised Tensor Learning[J].Knowledge&amp;amp;Information Systems, 2007, 13 (1) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001682552&amp;v=MTI3OTg4PU5qN0Jhck80SHRITnFZZEhZZTROWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaUhrVzcvSUkx&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                        Tao D, Li X, Hu W, et al.Supervised Tensor Learning[J].Knowledge&amp;amp;Information Systems, 2007, 13 (1) .
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_9" title="Chen Y, Wang K, Zhong P.One-class Support Tensor Machine[J].Knowledge-Based Systems, 2016, 96." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES85C2E528931110A0CFE01755AB20E335&amp;v=MjA5OTAxTmJlZ09EWDA1dmhaZ25FcDlTWGpucVdOSGU3TGhScm1hQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dEZnekxpL3c2az1OaWZPZmJ1OWJkTzVxbw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Chen Y, Wang K, Zhong P.One-class Support Tensor Machine[J].Knowledge-Based Systems, 2016, 96.
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_10" title="Hao Z, He L, Chen B, et al.A Linear Support Higher-order Tensor Machine for Classification[J].IEEE Transactions on Image Processing, 2013, 22 (7) ." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Linear Support Higher-Order Tensor Machine for Classification">
                                        <b>[10]</b>
                                        Hao Z, He L, Chen B, et al.A Linear Support Higher-order Tensor Machine for Classification[J].IEEE Transactions on Image Processing, 2013, 22 (7) .
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_11" title="Guo W, Kotsia I, Patras I.Tensor Learning for Regression[J].IEEE Transactions on Image Processing, 2012, 21 (2) ." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor Learning for Regression">
                                        <b>[11]</b>
                                        Guo W, Kotsia I, Patras I.Tensor Learning for Regression[J].IEEE Transactions on Image Processing, 2012, 21 (2) .
                                    </a>
                                </li>
                                <li id="122">


                                    <a id="bibliography_12" title="Kotsia I, Guo W, Patras I.Higher Rank Support Tensor Machines for Visual Recognition[J].Pattern Recognition, 2012, 45 (12) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600737717&amp;v=MTY2NDdsVXJiSktGNFVhUk09TmlmT2ZiSzdIdEROcVk5RlkrZ0lDMzArb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        Kotsia I, Guo W, Patras I.Higher Rank Support Tensor Machines for Visual Recognition[J].Pattern Recognition, 2012, 45 (12) .
                                    </a>
                                </li>
                                <li id="124">


                                    <a id="bibliography_13" title="Sun W W, Lu J, Han L, et al.Provable Sparse Tensor Decomposition[J].Journal of the Royal Statistical Society, 2017, 79 (3) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWDA4AD39436D87F08B39082535A44A17D4&amp;v=MTI2NjdtYUJ1SFlmT0dRbGZCckxVMDV0Rmd6TGkvdzZrPU5pZmNhc0s4YjZYUHBvdEdZcDhIQ3dvNXgyUVE0ejkxU25yaHFXTXhmY09WUXM2YkNPTnZGU2lXV3I3SklGcA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        Sun W W, Lu J, Han L, et al.Provable Sparse Tensor Decomposition[J].Journal of the Royal Statistical Society, 2017, 79 (3) .
                                    </a>
                                </li>
                                <li id="126">


                                    <a id="bibliography_14" title="Zhou H, Li L, Zhu H.Tensor Regression with Applications in Neuroimaging Data Analysis[J].Journal of the American Statistical Association, 2013, 108 (502) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13070900000789&amp;v=MjY0NjdGWk9zUEMzUXdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyYkpLRjRVYVJNPU5qbkJhcks3SHRiTXBvOQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        Zhou H, Li L, Zhu H.Tensor Regression with Applications in Neuroimaging Data Analysis[J].Journal of the American Statistical Association, 2013, 108 (502) .
                                    </a>
                                </li>
                                <li id="128">


                                    <a id="bibliography_15" title="Salton G, Allan J, Buckley C.Automatic Structuring and Retrieval of Large Text Files[J].Communications of the ACM1994, 37 (2) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000000060&amp;v=MTIzMDhOaWZJWTdLN0h0ak5yNDlGWk9zUERIbzVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyYkpLRjRVYVJNPQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                        Salton G, Allan J, Buckley C.Automatic Structuring and Retrieval of Large Text Files[J].Communications of the ACM1994, 37 (2) .
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_16" title="林鸿飞, 战学刚, 姚天顺.基于概念的文本结构分析方法[J].计算机研究与发展, 2000, 37 (3) ." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200003010&amp;v=MjIwNjl1Wm5GaURsVTd6Skx5dlNkTEc0SHRITXJJOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        林鸿飞, 战学刚, 姚天顺.基于概念的文本结构分析方法[J].计算机研究与发展, 2000, 37 (3) .
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=TJLT" target="_blank">统计与信息论坛</a>
                2019,34(07),10-18             </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于结构张量空间模型的文本分类</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BA%84%E5%BB%BA%E6%98%8C&amp;code=42128178&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">庄建昌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AD%A6%E5%A8%87&amp;code=42128179&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武娇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B4%AA%E5%BD%A9%E5%87%A4&amp;code=42128180&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">洪彩凤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A1%BE%E5%85%B4%E5%85%A8&amp;code=36172696&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">顾兴全</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E8%AE%A1%E9%87%8F%E5%A4%A7%E5%AD%A6%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=1699595&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国计量大学理学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E8%AE%A1%E9%87%8F%E5%A4%A7%E5%AD%A6%E6%A0%87%E5%87%86%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国计量大学标准化学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在自然语言处理中, 将非结构化的文本数据表示成结构化数据是文本处理工作的基础, 文本表示的优劣对后期文本处理的效果有直接的影响。提出一种新的结构化文本表示模型——结构张量空间模型, 该模型将文本按照其自身的层次含义进行分层表示, 相比较于传统的文本表示模型, 更充分地体现文本的结构信息。研究了基于结构张量空间模型的文本分类问题, 实验结果表明, 在小样本数据下, 结合结构张量空间模型的分类器性能更好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">向量空间模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BB%93%E6%9E%84%E5%BC%A0%E9%87%8F%E7%A9%BA%E9%97%B4%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">结构张量空间模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">文本分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%BC%A0%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持张量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    庄建昌, 男, 福建三明人, 硕士生, 研究方向:文本挖掘, 机器学习;;
                                </span>
                                <span>
                                    武娇, 女, 陕西西安人, 博士, 副教授, 研究方向:统计机器学习, 文本挖掘;;
                                </span>
                                <span>
                                    洪彩凤, 女, 浙江金华人, 硕士生, 研究方向:文本挖掘, 机器学习;;
                                </span>
                                <span>
                                    顾兴全, 男, 甘肃武威人, 副教授, 研究方向:标准化与大数据, 文本挖掘。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目《基于超稀疏结构学习的压缩感知重建研究》 (61302190);</span>
                    </p>
            </div>
                    <h1>Structured Tensor Space Model for Text Classification</h1>
                    <h2>
                    <span>ZHUANG Jian-chang</span>
                    <span>WU Jiao</span>
                    <span>HONG Cai-feng</span>
                    <span>HU Xing-quan</span>
            </h2>
                    <h2>
                    <span>College of Science, China Jiliang University</span>
                    <span>College of Standardization, China Jiliang University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In natural language processing, the representation of unstructured text into structured data is the basis of text processing, which has a direct impact on the results of text processing.Here, a new structured text representation model is proposed, the structured tensor space model (STSM) , which provides a hierarchical representation of text according to its own meaning and contains more structural information of text than traditional text representation model.The experimental results of the STSM-based text classification show that the classifier with STSM performs better under small sample data.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=vector%20space%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">vector space model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sturctured%20tensor%20space%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sturctured tensor space model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=text%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">text classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=support%20tensor%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">support tensor machine;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-03</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="1" name="1" class="anchor-tag">一、引言</h3>
                <div class="p1">
                    <p id="2">自然语言处理 (Natural Language Processing, NLP) 在人工智能中占据着重要的地位。自然语言处理的任务是使用计算机并结合机器学习算法处理各类文本数据、挖掘文本信息。文本数据是一种非结构化的数据, 计算机无法直接对文本进行处理, 因此必须将其转变成结构化的数据, 才能开展进一步的文本作业。文本数据的结构化表示对后续工作有直接的影响, 因此文本的表示模型是文本处理领域的一个研究热点。</p>
                </div>
                <div class="p1">
                    <p id="3">到目前为止, 传统的向量空间模型 (Vector Space Model, VSM) 是文本表示的主流模型<citation id="132" type="reference"><link href="100" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。该模型将文本转化为向量的形式, 向量中各维度的值对应着文本的各个特征。由于VSM操作简单, 容易理解, 在自然语言处理领域倍受关注, 许多相关工作都是以VSM为基础开展的<citation id="135" type="reference"><link href="102" rel="bibliography" /><link href="104" rel="bibliography" /><link href="106" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。但是基于VSM的文本表示假设文本特征是相互独立的, 导致文本的语义信息丢失, 因此, 一些学者针对此问题进行了深入研究。刘怀亮等依据知网的知识系统, 提出基于知网语义相似度的中文文本分类方法<citation id="133" type="reference"><link href="104" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 在进行文本相似性计算时, 考虑了同义词的影响。但该方法仍是以VSM为基础, 并未对文本的表示模型做出修改。Liu等则依据WordNet structure来构造概念向量, 并用之研究文本语义相关性<citation id="134" type="reference"><link href="106" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。所谓概念向量, 就是把原本用特征来构造的向量改成用概念来表示的向量, 相比较特征, 概念的适应性更强, 构造的向量模型维度更低。</p>
                </div>
                <div class="p1">
                    <p id="4">为了解决VSM的高维度问题, Cai等通过某种规则将文本的向量表示映射成二阶张量表示, 提出文本的张量空间模型 (Tensor Space Model, TSM) , 并基于此模型提出支持张量机 (Support Tensor Machine, STM) 算法解决文本分类问题, 实验证明了TSM在小样本数据下较传统模型更具有优势<citation id="136" type="reference"><link href="108" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。俞炯等通过对小样本及数据不平衡情况下的文本分类实验, 也证实了TSM优于传统VSM模型<citation id="137" type="reference"><link href="110" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。何伟等将TSM与KNN (k-nearest neighbors algorithm) 结合进行文本的多分类实验, 结果表明多分类任务中, TSM也优于VSM<citation id="138" type="reference"><link href="112" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="5">由于利用张量表示数据能够有效地降低数据特征维度和较好地保持数据结构, 因此近年来涌现出大量基于张量的算法, 以及张量在图像处理、模式识别、统计模型等领域的应用研究<citation id="139" type="reference"><link href="114" rel="bibliography" /><link href="116" rel="bibliography" /><link href="118" rel="bibliography" /><link href="120" rel="bibliography" /><link href="122" rel="bibliography" /><link href="124" rel="bibliography" /><link href="126" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。在图像处理问题中, 多通道图像或视频能够很自然地由三阶或高阶的张量表示, 并且有效保持各分量图像或各视频帧之间的结构关系。但在文本处理问题中, 张量表示能否有效地保持文本的结构信息呢?虽然有文献利用张量形式表示文本, 但由文本的向量表示向张量表示的映射具有随意性, 形成的张量空间模型不能明确体现文本的结构特征<citation id="140" type="reference"><link href="108" rel="bibliography" /><link href="110" rel="bibliography" /><link href="112" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。因此, 有必要对文本的结构信息进行挖掘, 以构造更具结构特征的张量空间模型。</p>
                </div>
                <div class="p1">
                    <p id="6">Salton认为文本的最小结构单位是段落, 提炼文本的结构信息有利于文本检索, 以及提取长文本不同的主题概念<citation id="141" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。林鸿飞等提出基于概念的文本结构分析方法, 其中文本结构被定义为文本的层次<citation id="142" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。他们认为文本的层次与层次之间应具有如下特性:同一层次下的段落尽可能相似, 不同层次下的段落尽可能相异。基于这种特性可以提取文本的层次结构。受到以上工作的启发, 在本文中, 我们首先提出一种文本层次结构提取算法 (Hierarchical Structure Extraction Algorithm, HSEA) , 提取文本层次结构信息;其次将提取的层次结构信息应用于文本的表示, 提出一种新颖的基于文本分层表示的结构张量空间模型 (Structured Tensor Space Model, STSM) ;最后, 我们将文本的结构张量表示与一种基于交替优化的高阶支持张量机算法结合应用于文本分类。在文本分类实验中, 与基于VSM的支持向量机分类算法和基于TSM的支持张量机分类算法进行了比较, 实验结果表明, 在小样本数据下, 本文的方法能够获得更优的分类效果。</p>
                </div>
                <h3 id="7" name="7" class="anchor-tag">二、结构张量空间模型</h3>
                <h4 class="anchor-tag" id="8" name="8"> (一) 向量空间模型到张量空间模型</h4>
                <div class="p1">
                    <p id="9">对语料库中任意的一个非结构化的文本f, 传统向量空间模型将其表示为一个结构化的向量w= (w<sub>1</sub>, w<sub>2</sub>, …, w<sub>N</sub>) ∈R<sup>N</sup>, 如图1所示。向量w的维度N是生成VSM表示的词典 (Vocabulary) 中所包含词 (Term) 的个数, w的每个分量表示文本的一个特征, 其中第n个分量w<sub>n</sub>对应着第n个词的某种统计量。根据不同的工作任务, 这些特征可以取为词频、词频—逆文档频率、信息增益、互信息和期望交叉熵等, 不同的特征反映文本不同方面的信息。由于文本语料中包含的词汇量巨大, 因此文本的VSM表示通常具有高维度、高稀疏度的特点, 此外如前文所述, VSM不能体现文本的语义信息。</p>
                </div>
                <div class="area_img" id="10">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 向量空间模型图" src="Detail/GetImg?filename=images/TJLT201907002_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 向量空间模型图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_01000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="11">为此, Cai等人提出文本的张量空间模型 (TSM) , 通过使用某种规则建立从VSM到TSM的映射关系, 将文本f的VSM表示向量w∈R<sup>N</sup>转变为一个2阶张量, 即矩阵W∈R<sup>N</sup>1<sup>×N</sup>2, 如图2所示<citation id="143" type="reference"><link href="108" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。图2 (a) 将一个9维的向量w转化为的3×3的矩阵W, 图2 (b) 通过补0将w转化为5×2的矩阵W。一般地, 当N<sub>1</sub>×N<sub>2</sub>&gt;N时, 可先对原N维向量补0, 再将其转化为N<sub>1</sub>×N<sub>2</sub>的矩阵。在文本处理时, 通过从VSM表示到TSM表示的转换, 模型参数的数量将从N下降为N<sub>1</sub>+N<sub>2</sub>, 可有效地避免维度灾难。</p>
                </div>
                <div class="area_img" id="12">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_01200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 VSM到TSM的映射图" src="Detail/GetImg?filename=images/TJLT201907002_01200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 VSM到TSM的映射图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_01200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="13">从图2可以看到, 一个向量可以被映射为不同维度的矩阵, 映射方式具有随意性, Cai等没有给出一种确定的映射规则, 并且由此形成的2阶TSM不能明确地体现文本的结构特征。为此, 在下文中我们将文本的层次信息融入文本表示, 得到更具结构性的文本表示模型。</p>
                </div>
                <h4 class="anchor-tag" id="14" name="14"> (二) 结构张量空间模型</h4>
                <h4 class="anchor-tag" id="15" name="15">1. 文本的分层表示</h4>
                <div class="p1">
                    <p id="16">文本的层次是一种重要的结构信息, 可用其优化文本的表示。本文提出的基于分层结构的文本表示模型如图3所示。在分层结构下, 文本f被表示为一个矩阵W= (w<sub>1</sub><sup>T</sup>, w<sub>2</sub><sup>T</sup>, …, w<sub>L</sub><sup>T</sup>) , 其中N为词典中词的个数, L为文本的层次个数, w<sub>i</sub>∈R<sup>N</sup>为W的第i个行向量, 是文本的第i个层次的VSM表示。由此可见, 文本的分层表示模型是由文本各个层次的VSM表示组成。</p>
                </div>
                <div class="area_img" id="17">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_01700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 文本的分层表示模型图" src="Detail/GetImg?filename=images/TJLT201907002_01700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 文本的分层表示模型图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_01700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="18">我们按以下原则提取文本层次结构<citation id="144" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="19"> (1) 段落为文本最小的结构单位, 文本的层次由段落按先后顺序聚合而成;</p>
                </div>
                <div class="p1">
                    <p id="20"> (2) 同一层次中的段落含义尽可能相似, 不同层次中的段落含义尽可能相异。</p>
                </div>
                <div class="p1">
                    <p id="21">将文本f看成是由P个段落构成的集合{p<sub>i</sub>}<sup>P</sup><sub>i=1</sub>, 其中p<sub>i</sub>∈R<sup>N</sup>是第i个段落的VSM表示向量, 并且P个段落按其在文本中出现的先后次序排列。为了提取最为合理的层次结构, 需要寻找对文本段落进行切分合并分层的最优分割点。用k表示分割点的位置, 那么对包含P个段落的文本, k共有P-1个可能的取值。本文确定最优分割点的方法为:在已知当前分割点的情况下, 考虑下一个分割点所有可能的取值, 遍历每种切分合并后的层次结构, 将能够最大化分层评价函数的分割点作为划分新层次的最优分割点。受Fisher判别准则的启发, 本文定义分层评价函数如下:</p>
                </div>
                <div class="p1">
                    <p id="22">定义:分层评价函数 (Hierarchical Evaluation Function, HEF) </p>
                </div>
                <div class="area_img" id="23">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/TJLT201907002_02300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="24">其中, S<sub>inter</sub>是层间离散度, 度量不同层次之间的距离;S<sub>intra</sub>是层内离散度, 度量同一层次内段落之间的距离。按上述层次结构提取原则, 合理的层次结构应当使S<sub>inter</sub>尽可能大, S<sub>intra</sub>尽可能小, 也就是使J<sub>HEF</sub>最大。S<sub>inter</sub>与S<sub>intra</sub>计算公式如下:</p>
                </div>
                <div class="area_img" id="25">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/TJLT201907002_02500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="26">其中, p<sub>ij</sub>表示第i个层次第j个段落的VSM表示的向量, Pi为第i个层次中段落总数, <image id="153" type="formula" href="images/TJLT201907002_15300.jpg" display="inline" placement="inline"><alt></alt></image>。mi和m分别为第i个层次和文本f的段落中心向量</p>
                </div>
                <div class="area_img" id="27">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/TJLT201907002_02700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="28">d (·) 为距离函数, 度量两个向量之间的距离, 本文使用余弦距离。</p>
                </div>
                <div class="p1">
                    <p id="29">基于上述思想, 本文提出文本层次结构提取算法 (HSEA) 。给定将要提取的层次个数L, HSEA首先将所有的段落并入一个层次, 通过迭代的过程逐步进行层次的切分。假设在第i次迭代时, 获得文本第i个层次的最优切分, 那么第i+1个层次的最优切分是通过在第i个层次中遍历所有可能的分割点, 选取最大化HEF值的分割点进行切分得到的。此过程重复进行, 直到获得L个层次为止。</p>
                </div>
                <div class="p1">
                    <p id="30">HSEA在每次提取新的层次时, 需要遍历所有可能的|K|个分割点, 计算相应分层结构的HEF值, 这里|K|为分割点候选集K中分割点的个数。对段落总数为P的文本, 获得层次个数为L的分层结构, 由于|K|&lt;P, 因此HSEA的计算复杂度不超过O (P<sup>L</sup>) 。通常一篇文本的段落数目P有限且值不会太大, 而文本的层次个数L也较小, 因此在进行文本层次结构提取时, HSEA具有很高的效率。</p>
                </div>
                <div class="p1">
                    <p id="31">在获得文本f的层次结构集P<sub>h</sub>={P<sub>h1</sub>, P<sub>h2</sub>, …, P<sub>hL</sub>}后, 使用语料库词典, 将每个层次用VSM表示为向量形式, 记第i个层次P<sub>hi</sub>的VSM表示向量为w<sub>i</sub>∈R<sup>N</sup>, 那么文本f的分层表示即为如下矩阵形式:</p>
                </div>
                <div class="area_img" id="154">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/TJLT201907002_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="36" name="36">2. 基于分层表示的结构张量空间模型</h4>
                <div class="p1">
                    <p id="37">从式 (6) 可以看出, 文本分层表示模型实际上是一个嵌入了文本层次结构的2阶TSM。但是在该模型中, 文本的结构 (即, 层次) 由高维的VSM表示, 因此形成的2阶TSM具有高维度的缺点。为此, 本文结合TSM中使用的由VSM到TSM的映射方法, 将分层表示模型进一步转化为3阶的TSM, 如图4所示。我们定义这个新的文本表示模型为基于分层表示的结构张量空间模型 (Hierarchical Representation-based Structured Tensor Space Model, HR-STSM) 。</p>
                </div>
                <div class="area_img" id="39">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_03900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于分层表示的结构张量空间模型图" src="Detail/GetImg?filename=images/TJLT201907002_03900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于分层表示的结构张量空间模型图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_03900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="40">在上一节中已得到文本f的分层表示矩阵W∈R<sup>L×N</sup>, 下面我们将每个层次的VSM表示向量w<sub>i</sub>∈R<sup>N</sup>映射为矩阵W<sub>i</sub>∈R<sup>M×M</sup> (i=1, 2, …, L) , 其中矩阵的维度M由式 (7) 计算, </p>
                </div>
                <div class="area_img" id="41">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/TJLT201907002_04100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="42">从而得到文本f的HR-STSM表示, 记为X∈R<sup>M×M×L</sup>。</p>
                </div>
                <h3 id="44" name="44" class="anchor-tag">三、基于STSM的文本分类</h3>
                <div class="p1">
                    <p id="45">将文本的高阶结构张量空间模型应用于文本分类的一个重要问题是设计能够处理张量结构数据的性能良好的分类算法。近年来, 作为支持向量机 (Support Vector Machine, SVM) 方法的延伸, 支持张量机 (Support Tensor Machine, STM) 在图像处理、文本处理等许多领域都备受关注, 并由不同的出发点扩展出不同的张量算法。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46"> (一) STM分类模型的一般形式</h4>
                <div class="p1">
                    <p id="47">若将训练语料{f<sub>d</sub>}<sup>D</sup><sub>d=1</sub>中的文本通过HR-STSM表示为张量, 则STM的训练样本集为{X<sub>d</sub>, y<sub>d</sub>}<sup>D</sup><sub>d=1</sub>, 其中输入样本形式为3阶张量X<sub>d</sub>∈R<sup>M×M×L</sup>, 相应的输出样本为y<sub>d</sub>∈{-1, 1}。</p>
                </div>
                <div class="p1">
                    <p id="48">与SVM相似, STM学习的最终结果也是找到能够最大程度分隔两类样本的最优分类超平面。STM的分类平面为</p>
                </div>
                <div class="area_img" id="49">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/TJLT201907002_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="50">其中α<sub>k</sub>为k-mode模式参数向量, X×<sub>k</sub>α<sub>k</sub>表示张量X与α<sub>k</sub>的k-mode积, b为分类阈值, K是张量的阶数 (本文中K=3) 。</p>
                </div>
                <div class="p1">
                    <p id="51">STM分类问题的目标函数为</p>
                </div>
                <div class="area_img" id="52">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/TJLT201907002_05200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="53">其中, ξ= (ξ<sub>1</sub>, ξ<sub>2</sub>, …, ξ<sub>D</sub>) <sup>T</sup>表示松驰变量, <image id="155" type="formula" href="images/TJLT201907002_15500.jpg" display="inline" placement="inline"><alt></alt></image>表示向量α<sub>1</sub>和α<sub>2</sub>的张量积。</p>
                </div>
                <h4 class="anchor-tag" id="54" name="54"> (二) 基于交替优化的高阶STM学习算法</h4>
                <div class="p1">
                    <p id="55">求解优化问题 (9) 时, 参数α<sub>k</sub>的确定依赖于其它的参数α<sub>l</sub> (1≤l≤K, l≠k) , 一般使用交替优化方法对参数进行求解。也就是说, 在求解某个参数α<sub>k</sub>时, 将其余的参数α<sub>l</sub> (l≠k) 的值固定, 然后交替地求解出每个参数。通过这种方法, 高阶STM优化问题 (9) 可以被分解为一系列标准的SVM子问题进行交替求解。高阶STM算法代码可从作者的Github下载<citation id="152" type="note"><link href="146" rel="footnote" /><sup> (1) </sup></citation>。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag">四、实验结果与分析</h3>
                <div class="p1">
                    <p id="57">在本章中, 我们通过文本的分类实验来验证结构张量空间模型在文本分类任务上的有效性。实验包括两部分:第一部分研究了文本分层结构中层次的个数对分类性能的影响, 以确定HR-STSM的最优分层数;第二部分研究了基于HR-STSM表示的高阶STM算法 (简记为STSM-HOSTM) 的分类效果, 并与基于VSM表示的SVM算法 (VSM-SVM) 、基于TSM表示的STM算法 (TSM-STM) 的性能做出比较。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58"> (一) 实验环境</h4>
                <div class="p1">
                    <p id="59">实验涉及的所有算法均采用Python 3.6.5进行实现, 并在Spyder 3下进行编译与运行。程序中主要使用的软件包以及相应的版本如下:机器学习包scikit-learn (0.19.1) , 数值运算包numpy (1.14.3) , 数据处理包pandas (0.23.0) , 结巴分词包 (0.39) , 张量代数运算包tensorly (0.4.2) 。我们采用libsvm求解方法作为SVM算法的实现, STM和HOSTM中子优化问题的求解也使用了此方法。实验使用电脑CPU型号为Intel (R) Core (TM) i7-7500U, 内存8GB, 操作系统为Windows 10企业版。</p>
                </div>
                <h4 class="anchor-tag" id="60" name="60"> (二) 实验语料</h4>
                <h4 class="anchor-tag" id="61" name="61">1. 搜狗新闻语料</h4>
                <div class="p1">
                    <p id="62">搜狗新闻语料库 (1) , 是一个包含大量不同主题的网络新闻语料库。本文选取主题为IT、教育、汽车和财经4个类别的语料进行实验。语料的分布情况见表1。</p>
                </div>
                <div class="area_img" id="63">
                                            <p class="img_tit">
                                                表1 搜狗语料类别以及数量表
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/TJLT201907002_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 搜狗语料类别以及数量表" src="Detail/GetImg?filename=images/TJLT201907002_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="64" name="64">2. 复旦中文语料表</h4>
                <div class="p1">
                    <p id="65">复旦中文语料 (2) , 是一个多类中文语料库, 语料中的题材多为历年来的相关文章。我们选择了类别为艺术, 农业, 政治三类语料进行文本实验, 其数量分别见表2。</p>
                </div>
                <div class="area_img" id="66">
                                            <p class="img_tit">
                                                表2 复旦语料类别以及数量表
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/TJLT201907002_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 复旦语料类别以及数量表" src="Detail/GetImg?filename=images/TJLT201907002_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="67">对语料的预处理包括:使用jieba分词工具对文本进行分词, 去停用词处理。VSM和TSM均使用TF-IDF作为文本特征来构建文本表示模型, 而在STSM模型中, 对采用词频作为文本特征进行文本的分层, 构建了文本的分层表示之后, 进一步采用IDF加权, 这意味着, 在分类实验中, STSM使用TF-IDF作为特征的表示。</p>
                </div>
                <h4 class="anchor-tag" id="68" name="68"> (三) 实验结果分析</h4>
                <h4 class="anchor-tag" id="69" name="69">1. HR-STSM层次实验</h4>
                <div class="p1">
                    <p id="70">本节研究HR-STSM中层次个数对分类性能的影响。实验使用IT、教育和汽车3个类别的语料, 将3个类进行两两组合, 共得到3个二分类组, 3个类别的语料数量如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="71">训练集从3个二分类组中随机抽取, 所包含的语料数量从100到800, 每次增加100个;训练集和测试集均占语料数量的50%。在HR-STSM的层次个数分别为2、3、4、5的情况下使用HOSTM进行分类学习, 利用测试准确率进行评价, 测试准确率取3个二分类组的平均值。</p>
                </div>
                <div class="p1">
                    <p id="72">实验结果如表3所示。可以看到4层HR-STSM的测试集分类精确度最高, 因此在下面的实验中使用4层HR-STSM表示文本。</p>
                </div>
                <div class="area_img" id="73">
                                            <p class="img_tit">
                                                表3 层次实验结果表
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_07300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/TJLT201907002_07300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_07300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表3 层次实验结果表" src="Detail/GetImg?filename=images/TJLT201907002_07300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>
                                <p class="img_note">注:粗体表示该组实验中的最大值。下同。</p>

                </div>
                <h4 class="anchor-tag" id="74" name="74">2. 文本分类实验</h4>
                <div class="p1">
                    <p id="75">本节对VSM-SVM、TSM-STM和TSM-HOSTM的分类性能进行比较, 实验中三种算法的惩罚参数的弹性大小为1、50、50, 以保证分类器对训练集的准确率能够不小于90%。</p>
                </div>
                <div class="p1">
                    <p id="76">1) 实验A:搜狗语料分类实验</p>
                </div>
                <div class="p1">
                    <p id="77">实验A使用IT、教育、汽车和财经4个类别的语料, 以IT语料作为正类样本, 分别与其它类别语料构成3个二分类组。</p>
                </div>
                <div class="p1">
                    <p id="78">实验A从两方面进行:固定语料总数, 改变训练集和测试集语料比例的分类性能比较;固定训练集语料, 改变测试集语料个数的分类性能比较。</p>
                </div>
                <div class="p1">
                    <p id="79">第一, 固定语料总数。3个二分类组包含的语料数量分别取200、400、600、800, 在语料总数固定, 训练集和测试集按不同比例分配 (见表3第1列) 的情况下, 对VSM-SVM、TSM-STM和STSM-HOSTM的分类性能比较结果见图5和表3, 其中测试准确率为3个二分类组的平均值。</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 实验A结果比较图" src="Detail/GetImg?filename=images/TJLT201907002_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 实验A结果比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="81">图5表示语料总数固定, 训练集和测试集按不同比例分配变化时, VSM-SVM、TSM-STM和STSM-HOSTM对测试集的分类准确率曲线。其中实心圆点、空心圆点和实心方块曲线分别是VSM-SVM、TSM-STM和STSM-HOSTM的分类结果。图6 (a) ～ (d) 分别为语料总数取200、400、600和800的分类结果。可以看到, 在4种规模的语料总数下, 当训练样本的比例较低, 即训练样本包含的语料个数不超过60时, VSM-SVM的分类性能均较差, 测试准确率低于70%。当训练样本语料个数约为30～60之间时, TSM-STM和STSM-HOSTM的分类精度都优于VSM-SVM, 可达到70%以上。将TSM-STM和STSM-HOSTM的分类结果进行比较可以发现, 当训练样本语料个数小于30时, TSM-STM的分类精度急剧下降, 而STSM-HOSTM的分类精度略微下降, 但仍保持着70%以上的准确率。</p>
                </div>
                <div class="p1">
                    <p id="82">表4给出语料总数为200和400时, 三种算法在训练样本与测试样本不同分配比例下得到的测试集分类准确率, 对应于图6 (a) 和 (b) 的结果。</p>
                </div>
                <div class="p1">
                    <p id="83">第二, 固定训练集。3个二分类组各包含的语料总数为800, 在固定训练集语料个数为20、40、60、80的四种情况下, 将测试集语料个数从40增加至800, 每次增加40个语料, 对VSM-SVM、TSM-STM和STSM-HOSTM的分类性能进行比较, 测试准确率为3个二分类组的平均值。实验结果见图6和表5。</p>
                </div>
                <div class="area_img" id="84">
                                            <p class="img_tit">
                                                表4 实验A分类结果比较表
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/TJLT201907002_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 实验A分类结果比较表" src="Detail/GetImg?filename=images/TJLT201907002_08400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 实验B结果比较图" src="Detail/GetImg?filename=images/TJLT201907002_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 实验B结果比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="86">
                                            <p class="img_tit">
                                                表5 实验B分类结果比较表
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/TJLT201907002_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 实验B分类结果比较表" src="Detail/GetImg?filename=images/TJLT201907002_08600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="87">图6表示训练集语料个数固定, 测试集语料个数变化时, VSM-SVM、TSM-STM和STSM-HOSTM对测试集的分类准确率曲线。其中实心圆点、空心圆点和实心方块曲线分别是VSM-SVM、TSM-STM和STSM-HOSTM的分类结果。图7 (a) ～ (d) 分别为训练集语料个数取20、40、60和80的分类结果。图7 (a) 和 (b) 表明, 当训练集语料个数为20和40时, STSM-HOSTM的分类性能明显优于VSM-SVM和TSM-STM。相应的测试集分类准确率由表4给出。可以看到, 训练集语料个数取20时, STSM-HOSTM的准确率均在70%以上, VSM-SVM和TSM-STM的准确率在55%附近波动, TSM-STM略优于VSM-SVM。当训练集语料个数取40时, STSM-HOSTM的准确率在测试集语料个数小于400时超过了80%, 在测试集语料个数超过400时, 准确率接近80%。而VSM-SVM和TSM-STM的分类准确率虽有所提高, 但仍明显低于STSM-HOSTM。VSM-SVM与TSM-STM相比, TSM-STM的性能整体上优于VSM-SVM。图7 (c) 给出训练集语料个数取60的实验结果, 可以看到随着训练语料的增加, VSM-SVM和TSM-STM的分类性能快速提升, 此时TSM-STM的平均分类准确率已超过STSM-HOSTM。TSM-STM和STSM-HOSTM均优于VSM-SVM。从图7 (d) 看出, 当训练集语料个数达到80时, VSM-SVM的分类准确率快速上升, 达到90%以上, 超过了TSM-STM和STSM-HOSTM。与训练集语料个数取60时的结果相比, TSM-STM和STSM-HOSTM的分类准确率略有上升。</p>
                </div>
                <div class="p1">
                    <p id="88">实验A和实验B的分类结果均表明, 当训练集语料个数小于60时, 基于张量表示的TSM-STM和STSM-HOSTM的分类性能都显著的优于基于向量表示的VSM-SVM。这或许是因为, 小样本训练语料提供的信息不够充分, 不能使VSM-SVM得到充分训练, 从而不能很好地识别文本特征, 分类性能低下。而文本的张量表示蕴含着文本的结构特征, 而这种潜在的结构特征有助于提升分类算法性能。前期关于基于TSM的文本分类的研究已表明, 与基于VSM的文本分类相比, 文本的张量表示更利于小样本训练集下的文本分类, 上述实验结果正是对此结论的进一步验证<citation id="145" type="reference"><link href="108" rel="bibliography" /><link href="110" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="89">将STSM-HOSTM与TSM-STM的实验结果做进一步对比, 可以看到, 当训练集语料个数减少至30以下时, TSM-STM变的极不稳定, 分类性能快速下降, 而STSM-HOSTM的分类准确率却能稳定地保持在75%～80%之间。这说明在小样本情况下, 向文本张量表示中加入的更为明确的文本层次结构信息能够起到保持分类算法稳定性、提高分类精度的作用。由此说明在文本的表示中加入有效的文本结构特征对提高后续文本处理任务的效果确实有着重要的意义。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90">2) 实验B:复旦语料分类实验</h4>
                <div class="p1">
                    <p id="91">为了验证的模型能够有更广的适用性, 还在复旦语料下进行了文本分类的实验。在复旦语料中, 我们分别在艺术与农业, 农业与政治下进行了文本分类, 并且固定语料的训练集为60个, 不断增加测试集从40, 80, …, 400, 测试不同测试集下分类模型对应的测试集的正确率。其结果见图7和表6。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 复旦语料下的分类实验图" src="Detail/GetImg?filename=images/TJLT201907002_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 复旦语料下的分类实验图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="93">
                                            <p class="img_tit">
                                                表6 实验C分类结果比较表
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/TJLT201907002_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/TJLT201907002_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/TJLT201907002_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表6 实验C分类结果比较表" src="Detail/GetImg?filename=images/TJLT201907002_09300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="94">图7中, (a) 表示艺术与农业下的分类实验, (b) 表示农业与政治下的分类实验, 各个曲线和之前的实验相同。从 (a) 和表6中, 可以看出VSM-SVM下的分类正确率均不高于80%, 而STSM-HOSTM与TSM-STM的正确率均高于80%, 相比较TSM-STM, STSM-HOSTM的正确率更高, 大多数超过了88%, 其曲线整体在另外二者的上方。从 (b) 和表6中可以发现, VSM-SVM的曲线程序上升趋势, 但是其整体正确率仍然比较低, 大多数实验组的正确率不高于80%。而TSM-STM与STSM-HOSTM的正确率均高于80%, 其中TSM-STM的正确率在80%到90%区间段, 曲线整体比较平稳;STSM-HOSTM的正确率大多数在90%以上, 曲线于另外二者上方。</p>
                </div>
                <div class="p1">
                    <p id="95">可以发现, 当使用复旦中文语料时, STSM-HOSTM与TSM-STM两者的正确率均高于VSM-SVM的分类正确率, 并且STSM-HOSTM的分类正确率效果相比较于另外两者是最好的。这再次验证了STSM-HOSTM在小样本数据下的优势。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag">五、结束语</h3>
                <div class="p1">
                    <p id="97">本文提出一种新的文本表示模型———基于文本分层表示的结构张量空间模型 (HR-STSM) 。HR-STSM将文本表示为3阶张量, 继承了2阶TSM的维度低的优点, 并且包含了文本的层次结构信息。利用本文提出的文本层次结构提取算法 (HSEA) , 能够实现文本的自动分层, 从而得到文本的结构张量表示。与高阶支持张量机相结合得到的STSM-STM分类算法对小样本的分类任务具有显著的优势, 分类性能明显优于VSM-SVM和TSM-STM。</p>
                </div>
                <div class="p1">
                    <p id="98">当训练样本的数目足够大时, 基于张量表示的STSM-HOSTM和TSM-STM的分类性能的提升都不如VSM-SVM。这可能是由于随着样本量增大, 分类器获得了充分训练, 从而一方面弱化了文本结构信息对分类性能提升的影响;另一方面, TSM不能明确地表示文本的结构, 而本文提出的HR-STSM可能会出现层次特征提取不够合理的问题, 由此导致TSM-STM和STSM-HOSTM在大样本数据下性能不如VSM-SVM。</p>
                </div>
                <div class="p1">
                    <p id="99">文本的层次结构提取是较为复杂的问题, 类型和内容不同的文本可能具有不同的层次结构。一方面, 在处理新闻语料分类问题时, 本文仅是将所有语料的层次粗略地进行硬划分, 使得同类别语料的相同层次之间的相关度不够显著;另一方面, 在文本层次结构提取时仅使用了词频这个特征。因此, 需要对文本的STSM表示开展进一步的研究: (1) 结合其它文本处理技术和文本语义信息, 提取语义结构更明确的文本层次表示模型; (2) 探索文本的其它结构表示形式及提取方法; (3) 研究STSM表示下的张量分类算法; (4) STSM在其它文本处理任务中的应用研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="100">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000024403&amp;v=MjU4MjlyYkpLRjRVYVJNPU5pZklZN0s3SHRqTnI0OUZaT2tMQ0h3Nm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>Salton G, Wong A, Yang C S.A Vector Space Model for Automatic Indexing[J].Communications of the ACM, 1975, 18 (11) .
                            </a>
                        </p>
                        <p id="102">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201711011&amp;v=Mjg4MTZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm5GaURsVTd6Sk1TZkhlckc0SDliTnJvOUU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>王婷婷, 韩满, 王宇.基于"21世纪海上丝绸之路"文献的文本挖掘研究[J].统计与信息论坛, 2017, 32 (11) .
                            </a>
                        </p>
                        <p id="104">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDTQ201502007&amp;v=MTM3MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGxVN3pKUFNuZmY3RzRIOVRNclk5Rlk0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b>刘怀亮, 杜坤, 秦春秀.基于知网语义相似度的中文文本分类研究[J].现代图书情报技术, 2015, 31 (2) .
                            </a>
                        </p>
                        <p id="106">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300675447&amp;v=MTY2MzJlcnFRVE1ud1plWnRGaW5sVXJiSktGNFVhUk09TmlmT2ZiSzdIdERPckk5Rll1d0tDSGcrb0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>Liu H, Bao H, Xu D.Concept Vector for Semantic Similarity and Relatedness Based on WordNet Structure[J].Journal of Systems and Software, 2012, 85 (2) .
                            </a>
                        </p>
                        <p id="108">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning with tensor representation">

                                <b>[5]</b>Cai D, He X, Han J.Learning with Tensor Representation.Department of Computer Science Technical Report[R].Urbana:University of Illinois at Urbana-Champaign, 2006.
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201609003&amp;v=MDYxOTQ5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabkZpRGxVN3pKTFNuUlpMRzRIOWZNcG8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>俞炯, 刘功申.基于支持张量机的文本分类研究[J].信息技术, 2016 (9) .
                            </a>
                        </p>
                        <p id="112">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEFE201012013&amp;v=MTk0OTFuRmlEbFU3ekpMU2pOYTdHNEg5SE5yWTlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b>何伟, 胡学钢, 谢飞.基于张量空间模型的中文文本分类[J].合肥工业大学学报:自然科学版, 2010, 33 (12) .
                            </a>
                        </p>
                        <p id="114">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001682552&amp;v=MjA5MDF4b3hjTUg3UjdxZForWnVGaUhrVzcvSUkxOD1OajdCYXJPNEh0SE5xWWRIWWU0TlkzazV6QmRoNGo5OVNYcVJy&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b>Tao D, Li X, Hu W, et al.Supervised Tensor Learning[J].Knowledge&amp;Information Systems, 2007, 13 (1) .
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES85C2E528931110A0CFE01755AB20E335&amp;v=MTI5NDFGcG1hQnVIWWZPR1FsZkJyTFUwNXRGZ3pMaS93Nms9TmlmT2ZidTliZE81cW8xTmJlZ09EWDA1dmhaZ25FcDlTWGpucVdOSGU3TGhScm1hQ09OdkZTaVdXcjdKSQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Chen Y, Wang K, Zhong P.One-class Support Tensor Machine[J].Knowledge-Based Systems, 2016, 96.
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Linear Support Higher-Order Tensor Machine for Classification">

                                <b>[10]</b>Hao Z, He L, Chen B, et al.A Linear Support Higher-order Tensor Machine for Classification[J].IEEE Transactions on Image Processing, 2013, 22 (7) .
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor Learning for Regression">

                                <b>[11]</b>Guo W, Kotsia I, Patras I.Tensor Learning for Regression[J].IEEE Transactions on Image Processing, 2012, 21 (2) .
                            </a>
                        </p>
                        <p id="122">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600737717&amp;v=MzE1NTE9TmlmT2ZiSzdIdEROcVk5RlkrZ0lDMzArb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcmJKS0Y0VWFSTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>Kotsia I, Guo W, Patras I.Higher Rank Support Tensor Machines for Visual Recognition[J].Pattern Recognition, 2012, 45 (12) .
                            </a>
                        </p>
                        <p id="124">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWDA4AD39436D87F08B39082535A44A17D4&amp;v=MjQ1MzVtYUJ1SFlmT0dRbGZCckxVMDV0Rmd6TGkvdzZrPU5pZmNhc0s4YjZYUHBvdEdZcDhIQ3dvNXgyUVE0ejkxU25yaHFXTXhmY09WUXM2YkNPTnZGU2lXV3I3SklGcA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>Sun W W, Lu J, Han L, et al.Provable Sparse Tensor Decomposition[J].Journal of the Royal Statistical Society, 2017, 79 (3) .
                            </a>
                        </p>
                        <p id="126">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=STJD&amp;filename=STJD13070900000789&amp;v=MTMxMTBubFVyYkpLRjRVYVJNPU5qbkJhcks3SHRiTXBvOUZaT3NQQzNRd29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>Zhou H, Li L, Zhu H.Tensor Regression with Applications in Neuroimaging Data Analysis[J].Journal of the American Statistical Association, 2013, 108 (502) .
                            </a>
                        </p>
                        <p id="128">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000000060&amp;v=MTU4OTBud1plWnRGaW5sVXJiSktGNFVhUk09TmlmSVk3SzdIdGpOcjQ5RlpPc1BESG81b0JNVDZUNFBRSC9pclJkR2VycVFUTQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b>Salton G, Allan J, Buckley C.Automatic Structuring and Retrieval of Large Text Files[J].Communications of the ACM1994, 37 (2) .
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ200003010&amp;v=MTM2MzJySTlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEbFU3ekpMeXZTZExHNEh0SE0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>林鸿飞, 战学刚, 姚天顺.基于概念的文本结构分析方法[J].计算机研究与发展, 2000, 37 (3) .
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
            <div class="reference anchor-tag" id="a_footnote">
 <h3>注释</h3>
                    <p>
                        <span id="146" href="javascript:void(0)">
                            <b>1</b> Github:https://github.com/spzhuang/support-tensor-machine/create/master.
                        </span>
                    </p>
                    <p>
                        <span id="148" href="javascript:void(0)">
                            <b>2</b> 搜狐新闻数据:https://www.sogou.com/labs/resource/cs.php.
                        </span>
                    </p>
                    <p>
                        <span id="150" href="javascript:void(0)">
                            <b>3</b> 复旦语料:http://www.nlpir.org/wordpress/download/tc-corpus-answer.rar
                        </span>
                    </p>
            </div>
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="TJLT201907002" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TJLT201907002&amp;v=MzE2Mjk5ak1xSTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpuRmlEbFU3ekpNU2ZIZXJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZEYVI3MHF6ek1oNHI0dHhJUW1XTT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=vAscMyvIPP9NePnbGPkqJ0A5tHOvnzl65tGuRDsf9xg1" rel="stylesheet"/>

</body>
</html>

