

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135688673381250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201912018%26RESULT%3d1%26SIGN%3dzb4EwfFOlf0utPDfwAFxCgVksZ0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201912018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201912018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201912018&amp;v=MTczMTA1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblZyM0lJVGZJWXJHNEg5ak5yWTlFYklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="&lt;b&gt;1 系统总体方案设计&lt;/b&gt; "><b>1 系统总体方案设计</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="&lt;b&gt;2 原理分析与硬件设计&lt;/b&gt; "><b>2 原理分析与硬件设计</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;3 软件设计与流程&lt;/b&gt; "><b>3 软件设计与流程</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="&lt;b&gt;3.1 系统详细设计&lt;/b&gt;"><b>3.1 系统详细设计</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;3.2 特征点检测&lt;/b&gt;"><b>3.2 特征点检测</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;3.3 特征的匹配及误匹配点剔除&lt;/b&gt;"><b>3.3 特征的匹配及误匹配点剔除</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;3.4 图像定位&lt;/b&gt;"><b>3.4 图像定位</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;3.5 网络通信部分&lt;/b&gt;"><b>3.5 网络通信部分</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;3.6 视频播放方案&lt;/b&gt;"><b>3.6 视频播放方案</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="&lt;b&gt;4 系统测试与误差分析&lt;/b&gt; "><b>4 系统测试与误差分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#100" data-title="&lt;b&gt;4.1 系统测试&lt;/b&gt;"><b>4.1 系统测试</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;4.2 误差分析&lt;/b&gt;"><b>4.2 误差分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#113" data-title="&lt;b&gt;5 结  论&lt;/b&gt; "><b>5 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="图1 系统设计">图1 系统设计</a></li>
                                                <li><a href="#50" data-title="图2 增强现实总体流程">图2 增强现实总体流程</a></li>
                                                <li><a href="#55" data-title="图3 图像识别流程">图3 图像识别流程</a></li>
                                                <li><a href="#72" data-title="图4 特征点描述向量">图4 特征点描述向量</a></li>
                                                <li><a href="#82" data-title="图5 对比度优化前后的识别对比">图5 对比度优化前后的识别对比</a></li>
                                                <li><a href="#86" data-title="图6 Unity 3D中场景搭建">图6 Unity 3D中场景搭建</a></li>
                                                <li><a href="#93" data-title="图7 俯视图">图7 俯视图</a></li>
                                                <li><a href="#94" data-title="图8 侧视图">图8 侧视图</a></li>
                                                <li><a href="#98" data-title="图9 在花朵上投影蝴蝶近景">图9 在花朵上投影蝴蝶近景</a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;表1 不同纸张材质的识别率和反应时长&lt;/b&gt;"><b>表1 不同纸张材质的识别率和反应时长</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;表2 虚实互动的识别率和反应时长&lt;/b&gt;"><b>表2 虚实互动的识别率和反应时长</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 林栎, 李剑, 覃桢桢, 等.基于增强现实技术的智能终端导游系统[J].软件工程, 2017, 20 (12) :35-38." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGC201712011&amp;v=MTU3OTFOclk5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WcjNJUHlyTWJiRzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         林栎, 李剑, 覃桢桢, 等.基于增强现实技术的智能终端导游系统[J].软件工程, 2017, 20 (12) :35-38.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 丁铮.增强现实和虚拟现实在博物馆的应用[J].信息与电脑 (理论版) , 2017 (24) :47-50." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXDL201724022&amp;v=MTM2MzBiT3E0OUhab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSVBUWFBZckc0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         丁铮.增强现实和虚拟现实在博物馆的应用[J].信息与电脑 (理论版) , 2017 (24) :47-50.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" SETOHARA H, KATO H, KAWAMOTO K, et al.A simple solution of occlusion problem in augmented reality and its application for interaction[J].Transactions of the Virtual Reality Society of Japan, 2004, 9 (4) :387-395." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A simple solution of occlusion problem in augmented reality and its application for interaction">
                                        <b>[3]</b>
                                         SETOHARA H, KATO H, KAWAMOTO K, et al.A simple solution of occlusion problem in augmented reality and its application for interaction[J].Transactions of the Virtual Reality Society of Japan, 2004, 9 (4) :387-395.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 周龙锋, 匡芳君.增强现实技术及其在高校教学中的应用[J].电脑知识与技术, 2017, 13 (32) :228-229, 238." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DNZS201732104&amp;v=MjU1OTR6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSUlTUFJmYkc0SDliUHJZNUZZSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         周龙锋, 匡芳君.增强现实技术及其在高校教学中的应用[J].电脑知识与技术, 2017, 13 (32) :228-229, 238.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 夏宗辉.基于增强现实的儿童读物交互设计研究[J].艺术教育, 2018 (15) :229-230." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YSJY201815193&amp;v=MDA4ODhadVp0RnlyblZyM0lQRDdCZDdHNEg5bk5xbzVNWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         夏宗辉.基于增强现实的儿童读物交互设计研究[J].艺术教育, 2018 (15) :229-230.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" KADE D, AKSIT K, &#220;REY H, et al.Head-mounted mixed reality projection display for games production and entertainment[J].Personal and Ubiquitous Computing, 2015, 19 (3) :509-521." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Head-mounted mixed reality projection display for games production and entertainment">
                                        <b>[6]</b>
                                         KADE D, AKSIT K, &#220;REY H, et al.Head-mounted mixed reality projection display for games production and entertainment[J].Personal and Ubiquitous Computing, 2015, 19 (3) :509-521.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" NAKEVSKA M, VOS C, JUAREZ A, et al.Using game engines in mixed reality installations[M].Entertainment Computing-ICEC 2011.Heidelberg:Springer Berlin, 2011:456-459." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using game engines in mixed reality installations">
                                        <b>[7]</b>
                                         NAKEVSKA M, VOS C, JUAREZ A, et al.Using game engines in mixed reality installations[M].Entertainment Computing-ICEC 2011.Heidelberg:Springer Berlin, 2011:456-459.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 李军锋, 巫庆辉, 刘杰.基于Unity3D的《电机拖动》虚拟实验室设计与开发[J].国外电子测量技术, 2016, 35 (10) :87-90." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWCL201610020&amp;v=MDc3MDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WcjNJSWpySVlyRzRIOWZOcjQ5SFpJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         李军锋, 巫庆辉, 刘杰.基于Unity3D的《电机拖动》虚拟实验室设计与开发[J].国外电子测量技术, 2016, 35 (10) :87-90.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 肖乾, 韩瑞, 刘行, 等.基于Unity3D虚实结合的铁道单车制动实验培训系统[J].华东交通大学学报, 2018, 35 (5) :135-142." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDJT201805020&amp;v=MTE4NTZxQnRHRnJDVVI3cWZadVp0RnlyblZyM0lMU25CZXJHNEg5bk1xbzlIWklRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         肖乾, 韩瑞, 刘行, 等.基于Unity3D虚实结合的铁道单车制动实验培训系统[J].华东交通大学学报, 2018, 35 (5) :135-142.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 秦超龙, 宋爱国, 吴常铖, 等.基于Unity 3D与Kinect的康复训练机器人情景交互系统[J].仪器仪表学报, 2017, 38 (3) :530-536." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201703003&amp;v=MTUxMTdyM0lQRHpUYkxHNEg5Yk1ySTlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         秦超龙, 宋爱国, 吴常铖, 等.基于Unity 3D与Kinect的康复训练机器人情景交互系统[J].仪器仪表学报, 2017, 38 (3) :530-536.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 朱照飞, 刘伟.基于改进的SURF特征点的双目测距[J].电子测量技术, 2018, 41 (12) :133-138." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201812028&amp;v=MDA5NDNVUjdxZlp1WnRGeXJuVnIzSUlUZklZckc0SDluTnJZOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         朱照飞, 刘伟.基于改进的SURF特征点的双目测距[J].电子测量技术, 2018, 41 (12) :133-138.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 任克强, 胡梦云.基于改进SURF算子的彩色图像配准算法[J].电子测量与仪器学报, 2016, 30 (5) :748-756." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201605016&amp;v=MTAzNDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WcjNJSVRmQ2Q3RzRIOWZNcW85RVlvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         任克强, 胡梦云.基于改进SURF算子的彩色图像配准算法[J].电子测量与仪器学报, 2016, 30 (5) :748-756.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 魏利胜, 甘泉.基于小波变换的新型SURF图像拼接方法[J].电子测量与仪器学报, 2017, 31 (5) :766-772." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201705018&amp;v=MDczNDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSUlUZkNkN0c0SDliTXFvOUViSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         魏利胜, 甘泉.基于小波变换的新型SURF图像拼接方法[J].电子测量与仪器学报, 2017, 31 (5) :766-772.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 陈敏, 汤晓安.SIFT与SURF特征提取算法在图像匹配中的应用对比研究[J].现代电子技术, 2018, 41 (7) :41-44." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201807012&amp;v=MTU2MjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WcjNJUFNuUFpMRzRIOW5NcUk5RVpvUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         陈敏, 汤晓安.SIFT与SURF特征提取算法在图像匹配中的应用对比研究[J].现代电子技术, 2018, 41 (7) :41-44.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 李文生, 解梅, 邓春健.基于多点手势识别的人机交互技术框架[J].计算机工程与设计, 2011, 32 (6) :2129-2133." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201106064&amp;v=MTM5NDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WcjNJTmlmWVpMRzRIOURNcVk5RFlJUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         李文生, 解梅, 邓春健.基于多点手势识别的人机交互技术框架[J].计算机工程与设计, 2011, 32 (6) :2129-2133.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 闻宏强, 李富勇, 赵一凡, 等.Modbus/TCP协议安全性分析与防护技术探讨[J].物联网技术, 2018, 8 (11) :34-35." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLWJ201811014&amp;v=MDEzMDU3cWZadVp0RnlyblZyM0lNaUhjWkxHNEg5bk5ybzlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         闻宏强, 李富勇, 赵一凡, 等.Modbus/TCP协议安全性分析与防护技术探讨[J].物联网技术, 2018, 8 (11) :34-35.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(12),100-105 DOI:10.19651/j.cnki.emt.11802553            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于Unity 3D的增强现实动画展示窗</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E7%91%9E&amp;code=24067536&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王瑞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%96%9B%E6%85%B0%E6%85%88&amp;code=42200477&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">薛慰慈</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0017580&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海大学通信与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了进一步研究增强现实在现实生活中的参考及应用价值, 本项目以Unity 3D为基础进行增强现实的软件开发, 搭建一个打破虚实隔阂的虚实交互展示窗。该系统基于增强现实的3个特点:虚拟结合、实时交互、三维注册, 利用投影仪搭建一个投影展台, 能够根据下方书册不同的书页进行图像识别处理, 通过摄像图片和数据库图片的比对, 选择对应视频进行投影, 最终实现虚实交互。经过系统测试, 展示窗工作稳定, 可靠性高。该系统可以与使用者进行互动, 根据人手势的挥动来进行相应的操作, 可应用于教育、娱乐和智慧生活等多方面, 具有较为广泛的应用前景。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">增强现实;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Unity3D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Unity3D;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像识别算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E6%9C%BA%E4%BA%92%E5%8A%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人机互动;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王瑞, 博士, 副教授, 主要研究方向为模式识别、神经网络。E-mail:rwang@shu.edu.cn;
                                </span>
                                <span>
                                    薛慰慈, 硕士研究生, 主要研究方向为模式识别、神经网络。E-mail:18817828368@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61771299);</span>
                    </p>
            </div>
                    <h1><b>Augmented reality animation display window based on Unity 3D</b></h1>
                    <h2>
                    <span>Wang Rui</span>
                    <span>Xue Weici</span>
            </h2>
                    <h2>
                    <span>Communication and Information Engineering Institute, Shanghai University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to further research the reference and application value of augmented reality in real life, this project develops an augmented reality interactive display window based on Unity 3 D, and breaks the gap between unreality and reality. The system is developed based on three characteristics of augmented reality: overlay of real and digital world, real-time interaction and registration and alignment in 3 D. We use a projector to build a projection booth, which can perform image recognition for different book pages on the booth, and can compare the camera image with the database image. Then, the window is developed to pick out and project the corresponding video, and finally achieve the virtual and real interaction in the augmented reality software. The system test shows that the display window works stably and is highly reliable. The system can be interactive with the user and carry out corresponding operations according to the gesture of the user. The system is able to be applied to various fields such as education, entertainment and smart-life, and has a wide application prospect.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=augmented%20reality&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">augmented reality;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Unity3D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Unity3D;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20recognition%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image recognition algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=human-computer%20interaction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">human-computer interaction;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="36">随着消费电子以及智能手机的快速发展<citation id="115" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 虚拟现实 (virtual reality, VR) 和增强现实 (augmented reality, AR) 技术越来越被人们熟知。增强现实技术是在虚拟现实基础上发展起来的, 它将计算机生成的场景融合到真实世界中, 扩张和补充真实世界而不是完全替代真实世界, 从而强化用户对现实的感官和认知。增强现实是虚拟世界信息和真实世界信息的共在。增强现实的特点可以概括为:虚拟结合、实时交互、三维注册<citation id="116" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。它是以真实世界为本位, 利用附加的虚拟信息对周围真实世界的场景动态地进行增强<citation id="117" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。增强现实技术具有真实性、交互性和实用性的特点, 目前已被应用于医学、军事、旅游等领域<citation id="118" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="37">本设计提出一种基于Unity 3D的增强现实动画展示窗。该展示窗能够即时识别人们随机放置在识别支架上的图案, 通过投影仪在特定图案上叠加视频或者3D图形, 同时, 人们可以通过挥手下达指令, 对播放的视频进行暂停及重新播放的操作, 实现人机交互。本系统目标为将教育、娱乐、智能家居与增强现实技术相结合, 根据用户所需实现虚拟与现实的虚实交互。例如面对专业教育工作者和展览场所, 通过投影展示设备, 项目能实现多种展示模型的三维投影呈现, 使教育和科普不再留于纸面, 使受众得到更为立体的感官体验<citation id="119" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>, 打破科技与用户之间的壁垒, 人们可以自主地控制它的展示效果。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag"><b>1 系统总体方案设计</b></h3>
                <div class="p1">
                    <p id="39">系统的总体设计框图如图1所示。该展示窗系统主要由展示台、图像处理模块、投影仪三部分组成, 通过图像处理模块识别支架上放置的特定图片, 在特定图片上叠加视频或模型, 再将处理后的图像信号通过WIFI传输至投影仪上, 最终投影至指定图片上, 实现在现实世界中叠加虚拟画面的功能。同时该系统也能够支持切换该设备上的视频或模型, 实现进一步的人机交互功能。</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_040.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 系统设计" src="Detail/GetImg?filename=images/DZCL201912018_040.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 系统设计  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_040.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="41">设备的软件使用图像处理模块作为运行环境。由于项目是基于图像识别实现增强现实, 并且图像处理模块距离书册一米以上, 所以对于处理模块图像识别能力有较高的要求。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag"><b>2 原理分析与硬件设计</b></h3>
                <div class="p1">
                    <p id="43">本系统的硬件设备要求较为简单, 由展示台和投影仪2部分组成。</p>
                </div>
                <div class="p1">
                    <p id="44">微型投影仪, 又称便携式投影机, 把传统庞大的投影机精巧化、便携化、娱乐化, 使投影技术更加贴近生活和娱乐。投影机主要的工作原理都是由光源发出光, 通过一系列的光学照明系统, 将光源的光均匀的照射到显示芯片上, 而信号通过电路系统在显示芯片上实现色阶以及灰阶, 显示出图像, 此后由投影前端的投影镜头将显示芯片上的图象放大投射到相应的屏幕上。</p>
                </div>
                <div class="p1">
                    <p id="45">本设计使用的投影仪选用的是酷迪斯CB-101微型投影仪, 其具有体积小, 流明高, 分辨率高等优点, 且支持1 920×1 080分辨率和自动梯形校正, 可使用WiFi和图像处理模块连接, 同步显示图像处理模块屏幕的画面。</p>
                </div>
                <div class="p1">
                    <p id="46">本投影仪在本项目中最大的优点是其体积相较于传统投影仪而言极小, 可以隐蔽地放置在展示框架的顶端而不显突兀, 而且其快速同步显示图像处理模块屏幕内容的功能也使得本项目的成功成为了可能。在实际测试中, 将该投影仪放置在框架顶端能够成功地将图像处理模块的屏幕内容投影至框架下方的书册上, 在合适的光影条件下投影效果良好。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>3 软件设计与流程</b></h3>
                <div class="p1">
                    <p id="48">软件部分是整个系统能协调运转的关键。本设计基于Unity 3D进行开发, 通过图像识别、匹配、定位算法实现增强现实功能<citation id="120" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="49">增强现实部分的总体流程如图2所示, 使用图像处理模块打开设备的摄像头, 通过检测进入摄像头的图像, 分析图像中是否有预先设置好的标志性图案存在, 若有, 在整个摄像头覆盖的范围中定位到该图案的三维坐标, 并在设备的屏幕上以此图案为中心在附近叠加上虚拟的模型、控制按键等<citation id="121" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。该图案被称为“识别图”, 实现识别图的检测和定位是实现该展示窗功能的必由之路。系统自运行开始就不断执行此功能, 以保障探测到识别图位置的准确性, 并对叠加的虚拟物体位置进行实时调整<citation id="122" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 增强现实总体流程" src="Detail/GetImg?filename=images/DZCL201912018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 增强现实总体流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="51" name="51"><b>3.1 系统详细设计</b></h4>
                <div class="p1">
                    <p id="52">在图像处理中, 通过对比两幅图片中特征点之间相对位置的分布, 可以实现图像匹配<citation id="123" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。线段的终点, 图像的极值点, 曲线曲率最大的点等都可以作为图像的特征点。一幅图像的特征点可以用于代表这幅图像。由于特征点能够代表一幅图像, 因而在图像处理中能利用特征点来替代整幅图像接受分析, 大幅减少了需要运算的数据量, 从而加快计算速度, 有利于实时计算。</p>
                </div>
                <div class="p1">
                    <p id="53">本系统中, 程序首先将准备用作识别图的图片转为灰度图, 然后在灰度图的基础上, 遍历图中各像素, 找出图片中具有以上特征的点, 并将其位置信息存入数据库中。</p>
                </div>
                <div class="p1">
                    <p id="54">实际操作中, 本系统首先从本地获取模板图片并通过摄像头实时获取视频帧, 将数据通过NDK传输到Native层, 使用SURF算法对图像的特征点进行提取和描述, 然后基于欧式距离对描述子集合进行匹配, 并删除不匹配点, 最后进行三维模型的注册, 实现虚实融合的效果, 具体流程如图3所示。</p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_055.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 图像识别流程" src="Detail/GetImg?filename=images/DZCL201912018_055.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 图像识别流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_055.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>3.2 特征点检测</b></h4>
                <div class="p1">
                    <p id="57">特征点检测主要分为3个步骤, 分别为:尺度空间极值点检测、精确定位极值点和选取特征点主方向<citation id="124" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="58">首先, SURF算法构建Hessian矩阵 (黑塞) 生成所有可用于特征提取的兴趣点<citation id="125" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。构建Hessian矩阵的目的是生成图像稳定的边缘点。算法对图像中的每个像素点都求出Hessian矩阵, 定义如式 (1) 所示。</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>x</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd><mtd><mi>L</mi><msub><mrow></mrow><mrow><mi>y</mi><mi>y</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>x</i>表示特征点坐标;<i>σ</i>表示尺度;<i>L</i><sub><i>xx</i></sub> (<i>x</i>, <i>σ</i>) 表示输入图像与高斯二阶微分<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mo>∂</mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>g</mi><mo stretchy="false"> (</mo><mi>σ</mi><mo stretchy="false">) </mo></mrow></math></mathml>的卷积。当Hessian矩阵的判别式取得局部极大值时, 判定当前点是比周围领域内其他点更亮或更暗的点, 从而定位关键点的位置<citation id="126" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="62">由于图像中的特征点需要具备尺度无关性, 所以先对特征点进行高斯滤波消除特征点的相关性, 再进行Hessian的计算。<i>L</i> (<i>x</i>, <i>t</i>) 代表不同解析度下的图像, 公式定义如下:</p>
                </div>
                <div class="p1">
                    <p id="63"><i>L</i> (<i>x</i>, <i>t</i>) =<i>G</i> (<i>t</i>) ·<i>I</i> (<i>x</i>, <i>t</i>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>g</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>x</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">式中:<i>I</i> (<i>x</i>, <i>t</i>) 为图像函数。</p>
                </div>
                <div class="p1">
                    <p id="66">在精确定位极值点过程中, SURF算法将Hessian矩阵处理过的每个像素点与其三维领域的26个点进行对比, 如果是极值点则保留, 反之剔除, 再通过三维线性差值法获得亚像素级的特征点, 并删除检测特征点中小于一定阈值的点。</p>
                </div>
                <div class="p1">
                    <p id="67">选取特征点的主方向过程中, 首先统计特征点领域内的haar小波特征, 将以获取的稳定特征点为中心, 计算以6<i>σ</i>为半径的圆形邻域内所有的点在<i>z</i>, <i>y</i>方向上的haar小波响应值。在特征点的领域内, 统计在滑动方向上覆盖π/3的区域内扇形内所有点的水平haar小波特征和垂直haar小波特征的矢量总和, 然后π/3度扇形以一定间隔进行旋转, 将得到最大值的方向作为该特征点的主方向<citation id="127" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="68">构造SURF特征点描述算子过程中, 沿着前一步选定的主方向在特征点周围取一个方形区域块, 边长为20<i>σ</i>。然后将该区域规律地分为4×4的方形子区域, 在每个子区域统计5×5<i>σ</i>范围内像素的相对于主方向的小波响应值, 即水平方向<i>dx</i>和垂直方向<i>dx</i>的haar小波响应值, 并将高斯权值赋给该响应值。该haar小波特征为水平方向值之和, 水平方向绝对值之和, 垂直方向之和, 垂直方向绝对值之和四个方向。这样每一个子区域就得到一个四维的向量<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mi>s</mi><mi>u</mi><mi>b</mi><mo>=</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><mi>x</mi><mo>, </mo><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>|</mo><mrow><mi>d</mi><mi>x</mi></mrow><mo>|</mo></mrow></mrow></mstyle><mo>, </mo><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><mi>y</mi><mo>, </mo><mstyle displaystyle="true"><mo>∑</mo><mrow><mrow><mo>|</mo><mrow><mi>d</mi><mi>y</mi></mrow><mo>|</mo></mrow></mrow></mstyle><mo stretchy="false">) </mo></mrow></math></mathml>, 归一化后形成16×4共64维SURF描述算子, 增加其对几何变换的鲁棒性, 减小局部误差。其中<i>dx</i>为水平方向haar小波特征;<i>dy</i>为垂直方向haar小波特征;<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>d</mi><mi>x</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>为水平方向haar小波特征的绝对值;<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>d</mi><mi>y</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>为垂直方向haar小波特征的绝对值, 具体如图4所示。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 特征点描述向量" src="Detail/GetImg?filename=images/DZCL201912018_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 特征点描述向量  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>3.3 特征的匹配及误匹配点剔除</b></h4>
                <div class="p1">
                    <p id="74">为提高匹配的正确率, 首先采用快速近似邻近点搜索算法找到具有最近距离的匹配点对, 定义如式 (4) 所示。</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo>=</mo><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mrow><mn>6</mn><mn>4</mn></mrow></msub><mo>-</mo><msup><mi>x</mi><mo>′</mo></msup><msub><mrow></mrow><mrow><mn>6</mn><mn>4</mn></mrow></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">式中: (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub>64</sub>) , (<i>x</i>′<sub>1</sub>, <i>x</i>′<sub>2</sub>, …, <i>x</i>′<sub>64</sub>) 为待匹配的两个特征点的SURF特征向量。</p>
                </div>
                <div class="p1">
                    <p id="77">经过上而的特征匹配后得到的初匹配点集中还存在一定数量的误匹配点, 若不进行剔除将会导致单应性矩阵和摄像机内外参数求解上的误差从而影响注册精度, 因此要对初匹配点集进行误匹配点剔除, 本系统采用了统计特征点间距离均值误差的方法剔除误匹配点。</p>
                </div>
                <div class="p1">
                    <p id="78">设<i>A</i><sub>0</sub>, <i>B</i><sub>0</sub>为一对匹配点, 首先在待匹配图像中的初匹配点集里选取一定数量的点<i>A</i><sub><i>i</i></sub>= (<i>i</i>=1, 2, …<i>n</i>) , 并计算<i>A</i><sub>0</sub>与<i>A</i><sub><i>i</i></sub>描述符间的欧式距离<i>D</i><sub><i>i</i></sub>, 再在参考图像中选择与之对应的初匹配点<i>B</i><sub><i>i</i></sub>= (<i>i</i>=1, 2, …, <i>n</i>) 并计算<i>B</i><sub>0</sub>与<i>B</i><sub><i>i</i></sub>描述符间的欧式距离<i>d</i><sub><i>i</i></sub>, 然后计算<i>D</i><sub><i>i</i></sub>/<i>d</i><sub><i>i</i></sub>, 记为<i>RD</i><sub><i>i</i></sub>, <i>RD</i><sub><i>i</i></sub>应分布在平均值附近, 因此构造响应函数:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>n</mi><mi>u</mi><mi>m</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>V</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">若<i>num</i>&lt;<i>n</i>/2, 则认为<i>A</i><sub>0</sub>, <i>B</i><sub>0</sub>是一对正确匹配, 否则剔除这对匹配点。阈值T的选取主要根据<i>d</i><sub><i>i</i></sub>, 当<i>d</i><sub><i>i</i></sub>较小时小的匹配误差会产生较大响应, 阈值T应取大;当<i>d</i><sub><i>i</i></sub>较大时匹配误差的响应较小, 阈值T应取小。以上方法在视角变换不大的场合有较好效果, 在满足AR系统要求的前提下降低了运算量。</p>
                </div>
                <div class="p1">
                    <p id="81">鉴于数据库中特征点相对位置信息是从灰度图上提取的, 所以若符合条件的识别图因纹理过于简单等原因导致可以用作特征点的像素太少, 则可以通过增加原彩色图像的对比度来解决。这是因为彩色图像的对比度增加后, 相应灰度图像的线条也更加明显, 一些原本未能被识别的特征点将被成功识别。识别图中的特征点越多, 实际使用APP时将该图案成功识别出来的概率越大。如图5所示, (a) 图像对比度不高, 不易识别; (b) 图像是左图经过对比度优化后的图像, 识别成功率较左图显著提高。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 对比度优化前后的识别对比" src="Detail/GetImg?filename=images/DZCL201912018_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 对比度优化前后的识别对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_082.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="83">本作品能够实现根据人手势进行暂停、播放视频以及与动画猫咪互动的操作。其基础就是采用了快速图像遮挡算法<citation id="128" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。当用户手势的挥动改变了摄像头获取到的下方图片的部分图像时, 图像处理模块可以捕捉到这种图像特征点的改变, 从而识别用户的操作并做出相应的反馈<citation id="129" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>3.4 图像定位</b></h4>
                <div class="p1">
                    <p id="85">实际操作过程中, Unity 3D中的场景搭建如图6所示。可见, 模型或按键相对识别图的位置与搭建场景时二者相对识别图的位置完全相同, 说明此时系统已自动完成了对识别图的三维定位。同一场景中可以有多张识别图, 同一张识别图上可放置多个虚拟模型或按键。识别图的纹理越复杂, 识别图面积占摄像头视场的面积比例越大, 识别的准确率越高。当控制终端的摄像头离识别图超过一定距离时, 识别图面积占比降至阈值以下, 无法被图像处理模块继续识别和定位, 则原先附着于识别图附近的虚拟按键或模型将会消失。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 Unity 3D中场景搭建" src="Detail/GetImg?filename=images/DZCL201912018_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 Unity 3D中场景搭建  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_086.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>3.5 网络通信部分</b></h4>
                <div class="p1">
                    <p id="88">本项目的网络通信基于WiFi局域网, 采用TCP协议利用Socket进行消息的传递。TCP是一种面向连接的可靠的传输协议<citation id="130" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 他在现今的网络传输中占据着非常重要的位置。TCP协议能够确保数据不会遗失, 特色在于3次握手——主动方发出连接请求, 被动方进行1次回答, 主动方收到回答之后再次发送连接请求最终建立可靠的连接传输需要传递的数据。由此可见, 在3次握手连接和4次挥手终止的作用下, TCP的数据传输稳定性得到了很大的保证。在本项目中选用TCP协议作为传输协议保证了数据传输的可靠和稳定。同时, TCP协议是物联网设备中应用广泛的协议, 如果日后需要增加设备该协议也能够支持。设备的IP地址已经在路由器上固化, 端口号也在程序中固化, 只需要上电即可自动将指定的IP和端口号分配到设备上, 简化了用户的操作。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>3.6 视频播放方案</b></h4>
                <div class="p1">
                    <p id="90">投影展台软件部分主要实现的功能是调用图像处理模块的摄像头, 捕捉置于框架下方的的图像, 通过识别不同的图像使投影仪在下方的书册上投影出不同的视频。</p>
                </div>
                <div class="p1">
                    <p id="91">为了实现这一预期的效果, 首先在识别完成图像之后需要让整个屏幕“变黑”, 即让图像处理模块的屏幕显示一个大型的纯黑图片以遮挡摄像头拍摄到的所有画面。如此做的目的是为了不让摄像头拍摄到的画面干扰到我们需要让投影仪投影到书册的画面。由于投影仪的工作原理是将图像处理模块屏幕上的所有画面直接投影出来, 而自然界中没有“黑光”的存在, 投影仪对黑色的处理方法是在黑色的区域不进行投影, 所以当图像处理模块的屏幕变为纯黑之后投影仪便不对下方进行任何投影。</p>
                </div>
                <div class="p1">
                    <p id="92">实现了图片处理模块屏幕的“纯黑”之后, 根据需求, 在黑幕的上方设置不同的视频。于是与下方的黑幕共同工作后, 投影仪便会只在有视频的位置投影出视频画面而不会让摄像头拍摄到的其他画面影响到投影质量。图7为识别图、黑幕、视频的俯视图;图8为识别图、黑幕、视频的侧视图。</p>
                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 俯视图" src="Detail/GetImg?filename=images/DZCL201912018_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 俯视图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_093.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_094.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 侧视图" src="Detail/GetImg?filename=images/DZCL201912018_094.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 侧视图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_094.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="95">视频播放有两种可行方案。方案1为将视频导入工程文件, 由工程文件内直接调用视频进行播放, 在打包成可执行文件时将视频一起打包发布。这一方案操作简单但是视频的选择不灵活, 一旦需要更换视频文件就要对工程文件进行更改, 重新编译生成可执行文件。并且由于视频被一起被打包成可执行文件, 这就导致可执行文件所占空间极大, 不利于程序传输。</p>
                </div>
                <div class="p1">
                    <p id="96">于是本项目的视频播放采用了方案2。该方案为在程序中预设需要播放的视频名称, 随后检索图像处理模块的存储空间, 当检索到与预设的名称相同的视频文件时就实时导入程序并将其播放。该方案的优点为极大地缩小了可执行文件的大小, 同时使视频文件的更换更加灵活, 仅需要将待更换的视频更改为预设的名称后与图像处理模块内存空间内已有的视频进行替换即可实现程序内播放视频的更改。</p>
                </div>
                <div class="p1">
                    <p id="97">本设备的设计目标是利用图像处理模块和投影仪实现裸眼的增强现实体验。可以利用图像处理模块的摄像头捕捉框架下方的图像, 从而在不同的图像上利用投影仪投影出不同的视频、动态模型。如图9所示, 系统成功识别花朵, 并且在花朵上投影蝴蝶的效果图近景.</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912018_098.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 在花朵上投影蝴蝶近景" src="Detail/GetImg?filename=images/DZCL201912018_098.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 在花朵上投影蝴蝶近景  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912018_098.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="99" name="99" class="anchor-tag"><b>4 系统测试与误差分析</b></h3>
                <h4 class="anchor-tag" id="100" name="100"><b>4.1 系统测试</b></h4>
                <div class="p1">
                    <p id="101">在测试中, 通过对200张图像的投影反应时间进行记录进行图像识别抗干扰测试, 结果如表1所示, 测试得到设备的平均反应时长为0.56 s, 能够满足设备的流畅使用需求。由于设备反应需要时间, 因此当出现用户翻页速度过快时, 设备会出现前一页的视频与现在播放的视频重叠的情况。</p>
                </div>
                <div class="p1">
                    <p id="102">在测试中, 通过比较不同材质纸张材料的反应时长和识别率得到理想的材质结果, 测试结果如表1所示, 证明使用彩色打印纸材质的识别图效果更好, 这主要是因为照片和塑封彩色图片在强烈环境光下会产生明显反光, 受到反射光源影响, 摄像头无法准确识别图像并进行处理, 导致图像识别率明显低于彩色打印纸材质。因此本系统推荐使用彩色打印纸作为识别图, 同时彩色打印纸的识别图测试结果良好, 达到98%, 只要保证一定的环境照度就可以实现理想的识别效果。</p>
                </div>
                <div class="p1">
                    <p id="103">由于该设备连续工作时间由投影仪与设置内部的电池决定, 它能够支持一定时间的不插电工作, 避免突然断电的不稳定因素。</p>
                </div>
                <div class="area_img" id="104">
                    <p class="img_tit"><b>表1 不同纸张材质的识别率和反应时长</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="104" border="1"><tr><td><br />纸质类型/200张</td><td>平均反应时长/s</td><td>识别率/%</td></tr><tr><td><br />彩色打印图像</td><td>0.56</td><td>98</td></tr><tr><td><br />塑封彩色图像</td><td>0.78</td><td>85</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="105">同时, 测试用户与系统互动时, 系统对200张彩色图像的反应时长与识别效率, 结果如表2所示, 测试得到设备的平均反应时长为0.6 s, 能够满足设备的流畅使用需求。同时识别率为90%, 这是由于摄像头与投影仪之间存在角度与距离差距, 且由于图片与摄像头之间的距离较大, 在识别图像上有困难, 难以灵敏地感应到人手的互动无法做出反应, 导致识别率下降。</p>
                </div>
                <div class="area_img" id="106">
                    <p class="img_tit"><b>表2 虚实互动的识别率和反应时长</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="106" border="1"><tr><td><br />彩色图像/200张</td><td>平均互动反应时长/s</td><td>识别率/%</td></tr><tr><td><br />彩色打印图像</td><td>0.6</td><td>90</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>4.2 误差分析</b></h4>
                <div class="p1">
                    <p id="108">在测试中, 观察到在互动过程中, 设备会出现不灵敏或者卡顿的现象, 这些不稳定因素的主要原因有:</p>
                </div>
                <h4 class="anchor-tag" id="109" name="109">1) 摄像头与投影仪之间的角度误差</h4>
                <div class="p1">
                    <p id="110">当用户在播放视频或者与图片上的动物互动时, 有时会出现人手挥动但视频没有播放声音或者动物没有做出预定的动作的情况。这是因为摄像头与投影仪之间存在角度与距离差距, 且由于图片与摄像头之间的距离较大, 在识别图像上有困难, 难以灵敏地感应到人手的互动。后期, 我们将通过提高图片识别率的方法来减少误差。</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111">2) 手机与投影仪之间的联系不稳定</h4>
                <div class="p1">
                    <p id="112">由于设备使用的是WIFI连接系统, 当网络不稳定时, 就会出现视频播放卡顿的情况。这个误差是由于外在条件所引起的, 所以为了改善此状况, 用户需要把设备安置在一个网络连接顺畅的场景下使用。</p>
                </div>
                <h3 id="113" name="113" class="anchor-tag"><b>5 结  论</b></h3>
                <div class="p1">
                    <p id="114">本系统在普遍的基于智能用户端增强现实的基础上, 完成了一台虚实交互展示窗。该设备简洁美观, 具有将对应图案3D化和智能播放视频的增强现实功能。技术上, 它克服了图像识别, 提取特征点, 匹配和定位的技术难点, 采用SURF算法确定两幅图像中的特征角点, 并生成特征点描述符, 然后采用快速近似邻近点搜索进行图像匹配。该方法保证了作品能够流畅地运行其功能。它在教育、娱乐等领域应用前景乐观, 是高科技趣味性的代表, 打破了传统科技与大众之间的壁垒, 能普遍吸引人们的关注。在对系统进行长时间和连续操作稳定性测试, 图像识别抗干扰测试后证明, 系统在稳定性测试中发挥优秀, 能够支持长时间的连续操作, 可以胜任日常生活所需的产品要求。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGGC201712011&amp;v=MTg5MTdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WcjNJUHlyTWJiRzRIOWJOclk5RVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 林栎, 李剑, 覃桢桢, 等.基于增强现实技术的智能终端导游系统[J].软件工程, 2017, 20 (12) :35-38.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXDL201724022&amp;v=MDEzMDNVUjdxZlp1WnRGeXJuVnIzSVBUWFBZckc0SDliT3E0OUhab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 丁铮.增强现实和虚拟现实在博物馆的应用[J].信息与电脑 (理论版) , 2017 (24) :47-50.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A simple solution of occlusion problem in augmented reality and its application for interaction">

                                <b>[3]</b> SETOHARA H, KATO H, KAWAMOTO K, et al.A simple solution of occlusion problem in augmented reality and its application for interaction[J].Transactions of the Virtual Reality Society of Japan, 2004, 9 (4) :387-395.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DNZS201732104&amp;v=MDkxMzNZNUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSUlTUFJmYkc0SDliUHI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 周龙锋, 匡芳君.增强现实技术及其在高校教学中的应用[J].电脑知识与技术, 2017, 13 (32) :228-229, 238.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YSJY201815193&amp;v=MjA2MzBadEZ5cm5WcjNJUEQ3QmQ3RzRIOW5OcW81TVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 夏宗辉.基于增强现实的儿童读物交互设计研究[J].艺术教育, 2018 (15) :229-230.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Head-mounted mixed reality projection display for games production and entertainment">

                                <b>[6]</b> KADE D, AKSIT K, ÜREY H, et al.Head-mounted mixed reality projection display for games production and entertainment[J].Personal and Ubiquitous Computing, 2015, 19 (3) :509-521.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using game engines in mixed reality installations">

                                <b>[7]</b> NAKEVSKA M, VOS C, JUAREZ A, et al.Using game engines in mixed reality installations[M].Entertainment Computing-ICEC 2011.Heidelberg:Springer Berlin, 2011:456-459.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWCL201610020&amp;v=MDExMDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSUlqcklZckc0SDlmTnI0OUhaSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 李军锋, 巫庆辉, 刘杰.基于Unity3D的《电机拖动》虚拟实验室设计与开发[J].国外电子测量技术, 2016, 35 (10) :87-90.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDJT201805020&amp;v=MzE4NzQ5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WcjNJTFNuQmVyRzRIOW5NcW8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 肖乾, 韩瑞, 刘行, 等.基于Unity3D虚实结合的铁道单车制动实验培训系统[J].华东交通大学学报, 2018, 35 (5) :135-142.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YQXB201703003&amp;v=MjA5MjZxZlp1WnRGeXJuVnIzSVBEelRiTEc0SDliTXJJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 秦超龙, 宋爱国, 吴常铖, 等.基于Unity 3D与Kinect的康复训练机器人情景交互系统[J].仪器仪表学报, 2017, 38 (3) :530-536.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201812028&amp;v=Mjg4NDl1WnRGeXJuVnIzSUlUZklZckc0SDluTnJZOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 朱照飞, 刘伟.基于改进的SURF特征点的双目测距[J].电子测量技术, 2018, 41 (12) :133-138.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201605016&amp;v=Mjg0OTgzSUlUZkNkN0c0SDlmTXFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 任克强, 胡梦云.基于改进SURF算子的彩色图像配准算法[J].电子测量与仪器学报, 2016, 30 (5) :748-756.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201705018&amp;v=MzE0MDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSUlUZkNkN0c0SDliTXFvOUViSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 魏利胜, 甘泉.基于小波变换的新型SURF图像拼接方法[J].电子测量与仪器学报, 2017, 31 (5) :766-772.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDDJ201807012&amp;v=MTM3NjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSVBTblBaTEc0SDluTXFJOUVab1FLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 陈敏, 汤晓安.SIFT与SURF特征提取算法在图像匹配中的应用对比研究[J].现代电子技术, 2018, 41 (7) :41-44.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201106064&amp;v=MjE1NDRaTEc0SDlETXFZOURZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVnIzSU5pZlk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 李文生, 解梅, 邓春健.基于多点手势识别的人机交互技术框架[J].计算机工程与设计, 2011, 32 (6) :2129-2133.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLWJ201811014&amp;v=MDUyNjNVUjdxZlp1WnRGeXJuVnIzSU1pSGNaTEc0SDluTnJvOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 闻宏强, 李富勇, 赵一凡, 等.Modbus/TCP协议安全性分析与防护技术探讨[J].物联网技术, 2018, 8 (11) :34-35.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201912018" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201912018&amp;v=MTczMTA1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblZyM0lJVGZJWXJHNEg5ak5yWTlFYklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

