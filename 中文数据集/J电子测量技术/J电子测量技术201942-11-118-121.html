

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135833302756250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201911021%26RESULT%3d1%26SIGN%3dCuGREwZyD8s2bctpxAKPjvWhGjw%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201911021&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201911021&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201911021&amp;v=MTk5MTVuVjczS0lUZklZckc0SDlqTnJvOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 道路场景感知模型&lt;/b&gt; "><b>1 道路场景感知模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="&lt;b&gt;1.1 特征提取层&lt;/b&gt;"><b>1.1 特征提取层</b></a></li>
                                                <li><a href="#43" data-title="&lt;b&gt;1.2 场景分类解码器&lt;/b&gt;"><b>1.2 场景分类解码器</b></a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;1.3 道路分割解码器&lt;/b&gt;"><b>1.3 道路分割解码器</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;2 实验与分析&lt;/b&gt; "><b>2 实验与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#58" data-title="&lt;b&gt;2.1 数据集与模型初始化&lt;/b&gt;"><b>2.1 数据集与模型初始化</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;2.2 实验结果与分析&lt;/b&gt;"><b>2.2 实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;3 结  论&lt;/b&gt; "><b>3 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="图1 道路场景感知CNN模型结构">图1 道路场景感知CNN模型结构</a></li>
                                                <li><a href="#60" data-title="图2 数据训练图集 (部分) ">图2 数据训练图集 (部分) </a></li>
                                                <li><a href="#63" data-title="图3 模型训练的准确率">图3 模型训练的准确率</a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;表1 模型比较结果&lt;/b&gt;"><b>表1 模型比较结果</b></a></li>
                                                <li><a href="#75" data-title="图4 道路场景识别前后图像对比">图4 道路场景识别前后图像对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="92">


                                    <a id="bibliography_1" title=" 金汉均, 段贝贝.卷积神经网络在跨媒体检索中的应用研究[J].电子测量技术, 2018, 41 (7) :54-57." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201807012&amp;v=MTk0OTQ3blY3M05JVGZJWXJHNEg5bk1xSTlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         金汉均, 段贝贝.卷积神经网络在跨媒体检索中的应用研究[J].电子测量技术, 2018, 41 (7) :54-57.
                                    </a>
                                </li>
                                <li id="94">


                                    <a id="bibliography_2" title=" 李学龙, 史建华, 董永生, 等.场景图像分类技术综述[J].中国科学:信息科学, 2015, 45 (7) :827-848." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201507001&amp;v=MTA3MDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk3blY3M05OVGZBZHJHNEg5VE1xSTlGWllRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         李学龙, 史建华, 董永生, 等.场景图像分类技术综述[J].中国科学:信息科学, 2015, 45 (7) :827-848.
                                    </a>
                                </li>
                                <li id="96">


                                    <a id="bibliography_3" title=" 石金进.基于视觉的智能车辆道路识别与障碍物检测方法研究[D].哈尔滨:工业大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017862454.nh&amp;v=MjkwNTZQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTduVjczTlZGMjZHYnUrSE5YSnE1RWI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         石金进.基于视觉的智能车辆道路识别与障碍物检测方法研究[D].哈尔滨:工业大学, 2017.
                                    </a>
                                </li>
                                <li id="98">


                                    <a id="bibliography_4" title=" 李建.城市道路识别方法研究与实现[D].北京:北方工业大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017166590.nh&amp;v=MzA2MDBWRjI2R2JLK0dOVEZyNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk3blY3M04=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         李建.城市道路识别方法研究与实现[D].北京:北方工业大学, 2017.
                                    </a>
                                </li>
                                <li id="100">


                                    <a id="bibliography_5" title=" 司朋举, 胡伟.一种改进的神经网络车牌识别算法研究[J].电子测量技术, 2016, 39 (10) :100-103." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201610021&amp;v=MDQyODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25WNzNOSVRmSVlyRzRIOWZOcjQ5SFpZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         司朋举, 胡伟.一种改进的神经网络车牌识别算法研究[J].电子测量技术, 2016, 39 (10) :100-103.
                                    </a>
                                </li>
                                <li id="102">


                                    <a id="bibliography_6" title=" LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2014, 39 (4) :640-651." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">
                                        <b>[6]</b>
                                         LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2014, 39 (4) :640-651.
                                    </a>
                                </li>
                                <li id="104">


                                    <a id="bibliography_7" title=" GINSCA A L, POPESCU A, BORGNE H L, et al.Large-scale image mining with flickr groups[M].MultiMedia Modeling, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large-scale image mining with flickr groups">
                                        <b>[7]</b>
                                         GINSCA A L, POPESCU A, BORGNE H L, et al.Large-scale image mining with flickr groups[M].MultiMedia Modeling, 2015.
                                    </a>
                                </li>
                                <li id="106">


                                    <a id="bibliography_8" title=" KRIZHEVSKY A, SUTSKEVER I, HINTON G.Imagenet classification with deep convolutional neural networks[C].NIPS.Curran Associates Inc.2012." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;ImageNet classification with deep convolutional neural networks,&amp;quot;">
                                        <b>[8]</b>
                                         KRIZHEVSKY A, SUTSKEVER I, HINTON G.Imagenet classification with deep convolutional neural networks[C].NIPS.Curran Associates Inc.2012.
                                    </a>
                                </li>
                                <li id="108">


                                    <a id="bibliography_9" title=" 冯国徽.基于卷积神经网络VGG模型的小规模图像分类[D].兰州:兰州大学, 2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018978648.nh&amp;v=MTUzNjRGcnEvRnRmSXA1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTduVjczTlZGMjY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         冯国徽.基于卷积神经网络VGG模型的小规模图像分类[D].兰州:兰州大学, 2018.
                                    </a>
                                </li>
                                <li id="110">


                                    <a id="bibliography_10" title=" CHEN L C, PAPANDREOU G, KOKKINOS I, et al.DeepLab:Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2018, 40 (4) :834-848." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Lab:semantic image segmentation with deep convolutional nets,atrous convolution,and fully connected CRFs">
                                        <b>[10]</b>
                                         CHEN L C, PAPANDREOU G, KOKKINOS I, et al.DeepLab:Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2018, 40 (4) :834-848.
                                    </a>
                                </li>
                                <li id="112">


                                    <a id="bibliography_11" title=" STEWART R, ANDRILUKA M, NG A Y.End-to-end people detection in crowded scenes[C].2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016:2325-2333." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=End-to-end people detection in crowded scenes">
                                        <b>[11]</b>
                                         STEWART R, ANDRILUKA M, NG A Y.End-to-end people detection in crowded scenes[C].2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016:2325-2333.
                                    </a>
                                </li>
                                <li id="114">


                                    <a id="bibliography_12" title=" XU M, SUN F, JIANG X.Multi-label learning with co-training based on semi-supervised regression[C].International Conference on Security.2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-label learning with co-training based on semi-supervised regression">
                                        <b>[12]</b>
                                         XU M, SUN F, JIANG X.Multi-label learning with co-training based on semi-supervised regression[C].International Conference on Security.2014.
                                    </a>
                                </li>
                                <li id="116">


                                    <a id="bibliography_13" title=" CHEN L C, PAPANDREOU G, KOKKINOS I, et al.DeepLab:Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2016, 40 (4) :834-848." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Lab:semantic image segmentation with deep convolutional nets,atrous convolution,and fully connected CRFs">
                                        <b>[13]</b>
                                         CHEN L C, PAPANDREOU G, KOKKINOS I, et al.DeepLab:Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2016, 40 (4) :834-848.
                                    </a>
                                </li>
                                <li id="118">


                                    <a id="bibliography_14" title=" FRITSCH J, KUHNL T, GEIGER A.A new performance measure and evaluation benchmark for road detection algorithms[C].International IEEE Conference on Intelligent Transportation Systems.IEEE, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new performance measure and evaluation benchmark for road detection algorithms">
                                        <b>[14]</b>
                                         FRITSCH J, KUHNL T, GEIGER A.A new performance measure and evaluation benchmark for road detection algorithms[C].International IEEE Conference on Intelligent Transportation Systems.IEEE, 2014.
                                    </a>
                                </li>
                                <li id="120">


                                    <a id="bibliography_15" title=" SERMANET P, EIGEN D, ZHANG X, et al.Overfeat:integrated recognition, localization and detection using convolutional networks[J].Eprint Arxiv:1312.6229, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Overfeat:integrated recognition,localization and detection using convolutional networks">
                                        <b>[15]</b>
                                         SERMANET P, EIGEN D, ZHANG X, et al.Overfeat:integrated recognition, localization and detection using convolutional networks[J].Eprint Arxiv:1312.6229, 2013.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(11),118-121 DOI:10.19651/j.cnki.emt.1802412            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度学习的多类道路场景感知</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E9%80%B8&amp;code=34239585&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘逸</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BA%94%E6%8D%B7&amp;code=08571483&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">应捷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%98%8E%E7%8E%BA&amp;code=42201433&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈明玺</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0256814&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海理工大学光电信息与计算机工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>对道路环境的感知是无人驾驶技术中的关键技术, 车辆对可行驶区域的判定是环境感知中的重要一环。提出一种基于CNN的双任务联合结构模型, 由1个编码器、2个解码器组成, 通过端到端训练, 实现特征信息共享, 完成对城市道路、乡村道路和高速公路等多种道路场景的分类, 并对场景中的道路进行分割, 达到场景分类和道路分割的双重目标。实验表明, 该结构模型能有效提高训练速度和分割精度, 具有实时性, 为智能驾驶辅助系统提供有价值的技术信息。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%8E%AF%E5%A2%83%E6%84%9F%E7%9F%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">环境感知;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像分割;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘逸, 硕士研究生, 主要研究方向为图像处理、测试计量。E-mail:yliu_61@163.com;
                                </span>
                                <span>
                                    应捷, 博士, 副教授, 主要研究方向为图像处理、模式识别。;
                                </span>
                                <span>
                                    陈明玺, 大学本科生, 主要研究方向为电子信息工程。E-mail:chen686997@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11</p>

            </div>
                    <h1><b>Road scene perception which based on convolution neural network</b></h1>
                    <h2>
                    <span>Liu Yi</span>
                    <span>Ying Jie</span>
                    <span>Chen Mingxi</span>
            </h2>
                    <h2>
                    <span>School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Road environment perception is the key technology in the unmanned driving technology, and the determination of the driving area is an important part of the environment perception. A dual-task joint structure model based on CNN is proposed. It is composed of an encoder and two decoders. Through end-to-end training, the feature information is shared. The classification of urban road, rural road and highway and other road scenes are completed. Experiment shows that the structure of this model can effectively improve the training speed and segmentation accuracy, with real-time, and provide valuable technical information for intelligent driving assistance system.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolution%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolution neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=environmental%20perception&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">environmental perception;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20segmentation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image segmentation;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11</p>
                            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="34">深度卷积神经网络 (convolutional neural network, CNN) 推动了计算机视觉领域的发展, 无人驾驶系统中的环境感知任务受到极大关注<citation id="122" type="reference"><link href="92" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。利用车载相机获取车辆行驶过程中的道路图像, 对图像进行道路场景分类<citation id="123" type="reference"><link href="94" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、道路区域检测<citation id="125" type="reference"><link href="96" rel="bibliography" /><link href="98" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>、行人检测及车辆检测<citation id="124" type="reference"><link href="100" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等是环境感知中的重要任务, 也是计算机视觉领域的一个热门研究课题。双任务道路场景识别的目标是:能够自动获取道路图像的高层语义信息, 赋予图像一个深度理解的语义标签, 对图像所属的场景类别进行判断, 并对图像中的可行驶区域进行提取<citation id="126" type="reference"><link href="102" rel="bibliography" /><link href="104" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。当智能车辆驾驶辅助系统有潜在危险时, 使用带标签的道路场景图像更能描绘驾驶员所处场景。</p>
                </div>
                <div class="p1">
                    <p id="35">CNN在语音识别、图像识别和自然语言处理等领域均有广泛运用<citation id="129" type="reference"><link href="106" rel="bibliography" /><link href="108" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>。CNN从样本中获得的初始特征经过卷积、池化等变换, 逐层得到新的特征向量, 有利于图像的分类和特征信息的可视化。2012年AlexNet模型提出后, 涌现出很多利用深度学习进行图像分类的方法, 诸如GooleNet、ResNet, 相比AlexNet网络更深, 不会产生梯度消失或爆炸。在语义分割任务方面, Chen等<citation id="130" type="reference"><link href="110" rel="bibliography" /><link href="112" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>提出了全卷积网络 (fully convolutional networks, FCN) , 采用端到端可训练的深度学习通道模型进行语义分割任务;Xu等<citation id="127" type="reference"><link href="114" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出转置卷积用于低分辨率特征进行上采样获得高分辨率特征图的方法;Shin等采用深度CNN来解决计算机辅助检测问题, 评估不同的CNN结构、数据规模以及空间图像背景对检查性能的影响, 并使用迁移学习的方法对医学图像进行检测;Chen等<citation id="131" type="reference"><link href="116" rel="bibliography" /><link href="118" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>提出全连接网络与条件随机场相结合的方式能得到很好的分割效果。在多个任务结合方面, Malik等提出使用支持向量机技术 (support vector machine, SVM) 与动态规划相结合的分类分割方法;Sepmanet等<citation id="128" type="reference"><link href="120" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出滑动窗口与多尺度相结合的卷积网络模型进行分类、定位和检测。但是, 这些模型完成每一个任务都需要设置一系列不同的参数值, 在需要同时完成多个任务目标时, 耗时较长, 从计算的角度来看, 在推理时有必要考虑网络在内存和计算时间方面的高效性。</p>
                </div>
                <div class="p1">
                    <p id="36">基于以上要求, 本文提出一个可以同时完成道路场景分类和道路分割的双任务CNN模型。该模型具有1个共享编码器, 用于图像信息的特征提取, 2个任务解码器分别完成分类、分割任务。模型可进行端到端的训练, 所有任务经联合推理输出, 用于对道路场景的理解, 为智能驾驶提供鲁棒性强、精度高的道路场景识别和平滑分割, 使得该方法能用于汽车领域的无人驾驶等领域。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>1 道路场景感知模型</b></h3>
                <div class="p1">
                    <p id="38">本文提出的道路场景感知CNN模型结构如图1所示, 包含4层结构:输入层、特征提取层、信息处理层和输出层。车辆行驶过程中, 由车载相机所获取的原始图像经预处理后作为模型的输入;特征信息提取层为一个深度CNN生成的编码器, 从输入层的图像中提取信息处理层所需的丰富的图像特征;信息处理层由2个解码器组成, 为分类解码器和分割解码器, 二者共享由特征提取出层的产生的图像特征信息, 分别完成道路场景分类和道路分割的任务, 2个解码器的结果经联合推理, 最终得到道路场景感知的结果。</p>
                </div>
                <div class="area_img" id="39">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911021_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 道路场景感知CNN模型结构" src="Detail/GetImg?filename=images/DZCL201911021_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 道路场景感知CNN模型结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911021_039.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="40" name="40"><b>1.1 特征提取层</b></h4>
                <div class="p1">
                    <p id="41">特征提取层的任务是处理图像并提取丰富的道路分割和场景分类所需的必要图像信息。本文采用深度CNN VGG16 (visual geometry group, VGG) 模型, 可以快速有效地学习场景图像特征, 使得场景图像特征更具抽象性, 表达能力更加突出。通常VGG模型使用224×224的图像作为输入, 对道路场景而言尺寸太小, 实验保留VGG网络的全部卷积层和池化层, 舍弃后面用于分类的3个全连接层, 并用1×1的卷积层替代, 这使得特征提取层的编码器能处理任意大小尺寸输入的图像。</p>
                </div>
                <div class="p1">
                    <p id="42">编码过程中, 使用大小为3×3, 步长为1的卷积核在每一次执行卷积操作时会产生相应的特征图, 提取图像的细节特征, 用ReLU激活函数对其结果进行非线性映射。之后用大小为2×2, 步长为2的滤波器进行池化操作, 对图像的特征进行筛选。每次下采样使得特征图的长与宽均变为原来的1/2。多次的卷积、池化操作后, 最终得到信息处理层所需固定分辨率的特征图。</p>
                </div>
                <h4 class="anchor-tag" id="43" name="43"><b>1.2 场景分类解码器</b></h4>
                <div class="p1">
                    <p id="44">特道路场景包括城市街道、乡村小路、雪地道路、荒漠道路和校园道路5类, 属于多分类类型, 采用soft Max分类器。设<i>m</i>个训练集样本为{ (<i>x</i><sup> (1) </sup>, <i>y</i><sup> (1) </sup>) (<i>x</i><sup> (2) </sup>, <i>y</i><sup> (2) </sup>) … (<i>x</i><sup> (<i>m</i>) </sup>, <i>y</i><sup> (<i>m</i>) </sup>) }, <b><i>x</i></b><sup> (<i>i</i>) </sup>表示输出征向量, <i>y</i><sup> (<i>i</i>) </sup>是这个数据的真实标签, <i>y</i><sup> (<i>i</i>) </sup>∈{1, 2, …, <i>k</i>}, <i>k</i>=5。对于给定的测试图片<i>x</i>, 计算出<i>x</i>属于每类别<i>j</i>的概率矩阵为:</p>
                </div>
                <div class="p1">
                    <p id="45"><mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>y</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mi>j</mi><mo stretchy="false">|</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>, </mo><mi>w</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false">[</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msup><mo>, </mo><mtext>e</mtext><msup><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msup><mo>⋯</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></msup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><mi>w</mi><msub><mrow></mrow><mi>l</mi></msub></mrow></msup></mrow></mfrac></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="47">式中:<i>w</i>是全连接层中神经元与softmax分类器第<i>i</i>个输出神经元相连接的权重参数。分类器对道路图像进行分类时, 计算图像属于各个分类的概率, 取概率值最大的分类为该图像的类别。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48"><b>1.3 道路分割解码器</b></h4>
                <div class="p1">
                    <p id="49">原始道路场景图像经特征编码器池化后缩小了的尺寸, 产生低分辨率特征图, 为得到与原图等大的分割图, 传统全卷积网络 (fully convolutional networks, FCN) 使用卷积层对输出结果通过反卷积进行上采样, 结合跳跃链接结构产生高分辨率图像优化输出结果, 达到分割效果。但FCN为增大图片尺寸对原图进行填充的做法会引入噪声, 分割得到的结果不够精细, 缺乏空间一致性。本文将FCN与条件随机场 (conditional random field, CRF) 相结合, 同时训练, 生成一个端到端的网络, 增进分割效果。条件随机场的能量目标函数为:</p>
                </div>
                <div class="p1">
                    <p id="50"><mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>ψ</mi></mstyle><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>&lt;</mo><mi>j</mi></mrow></munder><mi>ψ</mi></mstyle><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="52">式中:<i>i</i>, <i>j</i>表示像素点。能量方程的第1项<i>ψ</i><sub><i>u</i></sub> (<i>x</i><sub><i>i</i></sub>) 成为一元势函数, 用于衡量当像素点<i>i</i>的像素值为<i>y</i><sub><i>i</i></sub>时, 该像素点属于类别标签<i>x</i><sub><i>i</i></sub>的概率, 能量方程的第2项为成对势函数<i>ψ</i><sub><i>p</i></sub> (<i>x</i><sub><i>i</i></sub>, <i>x</i><sub><i>j</i></sub>) , 用于衡量2个像素点属于同一类的概率<i>P</i> (<i>x</i><sub><i>i</i></sub>, <i>x</i><sub><i>j</i></sub>) 。且:</p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>u</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>k</mi></mstyle><msubsup><mrow></mrow><mi>G</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false"> (</mo><mi>f</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>f</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="55">式中:<i>k</i><mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>G</mi><mrow><mo stretchy="false"> (</mo><mi>m</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>是高斯核, 用于度量像素点<i>i</i>和<i>j</i>的特征向量相似度的一个高斯权重项;特征向量<i>f</i><sub><i>i</i></sub>可用像素点的像素值和坐标位置表示为 (<i>x</i>, <i>y</i>, <i>R</i>, <i>G</i>, <i>B</i>) ;<i>u</i> (<i>x</i><sub><i>i</i></sub>, <i>x</i><sub><i>j</i></sub>) 表示标签之间的兼容度。把CRF的推理过程看成卷积层、softMax层等神经网络层的组合, 通过最小化CRF的能量函数达到分割效果。</p>
                </div>
                <h3 id="57" name="57" class="anchor-tag"><b>2 实验与分析</b></h3>
                <h4 class="anchor-tag" id="58" name="58"><b>2.1 数据集与模型初始化</b></h4>
                <div class="p1">
                    <p id="59">实验的训练集和测试集由SUN数据集、KITTI数据集和CamVid中的2 000幅道路场景图像按3∶1的比例组成, 使4类标签图像参与训练, 可在测试图像中识别城市街道、乡村小路、荒漠道路和高速公路4类道路场景, 对道路场景视频实时感知, 如图2所示为数据集展示。网络输入设置为RGB图像, 为还原真实场景的表现细节, 对图像的颜色与对比度进行修正后投入网络, 并计算训练集中图像像素的RGB值的平均值, 以供训练使用。实验采用迁移学习法进行网络训练, 将在2012年ILSVRC (imagenet large scale visual recognition challenge) 数据集上预先训练好的VGG-16网络模型参数作为特征编码器和分类解码器的初始权重。训练网络时采用动量参数为0.9, 学习率为0.01, 权值衰减为 0.000 5的随机梯度下降法 (SGD) 对目标损失函数进行优化, 训练中使用类平衡法, batchsiaze设为5, 训练集图片被打乱后, 按5幅图像为一个批次顺序的抽取, 确保迭代过程中每张图像的使用次数为1, 训练VGGNet网络直到损失函数收敛。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911021_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 数据训练图集 (部分)" src="Detail/GetImg?filename=images/DZCL201911021_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 数据训练图集 (部分)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911021_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="61" name="61"><b>2.2 实验结果与分析</b></h4>
                <div class="p1">
                    <p id="62">本文基于python语言的TensorFlow框架搭建模型进行实验, 采用GPU计算模式以加快网络运算速度。操作系统为Ubuntu18.04, 开发语言为python3.6, 深度学习框架为Tensorflow 1.2.1, 硬件上使用NVIDIA GeForce GTX960 M卡。实验使用5类标签图像参与训练, 网络经过1 000次迭代优化训练后精度曲线图如图3所示, 当迭代次数达到1 000次后, 模型的的精度稳定在95%左右。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911021_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 模型训练的准确率" src="Detail/GetImg?filename=images/DZCL201911021_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 模型训练的准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911021_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="64">对模型的分类性能通过计算精度和召回率进行评估, 精度是精确性的度量, 表示被分为某一类的图像占实际该类图像的比例;召回率是覆盖面的度量, 度量被正确分类的图像比例。计算方法如下, 假设<b><i>M</i></b>是<i>n</i>类道路场景的混淆矩阵, 列表示类别的真值, 行表示预测的类别, <b><i>M</i></b><sub><i>ij</i></sub>表示类别<i>i</i>被标记为<i>j</i>的数量。则计算精度<i>P</i>和召回率<i>R</i>的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="65"><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="bold-italic">Μ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="bold-italic">Μ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="67"><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="bold-italic">Μ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>/</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="bold-italic">Μ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="69">分割性能通过平衡<i>F</i>分数衡量, 偏置参数为<i>β</i>, 则<i>F</i><sub><i>β</i></sub>的计算如式 (6) 所示, 当取<i>β</i>=1时, <i>F</i>分数为准确率和召回率的调和平均数。</p>
                </div>
                <div class="p1">
                    <p id="70"><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mi>β</mi></msub><mo>=</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>β</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo><mo>⋅</mo><mfrac><mrow><mi>Ρ</mi><mo>⋅</mo><mi>R</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>β</mi><msup><mrow></mrow><mn>2</mn></msup><mo>⋅</mo><mi>Ρ</mi><mo stretchy="false">) </mo><mo>+</mo><mi>R</mi></mrow></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="72">在数据集上, 各个卷积神经网络通过相同训练次数得到的模型进行测试后, 指标的对比结果如表1所示。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit"><b>表1 模型比较结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"> (%) </p>
                    <table id="73" border="1"><tr><td><br />模型名称</td><td><i>P</i></td><td><i>R</i></td><td><i>F</i></td></tr><tr><td><br />Alex</td><td>89.3</td><td>84.1</td><td>85.4</td></tr><tr><td><br />ResNet</td><td>95.1</td><td>89.5</td><td>92.2</td></tr><tr><td><br />VGG</td><td>96.4</td><td>88.6</td><td>92.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="74">可以看出VGG与ResNet模型用于道路场景分类在精度和召回率2个评价标准上较有优越性, 基于VGG的卷积神经网络能达到精度最优, 召回率上略低于其他方法, 实验使用模型参数更少的VGG模型并进行了优化, 分类结果能够满足训回归器的要求。实验效果如图4所示。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911021_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 道路场景识别前后图像对比" src="Detail/GetImg?filename=images/DZCL201911021_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 道路场景识别前后图像对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911021_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="76">图4中, (a) 、 (c) 、 (e) 、 (g) 分别为沙漠、街道、乡村小路和高速路的原图; (b) 、 (d) 、 (f) 、 (h) 为沙漠、街道、乡村小路和高速路经模型进行场景识别的结果, 可以看出本文提出的模型对道路场景能进行有效感知, 可识别多类道路场景图像并分割出较为完整的道路区域, 证明了算法的适应性。</p>
                </div>
                <div class="p1">
                    <p id="77">根据图3可知, 本方法模型训练的准确率随着迭代次数的增加, 逐渐趋近95%。对比其它训练模型, 其精度最优, 由于本实验优化了VGG模型的参数, 提高了其对目标提取识别的效果。</p>
                </div>
                <div class="p1">
                    <p id="78">同时图4所示的实验结果直观的表明, 优化后的VGG模型在道路识别并提取的效果上表现出色。实验也说明基于VGG网络模型的道路识别提取能够准确实现, 该方法可应用于汽车领域的无人驾驶技术。本实验完全达到预期目的。</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>3 结  论</b></h3>
                <div class="p1">
                    <p id="80">本文提出了一种可同时完成场景分类和道路分割的CNN模型, 该模型可进行端到端训练, 在结构上通过图像特征共享的思想, 达到联合推理的目的, 完成道路场景感知任务。相对其他网络, 分割精度达到较高水平。随着最近汽车领域无人驾驶领域的蓬勃发展, 对道路的识别并提取无疑是模式识别和汽车领域的研究难点与重点。因此, 本实验具备很强的实用性。通过对VGG网络的参数优化, 基于该网络模型的道路提取识别的精密度高于其它网络模型。</p>
                </div>
                <div class="p1">
                    <p id="81">但是, 本文仍有值得优化改进的地方。道路分割时, 颜色作为CRF的成对能量函数的特征向量, 会受到阴影覆盖的影响, 且垂直物体与道路的颜色相近时也不利于分割。在下一步的研究中, 我们将针对存在阴影的道路场景进行深入的研究, 在保证道路感知效率的同时, 提高道路的分割精度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="92">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201807012&amp;v=MTExMjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25WNzNOSVRmSVlyRzRIOW5NcUk5RVpvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 金汉均, 段贝贝.卷积神经网络在跨媒体检索中的应用研究[J].电子测量技术, 2018, 41 (7) :54-57.
                            </a>
                        </p>
                        <p id="94">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201507001&amp;v=MTgyMzVuVjczTk5UZkFkckc0SDlUTXFJOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 李学龙, 史建华, 董永生, 等.场景图像分类技术综述[J].中国科学:信息科学, 2015, 45 (7) :827-848.
                            </a>
                        </p>
                        <p id="96">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CDFD&amp;filename=1017862454.nh&amp;v=MTUxMDJDVVI3cWZadVp0Rnk3blY3M05WRjI2R2J1K0hOWEpxNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 石金进.基于视觉的智能车辆道路识别与障碍物检测方法研究[D].哈尔滨:工业大学, 2017.
                            </a>
                        </p>
                        <p id="98">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017166590.nh&amp;v=MTQ5MjZxZlp1WnRGeTduVjczTlZGMjZHYksrR05URnI1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 李建.城市道路识别方法研究与实现[D].北京:北方工业大学, 2017.
                            </a>
                        </p>
                        <p id="100">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201610021&amp;v=MjM5NDNJWXJHNEg5Zk5yNDlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk3blY3M05JVGY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 司朋举, 胡伟.一种改进的神经网络车牌识别算法研究[J].电子测量技术, 2016, 39 (10) :100-103.
                            </a>
                        </p>
                        <p id="102">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">

                                <b>[6]</b> LONG J, SHELHAMER E, DARRELL T.Fully convolutional networks for semantic segmentation[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2014, 39 (4) :640-651.
                            </a>
                        </p>
                        <p id="104">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large-scale image mining with flickr groups">

                                <b>[7]</b> GINSCA A L, POPESCU A, BORGNE H L, et al.Large-scale image mining with flickr groups[M].MultiMedia Modeling, 2015.
                            </a>
                        </p>
                        <p id="106">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;ImageNet classification with deep convolutional neural networks,&amp;quot;">

                                <b>[8]</b> KRIZHEVSKY A, SUTSKEVER I, HINTON G.Imagenet classification with deep convolutional neural networks[C].NIPS.Curran Associates Inc.2012.
                            </a>
                        </p>
                        <p id="108">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018978648.nh&amp;v=MTU3NjBGckNVUjdxZlp1WnRGeTduVjczTlZGMjZGcnEvRnRmSXA1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 冯国徽.基于卷积神经网络VGG模型的小规模图像分类[D].兰州:兰州大学, 2018.
                            </a>
                        </p>
                        <p id="110">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Lab:semantic image segmentation with deep convolutional nets,atrous convolution,and fully connected CRFs">

                                <b>[10]</b> CHEN L C, PAPANDREOU G, KOKKINOS I, et al.DeepLab:Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2018, 40 (4) :834-848.
                            </a>
                        </p>
                        <p id="112">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=End-to-end people detection in crowded scenes">

                                <b>[11]</b> STEWART R, ANDRILUKA M, NG A Y.End-to-end people detection in crowded scenes[C].2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016:2325-2333.
                            </a>
                        </p>
                        <p id="114">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-label learning with co-training based on semi-supervised regression">

                                <b>[12]</b> XU M, SUN F, JIANG X.Multi-label learning with co-training based on semi-supervised regression[C].International Conference on Security.2014.
                            </a>
                        </p>
                        <p id="116">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Lab:semantic image segmentation with deep convolutional nets,atrous convolution,and fully connected CRFs">

                                <b>[13]</b> CHEN L C, PAPANDREOU G, KOKKINOS I, et al.DeepLab:Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2016, 40 (4) :834-848.
                            </a>
                        </p>
                        <p id="118">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new performance measure and evaluation benchmark for road detection algorithms">

                                <b>[14]</b> FRITSCH J, KUHNL T, GEIGER A.A new performance measure and evaluation benchmark for road detection algorithms[C].International IEEE Conference on Intelligent Transportation Systems.IEEE, 2014.
                            </a>
                        </p>
                        <p id="120">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Overfeat:integrated recognition,localization and detection using convolutional networks">

                                <b>[15]</b> SERMANET P, EIGEN D, ZHANG X, et al.Overfeat:integrated recognition, localization and detection using convolutional networks[J].Eprint Arxiv:1312.6229, 2013.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201911021" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201911021&amp;v=MTk5MTVuVjczS0lUZklZckc0SDlqTnJvOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

