

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135576572912500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dDZCL201919028%26RESULT%3d1%26SIGN%3dW2MGK17OCLRSwn%252bi%252fly91nufNQA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201919028&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201919028&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201919028&amp;v=MDg1OTZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5tVmJySklUZklZckc0SDlqTnBvOUg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;1 文献回顾&lt;/b&gt; "><b>1 文献回顾</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="&lt;b&gt;2 实验方法&lt;/b&gt; "><b>2 实验方法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;3 本文算法&lt;/b&gt; "><b>3 本文算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#63" data-title="&lt;b&gt;3.1 算法步骤简述&lt;/b&gt;"><b>3.1 算法步骤简述</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;3.2 流程图&lt;/b&gt;"><b>3.2 流程图</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;4 实验与结果&lt;/b&gt; "><b>4 实验与结果</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="&lt;b&gt;4.1 实验环境&lt;/b&gt;"><b>4.1 实验环境</b></a></li>
                                                <li><a href="#89" data-title="&lt;b&gt;4.2 均衡化和实验结果&lt;/b&gt;"><b>4.2 均衡化和实验结果</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;4.3 关键帧选择和实验结果&lt;/b&gt;"><b>4.3 关键帧选择和实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#100" data-title="&lt;b&gt;5 结  论&lt;/b&gt; "><b>5 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="图1 视频的层次结构">图1 视频的层次结构</a></li>
                                                <li><a href="#52" data-title="图2 图像直方图">图2 图像直方图</a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;表1 用于表示程序流程的图形&lt;/b&gt;"><b>表1 用于表示程序流程的图形</b></a></li>
                                                <li><a href="#92" data-title="图3 算法流程">图3 算法流程</a></li>
                                                <li><a href="#92" data-title="图3 算法流程">图3 算法流程</a></li>
                                                <li><a href="#94" data-title="图4 图像的均衡方法">图4 图像的均衡方法</a></li>
                                                <li><a href="#98" data-title="图5 本文算法得到的关键帧">图5 本文算法得到的关键帧</a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;表2 本文方法处理不同视频的实验结果汇总&lt;/b&gt;"><b>表2 本文方法处理不同视频的实验结果汇总</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" COTSACES C,NIKOLAIDIS N,PITAS I.Video shot detection and condensed representation.a review[J].IEEE Signal Processing Magazine,2006,23(2):28-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Video shot detection and condensed representation. a review">
                                        <b>[1]</b>
                                         COTSACES C,NIKOLAIDIS N,PITAS I.Video shot detection and condensed representation.a review[J].IEEE Signal Processing Magazine,2006,23(2):28-37.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" FENG D,SIU W,ZHANG H.Multimedia information retrieval and management:Technological Fundamentals and Applications[M].Springer,2003." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multimedia information retrieval and management:Technological Fundamentals and Applications">
                                        <b>[2]</b>
                                         FENG D,SIU W,ZHANG H.Multimedia information retrieval and management:Technological Fundamentals and Applications[M].Springer,2003.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" RASHEED Z,SHAH M.Scene detection in Hollywood movies and TV shows[C].Proceedings of the IEEE Computer Vision and Pattern Recognition Conference Madison,2003:343-348." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scene detection in hollywood movies and TV shows">
                                        <b>[3]</b>
                                         RASHEED Z,SHAH M.Scene detection in Hollywood movies and TV shows[C].Proceedings of the IEEE Computer Vision and Pattern Recognition Conference Madison,2003:343-348.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" KOBLA V,DOERMANN D,LIN K I.Archiving,indexing and retrieval of video in the compressed domain[C].Proceeding of SPIE Conference,1996,78-89." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Archiving,indexing and retrieval of video in the compressed domain">
                                        <b>[4]</b>
                                         KOBLA V,DOERMANN D,LIN K I.Archiving,indexing and retrieval of video in the compressed domain[C].Proceeding of SPIE Conference,1996,78-89.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" CALIC J,THOMAS B T.Spatial analysis in key-frame extraction using video segmentation[C].Proceedings of Workshop on Image Analysis for Multimedia Interactive Services,2004." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial analysis in key-frame extraction using video segmentation">
                                        <b>[5]</b>
                                         CALIC J,THOMAS B T.Spatial analysis in key-frame extraction using video segmentation[C].Proceedings of Workshop on Image Analysis for Multimedia Interactive Services,2004.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" DOULAMIS A D,DOULAMIS N D,KOLLIAS S D.A fuzzy video content representation for video summarization and content based retrieval[J].Journal of Signal Processing,2000,80(6):1049-1060." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300652443&amp;v=MDg1ODRZdTROQ0hnNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlWMFNieEk9TmlmT2ZiSzdIdERPckk5Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         DOULAMIS A D,DOULAMIS N D,KOLLIAS S D.A fuzzy video content representation for video summarization and content based retrieval[J].Journal of Signal Processing,2000,80(6):1049-1060.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" LAGENDIJ R L,HANJALIC A,CECCARELLI M,et al.Visual search in a SMASH system[C].Proceedings of IEEE ICIP,1996:671-674." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visual search in a SMASH system">
                                        <b>[7]</b>
                                         LAGENDIJ R L,HANJALIC A,CECCARELLI M,et al.Visual search in a SMASH system[C].Proceedings of IEEE ICIP,1996:671-674.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" FURHT B,SAKSOBHAVIVAT P.A fast content-based multimedia retrieval technique using compressed data [C].Proceedings of SPIE’94 Symposium on Image and Video Processing,1998:142-149." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A fast content-based multimedia retrieval technique using compressed data">
                                        <b>[8]</b>
                                         FURHT B,SAKSOBHAVIVAT P.A fast content-based multimedia retrieval technique using compressed data [C].Proceedings of SPIE’94 Symposium on Image and Video Processing,1998:142-149.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" ZHUANG Y,RUI Y,HUANG T S,et al.Adaptive key frame extraction using unsupervised clustering[C].Proceedings of IEEE Conference,1998:866-870." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive key frame extraction using unsupervised clustering">
                                        <b>[9]</b>
                                         ZHUANG Y,RUI Y,HUANG T S,et al.Adaptive key frame extraction using unsupervised clustering[C].Proceedings of IEEE Conference,1998:866-870.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" WOLF W.Key frame selection by motion analysis[C].Proceedings of the Acoustics,Speech,and Signal Processing,2002:1228-1231." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Key Frame selection,by motion analysis">
                                        <b>[10]</b>
                                         WOLF W.Key frame selection by motion analysis[C].Proceedings of the Acoustics,Speech,and Signal Processing,2002:1228-1231.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" MUKHARGEE D P,DAS S K,SAHA S.Key frame estimation in video using randomness measure of feature point pattern[J].IEEE Transactions on Circuits and Systems for Video Technology,2007,17(5):612-620." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Key frame estimation in video using randomness measure of feature point pattern">
                                        <b>[11]</b>
                                         MUKHARGEE D P,DAS S K,SAHA S.Key frame estimation in video using randomness measure of feature point pattern[J].IEEE Transactions on Circuits and Systems for Video Technology,2007,17(5):612-620.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" LIU L,SHAO L,ROCKETT P.Boosted key-frame selection and correlated pyramidal motion-feature representation for human action recognition [J].Pattern Recognition,2013,46(7):1810-1818." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739923&amp;v=MDc0NDdpclJkR2VycVFUTW53WmVadEZpbmxVcnpJSVYwU2J4ST1OaWZPZmJLN0h0RE5xWTlGWStnR0JYNDZvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         LIU L,SHAO L,ROCKETT P.Boosted key-frame selection and correlated pyramidal motion-feature representation for human action recognition [J].Pattern Recognition,2013,46(7):1810-1818.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" WANG D,LIU J,SUN J,et al.A novel key-frame extraction method for semi-automatic 2D-to-3D video conversion[C].IEEE International Symposium on Broadband Multimedia Systems and Broadcasting,2012:1-5." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel key-frame extraction method for semi-automatic 2D-to-3D video conversion">
                                        <b>[13]</b>
                                         WANG D,LIU J,SUN J,et al.A novel key-frame extraction method for semi-automatic 2D-to-3D video conversion[C].IEEE International Symposium on Broadband Multimedia Systems and Broadcasting,2012:1-5.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" GONG Y,LIU X.Video summarization using singular value decomposition[C].Proceedings of Computer Vision and Pattern Recognition,2000:174-180." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Video summarization using singular value decomposition">
                                        <b>[14]</b>
                                         GONG Y,LIU X.Video summarization using singular value decomposition[C].Proceedings of Computer Vision and Pattern Recognition,2000:174-180.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" ZHANG X D,LIU T,LO K T,et al.Dynamic selection and effective compression of key frames for video abstraction[J].Pattern Recognition Letters,2003,24(9/10):1523-1532." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300415777&amp;v=MDMyMjY0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJVjBTYnhJPU5pZk9mYks3SHRET3JJOUZZT29LQzNzK29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         ZHANG X D,LIU T,LO K T,et al.Dynamic selection and effective compression of key frames for video abstraction[J].Pattern Recognition Letters,2003,24(9/10):1523-1532.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" DIVAKARAN A,RADHAKRISHNAN R,PARKER K.Motion activity-based extraction of key-frames from video shots[C].Proceedings.International Conference on Image Processing:2002:932-935." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Motion activity-based extraction of key-frames from video shots">
                                        <b>[16]</b>
                                         DIVAKARAN A,RADHAKRISHNAN R,PARKER K.Motion activity-based extraction of key-frames from video shots[C].Proceedings.International Conference on Image Processing:2002:932-935.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" ZENG X L,HU W M,LI W Q,et al.Key-frame extraction using dominant-set clustering[C].2008 IEEE International Conference on Multimedia and Expo,2008:1285-1288." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Key-frame extraction using dominant-set clustering">
                                        <b>[17]</b>
                                         ZENG X L,HU W M,LI W Q,et al.Key-frame extraction using dominant-set clustering[C].2008 IEEE International Conference on Multimedia and Expo,2008:1285-1288.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" BORTH D,SCHULZE C,ULGES A,et al.Navidgator-similarity based browsing for image and video databases[C].Annual Conference on Artificial Intelligence,2008:22-29." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Navidgator - Similarity Based Browsing for Image and Video Databases">
                                        <b>[18]</b>
                                         BORTH D,SCHULZE C,ULGES A,et al.Navidgator-similarity based browsing for image and video databases[C].Annual Conference on Artificial Intelligence,2008:22-29.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(19),170-175 DOI:10.19651/j.cnki.emt.1902878            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于直方图计算与分析的视频关键帧选取方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=Jorge%20Michel%20D%C3%ADaz%20Rodriguez&amp;code=43369871&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Jorge Michel Díaz Rodriguez</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%9A%E5%93%81&amp;code=41060497&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姚品</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E6%97%BA%E6%A0%B9&amp;code=08537469&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万旺根</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0017580&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海大学通信与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海大学智慧城市研究院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>目前视频在教育、健康、工业等领域有着广泛的应用。这一领域的重要研究表明,视频和图像的处理仍然是一个挑战,进一步的深入研究是相当复杂的。在过去的几十年里,在这一领域的研究中,人们提出了不同的方法和应用。最常用的一种方法是通过关键帧提取技术来对视频数据进行压缩。提出了一种简单、快速、高效、复杂度低的方法,该方法利用直方图差异来实现视频关键帧。算法在读取视频、确定该视频的帧数以及通过计算两个连续帧绝对差的均值和标准差来提高这些帧之间的对比度之后,引入一种均衡化技术来计算每一帧的直方图,这样就可以计算出视频帧之间的直方图差值。之后再进行适当的阈值比较,如果连续两帧之间的直方图差值大于之前计算的阈值,那么当前帧就被选作关键帧。结果表明,该算法不仅复杂度低,而且简单有效。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E9%94%AE%E5%B8%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关键帧;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B4%E6%96%B9%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">直方图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%98%88%E5%80%BC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">阈值;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9D%87%E8%A1%A1%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">均衡化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BB%9D%E5%AF%B9%E5%B7%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">绝对差;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    Jorge Michel Díaz Rodriguez，工学硕士，主要研究方向为图像视频处理,E-mail:_DIAZ@shu.edu.cn;;
                                </span>
                                <span>
                                    姚品，工学硕士，主要研究方向为图像视频处理方向的行人再识别,E-mail:306905198@qq.com;;
                                </span>
                                <span>
                                    万旺根，教授，博士生导师，主要研究方向为计算机图形学、信号处理和数据挖掘,E-mail:wanwg@staff.shu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>上海市科委港澳台科技合作项目(18510760300)资助;</span>
                    </p>
            </div>
                    <h1><b>Histogram calculation and analysis for the selection of key frames in videos</b></h1>
                    <h2>
                    <span>Jorge Michel Díaz Rodriguez</span>
                    <span>Yao Pin</span>
                    <span>Wan Wanggen</span>
            </h2>
                    <h2>
                    <span>School of Communication and Information Engineering, Shanghai University</span>
                    <span>Institute of Smart City, Shanghai University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Currently videos have a wide range of applications, such as education, health, industry, etc. Important studies and research in this field have shown that the processing of video and image remains a challenge and continues under a deep study and research with a high degree of complexity. In the last decades, different methodologies and applications for the study and research of this field have been proposed. One of the most used methods is the extraction of the key frames to compress the video data. In the article we propose a simple method, fast, efficient and with a low degree of complexity, Histogram Difference for the selection of the key frames of a video. First, the algorithm starts with the reading of a video. Second step, the total number of frames in this video is determined. Third, calculate the value of the mean and standard deviation of the absolute difference between two consecutive frames, to improve the contrast levels of these frames, a methodology called equalization is introduced and the histogram values of each frame are calculated and successively the histogram difference frame to frame is calculated. Then an appropriate threshold value is determined and a comparison is performed, if the histogram difference between two consecutive frames is greater than the previously calculated threshold and the current frame is selected as key frame. The results show that the algorithm not only presents a low level of complexity, it is also simple and efficient.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=key%20frame&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">key frame;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=histogram&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">histogram;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=threshold&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">threshold;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=equalization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">equalization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=absolute%20difference&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">absolute difference;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-28</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="40">视频技术可以概括为5个步骤:记录、处理、存储、图像传输以及通过数字或模拟设备将一系列的图像重建为某个时刻的视频场景。这一系列图像是相机经过编辑处理产生的,也就是帧,它可以 伴有声音。视频技术首先是为了满足电视系统而开发出来的,目前已经衍生出了许多形式,能够允许消费者进行视频录制并且通过互联网观看。</p>
                </div>
                <div class="p1">
                    <p id="41">在视频数据管理系统中,视频数据结构的组织、处理和管理是重中之重。也就是说,视频是具有结构的,即视频层次结构,如图1所示。构成视频的第一层结构称为场景,一个场景就是一个逻辑事件,而这个逻辑事件又由一个或多个镜头组成。通常,视频处理的第一步是将视频分割成临时的“镜头”,这些镜头是一系列连续的图像,也就是同一时刻相互关联的帧,同时这些镜头展现了时间与空间上一系列连续的动作。在一段视频中,所有的帧大小相同,并且通常相邻两帧时间间隔1/25或1/30 s。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919028_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 视频的层次结构" src="Detail/GetImg?filename=images/DZCL201919028_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 视频的层次结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919028_042.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="43">在视频分析和处理中,提取视频中的关键帧是必不可少的。关键帧提供了索引、浏览和检索视频的框架摘要<citation id="103" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。在视频索引中,关键帧的使用减少了所需的数据量,并为管理和处理视频内容提供了最重要的帧。同时,关键帧概括了镜头的主要内容和信息。在提取这些关键帧的过程中,必须总结视频的特征,同时可以通过这些关键帧跟踪视频在时间序列中的图像特征,进而识别视频的内容。</p>
                </div>
                <div class="p1">
                    <p id="44">本文提出了一种确定关键帧、阈值和帧间直方图差值计算的方法。阈值的计算过程中,直方图差异的平均值和标准差是必需的,本文使用了均衡化函数计算绝对差,目的是增加图像的对比度。然后,将两个连续帧之间的直方图差值和阈值进行比较,如果直方图差值大于阈值,则选择当前帧作为关键帧。</p>
                </div>
                <h3 id="45" name="45" class="anchor-tag"><b>1 文献回顾</b></h3>
                <div class="p1">
                    <p id="46">Rasheed等<citation id="104" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出使用一种新关键帧,该帧由一组更小的关键帧组成,这些关键帧不是之前的关键帧,而是必须不同于所有现有的关键帧,这种方法具有简单和直观的观点,从计算和相对于视频中的所有关键帧来说,其复杂度不算高。但与此同时,关键帧表示的局部特性比全局镜头更多,对于那些需要均匀分布的应用程序来说,这种情况是不好的。因此这种算法的应用受限,帧的分布不规律会导致关键帧的数量不受限制,同时镜头中的内容有重复,这意味着在提取过程中存在重复现象。Kobla等<citation id="105" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>使用了一种简单的替代方法,但最大的缺点是每次输出只有一个帧,并且不能改变每个镜头中的时空内容。第一帧可能不包含完整的时空信息,在视频中获取帧序列时,内容序列中的后续帧可能被丢弃。Calic等<citation id="106" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了一种利用均匀采样来生成关键帧的简单方法,这是一种简便、高效的关键帧生成方法,但对于一个镜头来说基于采样的方法不能有效地生成关键帧。比如为了表示一个较长的稳定视频片段,该方法会生成多个具有相同基本内容的关键帧,因此,该方法不能有效地表示视频的真实内容。Doulamis等<citation id="107" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>采用了一种基于模糊关键帧的方法来确定关键帧,每一帧由模糊颜色和运动直方图表示,利用多路复用分辨率递归短生成树算法,提取了所有帧的特征,并对每一帧进行了分割。然后,对每个分段计算模糊颜色和运动直方图,并将其作为一个代表值存储。最后使用遗传算法,根据互相关联的条件,选择彼此不相似的每一帧。Lagendij等<citation id="108" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>也提出了一种关键帧的选择方法,该方法首先提出一个假设,在每个镜头下每个关键帧代表一个连续的区间,然后在每个区间中,对每个区间的长度进行优化,最后确定每个关键帧的位置。Furht等<citation id="109" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>使用累积差值直方图比较技术提取关键帧。累积差值是指当前帧与前一关键帧之间的相似性度量技术,用式(1)计算:</p>
                </div>
                <div class="p1">
                    <p id="47"><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>S</mi><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">[</mo></mstyle><mi>Η</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo><mo>-</mo><mi>Η</mi><msub><mrow></mrow><mrow><mi>Κ</mi><mi>F</mi></mrow></msub><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup><mo>/</mo><mi>Η</mi><mi>i</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="48">式中:<i>H</i><sub><i>KF</i></sub>(<i>j</i>)为前一关键帧累积差值直方图的第<i>j</i>个直方图通道值。在视频剪辑中,第一帧通常被设置为关键帧,接下来的帧都与第一帧进行比较。当直方图差值大于某一阈值<i>T</i>=10时,便将当前帧设置为下一个关键帧。选择第一帧作为关键帧并不是一种有效的方法,它取决于视频的前后内容,另外对每个视频都选择相同的阈值是不合适的。Zhuang等<citation id="110" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>计算视频中每帧的颜色直方图值,利用HVS颜色模型控制簇密度的方法来计算阈值。如果簇足够大,可以考虑作为关键帧。首先,需要选取关键帧,那就是,在每个簇中选取一个关键帧。该方法的局限性体现在寻找每个簇的中心时,在提取参数的限制下,不能实现所有帧都被覆盖在一个簇中。Wolf等<citation id="111" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>计算每帧光流的有效运动,并且使用简单的测量来推导沿着序列的光学流动的变化,其中度量函数是时间的函数,在其局部极小值的地方可以得到关键帧。Mukhargee等<citation id="112" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>为了估计视频的关键帧,提出了一种随机代表帧模型。该模型基于Har波,提取各帧在空间上的特征,并计算了超过3×3网格大小的图像的强度和占用率。同时对于Har波,估算了在不同分辨率下的空间频率点和帧间随机性,之后选取高随机帧作为关键帧。Liu等<citation id="113" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了一种提取关键帧的新方法,利用相关三角运动的函数对人体动作进行识别,然后在每个动作序列中使用Ada-Boost学习算法对关键帧进行选择。Wang等<citation id="114" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>对视频序列中的累积遮挡曲线进行了分析,采用了一种连续两帧之间的立体对应算法来检测遮挡,该方法首先计算一个镜头中关键帧的个数,然后计算深度传播误差来定位这些关键帧在两个连续关键帧之间的均匀累积遮挡曲线中的位置。Gong等<citation id="115" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出了一种基于奇异值分解的视频帧提取的有效方法,使用了RGB颜色空间的颜色直方图,为了整合空间信息,将每一帧划分为3×3网格块,在每个块中创建一个三维直方图,这九个直方图连接在一起形成一个特征向量,将这些向量和最靠近组中心的帧作为每组的关键帧进行分析。Zhang等<citation id="116" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出了一种动态提取关键帧的方法。首先,视频被分割成几个镜头,使用 “动态选择技术”在每个镜头中选择关键帧;然后,为了改进这些帧的选择,将基于运动的分组算法应用于同一镜头中,因为从运动补偿误差意义上说,它们具有相似性。Diwakaran等<citation id="117" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出了一种基于判断视频中是否存在高速运动来提取关键帧的方法,这意味着需要更多的关键帧。首先,将视频分成一个个含有运动活动的相等片段,然后确定每个片段的中点。将处于中间位置的帧视为关键帧,这些关键帧还建立了该段关键帧数量与该段运动活动之间的关系。Zeng等<citation id="118" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>采用主导集聚类技术来提取关键帧,该方法克隆是提取视频关键帧最常用的前提条件之一,与现有的聚类方法相比,该方法在分割视频中应用关键帧的动态决策来提取这些关键帧时,复杂度比较低。该方法工作循序渐进,计算量小。Borth等<citation id="119" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出了一种基于检测活跃极限的视频分割方法,用于提取关键帧,它利用<i>k</i>均值分组方法获取视频分段内的关键帧,在提取的关键帧中分了更多的组,以提供更好的视频结构。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag"><b>2 实验方法</b></h3>
                <div class="p1">
                    <p id="50">本文提出了一种基于计算连续两帧间直方图差值并利用阈值来确定关键帧的算法。</p>
                </div>
                <div class="p1">
                    <p id="51">图像直方图:图像直方图是一个表示与像素数量相关的展示颜色强度分布的图形化函数,如图2(b)和(d)所示。图像直方图是图像处理中一项应用广、实用强的可视化技术。可以通过分析图像中色彩、灰度和对比度的分布所表示的直方图中的值来确定处理图像的最合适方法。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919028_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 图像直方图" src="Detail/GetImg?filename=images/DZCL201919028_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 图像直方图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919028_052.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="53"><i>x</i>轴上标出灰度的强度,每个强度的出现次数在<i>y</i>轴上表示。直方图中每个灰度级的出现频率总是以相对值的形式表示,因为绝对值可能会随着图像的大小而有所不同。直方图具有如下所示的一系列特性:</p>
                </div>
                <div class="p1">
                    <p id="54">1)图像<i>f</i>不能从<i>h</i><sub><i>f</i></sub>推导出来;</p>
                </div>
                <div class="p1">
                    <p id="55">2)两个不同的图像可以有相同的直方图值。</p>
                </div>
                <div class="p1">
                    <p id="56">3)图像的直方图不包含它的空间信息。</p>
                </div>
                <div class="p1">
                    <p id="57">图像均衡化:这是目前图像处理中使用的一种方法,在调整对比度值的基础上,将每一灰度级对应像素个数实现均匀分布。MATLAB提供了3种不同类型的均衡函数,用户可以根据不同需要使用。他们的基本规则相同,但各有相互区别的特点,分别如下:</p>
                </div>
                <div class="p1">
                    <p id="58">1)histeq:该函数用来提高图像对比度,将值转换为强度图像,使输出图像与特定图像的直方图大致匹配。</p>
                </div>
                <div class="p1">
                    <p id="59">2)imadjust:该函数通过为输入值分配新的图像强度值来增加图像的对比度,使1%的数据在输入数据的高强度和低强度处饱和。</p>
                </div>
                <div class="p1">
                    <p id="60">3)adapthisteq:该函数在有限对比度下实现直方图自适应均衡。与histeq不同,它不是处理整个图像,而是处理小块数据区域(马赛克)。在每个输出区域,提高每个马赛克区的对比度,使输出图像的直方图与特定图像的直方图大致匹配从而避免出现放大现象。可以用来解决在图像中因为噪声的存在,对比度的值往往受限的问题。</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag"><b>3 本文算法</b></h3>
                <div class="p1">
                    <p id="62">本方算法的流程如图3所示,并且在MATLAB中实现。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63"><b>3.1 算法步骤简述</b></h4>
                <div class="p1">
                    <p id="64">1)输入一个文件类型的视频;</p>
                </div>
                <div class="p1">
                    <p id="65">2)提取视频中所有的帧;</p>
                </div>
                <div class="p1">
                    <p id="66">3)初始化从第一帧到最后一帧的循环;</p>
                </div>
                <div class="p1">
                    <p id="67">4)选择当前帧;</p>
                </div>
                <div class="p1">
                    <p id="68">5)选择下一帧;</p>
                </div>
                <div class="p1">
                    <p id="69">6)通过函数计算当前帧和下一帧之间的直方图差值(<i>Hist</i>_<i>Diff</i>);</p>
                </div>
                <div class="p1">
                    <p id="70">7)计算直方图差值的均值和标准差;</p>
                </div>
                <div class="p1">
                    <p id="71">8)设定一个阈值<i>T</i>,<i>T</i>=<i>μ</i>+<i>ασ</i>:<i>μ</i>和<i>σ</i>分别表示平均值和标准偏差, <i>α</i>的值通常较小。</p>
                </div>
                <div class="p1">
                    <p id="72">9)重复步骤3)～6);</p>
                </div>
                <div class="p1">
                    <p id="73">10)比较直方图插值是否大于阈值;</p>
                </div>
                <div class="p1">
                    <p id="74">11)选择满足步骤10)条件的当前帧作为关键帧。</p>
                </div>
                <div class="p1">
                    <p id="75">步骤6)直方图差值函数实现步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="76">1)将当前帧和下一帧转换为灰度值;</p>
                </div>
                <div class="p1">
                    <p id="77">2)均衡化当前帧和下一帧;</p>
                </div>
                <div class="p1">
                    <p id="78">3)计算当前帧和下一帧的直方图;</p>
                </div>
                <div class="p1">
                    <p id="79">4)计算当前帧和下一帧的直方图差值(<i>Hist</i>_<i>Diff</i>);</p>
                </div>
                <h4 class="anchor-tag" id="80" name="80"><b>3.2 流程图</b></h4>
                <div class="p1">
                    <p id="81">流程图是一种图形表示,用来展示程序的实现流程,方便理解算法。为了实现流程图,本文使用一系列基本符号,表示代码中的特定操作,如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="82">一个关键因素是为关键帧确定一个合适的阈值。函数实现是分别计算均值和标准差,然后选择一个适当的<i>α</i>值,一般取值介于3～5,本文使用尽可能低的值,之后确定阈值。最后比较直方图差值和阈值,如果绝对差的值大于阈值,就选择当前帧作为关键帧。流程中涉及的图像均衡化步骤是为了提高图像对比度,便于后续处理。</p>
                </div>
                <div class="area_img" id="83">
                                            <p class="img_tit">
                                                <b>表1 用于表示程序流程的图形</b>
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919028_08300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/DZCL201919028_08300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919028_08300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 用于表示程序流程的图形" src="Detail/GetImg?filename=images/DZCL201919028_08300.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h3 id="85" name="85" class="anchor-tag"><b>4 实验与结果</b></h3>
                <div class="p1">
                    <p id="86">本文选择不同类型的视频扩展来做实验,分析算法的优劣。该算法在MATLAB中实现,MATLAB的版本为R2017b。</p>
                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>4.1 实验环境</b></h4>
                <div class="p1">
                    <p id="88">电脑配置:华硕ZX70 V,酷睿i7第六代,16 GB内存,128 GB固态硬盘,1 TB硬盘,英特尔530外加英伟达GTX 960 M 显卡。</p>
                </div>
                <h4 class="anchor-tag" id="89" name="89"><b>4.2 均衡化和实验结果</b></h4>
                <div class="p1">
                    <p id="90">本文所用均衡方法是通过初步实验来选择。首先,将所有帧转化为灰度图,然后分别使用2.1节所述3种直方图均衡化函数处理图像,通过对比选择最优方法,结果如图4所示。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919028_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 算法流程" src="Detail/GetImg?filename=images/DZCL201919028_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919028_09200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919028_09201.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 算法流程" src="Detail/GetImg?filename=images/DZCL201919028_09201.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919028_09201.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919028_094.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 图像的均衡方法" src="Detail/GetImg?filename=images/DZCL201919028_094.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 图像的均衡方法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919028_094.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="95">通过在每个视频的不同帧进行测试,发现均衡后的结果是相同的。但从图4中可见,图4(a)和(b)得到的图像其对比度并不合适,而图4(c)得到了更清晰的图像,提高了每个像素的强度等级。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>4.3 关键帧选择和实验结果</b></h4>
                <div class="p1">
                    <p id="97">图5所示为本文算法得到的关键帧,实验结果如表2所示,可以看到算法在不同视频中的结果。在所有情况下,本文的算法有效性都超过90%,平均为93.33%。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919028_098.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 本文算法得到的关键帧" src="Detail/GetImg?filename=images/DZCL201919028_098.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 本文算法得到的关键帧  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919028_098.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="99">
                    <p class="img_tit"><b>表2 本文方法处理不同视频的实验结果汇总</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td>序号</td><td>描述</td><td>格式</td><td>分辨率</td><td>帧速</td><td>视频<br />时长</td><td>总帧数</td><td>关键帧</td><td>完成时间<br />(min:s)</td><td>关键<br />帧数/%</td><td>效率/<br />%</td></tr><tr><td><br />1</td><td>动作片(变形金刚3)</td><td>AVI</td><td>640x360</td><td>25</td><td>02:26</td><td>3504</td><td>344</td><td>5:35/6:00</td><td>10</td><td>90</td></tr><tr><td><br />2</td><td>动漫(Rio)</td><td>MP4</td><td>640x272</td><td>25</td><td>00:33</td><td>826</td><td>22</td><td>0:57/1:02</td><td>3</td><td>97</td></tr><tr><td><br />3</td><td>MV(Black or White)</td><td>MKV</td><td>352x288</td><td>25</td><td>01:00</td><td>1499</td><td>129</td><td>2:35/2:50</td><td>9</td><td>91</td></tr><tr><td><br />4</td><td>MV(Listen To Your Heart)</td><td>MPG or MPEG</td><td>352x288</td><td>25</td><td>04:15</td><td>7542</td><td>470</td><td>10:20/11:35</td><td>6</td><td>94</td></tr><tr><td><br />5</td><td>足球赛</td><td>MOV</td><td>320x240</td><td>30</td><td>01:08</td><td>2038</td><td>95</td><td>3:50/4:20</td><td>5</td><td>95</td></tr><tr><td><br />6</td><td>电视剧(权力的游戏)</td><td>WMV</td><td>640x360</td><td>30</td><td>01:42</td><td>2446</td><td>119</td><td>8:20/8:50</td><td>5</td><td>95</td></tr><tr><td><br />7</td><td>搞笑视频</td><td>FLV</td><td>320x176</td><td>25</td><td>00:30</td><td>749</td><td>39</td><td>0:50/1:01</td><td>5</td><td>95</td></tr><tr><td><br />8</td><td>教学视频</td><td>WEBM</td><td>640x360</td><td>25</td><td>04:52</td><td>7249</td><td>583</td><td>11:00/11:25</td><td>8</td><td>92</td></tr><tr><td><br />9</td><td>MV(If feels so good)</td><td>3GP</td><td>176x144</td><td>25</td><td>00:33</td><td>495</td><td>49</td><td>0.15/0.22</td><td>9</td><td>91</td></tr><tr><td><br />平均值</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>6.67</td><td>93.33</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="100" name="100" class="anchor-tag"><b>5 结  论</b></h3>
                <div class="p1">
                    <p id="101">本文提出了一种视频关键帧的提取方法,通过计算直方图的差值,来确定合适的阈值用于视频帧比较。但是本文的方法还有改进的空间,后续希望能够实现一种镜头检测的视频算法来对现有算法进行改进。目前,关键帧提取算法对关键帧的选取各有不同,比如有些方法引入具有一定复杂性的算法进行改进,但最终都实现需求,并且效果不错。然而,本文算法使用直方图计算关键帧的难度较低,是一种比较优秀的算法。该算法通过计算视频中连续帧的绝对差,复杂度较低。最终的实验结果体现了本文算法的有效性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Video shot detection and condensed representation. a review">

                                <b>[1]</b> COTSACES C,NIKOLAIDIS N,PITAS I.Video shot detection and condensed representation.a review[J].IEEE Signal Processing Magazine,2006,23(2):28-37.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multimedia information retrieval and management:Technological Fundamentals and Applications">

                                <b>[2]</b> FENG D,SIU W,ZHANG H.Multimedia information retrieval and management:Technological Fundamentals and Applications[M].Springer,2003.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scene detection in hollywood movies and TV shows">

                                <b>[3]</b> RASHEED Z,SHAH M.Scene detection in Hollywood movies and TV shows[C].Proceedings of the IEEE Computer Vision and Pattern Recognition Conference Madison,2003:343-348.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Archiving,indexing and retrieval of video in the compressed domain">

                                <b>[4]</b> KOBLA V,DOERMANN D,LIN K I.Archiving,indexing and retrieval of video in the compressed domain[C].Proceeding of SPIE Conference,1996,78-89.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial analysis in key-frame extraction using video segmentation">

                                <b>[5]</b> CALIC J,THOMAS B T.Spatial analysis in key-frame extraction using video segmentation[C].Proceedings of Workshop on Image Analysis for Multimedia Interactive Services,2004.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300652443&amp;v=MjMwODVIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJVjBTYnhJPU5pZk9mYks3SHRET3JJOUZZdTROQ0hnNm9CTVQ2VDRQUQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> DOULAMIS A D,DOULAMIS N D,KOLLIAS S D.A fuzzy video content representation for video summarization and content based retrieval[J].Journal of Signal Processing,2000,80(6):1049-1060.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visual search in a SMASH system">

                                <b>[7]</b> LAGENDIJ R L,HANJALIC A,CECCARELLI M,et al.Visual search in a SMASH system[C].Proceedings of IEEE ICIP,1996:671-674.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A fast content-based multimedia retrieval technique using compressed data">

                                <b>[8]</b> FURHT B,SAKSOBHAVIVAT P.A fast content-based multimedia retrieval technique using compressed data [C].Proceedings of SPIE’94 Symposium on Image and Video Processing,1998:142-149.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive key frame extraction using unsupervised clustering">

                                <b>[9]</b> ZHUANG Y,RUI Y,HUANG T S,et al.Adaptive key frame extraction using unsupervised clustering[C].Proceedings of IEEE Conference,1998:866-870.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Key Frame selection,by motion analysis">

                                <b>[10]</b> WOLF W.Key frame selection by motion analysis[C].Proceedings of the Acoustics,Speech,and Signal Processing,2002:1228-1231.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Key frame estimation in video using randomness measure of feature point pattern">

                                <b>[11]</b> MUKHARGEE D P,DAS S K,SAHA S.Key frame estimation in video using randomness measure of feature point pattern[J].IEEE Transactions on Circuits and Systems for Video Technology,2007,17(5):612-620.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600739923&amp;v=MDUzODkrZ0dCWDQ2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSVYwU2J4ST1OaWZPZmJLN0h0RE5xWTlGWQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> LIU L,SHAO L,ROCKETT P.Boosted key-frame selection and correlated pyramidal motion-feature representation for human action recognition [J].Pattern Recognition,2013,46(7):1810-1818.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel key-frame extraction method for semi-automatic 2D-to-3D video conversion">

                                <b>[13]</b> WANG D,LIU J,SUN J,et al.A novel key-frame extraction method for semi-automatic 2D-to-3D video conversion[C].IEEE International Symposium on Broadband Multimedia Systems and Broadcasting,2012:1-5.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Video summarization using singular value decomposition">

                                <b>[14]</b> GONG Y,LIU X.Video summarization using singular value decomposition[C].Proceedings of Computer Vision and Pattern Recognition,2000:174-180.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300415777&amp;v=MjA5NDdPZmJLN0h0RE9ySTlGWU9vS0MzcytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJVjBTYnhJPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> ZHANG X D,LIU T,LO K T,et al.Dynamic selection and effective compression of key frames for video abstraction[J].Pattern Recognition Letters,2003,24(9/10):1523-1532.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Motion activity-based extraction of key-frames from video shots">

                                <b>[16]</b> DIVAKARAN A,RADHAKRISHNAN R,PARKER K.Motion activity-based extraction of key-frames from video shots[C].Proceedings.International Conference on Image Processing:2002:932-935.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Key-frame extraction using dominant-set clustering">

                                <b>[17]</b> ZENG X L,HU W M,LI W Q,et al.Key-frame extraction using dominant-set clustering[C].2008 IEEE International Conference on Multimedia and Expo,2008:1285-1288.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Navidgator - Similarity Based Browsing for Image and Video Databases">

                                <b>[18]</b> BORTH D,SCHULZE C,ULGES A,et al.Navidgator-similarity based browsing for image and video databases[C].Annual Conference on Artificial Intelligence,2008:22-29.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201919028" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201919028&amp;v=MDg1OTZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5tVmJySklUZklZckc0SDlqTnBvOUg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

