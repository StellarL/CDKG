

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135823597756250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201911011%26RESULT%3d1%26SIGN%3dANWMVZoHU7mTtA987AmtyWDiwRg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201911011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201911011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201911011&amp;v=MDQxODl1WnRGeTdsVzd6S0lUZklZckc0SDlqTnJvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#36" data-title="&lt;b&gt;1 TE过程简介&lt;/b&gt; "><b>1 TE过程简介</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#44" data-title="&lt;b&gt;2 深度自编码网络&lt;/b&gt; "><b>2 深度自编码网络</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="&lt;b&gt;2.1 预训练&lt;/b&gt;"><b>2.1 预训练</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;2.2 微调 (调优&lt;/b&gt;) "><b>2.2 微调 (调优</b>) </a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;3 基于稀疏理论改进DAEN&lt;/b&gt; "><b>3 基于稀疏理论改进DAEN</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;4 深度自编码网络诊断模型&lt;/b&gt; "><b>4 深度自编码网络诊断模型</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="&lt;b&gt;5 改进的DAEN在TE过程故障诊断中的仿真实验研究&lt;/b&gt; "><b>5 改进的DAEN在TE过程故障诊断中的仿真实验研究</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#96" data-title="&lt;b&gt;5.1 AE层数的确定&lt;/b&gt;"><b>5.1 AE层数的确定</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;5.2 分类器的确定&lt;/b&gt;"><b>5.2 分类器的确定</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;5.3 基于改进DAEN的仿真研究&lt;/b&gt;"><b>5.3 基于改进DAEN的仿真研究</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;6 结  论&lt;/b&gt; "><b>6 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="图1 AE基本结构">图1 AE基本结构</a></li>
                                                <li><a href="#87" data-title="图2 深度自编码网络诊断模型">图2 深度自编码网络诊断模型</a></li>
                                                <li><a href="#98" data-title="图3 不同AE层数时的故障诊断结果">图3 不同AE层数时的故障诊断结果</a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;表1 不同训练集时, DAEN结合三种不同分类器的故障诊断结果&lt;/b&gt;"><b>表1 不同训练集时, DAEN结合三种不同分类器的故障诊断结果</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;表2 基于改进的DAEN、DAEN、BPNN的故障诊断结果&lt;/b&gt;"><b>表2 基于改进的DAEN、DAEN、BPNN的故障诊断结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="129">


                                    <a id="bibliography_1" title=" 任浩, 屈剑锋, 柴毅, 等.深度学习在故障诊断领域中的研究现状与挑战[J].控制与决策, 2017, 32 (8) :1345-1358." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201708001&amp;v=MTcyODBMamZTYmJHNEg5Yk1wNDlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk3bFc3eks=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         任浩, 屈剑锋, 柴毅, 等.深度学习在故障诊断领域中的研究现状与挑战[J].控制与决策, 2017, 32 (8) :1345-1358.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_2" title=" YIN S, GAO X, KARIMI HR, et al.Study on support vector machine-based fault detection in Tennessee Eastman process[J].Abstract &amp;amp; Applied Analysis, 2014 (2) :1-8." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD14051200000053&amp;v=MTg3ODByWTlGWk9zUERIazZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklKbDRjYVJBPU5pZkRhcks4SHRUTg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         YIN S, GAO X, KARIMI HR, et al.Study on support vector machine-based fault detection in Tennessee Eastman process[J].Abstract &amp;amp; Applied Analysis, 2014 (2) :1-8.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_3" title=" SHEN Y, DING S X, HAGHANI A, et al.A comparison study of basic data-driven fault diagnosis and process monitoring methods on the benchmark Tennessee Eastman Process[J].Journal of Process Control, 2012, 22 (9) :1567-1581." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501617570&amp;v=MzExNDhmYks3SHRETnFvOUVZdW9JQ1hzNW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUpsNGNhUkE9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         SHEN Y, DING S X, HAGHANI A, et al.A comparison study of basic data-driven fault diagnosis and process monitoring methods on the benchmark Tennessee Eastman Process[J].Journal of Process Control, 2012, 22 (9) :1567-1581.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_4" title=" 胡昭华, 宋耀良.基于Autoencoder网络的数据降维和重构[J].电子与信息学报, 2009, 31 (5) :1189-1192." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX200905041&amp;v=MDEwMjVyRzRIdGpNcW85QlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N2xXN3pLSVRmU2Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         胡昭华, 宋耀良.基于Autoencoder网络的数据降维和重构[J].电子与信息学报, 2009, 31 (5) :1189-1192.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_5" title=" RIFAI S, VINCENT P, MULLER X, et al.Contractive auto-encoders:explicit invariance during feature extraction[C].Proceedings of the 28th International Conference on Machine Learning, 2011:833-840." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contractive auto-encoders:Explicit invariance during feature extraction">
                                        <b>[5]</b>
                                         RIFAI S, VINCENT P, MULLER X, et al.Contractive auto-encoders:explicit invariance during feature extraction[C].Proceedings of the 28th International Conference on Machine Learning, 2011:833-840.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_6" title=" 石鑫, 朱永利, 宁晓光, 等.基于深度自编码网络的电力变压器故障诊断[J].电力自动化设备, 2016, 36 (5) :122-126." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLZS201605021&amp;v=MTIzODVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTdsVzd6S0lTSFJmYkc0SDlmTXFvOUhaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         石鑫, 朱永利, 宁晓光, 等.基于深度自编码网络的电力变压器故障诊断[J].电力自动化设备, 2016, 36 (5) :122-126.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_7" title=" THIRUKOVALLURU R, DIXIT S, SEVAKULA R K.Generating feature sets for fault diagnosis using denoising stacked auto-encoder[C].Proceedings of IEEE Conference on Prognostics and Health Management, 2016 (72) :303-315." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generating feature sets for fault diagnosis using denoising stacked auto-encoder">
                                        <b>[7]</b>
                                         THIRUKOVALLURU R, DIXIT S, SEVAKULA R K.Generating feature sets for fault diagnosis using denoising stacked auto-encoder[C].Proceedings of IEEE Conference on Prognostics and Health Management, 2016 (72) :303-315.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_8" title=" DENG J, ZHANG Z X, ERIK M, et al.Sparse auto-encoder based feature transfer learning for speech emotion recognition[C].Humaine Association Conference on Affective Computing and Intelligent Interaction, 2013:511-516." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse Autoencoder-based Feature Transfer Learning for Speech Emotion Recognition">
                                        <b>[8]</b>
                                         DENG J, ZHANG Z X, ERIK M, et al.Sparse auto-encoder based feature transfer learning for speech emotion recognition[C].Humaine Association Conference on Affective Computing and Intelligent Interaction, 2013:511-516.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_9" title=" 雒玉玺.稀疏自动编码器及其加速算法的研究[D].兰州:兰州大学, 2014." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014302217.nh&amp;v=MTI2OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N2xXN3pLVkYyNkdyQzRITlBOcUpFYlBJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         雒玉玺.稀疏自动编码器及其加速算法的研究[D].兰州:兰州大学, 2014.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_10" title=" LUO X X, LI W.A novel efficient method for training sparse auto-encoders[C].6th International Congress on Image and Signal Processing, 2013:1019-1023." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel efficient method for training sparse auto-encoders">
                                        <b>[10]</b>
                                         LUO X X, LI W.A novel efficient method for training sparse auto-encoders[C].6th International Congress on Image and Signal Processing, 2013:1019-1023.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_11" title=" VINCENT P, LAROCHELLE H, BENGIO Y, et al.Extracting and composing robust features with denoising autoencoders[C].Proceedings of the 25th International Conference on Machine Learning, 2008:1096-1103." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Extracting and composing robust features with denoising autoencoders">
                                        <b>[11]</b>
                                         VINCENT P, LAROCHELLE H, BENGIO Y, et al.Extracting and composing robust features with denoising autoencoders[C].Proceedings of the 25th International Conference on Machine Learning, 2008:1096-1103.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_12" title=" ALAIN G, BENGIO Y.What regularized auto-encoders learn from the data-generating distribution[J].The Journal of Machine Learning Research, 2014, 15 (1) :3563-3593." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=What regularized auto-encoders learn from the data-generating distribution?">
                                        <b>[12]</b>
                                         ALAIN G, BENGIO Y.What regularized auto-encoders learn from the data-generating distribution[J].The Journal of Machine Learning Research, 2014, 15 (1) :3563-3593.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_13" title=" 赵文清, 朱永利, 张小奇.应用支持向量机的变压器故障组合预测[J].中国电机工程学报, 2008, 28 (25) :14-19." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGDC200825005&amp;v=MDg2MzBadEZ5N2xXN3pLUHlyUGJiRzRIdG5PcW85RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         赵文清, 朱永利, 张小奇.应用支持向量机的变压器故障组合预测[J].中国电机工程学报, 2008, 28 (25) :14-19.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_14" title=" MINMIN C, KILLAN Q W, ZHIXIANG X.Marginalized denoising auto-encoders for domain adaptation[C].Proc.of the 29th International Conference on Machine Learning, 2012:538-542." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Marginalized denoising auto-encoders for domain adaptation">
                                        <b>[14]</b>
                                         MINMIN C, KILLAN Q W, ZHIXIANG X.Marginalized denoising auto-encoders for domain adaptation[C].Proc.of the 29th International Conference on Machine Learning, 2012:538-542.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_15" title=" 刘梦溪, 王征, 宋久旭, 等.基于稀疏深度置信网络的图像分类识别研究[J].微电子学与计算机, 2018, 35 (9) :59-63." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201809013&amp;v=MDg3MjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTdsVzd6S01qWFNaTEc0SDluTXBvOUVaNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         刘梦溪, 王征, 宋久旭, 等.基于稀疏深度置信网络的图像分类识别研究[J].微电子学与计算机, 2018, 35 (9) :59-63.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(11),56-60 DOI:10.19651/j.cnki.emt.1802489            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于改进的DAEN在TE过程故障诊断中的应用研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E8%BF%9C%E7%BB%AA&amp;code=40657647&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张远绪</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E6%8D%A2%E6%96%B0&amp;code=23396858&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程换新</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%9D%92%E5%B2%9B%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B8%8E%E7%94%B5%E5%AD%90%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0229824&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">青岛科技大学自动化与电子工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现代化工生产过程中故障情况十分复杂, 具有非线性、多种类、少标签问题, 传统方法很难建立准确的诊断模型。基于深度自编码网络 (DAEN) , 提出了一种新型智能故障诊断方法, 并且添加Softmax分类器, 构建了深度自编码网络诊断模型。该模型采取稀疏理论进行了改进, 解决故障数据少, 与正常数据不平衡问题。并且所提方法采取大量无标签样本作为训练集, 进行预训练, 优化模型参数, 并以少量有标签样本作为测试集, 进行微调。通过田纳西-伊斯曼 (TE) 过程仿真数据实验结果表明, 相比较支持向量机 (SVM) 、K最近邻 (KNN) 等学习方法, DAEN与Softmax回归结合, 得到更高的故障诊断正确率;而相比传统的DAEN诊断方法、以及基于反向传播神经网络 (BPNN) 的传统机器学习故障诊断方法, 本文改进的DAEN诊断方法诊断精度得到明显提高。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度自编码网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E7%90%86%E8%AE%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏理论;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">反向传播神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=K%E6%9C%80%E8%BF%91%E9%82%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">K最近邻;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Softmax%E5%88%86%E7%B1%BB%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Softmax分类器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%B0%E7%BA%B3%E8%A5%BF-%E4%BC%8A%E6%96%AF%E6%9B%BC%E8%BF%87%E7%A8%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">田纳西-伊斯曼过程;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%85%E9%9A%9C%E8%AF%8A%E6%96%AD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">故障诊断;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张远绪, 硕士研究生, 研究方向为智能控制理论及应用。E-mail:1120200696@qq.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12</p>

            </div>
                    <h1><b>Application of improved DAEN in fault diagnosis of TE process</b></h1>
                    <h2>
                    <span>Zhang Yuanxu</span>
                    <span>Cheng Huanxin</span>
            </h2>
                    <h2>
                    <span>College of Automation and Electronic Engineering, Qingdao University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The fault situation in the modern chemical production process is very complex, with the problems of nonlinear, multi-type and less labeling. It is difficult for traditional methods to establish accurate diagnosis models. Based on deep auto-encoder network (DAEN) , this paper proposes a new intelligent fault diagnosis method and constructs a deep auto-encoder network diagnosis model by adding Softmax classifier. The model is improved by sparse theory to solve the imbalance problem of less fault data and and more normal data. In addition, the proposed method takes a large number of unlabeled samples as the training set, performs pre-training, optimizes model parameters, and takes a small number of labeled samples as the test set for fine tuning. The experimental results of TE simulation data show that the DAEN combined with Softmax classifier can get higher accuracy of fault diagnosis than other learning methods such as support vector machine (SVM) and K-nearest neighbor (KNN) . Compared with the traditional DAEN diagnosis method and the traditional machine learning fault diagnosis method based on back propagation neural network (BPNN) , the diagnosis accuracy of the improved DAEN diagnosis method in this paper is obviously improved.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20auto-encoder%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep auto-encoder network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20theory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse theory;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=back%20propagation%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">back propagation neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=support%20vector%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">support vector machine;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=K-nearest%20neighbor&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">K-nearest neighbor;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Softmax%20classifier&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Softmax classifier;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Tennessee-Eastman%20process&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Tennessee-Eastman process;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=fault%20diagnosis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">fault diagnosis;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12</p>
                            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="34">化工生产过程是一个连续生产的工艺过程。作为国民经济重要的组成部分, 过程工业的重要性以及潜在的危险性, 越来越受到人们的重点关注。在化工生产过程中, 一旦发生故障导致生产中断而又不能及时排除时, 不仅对化工生产影响严重, 而且人身安全也存在严重的隐患。因此, 如何准确及时地诊断故障类型并做出修整显得尤为重要。但是, 在复杂的化工生产过程中, 建立一个准确完整的故障诊断模型并不容易。因此, 对化工过程中故障诊断方法的研究, 是一个具有重要现实意义的课题。</p>
                </div>
                <div class="p1">
                    <p id="35">目前, 发展较为成熟的故障诊断方法主要有人工神经网络 (artificial neural networks, ANN) 以及支持向量机 (support vector machine, SVM) 。而深度自编码网络 (deep auto-encodel network, DAEN) 是深度学习方法的一种, 它通过构建具有多隐含层的神经网络模型对训练样本进行逐层贪婪学习, 来获取一个新特征空间的表达, 从而更加方便、更加准确地进行分类。对比人工提取构造特征的方法, 该方法具有强大的海量数据处理能力<citation id="159" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 解决复杂的强非线性问题更具高效性, 在目前国际上机器学习研究中成为热门的领域, 但尚未见其应用于化工生产过程故障诊断方面。鉴于此, 本文提出了一种基于深度自编码网络 (DAEN) 的新型智能故障诊断方法, 所提模型结合Softmax分类器, 采取大量无标签样本作为训练集, 进行预训练, 优化模型参数, 并以少量有标签样本作为测试集, 进行微调, 有效提高故障诊断准确率。然后, 通过实验对SVM、KNN, Softmax分类器进行了验证分析。并且采取稀疏理论改进DAEN诊断方法, 解决故障数据稀疏性问题, 最终与传统DAEN以及传统机器学习BPNN的故障诊断方法进行了实验对比分析。</p>
                </div>
                <h3 id="36" name="36" class="anchor-tag"><b>1 TE过程简介</b></h3>
                <div class="p1">
                    <p id="37">本文化工过程的故障诊断以TE过程为研究对象。TE 过程, 全称田纳西-伊夫曼过程<citation id="160" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 是根据真实的化工流程、实现评估过程控制以及监测方法的工业过程仿真。其动态模型共有 30 个微分方程, 148个代数方程。系统具有高度非线性、分布参数和强耦合特性, 非常不稳定, 是当前控制领域中少数具有挑战性的问题之一。</p>
                </div>
                <div class="p1">
                    <p id="38">五部分组成了TE 过程:反应器、压缩机、冷凝器、汽/液分离器和汽提塔<citation id="161" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。共有8种物料:A, B, C, D, E, F, G和H。各反应如下:</p>
                </div>
                <div class="p1">
                    <p id="39">A (g) +C (g) +D (g) →G (liq) , 产品1</p>
                </div>
                <div class="p1">
                    <p id="40">A (g) +C (g) +E (g) →H (liq) , 产品2</p>
                </div>
                <div class="p1">
                    <p id="41">A (g) +E (g) →F (liq) , 副产品</p>
                </div>
                <div class="p1">
                    <p id="42">3D (g) →2F (liq) , 副产品</p>
                </div>
                <div class="p1">
                    <p id="43">TE过程模型中预设了21种过程故障, 记为IDV (1) -IDV (21) 。其中, 故障号IDV (1) -IDV (15) 和IDV (21) 是16种已知故障, IDV (16) -IDV (20) 是5种未知故障。更进一步, IDV (1) -IDV (7) 等7种故障的类型是变量的阶跃变化;IDV (8) -IDV (12) 等5种故障的类型是随机变量;IDV (13) 的类型是慢漂移;剩余的3个故障IDV (14) , IDV (15) 与IDV (21) 均为阀门问题。</p>
                </div>
                <h3 id="44" name="44" class="anchor-tag"><b>2 深度自编码网络</b></h3>
                <div class="p1">
                    <p id="45">深度自编码网络的基本结构是由多个自编码器AE (Auto-Encoder) 堆叠而成<citation id="162" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 它与传统多层神经网络的结构相似, 训练时采用逐层贪心的方式, 即每一个隐含层处理得到的输出作为下一层的输入, 这样依次往下进行训练, 因此传统神经网络训练方法存在不适用于多层网络训练的问题得到有效解决, 整个深度自编码网络的训练包括两个阶段:预训练和微调。</p>
                </div>
                <h4 class="anchor-tag" id="46" name="46"><b>2.1 预训练</b></h4>
                <div class="p1">
                    <p id="47">预训练的过程实质上就是获取网络较优初始参数的过程, 采用逐层非监督特征优化算法, 优化每个自编码器与下个自编码其之间的连接权值及偏置值<citation id="163" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。自编码器AE基本网络结构如图1所示。</p>
                </div>
                <div class="area_img" id="48">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911011_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 AE基本结构" src="Detail/GetImg?filename=images/DZCL201911011_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 AE基本结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911011_048.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="49">1个基本的自编码器AE包括输入层、隐含层和输出层。AE包括编码和解码:编码过程是从输入层到隐含层, 即编码器是从输入向量x通过激活函数<i>S</i><sub><i>f</i></sub>到隐含层特征表达式<i>h</i>的映射, 如式 (1) ;解码过程是从隐含层到输出层, 即解码器是从隐含层数据通过映射函数<i>S</i><sub><i>g</i></sub>到重构的输出向量y的映射, 如式 (2) ;</p>
                </div>
                <div class="p1">
                    <p id="50"><i>h</i>=<i>f</i> (<i>x</i>) =<i>S</i><sub><i>f</i></sub> (<i>Wx</i>+<i>p</i>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo>=</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>h</mi><mo stretchy="false">) </mo><mo>=</mo><mi>S</mi><msub><mrow></mrow><mi>g</mi></msub><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>W</mi></mstyle><mo>∼</mo></mover><mi>h</mi><mo>+</mo><mi>q</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">式中:<i>S</i><sub><i>f</i></sub>和<i>S</i><sub><i>g</i></sub>通常采用sigmoid函数;<i>W</i>、<mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>W</mi></mstyle><mo>∼</mo></mover></mrow></math></mathml>分别为输入层与隐含层及隐含层与输出层之间的权值矩阵;<i>p</i>和<i>q</i>分别表示隐含层和输出层上的偏置向量。将AE的参数记为<i>θ</i>={<i>W</i>, <i>p</i>, <i>q</i>}。</p>
                </div>
                <div class="p1">
                    <p id="54">AE的预训练过程就是利用训练样本集<i>S</i>={<i>x</i><sup> (1) </sup>, <i>x</i><sup> (2) </sup>, …, <i>x</i><sup> (<i>N</i>) </sup>}对参数<i>θ</i>进行训练的过程<citation id="164" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>。其训练目标即是找到最优的参数<i>θ</i>, 使解码后的输出<i>y</i>更大程度地接近输入<i>x</i>, 接近程度以重构误差函数<i>J</i><sub><i>AE</i></sub> (<i>θ</i>) 来进行表示, <i>J</i><sub><i>AE</i></sub> (<i>θ</i>) 定义为:</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>E</mi></mrow></msub><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>S</mi></mrow></munder><mi>L</mi></mstyle><mo stretchy="false">{</mo><mi>x</mi><mo>, </mo><mi>g</mi><mo stretchy="false">[</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">基于重构误差函数与训练数据集S, 损失函数如式 (4) 所示。然后为了使损失函数极小化, 采用梯度下降法, 就可以得到该层AE参数θ。</p>
                </div>
                <div class="p1">
                    <p id="57" class="code-formula">
                        <mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">[</mo></mstyle><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mrow><mi>ln</mi></mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mrow><mi>ln</mi></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="58">第一个自编码器训练完成之后, 将其输出作为下一个自编码器的输入, 依次训练下一个自编码器, 最终训练完成整个深度自编码网络。</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>2.2 微调 (调优</b>) </h4>
                <div class="p1">
                    <p id="60">在预训练过程中, 训练每一层AE参数时, 会保持其他层参数不变。而微调主要是将所有AE视为一个整体, 利用有标签数据集, 通常采用BP算法进一步调整整个深度自编码网络, 使所有层参数达到全局最优。如果采用BP算法直接在随机化的初始权重上进行训练, 往往易陷入局部最优<citation id="165" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。因此在预训练完成之后进行微调, 效果会更好。</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag"><b>3 基于稀疏理论改进DAEN</b></h3>
                <div class="p1">
                    <p id="62">为了迫使DAE在多数量隐藏层神经元时发挥最大的功能, 学习到真正稀疏简明的特征, 本文引入稀疏性约束条件<citation id="166" type="reference"><link href="143" rel="bibliography" /><link href="145" rel="bibliography" /><link href="147" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 添加在自编码器的基础上。</p>
                </div>
                <div class="p1">
                    <p id="63">通常情况下, 一个激活函数输出值接近于1, 可以被定义这个神经单元为“活跃的”, 如果输出接近于0, 那么则定义这个神经单元为“不活跃的”。引入稀疏惩罚项后, DAEN重构误差函数为:</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula"><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mi>p</mi><mi>a</mi><mi>r</mi><mi>s</mi><mi>e</mi></mrow></msub><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>J</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>E</mi></mrow></msub><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>+</mo><mi>β</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>Κ</mi></mstyle><mi>L</mi></mrow></math></mathml> (、<mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="67">式中:<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>β</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>Κ</mi></mstyle><mi>L</mi><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub><mo stretchy="false">) </mo></mrow></math></mathml>是稀疏惩罚项;<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>是Kullback-Leibler (KL) 散度。<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>及其参数ρ和<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub></mrow></math></mathml>满足式 (6) :</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub><mo stretchy="false">) </mo><mo>=</mo><mi>ρ</mi><mrow><mi>log</mi></mrow><mfrac><mi>ρ</mi><mrow><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub></mrow></mfrac><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>ρ</mi><mo stretchy="false">) </mo><mrow><mi>log</mi></mrow><mfrac><mrow><mn>1</mn><mo>-</mo><mi>ρ</mi></mrow><mrow><mn>1</mn><mo>-</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">式中:<i>ρ</i>是一个稀疏参数, 一般情况下取一个很小的数。<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>是第j个隐层变量的平均激活率:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mtext>j</mtext><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>a</mi></mstyle><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">式中:<i>a</i><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>代表隐藏层第j个激活单元。</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>函数值随着ρ与<mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub></mrow></math></mathml>之间的差异值增大而逐渐增大, 当ρ=<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub></mrow></math></mathml>时, <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>L</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>ρ</mi><mo stretchy="false">∥</mo><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>=0, 达到最小值。所以, 在对损失函数极小化处理的时候, 就可以达到<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><msub><mrow></mrow><mtext>j</mtext></msub></mrow></math></mathml>与ρ尽量靠近的效果, 得到最优参数<i>θ</i>。</p>
                </div>
                <div class="p1">
                    <p id="84">这样通过计算平均激活量得到代价函数中的惩罚项, 通过优化稀疏代价函数可以得到较好的隐层稀疏表达。</p>
                </div>
                <h3 id="85" name="85" class="anchor-tag"><b>4 深度自编码网络诊断模型</b></h3>
                <div class="p1">
                    <p id="86">构建一个完整的基于DAEN的诊断模型<citation id="167" type="reference"><link href="149" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 它的前面堆叠AE, 进行特征提取之后, 最后添加一层分类层, 利用有标签样本进行整个DAEN的微调, 输出诊断结果。DAEN诊断模型结构如图2所示。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911011_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 深度自编码网络诊断模型" src="Detail/GetImg?filename=images/DZCL201911011_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 深度自编码网络诊断模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911011_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="88">深度自编码网络的隐藏层数即为自动编码器的个数。深度自编码网络是对特征进行提取, 不具有分类的功能。所以在深度自动编码网络最后输出层加上分类器, 使其具有分类识别能力<citation id="168" type="reference"><link href="151" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。常用的分类器有支持向量机<citation id="169" type="reference"><link href="153" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, K最近邻、Softmax分类器等。本文分类器是采用一种有监督学习方法softmax回归进行实现, 它是逻辑回归中在多分类问题上的推广, 在解决非线性多分类问题方面具有很好的效果, 输入向量经激活函数映射到[0, 1]区间内, 输出结果即为输入向量针对每一类别估算出的条件概率值。在深度自编码网络的最后分类层处添加softmax回归, 就形成了一个完整的深度自编码网络, 最后利用有标签样本进行整个DAEN的微调, 得出一个诊断模型。</p>
                </div>
                <div class="p1">
                    <p id="89">整个DAEN诊断模型的建立及诊断流程, 主要包括:</p>
                </div>
                <div class="p1">
                    <p id="90">1) 样本划分:获取样本数据, 并进行归一化处理, 将数据划分为训练集和测试集;</p>
                </div>
                <div class="p1">
                    <p id="91">2) 预训练:确定自动编码器个数, 建立DAE网络, 逐个训练自动编码器, 固定学习得到的参数, 作为训练的自动编码器所对应深度自编码网络的隐层连接参数;</p>
                </div>
                <div class="p1">
                    <p id="92">3) 微调:根据故障类别状况确定输出层节点个数及根据样本的类别状况进行有监督学习来反向微调深度自编码网络;</p>
                </div>
                <div class="p1">
                    <p id="93">4) 分类诊断:完成训练后, 输入测试样本进行测试, 输出分类正确率。</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag"><b>5 改进的DAEN在TE过程故障诊断中的仿真实验研究</b></h3>
                <div class="p1">
                    <p id="95">本文选用排除TE过程模拟系统故障<citation id="170" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>的数据集来自网站http://depts.Washington.edu/control/LARRY/TE/download.html的标准数据。在TE数据中选取了2 000条无标签样本数据作为训练集, 以及200条标签数据作为测试数据。为了尽可能模仿真实的工业过程, 设定训练数据集中正常数据和故障数据的样本不平衡。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>5.1 AE层数的确定</b></h4>
                <div class="p1">
                    <p id="97">对于基于改进的DAEN的TE过程故障诊断, 网络参数W、a、b初始化为 (0, 1) 之间较小随机数值, 初始学习速率设为0.1, 训练最大迭代次数为2 000次<citation id="171" type="reference"><link href="155" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。为了确定测试中的AE层数, 首先在改进的DAEN诊断模型中采取Softmax分类器。在统一选取的2 000条训练数据及200条测试数据, AE层数即自编码器的个数分别为0到10时的故障诊断结果, 如图3所示。从图3可知, 随着AE层数的增加, 故障诊断平均正确率逐渐增高, 当选取3层AE时, 故障诊断平均正确率已经很高, 达到90%以上。当AE层数大于3层, 故障诊断平均正确率略有增长, 基本趋于不变。实际训练时, 考虑到故障诊断效果及训练时间的问题, DAEN故障诊断模型以选取3层AE为最佳。而改进前后, DAEN的诊断性能明显得到提高。</p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911011_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同AE层数时的故障诊断结果" src="Detail/GetImg?filename=images/DZCL201911011_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同AE层数时的故障诊断结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911011_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>5.2 分类器的确定</b></h4>
                <div class="p1">
                    <p id="100">当改进的DAEN诊断模型的分类器分别选择SVM、KNN、Softmax时, 在测试集为200的情况下, 选取不同的预训练集进行故障诊断, 训练集分别为500, 1 000, 1 500, 2 000。诊断结果如表1。由表1分析可知:</p>
                </div>
                <div class="p1">
                    <p id="101">1) 在分类器确定的DAEN诊断中, 预训练集越大, TE过程的故障诊断平均正确率也在逐步提升。可见, 预训练阶段可以保障故障诊断正确率的提升, 它是基于深度自编码网络的TE过程故障诊断方法的重要组成部分。</p>
                </div>
                <div class="p1">
                    <p id="102">2) 深度自编码器网络模型结合不同的分类器, 得到的故障诊断结果也不相同。本文提出的DAEN与Softmax分类器结合的故障诊断方法, 相比较使用SVM、KNN分类器, 其正确率更高, 在训练样本为2 000条时, 正确率达到了92.06%, 而SVM与KNN分类器正确率只有85.57%、85.63%。</p>
                </div>
                <div class="area_img" id="103">
                    <p class="img_tit"><b>表1 不同训练集时, DAEN结合三种不同分类器的故障诊断结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="103" border="1"><tr><td><br />方法</td><td>分类器</td><td>训练集</td><td>测试集</td><td>平均正确率/%</td></tr><tr><td rowspan="12"><br />DAE</td><td rowspan="4"><br />KNN</td><td><br />500</td><td>200</td><td>75.53</td></tr><tr><td><br />1 000</td><td>200</td><td>81.37</td></tr><tr><td><br />1 500</td><td>200</td><td>84.08</td></tr><tr><td><br />2 000</td><td>200</td><td>85.57</td></tr><tr><td rowspan="4"><br />SVM</td><td><br />500</td><td>200</td><td>76.42</td></tr><tr><td><br />1 000</td><td>200</td><td>82.41</td></tr><tr><td><br />1 500</td><td>200</td><td>84.42</td></tr><tr><td><br />2 000</td><td>200</td><td>85.63</td></tr><tr><td rowspan="4"><br />Softmax</td><td><br />500</td><td>200</td><td>86.35</td></tr><tr><td><br />1 000</td><td>200</td><td>88.91</td></tr><tr><td><br />1 500</td><td>200</td><td>91.21</td></tr><tr><td><br />2 000</td><td>200</td><td>92.06</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>5.3 基于改进DAEN的仿真研究</b></h4>
                <div class="p1">
                    <p id="105">最终确定的DAEN诊断模型, 结合Softmax分类器, 并且基于稀疏理论<citation id="172" type="reference"><link href="157" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>进行了改进。改进后的DAEN, 与传统的诊断方法BPNN以及改进前的DAEN, 在训练集为1 500、测试集为200的情况下, 分别进行故障诊断。TE过程21种故障进行诊断的结果如表2。</p>
                </div>
                <div class="p1">
                    <p id="106">根据表2分析可知, 本文提出改进的DAEN的诊断方法同传统的BPNN以及改进前的DAEN对比, 三种方法都能对21种故障进行识别, 但是改进后的DAEN对故障IDV (1) 、IDV (3) 、IDV (5) 、IDV (6) 、IDV (7) 、IDV (13) 的诊断正确率均高达99%以上, 21种故障诊断平均正确率达到了91.21%, 明显高于改进前的82.42%以及传统BPNN的78.60%。</p>
                </div>
                <div class="area_img" id="107">
                    <p class="img_tit"><b>表2 基于改进的DAEN、DAEN、BPNN的故障诊断结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="107" border="1"><tr><td rowspan="2"><br />状态</td><td colspan="3"><br />正确率/ (%) </td></tr><tr><td><br />BPNN</td><td>DAEN</td><td>改进的DAEN</td></tr><tr><td><br />IDV (1) </td><td>90.31</td><td>94.27</td><td>99.20</td></tr><tr><td><br />IDV (2) </td><td>87.14</td><td>90.11</td><td>98.21</td></tr><tr><td><br />IDV (3) </td><td>88.08</td><td>89.80</td><td>99.07</td></tr><tr><td><br />IDV (4) </td><td>83.89</td><td>90.53</td><td>98.14</td></tr><tr><td><br />IDV (5) </td><td>80.09</td><td>83.24</td><td>99.58</td></tr><tr><td><br />IDV (6) </td><td>87.66</td><td>90.21</td><td>99.74</td></tr><tr><td><br />IDV (7) </td><td>85.22</td><td>88.83</td><td>99.71</td></tr><tr><td><br />IDV (8) </td><td>80.65</td><td>86.22</td><td>95.59</td></tr><tr><td><br />IDV (9) </td><td>61.09</td><td>70.33</td><td>72.55</td></tr><tr><td><br />IDV (10) </td><td>70.10</td><td>77.64</td><td>84.56</td></tr><tr><td><br />IDV (11) </td><td>88.20</td><td>90.69</td><td>98.23</td></tr><tr><td><br />IDV (12) </td><td>80.03</td><td>77.63</td><td>94.52</td></tr><tr><td><br />IDV (13) </td><td>90.31</td><td>92.56</td><td>99.25</td></tr><tr><td><br />IDV (14) </td><td>70.66</td><td>70.36</td><td>74.70</td></tr><tr><td><br />IDV (15) </td><td>85.61</td><td>86.18</td><td>97.73</td></tr><tr><td><br />IDV (16) </td><td>77.38</td><td>82.45</td><td>90.55</td></tr><tr><td><br />IDV (17) </td><td>65.54</td><td>66.37</td><td>78.46</td></tr><tr><td><br />IDV (18) </td><td>70.41</td><td>77.14</td><td>87.20</td></tr><tr><td><br />IDV (19) </td><td>60.99</td><td>74.28</td><td>73.71</td></tr><tr><td><br />IDV (20) </td><td>78.11</td><td>80.91</td><td>94.28</td></tr><tr><td><br />IDV (21) </td><td>69.06</td><td>71.02</td><td>80.37</td></tr><tr><td><br />平均正确率</td><td>78.60</td><td>82.42</td><td>91.21</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>6 结  论</b></h3>
                <div class="p1">
                    <p id="110">本文采用一种基于深度自编码网络 (DAEN) 的新型智能故障诊断方法, 结合Softmax分类器, 并且针对工业过程中正常状态数据多而故障数据少的不平衡问题, 采用稀疏理论进行了改进, 应用在TE过程的故障诊断中。并且通过实验比较, 验证了该方法在故障诊断中的有效性, 结果表明:</p>
                </div>
                <div class="p1">
                    <p id="111">1) 预训练阶段是基于深度自编码网络的TE过程故障诊断方法的重要组成部分, 预训练集越大, 故障诊断平均正确率也越高;</p>
                </div>
                <div class="p1">
                    <p id="112">2) 相比较使用SVM、KNN等分类器, 本文提出的DAEN与Softmax分类器结合的故障诊断方法, 其正确率更高;</p>
                </div>
                <div class="p1">
                    <p id="113">3) 与传统的机器学习方法BPN以及传统DAEN对比, 本文采用稀疏理论改进的DAEN在TE过程诊断上具有更高的正确率。</p>
                </div>
                <div class="p1">
                    <p id="114">本文所提出的诊断模型可以处理海量数据, 利用大量无标签数据建模, 少量有标签数据微调, 堆叠式自编码网络结构解决复杂的强非线性;引入的稀疏性约束解决稀缺的故障数据与正常数据非平衡问题。该方法在复杂化工生产过程中, 对解决复杂的故障问题有重大意义。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="129">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201708001&amp;v=MjczNzBiTXA0OUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTdsVzd6S0xqZlNiYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 任浩, 屈剑锋, 柴毅, 等.深度学习在故障诊断领域中的研究现状与挑战[J].控制与决策, 2017, 32 (8) :1345-1358.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD14051200000053&amp;v=MTU4ODVycVFUTW53WmVadEZpbmxVcnpJSmw0Y2FSQT1OaWZEYXJLOEh0VE5yWTlGWk9zUERIazZvQk1UNlQ0UFFIL2lyUmRHZQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> YIN S, GAO X, KARIMI HR, et al.Study on support vector machine-based fault detection in Tennessee Eastman process[J].Abstract &amp; Applied Analysis, 2014 (2) :1-8.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501617570&amp;v=MjI4NjV1b0lDWHM1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSmw0Y2FSQT1OaWZPZmJLN0h0RE5xbzlFWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> SHEN Y, DING S X, HAGHANI A, et al.A comparison study of basic data-driven fault diagnosis and process monitoring methods on the benchmark Tennessee Eastman Process[J].Journal of Process Control, 2012, 22 (9) :1567-1581.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX200905041&amp;v=MTIzOTh0R0ZyQ1VSN3FmWnVadEZ5N2xXN3pLSVRmU2RyRzRIdGpNcW85QlpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 胡昭华, 宋耀良.基于Autoencoder网络的数据降维和重构[J].电子与信息学报, 2009, 31 (5) :1189-1192.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contractive auto-encoders:Explicit invariance during feature extraction">

                                <b>[5]</b> RIFAI S, VINCENT P, MULLER X, et al.Contractive auto-encoders:explicit invariance during feature extraction[C].Proceedings of the 28th International Conference on Machine Learning, 2011:833-840.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DLZS201605021&amp;v=MTUyNDViRzRIOWZNcW85SFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N2xXN3pLSVNIUmY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 石鑫, 朱永利, 宁晓光, 等.基于深度自编码网络的电力变压器故障诊断[J].电力自动化设备, 2016, 36 (5) :122-126.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generating feature sets for fault diagnosis using denoising stacked auto-encoder">

                                <b>[7]</b> THIRUKOVALLURU R, DIXIT S, SEVAKULA R K.Generating feature sets for fault diagnosis using denoising stacked auto-encoder[C].Proceedings of IEEE Conference on Prognostics and Health Management, 2016 (72) :303-315.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse Autoencoder-based Feature Transfer Learning for Speech Emotion Recognition">

                                <b>[8]</b> DENG J, ZHANG Z X, ERIK M, et al.Sparse auto-encoder based feature transfer learning for speech emotion recognition[C].Humaine Association Conference on Affective Computing and Intelligent Interaction, 2013:511-516.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1014302217.nh&amp;v=MDE4NTZXN3pLVkYyNkdyQzRITlBOcUpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N2w=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 雒玉玺.稀疏自动编码器及其加速算法的研究[D].兰州:兰州大学, 2014.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel efficient method for training sparse auto-encoders">

                                <b>[10]</b> LUO X X, LI W.A novel efficient method for training sparse auto-encoders[C].6th International Congress on Image and Signal Processing, 2013:1019-1023.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Extracting and composing robust features with denoising autoencoders">

                                <b>[11]</b> VINCENT P, LAROCHELLE H, BENGIO Y, et al.Extracting and composing robust features with denoising autoencoders[C].Proceedings of the 25th International Conference on Machine Learning, 2008:1096-1103.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=What regularized auto-encoders learn from the data-generating distribution?">

                                <b>[12]</b> ALAIN G, BENGIO Y.What regularized auto-encoders learn from the data-generating distribution[J].The Journal of Machine Learning Research, 2014, 15 (1) :3563-3593.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGDC200825005&amp;v=MTY4MDJyUGJiRzRIdG5PcW85RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N2xXN3pLUHk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 赵文清, 朱永利, 张小奇.应用支持向量机的变压器故障组合预测[J].中国电机工程学报, 2008, 28 (25) :14-19.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Marginalized denoising auto-encoders for domain adaptation">

                                <b>[14]</b> MINMIN C, KILLAN Q W, ZHIXIANG X.Marginalized denoising auto-encoders for domain adaptation[C].Proc.of the 29th International Conference on Machine Learning, 2012:538-542.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201809013&amp;v=MTk0NTBuTXBvOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTdsVzd6S01qWFNaTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 刘梦溪, 王征, 宋久旭, 等.基于稀疏深度置信网络的图像分类识别研究[J].微电子学与计算机, 2018, 35 (9) :59-63.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201911011" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201911011&amp;v=MDQxODl1WnRGeTdsVzd6S0lUZklZckc0SDlqTnJvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

