

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135667463850000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201914018%26RESULT%3d1%26SIGN%3dT7j6KnduZ5oik1pXZEKDsBJ0oco%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201914018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201914018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201914018&amp;v=MTk0ODNVUjdxZlp1WnRGeXZoVzc3QUlUZklZckc0SDlqTnE0OUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;1 算法描述&lt;/b&gt; "><b>1 算法描述</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;1.1 Census变换和SAD代价&lt;/b&gt;"><b>1.1 Census变换和SAD代价</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;1.2 自适应窗口的创建&lt;/b&gt;"><b>1.2 自适应窗口的创建</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;1.3 自适应权重&lt;/b&gt;"><b>1.3 自适应权重</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;1.4 视差匹配计算&lt;/b&gt;"><b>1.4 视差匹配计算</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#110" data-title="&lt;b&gt;2 实验结果&lt;/b&gt; "><b>2 实验结果</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#113" data-title="&lt;b&gt;2.1 改进前后的效果对比分析&lt;/b&gt;"><b>2.1 改进前后的效果对比分析</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;2.2 不同算法对比分析&lt;/b&gt;"><b>2.2 不同算法对比分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#134" data-title="&lt;b&gt;3 结  论&lt;/b&gt; "><b>3 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="图1 本文算法流程">图1 本文算法流程</a></li>
                                                <li><a href="#50" data-title="图2 Census变换">图2 Census变换</a></li>
                                                <li><a href="#58" data-title="图3 SAD代价计算">图3 SAD代价计算</a></li>
                                                <li><a href="#62" data-title="图4 十字支撑窗口示意">图4 十字支撑窗口示意</a></li>
                                                <li><a href="#85" data-title="图5 干扰值剔除">图5 干扰值剔除</a></li>
                                                <li><a href="#87" data-title="图6 窗口干扰值剔除效果">图6 窗口干扰值剔除效果</a></li>
                                                <li><a href="#116" data-title="图7 采用自适应阈值前后效果对比">图7 采用自适应阈值前后效果对比</a></li>
                                                <li><a href="#120" data-title="图8 10%椒盐噪声情况下改进前后对比">图8 10%椒盐噪声情况下改进前后对比</a></li>
                                                <li><a href="#121" data-title="图9 未采用干扰值剔除">图9 未采用干扰值剔除</a></li>
                                                <li><a href="#122" data-title="图10 采用干扰值剔除">图10 采用干扰值剔除</a></li>
                                                <li><a href="#126" data-title="图11 采用自适应权重前后对比">图11 采用自适应权重前后对比</a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;表1 常用算法匹配错误率&lt;/b&gt;"><b>表1 常用算法匹配错误率</b></a></li>
                                                <li><a href="#133" data-title="图12 算法改进前后视差图对比">图12 算法改进前后视差图对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="5">


                                    <a id="bibliography_1" title=" 闫利, 王芮, 刘华, 等.基于改进代价计算和自适应引导滤波的立体匹配[J].光学学报, 2018, 38 (11) :257-267." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811030&amp;v=MzIxMjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2aFc3N0FJalhUYkxHNEg5bk5ybzlHWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         闫利, 王芮, 刘华, 等.基于改进代价计算和自适应引导滤波的立体匹配[J].光学学报, 2018, 38 (11) :257-267.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_2" title=" LEE J, JUN D, EEM C.Improved census transform for noise robust stereo matching[J].Optical Engineering, 2016, 55 (6) :063107." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG2C9D5E13EF97A7506380CF74A18FBC52&amp;v=MjM5Mjk2WEoybzVHRVowR0N3MCt5aFlWNlRkOU93bmxxR00wY2NUbU5yK2RDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4N3kzd2FBPU5pZk9hYkhMRg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         LEE J, JUN D, EEM C.Improved census transform for noise robust stereo matching[J].Optical Engineering, 2016, 55 (6) :063107.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_3" title=" HEIKO H, SCHARSTEIN D.Evaluation of stereo matching costs on images with radiometric differences[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2008, 31 (9) :1582-1599." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Evaluation of Stereo Matching Costs on Images with Radiometric Differences">
                                        <b>[3]</b>
                                         HEIKO H, SCHARSTEIN D.Evaluation of stereo matching costs on images with radiometric differences[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2008, 31 (9) :1582-1599.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_4" title=" 门宇博, 马宁, 张国印, 等.非参数变换和改进动态规划的立体匹配算法[J].哈尔滨工业大学学报, 2015, 47 (3) :60-65." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201503010&amp;v=MjI5ODRkckc0SDlUTXJJOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZoVzc3QUxTako=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         门宇博, 马宁, 张国印, 等.非参数变换和改进动态规划的立体匹配算法[J].哈尔滨工业大学学报, 2015, 47 (3) :60-65.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_5" title=" 许金鑫, 李庆武, 刘艳, 等.基于色彩权值和树形动态规划的立体匹配算[J].光学学报, 2017, 37 (12) :289-297." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201712034&amp;v=MjYxMzR6cXFCdEdGckNVUjdxZlp1WnRGeXZoVzc3QUlqWFRiTEc0SDliTnJZOUdZSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         许金鑫, 李庆武, 刘艳, 等.基于色彩权值和树形动态规划的立体匹配算[J].光学学报, 2017, 37 (12) :289-297.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_6" title=" MEI X, SUN X, ZHOU M C, et al.On building an accurate stereo matching system on graphics hardware[C].IEEE International Conference on Computer Vision Workshops, 2011:467-474." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On Build an Accurate Stereo Matching System on Graphics Hardware">
                                        <b>[6]</b>
                                         MEI X, SUN X, ZHOU M C, et al.On building an accurate stereo matching system on graphics hardware[C].IEEE International Conference on Computer Vision Workshops, 2011:467-474.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_7" title=" ZHANG K.Cross-based local stereo matching using orthogonal integral images[J].IEEE Transactions on Circuits &amp;amp; Systems for Video Technology, 2009, 19 (7) :1073-1079." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cross-based local stereo matching using orthogonal integral images">
                                        <b>[7]</b>
                                         ZHANG K.Cross-based local stereo matching using orthogonal integral images[J].IEEE Transactions on Circuits &amp;amp; Systems for Video Technology, 2009, 19 (7) :1073-1079.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_8" title=" 吕鹏程, 厉小润.基于AD-Census和多权值的自适应窗口的立体匹配算法[J].工业控制计算机, 2018 (3) :49-52." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GYKJ201803021&amp;v=MzE2NjJDVVI3cWZadVp0Rnl2aFc3N0FJalRBWkxHNEg5bk1ySTlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         吕鹏程, 厉小润.基于AD-Census和多权值的自适应窗口的立体匹配算法[J].工业控制计算机, 2018 (3) :49-52.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_9" title=" BESSE F, ROTHER C, FITZGIBBON A, et al.PMBP:Patch match belief propagation for correspondence field estimation[J].International Journal of Computer Vision, 2014, 110 (1) :2-13." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14101300030946&amp;v=MDQzMDJnUEJYZy9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJMW9jYXhvPU5qN0Jhcks4SDlITnJJOUZaTw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         BESSE F, ROTHER C, FITZGIBBON A, et al.PMBP:Patch match belief propagation for correspondence field estimation[J].International Journal of Computer Vision, 2014, 110 (1) :2-13.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_10" title=" WANG Z F, ZHENG Z G.A region based stereo matching algorithm using cooperative optimization[C].IEEE Conference on Computer Vision &amp;amp; Pattern Recognition, 2008:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A region based stereo matchingalgorithm using cooperative optimization">
                                        <b>[10]</b>
                                         WANG Z F, ZHENG Z G.A region based stereo matching algorithm using cooperative optimization[C].IEEE Conference on Computer Vision &amp;amp; Pattern Recognition, 2008:1-8.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_11" title=" SUN X, MEI X, JIAO S H, et al.Stereo matching with reliable disparity propagation[C].International Conference on 3d Imaging, 2011:132-139." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stereo matching with reliable disparity propagation">
                                        <b>[11]</b>
                                         SUN X, MEI X, JIAO S H, et al.Stereo matching with reliable disparity propagation[C].International Conference on 3d Imaging, 2011:132-139.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_12" title=" GALUN M, Amir T, HASSNER T.Wide baseline stereo matching with convex bounded-distortion constraints[C].IEEE International Conference on Computer Vision, 2016:2228-2236." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wide baseline stereo matching with convex bounded-distortion constraints">
                                        <b>[12]</b>
                                         GALUN M, Amir T, HASSNER T.Wide baseline stereo matching with convex bounded-distortion constraints[C].IEEE International Conference on Computer Vision, 2016:2228-2236.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_13" title=" MADAIN P, ABIEL A.FPGA implementation of an efficient similarity-based adaptive window algorithm for real-time stereo matching[J].Journal of Real-Time Image Processing, 2015, 10 (3) :1-17." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=FPGA implementation of an efficient similarity-based adaptive window algorithm for real-time stereo matching">
                                        <b>[13]</b>
                                         MADAIN P, ABIEL A.FPGA implementation of an efficient similarity-based adaptive window algorithm for real-time stereo matching[J].Journal of Real-Time Image Processing, 2015, 10 (3) :1-17.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_14" title=" KRISTIAN A.Accurate hardware-based stereo vision[J].Computer Vision &amp;amp; Image Understanding, 2010, 114 (11) :1303-1316." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083587&amp;v=MzI2MTRxUVRNbndaZVp0RmlubFVyeklJMW9jYXhvPU5pZk9mYks3SHRETnFvOUVaT01NQ1hRK29CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         KRISTIAN A.Accurate hardware-based stereo vision[J].Computer Vision &amp;amp; Image Understanding, 2010, 114 (11) :1303-1316.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_15" title=" AFFENDI H R, HAIDI I.Literature survey on stereo vision disparity map algorithms[J].Journal of Sensors, 2016, 2016:1-23." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD3D4554200C902AF5475771AD5EACA887&amp;v=MjMyMDdJdVJNWDdUcDZUMzZUMkJkQUNNSGxUYktZQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeDd5M3dhQT1OaWZEYXJETUd0VEpxNDFGWkpnR0RINQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         AFFENDI H R, HAIDI I.Literature survey on stereo vision disparity map algorithms[J].Journal of Sensors, 2016, 2016:1-23.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(14),117-122 DOI:10.19651/j.cnki.emt.1902608            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于自适应窗口与权重的立体匹配算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B7%AF%E4%B9%BE%E5%9D%A4&amp;code=39910037&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">路乾坤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%BD%A6&amp;code=07779630&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李彦</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B1%9F%E8%8B%8F%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0153212&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江苏科技大学电子信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统立体匹配算法匹配窗口采用固定阈值以及代价聚合采用固定权重, 使得算法在边界区域和弱纹理区域匹配精度低的问题, 提出一种基于自适应窗口与权重的立体匹配算法。该算法首先根据图像像素梯度信息自动生成颜色阈值, 进而创建十字支撑窗口, 并对窗口像素点进行相似度计算, 按照3-<i>σ</i>原则剔除干扰像素, 然后用当前窗口最小臂长和臂长阈值自动计算灰度差绝对值之和和Census的权重, 利用指数归一化函数聚合SAD和Census代价, 通过win-take-all算法策略进行初始视差计算, 最后通过左右视差一致性原则筛选和滤波得到精密视差图。使用改进算法在Middlebury测速平台对标准图像进行实验测试, 平均错误率在4.5%以内, 较原有算法错误率降低了11.5%左右。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">立体匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E9%80%82%E5%BA%94%E6%9D%83%E9%87%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自适应权重;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E9%80%82%E5%BA%94%E7%AA%97%E5%8F%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自适应窗口;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A2%9C%E8%89%B2%E9%98%88%E5%80%BC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">颜色阈值;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B9%B2%E6%89%B0%E5%80%BC%E5%89%94%E9%99%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">干扰值剔除;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    路乾坤, 硕士研究生, 主要研究方向为图像处理和智能控制。E-mail:lqkisme@163.com;
                                </span>
                                <span>
                                    李彦, 硕士, 教授, 硕士生导师, 主要研究方向为智能控制和船舶自动化。E-mail:zjhdcylyl@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-11</p>

            </div>
                    <h1><b>Stereo matching algorithm based on adaptive window and weight</b></h1>
                    <h2>
                    <span>Lu Qiankun</span>
                    <span>Li Yan</span>
            </h2>
                    <h2>
                    <span>School of Electronics Information, Jiangsu University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problem that the traditional stereo matching algorithm uses fixed threshold for the matching window and fixed weight for the cost aggregation, which makes the algorithm have low matching accuracy in the boundary region and weak texture region, this paper presents a stereo matching algorithm based on adaptive window and weight. The algorithm firstly based on image pixel gradient information automatically generated color threshold, and then creates windows cross bracing, and carries out similarity calculation on the window pixels, eliminates interference in accordance with the principle of 3-<i>σ</i> pixels, and then uses the forearm length and arm length threshold in the current window to automatically calculate weight of the sum of absolute differences (SAD) and Census, using aggregate index normalized function SAD and Census costs, through the windows-take-all strategy calculates initial parallax, finally by principle of horizontal parallax the consistency sifts and filters precision parallax figure. The improved algorithm is used to test the standard image on the middlebury speed measurement platform, the average error rate is within 4.5%, which is about 17.4% lower than the original algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=stereo%20matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">stereo matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=adaptive%20weight&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">adaptive weight;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=adaptive%20window&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">adaptive window;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=color%20threshold&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">color threshold;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=interference%20value%20rejection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">interference value rejection;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-11</p>
                            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="36">立体视觉技术在计算机视觉、SLAM地图构建、人工智能、机器人等领域有广泛的应用。其中立体匹配又是立体视觉中最重要的一部分, 立体匹配算法有很多种, 根据匹配类型可以分为局部匹配算法和全局优化算法。局部匹配算法把图像分成若干独立的单元, 在这些小单元内计算使得能量最小的视差值。全局优化算法在整个图像区域内建立一个总体的能量函数, 利用优化算法求取使全局能量最小的视差值, 全局算法效果良好但是运算用时过长, 不适用于实时系统。相比全局算法, 局部算法原理简单速度快, 尤其近年来提出了许多局部算法及其改进算法, 使得局部算法的错误率大大降低, 使用局部算法得到稠密高精度的视差图是当前研究的热点问题。</p>
                </div>
                <div class="p1">
                    <p id="37">立体匹配主要分为匹配代价计算、匹配代价聚合、视差计算和视差细化4个步骤<citation id="136" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 常用的匹配代价计算目前主要有灰度差绝对值之和 (SAD) 、灰度差平方和 (sum of squared differences, SSD) 、灰度差绝对值 (absolute differences, AD) 和Census变换等<citation id="137" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, Heiko等<citation id="138" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>研究对比了几种匹配代价的优缺点, 发现Census变换算法对于图像角度、光照、颜色的抗干扰性比较强, 鲁棒性在几种算法中最好, Census变化解决了相机在拍摄过程中受到的外部干扰<citation id="139" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>, 缺点是在重复纹理区域容易出现误匹配<citation id="140" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, SAD变换可以较好地反映像素点的灰度变化, 在纹理丰富的图像边缘区域具有良好的匹配效果, 但SAD变换对于因光照变化产生的噪点比较敏感, 鲁棒性较差。Mei等<citation id="141" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>结合SAD和Census进行代价计算, 在低纹理和重复纹理区域都取得了良好效果, 但是SAD和Census的结合权重均采用固定方式, 而单像素点的匹配容易造成误匹配, 故通过对支持窗口内的所有代价进行聚合或取均值来提高匹配的可靠性, 但是取窗口过大会使得计算量增大, 不连续区域的误匹配率增加, 窗口小又会导致图像边缘误匹配率增加使得图像匹配整体轮廓边界效果差。</p>
                </div>
                <div class="p1">
                    <p id="38">故针对代价计算和匹配窗口的选取, 本文提出一种基于自适应窗口与权重的立体匹配算法。首先计算Census代价和SAD代价, 然后利用像素梯度信息自动计算颜色阈值, 根据颜色阈值自动构建匹配窗口, 根据窗口内像素的统计特征去除干扰值。根据匹配窗口臂长自适应设置SAD和Census的权重降低了极值和噪点对于匹配准确率的影响, 增强了重复区域和低纹理区域的正确率。同时为进一步提高精度, 改进窗口的生成方式, 运用相似度计算自动剔除干扰点。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag"><b>1 算法描述</b></h3>
                <div class="p1">
                    <p id="40">算法的输入是经过极线矫正的立体图像, 对立体图像进行代价计算、匹配窗口的创建, 代价聚合、视差粗算、视差精化, 最后输出视差图, 算法的总体流程如图1所示。其中, 匹配代价计算采用SAD-Census代价即Census和SAD结合的方式;匹配窗口创建采用自适应颜色阈值的十字窗口创建方式;代价聚合阶段用自适应权重思想结合Census和SAD代价, 采用窗口内所有代价累积值作为代价聚合值;视差粗算采用win-take-all策略;然后对输出图像进行左右一致性检测, 减少错误值和遮挡值以及孔洞现象, 最后输出结果。</p>
                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法流程" src="Detail/GetImg?filename=images/DZCL201914018_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="42" name="42"><b>1.1 Census变换和SAD代价</b></h4>
                <div class="p1">
                    <p id="43">Census变化是一种非参数变化, 其依赖于邻域像素颜色的相对值, 故此对光照, 角度的抗干扰性较强, 可以有效衡量像素之间的相似性。其原理如图2所示, 计算某点的Census变换值<i>Cen</i> (<i>p</i>) 首先以该点为中心点定义一个M×N大小的窗口, 将窗口内所有像素按顺序和该点进行比较, 得到结果组成一串二进制编码。Census代价为2点进行变换后的海明距离, 其计算方式如式 (1) ～ (3) 所示。</p>
                </div>
                <div class="p1">
                    <p id="44"><mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>e</mi><mi>n</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mo>⊗</mo></mstyle><mrow><mi>q</mi><mo>⊆</mo><mi>Ν</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></munder><mi>ξ</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>      (1) </p>
                </div>
                <div class="area_img" id="46">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZCL201914018_04600.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="48"><i>Cen</i> (<i>p</i>, <i>d</i>) =<i>Ham</i> (<i>Cen</i><sub><i>L</i></sub> (<i>p</i>) , <i>Cen</i><sub><i>R</i></sub> (<i>p</i><sub><i>d</i></sub>) ) (3) </p>
                </div>
                <div class="p1">
                    <p id="49">式中:<i>p</i>是窗口中心像素;<i>q</i>是窗口中心像素以外的其他像素;<i>N</i><sub><i>p</i></sub>表示中心像素<i>p</i>的邻域;<i>I</i> (*) 表示像素点*处的灰度值;<i>p</i><sub><i>d</i></sub>是视差为<i>d</i>时右图对应的点;<i>Ham</i> (<i>x</i>, <i>y</i>) 表示<i>x</i>, <i>y</i> 2点间的海明距离, 即用2个二进制编码做异或运算, 统计二进制结果中每一位上数值为1的个数。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Census变换" src="Detail/GetImg?filename=images/DZCL201914018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Census变换  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="51">像素点的SAD代价是用窗口内所有像素点的颜色值与该点做差后取绝对值再相加, 故此SAD代价能较好的反映图像颜色值的变化。像素点的SAD值计算方式如式 (4) 所示。</p>
                </div>
                <div class="p1">
                    <p id="52"><mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>a</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>s</mi><mo>+</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>t</mi><mo>+</mo><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>s</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></mstyle></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="54">式中:<i>I</i> (<i>i</i>, <i>j</i>) 表示像素的颜色值。</p>
                </div>
                <div class="p1">
                    <p id="55">故SAD代价可表示为左右2图待匹配点的空间距离, 如图3所示, 公式如下。</p>
                </div>
                <div class="p1">
                    <p id="56"><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><msub><mrow></mrow><mrow><mi>s</mi><mi>a</mi><mi>d</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>S</mi><mi>a</mi><mi>d</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>-</mo><mi>S</mi><mi>a</mi><mi>d</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></math></mathml>      (5) </p>
                </div>
                <div class="area_img" id="58">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 SAD代价计算" src="Detail/GetImg?filename=images/DZCL201914018_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 SAD代价计算  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_058.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>1.2 自适应窗口的创建</b></h4>
                <h4 class="anchor-tag" id="60" name="60">1) 自适应阈值窗口</h4>
                <div class="p1">
                    <p id="61">基于固定大小窗口的方法存在窗口大小和形状选择的难题, 取窗口过大会使得计算量增大, 不连续区域的误匹配率增加, 窗口过小又会导致图像边缘误匹配率增加使得图像匹配整体轮廓边界效果差。针对该问题, 文献<citation id="142" type="reference">[<a class="sup">7</a>]</citation>采用一种十字窗口生成策略, 先按照固定的颜色阈值, 得到上下左右4个方向的距离称之为臂长, 然后再依次生成分支骨架最后合成一个窗口区域, 如图4所示在点I处生成的窗口。此方法的效果相比固定大小窗口的方法取得良好的效果平均错误率在7.60%左右, 其中颜色阈值采用20, 臂长阈值17。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 十字支撑窗口示意" src="Detail/GetImg?filename=images/DZCL201914018_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 十字支撑窗口示意  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_062.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="63">骨架区域表示为:</p>
                </div>
                <div class="area_img" id="64">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZCL201914018_06400.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="66">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZCL201914018_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="68">窗口区域<i>U</i> (<i>p</i>, <i>q</i>) 为所有<i>H</i> (<i>q</i>) 的集合, 如下式:</p>
                </div>
                <div class="p1">
                    <p id="69"><i>U</i> (<i>p</i>, <i>q</i>) =∪<i>H</i> (<i>q</i>) (8) </p>
                </div>
                <div class="p1">
                    <p id="70">其后, 吕等<citation id="143" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>在此基础上采用多次窗口取均值的方法, 把平均错误率进一步降到5.3%, 该方法在生成窗口时的颜色阈值均为固定值, 其自适应能力有待进一步提升, 所以本文在此方法基础上提出自适应阈值窗口方法。</p>
                </div>
                <div class="p1">
                    <p id="71">首先用自适应阈值法生成十字骨架, 采用式 (9) 确定颜色阈值<i>τ</i>:</p>
                </div>
                <div class="area_img" id="72">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZCL201914018_07200.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="74">式中:<i>τ</i><sub>1</sub>是颜色阈值的初始值;<i>τ</i><sup>next</sup>是下一步的阈值;<i>τ</i><sub>now</sub>是当前的臂长;<i>ρ</i>是调节系数;<i>I</i><sub><i>p</i></sub>是起点;<i>I</i><sub><i>p</i></sub>是当前检测点;<i>L</i><sub>1</sub>是臂长的阈值。</p>
                </div>
                <div class="p1">
                    <p id="75">当给定初始值后, 以点<i>I</i><sub><i>p</i></sub>为起点向上下左右4个方向搜索, 此时随着距离越来越大颜色阈值是逐步减小的, 同时包含了距离相关性的影响因素, 而没有增加额外的变量, 在一个颜色变化小的区域<i>τ</i>变化缓慢, 当遇到具有边界特征的区域时候能够快速调整阈值<i>τ</i>防止引入更多的干扰点。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">2) 相似度检测以及干扰值剔除</h4>
                <div class="p1">
                    <p id="77">建立十字骨架后依照骨架扩展一个待匹配的矩形窗口, 然后进行第2步剔除干扰像素点。</p>
                </div>
                <div class="p1">
                    <p id="78">由于匹配算法对于噪声影响相对敏感, 而且直接生成的矩形窗口是一个规则图形容易包含进许多干扰点, 为此需要进行干扰点的甄别和剔除。选择用窗口匹配的原则是尽可能地选择图形特征一致的区域, 对于灰度图像而言图像特征由图像的像素值大小来体现, 故此运用统计方法计算窗口内像素的均值和方差。</p>
                </div>
                <div class="p1">
                    <p id="79"><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>μ</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub></mrow></munderover><mi>Ι</mi></mstyle><mo stretchy="false"> (</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⊆</mo><mi>S</mi></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="81"><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⊆</mo><mi>S</mi></mrow></munder><mrow><mfrac><mrow><mrow><mo stretchy="false">[</mo><mi>Ι</mi><mo stretchy="false"> (</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>μ</mi><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>u</mtext><mtext>m</mtext></mrow></msub></mrow></mfrac></mrow></mstyle></mrow></msqrt></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="83">式中:<i>N</i><sub>num</sub>是窗口S内所有像素个数。</p>
                </div>
                <div class="p1">
                    <p id="84">统计均值和方差后, 按照3-<i>σ</i>原则, 把不在范围内的像素点去除, 滤取自身的干扰点和随机出现的噪声。如果区域内存在边界同时还可以把边界外的点去除掉, 如图5所示。</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_085.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 干扰值剔除" src="Detail/GetImg?filename=images/DZCL201914018_085.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 干扰值剔除  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_085.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="86">图6所示为加入自适应阈值和干扰值剔除后的结果, 该算法可以自动识别边界信息同时滤去一些噪值。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_087.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 窗口干扰值剔除效果" src="Detail/GetImg?filename=images/DZCL201914018_087.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 窗口干扰值剔除效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_087.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>1.3 自适应权重</b></h4>
                <div class="p1">
                    <p id="89">Census变换和SAD代价属于不同类型的代价计算方式, 故不能直接相加用作为新的代价计算方式, 需要一个归一化函数, 将2种代价归一化后再相加。本文用到的归一化函数如式 (12) 所示。</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>C</mi><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>g</mtext><mtext>g</mtext><mtext>r</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo>=</mo><mi>α</mi><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mi>exp</mi><mfrac><mrow><mo>-</mo><mi>C</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo></mrow><mrow><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac></mrow><mo>) </mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mi>β</mi><mrow><mo> (</mo><mrow><mn>1</mn><mo>-</mo><mi>exp</mi><mfrac><mrow><mo>-</mo><mi>C</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>a</mtext><mtext>d</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo></mrow><mrow><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow><mo>) </mo></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91"><i>λ</i><sub>1</sub>, <i>λ</i><sub>2</sub>是一个经验值, 对于不同图像需要计算多次来取合适值, 一般<i>λ</i><sub>1</sub>=15, <i>λ</i><sub>2</sub>=25。</p>
                </div>
                <div class="p1">
                    <p id="92">为了使得算法能够依据图像自身的区域特征自适应的设置<i>α</i>, <i>β</i>的值, 使得Census算法在平滑区域的优势和SAD算法在边界区域的优势都能够体现。本文提出一种自适应权重的思路, 计算方式如式 (13) 所示。</p>
                </div>
                <div class="p1">
                    <p id="93"><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><mo>=</mo><mi>γ</mi><mfrac><mrow><mi>h</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub></mrow><mrow><mi>L</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="95">式中:<i>γ</i>为放大倍数调节系数;<i>h</i><sub>min</sub>为自适应窗口的最小臂长;<i>L</i><sub>1</sub>为窗口臂长最大阈值。</p>
                </div>
                <div class="p1">
                    <p id="96">由前面自适应颜色阈值得到的自适应窗口本身就在一定程度反应了图像的区域特征, 所以可以用自适应窗口的一些特征来设置Census和SAD的权重, 根据公式, 如果自适应窗口小说明此区域图像纹理多, 边界信息多, 此时应加大SAD系数, 即增大<i>β</i>减小<i>α</i>, 反之亦然。据此可以自动的调节2个代价的权重。</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97"><b>1.4 视差匹配计算</b></h4>
                <h4 class="anchor-tag" id="98" name="98">1) 视差初步计算</h4>
                <div class="p1">
                    <p id="99">代价聚合阶段结束后得到每个像素的最终代价<i>C</i><sub>aggr</sub> (<i>p</i>, <i>d</i>) , 考虑的计算量和计算准确率, 采用了计算速度和准确率较均衡的win-take-all方法。此算法是在每一行之间在视差选择范围内选择使得代价最小的视差值。</p>
                </div>
                <div class="p1">
                    <p id="100">其公式如式 (14) 所示。</p>
                </div>
                <div class="p1">
                    <p id="101"><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi></mrow></mstyle><mrow><mi>d</mi><mo>⊆</mo><mi>R</mi><msub><mrow></mrow><mi>d</mi></msub></mrow></munder><mo stretchy="false"> (</mo><mi>C</mi><msubsup><mrow></mrow><mrow><mtext>a</mtext><mtext>g</mtext><mtext>g</mtext><mtext>r</mtext></mrow><mo>*</mo></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>d</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>      (14) </p>
                </div>
                <div class="p1">
                    <p id="103">式中:<i>R</i><sub><i>d</i></sub> 为视差的选择范围。</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104">2) 视差精化</h4>
                <div class="p1">
                    <p id="105">通过上述算法获得的初始视差图中会包含很多错误匹配点, 造成一些孔洞现象和在非边界区域视差不连续的现象, 需要进行进一步处理。本文参考文献<citation id="144" type="reference">[<a class="sup">1</a>]</citation>和文献<citation id="145" type="reference">[<a class="sup">6</a>]</citation>使用的后处理方法进行优化。</p>
                </div>
                <div class="p1">
                    <p id="106">首先以左右2幅图像为基准按照上述算法进行匹配, 分布得到2幅视差图<i>M</i><sub>L</sub>和<i>M</i><sub><i>R</i></sub>, 然后以左图为标准进行左右一致性检测:</p>
                </div>
                <div class="p1">
                    <p id="107"><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>d</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>-</mo><mi>d</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>-</mo><mi>d</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>&gt;</mo><mi>δ</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></math></mathml>      (15) </p>
                </div>
                <div class="p1">
                    <p id="109">式中:<i>d</i><sub><i>L</i></sub> (<i>p</i>) 是左视差图中点<i>p</i>的视差值;<i>d</i><sub><i>R</i></sub> (<i>p</i>-<i>d</i><sub><i>L</i></sub> (<i>p</i>) ) 为右视差图中对应的点值, 如果这个值大于<i>δ</i><sub>0</sub> (一般取1) , 则认为该点是一个错误匹配点, 并将其标记。文本采用区域投票方式<citation id="146" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>进行插值, 在该点5×5的窗口内统计出现频率最多的视差值作为该点的插值。最后在该窗口内进行一次中值滤波作为最终的视差值。</p>
                </div>
                <h3 id="110" name="110" class="anchor-tag"><b>2 实验结果</b></h3>
                <div class="p1">
                    <p id="111">本文算法在python-opencv环境下实现, 计算机硬件为CPU:Intel I5-2500×4, 3.3 GHz, 内存8 G, 操作系统:Linux。为验证算法的有效性, 使用国际通用立体匹配评估测试平台Middlebury平台提供的Tsukuba、Venus、Teddy、Cones 4组标准数据对算法的误差进行评估并和其他算法以及改进效果进行验证。</p>
                </div>
                <div class="p1">
                    <p id="112">实验中的参数设置如下: <i>τ</i><sub>1</sub>=35, <i>L</i><sub>1</sub>=25, <i>γ</i>=30, <i>ρ</i>=1.9, <i>R</i><sub><i>d</i></sub>=35。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>2.1 改进前后的效果对比分析</b></h4>
                <h4 class="anchor-tag" id="114" name="114">1) 采用自适应颜色阈值前后的对比</h4>
                <div class="p1">
                    <p id="115">为了验证算法加入自适应颜色阈值方法后的效果, 对4组数据采用此方法前后进行测试, 采用前的颜色阈值手动确定, 实验使用了5～75的范围进行测试, 实验结果如图7所示。</p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 采用自适应阈值前后效果对比" src="Detail/GetImg?filename=images/DZCL201914018_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 采用自适应阈值前后效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_116.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="117">图7横坐标是颜色阈值, 纵坐标是匹配错误率 (%) , 由图7结果可看出增加自适应颜色阈值前, 颜色阈值需要手动调节, 针对不同图像最优的参数不同, 实验中进行了8组测试, 颜色阈值5～15, 几幅图像最优的参数大约在20～50之间, 但不同图像具有不同的最优值, 增加自适应颜色阈值后, 算法可以根据图像的区域特征估算一个颜色阈值, 虽然没有达到最优, 但是够有效降低平均错误率, 对不同的图像适应性有较大增加。</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118">2) 干扰值剔除前后对比</h4>
                <div class="p1">
                    <p id="119">为了验证干扰值剔除算法的效果, 实验对4组标准数据添加了5%、10%、15%、20%的椒盐噪声来进行对比, 图8展示的是添加10%的椒盐噪声情况下的算法效果, 具体错误率对比结果如图9和10所示。</p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_120.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 10%椒盐噪声情况下改进前后对比" src="Detail/GetImg?filename=images/DZCL201914018_120.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 10%椒盐噪声情况下改进前后对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_120.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_121.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 未采用干扰值剔除" src="Detail/GetImg?filename=images/DZCL201914018_121.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 未采用干扰值剔除  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_121.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 采用干扰值剔除" src="Detail/GetImg?filename=images/DZCL201914018_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 采用干扰值剔除  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_122.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="123">由图8可见, 采用干扰值剔除算法后, 本文算法错误率低于改进前的错误率, 噪声的控制效果较为明显, 由图9和图10对比可知, 在没有添加噪声的情况下错误率相同, 随着噪声干扰越来越严重, 匹配的错误率也越来越高, 并且提高的趋势越来越快, 增加干扰值剔除算法后, 错误率虽然也随之升高, 但是增加的量相对较少, 错误率增加越来越快的趋势也有所抑制。说明算法加入干扰值剔除操作后对噪声有明显的效果。</p>
                </div>
                <h4 class="anchor-tag" id="124" name="124">3) 采用自适应权重前后对比</h4>
                <div class="p1">
                    <p id="125">为了验证添加自适应权重的效果, 对4组标准数据集改进前后各进行20次运算取均值用作对比, 具体结果如图11所示。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_126.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 采用自适应权重前后对比" src="Detail/GetImg?filename=images/DZCL201914018_126.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 采用自适应权重前后对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_126.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="127">根据图11, 添加自适应权重后, 动态调节SAD和Census的权重, 算法的准确率较改进前都有了一定提升, 其中对Tsukuba数据集和Teddy数据集提升较为明显, 分析数据集的图像特征, 主要原因是这2组图像内主要物体比较突出, 轮廓较清晰, 其颜色特征相对背景比较突出, 而算法的改进点正是针对这些特征设计, 所有对此类图像效果更加明显。</p>
                </div>
                <h4 class="anchor-tag" id="128" name="128"><b>2.2 不同算法对比分析</b></h4>
                <div class="p1">
                    <p id="129">为客观的分析本文算法性能, 实验计算了各个数据集在不同区域的错误率, 并与CoopRegion<citation id="147" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, (原算法) SAD-Census<citation id="148" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, RDP (reliable disparity propagation) <citation id="149" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, DistinctSM (distinct stereo matching) <citation id="150" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, ReliabilityDP (reliability dynamic programming) <citation id="151" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, SAD+IGMCT<citation id="152" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, SSD+MF<sup><a class="sup">[16]</a></sup>等算法进行了对照比较。如表1所示, 其中, No-occ为非遮挡区域错误匹配率, all为全部区域的错误匹配率, disc为视差不连续区域的错误匹配率, average为平均错误匹配率。由表1可以知, 本文算法在Tsukuba、Venus、Teddy、Cones数据下的平均错误率为3.76%, 低于CoopRegion, SAD-Census, RDP, DistinctSM等算法, 同时对比原算法SAD-Census算法错误率降低11.5%左右。</p>
                </div>
                <div class="area_img" id="130">
                    <p class="img_tit"><b>表1 常用算法匹配错误率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="130" border="1"><tr><td rowspan="2"><br />alogorithm</td><td colspan="3"><br />Tsukuba</td><td colspan="3">Venus</td><td colspan="3">Teddy</td><td colspan="3">Cones</td><td rowspan="2">Average/<br />%</td></tr><tr><td><br />No-occ</td><td>All</td><td>Disc</td><td>No-occ</td><td>All</td><td>Disc</td><td>No-occ</td><td>All</td><td>Disc</td><td>No-occ</td><td>All</td><td>Disc</td></tr><tr><td><br />Proposed</td><td>1.13</td><td>1.29</td><td>5.39</td><td>0.12</td><td>0.21</td><td>1.13</td><td>4.71</td><td>7.38</td><td>9.70</td><td>2.53</td><td>7.33</td><td>7.21</td><td> 4.010 8</td></tr><tr><td><br />CoopRegion</td><td>0.87</td><td>1.16</td><td>4.61</td><td>0.11</td><td>0.21</td><td>1.54</td><td>5.16</td><td>8.31</td><td>13.00</td><td>2.79</td><td>7.18</td><td>8.01</td><td>4.412 5</td></tr><tr><td><br />AD-Census</td><td>1.07</td><td>1.48</td><td>5.73</td><td>0.09</td><td>0.25</td><td>1.15</td><td>6.22</td><td>10.90</td><td>13.26</td><td>2.42</td><td>7.25</td><td>6.95</td><td>4.534 2</td></tr><tr><td><br />RDP</td><td>0.97</td><td>1.39</td><td>5.00</td><td>0.21</td><td>0.38</td><td>1.89</td><td>4.84</td><td>9.94</td><td>12.60</td><td>2.53</td><td>7.69</td><td>7.38</td><td>4.568 3</td></tr><tr><td><br />DistinctSM</td><td>1.21</td><td>1.75</td><td>6.39</td><td>0.35</td><td>0.69</td><td>2.63</td><td>7.45</td><td>13.02</td><td>18.10</td><td>3.91</td><td>9.91</td><td>8.32</td><td>6.144 2</td></tr><tr><td><br />ReliabilityDP</td><td>1.36</td><td>3.39</td><td>7.25</td><td>2.35</td><td>3.48</td><td>12.20</td><td>9.82</td><td>16.69</td><td>19.50</td><td>12.90</td><td>19.90</td><td>9.70</td><td>10.729 2</td></tr><tr><td><br />SAD+IGMCT</td><td>5.81</td><td>7.14</td><td>22.60</td><td>2.61</td><td>3.33</td><td>25.30</td><td>9.79</td><td>15.50</td><td>25.70</td><td>5.08</td><td>11.50</td><td>15.00</td><td>12.446 7</td></tr><tr><td><br />SSD+MF</td><td>5.23</td><td>7.07</td><td>24.10</td><td>3.74</td><td>5.16</td><td>11.90</td><td>16.50</td><td>24.80</td><td>32.90</td><td>10.60</td><td>9.80</td><td>26.30</td><td>15.675 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="132">图12所示为本算法改进前后以及Middlebury标准视差图的对比结果。相比与原算法, 由于采用了自适应权重和自适应窗口使得算法在图像区域内部和物体边缘界有了明显改进, 图像内部的孔洞现象得到改善, 边界处的纹理更加贴近真实场景。</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201914018_133.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 算法改进前后视差图对比" src="Detail/GetImg?filename=images/DZCL201914018_133.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 算法改进前后视差图对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201914018_133.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="134" name="134" class="anchor-tag"><b>3 结  论</b></h3>
                <div class="p1">
                    <p id="135">本文改进并提出了一种自适应窗口和权重的立体匹配算法, 在SAD和Census代价聚合阶段加入了自适应权重, 增加了在边界和弱纹理区域匹配的精度, 在匹配窗口选择阶段加入了自适应颜色阈值和干扰值剔除操作, 使得算法对于不同图像更加具有适应性, 增加了抗干扰性。并且通过实验对比了改进前后的匹配错误率和添加噪声前后的效果, 以及和其他算法的性能对比, 实验结果表明本文算法较改进前错误率降低了11%, 平均错误率在4%左右, 在干扰性和图像适应性上均有加强, 在不同场景下均能获得良好的视差图, 在双面测量等应用上具有明显优势。由于增加了算法复杂度, 会导致匹配时间收到影响, 后续会对如何提升匹配速度进行改进研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="5">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201811030&amp;v=MDAyNDhIOW5Ocm85R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5dmhXNzdBSWpYVGJMRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 闫利, 王芮, 刘华, 等.基于改进代价计算和自适应引导滤波的立体匹配[J].光学学报, 2018, 38 (11) :257-267.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG2C9D5E13EF97A7506380CF74A18FBC52&amp;v=MDc3MzlKMm81R0VaMEdDdzAreWhZVjZUZDlPd25scUdNMGNjVG1OcitkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeDd5M3dhQT1OaWZPYWJITEY2WA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> LEE J, JUN D, EEM C.Improved census transform for noise robust stereo matching[J].Optical Engineering, 2016, 55 (6) :063107.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Evaluation of Stereo Matching Costs on Images with Radiometric Differences">

                                <b>[3]</b> HEIKO H, SCHARSTEIN D.Evaluation of stereo matching costs on images with radiometric differences[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2008, 31 (9) :1582-1599.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBX201503010&amp;v=MTEzOTF0Rnl2aFc3N0FMU2pKZHJHNEg5VE1ySTlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 门宇博, 马宁, 张国印, 等.非参数变换和改进动态规划的立体匹配算法[J].哈尔滨工业大学学报, 2015, 47 (3) :60-65.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201712034&amp;v=MTkzMjBJalhUYkxHNEg5Yk5yWTlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2aFc3N0E=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 许金鑫, 李庆武, 刘艳, 等.基于色彩权值和树形动态规划的立体匹配算[J].光学学报, 2017, 37 (12) :289-297.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On Build an Accurate Stereo Matching System on Graphics Hardware">

                                <b>[6]</b> MEI X, SUN X, ZHOU M C, et al.On building an accurate stereo matching system on graphics hardware[C].IEEE International Conference on Computer Vision Workshops, 2011:467-474.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cross-based local stereo matching using orthogonal integral images">

                                <b>[7]</b> ZHANG K.Cross-based local stereo matching using orthogonal integral images[J].IEEE Transactions on Circuits &amp; Systems for Video Technology, 2009, 19 (7) :1073-1079.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GYKJ201803021&amp;v=MjM5MTh0R0ZyQ1VSN3FmWnVadEZ5dmhXNzdBSWpUQVpMRzRIOW5Nckk5SFpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 吕鹏程, 厉小润.基于AD-Census和多权值的自适应窗口的立体匹配算法[J].工业控制计算机, 2018 (3) :49-52.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14101300030946&amp;v=MTM5MTVRVE1ud1plWnRGaW5sVXJ6SUkxb2NheG89Tmo3QmFySzhIOUhOckk5RlpPZ1BCWGcvb0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> BESSE F, ROTHER C, FITZGIBBON A, et al.PMBP:Patch match belief propagation for correspondence field estimation[J].International Journal of Computer Vision, 2014, 110 (1) :2-13.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A region based stereo matchingalgorithm using cooperative optimization">

                                <b>[10]</b> WANG Z F, ZHENG Z G.A region based stereo matching algorithm using cooperative optimization[C].IEEE Conference on Computer Vision &amp; Pattern Recognition, 2008:1-8.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stereo matching with reliable disparity propagation">

                                <b>[11]</b> SUN X, MEI X, JIAO S H, et al.Stereo matching with reliable disparity propagation[C].International Conference on 3d Imaging, 2011:132-139.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wide baseline stereo matching with convex bounded-distortion constraints">

                                <b>[12]</b> GALUN M, Amir T, HASSNER T.Wide baseline stereo matching with convex bounded-distortion constraints[C].IEEE International Conference on Computer Vision, 2016:2228-2236.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=FPGA implementation of an efficient similarity-based adaptive window algorithm for real-time stereo matching">

                                <b>[13]</b> MADAIN P, ABIEL A.FPGA implementation of an efficient similarity-based adaptive window algorithm for real-time stereo matching[J].Journal of Real-Time Image Processing, 2015, 10 (3) :1-17.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083587&amp;v=MTE0NzdpbmxVcnpJSTFvY2F4bz1OaWZPZmJLN0h0RE5xbzlFWk9NTUNYUStvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0Rg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> KRISTIAN A.Accurate hardware-based stereo vision[J].Computer Vision &amp; Image Understanding, 2010, 114 (11) :1303-1316.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD3D4554200C902AF5475771AD5EACA887&amp;v=MzE4OTJJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4N3kzd2FBPU5pZkRhckRNR3RUSnE0MUZaSmdHREg1SXVSTVg3VHA2VDM2VDJCZEFDTUhsVGJLWUNPTnZGU2lXV3I3Sg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> AFFENDI H R, HAIDI I.Literature survey on stereo vision disparity map algorithms[J].Journal of Sensors, 2016, 2016:1-23.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201914018" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201914018&amp;v=MTk0ODNVUjdxZlp1WnRGeXZoVzc3QUlUZklZckc0SDlqTnE0OUViSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

