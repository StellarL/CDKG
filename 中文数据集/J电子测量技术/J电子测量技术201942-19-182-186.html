

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135576933850000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dDZCL201919030%26RESULT%3d1%26SIGN%3dOIBZ7sFgxGkPAQU7Ne%252byl1XcXaA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201919030&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201919030&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201919030&amp;v=MTY1NDl1WnRGeW5tV3IvUElUZklZckc0SDlqTnBvOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;1 锂电池X射线影像&lt;/b&gt; "><b>1 锂电池X射线影像</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#43" data-title="&lt;b&gt;2 以CNN为核心的电极检测方案&lt;/b&gt; "><b>2 以CNN为核心的电极检测方案</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;2.1 数据集的生成&lt;/b&gt;"><b>2.1 数据集的生成</b></a></li>
                                                <li><a href="#48" data-title="&lt;b&gt;2.2 网络架构&lt;/b&gt;"><b>2.2 网络架构</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;2.3 网络训练&lt;/b&gt;"><b>2.3 网络训练</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#66" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#67" data-title="&lt;b&gt;3.1 检测精度&lt;/b&gt;"><b>3.1 检测精度</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;3.2 性能对比&lt;/b&gt;"><b>3.2 性能对比</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#83" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#41" data-title="图1 锂电池X射线影像">图1 锂电池X射线影像</a></li>
                                                <li><a href="#46" data-title="图2 子图裁剪结果">图2 子图裁剪结果</a></li>
                                                <li><a href="#54" data-title="&lt;b&gt;表1 网络架构&lt;/b&gt;"><b>表1 网络架构</b></a></li>
                                                <li><a href="#69" data-title="图3 训练曲线与测试曲线">图3 训练曲线与测试曲线</a></li>
                                                <li><a href="#72" data-title="图4 输入图像与分类置信度输出">图4 输入图像与分类置信度输出</a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;表2 SVM交叉验证结果&lt;/b&gt;"><b>表2 SVM交叉验证结果</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;表3 不同模型结合SVM的交叉验证结果&lt;/b&gt;"><b>表3 不同模型结合SVM的交叉验证结果</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;表4 不同模型结合SVM耗时对比&lt;/b&gt;"><b>表4 不同模型结合SVM耗时对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 李然,侯俊,杨海马,等.基于卡尔曼滤波的磷酸铁锂电池SOC管理系统研究[J].仪表技术与传感器,2015(3):50-52." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YBJS201503017&amp;v=MDc0NDFDL0JmYkc0SDlUTXJJOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5tV3IvUFA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李然,侯俊,杨海马,等.基于卡尔曼滤波的磷酸铁锂电池SOC管理系统研究[J].仪表技术与传感器,2015(3):50-52.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 陈功,许清泉,朱锡芳,等.锂电池极片质量监控系统的设计和实现[J].仪表技术与传感器,2013(12):87-89." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YBJS201312030&amp;v=MDk1MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bm1Xci9QUEMvQmZiRzRIOUxOclk5R1pJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈功,许清泉,朱锡芳,等.锂电池极片质量监控系统的设计和实现[J].仪表技术与传感器,2013(12):87-89.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 刘璐,刘缠牢.基于SIFT算法的疵病图像配准[J].电子测量技术,2019,42(6):94-98." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201906018&amp;v=MzAxNDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5tV3IvUElUZklZckc0SDlqTXFZOUViSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         刘璐,刘缠牢.基于SIFT算法的疵病图像配准[J].电子测量技术,2019,42(6):94-98.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 崔雪红,刘云,常伟,等.基于HOG特征的步态能量图身份识别算法[J].电子测量技术,2017,40(7):100-104." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201707022&amp;v=MTgwNjBJVGZJWXJHNEg5Yk1xSTlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlubVdyL1A=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         崔雪红,刘云,常伟,等.基于HOG特征的步态能量图身份识别算法[J].电子测量技术,2017,40(7):100-104.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     LECUN Y,BOTTOU L,BENGIO Y,et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE,1998,86(11):2278-2324.</a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" KRIZHEVSKY A,SUTSKEVER I,HINTON G E.ImageNet classification with deep convolutional neural networks[C].Advances in Neural Information Processing Systems.2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[6]</b>
                                         KRIZHEVSKY A,SUTSKEVER I,HINTON G E.ImageNet classification with deep convolutional neural networks[C].Advances in Neural Information Processing Systems.2012:1097-1105.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" ZEILER M D,FERGUS R.Visualizing and understanding convolutional networks[C].European Conference on Computer Vision,2014:818-833." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Visualizing and understanding convolutional networks">
                                        <b>[7]</b>
                                         ZEILER M D,FERGUS R.Visualizing and understanding convolutional networks[C].European Conference on Computer Vision,2014:818-833.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     SIMONYAN K,ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J/OL].arXiv preprint,2014.https://arxiv.org/abs/1409.1556.</a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C].Proceedings of the IEEE conference on computer vision and pattern recognition,2015:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">
                                        <b>[9]</b>
                                         SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C].Proceedings of the IEEE conference on computer vision and pattern recognition,2015:1-9.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" IOFFE S,SZEGEDY C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C].International Conference on Machine Learning,2016:676-685." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization Accelerating deep network training by reducing internal covariate shift">
                                        <b>[10]</b>
                                         IOFFE S,SZEGEDY C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C].International Conference on Machine Learning,2016:676-685.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" SZEGEDY C,VANHOUCKE V,IOFFE S,et al.Rethinking the inception architecture for computer vision[C].IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rethinking the Inception Architecture for Computer Vision">
                                        <b>[11]</b>
                                         SZEGEDY C,VANHOUCKE V,IOFFE S,et al.Rethinking the inception architecture for computer vision[C].IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" SZEGEDY C,IOFFE S,VANHOUCKE V,et al.Inception-v4,inception-resnet and the impact of residual connections on learning[C].Thirty-First AAAI Conference on Artificial Intelligence.2017:4278-4284." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Inception-v4 Inception-ResNet and the Impact of Residual Connections on Learning">
                                        <b>[12]</b>
                                         SZEGEDY C,IOFFE S,VANHOUCKE V,et al.Inception-v4,inception-resnet and the impact of residual connections on learning[C].Thirty-First AAAI Conference on Artificial Intelligence.2017:4278-4284.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C].IEEE Conference on Computer Vision and Pattern Recognition,2016:770-778.</a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     HE K,ZHANG X,REN S,et al.Identity mappings in deep residual networks[C].European conference on computer vision,2016:630-645.</a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     LONG J,SHELHAMER E,DARRELL T.Fully convolutional networks for semantic segmentation[C].IEEE Conference on Computer Vision and Pattern Recognition,2015:3431-3440.</a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" SERMANET P,EIGEN D,ZHANG X,et al.Overfeat:Integrated recognition,localization and detection using convolutional networks[J/OL].arXiv preprint,2014.https://arxiv.org/abs/1312.6229." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Over Feat:Integrated Recognition,Localization and Detection using Convolutional Networks">
                                        <b>[16]</b>
                                         SERMANET P,EIGEN D,ZHANG X,et al.Overfeat:Integrated recognition,localization and detection using convolutional networks[J/OL].arXiv preprint,2014.https://arxiv.org/abs/1312.6229.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(19),182-186 DOI:10.19651/j.cnki.emt.1903238            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>利用卷积神经网络检测锂电池电极缺陷</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E4%BD%B3%E7%A6%BE&amp;code=37641327&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周佳禾</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AE%AB%E5%85%83%E4%B9%9D&amp;code=07932308&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宫元九</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BE%BD%E5%AE%81%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0033169&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辽宁大学信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>锂电池X射线影像是通过X射线成像系统获得的,通过分析X射线影像能够有效地检测锂电池电极缺陷以确保产品质量。针对锂电池电极缺陷在X射线影像中的表现特点,提出了一种以卷积神经网络(CNN)为核心的锂电池电极缺陷检测方法。为提升检测速度,构建了轻量级的CNN并利用源自电池电极区域的小尺寸图像完成训练,将电池电极完整区域图像通过CNN提取的特征送入支持向量SVM机给出最终预测检测结果。实验结果表明,该方法具有较高的检测速度,检测的准确性优于99%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%94%82%E7%94%B5%E6%B1%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">锂电池;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    宫元九,教授,主要研究方向为数字图像处理、机器学习,E-mail:gongyj@lnu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-23</p>

            </div>
                    <h1><b>Detection of Electrode Defects in Lithium Batteries Based on Convolutional Neural Networks</b></h1>
                    <h2>
                    <span>Zhou Jiahe</span>
                    <span>Gong Yuanjiu</span>
            </h2>
                    <h2>
                    <span>College of Information Liaoning University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The X-ray image of lithium battery is obtained by X-ray imaging system. The electrode defects of lithium batteries can be effectively detected through the analysis of X-ray images to ensure product quality, thereby guaranteeing safety quality of products. A method for detecting electrode defects of lithium battery based on convolution neural network(CNN) is proposed by taking advantage of expression characteristics of electrode defects in lithium batteries in X-ray imaging. In order to improve the detection speed, a lightweight CNN is constructed. The training was accomplished by using small-size images cropped from the battery electrode region. The output of the image of the complete area of battery electrodes through convolution neural network were classified using support vector machine(SVM). Finally, the predictive test results were obtained. The experimental results show that the method has high detection speed and the accuracy of detection is better than 99%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=CNN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">CNN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=lithium%20battery&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">lithium battery;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SVM%201&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SVM 1;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-06-23</p>
                            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="36">锂离子电池是一种二次电池,广泛应用于电动汽车、移动电话、平板电脑等领域。在封装方式上,锂电池有圆柱卷绕式、方形层叠式和方形卷绕式等几种重要构型。其中,方形卷绕式集成了圆柱卷绕式与方形层叠式各自的有点,具有较高的空间利用率,是便携数码产品的首选。锂电池在生产过程中需采用多种手段确保产品质量<citation id="87" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>,其中X射线检测是常见的品控手段之一。利用X射线的穿透性穿透锂电池,经由图像增强器及相机形成锂电池的X射线影像供图像分析检测之用。</p>
                </div>
                <div class="p1">
                    <p id="37">早期的图像处理分析方法多依赖于人工定义的特征,如SIFT<citation id="88" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、SURF、HOG<citation id="89" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等。随着深度学习的发展特别是卷积神经网络(Convolutional Neural Networks, CNN)的日趋完善,传统的模式分类方法逐步让位于CNN。第一个成功的CNN模型LeNet-5是LeCun等<citation id="90" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>于1998年提出的,用于识别手写体的阿拉伯数字。LeNet-5中的卷积与池化操作、局部连接权值共享理念为CNN的后续发展奠定了坚实的基础。经过十余年的沉寂后,Krizhevsky等<citation id="91" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>于2012年推出了结合深度学习理念的AlexNet,在性能上显著超越了基于SIFT的传统模式分类方法。在网络组成上,AlexNet提出了新的非线性激活函数ReLU(rectified linear units)替代传统的sigmoid,提升了CNN深度增加的潜力。2013年,Zeiler等<citation id="92" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>人在AlexNet的基础上,在第一个卷积层使用7×7的卷积核,提高了CNN感知细节的能力。2014年出现了两种性能接近但架构迥异的CNN模型,VGG<citation id="93" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>与GoogLeNet<citation id="94" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。VGG在理念上使用多层小卷积核替代大卷积核,使之具有相同的感受域且计算量减少,在构成上使用单一的3x3卷积核,结构简洁清晰,成为后续不同应用迁移学习的首选。GoogLeNet的特点在于其Inception架构,同时将网络深度增加到了22层。GoogLeNet诸多改进版本<citation id="98" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>中提出的批归一化(batch normalization, BN)<citation id="95" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>操作加快了网络的训练速度、提升了网络泛化能力。无论是VGG的分阶段训练,还是GoogLeNet的辅助分类训练,都暗示着尽管使用了ReLU,反向传播时的梯度消失问题依然存在,CNN深度的增加依然存在限制。2015年,He等<citation id="96" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出了ResNets,使用残差学习架构,显著降低了梯度消失问题的影响<citation id="97" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。ResNets在网络深度上提高到152层,性能上超越了人类的极限。</p>
                </div>
                <div class="p1">
                    <p id="38">本文介绍一种以CNN为核心的锂电池电极缺陷检测方法,以期在检测速度与准确性两方面均满足生产流程的要求。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag"><b>1 锂电池X射线影像</b></h3>
                <div class="p1">
                    <p id="40">图1(a)所示为阳极卷绕层数为10层的方形卷绕式良品锂电池其中一角的X射线影像。从图1中容易看出,X射线覆盖的区域为圆形,图中部高亮度的部分是空白区域,四周成黑色的区域是X射线未覆盖区域。在右下角的电极区域中,亮度偏高的区域是锂电池的阳极,亮度偏低的区域是阳极与阴极的混合区域。图1(b)所示是阳极卷绕层数为6层的锂电池电极影像。可以看出,其阳极外层出现了明显的褶皱,可判缺陷电极。</p>
                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919030_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 锂电池X射线影像" src="Detail/GetImg?filename=images/DZCL201919030_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 锂电池X射线影像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919030_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="42">锂电池电极缺陷绝大多数出现在阳极区域,特别是阳极的外层区域。X射线成像系统需分别针对每块电池的四角分别生成4幅图像,每幅图像中电池电极有效区域的位置各不相同,分析处理时需经翻转或旋转处理将电池电极有效区域统一至固定区域(本文中统一使用右下角区域)。从完整电池影像的角度看,电极缺陷覆盖的区域占比较小,直接使用完整电池影像训练CNN,势必要求CNN具有较深的架构,这将严重影响检测速度。</p>
                </div>
                <h3 id="43" name="43" class="anchor-tag"><b>2 以CNN为核心的电极检测方案</b></h3>
                <h4 class="anchor-tag" id="44" name="44"><b>2.1 数据集的生成</b></h4>
                <div class="p1">
                    <p id="45">电池X射线影像经过位置调整、倾斜校正和图像分割后,获得独立的电极有效区域图像。利用电极有效区域图像,以10 pixel的步长依次裁剪出尺寸为95×95的100张子图。图2所示为图1(b)中电极有效区域经裁剪后获得的子图汇总。为了弥补CNN有限的旋转不变性,电极有效区域图像在分别经过±1°和±2°旋转后采用相同的子图裁剪方法,获得另外400张子图。这样,一幅电池X射线影像即可生成500张数据集所需的子图。在图2所示的100张子图中,源自电池电极缺陷区域的子图被标注为负例样例,源自无缺陷区域的子图可标注为正例样例或弃用。采用小尺寸子图构建数据集,容易提升数据集的规模。不仅如此,在小尺寸的子图图像中,电极缺陷区域的占比会有所提高,负例样例与正例例样例的对比较为强烈,CNN网络规模相应降低,训练所需的计算量与耗时则显著减少。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919030_046.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 子图裁剪结果" src="Detail/GetImg?filename=images/DZCL201919030_046.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 子图裁剪结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919030_046.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="47">本文所用训练集、验证集和测试集中的样例,分别源自不同电池的X射线影像,以保持相对独立。训练集中样例的数量是48万,验证集和测试集中样例的数量是5万。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48"><b>2.2 网络架构</b></h4>
                <div class="p1">
                    <p id="49">本文提出的CNN网络架构,是一种全卷积网络<citation id="99" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>,如表1所示。</p>
                </div>
                <div class="p1">
                    <p id="50">去均值处理是CNN输入图像通常的预处理手段,为了灵活地适应不同的数据集,将图像的预处理加入了网络的第一层,借鉴BN的思路实现图像归一化处理,并通过学习适度微调。</p>
                </div>
                <div class="p1">
                    <p id="51"><i>μ</i><sub><i>g</i></sub>=<i>E</i><sub><i>B</i></sub>[<i>μ</i><sub><i>B</i></sub>]      (1)</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>V</mi><mi>a</mi><mi>r</mi><msub><mrow></mrow><mi>g</mi></msub><mo>=</mo><mfrac><mi>m</mi><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></mfrac><mi>E</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">[</mo><mi>σ</mi><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>y</mi><mo>=</mo><mi>γ</mi><mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi><msub><mrow></mrow><mi>g</mi></msub></mrow><mrow><msqrt><mrow><mi>V</mi><mi>a</mi><mi>r</mi><msub><mrow></mrow><mi>g</mi></msub><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac><mo>+</mo><mi>β</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">式中:<i>μ</i><sub><i>B</i></sub>与<i>σ</i><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>B</mi><mn>2</mn></msubsup></mrow></math></mathml>分别是minibatch的均值与方差,在网络训练阶段用于估计训练集的均值<i>μ</i><sub><i>g</i></sub>与方差<i>Var</i><sub><i>g</i></sub>,使用一阶IIR低通滤波器实现;<i>x</i>与<i>y</i>是第一层网络的输入与输出,输入经归一化处理后又加入了缩放及平移处理,以期改善训练集中图像灰度分布的偏差;<i>γ</i>与<i>β</i>分别是待学习的缩放与平移因子,将与均值<i>μ</i><sub><i>g</i></sub>及方差<i>Var</i><sub><i>g</i></sub>一并存入网络的模型参数中;与标准BN略有不同的是,在训练与推理阶段均使用式(3)完成第一层的预处理操作,计算所用的均值与方差也同为<i>μ</i><sub><i>g</i></sub>与<i>Var</i><sub><i>g</i></sub>;<i>ε</i>是常规的保护参数,用于避免计算出现异常。</p>
                </div>
                <div class="area_img" id="54">
                    <p class="img_tit"><b>表1 网络架构</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="54" border="1"><tr><td><br />网络层</td><td>卷积核<br />尺寸</td><td>卷积<br />步长</td><td>池化<br />尺寸</td><td>池化<br />步长</td><td>输出</td></tr><tr><td><br />BN′</td><td>-</td><td>-</td><td>-</td><td>-</td><td>95×95×1</td></tr><tr><td><br />conv</td><td>7×7</td><td>2×2</td><td></td><td></td><td>48×48×16</td></tr><tr><td><br />max-pool</td><td>-</td><td>-</td><td>2×2</td><td>2×2</td><td>24×24×16</td></tr><tr><td><br />conv</td><td>3×3</td><td>1×1</td><td>-</td><td>-</td><td>24×24×16</td></tr><tr><td><br />conv</td><td>3×3</td><td>1×1</td><td>-</td><td>-</td><td>24×24×16</td></tr><tr><td><br />conv</td><td>1×1</td><td>1×1</td><td>-</td><td>-</td><td>24×24×32</td></tr><tr><td><br />max-pool</td><td>-</td><td>-</td><td>2×2</td><td>2×2</td><td>12×12×32</td></tr><tr><td><br />conv</td><td>3×3</td><td>1×1</td><td>-</td><td>-</td><td>12×12×32</td></tr><tr><td><br />conv</td><td>3×3</td><td>1×1</td><td>-</td><td>-</td><td>12×12×32</td></tr><tr><td><br />conv</td><td>1×1</td><td>1×1</td><td>-</td><td>-</td><td>12×12×48</td></tr><tr><td><br />max-pool</td><td>-</td><td>-</td><td>2×2</td><td>2×2</td><td>6×6×48</td></tr><tr><td><br />conv</td><td>6×6</td><td>1×1</td><td>-</td><td>-</td><td>1×1×256</td></tr><tr><td><br />conv</td><td>1×1</td><td>1×1</td><td>-</td><td>-</td><td>1×1×256</td></tr><tr><td><br />fc+softmax</td><td>-</td><td>-</td><td>-</td><td>-</td><td>1×1×2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="56">第一个卷积层使用了7×7的卷积核,是用于分类的CNN模型中常见配置,同时采用了2×2的步长进行下采样。最后的2个卷积层分别使用了6×6和1×1的卷积核,训练时这个2个卷积层与全连接层等价,推理时可以自适应输入图像的尺寸变化。输出层是常规的fc+softmax层,训练阶段该层的输出为1×1×2,是针对正例和负例的分类置信度,推理阶段该层的输出为<i>m</i>×<i>n</i>×2,其中<i>m</i>与<i>n</i>与输入图像的尺寸相关,可视为两幅分类置信度结果图,分别对应负例与正例。</p>
                </div>
                <div class="p1">
                    <p id="57">在网络中,所有的卷积层都加入了BN操作,每个卷积层的非线性激活函数均为ReLU。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58"><b>2.3 网络训练</b></h4>
                <div class="p1">
                    <p id="59">网络训练所用代价函数的主体为交叉熵,为提高网络的泛化能力,在代价函数中增加了正则项,同时引入了dropout机制。</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mi>log</mi></mrow></mstyle><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>w</mi><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">式中:<i>m</i>=128,是minibatch的规模;<i>y</i><sub><i>i</i></sub>是minibatch中第<i>i</i>个样例的分类置信度;<i>w</i>是网络各层中的突触权值;<i>λ</i>=1.0×10<sup>-3</sup>,是正则项系数。</p>
                </div>
                <div class="p1">
                    <p id="62">网络训练使用了带有动量项<citation id="100" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>的随机梯度下降法,网络中参数的更新规则为:</p>
                </div>
                <div class="p1">
                    <p id="63"><i>v</i><sub><i>j</i></sub><sub>+1</sub>:<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mi>μ</mi><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo>-</mo><mi>η</mi><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>θ</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="64"><i>θ</i><sub><i>j</i></sub><sub>+1</sub>:=<i>θ</i><sub><i>j</i></sub>+<i>v</i><sub><i>j</i></sub><sub>+1</sub>      (6)</p>
                </div>
                <div class="p1">
                    <p id="65">式中:<i>θ</i>是网络中待学习的参数;<i>v</i>是动量项;<i>μ</i>=0.6是动量项系数;<i>η</i>是学习率,其初值为0.01,随训练逐回合呈指数下降,到第100回合时降为5.0×10<sup>4</sup>。</p>
                </div>
                <h3 id="66" name="66" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <h4 class="anchor-tag" id="67" name="67"><b>3.1 检测精度</b></h4>
                <div class="p1">
                    <p id="68">使用0.8的dropout概率训练表1所示网络,训练的回合数为100。图3所示为训练过程中训练精度及测试精度的变化曲线,测试精度的最优值为99.22%。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919030_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 训练曲线与测试曲线" src="Detail/GetImg?filename=images/DZCL201919030_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 训练曲线与测试曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919030_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="70">对于待检测电池的X射线影像,经位置调整与倾斜校正后,从电极有效区域中裁剪出尺寸为275×275的图像。将该图像输入至已经训练完毕的CNN模型中,输出的维度为12×12×2,选择其中与负例对应的预测置信度结果图作为网络的预测输出。该预测置信度结果图一方面展示了CNN预测输出的可视化效果,另一方面也将被作为待检测电极图像的特征向量用于后续进一步的分类处理。</p>
                </div>
                <div class="p1">
                    <p id="71">全卷积网络的特点在于训练与预测可以分别使用尺寸不同的图像,在速度上优于直观的滑动窗口方法<citation id="101" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。图4所示为网络输入的电极图像及网络的预测输出,网络的预测输出是尺寸为12×12的置信度结果图。图4(a)是有缺陷的电极图像,图4(c)为其预测置信度结果图,出于便于对比的目的,该图经过了适度地放大。高亮度区域反映了电极缺陷预测具有较高的置信度,同时标明了电极缺陷的大体位置。图4(b)是无缺陷的电极图像,图4(d)为其预测置信度结果图,置信度结果图亮度极低,与图4(c)形成鲜明对比。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201919030_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 输入图像与分类置信度输出" src="Detail/GetImg?filename=images/DZCL201919030_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 输入图像与分类置信度输出  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201919030_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="73">根据置信度结果图的平均值,经统计后合理设置阈值,即可较好地区分良品电极与缺陷电极。在电极影像数量有限的条件下,使用支持向量机(SVM)则可以更加有效地降低置信风险。即视CNN为特征提取器,利用其预测输出的置信度结果图作为特征训练SVM,并以SVM的分类输出作为电池电极缺陷的最终检测结果。</p>
                </div>
                <div class="p1">
                    <p id="74">在两种情况下会出现电极有效区域过小的可能,即电池的卷绕层数较少或成像时电池位置过于靠近成像系统覆盖区域边缘,这可能导致网络预测所需的图像尺寸小于275×275,预测输出的尺寸小于12×12。针对此种情况,可以对输入图像进行补零将其调整为275×275,或着对输出预测置信度结果图进行补零调整至12×12,两种处理方法的效果完全相同。</p>
                </div>
                <div class="p1">
                    <p id="75">表2所示为使用10折叠交叉验证训练SVM的相关实验结果数据。所用数据集中包括11 355幅缺陷电极图像和10 426幅良品电池图像,SVM选用高斯核函数,惩罚因子设为1.0。交叉验证的平均精度为99.20%,与CNN相比略低但基本相当。</p>
                </div>
                <div class="p1">
                    <p id="76">在效率方面,在i5-4570+GTX1050的硬件平台上,CNN提取特征的平均耗时为8.5 ms,SVM分类预测的平均耗时为0.28 ms。</p>
                </div>
                <div class="area_img" id="77">
                    <p class="img_tit"><b>表2 SVM交叉验证结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="77" border="1"><tr><td><br />K</td><td>测试精度/%</td></tr><tr><td><br />1</td><td>99.38</td></tr><tr><td><br />2</td><td>99.44</td></tr><tr><td><br />3</td><td>99.08</td></tr><tr><td><br />4</td><td>99.08</td></tr><tr><td><br />5</td><td>99.20</td></tr><tr><td><br />6</td><td>99.20</td></tr><tr><td><br />7</td><td>99.14</td></tr><tr><td><br />8</td><td>99.26</td></tr><tr><td><br />9</td><td>99.14</td></tr><tr><td><br />10</td><td>99.08</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="78" name="78"><b>3.2 性能对比</b></h4>
                <div class="p1">
                    <p id="79">表3所示为采用4种不同方法提取特征训练SVM的10折叠交叉验证结果。其中,HOG特征属于传统的图像处理手段,其余3种均为基于深度学习的CNN模型。从中不难看出,HOG+SVM的性能明显偏低是意料之中的,而使用ResNet50+SVM的检测精度最高,但仍低于本文提出的方法。</p>
                </div>
                <div class="area_img" id="80">
                    <p class="img_tit"><b>表3 不同模型结合SVM的交叉验证结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="80" border="1"><tr><td><br />K</td><td>HOG/<br />%</td><td>VGG16/<br />%</td><td>ResNet50/<br />%</td><td>MobileNetV2/<br />%</td></tr><tr><td><br />1</td><td>84.63</td><td>90.71</td><td>96.80</td><td>88.60</td></tr><tr><td><br />2</td><td>83.60</td><td>92.16</td><td>97.06</td><td>89.32</td></tr><tr><td><br />3</td><td>83.30</td><td>93.12</td><td>95.75</td><td>87.58</td></tr><tr><td><br />4</td><td>84.56</td><td>91.44</td><td>97.12</td><td>88.12</td></tr><tr><td><br />5</td><td>81.73</td><td>93.30</td><td>96.47</td><td>89.08</td></tr><tr><td><br />6</td><td>82.94</td><td>92.22</td><td>96.80</td><td>88.60</td></tr><tr><td><br />7</td><td>83.48</td><td>92.76</td><td>95.88</td><td>87.52</td></tr><tr><td><br />8</td><td>83.72</td><td>91.80</td><td>96.80</td><td>88.96</td></tr><tr><td><br />9</td><td>82.39</td><td>91.80</td><td>95.95</td><td>89.14</td></tr><tr><td><br />10</td><td>84.63</td><td>93.30</td><td>96.99</td><td>88.54</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="81">表4所示为不同模型在特征提取与SVM预测阶段的耗时对比。针对不同模型的特点,在输入图像尺寸上采用了不同的设置。除了HOG特征提取采用256×256外,其余CNN模型均设置为缺省的224×224。其中,MobileNetV2+SVM的组合在检测速度上与本文方法接近,但表3中反映的其检测精度则明显低于本文方法。需说明的是,VGG16在特征提取时的耗时显著偏高,其重要的原因之一是,本文实验所用的GTX1050内存偏低,无法支持VGG16过于庞大的模型,导致VGG16在特征提取时只能在CPU上运行。但是,从VGG16、ResNet50与MobileNetV2的参数数量对比可知,即使在相同的硬件平台上,VGG16的运算耗时也将高于ResNet50与MobileNetV2。</p>
                </div>
                <div class="area_img" id="82">
                    <p class="img_tit"><b>表4 不同模型结合SVM耗时对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="82" border="1"><tr><td><br />模型</td><td>输入图像<br />尺寸</td><td>特征向量<br />长度</td><td>特征提取<br />耗时/ms</td><td>SVM预测<br />耗时/ms</td></tr><tr><td><br />HOG</td><td>256×256</td><td>8 100</td><td>10.6</td><td>52.1</td></tr><tr><td><br />VGG16</td><td>224×224</td><td>4 096</td><td>471.2</td><td>14.2</td></tr><tr><td><br />ResNet50</td><td>224×224</td><td>2 048</td><td>27.8</td><td>5.5</td></tr><tr><td><br />MobileNetV2</td><td>224×224</td><td>1 280</td><td>13.6</td><td>6.7</td></tr><tr><td><br />本文</td><td>275×275</td><td>144</td><td>8.5</td><td>0.28</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="83" name="83" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="84">利用CNN结合SVM检测锂电池电极缺陷可以实现较高的准确率,检测速度也能够满足生产流程的要求。进一步提高检测精度,可以考虑以下两个方面,一方面,改善X射线成像系统,减少成像环境对电池影像质量的的影响;另一方面,减小不同电极缺陷类别样例之间的数量差异,优化训练样本的均衡度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YBJS201503017&amp;v=MjE3MTgvUFBDL0JmYkc0SDlUTXJJOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5tV3I=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李然,侯俊,杨海马,等.基于卡尔曼滤波的磷酸铁锂电池SOC管理系统研究[J].仪表技术与传感器,2015(3):50-52.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YBJS201312030&amp;v=MDM3NTMzenFxQnRHRnJDVVI3cWZadVp0RnlubVdyL1BQQy9CZmJHNEg5TE5yWTlHWklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈功,许清泉,朱锡芳,等.锂电池极片质量监控系统的设计和实现[J].仪表技术与传感器,2013(12):87-89.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=DZCL201906018&amp;v=MTYxMzlQSVRmSVlyRzRIOWpNcVk5RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bm1Xci8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 刘璐,刘缠牢.基于SIFT算法的疵病图像配准[J].电子测量技术,2019,42(6):94-98.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201707022&amp;v=MTI0MjNJWXJHNEg5Yk1xSTlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlubVdyL1BJVGY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 崔雪红,刘云,常伟,等.基于HOG特征的步态能量图身份识别算法[J].电子测量技术,2017,40(7):100-104.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 LECUN Y,BOTTOU L,BENGIO Y,et al.Gradient-based learning applied to document recognition[J].Proceedings of the IEEE,1998,86(11):2278-2324.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[6]</b> KRIZHEVSKY A,SUTSKEVER I,HINTON G E.ImageNet classification with deep convolutional neural networks[C].Advances in Neural Information Processing Systems.2012:1097-1105.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Visualizing and understanding convolutional networks">

                                <b>[7]</b> ZEILER M D,FERGUS R.Visualizing and understanding convolutional networks[C].European Conference on Computer Vision,2014:818-833.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 SIMONYAN K,ZISSERMAN A.Very deep convolutional networks for large-scale image recognition[J/OL].arXiv preprint,2014.https://arxiv.org/abs/1409.1556.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">

                                <b>[9]</b> SZEGEDY C,LIU W,JIA Y,et al.Going deeper with convolutions[C].Proceedings of the IEEE conference on computer vision and pattern recognition,2015:1-9.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization Accelerating deep network training by reducing internal covariate shift">

                                <b>[10]</b> IOFFE S,SZEGEDY C.Batch normalization:Accelerating deep network training by reducing internal covariate shift[C].International Conference on Machine Learning,2016:676-685.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rethinking the Inception Architecture for Computer Vision">

                                <b>[11]</b> SZEGEDY C,VANHOUCKE V,IOFFE S,et al.Rethinking the inception architecture for computer vision[C].IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Inception-v4 Inception-ResNet and the Impact of Residual Connections on Learning">

                                <b>[12]</b> SZEGEDY C,IOFFE S,VANHOUCKE V,et al.Inception-v4,inception-resnet and the impact of residual connections on learning[C].Thirty-First AAAI Conference on Artificial Intelligence.2017:4278-4284.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C].IEEE Conference on Computer Vision and Pattern Recognition,2016:770-778.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 HE K,ZHANG X,REN S,et al.Identity mappings in deep residual networks[C].European conference on computer vision,2016:630-645.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 LONG J,SHELHAMER E,DARRELL T.Fully convolutional networks for semantic segmentation[C].IEEE Conference on Computer Vision and Pattern Recognition,2015:3431-3440.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Over Feat:Integrated Recognition,Localization and Detection using Convolutional Networks">

                                <b>[16]</b> SERMANET P,EIGEN D,ZHANG X,et al.Overfeat:Integrated recognition,localization and detection using convolutional networks[J/OL].arXiv preprint,2014.https://arxiv.org/abs/1312.6229.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201919030" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201919030&amp;v=MTY1NDl1WnRGeW5tV3IvUElUZklZckc0SDlqTnBvOUdaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

