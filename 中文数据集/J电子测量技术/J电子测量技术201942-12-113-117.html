

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135689138850000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201912019%26RESULT%3d1%26SIGN%3d1nyd4IRriEvrvXU0Mwx%252bPbyEm98%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201912019&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201912019&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201912019&amp;v=MTc4MjFUZklZckc0SDlqTnJZOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVjcvT0k=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="&lt;b&gt;1 迁移学习&lt;/b&gt; "><b>1 迁移学习</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="&lt;b&gt;2 基于迁移学习的人脸图像质量评估模型&lt;/b&gt; "><b>2 基于迁移学习的人脸图像质量评估模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;2.1 源模型&lt;/b&gt;"><b>2.1 源模型</b></a></li>
                                                <li><a href="#57" data-title="&lt;b&gt;2.2 学习目标模型&lt;/b&gt;"><b>2.2 学习目标模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;3 实验与分析&lt;/b&gt; "><b>3 实验与分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="&lt;b&gt;3.1 实验数据集&lt;/b&gt;"><b>3.1 实验数据集</b></a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;3.2 实验一:针对单一失真类型的人脸数据&lt;/b&gt;"><b>3.2 实验一:针对单一失真类型的人脸数据</b></a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;3.3 针对所有失真类型的人脸图像和针对具体失真类型的人脸图像实验&lt;/b&gt;"><b>3.3 针对所有失真类型的人脸图像和针对具体失真类型的人脸图像实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#74" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="图1 标准卷积和深度可分离卷积的结构">图1 标准卷积和深度可分离卷积的结构</a></li>
                                                <li><a href="#59" data-title="图2 学习一个目标模型">图2 学习一个目标模型</a></li>
                                                <li><a href="#64" data-title="&lt;b&gt;表1 人脸数据集统计表&lt;/b&gt;"><b>表1 人脸数据集统计表</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;表2 模糊人脸图像不同模型下的实验结果&lt;/b&gt;"><b>表2 模糊人脸图像不同模型下的实验结果</b></a></li>
                                                <li><a href="#69" data-title="图3 准确率变化曲线">图3 准确率变化曲线</a></li>
                                                <li><a href="#72" data-title="图4 准确率变化曲线图">图4 准确率变化曲线图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="91">


                                    <a id="bibliography_1" title=" 高修峰, 张培仁, 李子青.人脸图像质量评估标准[J].小型微型计算机系统, 2009, 30 (1) :95-99." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX200901021&amp;v=MDgwMTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WNy9PUFRYY2RyRzRIdGpNcm85SFpZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         高修峰, 张培仁, 李子青.人脸图像质量评估标准[J].小型微型计算机系统, 2009, 30 (1) :95-99.
                                    </a>
                                </li>
                                <li id="93">


                                    <a id="bibliography_2" title=" 陈志轩, 周大可, 黄经纬.基于卷积神经网络的表情不变三维人脸识别[J].电子测量技术, 2017, 40 (4) :157-161, 171." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201704035&amp;v=MjE0NTMzenFxQnRHRnJDVVI3cWZadVp0RnlyblY3L09JVGZJWXJHNEg5Yk1xNDlHWVlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈志轩, 周大可, 黄经纬.基于卷积神经网络的表情不变三维人脸识别[J].电子测量技术, 2017, 40 (4) :157-161, 171.
                                    </a>
                                </li>
                                <li id="95">


                                    <a id="bibliography_3" title=" 王亚, 朱明, 刘成林.基于CNN的监控视频中人脸图像质量评估[J].计算机系统应用, 2018, 27 (11) :71-77." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201811010&amp;v=MDM5ODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVjcvT1BUblNkN0c0SDluTnJvOUVaSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         王亚, 朱明, 刘成林.基于CNN的监控视频中人脸图像质量评估[J].计算机系统应用, 2018, 27 (11) :71-77.
                                    </a>
                                </li>
                                <li id="97">


                                    <a id="bibliography_4" title=" DONAHUE J, JIA Y, VINVALS O, et al.Decaf:A deep convolutional activation feature for generic visual recognition[C].International conference on machine learning, 2014:647-655." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=De CAF:A Deep Convolutional Activation Feature for Generic Visual Recognition">
                                        <b>[4]</b>
                                         DONAHUE J, JIA Y, VINVALS O, et al.Decaf:A deep convolutional activation feature for generic visual recognition[C].International conference on machine learning, 2014:647-655.
                                    </a>
                                </li>
                                <li id="99">


                                    <a id="bibliography_5" title=" KANG L, YE P, LI Y, et al.Convolutional neural networks for no-reference image quality assessment[C].In Proceedings of the IEEE conference on computer vision and pattern recognition, 2014:1733-1740." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for no-reference image quality assessment">
                                        <b>[5]</b>
                                         KANG L, YE P, LI Y, et al.Convolutional neural networks for no-reference image quality assessment[C].In Proceedings of the IEEE conference on computer vision and pattern recognition, 2014:1733-1740.
                                    </a>
                                </li>
                                <li id="101">


                                    <a id="bibliography_6" title=" 胡杨庆, 童卫青.人脸图像质量评价法[J].现代计算机 (专业版) , 2007 (12) :43-45, 49." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS200712015&amp;v=MTQwMDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WNy9PUFNuQmZiRzRIdGJOclk5RVlZUUs=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         胡杨庆, 童卫青.人脸图像质量评价法[J].现代计算机 (专业版) , 2007 (12) :43-45, 49.
                                    </a>
                                </li>
                                <li id="103">


                                    <a id="bibliography_7" title=" 李秋珍, 栾朝阳, 汪双喜.基于卷积神经网络的人脸图像质量评价[J].计算机应用, 2019, 39 (3) :695-699." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903014&amp;v=MTYyNjc0SDlqTXJJOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVjcvT0x6N0JkN0c=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         李秋珍, 栾朝阳, 汪双喜.基于卷积神经网络的人脸图像质量评价[J].计算机应用, 2019, 39 (3) :695-699.
                                    </a>
                                </li>
                                <li id="105">


                                    <a id="bibliography_8" title=" HOWARD A G, ZHU M, CHEN B, et al.MobileNets:Efficient Convolutional Neural Networks for Mobile Vision Applications[J/OL].arXiv e-prints, 2017.https://arxiv.org/abs/1704.04861" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mobilenets:efficient convolutional neural networks for mobile vision applications">
                                        <b>[8]</b>
                                         HOWARD A G, ZHU M, CHEN B, et al.MobileNets:Efficient Convolutional Neural Networks for Mobile Vision Applications[J/OL].arXiv e-prints, 2017.https://arxiv.org/abs/1704.04861
                                    </a>
                                </li>
                                <li id="107">


                                    <a id="bibliography_9" title=" 余化鹏, 张朋, 朱进.基于深度迁移学习的人脸识别方法研究[J].成都大学学报 (自然科学版) , 2017, 36 (2) :151-156." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CDDD201702009&amp;v=MTY4NjhIOWJNclk5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WNy9PSmluUGFyRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         余化鹏, 张朋, 朱进.基于深度迁移学习的人脸识别方法研究[J].成都大学学报 (自然科学版) , 2017, 36 (2) :151-156.
                                    </a>
                                </li>
                                <li id="109">


                                    <a id="bibliography_10" title=" GROTHER P J, QUINN G W, PHILLIPS P J.Report on the evaluation of 2D still-image face recognition algorithms:NIST Interagency Report:7709 [R].[doi:10.6028/NIST.IR.7709], 2010:106." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Report on the evaluation of 2D still-image face recognition algorithms">
                                        <b>[10]</b>
                                         GROTHER P J, QUINN G W, PHILLIPS P J.Report on the evaluation of 2D still-image face recognition algorithms:NIST Interagency Report:7709 [R].[doi:10.6028/NIST.IR.7709], 2010:106.
                                    </a>
                                </li>
                                <li id="111">


                                    <a id="bibliography_11" title=" 滕秋霞, 沈天飞, 杨金霄.基于多肤色模型的人脸检测系统研究[J].电子测量技术, 2015, 38 (9) :47-51." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201509011&amp;v=MjM4MjFUZklZckc0SDlUTXBvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVjcvT0k=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         滕秋霞, 沈天飞, 杨金霄.基于多肤色模型的人脸检测系统研究[J].电子测量技术, 2015, 38 (9) :47-51.
                                    </a>
                                </li>
                                <li id="113">


                                    <a id="bibliography_12" title=" 邹国锋, 傅桂霞, 李震梅, 等.融合二级评价指标的人脸图像质量评价方法[J].山东大学学报 (工学版) , 2016, 46 (2) :6-13." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SDGY201602002&amp;v=MzEyNzJyWTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblY3L09OaW5NZDdHNEg5Zk0=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         邹国锋, 傅桂霞, 李震梅, 等.融合二级评价指标的人脸图像质量评价方法[J].山东大学学报 (工学版) , 2016, 46 (2) :6-13.
                                    </a>
                                </li>
                                <li id="115">


                                    <a id="bibliography_13" title=" YANG Z G, AI H Z, WU B, et al.Face pose estimation and its application in video shot selection [C].Proceedings of the international conference on Pattern Recognition (ICPR) , Piscataway, NJ:IEEE, 2004:322-325." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face pose estimation and its application in video shot selection">
                                        <b>[13]</b>
                                         YANG Z G, AI H Z, WU B, et al.Face pose estimation and its application in video shot selection [C].Proceedings of the international conference on Pattern Recognition (ICPR) , Piscataway, NJ:IEEE, 2004:322-325.
                                    </a>
                                </li>
                                <li id="117">


                                    <a id="bibliography_14" title=" 杨源.基于深度学习的不良图片过滤技术研究[D].北京:北方工业大学, 2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018180246.nh&amp;v=MDYwMjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblY3L09WRjI2RnJLd0h0UElxWkViUElRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         杨源.基于深度学习的不良图片过滤技术研究[D].北京:北方工业大学, 2018.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_15" title=" CHEN JS, DENG Y, BAI GC.et al.Face image Quality assessment based on learning to rank[J].IEEE Signal Processing Letters, 2015, 22 (1) :9094." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face image quality assessment based on learning to rank">
                                        <b>[15]</b>
                                         CHEN JS, DENG Y, BAI GC.et al.Face image Quality assessment based on learning to rank[J].IEEE Signal Processing Letters, 2015, 22 (1) :9094.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(12),113-117 DOI:10.19651/j.cnki.emt.1802537            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于迁移学习的人脸图像质量评估</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E6%8D%A2%E6%96%B0&amp;code=23396858&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程换新</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BE%AF%E6%99%93%E5%85%8B&amp;code=42200478&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">侯晓克</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%9D%92%E5%B2%9B%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%87%AA%E5%8A%A8%E5%8C%96%E4%B8%8E%E7%94%B5%E5%AD%90%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0229824&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">青岛科技大学自动化与电子工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着科学技术和经济的快速发展以及社会的不断进步, 人们的安全意识不断提高, 人脸识别这一生物特征识别的关键技术之一被广泛应用于电子政务、计算机登录、门禁和电子商务等领域。但实际应用中输入人脸的图片质量严重影响到了人脸识别系统发挥其准确性及智能性, 因此针对人脸图像质量的问题提出基于迁移学习的人脸图像质量评估算法。在识别之前, 对自建的人脸图像数据集归一化预处理后, 再将数据集在tensorflow的框架上利用迁移学习的方式对Mobilenet网络再次训练, 得到人脸图像的质量评估模型, 过滤筛选出符合识别算法质量要求的人脸图像。并将本论文的方法与Inception模型对比, 实验表明迁移压缩后的Mobilenet模型的准确率略有降低, 但模型的参数量也大幅减少, 因此, 提高了模型的运算效率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">迁移学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Mobilenet&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Mobilenet;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像质量评价;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BC%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸图像质量评估;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    程换新, 教授, 博士, 硕士生导师, 主要研究方向为控制理论与应用。;
                                </span>
                                <span>
                                    侯晓克, 硕士研究生, 主要研究方向为控制工程。E-mail:1525100783@qq.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12</p>

            </div>
                    <h1><b>Quality evaluation of face image based on transfer learning</b></h1>
                    <h2>
                    <span>Cheng Huanxin</span>
                    <span>Hou Xiaoke</span>
            </h2>
                    <h2>
                    <span>College of Automation and Electronic Engineering, Qingdao University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the rapid development of science and technology and economy as well as the continuous progress of society, people′s safety awareness has been constantly improved. Face recognition, one of the key technologies of biometric recognition, has been widely applied in the fields of e-government, computer login, access control and e-commerce. However, the image quality of face input in practical application seriously affects the accuracy and intelligence of face recognition system. Therefore, a face image quality evaluation algorithm based on transfer learning is proposed to solve the problem of face image quality. Before recognition, the self-built face image data set is normalized and preprocessed, and then the data set is trained again on the Mobilenet network by means of migration learning on the framework of tensorflow to obtain the quality evaluation model of face image and filter out the face image that meets the quality requirements of the recognition algorithm.Compared with inception model, experiments show that the accuracy of Mobilenet model after migration compression is slightly reduced, but the number of parameters of the model is also greatly reduced, thus improving the computational efficiency of the model.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=face%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">face recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=transfer%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">transfer learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Mobilenet&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Mobilenet;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=image%20quality%20assessment&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">image quality assessment;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=quality%20evaluation%20of%20face%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">quality evaluation of face image;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12</p>
                            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="34">21世纪以来, 人们的公共安全意识不断提高, 与保障安全息息相关的身份验证技术的相关产品正日益惠及人们的学习工作与生活。数据表明自2010年来, 人脸识别作为安全友好的身份验证技术已占全球生物特征识别约百分之二十的市场份额<citation id="121" type="reference"><link href="91" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 且一直为持续快速增长的趋势, 因此, 在人脸图像识别方面研究的商业价值不可估量。</p>
                </div>
                <div class="p1">
                    <p id="35">人脸识别可分为4个步骤:人脸数据采集及检测、图像预处理、人脸特征提取、人脸特征匹配和识别<citation id="122" type="reference"><link href="93" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。虽然人脸识别在各个AI大赛及数据集上存在十分优秀表现, 并且众多公开人脸数据集都是图片质量较好, 但在实际应用中, 因为应用场景的复杂多样性, 获取的人脸图片效果存在很大的差别, 比如在视频流截取的海量图片中存在很多对于识别过程无效的图片<citation id="123" type="reference"><link href="95" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。而且有研究表明, 人脸识别的准确率与识别算法的好坏及人脸图片质量优劣都有关系<citation id="124" type="reference"><link href="97" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。所以, 如何过滤掉无效的人脸, 保留有效的图片 (即高质量的图片) 是目前人脸识别领域的一项艰巨任务。</p>
                </div>
                <div class="p1">
                    <p id="36">图像质量评估方法可根据按照参考图片提供信息量的多少分为:全参考、半参考和无参考<citation id="125" type="reference"><link href="99" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。无参考图像质量评估类算法可分成两种:一是针对特定类型的低质量图, 如尺寸较小、模糊、噪声严重等, 研究采取特定针对措施, 例如Hu<citation id="126" type="reference"><link href="101" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等提出一种从人脸位置、角度、清晰度和对比度用以综合性评价人脸图像质量高低的算法。另一种是估计非特定类型的图像质量, 此类算法是个通用的失真评估, 由于CNN可有效学习复杂的映射, 所以深度学习算法在此方面会表现出较积极的效果, 例如在人脸图像质量评估领域Li等通过建立CNN模型<citation id="127" type="reference"><link href="103" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 把输入在高质量类别的概率作为人脸图像的质量得分, 建立了人脸图像质量的打分系统。</p>
                </div>
                <div class="p1">
                    <p id="37">无参考人脸图像质量评估因只有低质失真图像, 难度较高, 是近些年的研究热点。谷歌团队在文献<citation id="128" type="reference"><link href="105" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>中提出一个轻量级网络模型Mobilenet并在一个大型多属性的数据集 (YFCC100 M) 训练了Mobilenet模型, 验证了其在人脸属性分类方面的优异功能。官方也给出Mobilenet的预训练模型供学习使用, 因此本研究选用此模型作为预训练的源模型, 自建数据集, 利用迁移学习建立一个人脸图像质量评估模型, 并验证其有效性。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag"><b>1 迁移学习</b></h3>
                <div class="p1">
                    <p id="39">迁移学习理论上是指用一种学习对另一种学习的影响, 其目的是将之前已经成熟学习的知识迁移到新的任务<citation id="129" type="reference"><link href="107" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。本论文研究的工作范畴属于特征表示迁移, 与文献<citation id="130" type="reference">[<a class="sup">10</a>]</citation>属于同一类型方法。由于此论文的研究是在更加类似的人脸识别任务之间进行迁移, 因此预料可取得更优越的性能, 进而更能够符合实际功能应用的要求。</p>
                </div>
                <div class="p1">
                    <p id="40">迁移学习的形式概念可以定义为:假设给定一个源域与源任务, 把源域称为<i>Ds</i>, 源任务为<i>Ts</i>, 一个目标域<i>Dt</i>与目标任务<i>Tt</i>, 其中迁移学习的目标是<i>Ds</i>与<i>Tt</i>的知识能够帮助提升或求解<i>Tt</i><citation id="131" type="reference"><link href="111" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。请注意:<i>Ds</i>≠<i>Dt</i>, 或<i>Ts</i>≠<i>Tt</i>。式 (1) 为域D的定义, 式 (2) 为学习任务T的定义:</p>
                </div>
                <div class="area_img" id="41">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZCL201912019_04100.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="45">对于人脸识别的任务, 假定<i>Ds</i>=<i>Dt</i>, 而<i>Ts</i>≠<i>Tt</i> (尽管紧密相关) 。详细的说, <i>Ts</i>已从一个大型的人脸数据集中学习到知识, 目前须要在一个特定任务的小型数据集上来完成<i>Tt</i>的学习。学习的目标是: 通过<i>Ts</i>来帮助学习一个有效的<i>Tt</i>。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag"><b>2 基于迁移学习的人脸图像质量评估模型</b></h3>
                <div class="p1">
                    <p id="47">人脸图像质量评估是个二分类问题, 图像质量被分为低质量与高质量<citation id="132" type="reference"><link href="113" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 将预训练好的源模型提取目标数据特征用来训练目标模型的高层表示目标最终将源模型与训练完成的高层相结合得到评估模型, 在人脸识别过程中, 当经过人脸检测环节标出人脸后, 将人脸数据输入评估模型中, 模型会将输入数据映射到质量标签空间, 以判断人脸图像质量的高低, 将低质量图像自动剔除, 高质量图像保留即可进行人脸识别的后续步骤。下面将对基于迁移学习的人脸图像质量评估模型进行介绍。</p>
                </div>
                <h4 class="anchor-tag" id="48" name="48"><b>2.1 源模型</b></h4>
                <div class="p1">
                    <p id="49">在tensorflow框架下预训练Mobilenet网络模型<citation id="133" type="reference"><link href="105" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>的前<i>n</i>层作为源模型<i>Ts</i>, 将<i>Ts</i>作为<i>Tt</i>的前<i>n</i>层, 之后初始化<i>Tt</i>的剩余层同时用目标数据训练目标任务<i>Tt</i>。因为本论文研究人脸识别的任务, 且只有小规模的特定于人脸任务的人脸数据集, 若截取Mobilenet全连接层后的剩余层的模型仍包含大量参数, 为避免过拟合, 所以源模型选择冻结。Mobilenet网络采用了深度可分离卷积 (depthwise separatable convolution) , 据文献<citation id="134" type="reference">[<a class="sup">8</a>,<a class="sup">13</a>,<a class="sup">14</a>]</citation>可知, 深度可分离卷积是用深度卷积结合逐点卷积代替标准卷积, 图1所示分别是标准卷积和深度可分离卷积的结构。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912019_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 标准卷积和深度可分离卷积的结构" src="Detail/GetImg?filename=images/DZCL201912019_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 标准卷积和深度可分离卷积的结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912019_050.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="51">标准卷积过程是用<i>Dk</i>×<i>Dk</i>×<i>M</i>×<i>N</i>的卷积核对输入特征图<i>DF</i>×<i>DF</i>×<i>M</i>进行卷积, 若步长是1, 则生成的输出特征图大小为<i>DF</i>×<i>DF</i>×<i>N</i>, 由此可知标准卷积过程的参数计算量为:<i>Dk</i>×<i>Dk</i>×<i>M</i>×<i>N</i>×<i>DF</i>×<i>DF</i>。深度可分离卷积是先进行深度卷积, 使用<i>Dk</i>×<i>Dk</i>×1的卷积核对每通道分别卷积, 计算量为<i>Dk</i>×<i>Dk</i>×<i>M</i>×<i>DF</i>×<i>DF</i>, 之后将<i>M</i>个输入特征经过点卷积输出为<i>N</i>个特征, 计算量为<i>M</i>×<i>N</i>×<i>DF</i>×<i>DF</i>。综上, 深度可分离卷积过程总的计算量为:<i>Dk</i>×<i>Dk</i>×<i>M</i>×<i>DF</i>×<i>DF</i>+<i>M</i>×<i>N</i>×<i>DF</i>×<i>DF</i>。</p>
                </div>
                <div class="p1">
                    <p id="52">因此两种卷积方式的计算量比较可得:</p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>D</mi><mi>Κ</mi><mo>×</mo><mi>D</mi><mi>Κ</mi><mo>×</mo><mi>Μ</mi><mo>×</mo><mi>D</mi><mi>F</mi><mo>+</mo><mi>Μ</mi><mo>×</mo><mi>Ν</mi><mo>×</mo><mi>D</mi><mi>F</mi><mo>×</mo><mi>D</mi><mi>F</mi></mrow><mrow><mi>D</mi><mi>Κ</mi><mo>×</mo><mi>D</mi><mi>Κ</mi><mo>×</mo><mi>Μ</mi><mo>×</mo><mi>Ν</mi><mo>×</mo><mi>D</mi><mi>F</mi><mo>×</mo><mi>D</mi><mi>F</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mi>D</mi><msubsup><mrow></mrow><mi>Κ</mi><mn>2</mn></msubsup></mrow></mfrac></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="55">由上式可知, Mobilenet通过深度可分离卷积的方式, 极大降低了计算量。</p>
                </div>
                <div class="p1">
                    <p id="56">为构建更小的模型和更少的计算量, Mobilenet网络引入了两个超参数用于压缩模型:宽度乘数<i>α</i>和分辨率乘数<i>β</i>。<i>α</i>与<i>β</i>的取值范围是[0, 1], <i>α</i>与<i>β</i>都为1时为标准的Mobilenet模型, 若<i>α</i>与<i>β</i>不全为1则是压缩的Mobilenet模型。<i>α</i>是对模型的每层加以压缩, 若给定了<i>α</i>, 则<i>M</i>通道的输入压缩后是<i>αM</i>的输入, 同时, <i>N</i>通道的输出压缩后为<i>αN</i>, 显然, 使用<i>α</i>后的模型的计算量为:<i>Dk</i>×<i>Dk</i>×<i>αM</i>×<i>DF</i>×<i>DF</i>+<i>αM</i>×<i>αN</i>×<i>DF</i>×<i>DF</i>。<i>β</i>是输入图像的约减因子, 即输入图像及每个模块产生的特征图的分辨率都相应减小, 若Mobilenet同时设置了<i>α</i>与<i>β</i>, 则模型的卷积计算量是:<i>Dk</i>×<i>Dk</i>×<i>αM</i>×<i>βDF</i>×<i>βDF</i>+<i>αM</i>×<i>αN</i>×<i>βDF</i>×<i>βDF</i>。</p>
                </div>
                <h4 class="anchor-tag" id="57" name="57"><b>2.2 学习目标模型</b></h4>
                <div class="p1">
                    <p id="58">如上文提到, 确定冻结源模型后。用目标数据来训练目标任务Tt得到一个对于特定于目标任务的目标模型<citation id="135" type="reference"><link href="119" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。图2为学习一个目标模型的全过程。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912019_059.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 学习一个目标模型" src="Detail/GetImg?filename=images/DZCL201912019_059.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 学习一个目标模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912019_059.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="60">由图2知, 先选取Mobilenet的前<i>n</i>层为冻结源模型, 之后利用源模型提取目标数据特征, 获得的特征来训练目标模型的高层信息, 最终经过目标数据训练的高层加上冻结的源模型即生成特定于目标任务的目标模型。设计目标模型高层表示存在自由的弹性, 由于本论文的研究的源任务与目标任务都是人脸领域, 相似性大, 并且目标数据集不大, 因此仅选择重新学习高层 (分类器层) 。</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag"><b>3 实验与分析</b></h3>
                <h4 class="anchor-tag" id="62" name="62"><b>3.1 实验数据集</b></h4>
                <div class="p1">
                    <p id="63">本文是采用自建的数据集进行实验, 数据集包括12 000张正样本, 15 000张负样本。详细数据集表示如下所示:</p>
                </div>
                <div class="area_img" id="64">
                    <p class="img_tit"><b>表1 人脸数据集统计表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="64" border="1"><tr><td><br />数据</td><td>类别</td><td>数量</td><td>来源</td></tr><tr><td><br />正样本</td><td>Brilliance<br />image</td><td>12 000</td><td>CASIA-Webface</td></tr><tr><td rowspan="4"><br />负样本</td><td><br />Blurred</td><td>6 000</td><td>Motion Blur Gauss Blur</td></tr><tr><td><br />Occlusion</td><td>3 000</td><td>Network crawling</td></tr><tr><td><br />Dim</td><td>3 000</td><td>RGB转HSV</td></tr><tr><td><br />Tilted</td><td>3 000</td><td>CASIA-Webface</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="65" name="65"><b>3.2 实验一:针对单一失真类型的人脸数据</b></h4>
                <div class="p1">
                    <p id="66">实验以模糊为例, 对模糊人脸图像进行实验, 需用6 000张模糊人脸图像 (负样本) 和6 000张清晰人脸图像 (正样本) 进行训练, 将数据随机分为20%测试, 80%训练, 对高层模型训练并验证其准确率, 迭代5 000次。进而区分出清晰及模糊的人脸。若Mobilenet的<i>α</i>、<i>β</i>选值不同, 模型的大小及效果也不同。例如模型Mobilenet-v1-1.0-224表示没有压缩的基础Mobilenet模型, 此处“1.0”是指超参<i>α</i>, “224”是指超参<i>β</i>, 与压缩模型相比此模型最大, 参数最多。实验模型选用Mobilenet的典型模型:Mobilenet-v1-1.0-224、Mobilenet-v1-0.75-224、Mobilenet-v1-0.75-128、Mobilenet-v1-0.25-224开展实验, 并对宽度乘数<i>α</i>和分辨率乘数<i>β</i>进行功能验证, 并用Inception模型进行对比, 图3为模型验证的准确率曲线图, 为更好比较分析, 将详细实验结果整理表2所示。</p>
                </div>
                <div class="area_img" id="67">
                    <p class="img_tit"><b>表2 模糊人脸图像不同模型下的实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="67" border="1"><tr><td><br />模型</td><td>参数<br />×10<sup>6</sup></td><td>准确率<br />/%</td><td>模型大小<br />/M</td></tr><tr><td><br />Mobilenet_v1_1.0_224</td><td>4.18</td><td>98.5</td><td>17.2</td></tr><tr><td><br />Mobilenet_v1_0.75_224</td><td>2.63</td><td>98.3</td><td>10.3</td></tr><tr><td><br />Mobilenet_v1_0.75_128</td><td>2.63</td><td>98.3</td><td>10.3</td></tr><tr><td><br />Mobilenet_v1_0.25_224</td><td>0.56</td><td>98.1</td><td>2.1</td></tr><tr><td><br />Inception</td><td>6.80</td><td>98.5</td><td>87.4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="68">由表2图3可知, 模型的训练准确率可达98.5%, 把数据分为模糊和清晰两种情形时, 基础模型Mobilenet-v1-1.0-224和Inception模型都可取得98.5%的准确率, 但Mobilenet网络大小的才是Inception模型的1/5, 虽然参数量比Inception模型参数量少两百多万, 但此时模型参数量还是较多。当用超参数压缩Mobilenet网络时, 随着超参宽度乘数<i>α</i>的降低, 模型的准确度略有降低, 但模型的参数量数倍的减少, 模型大小也大大的减小, 然而超参分辨率乘数<i>β</i>的变化对于模型准确率及模型大小影响并不明显。</p>
                </div>
                <div class="area_img" id="69">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912019_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 准确率变化曲线" src="Detail/GetImg?filename=images/DZCL201912019_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 准确率变化曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912019_069.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="70" name="70"><b>3.3 针对所有失真类型的人脸图像和针对具体失真类型的人脸图像实验</b></h4>
                <div class="p1">
                    <p id="71">针对所有失真类型的人脸图像实验和针对具体失真类型人脸图像实验与实验一都选择5种相同模型来对比训练验证, 数据也都是20%测试, 80%训练。针对所有失真类型的人脸图像实验 (在下文被称为实验二) 的负样本是所有失真类型的图像 (包括模糊、遮挡、昏暗、姿态不正人脸图像各3 000张) , 将负、正样本各12 000张放在一起训练, 将图像结果分为合格与不合格, 其训练过程的准确率曲线图如图4 (a) 所示。明确图像质量是否合格后, 有时还需明确图像具体的失真类型, 因此本文针对具体失真类型的人脸图像进行实验 (在下文中被称为实验三) , 实验三选取3 000张正样本与面部遮挡、模糊、姿态不正、昏暗各3 000张人脸图像一同训练验证, 其准确率曲线图如图4 (b) 所示。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912019_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 准确率变化曲线图" src="Detail/GetImg?filename=images/DZCL201912019_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 准确率变化曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912019_072.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="73">图4 (a) 图可看出实验二中几个模型经一段时间迭代训练后可很快达到90%准确率, 之后缓缓提升趋于稳定。稳定后, 基础模型Mobilenet-v1-1.0-224可达到97.4%的准确率;而压缩后的Mobilenet模型准确率稍有降低, 但压缩后模型参数量迅速降低并且模型大小极大的减小, 而Inception模型的准确率却只能与压缩程度最大的Mobilenet-v1-0.25-224模型大致一样为95.2%左右。实验三几个模型的准确率变化与实验二大致相似, 但模型收敛速度比实验二与实验一快。</p>
                </div>
                <h3 id="74" name="74" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="75">本文针对人脸识别中人脸图像质量的问题提出基于迁移学习的人脸图像质量评估方法, 旨在提高人脸识别的准确率及减小运算过程的参数量。本文介绍了迁移学习的理论, 将Mobilenet作为源模型, 学习生成一个目标模型 (图像质量分类器模型) 。实验结果表明, Mobilenet模型对于单一失真图像及具体失真图像都有较强的判别能力, 虽然压缩的模型准确度相比Inception模型略有降低, 但模型参数量极大减少, 因此, 提高了模型的运算效率。期望以后可以提高模型的适应性与准确性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="91">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX200901021&amp;v=MjQ1OTF0RnlyblY3L09QVFhjZHJHNEh0ak1ybzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 高修峰, 张培仁, 李子青.人脸图像质量评估标准[J].小型微型计算机系统, 2009, 30 (1) :95-99.
                            </a>
                        </p>
                        <p id="93">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201704035&amp;v=MjY3NTN5cm5WNy9PSVRmSVlyRzRIOWJNcTQ5R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈志轩, 周大可, 黄经纬.基于卷积神经网络的表情不变三维人脸识别[J].电子测量技术, 2017, 40 (4) :157-161, 171.
                            </a>
                        </p>
                        <p id="95">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201811010&amp;v=MDc0NjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WNy9PUFRuU2Q3RzRIOW5Ocm85RVpJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 王亚, 朱明, 刘成林.基于CNN的监控视频中人脸图像质量评估[J].计算机系统应用, 2018, 27 (11) :71-77.
                            </a>
                        </p>
                        <p id="97">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=De CAF:A Deep Convolutional Activation Feature for Generic Visual Recognition">

                                <b>[4]</b> DONAHUE J, JIA Y, VINVALS O, et al.Decaf:A deep convolutional activation feature for generic visual recognition[C].International conference on machine learning, 2014:647-655.
                            </a>
                        </p>
                        <p id="99">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for no-reference image quality assessment">

                                <b>[5]</b> KANG L, YE P, LI Y, et al.Convolutional neural networks for no-reference image quality assessment[C].In Proceedings of the IEEE conference on computer vision and pattern recognition, 2014:1733-1740.
                            </a>
                        </p>
                        <p id="101">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS200712015&amp;v=MzA4NjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WNy9PUFNuQmZiRzRIdGJOclk5RVlZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 胡杨庆, 童卫青.人脸图像质量评价法[J].现代计算机 (专业版) , 2007 (12) :43-45, 49.
                            </a>
                        </p>
                        <p id="103">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201903014&amp;v=MDQwNTMzenFxQnRHRnJDVVI3cWZadVp0RnlyblY3L09MejdCZDdHNEg5ak1ySTlFWUlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 李秋珍, 栾朝阳, 汪双喜.基于卷积神经网络的人脸图像质量评价[J].计算机应用, 2019, 39 (3) :695-699.
                            </a>
                        </p>
                        <p id="105">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mobilenets:efficient convolutional neural networks for mobile vision applications">

                                <b>[8]</b> HOWARD A G, ZHU M, CHEN B, et al.MobileNets:Efficient Convolutional Neural Networks for Mobile Vision Applications[J/OL].arXiv e-prints, 2017.https://arxiv.org/abs/1704.04861
                            </a>
                        </p>
                        <p id="107">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CDDD201702009&amp;v=MTk2MjBKaW5QYXJHNEg5Yk1yWTlGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblY3L08=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 余化鹏, 张朋, 朱进.基于深度迁移学习的人脸识别方法研究[J].成都大学学报 (自然科学版) , 2017, 36 (2) :151-156.
                            </a>
                        </p>
                        <p id="109">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Report on the evaluation of 2D still-image face recognition algorithms">

                                <b>[10]</b> GROTHER P J, QUINN G W, PHILLIPS P J.Report on the evaluation of 2D still-image face recognition algorithms:NIST Interagency Report:7709 [R].[doi:10.6028/NIST.IR.7709], 2010:106.
                            </a>
                        </p>
                        <p id="111">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201509011&amp;v=MjA4OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblY3L09JVGZJWXJHNEg5VE1wbzlFWlk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 滕秋霞, 沈天飞, 杨金霄.基于多肤色模型的人脸检测系统研究[J].电子测量技术, 2015, 38 (9) :47-51.
                            </a>
                        </p>
                        <p id="113">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SDGY201602002&amp;v=MDE3NTBmTXJZOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVjcvT05pbk1kN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 邹国锋, 傅桂霞, 李震梅, 等.融合二级评价指标的人脸图像质量评价方法[J].山东大学学报 (工学版) , 2016, 46 (2) :6-13.
                            </a>
                        </p>
                        <p id="115">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face pose estimation and its application in video shot selection">

                                <b>[13]</b> YANG Z G, AI H Z, WU B, et al.Face pose estimation and its application in video shot selection [C].Proceedings of the international conference on Pattern Recognition (ICPR) , Piscataway, NJ:IEEE, 2004:322-325.
                            </a>
                        </p>
                        <p id="117">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018180246.nh&amp;v=MzA1NTdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cm5WNy9PVkYyNkZyS3dIdFBJcVpFYlA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 杨源.基于深度学习的不良图片过滤技术研究[D].北京:北方工业大学, 2018.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face image quality assessment based on learning to rank">

                                <b>[15]</b> CHEN JS, DENG Y, BAI GC.et al.Face image Quality assessment based on learning to rank[J].IEEE Signal Processing Letters, 2015, 22 (1) :9094.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201912019" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201912019&amp;v=MTc4MjFUZklZckc0SDlqTnJZOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVjcvT0k=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

