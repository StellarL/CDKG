

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135831715568750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201911019%26RESULT%3d1%26SIGN%3dFxnoeaL1XFiCU7wYph6ELPuNEZA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201911019&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201911019&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201911019&amp;v=MTMxODZxZlp1WnRGeTduVUx2TUlUZklZckc0SDlqTnJvOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 特征提取&lt;/b&gt; "><b>1 特征提取</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#38" data-title="&lt;b&gt;1.1 SIFT特征&lt;/b&gt;"><b>1.1 SIFT特征</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;1.2 SURF特征&lt;/b&gt;"><b>1.2 SURF特征</b></a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;1.3 特征匹配&lt;/b&gt;"><b>1.3 特征匹配</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;2 实验结果与分析&lt;/b&gt; "><b>2 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;3 结  论&lt;/b&gt; "><b>3 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#101" data-title="图1 SIFT特征提取后的局部重建效果">图1 SIFT特征提取后的局部重建效果</a></li>
                                                <li><a href="#103" data-title="图2 SIFT特征与SURF特征提取后的局部重建效果">图2 SIFT特征与SURF特征提取后的局部重建效果</a></li>
                                                <li><a href="#105" data-title="图3 SIFT特征提取后的整体重建效果">图3 SIFT特征提取后的整体重建效果</a></li>
                                                <li><a href="#106" data-title="图4 SIFT特征与SURF特征提取后的整体重建效果">图4 SIFT特征与SURF特征提取后的整体重建效果</a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;表1 重建的三维网格模型属性&lt;/b&gt;"><b>表1 重建的三维网格模型属性</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="128">


                                    <a id="bibliography_1" title=" 吴彤, 傅中力.三维重建技术及其军事应用.国防科技, 2015, 36 (1) :31-34." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GFCK201501007&amp;v=MDgzMTMzenFxQnRHRnJDVVI3cWZadVp0Rnk3blVMdk1JaXZJWmJHNEg5VE1ybzlGWTRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         吴彤, 傅中力.三维重建技术及其军事应用.国防科技, 2015, 36 (1) :31-34.
                                    </a>
                                </li>
                                <li id="130">


                                    <a id="bibliography_2" title=" 曾宁, 范应方, 杨剑, 等.数字虚拟技术在肝胆外科临床教学中的应用研究[J].中国继续医学教育, 2018, 10 (33) :16-19." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXUY201833007&amp;v=MDQ0NzR6cXFCdEdGckNVUjdxZlp1WnRGeTduVUx2TUx6WGVkN0c0SDluUHJJOUZZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         曾宁, 范应方, 杨剑, 等.数字虚拟技术在肝胆外科临床教学中的应用研究[J].中国继续医学教育, 2018, 10 (33) :16-19.
                                    </a>
                                </li>
                                <li id="132">


                                    <a id="bibliography_3" title=" 明国辉, 委民正.SURF算法在无人机倾斜摄影测量三维建模中的应用[J].测绘工程, 2017, 26 (9) :41-45." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHGC201709009&amp;v=MjgwMjJYTWJiRzRIOWJNcG85RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNSmk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         明国辉, 委民正.SURF算法在无人机倾斜摄影测量三维建模中的应用[J].测绘工程, 2017, 26 (9) :41-45.
                                    </a>
                                </li>
                                <li id="134">


                                    <a id="bibliography_4" title=" 吴宁, 陈佳舟, 吴凯乐.面向数字化保护的自动文物三维重建方法研究[J].山西建筑, 2018, 44 (6) :257-258." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZSX201806139&amp;v=MDIxNjhIOW5NcVk1R2JZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNTHpmWWRyRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         吴宁, 陈佳舟, 吴凯乐.面向数字化保护的自动文物三维重建方法研究[J].山西建筑, 2018, 44 (6) :257-258.
                                    </a>
                                </li>
                                <li id="136">


                                    <a id="bibliography_5" title=" 霍林生, 张耀文, 李宏男.图像三维重建法在震损建筑实体建模中的应用研究[J].世界地震工程, 2017, 33 (2) :113-118." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJDC201702015&amp;v=MTQwMTh0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNTmlmUGJiRzRIOWJNclk5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         霍林生, 张耀文, 李宏男.图像三维重建法在震损建筑实体建模中的应用研究[J].世界地震工程, 2017, 33 (2) :113-118.
                                    </a>
                                </li>
                                <li id="138">


                                    <a id="bibliography_6" title=" SEITZ S M, CURLESS B, DIEBEL J, et al.A comparison and evaluation of multi-view stereo reconstruction algorithms[C].Ppwer Symposium (NAPS) , 2005:519-528." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A comparison and evaluation of multi-view stereo reconstruction algorithms">
                                        <b>[6]</b>
                                         SEITZ S M, CURLESS B, DIEBEL J, et al.A comparison and evaluation of multi-view stereo reconstruction algorithms[C].Ppwer Symposium (NAPS) , 2005:519-528.
                                    </a>
                                </li>
                                <li id="140">


                                    <a id="bibliography_7" title=" FUHRMANN S, LANGGUTH F, GOESELE M.MVE-A multiview reconstruction environment[C].GCH′14 Proceedings of the Eurogcaphics Workshop on Graphics and Cultural Heritage, 2014:11-18." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MVE-A Multi-View Reconstruction Environment">
                                        <b>[7]</b>
                                         FUHRMANN S, LANGGUTH F, GOESELE M.MVE-A multiview reconstruction environment[C].GCH′14 Proceedings of the Eurogcaphics Workshop on Graphics and Cultural Heritage, 2014:11-18.
                                    </a>
                                </li>
                                <li id="142">


                                    <a id="bibliography_8" title=" UMMENHOFER B, BROX T.Global, dense multiscale reconstruction for a billion points[C].Proceedings of the IEEE International Conference on Computer Vision.2015:1341-1349." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Global, dense multiscale reconstruction for a billion points">
                                        <b>[8]</b>
                                         UMMENHOFER B, BROX T.Global, dense multiscale reconstruction for a billion points[C].Proceedings of the IEEE International Conference on Computer Vision.2015:1341-1349.
                                    </a>
                                </li>
                                <li id="144">


                                    <a id="bibliography_9" title=" LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MTg3ODdScnhveGNNSDdSN3FkWitadUZpdmxWYjNMSkZvPU5qN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5U1hx&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                                    </a>
                                </li>
                                <li id="146">


                                    <a id="bibliography_10" title=" BAY H, ESS A, TUYTELAARS T, et al.Speeded-up robust features (SURF) [J].Computer Vision And Image Understanding, 2008, 110 (3) :346-359." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083888&amp;v=MDk5MDVNbndaZVp0RmlubFVyeklKbHdYYmhZPU5pZk9mYks3SHRETnFvOUVaT01NQkhReG9CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         BAY H, ESS A, TUYTELAARS T, et al.Speeded-up robust features (SURF) [J].Computer Vision And Image Understanding, 2008, 110 (3) :346-359.
                                    </a>
                                </li>
                                <li id="148">


                                    <a id="bibliography_11" title=" MANICKAM A, DEVARASAN E, MANOGARAN G, et al.Score level based latent fingerprint enhancement and matching using SIFT feature[J].Multimedia Tools and Applications, 2018, 78 (3) :1-21." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Score level based latent fingerprint enhancement and matching using SIFT feature">
                                        <b>[11]</b>
                                         MANICKAM A, DEVARASAN E, MANOGARAN G, et al.Score level based latent fingerprint enhancement and matching using SIFT feature[J].Multimedia Tools and Applications, 2018, 78 (3) :1-21.
                                    </a>
                                </li>
                                <li id="150">


                                    <a id="bibliography_12" title=" ELTNER A, KAISER A, CASTILLO C, et al.Image-based surface reconstruction in geomorphometry-merits, limits and developments[J].Earth Surface Dynamics, 2016, 4 (2) :359-389." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image-based surface reconstruction in geomorphometry-merits,limits and developments">
                                        <b>[12]</b>
                                         ELTNER A, KAISER A, CASTILLO C, et al.Image-based surface reconstruction in geomorphometry-merits, limits and developments[J].Earth Surface Dynamics, 2016, 4 (2) :359-389.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_13" title=" JIN R, KIM J.Tracking feature extraction techniques with improved SIFT for video identification[J].Multimedia Tools and Applications, 2017, 76 (4) :5927-5936." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tracking Feature Extraction Techniques with Improved SIFT for Video Identification">
                                        <b>[13]</b>
                                         JIN R, KIM J.Tracking feature extraction techniques with improved SIFT for video identification[J].Multimedia Tools and Applications, 2017, 76 (4) :5927-5936.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_14" title=" 索春宝, 杨东清, 刘云鹏.多种角度比较SIFT、SURF、BRISK、ORB、FREAK算法[J].北京测绘, 2014 (4) :23-26, 22." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJCH201404006&amp;v=MTc5NThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk3blVMdk1KeWZJWnJHNEg5WE1xNDlGWW8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         索春宝, 杨东清, 刘云鹏.多种角度比较SIFT、SURF、BRISK、ORB、FREAK算法[J].北京测绘, 2014 (4) :23-26, 22.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_15" title=" 王凌云, 尹海波, 王琪.SURF和RANSAC在图像拼接中的应用[J].电子测量技术, 2016, 39 (4) :71-75." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201604017&amp;v=MDczOTFNcTQ5RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNSVRmSVlyRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         王凌云, 尹海波, 王琪.SURF和RANSAC在图像拼接中的应用[J].电子测量技术, 2016, 39 (4) :71-75.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(11),107-111 DOI:10.19651/j.cnki.emt.1802448            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于联合SIFT和SURF特征的三维表面重建</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%87%91%E5%A6%8D%E5%90%9B&amp;code=42201949&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">金妍君</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%87%E6%97%BA%E6%A0%B9&amp;code=08537469&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">万旺根</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6%E6%99%BA%E6%85%A7%E5%9F%8E%E5%B8%82%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=0017580&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海大学通信与信息工程学院上海大学智慧城市研究院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>一般提取二维图像特征点的方法用到SIFT特征提取, 因为SIFT特征有几个特性:对噪声和光线容忍度高、区分性、多量性、可扩展性等, 但对于边缘光滑目标的特征点提取能力较弱。SURF特征也是提取图像的尺度不变特征, SURF方法使用Hessian矩阵的行列式值作特征点检测, 在对于光滑边缘的目标特征点检测效果要优于SIFT特征。采用同时提取图像中SIFT和SURF特征的方法用于关键点的确定, 能够在SIFT特征稳定性好、尺度不变性基础上, 提高边缘光滑目标的特征点检测能力。实验结果表明, 使用SIFT特征和SURF特征联合的方法能够重建出更多的顶点数和面片数, 包括利用SIFT特征提取后存在空缺的部分。重建出的三维表面有更完整更准确的顶点和三角形面片, 能提高重建表面的完整度与真实性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SIFT%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SIFT特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SURF%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SURF特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%94%E5%90%88%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">联合特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A8%80%E7%96%8F%E7%82%B9%E4%BA%91&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">稀疏点云;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%89%E7%BB%B4%E8%A1%A8%E9%9D%A2%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">三维表面重建;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *金妍君 (通信作者) , 硕士在读, 主要研究方向为虚拟现实。E-mail:565813934@qq.com;
                                </span>
                                <span>
                                    万旺根, 教授, 主要研究方向为计算机图形学与虚拟现实技术、数据挖掘与机器学习等。E-mail:wanwg@staff.shu.edu.cn;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12</p>

            </div>
                    <h1><b>3D surface reconstruction based on jointly SIFT and SURF features</b></h1>
                    <h2>
                    <span>Jin Yanjun</span>
                    <span>Wan Wanggen</span>
            </h2>
                    <h2>
                    <span>School of Communication and Information Engineering, Institute of Smart City, Shanghai University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The general method of extracting 2 D image feature points uses SIFT feature extraction because SIFT features have several characteristics: high tolerance to noise and light, discriminating, multiplicity, scalability, etc., but the extraction ability for feature points of edge smooth targets is weak. The SURF feature is also a scale-invariant feature of the extracted image. SURF method uses the determinant value of the Hessian matrix for feature point detection, and the detection effect on the target feature point for the smooth edge is better than the SIFT feature. In this paper, the method of simultaneously extracting the SIFT and SURF features in the image is used to determine the key points. Based on the SIFT feature stability and scale invariance, the feature point detection ability of the edge smooth target can be improved. The experimental result expression, using jointly SIFT features and SURF features, can obtain more number of vertexes and patches after reconstruction of point clouds, including the vacancy part after the SIFT feature extraction. The increase of point cloud information provides more complete and accurate point cloud information for the 3 D surface reconstruction step, which can improve the integrity and authenticity of the reconstructed surface.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SIFT%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SIFT features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SURF%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SURF features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=jointly%20feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">jointly feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=sparse%20point%20cloud&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">sparse point cloud;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=3D%20surface%20reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">3D surface reconstruction;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12</p>
                            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="34">三维表面重建能够应用在军事测绘导航<citation id="158" type="reference"><link href="128" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、虚拟战场构建、无人机作战应用、军事医疗救护<citation id="159" type="reference"><link href="130" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、测绘学<citation id="160" type="reference"><link href="132" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、考古学<citation id="161" type="reference"><link href="134" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>以及对震损建筑实体的研究<citation id="162" type="reference"><link href="136" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等方面。三维表面重建基于点云数据实现, 可以通过激光扫描仪设备对实物进行点云数据的主动获取, 如使用Kinect设备对需要三维重建的实物进行扫描获取其点云数据后可直接进行点云到网格表面的重建步骤。还有一种被动式的点云获取方式, 即从二维图像中获取点云数据。传统的获取表面三维信息的方法一般是利用三维激光扫描技术扫描, 这种方法由于其设备昂贵而使得成本很高, 另外其获取信息的过程复杂, 工作量大, 因此未能普及。通过采集目标的多幅图像, 获取实物表面的信息, 然后对实物表面进行三维表面重建, 这种方法对设备要求较低, 不同的手机摄像头即可满足要求, 且对于目标表面的三维重建效果较好。</p>
                </div>
                <div class="p1">
                    <p id="35">近年来, 从定向点集的表面重建一直是非常热门的研究课题。扫描设备和许多基于图像的重建算法, 例如多视图立体化 (multi-view stereo, MVS) <citation id="163" type="reference"><link href="138" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>仅生成每张视图深度信息, 必须合并为全局一致的模型。通常由于输入点样本包含噪声和异常值而不易实现。此外, 在不受控制的真实世界环境中, 场景经常出现不规则地采样, 导致不同的样本密度和结果。最近表面重建技术的焦点是多尺度重建<citation id="164" type="reference"><link href="140" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>或全局优化鲁棒性<citation id="165" type="reference"><link href="142" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="36">为了得到三维表面重建较好的效果, 达到目标表面的真实性三维重建目的, 本文提出共同使用SIFT<citation id="166" type="reference"><link href="144" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和SURF<citation id="167" type="reference"><link href="146" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>特征提取以获得更准确的特征点, 提高目标三维表面重建的效果, 并编程实现与验证本文算法效果。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>1 特征提取</b></h3>
                <h4 class="anchor-tag" id="38" name="38"><b>1.1 SIFT特征</b></h4>
                <div class="p1">
                    <p id="39">图像匹配是计算机视觉领域中很多问题的关键, 包括目标和场景识别<citation id="168" type="reference"><link href="148" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、多幅影像进行三维构建<citation id="169" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、运动追踪<citation id="170" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>等。SIFT特征具备很多可以将一个目标或场景的不同影像进行匹配的特性。这些特征对于图像尺度和旋转具有不变性, 并在光照变化和三维相机视点变化的情况下具有部分的不变性, 它在空间域和频率域都可以很好地定位, 减少了遮挡、聚类和噪音的影响。图像中可以提取海量特征, 且特征鲜明, 单个特征可以无误地与大型数据库中的特征进行匹配, 为目标和场景识别提供了基础。</p>
                </div>
                <div class="p1">
                    <p id="40">首先建立高斯金字塔, 对原始图像进行多尺度像素采样的方式, 把具有最高级别分辨率的图像放在底部, 往上的像素逐渐降低。第1层金字塔的第1张图像是将原始图像尺寸缩小一半后得到, 第1层的第2张图像是利用高斯卷积函数对第1张图像进行卷积, 生成分辨率低的图像。</p>
                </div>
                <div class="p1">
                    <p id="41"><i>L</i> (<i>x</i>, <i>y</i>, <i>σ</i>) =<i>G</i> (<i>x</i>, <i>y</i>, <i>σ</i>) *<i>I</i> (<i>x</i>, <i>y</i>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="42">式中:<i>L</i> (<i>x</i>, <i>y</i>, <i>σ</i>) 是卷积后的结果即同层的下一张图像;<i>G</i> (<i>x</i>, <i>y</i>, <i>σ</i>) 是高斯卷积函数;<i>I</i> (<i>x</i>, <i>y</i>) 是原图像。高斯卷积函数类似于一种图像滤波器, 高斯卷积函数如式 (2) 所示。</p>
                </div>
                <div class="p1">
                    <p id="43" class="code-formula">
                        <mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mtext>π</mtext><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>e</mi><msup><mrow></mrow><mrow><mo>-</mo><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mo stretchy="false"> (</mo><mi>y</mi><mo>-</mo><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo></mrow></msup><mo>/</mo><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="44">式中:<i>σ</i>为尺度空间的高斯模糊参数, 与图像在尺度空间所处的位置有关; (<i>x</i><sub>0</sub>, <i>y</i><sub>0</sub>) 为卷积模板中心; (<i>x</i>, <i>y</i>) 为模板上的元素位置, 由此可计算得到模糊模板。高斯模糊参数如式 (3) 所示。</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><mo stretchy="false"> (</mo><mi>o</mi><mo>, </mo><mi>s</mi><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><msub><mrow></mrow><mn>0</mn></msub><mo>⋅</mo><mn>2</mn><msup><mrow></mrow><mrow><mfrac><mrow><mi>o</mi><mo>+</mo><mi>s</mi></mrow><mi>S</mi></mfrac></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">式中:<i>o</i>和<i>s</i>指该图像位于金字塔第<i>o</i>层第<i>s</i>张;<i>σ</i><sub>0</sub>是高斯模糊初始值;<i>S</i>指金字塔总层数。将本层倒数第3张图像尺寸缩小一半后作为金字塔下一层的第1张图像。金字塔同层图像尺寸大小一致。得到高斯金字塔后, 将每层的相邻图像相减即得到高斯差分金字塔, 如式 (4) 所示。</p>
                </div>
                <div class="p1">
                    <p id="47"><i>D</i> (<i>x</i>, <i>y</i>, <i>σ</i>) = (<i>G</i> (<i>x</i>, <i>y</i>, <i>kσ</i>) -<i>G</i> (<i>x</i>, <i>y</i>, <i>σ</i>) ) *<i>I</i> (<i>x</i>, <i>y</i>) =</p>
                </div>
                <div class="p1">
                    <p id="48"><i>L</i> (<i>x</i>, <i>y</i>, <i>kσ</i>) -<i>L</i> (<i>x</i>, <i>y</i>, <i>σ</i>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="49">式中:<i>D</i> (<i>x</i>, <i>y</i>, <i>σ</i>) 即为所得的高斯差分图。</p>
                </div>
                <div class="p1">
                    <p id="50">空间极值点检测是对关键点的初步查探, 检测<i>D</i> (<i>x</i>, <i>y</i>, <i>σ</i>) 的局部最大值和最小值, 每个样本点都要和它当前图像的8个邻域以及上下尺度的各9个邻域共26个邻域相比较。只有在它比所有近邻大或者小时才会被选择。</p>
                </div>
                <div class="p1">
                    <p id="51">由差分高斯金字塔得到的局部极值点是在离散空间得到的, 离散空间是由连续空间采样得到的, 离散空间的极值并不一定是真正意义上连续空间内的局部极值点。所以需要把不符合局部极值点要求的点删除得到精确定位的关键点。首先通过泰勒展开式对极值点与周围的对比度, 删除对比度小的极值点, 泰勒展开式如式 (5) 所示。</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>X</mi><mo stretchy="false">) </mo><mo>=</mo><mi>D</mi><mo>+</mo><mfrac><mrow><mo>∂</mo><mi>D</mi><msup><mrow></mrow><mi>Τ</mi></msup></mrow><mrow><mo>∂</mo><mi>X</mi></mrow></mfrac><mi>X</mi><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>X</mi><msup><mrow></mrow><mi>Τ</mi></msup><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>D</mi></mrow><mrow><mo>∂</mo><mi>X</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mi>X</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>X</mi><mo>⌢</mo></mover><mo>=</mo><mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>σ</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mi>Τ</mi></msup></mrow></math></mathml>, 求导并让方程等于0, 可以得到极值点的偏移量为:</p>
                </div>
                <div class="p1">
                    <p id="55"><mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>X</mi><mo>⌢</mo></mover><mo>=</mo><mo>-</mo><mfrac><mrow><mo>∂</mo><msup><mrow></mrow><mn>2</mn></msup><mi>D</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow><mrow><mo>∂</mo><mi>X</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mfrac><mrow><mo>∂</mo><mi>D</mi></mrow><mrow><mo>∂</mo><mi>X</mi></mrow></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="57">代表相对插值中心的偏移量, 将<mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>X</mi><mo>⌢</mo></mover></math></mathml>代入泰勒公式:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula">
                        <mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>X</mi><mo>⌢</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mi>D</mi><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mfrac><mrow><mo>∂</mo><mi>D</mi><msup><mrow></mrow><mi>Τ</mi></msup></mrow><mrow><mo>∂</mo><mi>X</mi></mrow></mfrac><mover accent="true"><mi>X</mi><mo>⌢</mo></mover><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="60">设置对比度阈值<i>T</i>, 若<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>X</mi><mo>⌢</mo></mover><mo stretchy="false">) </mo><mo>&gt;</mo><mi>Τ</mi></mrow></math></mathml>则保留特征点, 否则删除该点。</p>
                </div>
                <div class="p1">
                    <p id="62">利用Hessian矩阵消除DOG带来的边缘响应, 剔除不稳定的边缘响应点, 边缘的梯度方向上主曲率值比较大, 而沿边缘方向主曲率值较小。特征点的<i>D</i> (<i>X</i>) 的主曲率与Hessian矩阵的特征值成正比。Hessian矩阵如式 (8) 所示:</p>
                </div>
                <div class="area_img" id="63">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZCL201911019_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="65">式中:<i>D</i><sub><i>xx</i></sub>、<i>D</i><sub><i>yx</i></sub>、<i>D</i><sub><i>xy</i></sub>、<i>D</i><sub><i>yy</i></sub>为候选点邻域对应位置的差分求得的。设<i>H</i>的最大特征值<i>α</i>=<i>λ</i><sub>max</sub>, <i>β</i>=<i>λ</i><sub>min</sub>为<b><i>H</i></b>的最小特征值, 不需要求解特征值的具体值, 所以有如下关系。</p>
                </div>
                <div class="p1">
                    <p id="66"><i>Tr</i> (<b><i>H</i></b>) =<i>D</i><sub><i>xx</i></sub>+<i>D</i><sub><i>yy</i></sub>=<i>α</i>+<i>β</i>      (9) </p>
                </div>
                <div class="p1">
                    <p id="67"><i>Det</i> (<b><i>H</i></b>) =<i>D</i><sub><i>xx</i></sub>+<i>D</i><sub><i>yy</i></sub>-<i>D</i><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow><mn>2</mn></msubsup></mrow></math></mathml>=<i>α</i>·<i>β</i>      (10) </p>
                </div>
                <div class="p1">
                    <p id="69">式中:<i>Tr</i> (<b><i>H</i></b>) 是矩阵<b><i>H</i></b>的迹;<i>Det</i> (<b><i>H</i></b>) 是矩阵<b><i>H</i></b>的行列式。令<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><mo>=</mo><mfrac><mi>α</mi><mi>β</mi></mfrac></mrow></math></mathml>则有:</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Τ</mi><mi>r</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>D</mi><mi>e</mi><mi>t</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi>α</mi><mo>+</mo><mi>β</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>α</mi><mi>β</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi>γ</mi><mi>β</mi><mo>+</mo><mi>β</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>γ</mi><mi>β</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi>γ</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mi>γ</mi></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72"><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi>γ</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mi>γ</mi></mfrac></mrow></math></mathml>在2个特征值相等时最小, 随γ增大而增大。比值越大则某一方向的梯度值越大, 另一方向梯度值越小, 类似于边缘。为了提出边缘响应点, 需要让比值小于一个阈值, 令<i>T</i><sub><i>γ</i></sub>=10为阈值。</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Τ</mi><mi>r</mi><mrow><mo stretchy="false"> (</mo><mi>Η</mi><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>D</mi><mi>e</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>Η</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>&gt;</mo><mfrac><mrow><mrow><mo stretchy="false"> (</mo><mi>Τ</mi><msub><mrow></mrow><mi>γ</mi></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>Τ</mi><msub><mrow></mrow><mi>γ</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">检测主曲率是否在阈值以下, 如果式 (12) 成立, 则剔除该特征点, 否则保留。</p>
                </div>
                <div class="p1">
                    <p id="76">稳定极值点和删除边缘响应点之后的特征点在各个尺度下都存在, 之后通过每个极值点的梯度进行方向信息分配, 梯度幅值和方向如式 (13) 、 (14) 所示。</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>m</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>θ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>tan</mi></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mfrac><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>-</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">式中:<i>m</i> (<i>x</i>, <i>y</i>) 是梯度幅值;<i>L</i> (<i>x</i>, <i>y</i>) 是极值点的像素值;<i>θ</i> (<i>x</i>, <i>y</i>) 是梯度方向。在邻域中求得方向后产生方向直方图, 0～360°分36个方向, 以直方图中最大值作为该关键点的主方向。为了增强匹配的鲁棒性, 只保留峰值大于主方向峰值80%的方向作为该关键点的辅方向。</p>
                </div>
                <div class="p1">
                    <p id="79">生成关键点的描述子, 首先对关键点的主方向进行矫正, 以特征点为中心, 在附近邻域内将坐标轴旋转<i>θ</i>°, 即将坐标轴旋转为特征点的主方向。旋转后邻域内像素的新坐标为:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><msup><mi>x</mi><mo>′</mo></msup></mtd></mtr><mtr><mtd><msup><mi>y</mi><mo>′</mo></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mi>θ</mi></mtd><mtd><mo>-</mo><mi>sin</mi><mi>θ</mi></mtd></mtr><mtr><mtd><mi>sin</mi><mi>θ</mi></mtd><mtd><mi>cos</mi><mi>θ</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>x</mi></mtd></mtr><mtr><mtd><mi>y</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">旋转后取16×16窗口, 求每个像素的梯度幅值与方向, 用高斯窗口进行加权运算, 之后绘制4×4的8方向梯度直方图, 即产生了128维的SIFT特征向量。</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82"><b>1.2 SURF特征</b></h4>
                <div class="p1">
                    <p id="83">SURF<citation id="171" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>特征提取与SIFT特征提取过程有相似之处, 但更加快速且具有鲁棒性。首先对图像进行高斯平滑滤波得到具有尺度不变性的图像, 之后再利用Hessian矩阵<citation id="172" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。为了简化这2个步骤为1步, 使用了近似值替代Hessian矩阵的元素, 则Hessian矩阵变为了式 (8) 所示。由Hessian矩阵初步检测极值点:</p>
                </div>
                <div class="p1">
                    <p id="84"><i>Det</i> (<i>D</i>) =<i>D</i><sub><i>xx</i></sub><i>D</i><sub><i>yy</i></sub>- (0.9<i>D</i><sub><i>xy</i></sub>) <sup>2</sup>      (16) </p>
                </div>
                <div class="p1">
                    <p id="85">起始的滤波器采用9×9尺寸, 滤波器尺寸可由式 (17) ～ (19) 计算得到:</p>
                </div>
                <div class="p1">
                    <p id="86"><i>L</i>=3<i>l</i> (17) </p>
                </div>
                <div class="p1">
                    <p id="87"><i>l</i>=2<sup><i>o</i>+1</sup> (<i>s</i>+1) +1 (18) </p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><mo>=</mo><mn>1</mn><mo>.</mo><mn>2</mn><mo>×</mo><mfrac><mi>L</mi><mn>9</mn></mfrac><mo>=</mo><mn>1</mn><mo>.</mo><mn>2</mn><mo>×</mo><mfrac><mi>l</mi><mn>3</mn></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">式中:<i>o</i>、<i>s</i>与SIFT特征金字塔中含义相同;<i>L</i>为滤波器边长;<i>l</i>为响应长度;<i>o</i>和<i>s</i>的初始值都是从0开始, 构建的尺度空间是4层4组。</p>
                </div>
                <div class="p1">
                    <p id="90">之后与SIFT相似, 进行26邻域的极值检测。在以极值点为中心半径为6<i>σ</i>的圆形区域内统计60°扇形内Harr小波特征, 最后将最大值那个扇形的方向作为该特征点的主方向。</p>
                </div>
                <div class="p1">
                    <p id="91">以20<i>σ</i>为边长取特征点周围一个正方形框, 主方向为特征点的主方向, 将框分为16个子区域, 统计每个区域内5×5个像素的水平方向和垂直方向的Harr小波特征<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><mi>x</mi><mo>, </mo><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><mrow><mo>|</mo><mi>x</mi><mo>|</mo></mrow><mo>, </mo><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><mi>y</mi><mo>, </mo><mstyle displaystyle="true"><mo>∑</mo><mi>d</mi></mstyle><mrow><mo>|</mo><mi>y</mi><mo>|</mo></mrow></mrow></math></mathml>, 即水平方向值之和, 水平方向绝对值之和, 垂直方向值之和, 垂直方向绝对值之和。则最终将得到一个4×16维的特征描述子。</p>
                </div>
                <h4 class="anchor-tag" id="93" name="93"><b>1.3 特征匹配</b></h4>
                <div class="p1">
                    <p id="94">本文的特征提取系统, 分为2个部分进行。1) SIFT特征提取, 首先将输入的二维图像进行高斯模糊生成高斯金字塔, 每层金字塔内的相邻高斯图像差分得到高斯差分金字塔, 构建尺度空间, 之后进行空间极值点检测之后确定关键点定位和方向, 生成关键点描述;2) SURF特征提取, 首先是利用Hessian矩阵生成尺度空间, 之后进行极值检测后确定关键点定位及其方向, 生成关键点描述子。</p>
                </div>
                <div class="p1">
                    <p id="95">之后用提取的低分辨率图像的SIFT特征进行二维输入图像的匹配后储存匹配结果, 利用得到的图像匹配结果进行相机内参的计算并完成SFM增量式重建。计算所有图像中特征的轨迹, 选择一个合适的初始对后利用计算好的特征轨迹寻找合适的下一张图进行增量计算, 直到建立出完整视图。将得到的稀疏点云经过密集点云重建以及点云表面重建得到三维表面。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>2 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="97">本文系统基于VS2017平台与C++语言开发实现, 基于SIFT特征提取加入SURF特征提取, 所以本文的结果与SIFT特征提取结果进行对比。算法实验参数设置如下, SIFT特征提取中, 图像金字塔为5层 (0～4层) , 每层6张图像, 高斯模糊初始值<i>σ</i><sub>0</sub>=1.6。SURF特征提取中, 图像金字塔为4层 (0～3层) , 每层4张图像, 滤波器尺寸为:</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>9</mn></mtd><mtd><mn>1</mn><mn>5</mn></mtd><mtd><mn>2</mn><mn>1</mn></mtd><mtd><mn>2</mn><mn>7</mn></mtd></mtr><mtr><mtd><mn>1</mn><mn>5</mn></mtd><mtd><mn>2</mn><mn>7</mn></mtd><mtd><mn>3</mn><mn>9</mn></mtd><mtd><mn>5</mn><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn><mn>7</mn></mtd><mtd><mn>5</mn><mn>1</mn></mtd><mtd><mn>7</mn><mn>5</mn></mtd><mtd><mn>9</mn><mn>9</mn></mtd></mtr><mtr><mtd><mn>5</mn><mn>1</mn></mtd><mtd><mn>9</mn><mn>9</mn></mtd><mtd><mn>1</mn><mn>4</mn><mn>7</mn></mtd><mtd><mn>1</mn><mn>9</mn><mn>5</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">使用相同的一组无序图片共79张, 大小为2 592×1 728作为输入, 在SFM过程中分别使用SIFT特征提取以及SIFT联合SURF特征提取2种方法得到输出结果, 由SIFT方法提取出69 172个特征点的稀疏点云和相机内参, 而由SIFT和SURF方法提取出有59 847个特征点的稀疏点云和相机内参。之后利用相同的稠密点云重建方法, 分别得到14 511 503和14 333 997个特征点的稠密点云结果。利用稠密重建后的输出结果进行三维模型的表面重建, 首先利用FSSR对点云重建三维模型表面, 之后删除多余的表面输出最终结果。</p>
                </div>
                <div class="p1">
                    <p id="100">由SIFT特征方法得到的输出是有1 060 610个三角面片以及538 057个顶点数的三维模型。由SIFT特征联合SURF特征的方法得到的输出是有1 150 758个三角面片和582 732个顶点的三维模型。</p>
                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911019_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SIFT特征提取后的局部重建效果" src="Detail/GetImg?filename=images/DZCL201911019_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SIFT特征提取后的局部重建效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911019_101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="102">点云表面重建得到如图1～4的结果。如图1所示为仅用SIFT特征提取的表面重建出的局部效果, 图2所示为利用SIFT和SURF特征提取的表面重建出的局部效果。可以看到在相同的输入图像情况下, 2种特征提取方法的最终得到的表面重建结果都较好, 能体现出局部细节。</p>
                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911019_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SIFT特征与SURF特征提取后的局部重建效果" src="Detail/GetImg?filename=images/DZCL201911019_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 SIFT特征与SURF特征提取后的局部重建效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911019_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="104">如图3所示为仅用SIFT特征提取的表面重建整体效果, 图4所示为利用SIFT和SURF特征提取的表面重建整体效果。在相同的输入图像情况下, 使用SIFT和SURF特征的方法能够在光滑表面的目标处得到更多的特征点, 例如图像中的地面、阶梯等。</p>
                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911019_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 SIFT特征提取后的整体重建效果" src="Detail/GetImg?filename=images/DZCL201911019_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 SIFT特征提取后的整体重建效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911019_105.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201911019_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 SIFT特征与SURF特征提取后的整体重建效果" src="Detail/GetImg?filename=images/DZCL201911019_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 SIFT特征与SURF特征提取后的整体重建效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201911019_106.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="107">表1是重建后的网格模型的属性, 可以看出使用本文的方法, 重建出的稠密点云数量比较相近, 但在对表面重建后去除多余表面后保留了更多的顶点与三角面片, 在保证细节的同时提高对于三维重建的网格模型完整性。</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表1 重建的三维网格模型属性</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td><br />方法</td><td>SIFT</td><td>SIFT+SURF</td></tr><tr><td><br />输入图像</td><td>Der Hass (79张) </td><td>Der Hass (79张) </td></tr><tr><td><br />特征点数</td><td>69 172</td><td>59 847</td></tr><tr><td><br />稠密点云数</td><td>14 511 503</td><td>14 333 997</td></tr><tr><td><br />三角面片数</td><td>1 060 610</td><td>1 150 758</td></tr><tr><td><br />顶点数</td><td>538 057</td><td>582 732</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>3 结  论</b></h3>
                <div class="p1">
                    <p id="110">本文在SIFT特征提取的基础上使用了SIFT 特征和SURF特征的方法以提高对于边缘光滑目标特征点的检测能力, 提高重建三维模型的完整性与真实性。由实验结果发现, 在加入SURF特征后能够保持重建模型的细节部分, 在此基础上能够得到更完整的三维网格模型, 说明在加入SURF特征后, 虽然得到的特征点比SIFT特征提取出的少, 但是重建出的模型效果在细节处精度并没有因此降低, 且在表面光滑的目标处能够保留更多的三角面片。</p>
                </div>
                <div class="p1">
                    <p id="111">通过实验结果来看, 共同使用SIFT特征以及SURF特征可以在去除多余面后最终保留更多的顶点和面片, 尤其在对于表面光滑的目标, 能够在保证细节质量的情况下提高图像重建三维目标时的完整性与真实性。</p>
                </div>
                <div class="p1">
                    <p id="112">虽然只利用低分辨率图像的SIFT特征来做图像, 但因为SIFT特征描述子是128维的, 在重建过程中, 由图像得到特征点以及相机内参这一步耗时较长。之后可以利用改进的SURF特征描述子进行匹配, 能够对图像做出区分匹配且因描述子维度降低从而节省时间。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="128">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GFCK201501007&amp;v=MTAyMDJ2SVpiRzRIOVRNcm85Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNSWk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 吴彤, 傅中力.三维重建技术及其军事应用.国防科技, 2015, 36 (1) :31-34.
                            </a>
                        </p>
                        <p id="130">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JXUY201833007&amp;v=MDM2MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeTduVUx2TUx6WGVkN0c0SDluUHJJOUZZNFFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 曾宁, 范应方, 杨剑, 等.数字虚拟技术在肝胆外科临床教学中的应用研究[J].中国继续医学教育, 2018, 10 (33) :16-19.
                            </a>
                        </p>
                        <p id="132">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CHGC201709009&amp;v=MjY0NzdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNSmlYTWJiRzRIOWJNcG85RmI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 明国辉, 委民正.SURF算法在无人机倾斜摄影测量三维建模中的应用[J].测绘工程, 2017, 26 (9) :41-45.
                            </a>
                        </p>
                        <p id="134">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JZSX201806139&amp;v=MDQ0MTR6cXFCdEdGckNVUjdxZlp1WnRGeTduVUx2TUx6Zllkckc0SDluTXFZNUdiWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 吴宁, 陈佳舟, 吴凯乐.面向数字化保护的自动文物三维重建方法研究[J].山西建筑, 2018, 44 (6) :257-258.
                            </a>
                        </p>
                        <p id="136">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJDC201702015&amp;v=MDkzMTQ5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNTmlmUGJiRzRIOWJNclk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 霍林生, 张耀文, 李宏男.图像三维重建法在震损建筑实体建模中的应用研究[J].世界地震工程, 2017, 33 (2) :113-118.
                            </a>
                        </p>
                        <p id="138">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A comparison and evaluation of multi-view stereo reconstruction algorithms">

                                <b>[6]</b> SEITZ S M, CURLESS B, DIEBEL J, et al.A comparison and evaluation of multi-view stereo reconstruction algorithms[C].Ppwer Symposium (NAPS) , 2005:519-528.
                            </a>
                        </p>
                        <p id="140">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MVE-A Multi-View Reconstruction Environment">

                                <b>[7]</b> FUHRMANN S, LANGGUTH F, GOESELE M.MVE-A multiview reconstruction environment[C].GCH′14 Proceedings of the Eurogcaphics Workshop on Graphics and Cultural Heritage, 2014:11-18.
                            </a>
                        </p>
                        <p id="142">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Global, dense multiscale reconstruction for a billion points">

                                <b>[8]</b> UMMENHOFER B, BROX T.Global, dense multiscale reconstruction for a billion points[C].Proceedings of the IEEE International Conference on Computer Vision.2015:1341-1349.
                            </a>
                        </p>
                        <p id="144">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002830901&amp;v=MjU4MjRTWHFScnhveGNNSDdSN3FkWitadUZpdmxWYjNMSkZvPU5qN0Jhck80SHRIT3A0eEZiZXNPWTNrNXpCZGg0ajk5&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> LOWE D G.Distinctive image features from scale-invariant keypoints[J].International Journal of Computer Vision, 2004, 60 (2) :91-110.
                            </a>
                        </p>
                        <p id="146">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083888&amp;v=MjkzMzRNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSmx3WGJoWT1OaWZPZmJLN0h0RE5xbzlFWk9NTUJIUXhvQg==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> BAY H, ESS A, TUYTELAARS T, et al.Speeded-up robust features (SURF) [J].Computer Vision And Image Understanding, 2008, 110 (3) :346-359.
                            </a>
                        </p>
                        <p id="148">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Score level based latent fingerprint enhancement and matching using SIFT feature">

                                <b>[11]</b> MANICKAM A, DEVARASAN E, MANOGARAN G, et al.Score level based latent fingerprint enhancement and matching using SIFT feature[J].Multimedia Tools and Applications, 2018, 78 (3) :1-21.
                            </a>
                        </p>
                        <p id="150">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image-based surface reconstruction in geomorphometry-merits,limits and developments">

                                <b>[12]</b> ELTNER A, KAISER A, CASTILLO C, et al.Image-based surface reconstruction in geomorphometry-merits, limits and developments[J].Earth Surface Dynamics, 2016, 4 (2) :359-389.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tracking Feature Extraction Techniques with Improved SIFT for Video Identification">

                                <b>[13]</b> JIN R, KIM J.Tracking feature extraction techniques with improved SIFT for video identification[J].Multimedia Tools and Applications, 2017, 76 (4) :5927-5936.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJCH201404006&amp;v=MjU4NzQ5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5N25VTHZNSnlmSVpyRzRIOVhNcTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 索春宝, 杨东清, 刘云鹏.多种角度比较SIFT、SURF、BRISK、ORB、FREAK算法[J].北京测绘, 2014 (4) :23-26, 22.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201604017&amp;v=MjQzNzJxNDlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk3blVMdk1JVGZJWXJHNEg5Zk0=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 王凌云, 尹海波, 王琪.SURF和RANSAC在图像拼接中的应用[J].电子测量技术, 2016, 39 (4) :71-75.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201911019" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201911019&amp;v=MTMxODZxZlp1WnRGeTduVUx2TUlUZklZckc0SDlqTnJvOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN6dEtvMkhTQkozQzBMTGlhZVljcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

