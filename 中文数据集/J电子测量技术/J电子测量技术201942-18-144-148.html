

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135588164162500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dDZCL201918025%26RESULT%3d1%26SIGN%3drPBRjz7kO6Esu%252f3Zj1QD9qigN1c%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201918025&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201918025&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201918025&amp;v=MjAyNjFyQ1VSN3FmWnVadEZ5bmdWTHZBSVRmSVlyRzRIOWpOcDQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 基于深度学习的短文本分类模型&lt;/b&gt; "><b>1 基于深度学习的短文本分类模型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;1.1 改进卷积神经网络(ICNN&lt;/b&gt;)"><b>1.1 改进卷积神经网络(ICNN</b>)</a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;1.2 长短期记忆卷积神经网络的文本分类&lt;/b&gt;"><b>1.2 长短期记忆卷积神经网络的文本分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="&lt;b&gt;2 基于LSTM-ICNN的短文本分类&lt;/b&gt; "><b>2 基于LSTM-ICNN的短文本分类</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;3 实验仿真&lt;/b&gt; "><b>3 实验仿真</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#97" data-title="&lt;b&gt;3.1 实验设置&lt;/b&gt;"><b>3.1 实验设置</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;3.2 仿真结果&lt;/b&gt;"><b>3.2 仿真结果</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;3.3 结果分析&lt;/b&gt;"><b>3.3 结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#115" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="图1 改进卷积神经网络结构">图1 改进卷积神经网络结构</a></li>
                                                <li><a href="#71" data-title="图2 基于LSTM的短文本分类结构">图2 基于LSTM的短文本分类结构</a></li>
                                                <li><a href="#84" data-title="图3 LSTM-ICNN结构">图3 LSTM-ICNN结构</a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;表1 样本数据属性&lt;/b&gt;"><b>表1 样本数据属性</b></a></li>
                                                <li><a href="#101" data-title="图4 3种算法在不同数据集上的分类对比">图4 3种算法在不同数据集上的分类对比</a></li>
                                                <li><a href="#104" data-title="图5 卷积核不同时分类效果">图5 卷积核不同时分类效果</a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表2 分类效果对比&lt;/b&gt;"><b>表2 分类效果对比</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;表3 大类问题的分类结果&lt;/b&gt;/%"><b>表3 大类问题的分类结果</b>/%</a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;表4 分类效果对比&lt;/b&gt;/%"><b>表4 分类效果对比</b>/%</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="127">


                                    <a id="bibliography_1" title=" 马丽菲,莫倩,杜辉.面向中文短影评的分类技术研究[J].山东大学学报(理学版),2016,51(1):52-57." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SDDX201601007&amp;v=MzA5MTBmTXJvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5nVkx2QU5pblBkckc0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         马丽菲,莫倩,杜辉.面向中文短影评的分类技术研究[J].山东大学学报(理学版),2016,51(1):52-57.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_2" title=" 李志宇,梁循,周小平.基于属性主题分割的评论短文本词向量构建优化算法[J].中文信息学报,2016,30(5):101-110,120." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201605015&amp;v=MTc0OTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBS0NqWWZiRzRIOWZNcW85RVlZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         李志宇,梁循,周小平.基于属性主题分割的评论短文本词向量构建优化算法[J].中文信息学报,2016,30(5):101-110,120.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_3" title=" 刘晓琳,曹付元,梁吉业.面向新闻评论的短文本增量聚类算法[J].计算机科学与探索,2018,12(6):950-960." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201806011&amp;v=MTA4NTJGeW5nVkx2QUxqWGZmYkc0SDluTXFZOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         刘晓琳,曹付元,梁吉业.面向新闻评论的短文本增量聚类算法[J].计算机科学与探索,2018,12(6):950-960.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_4" title=" 王义真,郑啸,后盾,等.基于SVM的高维混合特征短文本情感分类[J].计算机技术与发展,2018,28(2):88-93." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201802020&amp;v=MzA3MDU3cWZadVp0RnluZ1ZMdkFNaWZOZExHNEg5bk1yWTlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         王义真,郑啸,后盾,等.基于SVM的高维混合特征短文本情感分类[J].计算机技术与发展,2018,28(2):88-93.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_5" title=" 刘小敏,王昊,李心蕾,等.不同特征粒度在微博短文本分类中作用的比较研究[J].情报科学,2018,36(12):126-133." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBKX201812024&amp;v=MTY3NjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBTkMvQWRyRzRIOW5Oclk5SFlJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         刘小敏,王昊,李心蕾,等.不同特征粒度在微博短文本分类中作用的比较研究[J].情报科学,2018,36(12):126-133.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_6" title=" 李晓红,冉宏艳,龚继恒,等.基于改进相似度与类中心向量的半监督短文本聚类算法[J].计算机工程与科学,2018,40(9):1710-1716." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201809026&amp;v=MzExOTRuZ1ZMdkFMejdCWmJHNEg5bk1wbzlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         李晓红,冉宏艳,龚继恒,等.基于改进相似度与类中心向量的半监督短文本聚类算法[J].计算机工程与科学,2018,40(9):1710-1716.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_7" title=" 崔婉秋,杜军平,寇菲菲,等.面向微博短文本的社交与概念化语义扩展搜索方法[J].计算机研究与发展,2018,55(8):1641-1652." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201808006&amp;v=MjAxMjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkFMeXZTZExHNEg5bk1wNDlGWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         崔婉秋,杜军平,寇菲菲,等.面向微博短文本的社交与概念化语义扩展搜索方法[J].计算机研究与发展,2018,55(8):1641-1652.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_8" title=" 冯靖,莫秀良,王春东.基于LDA改进的K-means算法在短文本聚类中的研究[J].天津理工大学学报,2018,34(3):7-11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TEAR201803002&amp;v=MjQ1OTF0RnluZ1ZMdkFNU2pLZkxHNEg5bk1ySTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         冯靖,莫秀良,王春东.基于LDA改进的K-means算法在短文本聚类中的研究[J].天津理工大学学报,2018,34(3):7-11.
                                    </a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_9" title=" 刘德喜,付淇,韦亚雄,等.基于多重增强图和主题分析的社交短文本检索方法[J].中文信息学报,2018,32(3):110-119." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201803015&amp;v=MDg0MzZxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkFLQ2pZZmJHNEg5bk1ySTlFWVlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         刘德喜,付淇,韦亚雄,等.基于多重增强图和主题分析的社交短文本检索方法[J].中文信息学报,2018,32(3):110-119.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_10" title=" 卢玲,杨武,杨有俊,等.结合语义扩展和卷积神经网络的中文短文本分类方法[J].计算机应用,2017,37(12):3498-3503." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201712028&amp;v=MjA4MjNCZDdHNEg5Yk5yWTlIYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkFMejc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         卢玲,杨武,杨有俊,等.结合语义扩展和卷积神经网络的中文短文本分类方法[J].计算机应用,2017,37(12):3498-3503.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_11" title=" 周飞燕,金林鹏,董军.卷积神经网络研究综述[J].计算机学报,2017,40(6):1229-1251." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201706001&amp;v=MTIwMTBiTXFZOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUx6N0Jkckc0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         周飞燕,金林鹏,董军.卷积神经网络研究综述[J].计算机学报,2017,40(6):1229-1251.
                                    </a>
                                </li>
                                <li id="149">


                                    <a id="bibliography_12" title=" 梁斌,刘全,徐进,等.基于多注意力卷积神经网络的特定目标情感分析[J].计算机研究与发展,2017,54(8):1724-1735." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201708009&amp;v=MTI4NDRkTEc0SDliTXA0OUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUx5dlM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         梁斌,刘全,徐进,等.基于多注意力卷积神经网络的特定目标情感分析[J].计算机研究与发展,2017,54(8):1724-1735.
                                    </a>
                                </li>
                                <li id="151">


                                    <a id="bibliography_13" title=" 殷亚博,杨文忠,杨慧婷,等.基于卷积神经网络和KNN的短文本分类算法研究[J].计算机工程,2018,44(7):193-198." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201807034&amp;v=MjM1MjZHNEg5bk1xSTlHWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkFMejdCYmI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         殷亚博,杨文忠,杨慧婷,等.基于卷积神经网络和KNN的短文本分类算法研究[J].计算机工程,2018,44(7):193-198.
                                    </a>
                                </li>
                                <li id="153">


                                    <a id="bibliography_14" title=" 曾蒸,李莉,陈晶.用于情感分类的双向深度LSTM[J].计算机科学,2018,45(8):213-217,252." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201808040&amp;v=MjgxNDBMejdCYjdHNEg5bk1wNDlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         曾蒸,李莉,陈晶.用于情感分类的双向深度LSTM[J].计算机科学,2018,45(8):213-217,252.
                                    </a>
                                </li>
                                <li id="155">


                                    <a id="bibliography_15" title=" 高成亮,徐华,高凯.结合词性信息的基于注意力机制的双向LSTM的中文文本分类[J].河北科技大学学报,2018,39(5):447-454." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HBQJ201805012&amp;v=MTk3NTdvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBTFMvYVpMRzRIOW5NcW85RVo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         高成亮,徐华,高凯.结合词性信息的基于注意力机制的双向LSTM的中文文本分类[J].河北科技大学学报,2018,39(5):447-454.
                                    </a>
                                </li>
                                <li id="157">


                                    <a id="bibliography_16" title=" WEN X,ZHANG Y,LIU T,et al.Syntactic structure parsing based chinese question classification[J].Journal of Chinese Information Processing,2006,20(2):33-39." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200602004&amp;v=MjYyNzBadEZ5bmdWTHZBS0NqWWZiRzRIdGZNclk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         WEN X,ZHANG Y,LIU T,et al.Syntactic structure parsing based chinese question classification[J].Journal of Chinese Information Processing,2006,20(2):33-39.
                                    </a>
                                </li>
                                <li id="159">


                                    <a id="bibliography_17" title=" SUN J G,CAI D F,LV D X,et al.HowNet based Chinese question automatic classification[J].Journal of Chinese Information Processing,2007,21(1):90-95." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200701014&amp;v=MjAyNTdCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUtDallmYkc0SHRiTXJvOUVZSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         SUN J G,CAI D F,LV D X,et al.HowNet based Chinese question automatic classification[J].Journal of Chinese Information Processing,2007,21(1):90-95.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(18),144-148 DOI:10.19651/j.cnki.emt.1902860            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于LSTM-ICNN的网络情报信息技术研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%B2%E7%90%A6&amp;code=41137955&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曲琦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%AD%A3%E5%87%AF&amp;code=41137954&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张正凯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%AE%B8%E8%83%9C%E4%B9%8B&amp;code=41137953&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">许胜之</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%BD%E7%BD%91%E5%9B%BD%E9%99%85%E5%8F%91%E5%B1%95%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8&amp;code=0108958&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国网国际发展有限公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统的短本文分类方法不仅会造成特征向量的高稀疏性及维度灾难,而且还不能准确表达语序信息,采用改进卷积神经网络(ICNN)能够对文本特征进行有效挖掘,长短期记忆神经网络(LSTM)能够实现语序的准确表达,为此提出了基于LSTM-ICNN的短文本分类技术研究。首先,为了提高传统卷积神经网络的特征提取能力,引入了三种卷积核因子,提高了短文本特征信息的获取量。然后,由于LSTM具有优秀的字词序列语义表达效果,所以提出了基于LSTM-ICNN的短文本分类方法,该方法解决了短文本分类时特征量较少及语序表达不准确的问题。实验对比分析显示,在相同条件下,相比于其他传统的分类算法, LSTM-ICNN的短文本分类准确度最高,而且与现有研究成果相比, LSTM-ICNN方法具有明显优势,验证了本文所提方法的有效性和实用性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%AD%E6%96%87%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">短文本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张正凯,研究生,高级工程师,主要研究方向为跨国信息化管理。E-mail:2871665175@qq.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-25</p>

            </div>
                    <h1><b>Study on network intelligence information technology based on LSTM-ICNN</b></h1>
                    <h2>
                    <span>Qu Qi</span>
                    <span>Zhang Zhengkai</span>
                    <span>Xu Shengzhi</span>
            </h2>
                    <h2>
                    <span>State Grid International Development Co.,Ltd</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional short text classification method not only cause high sparsity and dimensional disaster of feature vectors, but also fail to accurately express word order information. The improved convolutional neural network(ICNN) can be used to effectively mine text features, and the long short-term memory neural network(LSTM) can realize the accurate expression of word order. Therefore, this paper proposes the study of short text classification technology based on LSTM-ICNN. Firstly, in order to improve the feature extraction ability of the traditional convolutional neural network, three convolution kernel factors are introduced to improve the amount of feature information in the short text. Then, because the excellent semantic expression effect of word sequences, a short text classification method based on LSTM-ICNN is proposed, which solves the problem of less feature quantity and inaccurate word order expression in short text classification. Experimental comparative analysis shows that, under the same conditions, compared with other traditional classification algorithms, LSTM-ICNN short text classification has the highest accuracy, and compared with existing research results, LSTM-ICNN method has obvious advantages, which verifies the effectiveness and practicability of the method proposed in this paper.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=long%20short-term%20memory%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">long short-term memory neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=short%20text&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">short text;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-03-25</p>
                            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="38">随着网络技术的快速发展和完善,作为信息服务中心的一种,互联网成为获取信息及知识重要来源,为人们工作和生活带来便利,同时互联网具备开放性、无界性等特点,随着自媒体时代的到来,互联网上的信息数量巨大,种类繁多,普遍存在信息质量参差不齐的现象,甚至有很多信息是虚假、有误、无用的,这些繁多的良莠不齐的信息给信息搜索带来挑战,作为商业工具的主流搜索引擎成为人们查找所需信息的主要渠道,用户筛选信息的时间和精力有限,由于排在前面的不一定是信息质量可靠的网页,同时存在大量重复和转载网页,降低了用户获取信息的效率,提高网络信息抽取的效率和准确率是提高搜索结果质量的重要保障<citation id="161" type="reference"><link href="127" rel="bibliography" /><link href="129" rel="bibliography" /><link href="131" rel="bibliography" /><link href="133" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="39">对短文本进行信息分类和抽取的研究受到了人们的广泛关注,近年来关于此类问题的研究也越来越多,文献<citation id="162" type="reference">[<a class="sup">5</a>]</citation>以微博为例,对词和字两种特征在短文本分类中的作用进行分析,实验结果显示,字特征在文本分类中的作用更大。文献<citation id="163" type="reference">[<a class="sup">6</a>]</citation>提出了一种改进相似度和类中心向量的短文本聚类方法,对比实验结果显示,提出的文本聚类准确性及效率比其他算法有了很大提高。文献<citation id="164" type="reference">[<a class="sup">7</a>]</citation>提出了一种社交与概念化语义相结合的文本搜索方法,对微博短文本进行精准搜索,实验结果表明,采用该方法的微博搜索性能得到了显著提升。文献<citation id="165" type="reference">[<a class="sup">8</a>]</citation>采用Latent Dirichlet Allocation模型建立数据模型,扩展了聚类的特征,并结合了K-means和Canopy算法,提高了聚类效果。文献<citation id="166" type="reference">[<a class="sup">9</a>]</citation>提出了一种基于多重增强图的短文本搜索方法,根据文本,作者,词语等进行建模,对比仿真实验结果显示,相比于其他传统算法,该方法在短文本检索上具有较好的效果。文献<citation id="167" type="reference">[<a class="sup">10</a>]</citation>采用Word Embedding的文本语义扩展方法,提高文本分类的准确率,通过将标题扩展成标题、副标题、主题词三元组,选用卷积神经网络建立文本分类模型,实验结果表明采用三元组建立的模型准确率为79.42%,提高了卷积神经网络的分类效果。</p>
                </div>
                <div class="p1">
                    <p id="40">如何快速准确的从海量文本信息中获取有用的信息,并加以利用,有利于解决信息多乱的问题,本文对长短期记忆神经网络进行了改进,用于挖掘短文本特征信息,并采用改进的神经网络建立学习问题句,候选信息句,和候选信息之间的关系。</p>
                </div>
                <h3 id="41" name="41" class="anchor-tag"><b>1 基于深度学习的短文本分类模型</b></h3>
                <h4 class="anchor-tag" id="42" name="42"><b>1.1 改进卷积神经网络(ICNN</b>)</h4>
                <div class="p1">
                    <p id="43">在进行短文本分类时,由于文本信息少,特征较少,而传统的卷积神经网络会导致数据信息的丢失,为了获取短文本中更多的特征信息,对卷积神经网络进行改进<citation id="168" type="reference"><link href="147" rel="bibliography" /><link href="149" rel="bibliography" /><link href="151" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>。改进卷积神经网络结构如图1所示。</p>
                </div>
                <div class="area_img" id="44">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201918025_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 改进卷积神经网络结构" src="Detail/GetImg?filename=images/DZCL201918025_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 改进卷积神经网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201918025_044.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="45">ICNN有A,B,C三种卷积核,每个卷积核都可以获得文本的特征状况。特征输出为隐藏层<i>h</i><sub><i>A</i></sub>,<i>h</i><sub><i>B</i></sub>,<i>h</i><sub><i>C</i></sub>,隐层<i>h</i><sub><i>A</i></sub>的求取方法为:</p>
                </div>
                <div class="p1">
                    <p id="46"><i>h</i><sub><i>A</i></sub>=<i>t</i>(<i>pooling</i>(<i>σ</i>(<i>w</i><sub><i>A</i></sub><i>Q</i>))+<i>b</i><sub><i>A</i></sub>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="47">式中:<i>w</i><sub><i>A</i></sub>是<i><b>A</b></i>卷积核的参数矩阵。文本表示为三个隐藏元的连接:<i>h</i>=(<i>h</i><sub><i>A</i></sub><i>h</i><sub><i>B</i></sub><i>h</i><sub><i>C</i></sub>)。</p>
                </div>
                <div class="p1">
                    <p id="48">其实现过程为:将文本中的词表示为词向量,句子<i>Q</i>=<i>q</i><sub>1</sub>,<i>q</i><sub>2</sub>,…,<i>q</i><sub>11</sub>,<i>q</i><sub><i>i</i></sub>表示为第<i>i</i>个词的词向量,<i>n</i>是文本中含有的词语个数。隐层是由特征map构成的,每个map又包含了<i>h</i><sub><i>i</i></sub>个隐藏神经元。每个隐藏神经元<i>h</i><sub><i>i</i></sub>的求取公式为式(2)。</p>
                </div>
                <div class="p1">
                    <p id="49"><i>h</i><sub><i>i</i></sub>=<i>t</i>(<i>pooling</i>(<i>σ</i>(<i>w</i><sub><i>i</i></sub><i>Q</i>))+<i>b</i><sub><i>t</i></sub>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="50">式中:<i>σ</i>为激活函数sigmoid;<i>t</i>是激活函数tanh;<i>w</i><sub><i>i</i></sub>是卷积核参数;<i>b</i><sub><i>t</i></sub>是偏置系数;pooling是池化操作。每个粒度经过卷积核卷积后会产生特征map,当全部粒度实现卷积操作后,进行池化操作,然后经过连接层的操作之后,做为softMax分类器的输入。softMax分类计算公式如式(3)所示。</p>
                </div>
                <div class="p1">
                    <p id="51"><i>P</i><sub><i>qi</i></sub>=<i>σ</i>(<i>w</i><sub><i>m</i></sub><i>H</i><sub><i>m</i></sub>+<i>b</i><sub><i>m</i></sub>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="52">式中:<i>H</i><sub><i>m</i></sub>是经过池化操作后的神经元输出;<i>w</i><sub><i>m</i></sub>是softMax权值;<i>b</i><sub><i>m</i></sub>是softMax的偏置。ICNN对短文本分类的过程如下:</p>
                </div>
                <div class="p1">
                    <p id="53">1)模型参数输入。<i>Q</i>(<i>q</i><sub>1</sub>,<i>q</i><sub>2</sub>,…,<i>q</i><sub><i>n</i></sub>)为文本数据,<i>q</i><sub><i>n</i></sub>是词向量。</p>
                </div>
                <div class="p1">
                    <p id="54">2)数据预处理。将文本信息截取成长度相同的句子,不够长度的用0补充。</p>
                </div>
                <div class="p1">
                    <p id="55">3)建立ICNN的文本分类模型包含<i>n</i>个隐层神经元,<i>m</i>个粒度不同的卷积核。输入层经过<i>m</i>个隐层神经元后获得<i>m</i>个隐藏层,然后进行池化处理,再进行<i>k</i>个隐藏单元的全连接层计算获得<i>k</i>个特征后,采用选用的分类器分类。</p>
                </div>
                <div class="p1">
                    <p id="56">4)参数初始化操作。</p>
                </div>
                <div class="p1">
                    <p id="57">5)对于每个<mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>〈</mo><mover accent="true"><mi>Q</mi><mo>→</mo></mover><mo>,</mo><mover accent="true"><mi>y</mi><mo>→</mo></mover><mo>〉</mo></mrow></math></mathml>,在未达到终止条件前进行如下操作。</p>
                </div>
                <div class="p1">
                    <p id="58">输入沿模型前向传播。第<i>i</i>个卷积核到隐藏元<i>h</i><sub><i>i</i></sub>传递并进行池化操作<i>h</i><sub><i>i</i></sub>=<i>t</i>(<i>pooling</i>(<i>σ</i>(<i>w</i><sub><i>i</i></sub><i>Q</i>))+<i>b</i><sub><i>t</i></sub>)。</p>
                </div>
                <div class="p1">
                    <p id="59">M个隐藏层连接h:<i>h</i>←<i>h</i><sub>1</sub>,<i>h</i><sub>2</sub>,…,<i>h</i><sub><i>m</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="60">全连接层隐藏输出单元Hk:</p>
                </div>
                <div class="p1">
                    <p id="61"><i>H</i><sub><i>k</i></sub>=<i>sigmoid</i>(<i>wh</i>+<i>b</i>)。</p>
                </div>
                <div class="p1">
                    <p id="62">Softmax层概率公式:</p>
                </div>
                <div class="p1">
                    <p id="63"><i>P</i><sub><i>Qi</i></sub>=<i>sigmoid</i>(<i>wH</i>+<i>b</i>)。</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mtext>代</mtext><mtext>价</mtext><mtext>函</mtext><mtext>数</mtext><mtext>J</mtext><mo stretchy="false">(</mo><mtext>w</mtext><mo>,</mo><mtext>b</mtext><mo stretchy="false">)</mo><mo>:</mo><mspace width="0.25em" /><mi>J</mi><mo stretchy="false">(</mo><mi>w</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>←</mo><mo>-</mo><mstyle displaystyle="true"><mo>∑</mo><mrow><mi>log</mi></mrow></mstyle><mo stretchy="false">(</mo><mi>Ρ</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo></mtd></mtr><mtr><mtd><mi>y</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">|</mo><mi>Q</mi><msup><mrow></mrow><mi>i</mi></msup><mo>,</mo><mi>w</mi><mo>,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><mrow><mo>|</mo><mi>w</mi><mo>|</mo></mrow><mo stretchy="false">)</mo><mo>。</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">反向传播更新模型权值参数<i>w</i>,<i>b</i>。</p>
                </div>
                <div class="p1">
                    <p id="66"><i>w</i>←<i>w</i>+<i>Δw</i>,<i>w</i>←<i>w</i>+<i>Δw</i></p>
                </div>
                <div class="p1">
                    <p id="67">其中,<i>Δw</i>=∂<i>J</i>(<i>w</i>,<i>b</i>)/<i>w</i>,<i>Δb</i>=∂<i>J</i>(<i>w</i>,<i>b</i>)/<i>b</i>。</p>
                </div>
                <div class="p1">
                    <p id="68">在ICNN中,pooling是最大池化操作。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>1.2 长短期记忆卷积神经网络的文本分类</b></h4>
                <div class="p1">
                    <p id="70">长短期记忆神经网络(LSTM)是为了对传统的循环神经网络(RNN)进行改进<citation id="169" type="reference"><link href="153" rel="bibliography" /><link href="155" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。在采用LSTM对短文本进行分类的结构如图2所示。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201918025_071.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于LSTM的短文本分类结构" src="Detail/GetImg?filename=images/DZCL201918025_071.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于LSTM的短文本分类结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201918025_071.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72">将短文本分割成词向量,作为LSTM的输入,采用softMax作为分类器。<i>t</i>时刻的输入<i>q</i><sub><i>t</i></sub>,(<i>q</i><sub><i>t</i></sub>表示问题<i>q</i>中第<i>t</i>个词)此时LSTM的输出<i>h</i><sub><i>t</i></sub>求取过程为:</p>
                </div>
                <div class="p1">
                    <p id="73"><i>c</i><sub><i>t</i></sub>=<i>i</i><sub><i>t</i></sub>*tanh(<i>w</i><sub><i>c</i></sub><i>q</i><sub><i>t</i></sub>+<i>u</i><sub><i>c</i></sub><i>h</i><sub><i>t</i></sub><sub>-1</sub>+<i>b</i><sub><i>c</i></sub>)+<i>f</i><sub><i>t</i></sub><i>c</i><sub><i>t</i></sub><sub>-1</sub>      (4)</p>
                </div>
                <div class="p1">
                    <p id="74">式中:<i>w</i><sub><i>c</i></sub>,<i>u</i><sub><i>c</i></sub>为权重系数,<i>b</i><sub><i>c</i></sub>是阈值;<i>h</i><sub><i>t</i></sub><sub>-1</sub>是上一个LSTM的输出;<i>c</i><sub><i>t</i></sub><sub>-1</sub>是上一个隐藏单元的记忆单元;<i>i</i><sub><i>t</i></sub>和<i>f</i><sub><i>t</i></sub>分别是输入门和遗忘门。求取过程表示为:</p>
                </div>
                <div class="p1">
                    <p id="75"><i>i</i><sub><i>t</i></sub>=<i>σ</i>(<i>w</i><sub><i>i</i></sub><i>q</i><sub><i>t</i></sub>+<i>u</i><sub><i>i</i></sub><i>h</i><sub><i>t</i></sub><sub>-1</sub>+<i>b</i><sub><i>i</i></sub>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="76"><i>f</i><sub><i>t</i></sub>=<i>σ</i>(<i>w</i><sub><i>f</i></sub><i>q</i><sub><i>t</i></sub>+<i>u</i><sub><i>f</i></sub><i>h</i><sub><i>t</i></sub><sub>-1</sub>+<i>b</i><sub><i>f</i></sub>)      (6)</p>
                </div>
                <div class="p1">
                    <p id="77">计算出<i>t</i>时刻的记忆单元<i>c</i><sub><i>t</i></sub>,求取<i>t</i>时刻记忆单元的输出<i>o</i><sub><i>t</i></sub>和<i>h</i><sub><i>t</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="78"><i>o</i><sub><i>t</i></sub>=<i>σ</i>(<i>w</i><sub><i>o</i></sub><i>q</i><sub><i>t</i></sub>+<i>u</i><sub><i>o</i></sub><i>h</i><sub><i>t</i></sub><sub>-1</sub>+<i>b</i><sub><i>o</i></sub>)      (7)</p>
                </div>
                <div class="p1">
                    <p id="79"><i>h</i><sub><i>t</i></sub>=<i>o</i><sub><i>t</i></sub>tanh(<i>c</i><sub><i>t</i></sub>)      (8)</p>
                </div>
                <div class="p1">
                    <p id="80">LSTM的最终时刻<i>T</i>的输出<i>h</i><sub><i>T</i></sub>,输入softMax,求取分类概率。</p>
                </div>
                <div class="p1">
                    <p id="81"><i>P</i><sub><i>qi</i></sub>=<i>σ</i>(<i>w</i><sub><i>T</i></sub><i>H</i><sub><i>T</i></sub>+<i>b</i><sub><i>T</i></sub>)      (9)</p>
                </div>
                <h3 id="82" name="82" class="anchor-tag"><b>2 基于LSTM-ICNN的短文本分类</b></h3>
                <div class="p1">
                    <p id="83">由于ICNN挖掘的信息特征较多,而LSTM在表示字词序列语义有更好的效果,为了集中两种方法在短文本分类上的优点,提出了结合长短期记忆神经网络和改进的卷积神经网络(LSTM-ICNN)方法。先采用LSTM方法表示文本中语言量的时序规律,对句法和语义进行总结,然后采用改进的卷积神经网络对短文本的特征进行提取。LSTM-ICNN算法的结构如图3所示。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201918025_084.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 LSTM-ICNN结构" src="Detail/GetImg?filename=images/DZCL201918025_084.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 LSTM-ICNN结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201918025_084.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="85">LSTM-ICNN的实现过程可以表示为:短文本<i><b>Q</b></i><sub><i>i</i></sub>表示为词向量:<i><b>Q</b></i><sub><i>i</i></sub>=(<i>q</i><sub>1</sub><i>q</i><sub>2</sub><i>q</i><sub>3</sub><i>q</i><sub>4</sub>)。如图3所示的递归层用于学习词序列的特征。当计算3时刻隐藏层单元的输出<i>h</i><sub><i>L</i></sub><sub>3</sub>,先求取记忆单元<i>c</i><sub>3</sub>。</p>
                </div>
                <div class="p1">
                    <p id="86"><i>c</i><sub>3</sub>=<i>i</i><sub>3</sub>*tanh(<i>w</i><sub><i>c</i></sub><i>q</i><sub>3</sub>+<i>u</i><sub><i>c</i></sub><i>h</i><sub><i>L</i></sub><sub>2</sub>+<i>b</i><sub><i>c</i></sub>)+<i>f</i><sub>3</sub><i>c</i><sub>2</sub>      (10)</p>
                </div>
                <div class="p1">
                    <p id="87">式中:<i>w</i><sub><i>c</i></sub>,<i>u</i><sub><i>c</i></sub>,<i>b</i><sub><i>c</i></sub>分别为权重系数和偏置系数;<i>h</i><sub><i>L</i></sub><sub>2</sub>,<i>c</i><sub>2</sub>表示前一时刻隐藏单元输出及记忆信息;<i>i</i><sub>3</sub>,<i>f</i><sub>3</sub>表示3时刻输入门和遗忘门。其求取过程为:</p>
                </div>
                <div class="p1">
                    <p id="88"><i>i</i><sub>3</sub>=<i>σ</i>(<i>w</i><sub><i>i</i></sub><i>q</i><sub>3</sub>+<i>u</i><sub><i>i</i></sub><i>h</i><sub><i>L</i></sub><sub>2</sub>+<i>b</i><sub><i>i</i></sub>)      (11)</p>
                </div>
                <div class="p1">
                    <p id="89"><i>f</i><sub>3</sub>=<i>σ</i>(<i>w</i><sub><i>f</i></sub><i>q</i><sub>3</sub>+<i>u</i><sub><i>f</i></sub><i>h</i><sub><i>L</i></sub><sub>2</sub>+<i>b</i><sub><i>f</i></sub>)      (12)</p>
                </div>
                <div class="p1">
                    <p id="90">接着求取3时刻记忆单元的输出门o<sub>3</sub>和隐藏单元<i>h</i><sub><i>L</i></sub><sub>3</sub>。</p>
                </div>
                <div class="p1">
                    <p id="91"><i>o</i><sub>3</sub>=<i>σ</i>(<i>w</i><sub><i>o</i></sub><i>q</i><sub>3</sub>+<i>u</i><sub><i>o</i></sub><i>h</i><sub><i>L</i></sub><sub>2</sub>+<i>b</i><sub><i>o</i></sub>)      (13)</p>
                </div>
                <div class="p1">
                    <p id="92"><i>h</i><sub>3</sub>=<i>o</i><sub>3</sub>tanh(<i>c</i><sub>3</sub>)      (14)</p>
                </div>
                <div class="p1">
                    <p id="93">卷积核A,B的窗口尺寸分别为2和3,则<i>h</i><sub><i>A</i></sub><sub>1</sub>的求取过程为:</p>
                </div>
                <div class="p1">
                    <p id="94"><i>h</i><sub><i>A</i></sub><sub>1</sub>=<i>t</i>(<i>pooling</i>(<i>σ</i>(<i>w</i><sub><i>A</i></sub><i>h</i><sub><i>LA</i></sub><sub>1</sub>))+<i>b</i><sub><i>A</i></sub>)      (15)</p>
                </div>
                <div class="p1">
                    <p id="95">式中:<i>w</i><sub><i>A</i></sub>是卷积核A的系数矩阵;<i>h</i><sub><i>LA</i></sub><sub>1</sub>是由<i>h</i><sub><i>L</i></sub><sub>1</sub>和<i>h</i><sub><i>L</i></sub><sub>2</sub> 构成的矩阵;<i>T</i>为激活函数tanh。卷积层的输出作为Softmax分类器的输入,最后获得短文本分类结果。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>3 实验仿真</b></h3>
                <h4 class="anchor-tag" id="97" name="97"><b>3.1 实验设置</b></h4>
                <div class="p1">
                    <p id="98">为了对比上文所述的短文本分类方法的优劣,选取了中文维基百科训练语料的词向量150维。采用word2vec对词向量进行训练。使用的数据主要来包括3个部分:1)复旦大学2 400个样本;2)NLPCC有888个样本,分类数据集共9 600个样本;3)哈尔滨工业大学有样本6 312个。这3个部分的数据主要包含6个大类和84个小类。将实验用数据分成训练集和测试集。数据情况如表1所示。</p>
                </div>
                <div class="area_img" id="99">
                    <p class="img_tit"><b>表1 样本数据属性</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td><br />数据</td><td>时间</td><td>地点</td><td>人物</td><td>表述</td><td>实物</td><td>数字</td><td>合计</td></tr><tr><td><br />训练</td><td>1 281</td><td>1 234</td><td>1 544</td><td>687</td><td>1 043</td><td>1 411</td><td>7 200</td></tr><tr><td><br />测试</td><td>368</td><td>451</td><td>476</td><td>252</td><td>393</td><td>460</td><td>2 400</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="100">取Twitter Events、News Topics、Twitter Sentiments、 Movie Reviews等社交媒体文本数据集,分别采用CNN,SVM,LSTM-ICNN方法进行文本分类对比实验,实验结果如图4所示。</p>
                </div>
                <div class="area_img" id="101">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201918025_101.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 3种算法在不同数据集上的分类对比" src="Detail/GetImg?filename=images/DZCL201918025_101.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 3种算法在不同数据集上的分类对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201918025_101.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="102" name="102"><b>3.2 仿真结果</b></h4>
                <div class="p1">
                    <p id="103">为了确定合适的卷积核数目,对不同卷积核情况下的文本分类情况进行了分析,实验结果如图5所示。从图5中可以看出,当卷积核为3时,卷积核大小为2×150,3×150,4×150,精度为最高。所以本文确定的卷积神经网络的卷积核数目为3。分别采用本文所提的改进算法与传统算法进行分类准确性对比,对比结果如表2所示。分别用L-accuracy和B-accuracy表示84个小类和6个大类文本分类的准确率。采用3种算法在6大类分类问题进行了实验对比,分别对比了准确率(A),召回率(R),F1值,如表3所示。并且将本文所提的方法与其他人所提方法进行效果对比,对标结果如表4所示。</p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201918025_104.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 卷积核不同时分类效果" src="Detail/GetImg?filename=images/DZCL201918025_104.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 卷积核不同时分类效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201918025_104.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表2 分类效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td><br />算法</td><td>B-accuracy/%</td><td>L-accuracy/%</td></tr><tr><td><br />CNN</td><td>85.21</td><td>62.08</td></tr><tr><td><br />ICNN</td><td>88.79</td><td>65.76</td></tr><tr><td><br />LSTM</td><td>91.37</td><td>80.26</td></tr><tr><td><br />LSTM-ICNN</td><td>94.11</td><td>83.70</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="106" name="106"><b>3.3 结果分析</b></h4>
                <div class="p1">
                    <p id="107">从表2可以看出,ICNN算法的分类精度高于传统的CNN算法;LSTM算法分类的精度高于ICNN算法;LSTM-ICNN算法的精度比其他3种算法都高,大类文本的分类准确率达到了94.11%,比CNN算法高出了8.9%,小类文本分类的准确率达到了83.70%,比CNN算法高出了21.62,表明LSTM-ICNN算法能够有效学习句子的词序特征。</p>
                </div>
                <div class="p1">
                    <p id="108">从表3可以看出,时间,地点,任务和数字等类别在分类时的3个指标精度都很高,且在所有类别的分类效果中,相比于其他算法,LSTM-ICNN算法精度最高。实验中,实物和表述的效果较差。分析其原因,是因为这两类文本的语料少,模型较为复杂。而其余几种大类,特征语句容易识别,比如与时间,地点和人物相关的关键词,能够准确的表示问题。</p>
                </div>
                <div class="area_img" id="109">
                    <p class="img_tit"><b>表3 大类问题的分类结果</b>/% <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="109" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="3"><br />时间</td><td colspan="3">地点</td><td colspan="3">人物</td></tr><tr><td><br />A</td><td>R</td><td>F1</td><td>A</td><td>R</td><td>F1</td><td>A</td><td>R</td><td>F1</td></tr><tr><td><br />CNN</td><td>91.28</td><td>84.52</td><td>88.05</td><td>90.36</td><td>88.73</td><td>89.27</td><td>90.04</td><td>85.82</td><td>87.80</td></tr><tr><td><br />ICNN</td><td>92.97</td><td>88.17</td><td>90.51</td><td>93.86</td><td>93.16</td><td>94.15</td><td>93.11</td><td>87.85</td><td>90.22</td></tr><tr><td><br />LSTM</td><td>97.42</td><td>92.35</td><td>94.78</td><td>95.83</td><td>94.64</td><td>95.38</td><td>92.00</td><td>93.46</td><td>93.03</td></tr><tr><td><br />LSTM-ICNN</td><td>98.16</td><td>94.58</td><td>96.71</td><td>96.41</td><td>96.55</td><td>96.91</td><td>95.76</td><td>94.50</td><td>95.29</td></tr><tr><td rowspan="2"><br />算法</td><td colspan="3"><br />表述</td><td colspan="3">实物</td><td colspan="3">数字</td></tr><tr><td><br />A</td><td>R</td><td>F1</td><td>A</td><td>R</td><td>F1</td><td>A</td><td>R</td><td>F1</td></tr><tr><td><br />CNN</td><td>66.38</td><td>72.57</td><td>70.10</td><td>74.51</td><td>80.02</td><td>76.73</td><td>89.50</td><td>91.27</td><td>90.35</td></tr><tr><td><br />ICNN</td><td>72.72</td><td>76.35</td><td>74.52</td><td>79.92</td><td>86.31</td><td>82.81</td><td>91.82</td><td>94.92</td><td>93.60</td></tr><tr><td><br />LSTM</td><td>74.70</td><td>82.58</td><td>78.20</td><td>89.62</td><td>84.55</td><td>86.91</td><td>93.80</td><td>96.81</td><td>95.30</td></tr><tr><td><br />LSTM-ICNN</td><td>95.87</td><td>88.99</td><td>92.15</td><td>91.27</td><td>87.13</td><td>88.96</td><td>96.25</td><td>97.52</td><td>96.58</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="110">
                    <p class="img_tit"><b>表4 分类效果对比</b>/% <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="110" border="1"><tr><td><br />作者</td><td>数据量</td><td>大类准确率</td><td>小类准确率</td></tr><tr><td><br />文勖<sup>[16]</sup></td><td>6565</td><td>86.62</td><td>71.92</td></tr><tr><td><br />孙景广<sup>[17]</sup></td><td>5613</td><td>92.18</td><td>83.86</td></tr><tr><td><br />LSTM-ICNN</td><td>9600</td><td>94.11</td><td>83.70</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="112">从表4可以看出,相比于其他作者的工作,本文的分类在处理大类问题时高于其他研究人员所作工作,在处理小类分类上性能不是最好的,由于类别多语料少,致使分类效果不是很理想。</p>
                </div>
                <div class="p1">
                    <p id="113">从图5的对比实验中可以看出,在4种数据样本集的实验对比中,分别采用SVM,CNN,LSTM-ICNN方法进行仿真实验,实验结果显示,LSTM-ICNN算法分类的准确率最高,验证了LSTM-ICNN算法分类的准确性。</p>
                </div>
                <div class="p1">
                    <p id="114">通过以上对比分析可知,本文提出的LSTM-ICNN算法能够有效的对短文本进行分类,具有很大的实际应用价值。</p>
                </div>
                <h3 id="115" name="115" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="116">本文分别采用卷积神经网络,改进的卷积神经网络,长短期记忆神经网络对短文本分类进行了建模。由于改进卷积神经网络能够挖掘更多的文本信息特征,而长短期记忆神经网络在表示字词序列语义有更好的效果,所提提出了将长短期记忆神经网络和改进卷积神经网络相结合用于短文本分类。通过仿真实验确定最优卷积核数目,然后选用相同的参数进行实验对比,对比结果显示,本文所提的LSTM-ICNN在大类和小类分类中均表现出了良好的性能,验证了该方法的有效性。但是当粒度较小的小类分类时,准确率还有待近一步提高。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="127">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SDDX201601007&amp;v=MTAxODZxZlp1WnRGeW5nVkx2QU5pblBkckc0SDlmTXJvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 马丽菲,莫倩,杜辉.面向中文短影评的分类技术研究[J].山东大学学报(理学版),2016,51(1):52-57.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201605015&amp;v=MDU0MTNvOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUtDallmYkc0SDlmTXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 李志宇,梁循,周小平.基于属性主题分割的评论短文本词向量构建优化算法[J].中文信息学报,2016,30(5):101-110,120.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201806011&amp;v=MDc0ODRSN3FmWnVadEZ5bmdWTHZBTGpYZmZiRzRIOW5NcVk5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 刘晓琳,曹付元,梁吉业.面向新闻评论的短文本增量聚类算法[J].计算机科学与探索,2018,12(6):950-960.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201802020&amp;v=MTI3ODJmTmRMRzRIOW5Nclk5SFpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBTWk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 王义真,郑啸,后盾,等.基于SVM的高维混合特征短文本情感分类[J].计算机技术与发展,2018,28(2):88-93.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBKX201812024&amp;v=MjE2NjhIOW5Oclk5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBTkMvQWRyRzQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 刘小敏,王昊,李心蕾,等.不同特征粒度在微博短文本分类中作用的比较研究[J].情报科学,2018,36(12):126-133.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201809026&amp;v=MjEyNThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkFMejdCWmJHNEg5bk1wbzlIWW8=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 李晓红,冉宏艳,龚继恒,等.基于改进相似度与类中心向量的半监督短文本聚类算法[J].计算机工程与科学,2018,40(9):1710-1716.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201808006&amp;v=MTg4MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBTHl2U2RMRzRIOW5NcDQ5RllvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 崔婉秋,杜军平,寇菲菲,等.面向微博短文本的社交与概念化语义扩展搜索方法[J].计算机研究与发展,2018,55(8):1641-1652.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TEAR201803002&amp;v=MjUwNTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBTVNqS2ZMRzRIOW5Nckk5RlpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 冯靖,莫秀良,王春东.基于LDA改进的K-means算法在短文本聚类中的研究[J].天津理工大学学报,2018,34(3):7-11.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201803015&amp;v=Mjk3OTdCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUtDallmYkc0SDluTXJJOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 刘德喜,付淇,韦亚雄,等.基于多重增强图和主题分析的社交短文本检索方法[J].中文信息学报,2018,32(3):110-119.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201712028&amp;v=MzIxMTFOclk5SGJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmdWTHZBTHo3QmQ3RzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 卢玲,杨武,杨有俊,等.结合语义扩展和卷积神经网络的中文短文本分类方法[J].计算机应用,2017,37(12):3498-3503.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201706001&amp;v=MjU3NTBiTXFZOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUx6N0Jkckc0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 周飞燕,金林鹏,董军.卷积神经网络研究综述[J].计算机学报,2017,40(6):1229-1251.
                            </a>
                        </p>
                        <p id="149">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201708009&amp;v=MDcxMDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUx5dlNkTEc0SDliTXA0OUZiWVFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 梁斌,刘全,徐进,等.基于多注意力卷积神经网络的特定目标情感分析[J].计算机研究与发展,2017,54(8):1724-1735.
                            </a>
                        </p>
                        <p id="151">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201807034&amp;v=MDU2NjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5nVkx2QUx6N0JiYkc0SDluTXFJOUdZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 殷亚博,杨文忠,杨慧婷,等.基于卷积神经网络和KNN的短文本分类算法研究[J].计算机工程,2018,44(7):193-198.
                            </a>
                        </p>
                        <p id="153">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201808040&amp;v=MjIxMjFyQ1VSN3FmWnVadEZ5bmdWTHZBTHo3QmI3RzRIOW5NcDQ5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 曾蒸,李莉,陈晶.用于情感分类的双向深度LSTM[J].计算机科学,2018,45(8):213-217,252.
                            </a>
                        </p>
                        <p id="155">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HBQJ201805012&amp;v=MDY3NzRuZ1ZMdkFMUy9hWkxHNEg5bk1xbzlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 高成亮,徐华,高凯.结合词性信息的基于注意力机制的双向LSTM的中文文本分类[J].河北科技大学学报,2018,39(5):447-454.
                            </a>
                        </p>
                        <p id="157">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200602004&amp;v=MTc5MDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkFLQ2pZZmJHNEh0Zk1yWTlGWUlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> WEN X,ZHANG Y,LIU T,et al.Syntactic structure parsing based chinese question classification[J].Journal of Chinese Information Processing,2006,20(2):33-39.
                            </a>
                        </p>
                        <p id="159">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS200701014&amp;v=MDIzNzA1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluZ1ZMdkFLQ2pZZmJHNEh0Yk1ybzlFWUlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> SUN J G,CAI D F,LV D X,et al.HowNet based Chinese question automatic classification[J].Journal of Chinese Information Processing,2007,21(1):90-95.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201918025" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201918025&amp;v=MjAyNjFyQ1VSN3FmWnVadEZ5bmdWTHZBSVRmSVlyRzRIOWpOcDQ5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekc1UDhybXA2TzF5RHYzd3RWOD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

