

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135688174787500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201912016%26RESULT%3d1%26SIGN%3dSnDmMkJDjFnOQI2SP2gLYmGAczU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201912016&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201912016&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201912016&amp;v=MDQ4OTE0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVWJySklUZklZckc0SDlqTnJZOUVZb1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;1 AVS2编码块划分原理&lt;/b&gt; "><b>1 AVS2编码块划分原理</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;2 基于卷积神经网络的帧内编码&lt;/b&gt; "><b>2 基于卷积神经网络的帧内编码</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;3 实验结果与分析&lt;/b&gt; "><b>3 实验结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#33" data-title="图1 AVS2编码框架">图1 AVS2编码框架</a></li>
                                                <li><a href="#35" data-title="图2 AVS2编码单元结构">图2 AVS2编码单元结构</a></li>
                                                <li><a href="#41" data-title="图3 编码单元64&#215;64深度卷积神经网络结构">图3 编码单元64×64深度卷积神经网络结构</a></li>
                                                <li><a href="#43" data-title="图4 编码单元32&#215;32深度卷积神经网络">图4 编码单元32×32深度卷积神经网络</a></li>
                                                <li><a href="#45" data-title="&lt;b&gt;表1 编码块64&#215;64卷积神经网络的可训练参数个数统计&lt;/b&gt;"><b>表1 编码块64×64卷积神经网络的可训练参数个数统计</b></a></li>
                                                <li><a href="#46" data-title="&lt;b&gt;表2 编码块64&#215;64卷积神经网络的可训练参数个数统计&lt;/b&gt;"><b>表2 编码块64×64卷积神经网络的可训练参数个数统计</b></a></li>
                                                <li><a href="#54" data-title="&lt;b&gt;表3 视频序列压缩性能&lt;/b&gt;"><b>表3 视频序列压缩性能</b></a></li>
                                                <li><a href="#55" data-title="图5 使用Y-PSNR的4个序列的RD曲线">图5 使用Y-PSNR的4个序列的RD曲线</a></li>
                                                <li><a href="#56" data-title="图6 使用CSPSNR的4个序列的RD曲线">图6 使用CSPSNR的4个序列的RD曲线</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" GAO W, MA S W.An overview of AVS2 standard[M].Advanced Video Coding Systems.Springer International Publishing, 2014:35-49." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An overview of AVS2 standard">
                                        <b>[1]</b>
                                         GAO W, MA S W.An overview of AVS2 standard[M].Advanced Video Coding Systems.Springer International Publishing, 2014:35-49.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 毕厚杰.新一代视频压缩编码标准[M].北京:人民邮电出版社, 2009." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787115214362001&amp;v=Mjg1ODZ2bktyaWZaZVp2RnlubVU3M0tJbHNVWEZxekdiSzVHOVBOcTR4RFp1c1BEUk04enhVU21EZDlTSDduM3hFOWZi&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         毕厚杰.新一代视频压缩编码标准[M].北京:人民邮电出版社, 2009.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" YOO H M, SUH J W.Fast coding unit decision algorithm based on inter and intra prediction unit termination for HEVC[C].IEEE International Conference on Consumer Electronics.IEEE, 2013:300-301." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast coding unit decision algorithm based on inter and intra prediction unit termination for HEVC">
                                        <b>[3]</b>
                                         YOO H M, SUH J W.Fast coding unit decision algorithm based on inter and intra prediction unit termination for HEVC[C].IEEE International Conference on Consumer Electronics.IEEE, 2013:300-301.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" CHOI K, JANG E S.Early TU decision method for fast video encoding in high efficiency video coding[J].Electronics Letters, 2012, 48 (12) :689." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Early TU decision method for fast video encoding in high efficiency video coding">
                                        <b>[4]</b>
                                         CHOI K, JANG E S.Early TU decision method for fast video encoding in high efficiency video coding[J].Electronics Letters, 2012, 48 (12) :689.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" ZENG L, LIANG F, XIE L.An adaptive fast algorithm based on variance for AVS2[C].International Conference on Audio, Language and Image Processing.IEEE, 2016:312-317." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An adaptive fast algorithm based on variance for AVS2">
                                        <b>[5]</b>
                                         ZENG L, LIANG F, XIE L.An adaptive fast algorithm based on variance for AVS2[C].International Conference on Audio, Language and Image Processing.IEEE, 2016:312-317.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" YAO K L, WANG R G, WANG Z Y, et al.A Fast and Lossless IDCT Design for AVS2 Codec[C].IEEE Second International Conference on Multimedia Big Data.IEEE, 2016:241-245." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Fast and Lossless IDCT Design for AVS2 Codec">
                                        <b>[6]</b>
                                         YAO K L, WANG R G, WANG Z Y, et al.A Fast and Lossless IDCT Design for AVS2 Codec[C].IEEE Second International Conference on Multimedia Big Data.IEEE, 2016:241-245.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 吴晓光, 李国平, 王国中, 等.基于视频并行编码的码率控制算法研究[J].电视技术, 2015, 39 (16) :78-82." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201516026&amp;v=MjM1OTJxWTlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblVicklJVDdZZmJHNEg5VE4=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         吴晓光, 李国平, 王国中, 等.基于视频并行编码的码率控制算法研究[J].电视技术, 2015, 39 (16) :78-82.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 梁梦霞, 郭斯羽, 刘敏, 等.二值图像截断四叉树编码及快速逻辑运算方法[J].电子测量与仪器报, 2017, 31 (11) :1702-1710." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201711003&amp;v=MDc3MDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVWJySUlUZkNkN0c0SDliTnJvOUZaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         梁梦霞, 郭斯羽, 刘敏, 等.二值图像截断四叉树编码及快速逻辑运算方法[J].电子测量与仪器报, 2017, 31 (11) :1702-1710.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" WANG S S, LUO F L, MA S W.Overview of the Second Generation AVS Video Coding Standard (AVS2) [J].ZTE Communications, 2016, 14 (1) :3-11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZCTX201601003&amp;v=MjI1NjF5N2Zkckc0SDlmTXJvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVWJySVA=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         WANG S S, LUO F L, MA S W.Overview of the Second Generation AVS Video Coding Standard (AVS2) [J].ZTE Communications, 2016, 14 (1) :3-11.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" BJONTEGARD G.Calculation of average PSNR difference between RD-Curves[Z].ITU-T, VCEG-M33, 2001." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Calculation of average PSNR differences between RDcurves">
                                        <b>[10]</b>
                                         BJONTEGARD G.Calculation of average PSNR difference between RD-Curves[Z].ITU-T, VCEG-M33, 2001.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" SHANG X W, WANG G Z, ZHAO H W, et al.A new combined PSNR for objective video quality assessment[C].IEEE International Conference on Multimedia and Expo.IEEE, 2017:811-816." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A new combined PSNR for objective video quality assessment">
                                        <b>[11]</b>
                                         SHANG X W, WANG G Z, ZHAO H W, et al.A new combined PSNR for objective video quality assessment[C].IEEE International Conference on Multimedia and Expo.IEEE, 2017:811-816.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" LI T Y, XU M, DENG X.A deep convolutional neural network approach for complexity reduction on intra-mode HEVC[C].IEEE International Conference on Multimedia and Expo.IEEE, 2017:1255-1260." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A deep convolutional neural network approach for complexity reduction on intra-mode HEVC">
                                        <b>[12]</b>
                                         LI T Y, XU M, DENG X.A deep convolutional neural network approach for complexity reduction on intra-mode HEVC[C].IEEE International Conference on Multimedia and Expo.IEEE, 2017:1255-1260.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(12),90-94 DOI:10.19651/j.cnki.emt.1802465            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度卷积神经网络的帧内模式决策</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%B5%B7%E6%AD%A6&amp;code=27028528&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵海武</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%99%E7%8E%B2%E8%8A%9D&amp;code=39550059&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">余玲芝</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E4%BD%B3%E7%8E%B2&amp;code=39550058&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈佳玲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A1%BE%E6%99%93&amp;code=35275421&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">顾晓</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%8A%E6%B5%B7%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0017580&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">上海大学通信与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>AVS2编码在节省码率的同时, 自身的编码复杂度很高。因为AVS2采用了率失真优化 (RDO) 技术, 所以编码树单元 (CTU) 划分的复杂度占据了AVS2编码复杂度的很大一部分。因此, 提议用卷积神经网络 (CNN) 模型来替代原AVS2编码标准的参考软件RD19.1中编码树划分的过程。首先, 将问题归类为分类问题, 然后设计了适用于编码块划分的卷积神经网络结构, 包括3个卷积层、1个最大池化层和2个全连接层。最后, 将训练得到的模型分别应用于64×64和32×32大小的编码块上。实验结果显示, 所建议方案比原RD19.1平均节省时间为31.36%, 比特率平均增加了2.25%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=AVS2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">AVS2;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B8%A7%E5%86%85%E7%BC%96%E7%A0%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">帧内编码;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BF%AB%E9%80%9F%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">快速算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    赵海武, 高级工程师, 博士, 主要研究方向为视频编解码。E-mail:zhaohaiwu@shu.edu.cn;
                                </span>
                                <span>
                                    *余玲芝 (通讯作者) , 硕士研究生, 主要研究方向为视频编码、深度学习。E-mail:991986789@qq.com;
                                </span>
                                <span>
                                    陈佳玲, 硕士研究生, 主要研究为全景视频的压缩。E-mail:15371257515@163.com;
                                </span>
                                <span>
                                    顾晓, 硕士研究生, 主要研究方向为全景视频映射。E-mail:markguxiaoxiao@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12</p>

            </div>
                    <h1><b>Fast intra CTU partition based on CNN in AVS2</b></h1>
                    <h2>
                    <span>Zhao Haiwu</span>
                    <span>Yu Lingzhi</span>
                    <span>Chen Jialing</span>
                    <span>Gu Xiao</span>
            </h2>
                    <h2>
                    <span>School of Communication & Information Engineering, Shanghai University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>AVS2, the second generation of Audio-Video Coding Standard, has a higher coding efficiency than AVS1, but at the expense of extremely high encoding complexity. During the process of intra coding, the coding tree units (CTU) are recursively split into four sub CUs until the smallest size by the rate-distortion optimization model, which costs large parts of computational complexity. Therefore, developing a low complexity coding algorithm is necessary for the practical application. In this paper, we propose a fast intra CTU partitioning scheme based on the convolutional neural network (CNN) . Firstly, the split mode of CU is modeled as two classification problem. Then, we design a CNN to predict the split mode with 3 convolution levels, 1 pooling level and 2 full-connection levels. Finally, the CNN model which is trained subtly is used for fast CTU partition and 32×32 coding unit (CU) partition respectively. Experimental results show that the proposed scheme saves 31.36% coding time on average, with 2.25% BD-rate increase and 0.13 dB BD-PSNR decrease.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=AVS2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">AVS2;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=intra-coding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">intra-coding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=complexity%20reduction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">complexity reduction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">convolutional neural network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12</p>
                            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="28">视音频编码标准 (audio-video coding standard, AVS) 是由中国AVS工作组开发的源编码标准, 它旨在满足数字音频和视频应用的需求, 有一系列标准是根据国际开放规则制定的<citation id="61" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。目前已经出版了两代AVS标准, 第2代AVS标准 (AVS2) 的主要应用目标是超高清视频, 它还支持宽色域 (wide color gamut, WCG) 和高动态范围 (high dynamic range, HDR) 视频压缩。AVS2的编码效率是AVS1的2倍, 在某些应用中超过了新的国际标准HEVC/H.265<citation id="62" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="29">在过去的几年中, 编码树划分方案的研究都是在国际高效率视频编码标准 (high efficiency video coding, HEVC) <citation id="65" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>上进行的。与HEVC编码块的从上到下划分方式不同, AVS2使用自底向上的划分方式, 因此不能将HEVC上面的方法直接应用于AVS2。对AVS2, 目前的研究都是传统的分割编码树单元的方案。Zeng等<citation id="63" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出了一种基于方差的自适应快速算法, 将编码时间平均减少21%, 比特率平均增加了0.58%。Yao等<citation id="64" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出了一种基于跳过零系数计算的AVS2的快速反余弦变换 (inverse discrete cosine transform, IDCT) 设计, 将帧间模式的编码时间平均减少了19.3%, 比特率几乎没有增加。</p>
                </div>
                <div class="p1">
                    <p id="30">但上述方法对并行编码并不友好, 因此本文建议将深度学习应用于AVS2, 这不依赖于编码块深度或编码块附近像素之间的相关性, 对并行编码等技术更加友好。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>1 AVS2编码块划分原理</b></h3>
                <div class="p1">
                    <p id="32">AVS2采用了混合编码框架, 整个编码过程包括帧内预测、帧间预测、变换量化、反量化反变换、环路滤波和熵编码等模块<citation id="66" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 如图1所示。</p>
                </div>
                <div class="area_img" id="33">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912016_033.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 AVS2编码框架" src="Detail/GetImg?filename=images/DZCL201912016_033.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 AVS2编码框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912016_033.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="34">为了满足高清和超高清分辨率视频对压缩效率的要求, AVS2采用了基于四叉树<citation id="67" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>的块划分结构, 包括编码单元 (coding unit, CU) 、预测单元 (prediction unit, PU) 和变换单元 (transform unit, TU) 。在视频编码过程中, 一幅图像首先被分割成固定大小的最大编码单元 (largest coding unit, LCU) , 然后最大编码单元按照四叉树的方式迭代划分为一系列的编码块, 如图2所示, 每个编码块包含1个亮度编码块和2个对应的色度编码块。与传统的宏块相比, 基于四叉树的划分结构更加灵活, 编码块大小可以为2<i>N</i>×2<i>N</i>, 其中<i>N</i>=4, 8, 16, 32。每种大小的编码块都有继续往下划分和不再往下划分的可能性。对于8×8大小的编码块还可以继续往下分成PU。</p>
                </div>
                <div class="area_img" id="35">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912016_035.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 AVS2编码单元结构" src="Detail/GetImg?filename=images/DZCL201912016_035.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 AVS2编码单元结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912016_035.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="36">在AVS2中, 默认的最大编码单元为64×64, 最小编码单元为8×8<citation id="68" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。对于每一个16×16的编码块, 有2种划分模式, 即向下划分和不划分;对于每一个32×32大小的编码块, 划分模式有2<sup>4</sup>+1=17种, 即32×32中4个16×16大小的编码块的2种划分可能性2<sup>4</sup>和32×32不划分时的1种可能性;对于每一个LCU, 模式有17<sup>4</sup>+1=83 522种。因此, 对于视频中每一帧的每一个LCU, 编码时都要检索83 522种可能性, 分别计算比较每一种可能性的率失真代价 (rate-distortion cost, RDcost) , 以确定最优大小的编码块, 这极大地提高了编码的复杂度。与HEVC编码块自上往下的划分方式不同的是, AVS2在编码块划分时采用自底向上的划分比较方式, 即首先将视频每一帧中的每一个最大编码单元LCU直接从64×64划分到8×8, 然后从编码底层8×8的编码块依次往上编码至16×16、32×32、64×64的编码块, 比较各层编码块划分和不划分时的率失真代价 (式 (1) ) , 来确定最终的编码块大小。</p>
                </div>
                <div class="p1">
                    <p id="37"><i>J</i>=<i>λR</i>+<i>D</i> (1) </p>
                </div>
                <div class="p1">
                    <p id="38">式中:<i>λ</i>是拉格朗日因子;<i>R</i>是编码的比特率;<i>D</i>是原始块和预测块的像素差值。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag"><b>2 基于卷积神经网络的帧内编码</b></h3>
                <div class="p1">
                    <p id="40">本文主要讨论帧内编码模式下编码块为64×64和32×32的两层。对于64×64和32×32的编码单元分别设计了2个不同的卷积神经网络分类器。首先, 对于64×64的编码块, 采用3层卷积神经网络模型, 如图3所示, 原始图片为64×64, 卷积层1、2、3的卷积核大小都为3×3, 步长都为3, 其中卷积层1的卷积核数量为6, 卷积层2的卷积核数量为16, 卷积层3的卷积核数量为26。池化层采用最大池化, 核大小为2×2, 步长为2。全连接层1的核数量为10, 全连接层2的核数量为2。</p>
                </div>
                <div class="area_img" id="41">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912016_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 编码单元64&#215;64深度卷积神经网络结构" src="Detail/GetImg?filename=images/DZCL201912016_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 编码单元64×64深度卷积神经网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912016_041.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="42">对于32×32的编码单元, 采用3层卷积神经网络模型, 如图4所示, 原始图片为32×32, 卷积层1、2、3的卷积核大小都为3×3, 步长都为1, 其中卷积层1的卷积核数量为6, 卷积层2的卷积核数量为16, 卷积层3的卷积核数量为26。池化层采用最大池化, 核大小为2×2, 步长为2。全连接层1的核数量为10, 全连接层2的核数量为2。</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912016_043.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 编码单元32&#215;32深度卷积神经网络" src="Detail/GetImg?filename=images/DZCL201912016_043.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 编码单元32×32深度卷积神经网络  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912016_043.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="44">对于编码块为64×64和32×32的2个卷积神经网络结构, 可训练的参数个数, 如表1和2所示:</p>
                </div>
                <div class="area_img" id="45">
                    <p class="img_tit"><b>表1 编码块64×64卷积神经网络的可训练参数个数统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="45" border="1"><tr><td><br />层名</td><td>滤波器尺寸</td><td>滤波器个数</td><td>参数</td></tr><tr><td><br />卷积层1</td><td>3×3</td><td>6</td><td>60</td></tr><tr><td><br />池化层</td><td>2×2</td><td>6</td><td>12</td></tr><tr><td><br />卷积层2</td><td>3×3</td><td>16</td><td>880</td></tr><tr><td><br />卷积层3</td><td>3×3</td><td>26</td><td>3 770</td></tr><tr><td><br />全连接层1</td><td>1×1</td><td>10</td><td>270</td></tr><tr><td><br />全连接层2</td><td>1×1</td><td>2</td><td>22</td></tr><tr><td><br />总参数</td><td colspan="3">5 014</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="46">
                    <p class="img_tit"><b>表2 编码块64×64卷积神经网络的可训练参数个数统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="46" border="1"><tr><td><br />层名</td><td>滤波器尺寸</td><td>滤波器个数</td><td>参数</td></tr><tr><td><br />卷积层1</td><td>3×3</td><td>6</td><td>60</td></tr><tr><td><br />池化层</td><td>2×2</td><td>6</td><td>12</td></tr><tr><td><br />卷积层2</td><td>3×3</td><td>16</td><td>880</td></tr><tr><td><br />卷积层3</td><td>3×3</td><td>26</td><td>3 770</td></tr><tr><td><br />全连接层1</td><td>1×1</td><td>10</td><td>31 470</td></tr><tr><td><br />全连接层2</td><td>1×1</td><td>2</td><td>22</td></tr><tr><td><br />总参数</td><td colspan="3">36 214</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>3 实验结果与分析</b></h3>
                <div class="p1">
                    <p id="48">通过比较本文方案和原始AVS2的性能来评价本文提议方案。所有的实验都在AVS2的参考软件RD19.1上实现, 采用全I帧 (all-intra, AI) 配置, 并选取了4个量化参数 (quantization parameter, QP) , 分别为27、32、38和45。本文一共测试了AVS2标准测试集中的16个视频序列, 每个视频编码100帧, 用比特率变化 (bj⌀ntegaard delta bit-rate, BD-BR) 、峰值信噪比变化 (bj⌀ntegaard delta peak signal-to-noise rate, BD-PSNR) <citation id="69" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>来评价压缩的性能。由于只有亮度PSNR不能很好地表示序列的整体质量, 因此利用来自3个分量Y, Cb和Cr的PSNR组合, 基于颜色敏感的PSNR<citation id="70" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>来计算BD-BR和BD-PSNR。Δ<i>T</i>表示与原始RD19.1相比, 编码时间的节省率, 如式 (2) 所示。</p>
                </div>
                <div class="p1">
                    <p id="49"><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Δ</mi><mi>Τ</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>n</mtext><mtext>c</mtext><mtext>h</mtext><mtext>o</mtext><mtext>r</mtext></mrow></msub><mo>-</mo><mi>Τ</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>r</mtext><mtext>o</mtext><mtext>p</mtext><mtext>o</mtext><mtext>s</mtext><mtext>e</mtext><mtext>d</mtext></mrow></msub></mrow><mrow><mtext>Τ</mtext><msub><mrow></mrow><mrow><mtext>a</mtext><mtext>n</mtext><mtext>c</mtext><mtext>h</mtext><mtext>o</mtext><mtext>r</mtext></mrow></msub></mrow></mfrac><mo>⋅</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="51">式中:<i>T</i><sub>anchor</sub>是原RD19.1编码一个视频序列所需的时间;<i>T</i><sub>proposed</sub>是本文所提议方案编码一个视频序列所需的编码时间。</p>
                </div>
                <div class="p1">
                    <p id="52">本文的网络结构较小, 训练可以在中央处理器 (central processing unit, CPU) 上完成。本文一共在CPU上训练了8个深度卷积神经网络模型, 分别为当编码块为64×64时的4个不同QP值模型和当编码块为32×32时的4个不同QP的模型。训练CNN模型的时候, 本文采用CPIH数据集<citation id="71" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 将原数据集中的视频序列切割成相应大小的图片, 使用只包含亮度分量的图片来训练。在训练编码块为32×32的模型时, 训练集的大小为10万张, 选取基础学习率为0.01, 每迭代1 000次学习率减小为原来的10%, 一共训练了10 000次, 选取最好的迭代次数模型。在训练编码块为64×64的卷积网络模型时, 选取基础学习率为0.01, 每迭代1 000次学习率减小为原来的10%, 一共训练10 000次。</p>
                </div>
                <div class="p1">
                    <p id="53">实验结果如表3, 图5和6所示。 在计算BD-BR, BD-PSNR, Δ<i>T</i>和率失真 (rate-distortion, RD) 曲线期间, 将RD19.1的原始性能作为对比。</p>
                </div>
                <div class="area_img" id="54">
                    <p class="img_tit"><b>表3 视频序列压缩性能</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="54" border="1"><tr><td rowspan="2"><br /></td><td rowspan="2">视频序列</td><td colspan="2"><br />BD-BR/%</td><td>BD-PSNR/dB</td><td rowspan="2">Δ<i>T</i>/%</td></tr><tr><td><br />CSPSNR</td><td>YPSNR</td><td>YPSNR</td></tr><tr><td rowspan="3"><br />UHD</td><td><br />pku_girls</td><td>1.97</td><td>1.91</td><td>-0.09</td><td>31.62</td></tr><tr><td><br />pku_parkwalk</td><td>2.87</td><td>2.91</td><td>-0.14</td><td>42.59</td></tr><tr><td><br />Traffic</td><td>3.00</td><td>3.02</td><td>-0.16</td><td>34.94</td></tr><tr><td rowspan="4"><br />1080p</td><td><br />beach</td><td>3.78</td><td>3.12</td><td>-0.15</td><td>37.29</td></tr><tr><td><br />taishan</td><td>1.28</td><td>1.22</td><td>-0.09</td><td>27.73</td></tr><tr><td><br />Kimono1</td><td>4.97</td><td>5.47</td><td>-0.19</td><td>54.19</td></tr><tr><td><br />Cactus</td><td>3.56</td><td>3.49</td><td>-0.13</td><td>32.69</td></tr><tr><td rowspan="4"><br />WVGA</td><td><br />BasketballDrill</td><td>1.87</td><td>1.86</td><td>-0.08</td><td>26.09</td></tr><tr><td><br />BQMall</td><td>4.27</td><td>4.16</td><td>-0.23</td><td>29.56</td></tr><tr><td><br />PartyScene</td><td>1.32</td><td>1.32</td><td>-0.11</td><td>24.13</td></tr><tr><td><br />RaceHorses</td><td>2.08</td><td>2.03</td><td>-0.15</td><td>29.75</td></tr><tr><td rowspan="4"><br />WQVGA</td><td><br />BasketballPass</td><td>2.65</td><td>2.55</td><td>-0.14</td><td>23.98</td></tr><tr><td><br />BQSquare</td><td>0.45</td><td>0.39</td><td>-0.03</td><td>25.15</td></tr><tr><td><br />BlowingBubbles</td><td>1.49</td><td>1.51</td><td>-0.09</td><td>25.42</td></tr><tr><td><br />RaceHorses</td><td>2.03</td><td>2.05</td><td>-0.14</td><td>27.03</td></tr><tr><td><br />CIF</td><td>container</td><td>1.38</td><td>1.33</td><td>-0.08</td><td>30.30</td></tr><tr><td><br />平均值</td><td></td><td>2.29</td><td>2.25</td><td>-0.13</td><td>31.36</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="55">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912016_055.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 使用Y-PSNR的4个序列的RD曲线" src="Detail/GetImg?filename=images/DZCL201912016_055.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 使用Y-PSNR的4个序列的RD曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912016_055.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201912016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 使用CSPSNR的4个序列的RD曲线" src="Detail/GetImg?filename=images/DZCL201912016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 使用CSPSNR的4个序列的RD曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201912016_056.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="57">由表3可知, 在QP=27、32、38和45上, 对视频而言, 本文所提议的方案相对比于原AVS2参考软件RD19.1的编码时间最高节省了54.19%的编码时间, 平均减少了31.36%的编码时间, 而在YPSNR上的BD-BR平均增加了2.25%, 用CSPSNR评价得到的BD-BR平均增加了2.29%。同时BD-PSNR平均亏损了0.13 dB。</p>
                </div>
                <div class="p1">
                    <p id="58">从图5和图6可以看出, 无论本文使用CSPSNR还是Y-PSNR来绘制RD曲线, BD-BR只在序列Kimono1中具有显着下降, 但同时其也具有较大的速度的提升。而其他3个序列的BD-BR的亏损都较少。从上述结果可以看出, 本文的方法在帧内模式决策上有一定的先进性, 适用性较好, 并且本文的方法不依赖于编码块的其他信息, 更加利于并行编码等方法在编码器上的实现。</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="60">本文提出了一种基于深度卷积神经网络来降低AVS2编码复杂度的方案。通过卷积神经网络学习AVS2中编码块的划分标志来代替原AVS2中的编码块模式决策部分, 以此降低了编码的复杂度, 减少了原软件所需的编码时间。与原编码软件RD19.1相比, 本文的方案平均减少了31.36%的编码时间, BD-BR增加2.25%, BD-PSNR减小0.13 dB。在未来, 将对编码单元16×16, 8×8继续进行研究, 同时将编码模式扩展到帧间。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An overview of AVS2 standard">

                                <b>[1]</b> GAO W, MA S W.An overview of AVS2 standard[M].Advanced Video Coding Systems.Springer International Publishing, 2014:35-49.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787115214362001&amp;v=MTAyMDlIN24zeEU5ZmJ2bktyaWZaZVp2RnlubVU3M0tJbHNVWEZxekdiSzVHOVBOcTR4RFp1c1BEUk04enhVU21EZDlT&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 毕厚杰.新一代视频压缩编码标准[M].北京:人民邮电出版社, 2009.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast coding unit decision algorithm based on inter and intra prediction unit termination for HEVC">

                                <b>[3]</b> YOO H M, SUH J W.Fast coding unit decision algorithm based on inter and intra prediction unit termination for HEVC[C].IEEE International Conference on Consumer Electronics.IEEE, 2013:300-301.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Early TU decision method for fast video encoding in high efficiency video coding">

                                <b>[4]</b> CHOI K, JANG E S.Early TU decision method for fast video encoding in high efficiency video coding[J].Electronics Letters, 2012, 48 (12) :689.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An adaptive fast algorithm based on variance for AVS2">

                                <b>[5]</b> ZENG L, LIANG F, XIE L.An adaptive fast algorithm based on variance for AVS2[C].International Conference on Audio, Language and Image Processing.IEEE, 2016:312-317.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Fast and Lossless IDCT Design for AVS2 Codec">

                                <b>[6]</b> YAO K L, WANG R G, WANG Z Y, et al.A Fast and Lossless IDCT Design for AVS2 Codec[C].IEEE Second International Conference on Multimedia Big Data.IEEE, 2016:241-245.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201516026&amp;v=MDE3Njg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVWJySUlUN1lmYkc0SDlUTnFZOUhZb1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 吴晓光, 李国平, 王国中, 等.基于视频并行编码的码率控制算法研究[J].电视技术, 2015, 39 (16) :78-82.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201711003&amp;v=MjY2MTA1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlyblVicklJVGZDZDdHNEg5Yk5ybzlGWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 梁梦霞, 郭斯羽, 刘敏, 等.二值图像截断四叉树编码及快速逻辑运算方法[J].电子测量与仪器报, 2017, 31 (11) :1702-1710.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZCTX201601003&amp;v=MjAzODhadVp0RnlyblVicklQeTdmZHJHNEg5Zk1ybzlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> WANG S S, LUO F L, MA S W.Overview of the Second Generation AVS Video Coding Standard (AVS2) [J].ZTE Communications, 2016, 14 (1) :3-11.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Calculation of average PSNR differences between RDcurves">

                                <b>[10]</b> BJONTEGARD G.Calculation of average PSNR difference between RD-Curves[Z].ITU-T, VCEG-M33, 2001.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A new combined PSNR for objective video quality assessment">

                                <b>[11]</b> SHANG X W, WANG G Z, ZHAO H W, et al.A new combined PSNR for objective video quality assessment[C].IEEE International Conference on Multimedia and Expo.IEEE, 2017:811-816.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A deep convolutional neural network approach for complexity reduction on intra-mode HEVC">

                                <b>[12]</b> LI T Y, XU M, DENG X.A deep convolutional neural network approach for complexity reduction on intra-mode HEVC[C].IEEE International Conference on Multimedia and Expo.IEEE, 2017:1255-1260.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201912016" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201912016&amp;v=MDQ4OTE0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJuVWJySklUZklZckc0SDlqTnJZOUVZb1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

