

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135676971037500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201913018%26RESULT%3d1%26SIGN%3dEIZ9%252fNduWAdKKGpfykcbkkDANJ4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201913018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201913018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201913018&amp;v=MjM2NTVFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlybFY3N0pJVGZJWXJHNEg5ak5ySTk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#53" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#59" data-title="&lt;b&gt;1 稀疏表示与字典学习&lt;/b&gt; "><b>1 稀疏表示与字典学习</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#68" data-title="&lt;b&gt;2 基于结构不相关性字典的分类算法&lt;/b&gt; "><b>2 基于结构不相关性字典的分类算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#70" data-title="&lt;b&gt;2.1 特定类字典的学习&lt;/b&gt;"><b>2.1 特定类字典的学习</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;2.2 图像缺陷的分类&lt;/b&gt;"><b>2.2 图像缺陷的分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#129" data-title="&lt;b&gt;3 实验结果分析&lt;/b&gt; "><b>3 实验结果分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#143" data-title="&lt;b&gt;4 结  论&lt;/b&gt; "><b>4 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#137" data-title="图1 6类缺陷图像">图1 6类缺陷图像</a></li>
                                                <li><a href="#138" data-title="图2 训练样本数为1 000时不同字典原子数的分类精度">图2 训练样本数为1 000时不同字典原子数的分类精度</a></li>
                                                <li><a href="#139" data-title="图3 不同训练样本时各种分类算法的分类精度">图3 不同训练样本时各种分类算法的分类精度</a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表1 训练样本为1100时各个分类算法的分类精度&lt;/b&gt;"><b>表1 训练样本为1100时各个分类算法的分类精度</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" ZHANG M, MATINLINNA J P.E-glass fiber reinforced composites in dental applications[J].Silicon, 2012, 4 (1) :73-78." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=E-Glass Fiber Reinforced Composites in Dental Applications">
                                        <b>[1]</b>
                                         ZHANG M, MATINLINNA J P.E-glass fiber reinforced composites in dental applications[J].Silicon, 2012, 4 (1) :73-78.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" WANG X, CHEN S H, ZHENG T Y, et al.Study on the filament yarns spreading techniques and assessment methods of the electronic fiberglass fabric[C].International Symposium on Application of Materials Science and Energy Materials, 2018, 322 (2) :215-220." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Study on the filament yarns spreading techniques and assessment methods of the electronic fiberglass fabric">
                                        <b>[2]</b>
                                         WANG X, CHEN S H, ZHENG T Y, et al.Study on the filament yarns spreading techniques and assessment methods of the electronic fiberglass fabric[C].International Symposium on Application of Materials Science and Energy Materials, 2018, 322 (2) :215-220.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 李纪峰, 赵凤霞, 金少搏.玻璃纤维布的机器视觉缺陷检测系统设计[J].机械设计与制造, 2018 (1) :163-165, 169." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYZ201801046&amp;v=MTU1NzR6cXFCdEdGckNVUjdxZlp1WnRGeXJsVjc3Skx6N1NkTEc0SDluTXJvOUJZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         李纪峰, 赵凤霞, 金少搏.玻璃纤维布的机器视觉缺陷检测系统设计[J].机械设计与制造, 2018 (1) :163-165, 169.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 游信勇, 钱慧芳.基于变差函数的纺织纹理图像分析[J].西安工程大学学报, 2015, 29 (4) :410-414, 419." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XBFZ201504006&amp;v=MDQwMzFNcTQ5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cmxWNzdKUFMvTmRMRzRIOVQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         游信勇, 钱慧芳.基于变差函数的纺织纹理图像分析[J].西安工程大学学报, 2015, 29 (4) :410-414, 419.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" JING J F, FAN X T, LI P F.Patterned fabric defect detection via convolutional matching pursuit dual-dictionary[J].Optical Engineering, 2016, 55 (5) :053109." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG042990F37F1F112FD0BD9E6C0B8FEE41&amp;v=MTIwNTJOaWZPYWJPOEhOakZyL2xHWTUwT2VuMDR6V0JuNmswSlFRcmszeEpIY2NUaE1MNmVDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4cmk3d2FrPQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         JING J F, FAN X T, LI P F.Patterned fabric defect detection via convolutional matching pursuit dual-dictionary[J].Optical Engineering, 2016, 55 (5) :053109.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 韩辰希, 刘惠义, 商国中.视觉显著性纹理——色彩特征融合的图像目标分类[J].电子测量技术, 2017, 40 (11) :94-98." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201711021&amp;v=MjczNTBadEZ5cmxWNzdKSVRmSVlyRzRIOWJOcm85SFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         韩辰希, 刘惠义, 商国中.视觉显著性纹理——色彩特征融合的图像目标分类[J].电子测量技术, 2017, 40 (11) :94-98.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     WRIGHT J, YANG A Y, GANESH A, et al.Robust face recognition via sparse representation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) :210-227.</a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" BAHRAMPOUR S, RAY A, NASRABADI N M, et al.Quality-based multimodal classification using tree-structured sparsity[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014:4114-4121." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Quality-Based Multimodal Classification Using Tree-Structured Sparsity">
                                        <b>[8]</b>
                                         BAHRAMPOUR S, RAY A, NASRABADI N M, et al.Quality-based multimodal classification using tree-structured sparsity[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014:4114-4121.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" MOUSAVI H S, SRINIVAS U, MONGA V, et al.Multi-task image classification via collaborative, hierarchical spike-and-slab priors[C].2014 IEEE International Conference on Image Processing (ICIP) .IEEE, 2014:4236-4240." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-task image classification via collaborative,hierarchical spike-and-slab priors">
                                        <b>[9]</b>
                                         MOUSAVI H S, SRINIVAS U, MONGA V, et al.Multi-task image classification via collaborative, hierarchical spike-and-slab priors[C].2014 IEEE International Conference on Image Processing (ICIP) .IEEE, 2014:4236-4240.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" ELAD M, AHARON M.Image denoising via sparse and redundant representations over learned dictionaries[J].IEEE Transactions on Image processing, 2006, 15 (12) :3736-3745." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image denoising via sparse and redundant representations over learned dictionaries">
                                        <b>[10]</b>
                                         ELAD M, AHARON M.Image denoising via sparse and redundant representations over learned dictionaries[J].IEEE Transactions on Image processing, 2006, 15 (12) :3736-3745.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     AHARON M, ELAD M, BRUCKSTEIN A, et al.K-SVD:An algorithm for designing overcomplete dictionaries for sparse representation[J].IEEE Transactions on Signal Processing, 2006, 54 (11) :4311-4322.</a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" MAIRAL J, BACH F, PONCE J, et al.Online dictionary learning for sparse coding[C].International Conference on Machine Learning (ICML 2009) , 2009:689-696." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online dictionary learning for sparse coding">
                                        <b>[12]</b>
                                         MAIRAL J, BACH F, PONCE J, et al.Online dictionary learning for sparse coding[C].International Conference on Machine Learning (ICML 2009) , 2009:689-696.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" ANARAKI F P, HUGHES S M.Kernel compressive sensing[C].Image Processing (ICIP) , 2013 IEEE International Conference on Image Processing.IEEE, 2013:494-498." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Kernel compressive sensing">
                                        <b>[13]</b>
                                         ANARAKI F P, HUGHES S M.Kernel compressive sensing[C].Image Processing (ICIP) , 2013 IEEE International Conference on Image Processing.IEEE, 2013:494-498.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" SADEGHI M, BABAIE-ZADEH M, JUTTEN C.Learning overcomplete dictionaries based on atom-by-atom updating[J].IEEE Transactions on Signal Processing, 2014, 62 (4) :883-891." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning overcomplete dictionaries based on atom-by-atom updating">
                                        <b>[14]</b>
                                         SADEGHI M, BABAIE-ZADEH M, JUTTEN C.Learning overcomplete dictionaries based on atom-by-atom updating[J].IEEE Transactions on Signal Processing, 2014, 62 (4) :883-891.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     WRIGHT J, YANG A Y, GANESH A, et al.Robust face recognition via sparse representation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) :210-227.</a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 刘绥美.彩色印花织物疵点检测的研究与实现[D].西安:西安工程大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016094457.nh&amp;v=MDExNTBYSnFKRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJsVjc3SlZGMjZHTE94R3Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         刘绥美.彩色印花织物疵点检测的研究与实现[D].西安:西安工程大学, 2016.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" EFRON B, HASTIE T, JOHNSTONE I, et al.Least angle regression[J].The Annals of Statistics, 2004, 32 (2) :407-499." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14112600629333&amp;v=MTY5NDE5RE9xWTlGWXVrR0QzODZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJbDRRYXhNPU5pZlllcks4SA==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         EFRON B, HASTIE T, JOHNSTONE I, et al.Least angle regression[J].The Annals of Statistics, 2004, 32 (2) :407-499.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" GANGEH M J, FARAHAT A K, GHODSI A, et al.Supervised dictionary learning and sparse representation-a review[J/OL].arXiv Preprint, 2015.https://arxiv.org/abs/1502.05928." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised dictionary learning and sparse representation-a review">
                                        <b>[18]</b>
                                         GANGEH M J, FARAHAT A K, GHODSI A, et al.Supervised dictionary learning and sparse representation-a review[J/OL].arXiv Preprint, 2015.https://arxiv.org/abs/1502.05928.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" MAIRAL J, BACH F, PONCE J, et al.Online dictionary learning for sparse coding[C].Proceedings of the 26th Annual International Conference on Machine Learning, 2009:689-696." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online dictionary learning for sparse coding">
                                        <b>[19]</b>
                                         MAIRAL J, BACH F, PONCE J, et al.Online dictionary learning for sparse coding[C].Proceedings of the 26th Annual International Conference on Machine Learning, 2009:689-696.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" MAIRAL J, BACH F, PONCE J, et al.Discriminative learned dictionaries for local image analysis[C].2008 IEEE Conference on Computer Vision and Pattern Recognition, 2008:2415-2422." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Discriminative learned dictionaries for localimage analysis">
                                        <b>[20]</b>
                                         MAIRAL J, BACH F, PONCE J, et al.Discriminative learned dictionaries for local image analysis[C].2008 IEEE Conference on Computer Vision and Pattern Recognition, 2008:2415-2422.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" PEYR&#201; G.Sparse modeling of textures[J].Journal of Mathematical Imaging and Vision, 2009, 34 (1) :17-31." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003520613&amp;v=MjE3MjQ0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXZsVWIvTUlWOD1OajdCYXJPNEh0SFBxbzFGWXVvTVkzazV6QmRo&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         PEYR&#201; G.Sparse modeling of textures[J].Journal of Mathematical Imaging and Vision, 2009, 34 (1) :17-31.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" ZHANG L L, XU G Q, XUE Q, et al.An iterative thresholding algorithm for the inverse problem of electrical resistance tomography[J].Flow Measurement and Instrumentation, 2013, 33:244-250." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600394713&amp;v=MTM5NjZNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSWw0UWF4TT1OaWZPZmJLOEh0RE1xWTlGWitJTEMzMDZvQg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         ZHANG L L, XU G Q, XUE Q, et al.An iterative thresholding algorithm for the inverse problem of electrical resistance tomography[J].Flow Measurement and Instrumentation, 2013, 33:244-250.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" 詹曙, 姚尧, 高贺.基于随机森林的脑磁共振图像分类[J].电子测量与仪器学报, 2013, 27 (11) :1067-1072." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201311012&amp;v=MDM0MzBMTnJvOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXJsVjc3SklUZkNkN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         詹曙, 姚尧, 高贺.基于随机森林的脑磁共振图像分类[J].电子测量与仪器学报, 2013, 27 (11) :1067-1072.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" WANG W, WANG D.KNN classification algorithm for multiple statuses detection of through-wall human being[C].International Conference in Communications, Signal Processing, and Systems, 2016:229-235." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=KNN classification algorithm for multiple statuses detection of through-wall human being">
                                        <b>[24]</b>
                                         WANG W, WANG D.KNN classification algorithm for multiple statuses detection of through-wall human being[C].International Conference in Communications, Signal Processing, and Systems, 2016:229-235.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" DEMIRHAN M E, SALOR &#214;.Classification of targets in SAR images using SVM and k-NN techniques[C].2016 24th Signal Processing and Communication Application Conference (SIU) , 2016:1581-1584." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classification of targets in SAR images using SVM and k-NN techniques">
                                        <b>[25]</b>
                                         DEMIRHAN M E, SALOR &#214;.Classification of targets in SAR images using SVM and k-NN techniques[C].2016 24th Signal Processing and Communication Application Conference (SIU) , 2016:1581-1584.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(13),98-102 DOI:10.19651/j.cnki.emt.1902571            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于字典学习的电子级玻璃纤维布缺陷分类</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BB%BB%E8%8C%B9&amp;code=42390846&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">任茹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%99%AF%E5%86%9B%E9%94%8B&amp;code=10564246&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">景军锋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%BC%93%E7%BC%93&amp;code=27837015&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张缓缓</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%8F%E6%B3%BD%E6%96%8C&amp;code=30805966&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏泽斌</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0269206&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安工程大学电子信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在电子级玻璃纤维布的缺陷分类中, 由于每类缺陷特征的多样性以及其丰富的几何结构的存在, 用于分类的特征提取方法具有挑战性。提出了一个自动发现特征的框架, 即结构不相关性字典学习 (dictionary learning with structured incoherence, DLSI) 用于提取每类缺陷的特征, 并贡献了电子级玻璃纤维布的数据集。首先, 利用DLSI学习每类图像的缺陷特征得到一个特定类字典, 该字典适合于表示来自该类的电子级玻璃纤维布缺陷, 同时很难表示来自其他类的缺陷图像;接着对于待分类图像, 利用学习到的特定类字典对其进行重构, 得到相应的重构误差;最后根据误差最小准则对待分类图像进行分类。所提出的方法在玻璃纤维布数据集上的平均分类准确率可达96.33%, 显示了DLSI模型对玻璃纤维布缺陷分类的适用性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%B5%E5%AD%90%E7%BA%A7%E7%8E%BB%E7%92%83%E7%BA%A4%E7%BB%B4%E5%B8%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电子级玻璃纤维布;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BC%BA%E9%99%B7%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">缺陷分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BB%93%E6%9E%84%E4%B8%8D%E7%9B%B8%E5%85%B3%E6%80%A7%E5%AD%97%E5%85%B8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">结构不相关性字典学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%87%8D%E6%9E%84%E8%AF%AF%E5%B7%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">重构误差;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    任茹, 研究生, 主要研究方向为机器视觉及图像处理。E-mail:2445712397@qq.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>陕西省高校科协青年人才托举计划项目 (20180115);</span>
                                <span>陕西省教育厅科研计划项目资助 (18JK0338);</span>
                    </p>
            </div>
                    <h1><b>Classification of e-glass fiber fabric defects based on dictionary learning</b></h1>
                    <h2>
                    <span>Ren Ru</span>
                    <span>Jing Junfeng</span>
                    <span>Zhang Huanhuan</span>
                    <span>Su Zebin</span>
            </h2>
                    <h2>
                    <span>School of Electronic Information, Xi'an Polytechnic University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In the classification of e-glass fiber fabric defects, the feature extraction method for classification is challenging due to the diversity of each type of defect features and its rich geometric structures. In this paper, a framework for automatically discovering features, namely dictionary learning with structured incoherence (DLSI) , is proposed to extract features of each type of defect automatically. And contributes to the dataset of e-glass fiber fabric. First, DLSI is used to learn the defect characteristics of each type of images to obtain a specific-class dictionary, which is suitable for representing e-glass fiber fabric defects from the class, while it is difficult to represent defective images from other classes. For the image to be classified, it is reconstructed by using the learned specific-class dictionary to obtain the corresponding reconstruction error. Finally, the classified image is classified according to the error minimum criterion. The average classification accuracy of the proposed method on the e-glass fiber fabric dataset can reach 96.33%, which shows the applicability of the DLSI model to the classification of e-glass fiber fabric defects.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=e-glass%20fiber%20fabric&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">e-glass fiber fabric;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=defect%20classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">defect classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=dictionary%20learning%20with%20structured%20incoherence&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">dictionary learning with structured incoherence;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=reconstruction%20error&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">reconstruction error;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="53" name="53" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="54">玻璃纤维是由细状的二氧化硅或其他配方玻璃被挤压成许多适合纺织加工的小直径纤维形成的<citation id="145" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。玻璃纤维中最常见的类型是电子级玻璃纤维, 该纤维现在已经构成了世界上大部分的玻璃纤维生产。电子级玻璃纤维布, 简称电子布, 是覆铜板、印刷电路板的基本材料<citation id="146" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。在覆铜板或印刷电路板中存在的某些缺陷将可能导致电路板的电子特性发生变化。因此电子布的缺陷分类对于提高电路板生产效率及质量都至关重要。</p>
                </div>
                <div class="p1">
                    <p id="55">目前国内电子布的缺陷主要靠人眼识别, 由于工作人员视觉疲劳等主观因素的影响, 缺陷分类正确率有待提高。传统人工分类织物缺陷的方式不仅效率低, 且用人和管理成本高, 随着全球化市场竞争的压力以及行业对电子布质量新标准的实施, 迫切需要用更科学更有效的方式来代替人工分类<citation id="147" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="56">一般的图像分类包括特征提取与分类器设计2个部分。其中一个具有挑战性的问题是特征的提取, 需要考虑到图像中丰富的几何结构和不同尺度的纹理信息。近年来关于特征提取算法的研究很多<citation id="149" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>, 但大多是针对特定数据集而设计, 并且高度依赖于预处理步骤, 如颜色标准化<citation id="148" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 限制了所设计算法对具有其他纹理特性的图像问题的鲁棒性。为了减轻预处理步骤中的工作量并开发更通用的解决方案, 本文提出了一种依赖于稀疏表示框架的字典学习方法, 该方法可以从原始图像中自动发现相关的缺陷特征。</p>
                </div>
                <div class="p1">
                    <p id="57">基于稀疏表示的方法对于图像分类非常有效<citation id="150" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>, 其基本思想是给定一类图像和足够的基集合, 测试图像可以近似表示为基的稀疏线性组合。DCT和小波基在各种应用中都产生了理想的结果, 如图像的去噪、修复和分类<citation id="151" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>等。为了实现更理想的基集合, 稀疏性和任务驱动的约束以多种方式组合在一起, 形成优化问题, 成为字典学习方法。对于分类问题, 特定的类字典通过简单的基于重建误差的度量实现类分配<citation id="152" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="58">近年来稀疏表示应用在了人脸识别中, Wright等<citation id="153" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出一幅测试的人脸图像作为稀疏约束下训练图像的稀疏线性组合, 并提出一种基于残差的分类技术。该算法的不足之处在于直接对图像进行字典学习会产生噪声等不必要的信息。刘绥美<citation id="154" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出基于K-SVD的稀疏编码字典学习的织物表面疵点检测算法, 但是该算法的鲁棒性不足。Jing等<citation id="155" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出卷积匹配追踪和基于Gabor的K-SVD进行双重字典学习的检测算法, 该算法学习到的字典对不同类间的相关性不是很敏感。因此本文主要目的是学习到一个能更好表达图像的辨别性字典。</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag"><b>1 稀疏表示与字典学习</b></h3>
                <div class="p1">
                    <p id="60">稀疏编码, 即使用给定字典的少数个原子对一个信号进行线性组合的表示。假设给定一个信号<i>X</i>∈<i>R</i><sup><i>n</i></sup>和一个字典<i>D</i>∈<i>R</i><sup><i>n</i>×<i>k</i></sup>, 稀疏表示的问题可以描述为min<sub><i>a</i></sub>‖<i>a</i>‖<sub>0</sub><i>s</i>.<i>t</i>.<i>X</i>=<i>Da</i>, 其中‖<i>a</i>‖<sub>0</sub>是系数向量<i>a</i>∈<i>R</i><sup><i>k</i></sup>的<i>l</i><sub>0</sub>伪范数, 即非0元素的数目。由于最小化<i>l</i><sub>0</sub>属于NP难问题, 通常使用<i>l</i><sub>1</sub>范数来代替。接下来就是解决无约束问题:</p>
                </div>
                <div class="p1">
                    <p id="61">min<sub><i>a</i></sub>‖<i>x</i>-<i>Da</i>‖<mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+<i>λ</i>‖<i>a</i>‖<sub>1</sub> (1) </p>
                </div>
                <div class="p1">
                    <p id="63">式中:<i>λ</i>是平衡重建误差和稀疏度之间权衡的参数。<i>l</i><sub>1</sub>约束可以求得系数向量<i>a</i>的稀疏解。此外, 式 (1) 被证明是一个凸问题, 文献<citation id="156" type="reference">[<a class="sup">17</a>]</citation>使用LARS-Lasso算法进行了有效的求解。该方案也被证明比<i>l</i><sub>0</sub>方法更稳定, 在<i>l</i><sub>0</sub>方法中, 输入信号的微小变化都会产生非常不同的有效集 (即一组非0系数, 或者来自字典的被选原子) 。</p>
                </div>
                <div class="p1">
                    <p id="64">对于实际中的字典<i>D</i>, 文献<citation id="157" type="reference">[<a class="sup">18</a>]</citation>表明字典<i>D</i>最好是从数据中学习到的。给定一组信号{<i>x</i><sub><i>i</i></sub>}<sub><i>i</i>=1, …, <i>m</i></sub>, <i>x</i><sub><i>i</i></sub>∈<i>R</i><sup><i>n</i></sup>, 需要找到一个字典<i>D</i>∈<i>R</i><sup><i>n</i>×<i>k</i></sup>, 使得信号组中的每一个都可以由字典中的原子线性组合表示。本文使用与文献<citation id="158" type="reference">[<a class="sup">19</a>]</citation>类似的方法对式 (2) 进行求解。</p>
                </div>
                <div class="p1">
                    <p id="65"><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>D</mi><mo>, </mo><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo><msub><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>m</mi></mrow></msub></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mo stretchy="false">∥</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>D</mi><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow></mstyle><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="67">对于式 (1) , 使用由2个凸步骤组成的迭代方法进行优化:固定<i>D</i>进行稀疏编码和固定系数向量进行字典更新。</p>
                </div>
                <h3 id="68" name="68" class="anchor-tag"><b>2 基于结构不相关性字典的分类算法</b></h3>
                <div class="p1">
                    <p id="69">为了使得学习到的字典能够对原始图像进行很好的表达, 在字典的学习模型上进行了改进。在提出的分类算法中, 主要包括特定类字典的学习和图像缺陷的分类。在字典学习中, 为了避免冗余信息的干扰, 对图像进行简单的预处理, 采用LBP+HOG滤波器对图像进行滤波。</p>
                </div>
                <h4 class="anchor-tag" id="70" name="70"><b>2.1 特定类字典的学习</b></h4>
                <h4 class="anchor-tag" id="71" name="71">1) 模型的提出</h4>
                <div class="p1">
                    <p id="72">使用字典进行分类时, 常用的方法是使用标记的训练数据训练好特定类字典, 然后将每个待分类图像分配给获得最佳重建的字典类<citation id="159" type="reference"><link href="41" rel="bibliography" /><link href="43" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>。用于该分类任务的度量标准一般是重构误差<i>R</i> (<i>x</i>, <i>D</i>) =‖<i>x</i>-<i>Da</i>‖<mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>, 其中<i>a</i>是稀疏编码中的最优系数向量。虽然这种方法可以产生很好的结果, 但没有考虑到重建的实际稀疏性。假设有两类字典几乎获得了相同的重建误差, 但其中一类字典需要的原子数较多。在这种情况下, 人们宁愿选择提供最稀疏解决方案的字典, 即使重建误差稍大。</p>
                </div>
                <div class="p1">
                    <p id="74">在实践中, 可以使用<i>l</i><sub>0</sub>方法中的一个小的预定义稀疏度<i>L</i>来解决该问题。当采用式 (1) 中的方法时, <i>l</i><sub>0</sub>方法将不再有效 (模型的鲁棒性和稳定性对分类任务至关重要) , 单独比较重建误差几乎没有意义。本文将式 (1) 中的成本函数作为学习字典的性能的度量, 如在式 (2) 的字典学习中, <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>R</mi><mo>^</mo></mover><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>min</mi></mrow><msub><mrow></mrow><mi>a</mi></msub><mrow><mo stretchy="false">∥</mo><mi>x</mi><mo>-</mo><mi>D</mi><mi>a</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>a</mi><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>, 该模型考虑了重建误差和稀疏分解的复杂性。重建误差度量近似的好坏, 复杂度通过优化系数向量<i>a</i>的<i>l</i><sub>1</sub>约束来度量。</p>
                </div>
                <div class="p1">
                    <p id="76">假设<i>X</i><sub><i>i</i></sub>, <i>i</i>=1, …, <i>K</i>是<i>K</i>类图像的集合, <i>D</i><sub><i>i</i></sub>是对应于每一类的特定类字典, 如公式 (2) 中的字典。对于每一个特定类字典, 都只是从该类图像中训练得到, 与其它类中的图像无关, 因此, 为了增强字典不相关性, 提出了以下字典学习模型。</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mrow><mo stretchy="false">{</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><msub><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Κ</mi></mrow></msub></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mo stretchy="false">{</mo></mstyle><mrow><mo stretchy="false">∥</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>D</mi><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munderover><mrow><mo stretchy="false">∥</mo><mi>a</mi><msubsup><mrow></mrow><mrow><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>j</mi></msubsup><mo stretchy="false">∥</mo></mrow></mstyle><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">}</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>η</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>≠</mo><mi>j</mi></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo></mrow></mstyle><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mtext> </mtext><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mrow><mo stretchy="false">∥</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>=</mo><mn>1</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">式中:<i>A</i><sub><i>i</i></sub>=[<i>a</i><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>1</mn></msubsup></mrow></math></mathml>…<i>a</i><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msubsup></mrow></math></mathml>]∈<i>R</i><sup><i>k</i><sub><i>i</i></sub>×<i>m</i><sub><i>i</i></sub></sup>;每个列向量<i>a</i><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>是第<i>i</i>类图像中第<i>j</i>∈[1…<i>m</i><sub><i>i</i></sub>]幅图像对应的稀疏编码。模型中的第1项与式 (2) 中的模型一样, 第2项提供耦合, 增强不同类字典间的不相关性。</p>
                </div>
                <h4 class="anchor-tag" id="82" name="82">2) 模型的求解</h4>
                <div class="p1">
                    <p id="83">式 (3) 是学习每一个特定类字典的学习模型, 总样本的类别数决定了特定类字典的个数。对于该模型, 求解步骤分为: (1) 固定字典<i>D</i><sub><i>i</i></sub>对系数矩阵<i>A</i><sub><i>i</i></sub>进行稀疏编码; (2) 固定系数矩阵<i>A</i><sub><i>i</i></sub>对字典<i>D</i><sub><i>i</i></sub>进行逐列更新。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"> (1) 稀疏编码</h4>
                <div class="p1">
                    <p id="85">首先初始化一个字典<i>D</i><sub><i>i</i></sub>, 字典的大小为<i>R</i><sup><i>n</i><sub><i>i</i></sub>×<i>k</i><sub><i>i</i></sub></sup>。固定字典<i>D</i><sub><i>i</i></sub>, 使用式 (4) 对第<i>i</i>类图像进行稀疏编码。</p>
                </div>
                <div class="p1">
                    <p id="86"><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>D</mi><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="88">对于系数向量<i>A</i><sub><i>i</i></sub>, 使用文献<citation id="160" type="reference">[<a class="sup">22</a>]</citation>中的快速迭代阈值收缩 (FISTA) 算法对式 (4) 进行求解。具体步骤如下。</p>
                </div>
                <div class="p1">
                    <p id="89">输入:∇<i>f</i>的固定步长<i>L</i>:=<i>L</i> (<i>f</i>) </p>
                </div>
                <div class="p1">
                    <p id="90">步骤0:设<i>y</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>1</mn></msubsup></mrow></math></mathml>=<i>A</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mn>0</mn></msubsup></mrow></math></mathml>∈<i>R</i><sup><i>k</i><sub><i>i</i></sub>×<i>m</i><sub><i>i</i></sub></sup>, <i>t</i><sup>0</sup>=1, <i>k</i>=500.</p>
                </div>
                <div class="p1">
                    <p id="93">步骤<i>k</i>: (<i>k</i>≥1) 计算</p>
                </div>
                <div class="p1">
                    <p id="94"><i>A</i><sup><i>k</i></sup><sub>i</sub>=<i>P</i><sub><i>L</i></sub> (<i>y</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup></mrow></math></mathml>) (5) </p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mfrac><mrow><mn>1</mn><mo>+</mo><msqrt><mrow><mn>1</mn><mo>+</mo><mn>4</mn><mrow><mo stretchy="false"> (</mo><mi>t</mi><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow><mn>2</mn></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><mi>A</mi><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup><mo>+</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>t</mi><msup><mrow></mrow><mi>k</mi></msup><mo>-</mo><mn>1</mn></mrow><mrow><mi>t</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo stretchy="false"> (</mo><mi>A</mi><msubsup><mrow></mrow><mi>i</mi><mi>k</mi></msubsup><mo>-</mo><mi>A</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="100">其中, <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>arg</mi></mrow><mrow><mi>min</mi></mrow><msub><mrow></mrow><mrow><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">{</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mfrac><mi>L</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mi>L</mi></mfrac><mo>∇</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mo>, </mo><mi>g</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>λ</mi><mrow><mo stretchy="false">∥</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mtext> </mtext><mo stretchy="false"> (</mo><mi>λ</mi><mo>&gt;</mo><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="102">∇<i>f</i>的固定步长<i>L</i> (<i>f</i>) 等于<i>D</i><sup><i>T</i></sup><sub><i>i</i></sub><i>D</i><sub><i>i</i></sub>的最大特征值。当<i>k</i>=500后, 停止迭代, 便可得到求解后的系数矩阵<i>A</i><sub><i>i</i></sub>。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103"> (2) 字典更新</h4>
                <div class="p1">
                    <p id="104">得到系数矩阵<i>A</i><sub><i>i</i></sub>后, 固定系数矩阵, 得到关于字典<i>D</i><sub><i>i</i></sub>的求解模型。</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>η</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>≠</mo><mi>j</mi></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo></mrow></mstyle><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mo stretchy="false">∥</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>=</mo><mn>1</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">式 (8) 可写为:</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo stretchy="false">∥</mo><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>η</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>≠</mo><mi>j</mi></mrow></munder><mrow><mo stretchy="false">∥</mo><mi>Η</mi><mi>D</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">∥</mo></mrow></mstyle><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup></mtd></mtr><mtr><mtd><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mo stretchy="false">∥</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>=</mo><mn>1</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">其中<i>H</i>矩阵为不属于第<i>i</i>类的字典的集合的转置。式 (9) 的第1项可写为:<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>X</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>X</mi><msub><mrow></mrow><mtext>i</mtext></msub><mo>-</mo><mn>2</mn><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mi>A</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mo>+</mo><mi>A</mi><msub><mrow></mrow><mi>i</mi></msub><mi>A</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, 令<i>E</i>=<i>X</i><sub><i>i</i></sub><i>A</i><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup></mrow></math></mathml>, <i>F</i>=<i>A</i><sub><i>i</i></sub><i>A</i><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup></mrow></math></mathml>, 则式 (9) 可改写为:</p>
                </div>
                <div class="p1">
                    <p id="112"><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>{</mo><mrow><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>X</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mn>2</mn><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>E</mi><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>F</mi><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mo>}</mo></mrow><mo>+</mo><mi>η</mi><mo stretchy="false">∥</mo><mi>Η</mi><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mtext> </mtext><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mo stretchy="false">∥</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>=</mo><mn>1</mn></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="114">为了简化计算, 根据交替方向乘子 (ADMM) 算法, 式 (11) 可以写为:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>Ζ</mi></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">{</mo><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>X</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mn>2</mn><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>E</mi><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>F</mi><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">}</mo><mo>+</mo></mtd></mtr><mtr><mtd><mi>η</mi><mrow><mo stretchy="false">∥</mo><mi>Η</mi><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mtext> </mtext><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>Ζ</mi><mo>;</mo><mo stretchy="false">∥</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>=</mo><mn>1</mn><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">则模型 (11) 的求解可分为3个小模型的求解:</p>
                </div>
                <div class="p1">
                    <p id="117"><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>X</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mn>2</mn><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>E</mi><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mi>t</mi><mi>r</mi><mo stretchy="false"> (</mo><mi>F</mi><mi>D</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mrow><mi>ρ</mi><mo stretchy="false">∥</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Ζ</mi><mo>+</mo><mi>U</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup><mtext> </mtext><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><mo stretchy="false">∥</mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>=</mo><mn>1</mn></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="119"><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ζ</mi><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>Ζ</mi></munder><mi>η</mi><mrow><mo stretchy="false">∥</mo><mi>Η</mi><mi>Ζ</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>ρ</mi><mrow><mo stretchy="false">∥</mo><mi>D</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Ζ</mi><mo>+</mo><mi>U</mi><mo stretchy="false">∥</mo></mrow><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="121"><i>U</i>=<i>U</i>+<i>D</i><sub><i>i</i></sub>-<i>Z</i> (14) </p>
                </div>
                <div class="p1">
                    <p id="122">对式 (12) 、 (13) , 分别令其各自的偏导为0并代入式 (14) , 即可求出第<i>i</i>类的字典<i>D</i><sub><i>i</i></sub>。一旦更新完字典<i>D</i><sub><i>i</i></sub>, 之后固定<i>D</i><sub><i>i</i></sub>并根据式 (4) 求解新的编码系数<i>A</i><sub><i>i</i></sub>, 再固定<i>A</i><sub><i>i</i></sub>根据式 (8) 更新字典<i>D</i><sub><i>i</i></sub>。每一次迭代都会使得函数 (3) 减小, 迭代优化过程将使其收敛到局部最小值并学习到所需的特定类字典<i>D</i><sub><i>i</i></sub>。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>2.2 图像缺陷的分类</b></h4>
                <div class="p1">
                    <p id="124">对于待分类图像<i>Y</i>, 使用每个特定类字典<i>D</i><sub><i>i</i></sub>对其进行重构, 都可得到一个重构误差, 如式 (15) 所示。</p>
                </div>
                <div class="p1">
                    <p id="125"><i>err</i><sub><i>i</i></sub>=‖<i>Y</i>-<i>D</i><sub><i>i</i></sub><i>A</i><sub><i>i</i></sub>‖<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>+<i>λ</i>‖<i>A</i><sub><i>i</i></sub>‖<sub>1</sub> (15) </p>
                </div>
                <div class="p1">
                    <p id="127">假设共有<i>K</i>类图像缺陷, 根据最小误差准则, 图像<i>Y</i>被分配给重构其得到最小误差的字典类:</p>
                </div>
                <div class="p1">
                    <p id="128"><i>identify</i> (<i>Y</i>) =argmin<i>err</i><sub><i>k</i></sub> (<i>Y</i>) <i>k</i>=1, 2, …, <i>C</i> (16) </p>
                </div>
                <h3 id="129" name="129" class="anchor-tag"><b>3 实验结果分析</b></h3>
                <div class="p1">
                    <p id="130">在本文中, 电子布数据集于实际工厂采集。布匹缺陷类型包括断经、边缘、双纬、毛团、阴影和无缺陷6类。每类图像1 200幅。图像格式均为bmp格式, 大小为220×80 pixel, 分辨率为700 dpi。图1所示为6类不同缺陷的电子布图像。本实验是在MATLAB R2017b环境下进行的。为了对基于非结构型字典的电子布缺陷分类方法进行准确的评估, 采用分类准确率进行计算。分类准确率的定义式 (17) 所示, 为了降低实验的误差, 每次分类实验迭代50次, 然后取其平均值。</p>
                </div>
                <div class="area_img" id="165">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/DZCL201913018_16500.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="134">在所提出的方法的实验中, 设置惩罚参数<i>λ</i>=1。字典的大小取决于训练样本的数量以及数据的内在复杂性。对于本文中的数据集, 由于样本数并不大, 字典可变范围在10～80之间, 为了确定字典数量, 进行测试。将实验样本进行训练/测试分组, 在每类训练样本为1 000时, 对字典原子数目分别为10、20、30、40、50、60、70、80时进行了待分类样本的分类, 实验结果如图2所示。从图2中可以看到, 随着字典原子数的增加, 分类准确率大致呈现增加的趋势, 但增加的幅度并不大, 并且如果字典的原子数越多, 则尺寸越大, 字典训练需要的时间就越长, 在综合考虑分类准确率与分类效率的情况下, 该实验设置的字典原子数目为10。</p>
                </div>
                <div class="p1">
                    <p id="135">将提出的算法与目前常用的4类经典分类算法进行了比较, 包括稀疏表示分类 (sparse represent classification, SRC) <citation id="161" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 随机森林 (random forest, RF) <citation id="162" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>, K-近邻 (k-nearest neighbor, KNN) <citation id="163" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>, 支持向量机 (support vector machines, SVM) <citation id="164" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>。分类结果如图3所示。</p>
                </div>
                <div class="p1">
                    <p id="136">从图3中可以看出, 本文提出的算法在各个训练数目上都能得到好的分类准确率, 具有更好的分类性能。这是因为传统的字典学习方法本质上其实就是图像特征的提取, 而本文设计的非结构型字典学习算法更进一步增强了类特定字典对不同类图像缺陷的辨别性。</p>
                </div>
                <div class="area_img" id="137">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201913018_137.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 6类缺陷图像" src="Detail/GetImg?filename=images/DZCL201913018_137.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 6类缺陷图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201913018_137.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="138">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201913018_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 训练样本数为1 000时不同字典原子数的分类精度" src="Detail/GetImg?filename=images/DZCL201913018_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 训练样本数为1 000时不同字典原子数的分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201913018_138.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201913018_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同训练样本时各种分类算法的分类精度" src="Detail/GetImg?filename=images/DZCL201913018_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同训练样本时各种分类算法的分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201913018_139.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="141">表1为训练样本数为1 100时各个分类器得到的分类精度, 可以明显地看到训练样本数为1 100时文中提出的算法已经达到较高的分类准确率。对于传统算法RF, KNN, SVM, 需要可以明显表征缺陷的特征才可以表现出好的分类效果。SRC是直接对图像进行字典学习, 这会模糊字典的辨别性。</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表1 训练样本为1100时各个分类算法的分类精度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td><br />分类算法</td><td>RF</td><td>KNN</td><td>SVM</td><td>SRC</td><td>本文方法</td></tr><tr><td><br />分类精度/%</td><td>79.44</td><td>80.33</td><td>86.00</td><td>87.50</td><td>96.33</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="143" name="143" class="anchor-tag"><b>4 结  论</b></h3>
                <div class="p1">
                    <p id="144">针对电子级玻璃纤维布缺陷特征提取困难的问题, 提出了非结构型字典的学习模型自动提取图像缺陷特征, 并给出了模型求解方法。该模型通过对每一类缺陷图像学习到一个特定类字典, 降低了该类字典与其他类字典的相关性, 能更准确地表达该类缺陷, 实现对图像缺陷的分类, 通过与常用的几类经典算法对比, 该算法对电子级玻璃纤维布缺陷的分类具有很好的适应性, 并且针对目前电子布可用数据集少的问题贡献了一组电子布数据集。该数据集是在实际工厂中, 织物检测机以80 m/min运行时, 使用三台Basler线阵相机对宽度为1.8 m的电子布进行成像, 在该设备下获得了比较一致的数据集。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=E-Glass Fiber Reinforced Composites in Dental Applications">

                                <b>[1]</b> ZHANG M, MATINLINNA J P.E-glass fiber reinforced composites in dental applications[J].Silicon, 2012, 4 (1) :73-78.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Study on the filament yarns spreading techniques and assessment methods of the electronic fiberglass fabric">

                                <b>[2]</b> WANG X, CHEN S H, ZHENG T Y, et al.Study on the filament yarns spreading techniques and assessment methods of the electronic fiberglass fabric[C].International Symposium on Application of Materials Science and Energy Materials, 2018, 322 (2) :215-220.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYZ201801046&amp;v=MzExMDdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlybFY3N0pMejdTZExHNEg5bk1ybzlCWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 李纪峰, 赵凤霞, 金少搏.玻璃纤维布的机器视觉缺陷检测系统设计[J].机械设计与制造, 2018 (1) :163-165, 169.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XBFZ201504006&amp;v=MzAxOTFNcTQ5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cmxWNzdKUFMvTmRMRzRIOVQ=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 游信勇, 钱慧芳.基于变差函数的纺织纹理图像分析[J].西安工程大学学报, 2015, 29 (4) :410-414, 419.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEG042990F37F1F112FD0BD9E6C0B8FEE41&amp;v=MTgwMDdIWWZPR1FsZkJyTFUwNXR0aHhyaTd3YWs9TmlmT2FiTzhITmpGci9sR1k1ME9lbjA0eldCbjZrMEpRUXJrM3hKSGNjVGhNTDZlQ09OdkZTaVdXcjdKSUZwbWFCdQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> JING J F, FAN X T, LI P F.Patterned fabric defect detection via convolutional matching pursuit dual-dictionary[J].Optical Engineering, 2016, 55 (5) :053109.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201711021&amp;v=MTEzMzc3N0pJVGZJWXJHNEg5Yk5ybzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlybFY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 韩辰希, 刘惠义, 商国中.视觉显著性纹理——色彩特征融合的图像目标分类[J].电子测量技术, 2017, 40 (11) :94-98.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 WRIGHT J, YANG A Y, GANESH A, et al.Robust face recognition via sparse representation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) :210-227.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Quality-Based Multimodal Classification Using Tree-Structured Sparsity">

                                <b>[8]</b> BAHRAMPOUR S, RAY A, NASRABADI N M, et al.Quality-based multimodal classification using tree-structured sparsity[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014:4114-4121.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-task image classification via collaborative,hierarchical spike-and-slab priors">

                                <b>[9]</b> MOUSAVI H S, SRINIVAS U, MONGA V, et al.Multi-task image classification via collaborative, hierarchical spike-and-slab priors[C].2014 IEEE International Conference on Image Processing (ICIP) .IEEE, 2014:4236-4240.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image denoising via sparse and redundant representations over learned dictionaries">

                                <b>[10]</b> ELAD M, AHARON M.Image denoising via sparse and redundant representations over learned dictionaries[J].IEEE Transactions on Image processing, 2006, 15 (12) :3736-3745.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 AHARON M, ELAD M, BRUCKSTEIN A, et al.K-SVD:An algorithm for designing overcomplete dictionaries for sparse representation[J].IEEE Transactions on Signal Processing, 2006, 54 (11) :4311-4322.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online dictionary learning for sparse coding">

                                <b>[12]</b> MAIRAL J, BACH F, PONCE J, et al.Online dictionary learning for sparse coding[C].International Conference on Machine Learning (ICML 2009) , 2009:689-696.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Kernel compressive sensing">

                                <b>[13]</b> ANARAKI F P, HUGHES S M.Kernel compressive sensing[C].Image Processing (ICIP) , 2013 IEEE International Conference on Image Processing.IEEE, 2013:494-498.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning overcomplete dictionaries based on atom-by-atom updating">

                                <b>[14]</b> SADEGHI M, BABAIE-ZADEH M, JUTTEN C.Learning overcomplete dictionaries based on atom-by-atom updating[J].IEEE Transactions on Signal Processing, 2014, 62 (4) :883-891.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 WRIGHT J, YANG A Y, GANESH A, et al.Robust face recognition via sparse representation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009, 31 (2) :210-227.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016094457.nh&amp;v=MTU0NTdCdEdGckNVUjdxZlp1WnRGeXJsVjc3SlZGMjZHTE94R3RYSnFKRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 刘绥美.彩色印花织物疵点检测的研究与实现[D].西安:西安工程大学, 2016.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST14112600629333&amp;v=MTIyODd3WmVadEZpbmxVcnpJSWw0UWF4TT1OaWZZZXJLOEg5RE9xWTlGWXVrR0QzODZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> EFRON B, HASTIE T, JOHNSTONE I, et al.Least angle regression[J].The Annals of Statistics, 2004, 32 (2) :407-499.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised dictionary learning and sparse representation-a review">

                                <b>[18]</b> GANGEH M J, FARAHAT A K, GHODSI A, et al.Supervised dictionary learning and sparse representation-a review[J/OL].arXiv Preprint, 2015.https://arxiv.org/abs/1502.05928.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online dictionary learning for sparse coding">

                                <b>[19]</b> MAIRAL J, BACH F, PONCE J, et al.Online dictionary learning for sparse coding[C].Proceedings of the 26th Annual International Conference on Machine Learning, 2009:689-696.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Discriminative learned dictionaries for localimage analysis">

                                <b>[20]</b> MAIRAL J, BACH F, PONCE J, et al.Discriminative learned dictionaries for local image analysis[C].2008 IEEE Conference on Computer Vision and Pattern Recognition, 2008:2415-2422.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00003520613&amp;v=Mjc3NTNNSDdSN3FkWitadUZpdmxVYi9NSVY4PU5qN0Jhck80SHRIUHFvMUZZdW9NWTNrNXpCZGg0ajk5U1hxUnJ4b3hj&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> PEYRÉ G.Sparse modeling of textures[J].Journal of Mathematical Imaging and Vision, 2009, 34 (1) :17-31.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600394713&amp;v=MTAzODN3WmVadEZpbmxVcnpJSWw0UWF4TT1OaWZPZmJLOEh0RE1xWTlGWitJTEMzMDZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> ZHANG L L, XU G Q, XUE Q, et al.An iterative thresholding algorithm for the inverse problem of electrical resistance tomography[J].Flow Measurement and Instrumentation, 2013, 33:244-250.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZIY201311012&amp;v=MTQ5NDU3RzRIOUxOcm85RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5cmxWNzdKSVRmQ2Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> 詹曙, 姚尧, 高贺.基于随机森林的脑磁共振图像分类[J].电子测量与仪器学报, 2013, 27 (11) :1067-1072.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=KNN classification algorithm for multiple statuses detection of through-wall human being">

                                <b>[24]</b> WANG W, WANG D.KNN classification algorithm for multiple statuses detection of through-wall human being[C].International Conference in Communications, Signal Processing, and Systems, 2016:229-235.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classification of targets in SAR images using SVM and k-NN techniques">

                                <b>[25]</b> DEMIRHAN M E, SALOR Ö.Classification of targets in SAR images using SVM and k-NN techniques[C].2016 24th Signal Processing and Communication Application Conference (SIU) , 2016:1581-1584.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201913018" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201913018&amp;v=MjM2NTVFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlybFY3N0pJVGZJWXJHNEg5ak5ySTk=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

