

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135659880725000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dDZCL201915023%26RESULT%3d1%26SIGN%3dTak0a%252faLigfJBAcQ53eOd%252fUmi00%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201915023&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=DZCL201915023&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201915023&amp;v=MTc0ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2Z1ZMM0lJVGZJWXJHNEg5ak5xbzlIWjRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#35" data-title="&lt;b&gt;0 引  言&lt;/b&gt; "><b>0 引  言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 方法与实验&lt;/b&gt; "><b>1 方法与实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;1.1 实现细节&lt;/b&gt;"><b>1.1 实现细节</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;1.2 实验&lt;/b&gt;"><b>1.2 实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#107" data-title="&lt;b&gt;2 结果与分析&lt;/b&gt; "><b>2 结果与分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#115" data-title="&lt;b&gt;3 结  论&lt;/b&gt; "><b>3 结  论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="图1 模型框架">图1 模型框架</a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;表1 评估测试集的统计信息&lt;/b&gt;"><b>表1 评估测试集的统计信息</b></a></li>
                                                <li><a href="#110" data-title="图2 平滑度&lt;i&gt;β&lt;/i&gt;对推荐性能的影响">图2 平滑度<i>β</i>对推荐性能的影响</a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;表2 嵌入大小为16的推荐准确度&lt;/b&gt;"><b>表2 嵌入大小为16的推荐准确度</b></a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表3 嵌入大小为8, 32时的推荐准确性&lt;/b&gt;"><b>表3 嵌入大小为8, 32时的推荐准确性</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" HE X, LIAO L, ZHANG H, et al.Neural collaborative filtering[C].Pisa:ACM, 2017:173-182." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural collaborative filtering">
                                        <b>[1]</b>
                                         HE X, LIAO L, ZHANG H, et al.Neural collaborative filtering[C].Pisa:ACM, 2017:173-182.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 陈琦, 吕杰, 张世超.一个解决协同过滤推荐系统相关问题的新算法[J].电子测量技术, 2016, 39, (35) :66-69." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201605015&amp;v=MDY5MTFNcW85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5dmdWTDNJSVRmSVlyRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈琦, 吕杰, 张世超.一个解决协同过滤推荐系统相关问题的新算法[J].电子测量技术, 2016, 39, (35) :66-69.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 余永红, 高阳, 王皓, 等.融合用户社会地位和矩阵分解的推荐算法[J].计算机研究与发展, 2018, 55 (1) :113-124." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801009&amp;v=MjE1OTVnVkwzSUx5dlNkTEc0SDluTXJvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXY=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         余永红, 高阳, 王皓, 等.融合用户社会地位和矩阵分解的推荐算法[J].计算机研究与发展, 2018, 55 (1) :113-124.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" HE X, ZHANG H, KA M Y, et al.Fast matrix factorization for online recommendation with implicit feedback[C].Pisa:ACM, 2016:549-558." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast matrix factorization for online recommendation with implicit feedback">
                                        <b>[4]</b>
                                         HE X, ZHANG H, KA M Y, et al.Fast matrix factorization for online recommendation with implicit feedback[C].Pisa:ACM, 2016:549-558.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" DAVIDSON J, LIEBALD B, LIU J, et al.The YouTube video recommendation system[C].New York:ACM, 2010:293-296." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The YouTube video recommendation system">
                                        <b>[5]</b>
                                         DAVIDSON J, LIEBALD B, LIU J, et al.The YouTube video recommendation system[C].New York:ACM, 2010:293-296.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" GOMEZ-URIBE C A, HUNT N.The netflix recommender system:algorithms, business value, and innovation[J].ACM Transactions on Management Information Systems (TMIS) , 2016, 6 (4) :13." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM29D4BE407246B17C8907DF87B9F0E0C3&amp;v=MjUyMTV4YXRXKzJvdEZZK2tMQ2c0NHlHVWI0ejk2UEFucXEyQThEN0xoUmNtY0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHg3MjR3cWc9TmlmSVk3Rw==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         GOMEZ-URIBE C A, HUNT N.The netflix recommender system:algorithms, business value, and innovation[J].ACM Transactions on Management Information Systems (TMIS) , 2016, 6 (4) :13.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" SMITH B, LINDEN G.Two decades of recommender systems at amazon.com[J].Ieee internet computing, 2017, 21 (3) :12-18." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Two decades of recommender systems at a-mazon com">
                                        <b>[7]</b>
                                         SMITH B, LINDEN G.Two decades of recommender systems at amazon.com[J].Ieee internet computing, 2017, 21 (3) :12-18.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" BARKAN O, KOENIGSTEIN N.Item2vec:neural item embedding for collaborative filtering[C].Vietri sul Mare:IEEE, 2016:1-6." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Item2vec:neural item embedding for collaborative filtering">
                                        <b>[8]</b>
                                         BARKAN O, KOENIGSTEIN N.Item2vec:neural item embedding for collaborative filtering[C].Vietri sul Mare:IEEE, 2016:1-6.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" VASWANI A, SHAZEER N, PARMAR N, et al.Attention is all you need[C].Advances in Neural Information Processing Systems.2017:5998-6008." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention is all you need">
                                        <b>[9]</b>
                                         VASWANI A, SHAZEER N, PARMAR N, et al.Attention is all you need[C].Advances in Neural Information Processing Systems.2017:5998-6008.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" CHEN J, ZHANG H, HE X, et al.Attentive collaborative filtering:Multimedia recommendation with item and component-level attention[C].Shinjuku, Tokyo:ACM, 2017:335-344." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attentive collaborative filtering:Multimedia recommendation with item and component-level attention">
                                        <b>[10]</b>
                                         CHEN J, ZHANG H, HE X, et al.Attentive collaborative filtering:Multimedia recommendation with item and component-level attention[C].Shinjuku, Tokyo:ACM, 2017:335-344.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" LI J, REN P, CHEN Z, et al.Neural attentive session-based recommendation[C].Singapore:ACM, 2017:1419-1428." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural attentive session-based recommendation">
                                        <b>[11]</b>
                                         LI J, REN P, CHEN Z, et al.Neural attentive session-based recommendation[C].Singapore:ACM, 2017:1419-1428.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" MNIH A, SALAKHUTDINOV R R.Probabilistic matrix factorization[C].Advances in neural information processing systems.2008:1257-1264." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Probabilistic matrix factorization">
                                        <b>[12]</b>
                                         MNIH A, SALAKHUTDINOV R R.Probabilistic matrix factorization[C].Advances in neural information processing systems.2008:1257-1264.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" DUCHI J, HAZAN E, SINGER Y.Adaptive subgrad-ient methods for online learning and stochastic optimization[J].Journal of Machine Learning Research, 2011, 12 (Jul) :2121-2159." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive subgradient methods for online learning and stochastic optimization">
                                        <b>[13]</b>
                                         DUCHI J, HAZAN E, SINGER Y.Adaptive subgrad-ient methods for online learning and stochastic optimization[J].Journal of Machine Learning Research, 2011, 12 (Jul) :2121-2159.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" DESHPANDE M, KARYPIS G.Item-based top-n recommendat-ion algorithms[J].ACM Transactions on Information Systems (TOIS) , 2004, 22 (1) :143-177." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000099859&amp;v=MjkwMTV3WmVadEZpbmxVcnpJSTFzVGFCST1OaWZJWTdLN0h0ak5yNDlGWk9JR0JIa3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         DESHPANDE M, KARYPIS G.Item-based top-n recommendat-ion algorithms[J].ACM Transactions on Information Systems (TOIS) , 2004, 22 (1) :143-177.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" HE X, CHEN T, KAN M Y, et al.Trirank:Review-aware explainable recommendation by modeling aspects[C].Melbourne:ACM, 2015:1661-1670." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Trirank:Review-aware explainable recommendation by modeling aspects">
                                        <b>[15]</b>
                                         HE X, CHEN T, KAN M Y, et al.Trirank:Review-aware explainable recommendation by modeling aspects[C].Melbourne:ACM, 2015:1661-1670.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" SARWAR B M, KARYPIS G, KONSTAN J A, et al.Item-based collaborative filtering recommendation algorithms[J].Www, 2001, 1:285-295." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Item-Based Collaborative Filtering Recommendation Algorithms">
                                        <b>[16]</b>
                                         SARWAR B M, KARYPIS G, KONSTAN J A, et al.Item-based collaborative filtering recommendation algorithms[J].Www, 2001, 1:285-295.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=DZCL" target="_blank">电子测量技术</a>
                2019,42(15),150-154 DOI:10.19651/j.cnki.emt.1902734            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于注意力机制的项目相似性推荐模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B2%88%E5%86%AC%E4%B8%9C&amp;code=42606880&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">沈冬东</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%AA%E6%B5%B7%E6%B6%9B&amp;code=07896577&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汪海涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%9C%E7%91%9B&amp;code=07898974&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姜瑛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E6%98%9F&amp;code=07892463&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈星</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%98%86%E6%98%8E%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0242668&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">昆明理工大学信息工程与自动化学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统基于项目的协同过滤算法具有优秀的可解释性以及实时性, 但是存在推荐精确度不高、难以充分挖掘数据间隐含信息等问题, 该模型引入注意力机制来改善这些问题。该模型分为两个主要的部分:神经项目嵌入、改进的注意力神经网络学习。首先采用item2vec项目嵌入技术生成项目的统一向量表示;其次使用注意力机制学习用户历史交互项目对当前偏好预测的重要性, 得到用户的偏好进行推荐。通过在公共数据集MovieLens和Pinterest上的广泛实验, 与传统的推荐算法以及同类的神经推荐模型进行对比。结果表明改进后的模型在推荐准确性上有明显的提升, 最高可提升6.04%。该模型在保证推荐算法的可解释性与实时性的同时提高了推荐算法的精确性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">协同过滤;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经推荐模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%A1%B9%E7%9B%AE%E5%B5%8C%E5%85%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">项目嵌入;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    沈冬东, 硕士研究生, 主要研究方向为个性化推荐系统、软件复用。E-mail:martin5656@126.com;
                                </span>
                                <span>
                                    *汪海涛 (通讯作者) , 副教授, 硕士研究生导师, 从事软件复用方向的研究工作。E-mail:kmwht@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-26</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金资助项目 (61462049) 资助;</span>
                    </p>
            </div>
                    <h1><b>Item similarity recommendation model based on attention mechanism</b></h1>
                    <h2>
                    <span>Shen Dongdong</span>
                    <span>Wang Haitao</span>
                    <span>Jiang Ying</span>
                    <span>Chen Xing</span>
            </h2>
                    <h2>
                    <span>Faculty of Information Engineering and Automation, Kunming University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional item-based collaborative filtering algorithm has excellent interpretability and real-time performance, but there are problems such as low recommendation accuracy and difficulty in fully mining the implicit information between data. The model introduces attention mechanism to improve these problems. The model is divided into two main parts: neural project embedding, and improved attention neural network learning. Firstly, the item2 vec item embedding technology is used to generate the unified vector representation of the item. Secondly, the attention mechanism is used to learn the importance of the user history interaction item to the current preference prediction, and the user′s preference is recommended. Through extensive experiments on the public datasets MovieLens and Pinterest, it is compared with traditional recommendation algorithms and similar neural recommendation models. The results show that the improved model has a significant improvement in recommendation accuracy, up to 6.04%. The model improves the accuracy of the recommendation algorithm while ensuring the interpretability and real-time performance of the recommendation algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=collaborative%20filtering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">collaborative filtering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=neural%20recommendation%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">neural recommendation model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=item%20embedding&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">item embedding;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=attention%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">attention network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-26</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="35" name="35" class="anchor-tag"><b>0 引  言</b></h3>
                <div class="p1">
                    <p id="36">在推荐系统的各种研究方法中, 协同过滤是一种仅通过用户-项目交互信息来预测用户个性化偏好的方法, 在学术界和工业界都有广泛的应用<citation id="117" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>。通过Netflix奖的推广, 矩阵分解方法<citation id="118" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>已成为学术界最受欢迎的推荐方法之一, 在很多文献中得到了广泛的研究。尽管矩阵分解方法在评分预测方面显示出比基于领域的方法更高的准确性, 但是相对很少被用于工业应用中。一个可能的原因是, 矩阵分解将用户表征为具有ID的嵌入向量, 所以当用户有了新的项目交互时, 必须更新用户的嵌入向量。对于需要重新训练大量数据的矩阵分解模型来说, 很难实时实现, 所以对于需要实时更新的实际应用来说, 矩阵分解往往不是一个好的选择。</p>
                </div>
                <div class="p1">
                    <p id="37">另一方面, 项目到项目的协同过滤已经在工业应用中被大量使用<citation id="119" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>, 该方法基于用户可能会喜欢相似、相关历史项目的假设, 从而具有更好的解释性, 在实时推荐的情境下, 也可以进行高效地推荐。具体来说, 估计项目相似性的主要计算可以离线完成, 在线推荐模型仅需要对相似项目进行一系列查找就可以很容易实时完成。</p>
                </div>
                <div class="p1">
                    <p id="38">早期的协同过滤技术采用简单的统计方法来计算项目的相似性, 因此通常在Top-N推荐精度方面表现不如基于机器学习的推荐方法。近年来, 神经嵌入技术在自然语言领域得到了足够的研究。在这些工作中, item2vec<citation id="120" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>是Skip-gram与负抽样的重要扩展之一, 用于为项目产生嵌入向量。</p>
                </div>
                <div class="p1">
                    <p id="39">item2vec的建模保真度可能受到以下假设的限制:用户交互的历史项目在预测目标项目时具有同等贡献。直观地来说, 用户在过去与多个项目交互, 但是用户对这些交互项目可能具有不同的兴趣度。例如, 一个喜欢看电影的影迷可能因为恐怖电影在那段时间比较流行而观看恐怖电影, 另一个例子是用户的兴趣度可能随时间而变化, 因此, 最近交互的项目应该更能反映用户的未来偏好。</p>
                </div>
                <div class="p1">
                    <p id="40">基于传统的项目嵌入的缺点, 本文对item2vec进行改进。通过区分历史交互项目对构建用户偏好的不同贡献提出增强的项目相似性模型。改进的模型建立在item2vec之上, 在线预测的高效性方面与item2vec保持相同的优点, 同时通过学习历史交互项目的对预测的不同重要性, 比item2vec更具表征能力。本文采用神经表征学习的最新进展注意力机制来实现学习用户历史交互项目对预测目标项目的贡献。在实验中发现标准的注意力机制无法准确地从历史数据中学习, 因为用户的历史交互长度存在很大的差异。为了解决这个问题, 本文通过平滑用户历史来调整注意力的设计, 以此来构建本文中提出的基于注意力机制的项目协同过滤模型 (item collaborative filtering model based on attention mechanism, Attention-ICF) 。</p>
                </div>
                <h3 id="41" name="41" class="anchor-tag"><b>1 方法与实验</b></h3>
                <div class="p1">
                    <p id="42">本文重点讨论使用隐式反馈来优化模型, 这也是推荐系统最近研究的重点, 因为隐式反馈比显示评分更普遍且易于收集。Attention-ICF主要包括两个主要组成部分, 分别是神经项目嵌入和改进的注意力网络学习, 模型的整体结构图如图1所示。</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201915023_043.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 模型框架" src="Detail/GetImg?filename=images/DZCL201915023_043.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 模型框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201915023_043.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="44" name="44"><b>1.1 实现细节</b></h4>
                <h4 class="anchor-tag" id="45" name="45">1) 神经项目嵌入</h4>
                <div class="p1">
                    <p id="46">在本模型的第一阶段, 通过神经项目嵌入技术从大量的历史交互中学习项目的统一表示来度量项目的相似性。使用Skip-gram模型来捕获项目的相似性, 通过直接利用用户对项目的历史交互来生成项目表示。具体来说, 给定来自用户<i>u</i>的交互序列<i>S</i><sub><i>u</i></sub>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>N</i></sub>}, item2vec技术的Skip-gram模型旨在最小化以下目标:</p>
                </div>
                <div class="p1">
                    <p id="47"><mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mi>t</mi><mo>=</mo><mfrac><mn>1</mn><mi>Κ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><mi>i</mi></mrow><mi>Κ</mi></munderover><mrow><mi>lg</mi></mrow></mstyle></mrow></mstyle><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="49">式中:<i>K</i>是序列<i>S</i><sub><i>u</i></sub>的长度。<i>p</i> (<i>x</i><sub><i>j</i></sub>|<i>x</i><sub><i>i</i></sub>) 定义为<i>softmax</i>函数:</p>
                </div>
                <div class="p1">
                    <p id="50"><mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>k</mi></msub><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>v</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="52">式中:<i>w</i><sub><i>i</i></sub>和<i>v</i><sub><i>i</i></sub>对应于<i>x</i><sub><i>i</i></sub>的目标和上下文表示的潜在向量。为了减少梯度下降∇ (<i>x</i><sub><i>j</i></sub>|<i>x</i><sub><i>i</i></sub>) 的计算复杂度, 采用负抽样来取代, 式 (2) 变为如下所示:</p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>E</mi></munderover><mi>σ</mi></mstyle><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>v</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="55">式中:<i>σ</i> (<i>x</i>) 为<i>sigmod</i>函数;<i>E</i>表示为每个正样本绘制的负样本数量, 方便优化模型。经过上面的一系列变形, 目标函数由式 (3) 变为如下所示:</p>
                </div>
                <div class="p1">
                    <p id="56"><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>a</mtext><mtext>r</mtext><mtext>g</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mi>t</mi><mo>=</mo><mfrac><mn>1</mn><mi>Κ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mrow><mi>log</mi></mrow><mi>σ</mi><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>E</mi></munderover><mi>σ</mi></mstyle><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mi>v</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="58">最后, 本文通过传统的梯度下降训练item2vec, 并获得所有项目的高质量分布式矢量表示。</p>
                </div>
                <div class="p1">
                    <p id="59">使用item2vec, 可以在用户交互的帮助下捕获项目的相似性, 并生成统一的项目表示空间, 其中嵌入产生的向量可以解释项目的相似性和顺序关系。并且, 对于每个用户<i>u</i>, 可以生成具有嵌入项的交互序列, 如下所示</p>
                </div>
                <div class="p1">
                    <p id="60"><i>P</i><sub><i>u</i></sub>={<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, …, <i>v</i><sub><i>T</i></sub>} (5) </p>
                </div>
                <div class="p1">
                    <p id="61">式中:<i>v</i><sub><i>j</i></sub>表示项目<i>x</i><sub><i>j</i></sub>的<i>d</i>维潜在向量。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62">2) 改进注意力网络学习</h4>
                <div class="p1">
                    <p id="63">在获得项目嵌入后, 通过改进标准注意力机制来学习用户的历史数据对预测目标的贡献程度, 直接从自然语言处理类比过来的注意力模型和推荐不同, 在诸如计算机视觉, 自然语言处理任务的常规使用场景中, 注意力成分的数量变化不大, 例如句子中的单词和图像中的区域变化不大。因此, 使用<i>softmax</i>函数可以正确地标准化注意力, 而且反过来具有很好的概率解释, 然而, 对于推荐系统相关数据, 用户的历史交互项目长度可能变化很大。定性的说, <i>softmax</i>函数对注意力权重执行L1归一化, 这可能过度惩罚具有长历史的活动用户的权重, 并导致不同用户的注意力量变化很大。</p>
                </div>
                <div class="p1">
                    <p id="64">为了解决这个问题, 本文在标准注意力机制上做出改进变化, 区别的对待数据, 在后续实验中取得积极的效果。当用户交互序列长度大于所有用户交互长度均值<i>μ</i>时, 采用添加<i>β</i>来平滑<i>softmax</i>的分母, 以减轻对活跃用户的惩罚, 同时减少注意力度量的方差。表示如下:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>a</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mi>β</mi><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>R</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup></mrow></msub><mi>f</mi></mstyle><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mi>R</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup></mrow><mo>|</mo></mrow><mo>&gt;</mo><mi>μ</mi><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">式中:<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>R</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup></mrow><mo>|</mo></mrow></mrow></math></mathml>表示用户<i>u</i>的交互序列长度;<i>μ</i>表示所有用户的交互序列长度平均值。</p>
                </div>
                <div class="p1">
                    <p id="68">本文采用为每个历史交互加上一个权重实现注意力机制, 具体地用户对目标项目的预测如下所示:</p>
                </div>
                <div class="p1">
                    <p id="69"><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub><mo>=</mo><mi>v</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>R</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup></mrow></munder><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="71">式中:<i>a</i><sub><i>ij</i></sub>表示历史交互序列中的项目对预测目标项目<i>i</i>的影响程度。本文通过注意力函数来参数化<i>a</i><sub><i>ij</i></sub>, 即</p>
                </div>
                <div class="p1">
                    <p id="72"><i>a</i><sub><i>ij</i></sub>=<i>f</i> (<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>) (8) </p>
                </div>
                <div class="p1">
                    <p id="73">注意力机制的优势在于即使一对 (<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>) 从从未在用户交互中同时发生过, 只要已经从神经嵌入中学习到可靠的<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>仍然可以很好地用于估计注意权重。要实现这一目标, 需要确保函数<i>f</i>具有强大的表示能力, 受近期注意力神经网络模型<citation id="121" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>的启发, Attention-ICF使用多层感知机 (MLP) 来参数化注意力函数<i>f</i>, 具体来说, 其表示为:</p>
                </div>
                <div class="p1">
                    <p id="74"><i>f</i> (<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>) =<i>h</i><sup><i>T</i></sup>Re<i>LU</i> (<i>W</i> (<i>v</i><sub><i>i</i></sub>⊙<i>v</i><sub><i>j</i></sub>) +<i>b</i>) (9) </p>
                </div>
                <div class="p1">
                    <p id="75">注意力网络采用整流线性单元 (ReLU) 作为隐藏层的激活函数, 其已被证明在注意神经网络中具有良好的性能。本文将隐藏层的大小称为“关注因子”, 其中较大的值为注意力网络带来更强的表示能力。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76">3) 整体模型设计</h4>
                <div class="p1">
                    <p id="77">按照前两步得出的研究和设计, 模型的的整体设计表述为:</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub><mo>=</mo><mi>v</mi><msubsup><mrow></mrow><mi>i</mi><mi>Τ</mi></msubsup><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>R</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup></mrow></munder><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mi>β</mi><mstyle displaystyle="true"><msub><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>R</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup></mrow></msub><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mrow><mo>|</mo><mrow><mi>R</mi><msubsup><mrow></mrow><mi>u</mi><mo>+</mo></msubsup></mrow><mo>|</mo></mrow><mo>&gt;</mo><mi>μ</mi></mrow></math></mathml>      (11) </p>
                </div>
                <h4 class="anchor-tag" id="82" name="82">4) 模型的优化</h4>
                <div class="p1">
                    <p id="83">本小节讨论模型的优化, 首先确定模型的目标函数。传统的目标函数使用均方误差的逐点学习方法来定义。虽然均方误差可以假设传统方法服从高斯分布<citation id="122" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>来做出解释, 但是其不适合处理隐式数据, 这是因为对于隐式数据来说, 目标值<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub></mrow></math></mathml>是二进制1或0, 表示<i>u</i>是否与<i>i</i>进行了互动。本文使用概率学方法来定义损失函数, 在处理数据之前加入一个函数 (例如, <i>sigmoid</i>函数或者<i>probit</i>函数) 实现对预测分数的压缩, 这样的设置将预测分数<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub></mrow></math></mathml>可以用来形象化的理解为用户<i>u</i>可能对项目<i>i</i>选择的可能性。</p>
                </div>
                <div class="p1">
                    <p id="86">经过上面的讨论, 将推荐问题理解为机器学习中的二分类问题。本文将观察到的用户-项目交互设为正实例, 从剩余的未观察到的交互中抽取负实例。设<i>R</i><sup>+</sup>和<i>R</i><sup>-</sup>分别表示正负实例的集合, 本文将规则化的对数损失最小化定义如下:</p>
                </div>
                <div class="p1">
                    <p id="87"><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>i</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mo>+</mo></msup></mrow><mi>Κ</mi></munderover><mrow><mi>log</mi></mrow></mstyle><mi>σ</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>i</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>R</mi><msup><mrow></mrow><mo>-</mo></msup></mrow><mi>Κ</mi></munderover><mrow><mi>log</mi></mrow></mstyle><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>σ</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>+</mo><mrow><mi>λ</mi><mo stretchy="false">∥</mo><mtext>Θ</mtext><mo stretchy="false">∥</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (12) </p>
                </div>
                <div class="p1">
                    <p id="89">式中:<i>N</i>表示所有训练样本的数量。本文设置一个超参数来<i>λ</i>来防止过拟合, 其通过控制L2正则化的强度来实现, 其中的Θ中包含本文所设定的所有参数。</p>
                </div>
                <div class="p1">
                    <p id="90">优化目标函数, 本文采用Adagrad 方法<citation id="123" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 从所有训练实例中抽取随机样本, 将相关参数更新为其梯度的负方向, 并且使用Adagrad的迷你批量版本来加速培训过程。在每个训练时期, 首先生成所有负面实例, 然后将负面实例与正实例一起馈送到训练算法中以进行参数更新。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>1.2 实验</b></h4>
                <h4 class="anchor-tag" id="92" name="92">1) 数据准备</h4>
                <div class="p1">
                    <p id="93">本文采用2个公共基准数据集作为实验数据, 这两个数据集的详细信息如表1所示:</p>
                </div>
                <div class="area_img" id="94">
                    <p class="img_tit"><b>表1 评估测试集的统计信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="94" border="1"><tr><td>数据集</td><td>用户数</td><td>项目数</td><td>交互数</td><td>稀疏性</td></tr><tr><td><br />MovieLens</td><td>3 706</td><td>1 000 209</td><td>6 040</td><td>95.53%</td></tr><tr><td><br />Pinterest</td><td>9 916</td><td>1 500 809</td><td>55 187</td><td>99.73%</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="95">MovieLens, 数据集为用户对电影评分的显示信息, 因为本文主要研究隐式反馈构建推荐系统。为此, 本文将其转换为隐式数据, 其中每个项目被标记为0或1表示用户是否对该项目进行评分。</p>
                </div>
                <div class="p1">
                    <p id="96">Pinterest, 这是一个隐式反馈数据集, 这个数据集的数据稀疏性问题特别严重。本文仅保留至少包含20次交互记录的用户, 处理后的数据包含55 187个用户和1 580 809个项目交互的数据的子集。</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97">2) 评估方案</h4>
                <div class="p1">
                    <p id="98">本文采用留一法来评价推荐系统的性能, 即将最后一次的交互数据留出作为评估数据。具体的来说, 每个留下的测试数据加上随机从用户没交互的项目中选出99个组成训练数据集。然后每种方法输出100个实例的预测分数 (1个正实例加上99个负实例) 选择在第10个位置的命中率 (HR) <citation id="124" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和归一化折扣累积增益 (NDCG) <citation id="125" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>来评估推荐系统的性能。本文中的实验结果为所有用户的平均分数, 其中HR@10可以被解释为基于召回的度量, 表示成功推荐用户的百分比 (即, 正面实例出现在前10名) , 而NDCG@10是一种基于精度的度量, 其考虑了正实例的预测位置, 其值越大越好。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99">3) 基线方法</h4>
                <div class="p1">
                    <p id="100">POP, 项目被交互次数多就被推荐给用户, 是在Top-N推荐中常见的基线方法。</p>
                </div>
                <div class="p1">
                    <p id="101">ItemKNN<citation id="126" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 这是基于标准项目的CF方法, 使用余弦相似度来测量<i>S</i><sub><i>ij</i></sub>, 本文尝试使用不同数量的最近项目邻居来考虑, 使用所有邻居查找可获得最佳结果。</p>
                </div>
                <div class="p1">
                    <p id="102">Item2vec, 通过神经项目嵌入获得项目向量后, 采用基本的向量的内积表征项目相似的协同过滤模型。</p>
                </div>
                <div class="p1">
                    <p id="103">MLP, 该方法在用户和项目嵌入之上应用多层感知器 (MLP) 以从数据学习评分函数。本文采用3层MLP并优化相同的逐点对数损失。</p>
                </div>
                <div class="p1">
                    <p id="104">本文设置ItemKNN和Item2vec代表基于项目的协同过滤方法, 已验证Attention-ICF方法中注意力网络建模的效果, 而MLP是最近提出的基于深度神经网络的协同过滤方法, 用于针对性的对比Attention-ICF。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105">4) 参数设置</h4>
                <div class="p1">
                    <p id="106">对于每种方法, 首先训练它而不进行正则化, 如果观察到过拟合, 则将正则化系数<i>λ</i>调整在[10<sup>-6</sup>, 10<sup>-5</sup>, …, 1]的范围内。验证集有每个用户随机绘制的交互组成, 对于嵌入大小<i>k</i>, 我们测试[8, 16, 32, 64]的值, 并将注意因子<i>α</i>设置为用嵌入大小相同。参数设置为:1) <i>λ</i>=0, 2) <i>k</i>=<i>α</i>=16, 3) <i>β</i>=0.7, 4) Adagrad的学习率为0.01</p>
                </div>
                <h3 id="107" name="107" class="anchor-tag"><b>2 结果与分析</b></h3>
                <div class="p1">
                    <p id="108">在结果分析中首先分析平滑因子<i>β</i>对推荐性能的影响, 采用HR以及NDCG对其进行评估, 并在两个数据集上进行实现, 结果显示在<i>β</i>=0.7左右时能获得较好的推荐性能, 实验结果如图2所示:</p>
                </div>
                <div class="p1">
                    <p id="109">本文实验的结果如表2和表3所示, 其中性能最佳的用加粗表示。对于基线方法中的item2vec和MLP, 其嵌入的大小控制其建模能力, 因此将所有方法设置为16, 以进行公平比较。在后面的研究者, 本文改变了每种方法的嵌入大小来探讨推荐性能, 表3显示整体推荐的准确性。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/DZCL201915023_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 平滑度β对推荐性能的影响" src="Detail/GetImg?filename=images/DZCL201915023_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 平滑度<i>β</i>对推荐性能的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/DZCL201915023_110.jpg&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="111">
                    <p class="img_tit"><b>表2 嵌入大小为16的推荐准确度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">（%）</p>
                    <table id="111" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="2"><br />MovieLens</td><td colspan="2">Pinterest</td></tr><tr><td><br />HR</td><td>NDCG</td><td>HR</td><td>NDCG</td></tr><tr><td><br />Pop</td><td>45.72</td><td>26.12</td><td>28.45</td><td>14.54</td></tr><tr><td><br />ItemKNN</td><td>63.67</td><td>35.34</td><td>78.32</td><td>49.12</td></tr><tr><td><br />Item2vec</td><td>65.63</td><td>39.50</td><td>86.40</td><td>53.97</td></tr><tr><td><br />MLP</td><td>68.12</td><td>41.08</td><td>86.56</td><td>53.38</td></tr><tr><td><br />Attention-ICF</td><td>69.85</td><td>41.93</td><td>88.12</td><td>57.38</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表3 嵌入大小为8, 32时的推荐准确性</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">（%）</p>
                    <table id="112" border="1"><tr><td rowspan="3"><br />方法</td><td colspan="4"><br />K=8</td><td colspan="4">K=32</td></tr><tr><td colspan="2"><br />MovieLens</td><td colspan="2">Pinterest</td><td colspan="2">MovieLens</td><td colspan="2">Pinterest</td></tr><tr><td><br />HR</td><td>NDCG</td><td>HR</td><td>NDCG</td><td>HR</td><td>NDCG</td><td>HR</td><td>NDCG</td></tr><tr><td><br />Item2vec</td><td>60.73</td><td>35.78</td><td>86.89</td><td>54.03</td><td>68.76</td><td>41.29</td><td>87.40</td><td>57.03</td></tr><tr><td><br />MLP</td><td>64.87</td><td>37.24</td><td>85.91</td><td>53.98</td><td>68.59</td><td>42.26</td><td>86.44</td><td>54.77</td></tr><tr><td><br />Attention-ICF</td><td>67.24</td><td>39.61</td><td>87.34</td><td>55.85</td><td>70.87</td><td>43.39</td><td>88.76</td><td>57.43</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="114">本文提出的方法在两个数据集上都展示出良好的推荐性能, 相比较其他先进算法有了显著的改进, 特别对于item2vec模型, 注意力机制加入偏好预测后, 推荐的性能得到提高;改变计算项目相似度的方法后, 有积极的影响, 对Attention-ICF与itemKNN的对比中可以看出, 两种的预测方式都是一样, 但计算项目相似度方法不同, 改进之后有很大的提升, 可以清楚地看到定制优化对推荐的积极影响;本文设置基于用户的方法 (MLP) , 来和基于项目的方法 (item2vec) 作对比。实验结果表明, 在MovieLens上, 基于用户的模型比Item2vec表现更好, 而在Pinterest上Item2vec优于基于用户的模型。这是由于Pinterest数据的用户交互更加稀疏, 这可以揭示基于项目的协同过滤在面对数据稀疏问题时更有利;在嵌入大小为8, 16, 32时Attention-ICF均表现出比其他需要项目嵌入得算法有好的推荐性能, 表明对原方法的改进的能很好的提高推荐性能。</p>
                </div>
                <h3 id="115" name="115" class="anchor-tag"><b>3 结  论</b></h3>
                <div class="p1">
                    <p id="116">本文中, 开发了项目到项目协同过滤的神经网络方法, 改进了标准注意力机制不适用与推荐系统的问题, 实验结果表明改进之后的方法由于传统的item2vec方法以及同等的神经推荐模型MLP, 结果证明引入注意力机制是能很好的提高推荐性能的。但是在注意力网络设计时由于考虑到在线个性化推荐的准确性和简单性, 本文在仅考虑了多层感知机实现注意力机制。在后续工作中, 思考使用更复杂的神经网络学习数据的隐含信息, 例如卷积神经网络或者循环神经网络, 这已经在有些研究中有所体现。在本文的第一步神经嵌入中, 也可以考虑将注意力机制融入到学习项目嵌入表示的模型中, 这样能更加精确的获得项目嵌入向量, 最后将进一步的研究推荐系统的可解释。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural collaborative filtering">

                                <b>[1]</b> HE X, LIAO L, ZHANG H, et al.Neural collaborative filtering[C].Pisa:ACM, 2017:173-182.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201605015&amp;v=MDg0OTh0R0ZyQ1VSN3FmWnVadEZ5dmdWTDNJSVRmSVlyRzRIOWZNcW85RVlZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈琦, 吕杰, 张世超.一个解决协同过滤推荐系统相关问题的新算法[J].电子测量技术, 2016, 39, (35) :66-69.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201801009&amp;v=MDkxOTNvOUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZnVkwzSUx5dlNkTEc0SDluTXI=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 余永红, 高阳, 王皓, 等.融合用户社会地位和矩阵分解的推荐算法[J].计算机研究与发展, 2018, 55 (1) :113-124.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast matrix factorization for online recommendation with implicit feedback">

                                <b>[4]</b> HE X, ZHANG H, KA M Y, et al.Fast matrix factorization for online recommendation with implicit feedback[C].Pisa:ACM, 2016:549-558.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The YouTube video recommendation system">

                                <b>[5]</b> DAVIDSON J, LIEBALD B, LIU J, et al.The YouTube video recommendation system[C].New York:ACM, 2010:293-296.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM29D4BE407246B17C8907DF87B9F0E0C3&amp;v=MTE5MzdmT0dRbGZCckxVMDV0dGh4NzI0d3FnPU5pZklZN0d4YXRXKzJvdEZZK2tMQ2c0NHlHVWI0ejk2UEFucXEyQThEN0xoUmNtY0NPTnZGU2lXV3I3SklGcG1hQnVIWQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> GOMEZ-URIBE C A, HUNT N.The netflix recommender system:algorithms, business value, and innovation[J].ACM Transactions on Management Information Systems (TMIS) , 2016, 6 (4) :13.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Two decades of recommender systems at a-mazon com">

                                <b>[7]</b> SMITH B, LINDEN G.Two decades of recommender systems at amazon.com[J].Ieee internet computing, 2017, 21 (3) :12-18.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Item2vec:neural item embedding for collaborative filtering">

                                <b>[8]</b> BARKAN O, KOENIGSTEIN N.Item2vec:neural item embedding for collaborative filtering[C].Vietri sul Mare:IEEE, 2016:1-6.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention is all you need">

                                <b>[9]</b> VASWANI A, SHAZEER N, PARMAR N, et al.Attention is all you need[C].Advances in Neural Information Processing Systems.2017:5998-6008.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attentive collaborative filtering:Multimedia recommendation with item and component-level attention">

                                <b>[10]</b> CHEN J, ZHANG H, HE X, et al.Attentive collaborative filtering:Multimedia recommendation with item and component-level attention[C].Shinjuku, Tokyo:ACM, 2017:335-344.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural attentive session-based recommendation">

                                <b>[11]</b> LI J, REN P, CHEN Z, et al.Neural attentive session-based recommendation[C].Singapore:ACM, 2017:1419-1428.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Probabilistic matrix factorization">

                                <b>[12]</b> MNIH A, SALAKHUTDINOV R R.Probabilistic matrix factorization[C].Advances in neural information processing systems.2008:1257-1264.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive subgradient methods for online learning and stochastic optimization">

                                <b>[13]</b> DUCHI J, HAZAN E, SINGER Y.Adaptive subgrad-ient methods for online learning and stochastic optimization[J].Journal of Machine Learning Research, 2011, 12 (Jul) :2121-2159.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000099859&amp;v=MTQ1NDlCST1OaWZJWTdLN0h0ak5yNDlGWk9JR0JIa3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJMXNUYQ==&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> DESHPANDE M, KARYPIS G.Item-based top-n recommendat-ion algorithms[J].ACM Transactions on Information Systems (TOIS) , 2004, 22 (1) :143-177.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Trirank:Review-aware explainable recommendation by modeling aspects">

                                <b>[15]</b> HE X, CHEN T, KAN M Y, et al.Trirank:Review-aware explainable recommendation by modeling aspects[C].Melbourne:ACM, 2015:1661-1670.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Item-Based Collaborative Filtering Recommendation Algorithms">

                                <b>[16]</b> SARWAR B M, KARYPIS G, KONSTAN J A, et al.Item-based collaborative filtering recommendation algorithms[J].Www, 2001, 1:285-295.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="DZCL201915023" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZCL201915023&amp;v=MTc0ODFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2Z1ZMM0lJVGZJWXJHNEg5ak5xbzlIWjRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1Fhb09pSnNveUxRekd3QkxsbWVobFYrZnFaTmhSdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

