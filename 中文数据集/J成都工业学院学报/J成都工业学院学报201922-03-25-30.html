<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=NOOK-mvTMnxl11s6oPYV0boPXN3iP4N7Rc-A56nk4KI1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2fKXReader%2fDetail%3fTIMESTAMP%3d637141889990600000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dCDDJ201903007%26RESULT%3d1%26SIGN%3d7ivCoyq9m4LvFJqCwEoAi2yehns%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CDDJ201903007&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=CDDJ201903007&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CDDJ201903007&amp;v=MDg5NzR6cXFCdEdGckNVUjdxZlp1Wm1GeTdoVXI3SkppblBaTEc0SDlqTXJJOUZZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="1 YOLOv3算法描述 ">1 YOLOv3算法描述</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="1.1 YOLOv3的主体结构">1.1 YOLOv3的主体结构</a></li>
                                                <li><a href="#51" data-title="1.2 损失函数">1.2 损失函数</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#60" data-title="2 基于YOLOv3的磁瓦缺陷检测 ">2 基于YOLOv3的磁瓦缺陷检测</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#61" data-title="2.1 磁瓦数据集">2.1 磁瓦数据集</a></li>
                                                <li><a href="#64" data-title="2.2 实验条件及训练过程">2.2 实验条件及训练过程</a></li>
                                                <li><a href="#67" data-title="2.3 本文算法评估指标">2.3 本文算法评估指标</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#70" data-title="3 磁瓦检测结果与分析 ">3 磁瓦检测结果与分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="3.1 预处理图片">3.1 预处理图片</a></li>
                                                <li><a href="#76" data-title="3.2 缺陷检测结果">3.2 缺陷检测结果</a></li>
                                                <li><a href="#81" data-title="3.3 不同算法检测结果对比">3.3 不同算法检测结果对比</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="4 结论 ">4 结论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="&lt;b&gt;图&lt;/b&gt;1 Darknet-53&lt;b&gt;残差结构图&lt;/b&gt;"><b>图</b>1 Darknet-53<b>残差结构图</b></a></li>
                                                <li><a href="#44" data-title="&lt;b&gt;图&lt;/b&gt;2 Darknet-53&lt;b&gt;中&lt;/b&gt;res&lt;b&gt;结构图&lt;/b&gt;"><b>图</b>2 Darknet-53<b>中</b>res<b>结构图</b></a></li>
                                                <li><a href="#47" data-title="&lt;b&gt;图&lt;/b&gt;3 YOLOv3&lt;b&gt;主体结构图&lt;/b&gt;"><b>图</b>3 YOLOv3<b>主体结构图</b></a></li>
                                                <li><a href="#63" data-title="&lt;b&gt;图&lt;/b&gt;4 &lt;b&gt;数据集部分缺陷图&lt;/b&gt;"><b>图</b>4 <b>数据集部分缺陷图</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;图&lt;/b&gt;5 &lt;b&gt;预处理图片&lt;/b&gt;"><b>图</b>5 <b>预处理图片</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;表&lt;/b&gt;1 &lt;b&gt;预处理检测出的具体坐标&lt;/b&gt;"><b>表</b>1 <b>预处理检测出的具体坐标</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;表&lt;/b&gt;2 &lt;b&gt;算法检测出的具体坐标&lt;/b&gt;"><b>表</b>2 <b>算法检测出的具体坐标</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;表&lt;/b&gt;3 &lt;b&gt;同算法的检测结果对比&lt;/b&gt;"><b>表</b>3 <b>同算法的检测结果对比</b></a></li>
                                                <li><a href="#87" data-title="&lt;b&gt;图&lt;/b&gt;6 &lt;b&gt;不同算法检测结果&lt;/b&gt;"><b>图</b>6 <b>不同算法检测结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="2">


                                    <a id="bibliography_1" title="LI F,MAO Q,CHANG C C.Reversible data hiding scheme based on the Haar discrete wavelet transform and interleaving prediction method[J].Multimedia Tools &amp;amp; Applications,2017(8):1-20." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reversible data hiding scheme based on the Haar discrete wavelet transform and interleaving prediction method">
                                        <b>[1]</b>
                                        LI F,MAO Q,CHANG C C.Reversible data hiding scheme based on the Haar discrete wavelet transform and interleaving prediction method[J].Multimedia Tools &amp;amp; Applications,2017(8):1-20.
                                    </a>
                                </li>
                                <li id="4">


                                    <a id="bibliography_2" title="ZHANG H,HAN J,GUAN Y,et al.A SIFT algorithm based on DOG operator[C]// International Conference on Intelligent Transportation,2018:609-612." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A SIFT algorithm based on DOG operator">
                                        <b>[2]</b>
                                        ZHANG H,HAN J,GUAN Y,et al.A SIFT algorithm based on DOG operator[C]// International Conference on Intelligent Transportation,2018:609-612.
                                    </a>
                                </li>
                                <li id="6">


                                    <a id="bibliography_3" title="&lt;image href=&quot;images/CDDJ201903007_008.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt; J,HAGARA M.One-shot-learning gesture recognition using HOG-HOF features[J].Journal of Machine Learning Research,2017,15(1):2513-2532." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=One-Shot-Learning Gesture Recognition Using HOG-HOF Features">
                                        <b>[3]</b>
                                        &lt;image href=&quot;images/CDDJ201903007_008.jpg&quot; type=&quot;&quot; display=&quot;inline&quot; placement=&quot;inline&quot;&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt; J,HAGARA M.One-shot-learning gesture recognition using HOG-HOF features[J].Journal of Machine Learning Research,2017,15(1):2513-2532.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title="ZHANG C,PAN X,LI H,et al.A hybrid MLP-CNN classifier for very fine resolution remotely sensed image classification[J].Isprs Journal of Photogrammetry &amp;amp; Remote Sensing,2018(140):133-144." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD1779EBFFD47F5DA9047BC1473922097&amp;v=MDYyMzNmT0dRbGZCckxVMDV0Qmh3cnkrd2FrPU5pZk9mY2U1R2RiRjJ2MHpFcDhMQ3dvOHUyY2E2anQ2T2d6anFCVTJjTENXUmJPWUNPTnZGU2lXV3I3SklGcG1hQnVIWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                        ZHANG C,PAN X,LI H,et al.A hybrid MLP-CNN classifier for very fine resolution remotely sensed image classification[J].Isprs Journal of Photogrammetry &amp;amp; Remote Sensing,2018(140):133-144.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title="WU J,YANG H.Linear regression-based efficient SVM learning for large-scale classification[J].IEEE Transactions on Neural Networks &amp;amp; Learning Systems,2017,26(10):2357-2369." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Linear Regression-Based Efficient SVM Learning for Large-Scale Classification">
                                        <b>[5]</b>
                                        WU J,YANG H.Linear regression-based efficient SVM learning for large-scale classification[J].IEEE Transactions on Neural Networks &amp;amp; Learning Systems,2017,26(10):2357-2369.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title="MIN H,LUO X.Calibration of soft sensor by using Just-in-time modeling and AdaBoost learning method[J].Chinese Journal of Chemical Engineering,2016,24(8):1038-1046." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHGC201608013&amp;v=MjIxNzVxcUJ0R0ZyQ1VSN3FmWnVabUZ5N2hVcjdKUHlYTWJiRzRIOWZNcDQ5RVo0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        MIN H,LUO X.Calibration of soft sensor by using Just-in-time modeling and AdaBoost learning method[J].Chinese Journal of Chemical Engineering,2016,24(8):1038-1046.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title="LIU W,ANGUELOV D,ERHAN D,et al.SSD:single shot multi box detector[C]// European Conference on Computer Vision,2016:159-164." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;SSD:Single Shot Multi Box Detector,&amp;quot;">
                                        <b>[7]</b>
                                        LIU W,ANGUELOV D,ERHAN D,et al.SSD:single shot multi box detector[C]// European Conference on Computer Vision,2016:159-164.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                    REN S,HE K,GIRSHICK R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]// International Conference on Neural Information Processing Systems,2015:91-99.</a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title="常海涛,苟军年,李晓梅.Faster R-CNN在工业CT图像缺陷检测中的应用[J].中国图象图形学报,2018,23(7):129-139." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201807013&amp;v=MjIyMTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5N2hVcjdKUHlyZmJMRzRIOW5NcUk5RVo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        常海涛,苟军年,李晓梅.Faster R-CNN在工业CT图像缺陷检测中的应用[J].中国图象图形学报,2018,23(7):129-139.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title="孙晖,孙锡柯,孙燕,等.基于改进SSD模型的热镀锌板表面缺陷在线检测系统[J].电子技术,2018,47(12):112-115." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJS201812032&amp;v=MDk0ODFUZkJmYkc0SDluTnJZOUdab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1Wm1GeTdoVXI3Skk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        孙晖,孙锡柯,孙燕,等.基于改进SSD模型的热镀锌板表面缺陷在线检测系统[J].电子技术,2018,47(12):112-115.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title="李明,景军锋,李鹏飞.应用GAN和Faster R-CNN的色织物缺陷识别[J].西安工程大学学报,2018,32(6):44-50." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XBFZ201806008&amp;v=MDM4NDZHNEg5bk1xWTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnk3aFVyN0pQUy9OZEw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        李明,景军锋,李鹏飞.应用GAN和Faster R-CNN的色织物缺陷识别[J].西安工程大学学报,2018,32(6):44-50.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title="GOODFELLOW I J,POUGET-ABADIE J,MIRZA M,et al.Generative adversarial nets[C]// International Conference on Neural Information Processing Systems,2014:2672-2680." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">
                                        <b>[12]</b>
                                        GOODFELLOW I J,POUGET-ABADIE J,MIRZA M,et al.Generative adversarial nets[C]// International Conference on Neural Information Processing Systems,2014:2672-2680.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title="REDMON J,FARHADI A .YOLOv3:an incremental improvement[J].2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=YOLOv3:an incremental improvement">
                                        <b>[13]</b>
                                        REDMON J,FARHADI A .YOLOv3:an incremental improvement[J].2018.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title="HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C]// IEEE Conference on Computer Vision and Pattern Recognition(CVPR),2016:770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">
                                        <b>[14]</b>
                                        HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C]// IEEE Conference on Computer Vision and Pattern Recognition(CVPR),2016:770-778.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                    REDMON J,FAHADI A.YOLO9000:better,faster,stronger[C]// 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017:6517-6525.</a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title="DAY M J,HORZINEK M C,SCHULTZ R D.Guidelines for the vaccination of dogs and cats.compiled by the vaccination guidelines group (VGG) of the world small animal veterinary association (WSAVA) [J].Journal of Small Animal Practice,2007,48(9):528-41." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00000942492&amp;v=MjA0ODZPNEh0SE1wb3RIWU9JTlkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1RmlEbFZidkpJVjg9TmlmY2Fy&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                        DAY M J,HORZINEK M C,SCHULTZ R D.Guidelines for the vaccination of dogs and cats.compiled by the vaccination guidelines group (VGG) of the world small animal veterinary association (WSAVA) [J].Journal of Small Animal Practice,2007,48(9):528-41.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title="LIN T Y,DOLL&#193;R,PIOTR,et al.Feature pyramid networks for object detection[J/OL].(2017-04-19) [2019-03-21].https://arxiv.org/abs/1612.03144.DOI:10.1109/CVPR,2017:106." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Feature pyramid networks for object detection.&amp;quot;">
                                        <b>[17]</b>
                                        LIN T Y,DOLL&#193;R,PIOTR,et al.Feature pyramid networks for object detection[J/OL].(2017-04-19) [2019-03-21].https://arxiv.org/abs/1612.03144.DOI:10.1109/CVPR,2017:106.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=CDDJ" target="_blank">成都工业学院学报</a>
                2019,22(03),25-30 DOI:10.13542/j.cnki.51-1747/tn.2019.03.006            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于YOLOv3的磁瓦表面缺陷检测算法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E9%BE%99%E6%BA%90&amp;code=14715730&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭龙源</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%AB%A5%E5%85%89%E7%BA%A2&amp;code=42875699&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">童光红</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AE%B5%E5%8E%9A%E8%A3%95&amp;code=42875700&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">段厚裕</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%9E%97&amp;code=10960238&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵林</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%AD%A6%E5%8A%B2&amp;code=41883430&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李武劲</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%AC%A7%E5%85%88%E9%94%8B&amp;code=35755892&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">欧先锋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%99%8F%E9%B9%8F%E7%A8%8B&amp;code=37870985&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">晏鹏程</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E4%B8%80%E9%B8%A3&amp;code=40809524&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张一鸣</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B9%96%E5%8D%97%E7%90%86%E5%B7%A5%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0042180&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">湖南理工学院信息科学与工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E5%8F%8A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器视觉及人工智能研究中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>由于磁瓦缺陷本身对比度、不同缺陷特征不尽相同等原因,传统缺陷检测算法检测效果较差。针对不同缺陷特征的磁瓦缺陷检测的问题,提出了一种基于YOLOv3的磁瓦缺陷检测方法。YOLOv3借鉴Resnet的残差结构可以很轻松的构建更深的卷积网络,更深的网络可以更好地表达磁瓦缺陷的特征。同时其类似FPN的特征融合思想,可以较好地保证小缺陷样本不会出现特征丢失的情况。基于以上优点,YOLOv3很适合应用于缺陷检测。实验结果表明,该方法在检测效果上不差于基于Resnet101的Faster R-CNN的方法,而且其平均检测速度快5倍以上。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">缺陷检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">目标检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A3%81%E7%93%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">磁瓦;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郭龙源(1973—),男,教授,博士,研究方向:计算机视觉、图像处理。;
                                </span>
                                <span>
                                    *欧先锋(1983—),男,副教授,博士,研究方向:图像处理、视频压缩编码及传输,电子邮箱:ouxf@hnist.edu.cn。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-22</p>

                    <p>

                            <b>基金：</b>
                                                        <span>湖南省研究生科研创新项目资助(CX2018B779,CX2018B776);</span>
                                <span>湖南省教育厅优秀青年项目(18B345);</span>
                                <span>国家自然科学基金(51704115);</span>
                                <span>湖南省自然科学基金面上项目(2019JJ40104);</span>
                    </p>
            </div>
                    <h1><b>Research on Magnetic Tile Defect Detection Algorithm based on YOLOv</b>3</h1>
                    <h2>
                    <span>GUO Longyuan</span>
                    <span>TONG Guanghong</span>
                    <span>DUAN Houyu</span>
                    <span>ZHAO Lin</span>
                    <span>LI Wujing</span>
                    <span>OU Xianfeng</span>
                    <span>YAN Pengcheng</span>
                    <span>ZHANG Yiming</span>
            </h2>
                    <h2>
                    <span>College of Information Science and Engineering,Hunan Institute of Science and Technology</span>
                    <span>Machine Vision &amp; Artificial Intelligence Research Center,Hunan Institute of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The detection performance of traditional defect detection algorithm is poor due to the contrast of the magnetic tile defect and the different defect characteristics. Aiming at the problem of magnetic tile defect detection with different defect characteristics, a method for detecting magnetic tile defects based on YOLOv3 was proposed. YOLOv3 can easily build a deeper convolution network by using Resnet's residual structure. The deeper network can better express the characteristics of the magnetic tile defect. At the same time, it is similar to the FPN feature fusion idea, which can better guarantee the small defect sample. Based on the above, YOLOv3 is suitable for defect detection. The experimental results show that the method is not worse than the Faster R-CNN based on Resnet101, and its average detection speed is more than five times faster.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=defect%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">defect detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=target%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">target detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=magnetic%20tile&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">magnetic tile;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-04-22</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="37">缺陷检测是机器视觉领域中的一个重要研究方向。磁瓦作为汽车发动机中电机的重要组成部分,表面缺陷的存在将直接影响汽车发动机的寿命。所以在磁瓦生产过程中,必须对其进行表面缺陷检测。如何解决磁瓦缺陷检测的实时性以及由于磁瓦缺陷本身对比度低、缺陷小而造成检测难度大等问题,是缺陷检测的重点和难点。缺陷检测一般先依据工件的特性和现场的环境,选择相应的光源,通过打光测试选择合适的照明方法可以获得良好的图像。然后根据实际成像图片的缺陷特征来设计提取算法,其提取算法常用到的特征包括:Haar<citation id="90" type="reference"><link href="2" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、SIFT<citation id="91" type="reference"><link href="4" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、HOG<citation id="92" type="reference"><link href="6" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等;而其缺陷分类算法常用神经网络(MLP)<citation id="93" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、支持向量机(SVM)<citation id="94" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、Adaboost<citation id="95" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等。传统缺陷检测算法对于一类缺陷通过打光以及特定的算法设计,可以到达很好的检测效果。</p>
                </div>
                <div class="p1">
                    <p id="38">在本文中磁瓦缺陷对比度较低,而且不同缺陷对比度不尽相同,所以无法通过打光来突出缺陷特征;其次磁瓦不同缺陷间的特征不相同,设计对应的特征提取算法难度较大;最后传统分类算法较难学习到磁瓦缺陷的特征。近年来,随着深度学习的广泛应用,在目标检测领域取得了一系列成果,如SSD<citation id="96" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、Faster R-CNN<citation id="97" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等,同时在工业检测领域得到极大的应用。常海涛等<citation id="98" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>将Faster R-CNN应用到工业缺陷检测中通过预处理来修正预测框位置,取得较好的检测效果,孙晖等<citation id="99" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>通过改进SSD来实现在线检测表面缺陷,李明等<citation id="100" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>通过GAN<citation id="101" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>来扩容数据集,再通过Faster R-CNN来进行缺陷检测,一定程度上解决了工业数据集难收集等问题。基于以上研究,本文针对磁瓦缺陷的特征以及工业实时在线检测的要求,提出一种改进的YOLOv3<citation id="102" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>缺陷检测模型。</p>
                </div>
                <h3 id="39" name="39" class="anchor-tag">1 YOLOv3算法描述</h3>
                <h4 class="anchor-tag" id="40" name="40">1.1 YOLOv3的主体结构</h4>
                <h4 class="anchor-tag" id="41" name="41">1.1.1 YOLOv3特征提取网络</h4>
                <div class="p1">
                    <p id="42">对于卷积神经网络来说,特征提取设计是极其重要的。为了保留原图大部分信息,又能提取目标的大部分特征,YOLOv3在特征提取网络中采用了Darknet-53,整个网络中没有池化层和固定输出的连接层,基本上采用了完整的卷积层,而且图像输入在正向计算中,通过卷积层改变卷积核的步幅来实现尺寸变化。Darknet-53另一方面为了构建出更复杂的模型,引入了Resnet<citation id="103" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>的残差块结构,这个结构如图1所示,不同于YOLOv2<citation id="104" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>直接采用类似VGG<citation id="105" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的网络,采用Resnet的残参块设计,残差这种结构能保证网络结构在很深的情况下,仍能收敛,模型能训练下去;网络越深,表达的特征越好,分类+检测的效果都会提升;此外,利用网络中的残差思想,残差中的1*1卷积大大减少了每个卷积的信道,一方面减少了参数的数量,同时计算量也会减少到一定程度。因此相比较YOLOv2的19层设计,v3可以轻易设计53层的特征提取层,精度提升相比v2比较明显。Darknet-53中大部分层如图3所示等,res8表示含有8个残差结构,其结构如图2所示,其中DBL为卷积层+归一化层+激活层。</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CDDJ201903007_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Darknet-53残差结构图" src="Detail/GetImg?filename=images/CDDJ201903007_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>1 Darknet-53<b>残差结构图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CDDJ201903007_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="44">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CDDJ201903007_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Darknet-53中res结构图" src="Detail/GetImg?filename=images/CDDJ201903007_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>2 Darknet-53<b>中</b>res<b>结构图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CDDJ201903007_044.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="45" name="45">1.1.2 YOLOv3多尺度特征融合</h4>
                <div class="p1">
                    <p id="46">对于大多数卷积神经网络,通过特征提取层提取输入图像以获得最终特征图,然后在该特征图上直接预测。这样直接获取最后一层的热图,丢失了浅层的语义信息,这对小目标检测是不利。而且对于目标检测,输入图片可能存在不同尺寸的目标,不同目标之间存在不同的特征,我们需要利用浅层特征来区分小目标,利用深层特征来区分大目标。对于YOLOv3来说,每一次尺寸变化的特征图对后面目标区域预测都是有用的,所以YOLOv3借鉴了FPN<citation id="106" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>的多尺度特征融合的思路,将不同分辨率的特征图融合之后单独输出,分别进行目标预测。如图3主结构所示,它将darknet-53的中间层某一层和后面的某一层的上采样进行拼接,最后输出了3个不同尺度的热图,如图3中的y1,y2,y3,采用多尺度特征融合来对不同尺寸的目标进行分别检测,越精细的网格单元就可以检测出越精细的物体,极大改善YOLOv3在小目标检测方面的提升。</p>
                </div>
                <div class="area_img" id="47">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CDDJ201903007_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 YOLOv3主体结构图" src="Detail/GetImg?filename=images/CDDJ201903007_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>3 YOLOv3<b>主体结构图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CDDJ201903007_047.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="48" name="48">1.1.3 YOLOv3的类别预测</h4>
                <div class="p1">
                    <p id="49">YOLOv3在预测类别这方面用多标签分类替换了原先的单标签分类,因为在实际中一个目标或一张图片不可能只存在一个类别,例如数据集中有car和bus这两个类别,那么数据集一张图片中存在bus这个类,你实际检测的结果就必须要用bus和car这两个类别,这就是多标签分类。基于以上所述,YOLOv3将v2单标签分类的softmax层改进为可以通过多个标签分类的逻辑回归。这样YOLOv3在预测汽车这个类别时,还可以预测出汽车本身所属的子集。对于逻辑回归(logistic)层YOLOv3主要使用sigmoid函数,这个函数可以将特征层输出的结果约束到[0,1]的区间内,所以当一张图片经过darknet-53特征提取后,输出的结果继续经过sigmoid函数得到的小数如果大于设定阈值,则表示属于这个类,否则不属于。</p>
                </div>
                <div class="p1">
                    <p id="50">总的来说,YOLOv3借鉴了残差网络结构,形成更深的网络层次以及多尺度检测,提升了mAP以及小物体检测效果。在保证精度正确率的情况下,比Faster R-CNN快4～5倍以上。</p>
                </div>
                <h4 class="anchor-tag" id="51" name="51">1.2 损失函数</h4>
                <div class="p1">
                    <p id="52">损失函数(loss function)是用来估量你模型的预测值与真实值的不一致程度,对于YOLOv3来说损失函数清晰的表达了预测框与真实框之间的差距。YOLOv3通过损失函数来不断训练减少这个差距,YOLOv3的损失函数在原文中作者没有明确提出其损失函数的公式。但是在目标检测任务中有几个关键信息是需要确定的:预测及区域置信度(confidence)。根据这4类信息,可以知道YOLOv3的损失函数由这4部分的损失函数组成,其定义可为:</p>
                </div>
                <div class="p1">
                    <p id="53"><i>Loss</i>=<i>L</i><sub><i>box</i></sub><sub>_</sub><sub><i>xy</i></sub>+<i>L</i><sub><i>box</i></sub><sub>_</sub><sub><i>wh</i></sub>+<i>L</i><sub><i>cls</i></sub>+<i>L</i><sub><i>conf</i></sub>      (1)</p>
                </div>
                <div class="p1">
                    <p id="54">其中:<i>L</i><sub><i>box</i></sub><sub>_</sub><sub><i>xy</i></sub>为锚框坐标(<i>x</i>,<i>y</i>)误差;<i>L</i><sub><i>box</i></sub><sub>_</sub><sub><i>wh</i></sub>为锚框长宽(<i>w</i>,<i>h</i>)误差;<i>L</i><sub><i>cls</i></sub>为分类损失;<i>L</i><sub><i>conf</i></sub>为区域置信度误差。</p>
                </div>
                <div class="p1">
                    <p id="55"><i>L</i><sub><i>box</i></sub><sub>_</sub><sub><i>xy</i></sub>=(<i>S</i>(<i>t</i><sub><i>x</i></sub>,<i>t</i><sub><i>y</i></sub>)+(<i>C</i><sub><i>x</i></sub>,<i>C</i><sub><i>y</i></sub>))/(<i>W</i>,<i>H</i>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="56">其中:<i>S</i>()是Sigmoid函数,<i>S</i>(<i>x</i>)=1/(1+e<sup>-</sup><sup><i>x</i></sup>);<i>C</i><sub><i>x</i></sub>,<i>C</i><sub><i>y</i></sub>是特征图中网格单元的左上角坐标;<i>t</i><sub><i>x</i></sub>,<i>t</i><sub><i>y</i></sub>为预测的坐标偏移值;<i>W</i>,<i>H</i>为特征图的输出尺度。</p>
                </div>
                <div class="p1">
                    <p id="57"><i>L</i><sub><i>box</i></sub><sub>_</sub><sub><i>wh</i></sub>=((<i>P</i><sub><i>w</i></sub>,<i>P</i><sub><i>h</i></sub>)*(<i>e</i><sup><i>t</i></sup><sub><sup><i>w</i></sup></sub>,<i>e</i><sup><i>t</i></sup><sub><sup><i>h</i></sup></sub>))/(<i>W</i>,<i>H</i>)      (3)</p>
                </div>
                <div class="p1">
                    <p id="58">其中:<i>P</i><sub><i>w</i></sub>,<i>P</i><sub><i>h</i></sub>是锚框的长度和宽度;<i>t</i><sub><i>w</i></sub>,<i>t</i><sub><i>h</i></sub>为锚框长度和宽度的偏移值。</p>
                </div>
                <div class="p1">
                    <p id="59"><i>L</i><sub><i>conf</i></sub>和<i>L</i><sub><i>cls</i></sub>是直接经过Sigmoid函数,例如用sigmoid将置信度压缩到[0,1]內,此时置信度不仅反映了该区域是否含有物体,还预测这个预测框中坐标的准确度。</p>
                </div>
                <h3 id="60" name="60" class="anchor-tag">2 基于YOLOv3的磁瓦缺陷检测</h3>
                <h4 class="anchor-tag" id="61" name="61">2.1 磁瓦数据集</h4>
                <div class="p1">
                    <p id="62">本文磁瓦数据集由实际磁瓦生产流水线上采集的图像,包含磁瓦常见的两种缺陷:裂纹、缺口。每类缺陷有1 200张494×648的单通道图像,共2 400张,将其按2∶1∶1均匀分成训练集、验证集以及测试集,部分缺陷图片如图4所示。</p>
                </div>
                <div class="area_img" id="63">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CDDJ201903007_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 数据集部分缺陷图" src="Detail/GetImg?filename=images/CDDJ201903007_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>4 <b>数据集部分缺陷图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CDDJ201903007_063.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="64" name="64">2.2 实验条件及训练过程</h4>
                <div class="p1">
                    <p id="65">本实验的硬件为英特尔i7-8700K六核十二线程CPU、英伟达GTX 1080Ti×2独立显卡(11 G显存)、16 G双通道内存和512 GB的三星860evo固态硬盘,windows 10操作系统。本文的对比实验Faster R-CNN、SSD和本文YOLOv3以及后期结果预处理都基于深度学习框架Mxnet1.5.0实现。</p>
                </div>
                <div class="p1">
                    <p id="66">在实际训练网络中,磁瓦缺陷有2类,所以将YOLOv3最后输出的全连接层数量设置为2,当这4层全连接层输出的置信度均小于设定阈值0.5时,表示磁瓦无缺陷,如果大于阈值前取最大置信度,对应全连接层输出为磁瓦缺陷类别。对于预测框重叠情况采用非极大性抑制(NMS),当预测框之间重叠度(重叠区域面积比例IOU)超过设定重叠阈值0.45,则丢弃此预测框,并使用随机梯度下降(SGD)微调YOLOv3的预训练模型。初始学习率设置0.001,并采用学习率衰减,每迭代200次,学习率衰减为初始学习率的0.1倍。在预测中,将YOLOv3视作端到端的分类网络,由逻辑回归层来得到输出结果。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67">2.3 本文算法评估指标</h4>
                <div class="p1">
                    <p id="68">为了定量评价磁瓦缺陷检测算法的性能,采用工业检测常用的正确率以及目标检测的mAP来评价。设<i>R</i><sub><i>CD</i></sub>表示正确的样本检测率,<i>N</i><sub><i>C</i></sub>表示正确识别某种类型的缺陷数,<i>N</i><sub><i>D</i></sub>表示错误识别的缺陷类别的数量,<i>I</i><sub><i>n</i></sub>表示预测框与真实标注框的交集,<i>U</i><sub><i>n</i></sub>表示预测框与真实标注框的并集。则mAP和<i>R</i><sub><i>CD</i></sub>可由式(4)(5)计算。</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><msub><mrow></mrow><mrow><mi>C</mi><mi>D</mi></mrow></msub><mo>=</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mi>C</mi></msub></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>C</mi></msub><mo>+</mo><mi>Ν</mi><msub><mrow></mrow><mi>D</mi></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext>m</mtext><mtext>A</mtext><mtext>Ρ</mtext><mo>=</mo><mfrac><mrow><mi>Ι</mi><msub><mrow></mrow><mi>n</mi></msub></mrow><mrow><mi>U</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h3 id="70" name="70" class="anchor-tag">3 磁瓦检测结果与分析</h3>
                <h4 class="anchor-tag" id="71" name="71">3.1 预处理图片</h4>
                <div class="p1">
                    <p id="72">图5 (a)是原图,(b)是(a)对应的灰度直方图,原图中只有一个缺口缺陷,占据原图尺寸很小,而且灰度值分布在一定区域内,缺陷和背景的灰度值主要在这个区域中,这对缺陷特征提取很不利;(c)是(a)经过预处理后的图像,(d)是(c)对应的灰度直方图。从图5可以得知,缺陷区域对比度有一定提升,而且直方图中一定数量的灰度值均匀分布到了其他区域,这样可以在提升缺陷区域对比度的同时,限制背景的区域的灰度值增幅。这样的预处理,对后面图片的缺陷检测是有利的。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CDDJ201903007_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 预处理图片" src="Detail/GetImg?filename=images/CDDJ201903007_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>5 <b>预处理图片</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CDDJ201903007_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="76" name="76">3.2 缺陷检测结果</h4>
                <div class="p1">
                    <p id="77">将YOLOv3训练后检测的结果和预处理后再检测的结果做比较,两种检测比较的预测框精度如表1、表2所示。</p>
                </div>
                <div class="area_img" id="78">
                    <p class="img_tit"><b>表</b>1 <b>预处理检测出的具体坐标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="78" border="1"><tr><td rowspan="2">缺陷</td><td rowspan="2">GT</td><td rowspan="2">未做预处理</td><td rowspan="2">GT尺寸/像素</td><td rowspan="2">缺陷尺寸/像素</td><td rowspan="2">AP</td></tr><tr></tr><tr><td rowspan="2"><br />裂纹1</td><td rowspan="2">[164,368,283,423]</td><td rowspan="2">[156,354,295,439]</td><td rowspan="2">119×55</td><td rowspan="2">139×85</td><td rowspan="2">0.56</td></tr><tr></tr><tr><td rowspan="2"><br />裂纹2</td><td rowspan="2">[369,198,412,290]</td><td rowspan="2">[372,198,408,294]</td><td rowspan="2">43×92</td><td rowspan="2">36×96</td><td rowspan="2">0.80</td></tr><tr></tr><tr><td rowspan="2"><br />裂纹3</td><td rowspan="2">[277,241,391,287]</td><td rowspan="2">[271,236,403,295]</td><td rowspan="2">114×46</td><td rowspan="2">132×59</td><td rowspan="2">0.68</td></tr><tr></tr><tr><td rowspan="2"><br />缺口1</td><td rowspan="2">[205,145,235,173]</td><td rowspan="2">[206,145,237,171]</td><td rowspan="2">30×28</td><td rowspan="2">31×26</td><td rowspan="2">0.85</td></tr><tr></tr><tr><td rowspan="2"><br />缺口2</td><td rowspan="2">[502,129,537,164]</td><td rowspan="2">[506,129,537,161]</td><td rowspan="2">35×35</td><td rowspan="2">31×32</td><td rowspan="2">0.81</td></tr><tr></tr><tr><td rowspan="2"><br />缺口3</td><td rowspan="2">[149,142,212,181]</td><td rowspan="2">[154,139,210,176]</td><td rowspan="2">63×39</td><td rowspan="2">56×37</td><td rowspan="2">0.73</td></tr><tr></tr><tr><td colspan="6"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="79">
                    <p class="img_tit"><b>表</b>2 <b>算法检测出的具体坐标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="79" border="1"><tr><td rowspan="2">缺陷</td><td rowspan="2">GT</td><td rowspan="2">未做预处理</td><td rowspan="2">GT尺寸/像素</td><td rowspan="2">缺陷尺寸/像素</td><td rowspan="2">AP</td></tr><tr></tr><tr><td rowspan="2"><br />裂纹1</td><td rowspan="2">[164,368,283,423]</td><td rowspan="2">[152,370,276,419]</td><td rowspan="2">119×55</td><td rowspan="2">124×49</td><td rowspan="2">0.77</td></tr><tr></tr><tr><td rowspan="2"><br />裂纹2</td><td rowspan="2">[369,198,412,290]</td><td rowspan="2">[368,198,410,297]</td><td rowspan="2">43×92</td><td rowspan="2">42×99</td><td rowspan="2">0.87</td></tr><tr></tr><tr><td rowspan="2"><br />裂纹3</td><td rowspan="2">[277,241,391,287]</td><td rowspan="2">[281,241,398,289]</td><td rowspan="2">114×46</td><td rowspan="2">127×48</td><td rowspan="2">0.87</td></tr><tr></tr><tr><td rowspan="2"><br />缺口1</td><td rowspan="2">[205,145,235,173]</td><td rowspan="2">[204,144,235,172]</td><td rowspan="2">30×28</td><td rowspan="2">31×28</td><td rowspan="2">0.91</td></tr><tr></tr><tr><td rowspan="2"><br />缺口2</td><td rowspan="2">[502,129,537,164]</td><td rowspan="2">[506,127,537,163]</td><td rowspan="2">35×35</td><td rowspan="2">31×36</td><td rowspan="2">0.82</td></tr><tr></tr><tr><td rowspan="2"><br />缺口3</td><td rowspan="2">[149,142,212,181]</td><td rowspan="2">[152,143,214,178]</td><td rowspan="2">63×39</td><td rowspan="2">62×35</td><td rowspan="2">0.83</td></tr><tr></tr><tr><td colspan="6"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="80">GT为标注的缺陷实际坐标(真值),表1未作预处理直接用YOLOv3检测的缺陷区域坐标值,表2预处理后再用YOLOv3检测的坐标值。其中,GT尺寸表示实际缺陷面积,缺陷尺寸为算法检测出的缺陷面积,AP表示算法检测出的区域与实际GT标注区域的交集与并集的比例。AP越大,检测区域和标签区域越重叠,表明算法越精确。从表1、表2可以看出,特别是裂纹缺陷的AP有较大提升,这说明缺陷与背景对比度过低,会影响最终的检测结果,通过预处理在增强缺陷对比度的同时,可以有效抑制背景的对比度。所以预处理图片后,可以帮助本文算法准确定位出缺陷区域。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81">3.3 不同算法检测结果对比</h4>
                <div class="p1">
                    <p id="82">为了验证该算法优于其他算法,本文与常用的缺陷检测算法Faster R-CNN和SSD等对比,从正确率、mAP以及检测时间等评估指标对比,其评估结果如表3所示。</p>
                </div>
                <div class="p1">
                    <p id="83">从表3可以得知,SSD虽然引入了尺度变换,网络不同层抽取不同尺度的特征做预测,缺少特征融合,不能将低层语义信息和高层语义信息结合,所以其正确率和mAP都要低于YOLOv3;本文Faster R-CNN的特征提取网络是基于Resnet101,更深层的网络对精度是有提升的。</p>
                </div>
                <div class="area_img" id="84">
                    <p class="img_tit"><b>表</b>3 <b>同算法的检测结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="84" border="1"><tr><td rowspan="2"> 算法</td><td rowspan="2">裂纹正确率/%</td><td rowspan="2">缺口正确率/%</td><td rowspan="2">mAP</td><td rowspan="2">检测时间/ms</td></tr><tr></tr><tr><td rowspan="2"><br />本文算法</td><td rowspan="2">96.67</td><td rowspan="2">97.33</td><td rowspan="2">0.92</td><td rowspan="2">0.03</td></tr><tr></tr><tr><td rowspan="2"><br />Faster R-CNN</td><td rowspan="2">97.33</td><td rowspan="2">98.00</td><td rowspan="2">0.91</td><td rowspan="2">0.15</td></tr><tr></tr><tr><td rowspan="2"><br />SSD</td><td rowspan="2">94.33</td><td rowspan="2">92.67</td><td rowspan="2">0.85</td><td rowspan="2">0.04</td></tr><tr></tr><tr><td colspan="5"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="85">表3中,YoLOv3在与Faster R-CNN相差不多的正确率和mAP的情况下,其检测速度比它快5倍以上,检测时间对工业检测来说是极其重要的,所以相对于Faster R-CNN,YoLOv3更具实际使用价值。</p>
                </div>
                <div class="p1">
                    <p id="86">本文部分测试集中磁瓦检测结果如图6所示,其中对于裂纹缺陷SSD有较好的检测效果,但是对于小目标的缺口缺陷,例如缺口2,SSD出现误检,将缺口缺陷检测成良品,本文SSD的特征提取忽视低层语义信息,导致小缺口在经过特征提取网络后出现特征丢失的情况。结合表3和图6,Faster R-CNN和YOLOv3对实际磁瓦缺陷图片,无论是缺陷位置的定位以及缺陷的正确率结果都比较好,特别是YOLOv3的平均检测时间只需要0.03 ms,这对工业检测极为有利,所以这些特点使YOLOv3能够较好的解决磁瓦的在线缺陷检测。</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/CDDJ201903007_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法检测结果" src="Detail/GetImg?filename=images/CDDJ201903007_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图</b>6 <b>不同算法检测结果</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/CDDJ201903007_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="88" name="88" class="anchor-tag">4 结论</h3>
                <div class="p1">
                    <p id="89">本文讨论了磁瓦缺陷检测中的正确率以及检测时间等工业评估指标,还计算了目标定位准确度的mAP以及部分图片的坐标位置的评估指标。本文提出了在YOLOv3的检测结果上,增加预处理的磁瓦缺陷检测算法,利用类似FPN的特征融合较好地保证了小缺陷、较低对比度缺陷的特征信息的提取,一定程度上改善了检测算法对小目标缺陷的检测效果。总的来说,该算法可以快速实现缺陷位置的定位和缺陷类别的分类,同时保证磁瓦缺陷的检测效果。目前,本文算法只实现了缺陷位置的定位以及缺陷的分类,在接下来的研究中,希望能够借助一些新的网络应用到实际缺陷检测,实现缺陷分割,并且进一步提高缺陷检测的正确率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="2">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reversible data hiding scheme based on the Haar discrete wavelet transform and interleaving prediction method">

                                <b>[1]</b>LI F,MAO Q,CHANG C C.Reversible data hiding scheme based on the Haar discrete wavelet transform and interleaving prediction method[J].Multimedia Tools &amp; Applications,2017(8):1-20.
                            </a>
                        </p>
                        <p id="4">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A SIFT algorithm based on DOG operator">

                                <b>[2]</b>ZHANG H,HAN J,GUAN Y,et al.A SIFT algorithm based on DOG operator[C]// International Conference on Intelligent Transportation,2018:609-612.
                            </a>
                        </p>
                        <p id="6">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=One-Shot-Learning Gesture Recognition Using HOG-HOF Features">

                                <b>[3]</b><image href="images/CDDJ201903007_008.jpg" type="" display="inline" placement="inline"><alt></alt></image> J,HAGARA M.One-shot-learning gesture recognition using HOG-HOF features[J].Journal of Machine Learning Research,2017,15(1):2513-2532.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD1779EBFFD47F5DA9047BC1473922097&amp;v=MjI2NzNMQ1dSYk9ZQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dEJod3J5K3dhaz1OaWZPZmNlNUdkYkYydjB6RXA4TEN3bzh1MmNhNmp0Nk9nempxQlUyYw==&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b>ZHANG C,PAN X,LI H,et al.A hybrid MLP-CNN classifier for very fine resolution remotely sensed image classification[J].Isprs Journal of Photogrammetry &amp; Remote Sensing,2018(140):133-144.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Linear Regression-Based Efficient SVM Learning for Large-Scale Classification">

                                <b>[5]</b>WU J,YANG H.Linear regression-based efficient SVM learning for large-scale classification[J].IEEE Transactions on Neural Networks &amp; Learning Systems,2017,26(10):2357-2369.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZHGC201608013&amp;v=MTcxNTQ3aFVyN0pQeVhNYmJHNEg5Zk1wNDlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>MIN H,LUO X.Calibration of soft sensor by using Just-in-time modeling and AdaBoost learning method[J].Chinese Journal of Chemical Engineering,2016,24(8):1038-1046.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;SSD:Single Shot Multi Box Detector,&amp;quot;">

                                <b>[7]</b>LIU W,ANGUELOV D,ERHAN D,et al.SSD:single shot multi box detector[C]// European Conference on Computer Vision,2016:159-164.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                REN S,HE K,GIRSHICK R,et al.Faster R-CNN:towards real-time object detection with region proposal networks[C]// International Conference on Neural Information Processing Systems,2015:91-99.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201807013&amp;v=MDA4NzJPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5N2hVcjdKUHlyZmJMRzRIOW5NcUk5RVo0UUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>常海涛,苟军年,李晓梅.Faster R-CNN在工业CT图像缺陷检测中的应用[J].中国图象图形学报,2018,23(7):129-139.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZJS201812032&amp;v=MjQzNzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVptRnk3aFVyN0pJVGZCZmJHNEg5bk5yWTlHWm8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>孙晖,孙锡柯,孙燕,等.基于改进SSD模型的热镀锌板表面缺陷在线检测系统[J].电子技术,2018,47(12):112-115.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XBFZ201806008&amp;v=MjQ2MTQ5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVabUZ5N2hVcjdKUFMvTmRMRzRIOW5NcVk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>李明,景军锋,李鹏飞.应用GAN和Faster R-CNN的色织物缺陷识别[J].西安工程大学学报,2018,32(6):44-50.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative adversarial nets">

                                <b>[12]</b>GOODFELLOW I J,POUGET-ABADIE J,MIRZA M,et al.Generative adversarial nets[C]// International Conference on Neural Information Processing Systems,2014:2672-2680.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=YOLOv3:an incremental improvement">

                                <b>[13]</b>REDMON J,FARHADI A .YOLOv3:an incremental improvement[J].2018.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition">

                                <b>[14]</b>HE K,ZHANG X,REN S,et al.Deep residual learning for image recognition[C]// IEEE Conference on Computer Vision and Pattern Recognition(CVPR),2016:770-778.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                REDMON J,FAHADI A.YOLO9000:better,faster,stronger[C]// 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017:6517-6525.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00000942492&amp;v=MDc2NTV4Y01IN1I3cWRaK1p1RmlEbFZidkpJVjg9TmlmY2FyTzRIdEhNcG90SFlPSU5ZM2s1ekJkaDRqOTlTWHFScnhv&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b>DAY M J,HORZINEK M C,SCHULTZ R D.Guidelines for the vaccination of dogs and cats.compiled by the vaccination guidelines group (VGG) of the world small animal veterinary association (WSAVA) [J].Journal of Small Animal Practice,2007,48(9):528-41.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Feature pyramid networks for object detection.&amp;quot;">

                                <b>[17]</b>LIN T Y,DOLLÁR,PIOTR,et al.Feature pyramid networks for object detection[J/OL].(2017-04-19) [2019-03-21].https://arxiv.org/abs/1612.03144.DOI:10.1109/CVPR,2017:106.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="CDDJ201903007" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CDDJ201903007&amp;v=MDg5NzR6cXFCdEdGckNVUjdxZlp1Wm1GeTdoVXI3SkppblBaTEc0SDlqTXJJOUZZNFFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDM0Lyt6WGRicHQzdFV6dG0zODBDdz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=842_VlRz_g1CMCLi-M0twVw-4EOFG_noWyi_OsMnrAg1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
