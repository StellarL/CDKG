<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131445501123750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201904012%26RESULT%3d1%26SIGN%3dy3EajF07GIUE8zU6mMqCdg7adyc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201904012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201904012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201904012&amp;v=MDIyNjdlWmVSbkZ5emdVTDNKS0Q3WWJMRzRIOWpNcTQ5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#71" data-title="1 基于字符级表示的截断式循环神经网络模型 ">1 基于字符级表示的截断式循环神经网络模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="&lt;b&gt;1.1&lt;/b&gt; 字符特征表示层"><b>1.1</b> 字符特征表示层</a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;1.2&lt;/b&gt; 截断式循环神经网络层"><b>1.2</b> 截断式循环神经网络层</a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;1.3&lt;/b&gt; 全连接层"><b>1.3</b> 全连接层</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#106" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#107" data-title="&lt;b&gt;2.1&lt;/b&gt; 实验数据"><b>2.1</b> 实验数据</a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;2.2&lt;/b&gt; 评估指标及对比方法"><b>2.2</b> 评估指标及对比方法</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;2.3&lt;/b&gt; 优化方法"><b>2.3</b> 优化方法</a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;2.4&lt;/b&gt; 各方法结果对比"><b>2.4</b> 各方法结果对比</a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;2.5&lt;/b&gt; 滑动窗口大小对模型的影响"><b>2.5</b> 滑动窗口大小对模型的影响</a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;2.6&lt;/b&gt; 样例分析"><b>2.6</b> 样例分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#139" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#76" data-title="图1 CDRNN整体模型结构图">图1 CDRNN整体模型结构图</a></li>
                                                <li><a href="#90" data-title="图2 Skip-gram模型的工作原理图">图2 Skip-gram模型的工作原理图</a></li>
                                                <li><a href="#96" data-title="图3 CDRNN内部结构图">图3 CDRNN内部结构图</a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;表1 数据集统计情况&lt;/b&gt;"><b>表1 数据集统计情况</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;表2 各方法在2个数据集上的分类预测结果&lt;/b&gt;"><b>表2 各方法在2个数据集上的分类预测结果</b></a></li>
                                                <li><a href="#133" data-title="图4 不同窗口大小对模型性能的影响">图4 不同窗口大小对模型性能的影响</a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;表3 4种模型对2个数据样例的预测结果&lt;/b&gt;"><b>表3 4种模型对2个数据样例的预测结果</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" LIU W, RUTHS D.What′s in a Name?Using First Names as Features for Gender Inference in Twitter // Proc of the AAAI Spring Symposium:Analyzing Microtext.Palo Alto, USA:AAAI Press, 2013:10-16." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=What&amp;#39;&amp;#39;s in a name?Using first names as features for gender inference in Tw itter">
                                        <b>[1]</b>
                                         LIU W, RUTHS D.What′s in a Name?Using First Names as Features for Gender Inference in Twitter // Proc of the AAAI Spring Symposium:Analyzing Microtext.Palo Alto, USA:AAAI Press, 2013:10-16.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" KARIMI F, WAGNER C, LEMMERICH F, &lt;i&gt;et al&lt;/i&gt;.Inferring Gender from Names on the Web:A Comparative Evaluation of Gender Detection Methods // Proc of the 25th International Conference Companion on World Wide Web.New York, USA:ACM, 2016:53-54." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Inferring Gender from Names on the Web:A Comparative Evaluation of Gender Detection Methods">
                                        <b>[2]</b>
                                         KARIMI F, WAGNER C, LEMMERICH F, &lt;i&gt;et al&lt;/i&gt;.Inferring Gender from Names on the Web:A Comparative Evaluation of Gender Detection Methods // Proc of the 25th International Conference Companion on World Wide Web.New York, USA:ACM, 2016:53-54.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" WOOD-DOUGHTY Z, ANDREWS N, MARVIN R, &lt;i&gt;et al&lt;/i&gt;.Predicting Twitter User Demographics from Names Alone // Proc of the 2nd Workshop on Computational Modeling of People′s Opinions, Personality, and Emotions in Social Media.Stroudsburg, USA:ACL, 2018:105-111." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting Twitter User Demographics from Names Alone">
                                        <b>[3]</b>
                                         WOOD-DOUGHTY Z, ANDREWS N, MARVIN R, &lt;i&gt;et al&lt;/i&gt;.Predicting Twitter User Demographics from Names Alone // Proc of the 2nd Workshop on Computational Modeling of People′s Opinions, Personality, and Emotions in Social Media.Stroudsburg, USA:ACL, 2018:105-111.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" AMBEKAR A, WARD C, MOHAMMED J, &lt;i&gt;et al&lt;/i&gt;.Name-Ethnicity Classification from Open Sources // Proc of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2009:49-58." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Name-Ethnicity Classification from Open Sources">
                                        <b>[4]</b>
                                         AMBEKAR A, WARD C, MOHAMMED J, &lt;i&gt;et al&lt;/i&gt;.Name-Ethnicity Classification from Open Sources // Proc of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2009:49-58.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" CHANG J, ROSENN I, BACKSTROM L, &lt;i&gt;et al&lt;/i&gt;.Epluribus:Ethni-city on Social Networks // Proc of the 4th International Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2010:18-25." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Epluribus:Ethni-city on Social Networks">
                                        <b>[5]</b>
                                         CHANG J, ROSENN I, BACKSTROM L, &lt;i&gt;et al&lt;/i&gt;.Epluribus:Ethni-city on Social Networks // Proc of the 4th International Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2010:18-25.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" MISLOVE A, LEHMANN S, AHN Y Y, &lt;i&gt;et al&lt;/i&gt;.Understanding the Demographics of Twitter Users // Proc of the 5th International AAAI Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2012:554-557." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Understanding the Demographics of Twitter Users">
                                        <b>[6]</b>
                                         MISLOVE A, LEHMANN S, AHN Y Y, &lt;i&gt;et al&lt;/i&gt;.Understanding the Demographics of Twitter Users // Proc of the 5th International AAAI Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2012:554-557.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" TREERATPITUK P, GILES C L.Name-Ethnicity Classification and Ethnicity-Sensitive Name Matching // Proc of the 26th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2012:1141-1147." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Name-Ethnicity Classification and Ethnicity-Sensitive Name Matching">
                                        <b>[7]</b>
                                         TREERATPITUK P, GILES C L.Name-Ethnicity Classification and Ethnicity-Sensitive Name Matching // Proc of the 26th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2012:1141-1147.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" ANDREW H J.What′s in a Name?A Method for Extracting Information about Ethnicity from Names.Political Analysis, 2015, 23 (2) :212-224." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=What′s in a Name?A Method for Extracting Information about Ethnicity from Names">
                                        <b>[8]</b>
                                         ANDREW H J.What′s in a Name?A Method for Extracting Information about Ethnicity from Names.Political Analysis, 2015, 23 (2) :212-224.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" BERGSMA S, DREDZE M, VAN DURME B, &lt;i&gt;et al&lt;/i&gt;.Broadly Improving User Classification via Communication-Based Name and Location Clustering on Twitter // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, USA:ACL, 2013:1010-1019." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Broadly Improving User Classification via Communication-Based Name and Location Clustering on Twitter">
                                        <b>[9]</b>
                                         BERGSMA S, DREDZE M, VAN DURME B, &lt;i&gt;et al&lt;/i&gt;.Broadly Improving User Classification via Communication-Based Name and Location Clustering on Twitter // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, USA:ACL, 2013:1010-1019.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" HUANG W Y, WEBER I, VIEWEG S.Inferring Nationalities of Twitter Users and Studying International Linking // Proc of the 25th ACM Conference on Hypertext and Social Media.New York, USA:ACM, 2014:237-242." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Inferring nationalities of Twitter users and studying inter-national linking">
                                        <b>[10]</b>
                                         HUANG W Y, WEBER I, VIEWEG S.Inferring Nationalities of Twitter Users and Studying International Linking // Proc of the 25th ACM Conference on Hypertext and Social Media.New York, USA:ACM, 2014:237-242.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" PENNACCHIOTTI M, POPESCU A.A Machine Learning Approa-ch to Twitter User Classification // Proc of the 5th AAAI International Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2011:281-288." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A machine learning approach to twitter user classification">
                                        <b>[11]</b>
                                         PENNACCHIOTTI M, POPESCU A.A Machine Learning Approa-ch to Twitter User Classification // Proc of the 5th AAAI International Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2011:281-288.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" BHARGAVA A, KONDRAK G.Language Identification of Names with SVMs // Proc of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2010:693-696." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Language Identification of Names with SVMs">
                                        <b>[12]</b>
                                         BHARGAVA A, KONDRAK G.Language Identification of Names with SVMs // Proc of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2010:693-696.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" KRIZHEVSKY A, SUTSKEVER L, HINTON G E.ImageNet Cla-ssification with Deep Convolutional Neural Networks // PEREIRA F, BURGES C J C, BOTTOU L, &lt;i&gt;et al&lt;/i&gt;., eds.Advances in Neural Information Processing Systems 25.Cambridge, USA:The MIT Press, 2012:1106-1114." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[13]</b>
                                         KRIZHEVSKY A, SUTSKEVER L, HINTON G E.ImageNet Cla-ssification with Deep Convolutional Neural Networks // PEREIRA F, BURGES C J C, BOTTOU L, &lt;i&gt;et al&lt;/i&gt;., eds.Advances in Neural Information Processing Systems 25.Cambridge, USA:The MIT Press, 2012:1106-1114.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" SIMONYAN K, ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2018-02-14].https://arxiv.org/pdf/1409.1556.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL]">
                                        <b>[14]</b>
                                         SIMONYAN K, ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2018-02-14].https://arxiv.org/pdf/1409.1556.pdf.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" MIKOLOV T, CHEN K, CORRADO G, &lt;i&gt;et al&lt;/i&gt;.Efficient Estimation of Word Representations in Vector Space[C/OL].[2018-02-14].https://arxiv.org/pdf/1301.3781.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient estimation of word representations in vector space">
                                        <b>[15]</b>
                                         MIKOLOV T, CHEN K, CORRADO G, &lt;i&gt;et al&lt;/i&gt;.Efficient Estimation of Word Representations in Vector Space[C/OL].[2018-02-14].https://arxiv.org/pdf/1301.3781.pdf.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" PENNINGTON J, SOCHER R, MANNING C D.Glove:Global Vectors for Word Representation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1532-1543." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">
                                        <b>[16]</b>
                                         PENNINGTON J, SOCHER R, MANNING C D.Glove:Global Vectors for Word Representation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1532-1543.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     PEROZZI B, AL-RFOU R, SKIENA S.DeepWalk:Online Lear-ning of Social Representations // Proc of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, New York, USA:ACM, 2014:701-710.</a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" TANG J, MU M, WANG M Z, &lt;i&gt;et al&lt;/i&gt;.LINE:Large-Scale Information Network Embedding // Proc of the 24th International Confe-rence on World Wide Web.New York, USA:ACM, 2015:1067-1077." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LINE:large-scale information network embedding">
                                        <b>[18]</b>
                                         TANG J, MU M, WANG M Z, &lt;i&gt;et al&lt;/i&gt;.LINE:Large-Scale Information Network Embedding // Proc of the 24th International Confe-rence on World Wide Web.New York, USA:ACM, 2015:1067-1077.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" YE J T, HAN S C, HU Y F, &lt;i&gt;et al&lt;/i&gt;.Nationality Classification Using Name Embeddings // Proc of the ACM Conference on Information and Knowledge Management.New York, USA:ACM, 2017:1897-1906." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nationality Classification Using Name Embeddings">
                                        <b>[19]</b>
                                         YE J T, HAN S C, HU Y F, &lt;i&gt;et al&lt;/i&gt;.Nationality Classification Using Name Embeddings // Proc of the ACM Conference on Information and Knowledge Management.New York, USA:ACM, 2017:1897-1906.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" HOCHREITER S, SCHMIDHUBER J.Long Short-Term Memory.Neural Computation, 1997, 9 (8) .DOI:10.1162/neco.1997.9.8.1735." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MjU4MDA2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGc1hhQk09TmlmSlpiSzlIdGpNcW85RlpPb0xEWFV4b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         HOCHREITER S, SCHMIDHUBER J.Long Short-Term Memory.Neural Computation, 1997, 9 (8) .DOI:10.1162/neco.1997.9.8.1735.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" CHUNG J, GULCEHRE C, CHO K H, &lt;i&gt;et al&lt;/i&gt;.Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL].[2018-02-11].https://arxiv.org/pdf/1412.3555.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Empirical evaluation of gated recurrent neural networks on sequence modeling">
                                        <b>[21]</b>
                                         CHUNG J, GULCEHRE C, CHO K H, &lt;i&gt;et al&lt;/i&gt;.Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL].[2018-02-11].https://arxiv.org/pdf/1412.3555.pdf.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" LEE J, KIM H, KO M, &lt;i&gt;et al&lt;/i&gt;.Name Nationality Classification with Recurrent Neural Networks // Proc of the 26th International Joint Conference on Artificial Intelligence.Melbourne, Australia:IJCAI, 2017:2081-2087." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Name Nationality Classification with Recurrent Neural Networks">
                                        <b>[22]</b>
                                         LEE J, KIM H, KO M, &lt;i&gt;et al&lt;/i&gt;.Name Nationality Classification with Recurrent Neural Networks // Proc of the 26th International Joint Conference on Artificial Intelligence.Melbourne, Australia:IJCAI, 2017:2081-2087.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" WANG B X.Disconnected Recurrent Neural Networks for Text Categorization // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:2311-2320." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Disconnected Recurrent Neural Networks for Text Categorization">
                                        <b>[23]</b>
                                         WANG B X.Disconnected Recurrent Neural Networks for Text Categorization // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:2311-2320.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" KIM Y.Convolutional Neural Networks for Sentence Classification // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1746-1751." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">
                                        <b>[24]</b>
                                         KIM Y.Convolutional Neural Networks for Sentence Classification // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1746-1751.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(04),369-375 DOI:10.16451/j.cnki.issn1003-6059.201904010            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于字符级截断式循环神经网络的人名国籍识别</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E9%92%B0%E8%8E%8E&amp;code=36437240&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张钰莎</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%A4%BC%E6%98%8E&amp;code=41408863&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张礼明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%92%8B%E7%9B%9B%E7%9B%8A&amp;code=06844554&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蒋盛益</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B9%96%E5%8D%97%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=1699656&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">湖南信息学院电子信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E5%A4%96%E8%AF%AD%E5%A4%96%E8%B4%B8%E5%A4%A7%E5%AD%A6%E5%B9%BF%E5%B7%9E%E5%B8%82%E9%9D%9E%E9%80%9A%E7%94%A8%E8%AF%AD%E7%A7%8D%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0090875&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东外语外贸大学广州市非通用语种智能处理重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>人名是反映用户国籍的关键信息, 不同国籍的人名在结构和组成成分方面存在差异性和关联性.目前, 基于人名的国籍识别研究工作大部分将人名切分成多个独立的字符单元, 忽略字符间微妙的搭配和序列关系.针对上述问题, 文中提出基于字符级截断式循环神经网络的人名国籍识别模型, 将人名通过滑动窗口的方式截断成多个子序列, 利用长短期记忆单元模型学习不同子序列内部的字符组合关系, 通过平均池化操作聚合所有子序列信息, 获取最终的人名向量表示.最后根据该人名向量实现用户的国籍识别.截断式的子序列有利于模型更关注人名内部的细微差异.在Olympic运动员和Aminer学者数据集上的实验表明, 文中模型性能较优.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BD%E7%B1%8D%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国籍识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">用户画像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%97%E7%AC%A6%E7%BA%A7%E8%A1%A8%E7%A4%BA%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">字符级表示模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">循环神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张钰莎, 硕士, 副教授, 主要研究方向为数据挖掘、自然语言处理.E-mail:zys1982xx@163.com.;
                                </span>
                                <span>
                                    *张礼明 (通讯作者) , 硕士研究生, 主要研究方向为自然语言处理.E-mail:zhangliming134@foxmail.com.;
                                </span>
                                <span>
                                    蒋盛益, 博士, 教授, 主要研究方向为数据挖掘、自然语言处理.E-mail:jiangshengyi@163.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.61572145);</span>
                                <span>湖南省教育科学“十三五”规划课题 (No.XJK18CGD044) 资助;</span>
                    </p>
            </div>
                    <h1><b>Character-Based Disconnected Recurrent Neural Network for Name Nationality Identification</b></h1>
                    <h2>
                    <span>ZHANG Yusha</span>
                    <span>ZHANG Liming</span>
                    <span>JIANG Shengyi</span>
            </h2>
                    <h2>
                    <span>School of Electronic Information, Hunan Institute of Information Technology</span>
                    <span>Eastern Language Processing Center, Guangdong University of Foreign Studies</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Personal name is viewed as a strong indicator of inferring the nationality of the user. Generally, personal names reveal the differentiation and correlation of naming conventions among different nationalities. In the current research, personal name features are extracted by cutting off name strings into a set of independent n-gram units, while subtle relationships between characters are not explored. Therefore, a character-based disconnected recurrent neural network is proposed to capture subtle features among personal names in this paper. Concretely, a set of fragments is derived from name strings by order using a slice window. Then, long short-term memory units are utilized to learn information of each fragment, and they are aggregated via mean-pooling operation to obtain the whole name representation for nationalities prediction of users. Disconnected fragments enable model to focus on subtle features among different personal names. Experiments on Olympic dataset and Aminer dataset show that the proposed model outperforms the existing models and the performance is satisfactory.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nationality%20Identification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nationality Identification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=User%20Profiling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">User Profiling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Character%20Modeling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Character Modeling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Recurrent%20Neural%20Network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Recurrent Neural Network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHANG Yusha, master, associate professor. Her research interests include data mining and natural language processing.;
                                </span>
                                <span>
                                    ZHANG Liming ( Corresponding author) , master student. His research interests include natural language processing.;
                                </span>
                                <span>
                                    JIANG Shengyi, Ph.D, professor. His research interests include data mining and natural language processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-24</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.61572145);</span>
                                <span>The Thirteenth Five-Year Plan Project of Educational Science in Hunan Province (No.XJK18CGD044);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="65">信息化建设的不断发展促进个性化服务需求的不断增加, 用户画像 (User Profiling) 的需求也随之增大.用户画像的目标是将用户信息高度标签化.用户国籍识别作为用户画像中的一项子任务, 旨在利用用户内容数据识别国籍身份 (Nationality Identification) , 具有重要的现实意义, 既可用于生物学、社会学的相关研究, 也可用于市场营销、新闻推送、政治事件分析等实际场合.</p>
                </div>
                <div class="p1">
                    <p id="66">在用户国籍识别时人名起到关键作用, 它通常具有反映用户所处国家的特征信息.随着互联网的快速发展, 人们容易通过网络获取大量人名信息, 并在不同领域有所应用, 如用户性别预测<citation id="141" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>、种族识别<citation id="142" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>等.然而, 利用人名识别用户国籍具有一定困难.首先, 用户的国籍类别数一般较多, 远超过用户的性别类别数.其次, 不同国家的人名具有一定的关联性和差异性.有些国家所属人名较容易识别, 相反, 有些国家的人名较难区分, 这是由于不同国家的文化异同和历史发展因素综合造成的.</p>
                </div>
                <div class="p1">
                    <p id="67">目前, 基于人名判断国籍的研究相对较少, 许多研究融入额外的数据知识, 如社交关系<citation id="143" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、地理信息<citation id="144" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>和社交媒体内容<citation id="145" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>等.通常人名是由一组连续的字符组成, 大部分研究是将人名字符串切分成若干个独立的<i>n</i>-gram单元.Bhargava等<citation id="146" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>将人名特征以5-gram模型表示, 并通过实验发现SVM分类模型优于语言模型.但是, 由<i>n</i>-gram模型构建的特征表示为离散数值, 忽略人名字符之间的非线性关系.基于神经网络模型的表示因其可以捕捉对象之间的线性与非线性联系, 广泛应用于不同研究领域, 如图像识别<citation id="148" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>、自然语言处理<citation id="149" type="reference"><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>、复杂网络分析<citation id="150" type="reference"><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>等.Ye等<citation id="147" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>收集用户通话记录中约7 400万条人名, 认为与用户通话的人极可能具有相同国籍.因此, 将通信名单组成一个个句子, 以人名作为基本单元, 构建单词转换成向量 (Word to Vector, word2vec) 模型, 从而获取人名的向量表示, 忽略人名中字符级别的信息.</p>
                </div>
                <div class="p1">
                    <p id="68">实际上, 人名中不同字符的排列组合顺序蕴含大量有价值的信息.人名常由较短的字符串组成, 字符串中序列的长度和字母排列次序都反映用户所处国家的文化特性.较常见的做法是采用循环神经网络 (Recurrent Neural Network, RNN) 获取人名中字符序列信息, 如长短期记忆单元 (Long-Short Term Memory, LSTM) <citation id="151" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>和门控循环单元 (Gated Recurrent Unit, GRU) <citation id="152" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>等.Lee等<citation id="153" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>将人名切分成1-gram、2-gram和3-gram三组字符特征, 并分别输入到LSTM模型中, 获取3种不同的人名向量表示, 用于预测用户的国籍.然而, 虽然该方法能较好地记忆人名中的字符序列信息和长依赖关系, 但对整个序列进行建模时难以有效识别人名中一些微妙的特征.</p>
                </div>
                <div class="p1">
                    <p id="69">为了更有效地表示人名的序列信息并挖掘局部特征.本文采用改进截断式循环神经网络 (Disconnected RNN, DRNN) 模型<citation id="154" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>代替RNN.DRNN主要用于解决RNN单元在记忆长文本时难以捕捉关键词项信息的问题, 其采用窗口切片的形式截断文本, 缩短RNN的记忆负担, 然后通过最大池化 (Max-Pooling) 操作提取文本中的关键信息.</p>
                </div>
                <div class="p1">
                    <p id="70">因此, 本文提出基于字符级别的截断式循环神经网络模型 (Character-Based Disconnected RNN, CDRNN) , 根据人名识别用户的国籍信息.模型充分结合神经网络的优势, 有效捕捉用户中字符与字符之间的非线性关系, 并利用DRNN提取人名中局部的显微特征.针对人名国籍识别任务的特点, 采用平均池化 (Mean-Pooling) 操作替换原有的最大池化操作, 以及对截断序列的记忆信息取平均, 使模型最终输出的向量表示更丰富.在2个真实数据集 (奥林匹克运动员数据集、Aminer学者数据集) 上的实验结果表明本文模型的有效性.</p>
                </div>
                <h3 id="71" name="71" class="anchor-tag">1 基于字符级表示的截断式循环神经网络模型</h3>
                <div class="p1">
                    <p id="72">本文提出基于字符级表示的截断式循环神经网络 (CDRNN) 模型, 结构如图1所示, 主要由字符特征表示层、截断式循环神经网络层及全连接层构成.</p>
                </div>
                <div class="p1">
                    <p id="73">1) 字符特征表示层.主要将人名中的字符以向量形式输出.字符特征表示层由字符编码和字符向量组成.字符编码是将人名中出现的所有字符转变为离散的one-hot编码, 然后将字符编码与其对应的字符向量相乘, 得到字符特征向量表示.</p>
                </div>
                <div class="p1">
                    <p id="74">2) 截断式循环神经网络层.该网络层接收字符特征向量作为输入, 以固定的滑动窗口将人名字符序列截断成多个子序列, 然后将所得的连续片段输入到RNN记忆单元中获取子序列的向量表示, 最后采用平均池化操作得到总体的人名向量表示.</p>
                </div>
                <div class="p1">
                    <p id="75">3) 全连接层.接收截断式循环神经网络层的输出, 接入权重矩阵<b><i>W</i></b>和偏置项<i>b</i>, 以及softmax非线性函数, 将人名向量转变为不同国籍的概率分布向量, 根据概率的大小选择最可能的国籍.</p>
                </div>
                <div class="area_img" id="76">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904012_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 CDRNN整体模型结构图" src="Detail/GetImg?filename=images/MSSB201904012_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 CDRNN整体模型结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904012_076.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Overall architecture of CDRNN model</p>

                </div>
                <h4 class="anchor-tag" id="77" name="77"><b>1.1</b> 字符特征表示层</h4>
                <div class="p1">
                    <p id="78">字符特征表示将人名字符串</p>
                </div>
                <div class="p1">
                    <p id="79"><b><i>s</i></b>=[<i>x</i><sub>0</sub>, <i>x</i><sub>1</sub>, …, <i>x</i><sub><i>n</i>-1</sub>]</p>
                </div>
                <div class="p1">
                    <p id="80">中每个字符<i>x</i><sub><i>i</i></sub>以one-hot编码的形式表示为<i>v</i><sub><i>i</i></sub>, 然后利用矩阵-向量相乘的方法映射成对应的字符向量<b><i>c</i></b><sub><i>i</i></sub>=<b><i>W</i></b><sup><i>emb</i></sup><b><i>v</i></b><sub><i>i</i></sub>, 其中, <b><i>v</i></b><sub><i>i</i></sub>为one-hot表示的向量, 长度为<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">|</mo></mrow></math></mathml>, 矩阵<b><i>W</i></b><sup><i>emb</i></sup>为模型参数, 矩阵中的向量维度<i>d</i>为超参数.经映射后, 字符特征表示层生成一组字符向量序列</p>
                </div>
                <div class="p1">
                    <p id="82"><b><i>C</i></b>=[<i>c</i><sub>0</sub>, <i>c</i><sub>1</sub>, …, <i>c</i><sub><i>n</i>-1</sub>], </p>
                </div>
                <div class="p1">
                    <p id="83">作为模型下一层输入.</p>
                </div>
                <div class="p1">
                    <p id="84">对于<b><i>W</i></b><sup><i>emb</i></sup>的初始化, 目前有随机初始化和采用预先训练好的模型两种方式.本文采用word2vec<citation id="155" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>的模型对语料进行预训练, 获得低维的字符向量矩阵<b><i>W</i></b><sup><i>emb</i></sup>.</p>
                </div>
                <div class="p1">
                    <p id="85">word2vec分为CBOW (Continuous Bag-of-Words Model) 和Skip-gram (Continuous Skip-Gram Model) 两种不同训练模型.CBOW模型利用上下文预测当前词, 而Skip-gram模型根据当前词预测上下文.本文采用Skip-gram模型训练字向量.图2为Skip-gram的工作原理, 以人名中当前字符向量<b><i>c</i></b><sub><i>i</i></sub>作为输入, 投射到隐藏层, 进而预测<b><i>c</i></b><sub><i>i</i></sub>在固定窗口周围的字符向量的大小, 图2的窗口大小<i>m</i>=2.模型训练的目标函数为</p>
                </div>
                <div class="p1">
                    <p id="86"><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mi>s</mi><mi>k</mi><mi>i</mi><mi>p</mi><mo>-</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi></mrow></msub><mo>=</mo><mo>-</mo><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mstyle displaystyle="true"><munderover><mo>∏</mo><mtable columnalign="left"><mtr><mtd><mi>j</mi><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>j</mi><mo>≠</mo><mi>m</mi></mtd></mtr></mtable><mrow><mn>2</mn><mi>m</mi></mrow></munderover><mrow></mrow></mstyle><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mi>m</mi><mo>+</mo><mi>j</mi></mrow></msub><mo stretchy="false">|</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="88">其中, <i>m</i>为上下文窗口大小, <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mi>m</mi><mo>+</mo><mi>j</mi></mrow></msub><mo stretchy="false">|</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>为已知<b><i>c</i></b><sub><i>i</i></sub>的条件下, 出现<b><i>c</i></b><sub><i>i</i>-<i>m</i>+<i>j</i></sub>的概率估计.</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904012_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 Skip-gram模型的工作原理图" src="Detail/GetImg?filename=images/MSSB201904012_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 Skip-gram模型的工作原理图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904012_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Diagram of skip-gram model</p>

                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>1.2</b> 截断式循环神经网络层</h4>
                <div class="p1">
                    <p id="92">本文采用LSTM模型, 主要包括一个记忆单元 (Memory Cell) 和3个不同的门机制, 包括输入门 (Input Gate) 、遗忘门 (Forget Gate) 及输出门 (Out-put Gate) .LSTM模型的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>i</mi></msup><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mi>i</mi></msup><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mi>i</mi></msup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>o</mi></msup><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mi>o</mi></msup><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mi>o</mi></msup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mover accent="true"><mi mathvariant="bold-italic">c</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mi>c</mi></msup><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mi>c</mi></msup><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mi>c</mi></msup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mover accent="true"><mi mathvariant="bold-italic">m</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">其中, <b><i>c</i></b><sub><i>t</i></sub>表示第<i>t</i>步的字符向量输入, <b><i>i</i></b><sub><i>t</i></sub>、 <b><i>f</i></b><sub><i>t</i></sub>、<b><i>o</i></b><sub><i>t</i></sub>分别表示输入门、遗忘门、输出门, <b><i>m</i></b><sub><i>t</i></sub>表示记忆单元, <b><i>h</i></b><sub><i>t</i></sub>表示隐藏层状态, <b><i>W</i></b><sup>*</sup>、<b><i>U</i></b><sup>*</sup>、<b><i>b</i></b><sup>*</sup>均为模型参数.</p>
                </div>
                <div class="p1">
                    <p id="95">CDRNN神经网络针对RNN神经网络因长序列的记忆负担而难以捕获关键信息的问题, 将RNN记忆序列通过滑动窗口的形式截断成多个子序列, 形式类似于CNN<citation id="156" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>中的滑动操作.另外, 不同子序列中的LSTM单元参数共享.模型如图3所示, 假设滑动窗口大小为3, 步长为1, 首先得到子序列[<b><i>c</i></b><sub>0</sub>, <b><i>c</i></b><sub>1</sub>, <b><i>c</i></b><sub>2</sub>], 并将其输入到LSTM神经网络单元, 然后将隐藏层单元输出[<b><i>h</i></b><sub>0</sub>, <b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>].在文献<citation id="157" type="reference">[<a class="sup">23</a>]</citation>中, 子序列是以最后的隐藏层单元信息作为最终表示, 但其忽略其它隐藏层单元同样具有重要的信息, 因此本文采用平均池化操作, 将子序列中所有隐藏层取平均以得到子序列的向量表示.同样地, 获得[<b><i>c</i></b><sub>1</sub>, <b><i>c</i></b><sub>2</sub>, <b><i>c</i></b><sub>3</sub>], [<b><i>c</i></b><sub>2</sub>, <b><i>c</i></b><sub>3</sub>, <b><i>c</i></b><sub>4</sub>], [<b><i>c</i></b><sub>3</sub>, <b><i>c</i></b><sub>4</sub>, <b><i>c</i></b><sub>5</sub>], [<b><i>c</i></b><sub>4</sub>, <b><i>c</i></b><sub>5</sub>, <b><i>c</i></b><sub>6</sub>]等多个子序列的向量表示.最后, 对所有CDRNN子序列也进行平均池化操作, 得到整个人名字符序列的向量表示<b><i>v</i></b><sub><i>s</i></sub>, 作为本层的输出.</p>
                </div>
                <div class="area_img" id="96">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 CDRNN内部结构图" src="Detail/GetImg?filename=images/MSSB201904012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 CDRNN内部结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904012_096.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Inner structure of CDRNN</p>

                </div>
                <h4 class="anchor-tag" id="97" name="97"><b>1.3</b> 全连接层</h4>
                <div class="p1">
                    <p id="98">将上一层得到的人名向量<b><i>v</i></b><sub><i>s</i></sub>作为输入, 经过全连接层 (Fully-Connected) 压缩转换后, 最终转变成长度为<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>Y</mi><mo stretchy="false">|</mo></mrow></math></mathml>的向量.本文模型只用一层全连接层, 具体表示如下:</p>
                </div>
                <div class="p1">
                    <p id="100"><b><i>l</i></b>=<i>g</i> (<b><i>W</i></b><sub><i>l</i></sub><b><i>v</i></b><sub><i>s</i></sub>+<b><i>b</i></b><sub><i>l</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="101">其中, <i>g</i>为激活函数, <b><i>W</i></b><sub><i>l</i></sub>、<b><i>b</i></b><sub><i>l</i></sub>分别为模型参数.<b><i>l</i></b>为<b><i>v</i></b><sub><i>s</i></sub>经过全连接层映射后得到的结果, 且<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">l</mi><mo stretchy="false">|</mo><mo>=</mo><mo stretchy="false">|</mo><mi>Y</mi><mo stretchy="false">|</mo></mrow></math></mathml>, 表示不同国籍的个数.使用softmax函数作为激活函数<i>g</i>, 使用最大交叉熵优化模型, 损失函数为</p>
                </div>
                <div class="p1">
                    <p id="103"><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>Y</mi><mo stretchy="false">|</mo></mrow></munderover><mi>y</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mover accent="true"><mi>Y</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="105">其中, <i>N</i>表示训练样本的个数, <sub><i>ik</i></sub>表示模型预测的类别标签, <i>y</i><sub><i>ik</i></sub>表示训练样本中的真实标签.</p>
                </div>
                <h3 id="106" name="106" class="anchor-tag">2 实验及结果分析</h3>
                <h4 class="anchor-tag" id="107" name="107"><b>2.1</b> 实验数据</h4>
                <div class="p1">
                    <p id="108">为了验证模型的有效性, 本文采用2个真实生活的数据集:文献<citation id="158" type="reference">[<a class="sup">22</a>]</citation>提供的奥林匹克运动员数据集 (Olympic) 、在Aminer学者网站中收集到的学者数据集.</p>
                </div>
                <div class="p1">
                    <p id="109">奥林匹克运动员数据集来自于2008年的北京奥运会和2012年的伦敦奥运会中运动员名字及对应的国籍信息.整个数据集分两类:1) 未经清洗数据集 (Raw) 、2) 经过清洗后的数据集 (Cleaned) .</p>
                </div>
                <div class="p1">
                    <p id="110">Aminer数据集共收集1998年至2015年内的论文作者及其对应机构信息.通过对机构标注相应的国籍并进行清洗, 获得相应的〈人名, 国家〉对.为了确保数据分布均衡, 过滤人名频数低于20的国籍类别.具体数据统计信息见表1.</p>
                </div>
                <div class="p1">
                    <p id="111">2个数据集均存在国籍类别不均衡情况, 在奥林匹克数据集上, 运动员主要集中在发达国家, 但分布相对较均匀, 具有127个类别, 前20个国籍类别数据规模基本持平.原有的Aminer学者数据集上中美国籍人名占据主体, 两个国籍人名合计占比达50%, 本文采用下抽样方式, 使中美国籍人名数据与前10国籍数据规模基本持平.</p>
                </div>
                <div class="area_img" id="112">
                    <p class="img_tit"><b>表1 数据集统计情况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Statistics of dataset</p>
                    <p class="img_note"></p>
                    <table id="112" border="1"><tr><td rowspan="2"><br /></td><td colspan="2"><br />奥林匹克</td><td rowspan="2">Aminer<br />学者</td></tr><tr><td><br />raw</td><td>cleaned</td></tr><tr><td><br />训练集</td><td>10633</td><td>10592</td><td>138572</td></tr><tr><td><br />验证集</td><td>3545</td><td>3531</td><td>46191</td></tr><tr><td><br />测试集</td><td>3543</td><td>3530</td><td>46189</td></tr><tr><td><br />国籍类别</td><td>127</td><td>95</td><td>46</td></tr><tr><td><br />字符表大小</td><td>82</td><td>42</td><td>138</td></tr><tr><td><br />平均人名长度</td><td>15.3</td><td>19.8</td><td>21.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>2.2</b> 评估指标及对比方法</h4>
                <div class="p1">
                    <p id="114">本文按照文献<citation id="159" type="reference">[<a class="sup">22</a>]</citation>的方法, 采用精确率 (Accu-racy, acc) , topk精确率 (Accuracy Topk, acc@topk) 作为模型评估指标.具体计算如下:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>a</mi><mi>c</mi><mi>c</mi><mo>=</mo><mfrac><mtable columnalign="left"><mtr><mtd><mtext>预</mtext><mtext>测</mtext><mtext>与</mtext><mtext>真</mtext><mtext>实</mtext><mtext>标</mtext><mtext>签</mtext><mtext>匹</mtext><mtext>配</mtext><mtext>的</mtext><mtext>样</mtext><mtext>本</mtext><mtext>数</mtext></mtd></mtr><mtr><mtd></mtd></mtr></mtable><mrow><mtext>样</mtext><mtext>本</mtext><mtext>的</mtext><mtext>总</mtext><mtext>个</mtext><mtext>数</mtext></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi>a</mi><mi>c</mi><mi>c</mi><mo>@</mo><mi>t</mi><mi>o</mi><mi>p</mi><mi>k</mi><mo>=</mo><mfrac><mtable columnalign="left"><mtr><mtd><mtext>预</mtext><mtext>测</mtext><mtext>前</mtext><mi>k</mi><mtext>个</mtext><mtext>与</mtext><mtext>真</mtext><mtext>实</mtext><mtext>标</mtext><mtext>签</mtext><mtext>匹</mtext><mtext>配</mtext><mtext>的</mtext><mtext>样</mtext><mtext>本</mtext><mtext>数</mtext></mtd></mtr><mtr><mtd></mtd></mtr></mtable><mrow><mtext>样</mtext><mtext>本</mtext><mtext>的</mtext><mtext>总</mtext><mtext>个</mtext><mtext>数</mtext></mrow></mfrac><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">在奥林匹克数据集上<i>acc</i>@<i>topk</i>中的<i>k</i>=5.在Aminer学者数据集上, 由于国籍类别相对较少, <i>k</i>=3.</p>
                </div>
                <div class="p1">
                    <p id="117">对比方法如下.</p>
                </div>
                <div class="p1">
                    <p id="118">1) Multi_feature + MLR.Ambekar等<citation id="160" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>采用人工构造特征, 包括非ASCII字符统计特征、字符<i>n</i>-grams特征、双变音位<i>n</i>-grams特征 (Double Meta-phone) 、字符代码 (Soundex) 等.以多项式逻辑回归 (Multinomial Logistic Regression, MLR) 为分类器.</p>
                </div>
                <div class="p1">
                    <p id="119">2) Multi_CNN<citation id="161" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>.采用不同窗口的卷积核对人名字符向量进行特征抽取, 然后经过平均池化操作, 预测用户国籍, 窗口选择为{1, 2, 3}.</p>
                </div>
                <div class="p1">
                    <p id="120">3) LSTM.利用LSTM对人名字符串从首到尾进行编码.</p>
                </div>
                <div class="p1">
                    <p id="121">4) BiLSTM.使用双向LSTM (Bi-directional LSTM, BiLSTM) 模型对人名分别进行前向编码和后向编码, 然后拼接, 预测用户国籍.</p>
                </div>
                <div class="p1">
                    <p id="122">5) LSTM_ensemble<citation id="162" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.将人名分别拆分为1-gram、2-gram、3-gram连续序列, 输入到对应LSTM模型当中, 得到3种不同的人名向量表示, 然后拼接, 输出至全连接层.</p>
                </div>
                <div class="p1">
                    <p id="123">6) DRNN<citation id="163" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>.利用截断式神经网络模型, 将人名序列切分成多个子序列, 然后输出至全连接层.与文献<citation id="164" type="reference">[<a class="sup">23</a>]</citation>一致, 在截断式神经单元中使用最后的隐藏层作为子序列的表示, 采用最大池化操作得到人名向量表示.</p>
                </div>
                <h4 class="anchor-tag" id="124" name="124"><b>2.3</b> 优化方法</h4>
                <div class="p1">
                    <p id="125">本文采用TensorFlow框架, 模型参数设置如下.字符向量维度设为50, LSTM隐藏层维度设为200, 批处理大小 (Batch-Size) 设为100.在模型训练过程中, 使用Adam优化方法, 初始学习率设为0.001, 并采用学习率自衰减策略, 衰减率为0.99, 衰减步长为1 000.为了防止梯度爆炸情况, 采用梯度截断的方法, 设置为5.0.为了避免过拟合, 采用dropout策略, 设为0.5.对于预训练字符向量的word2vec模型, 将上下文窗口设为5, 迭代轮次设为10.在模型训练过程中, 对比动态更新预训练的字符向量与固定字符向量两种策略, 发现固定字符向量的效果优于动态更新的策略.</p>
                </div>
                <h4 class="anchor-tag" id="126" name="126"><b>2.4</b> 各方法结果对比</h4>
                <div class="p1">
                    <p id="127">表2给出CDRNN及其它方法的预测结果.从表中结果可看出, Multi_feature+MLR的效果明显差于其它基于神经网络的模型, 这反映神经网络模型可以有效捕获字符之间的非线性联系, 提升模型的识别效果.CNN整体上优于LSTM, 说明CNN能更有效地捕捉人名字符串中的关键区域信息.BiLSTM由于能对字符串进行前后向记忆, 丰富人名向量表达, 结果稍优于CNN.LSTM_ensemble是目前工作中最好的模型, 分别捕捉人名字符串中1-gram、2-gram、3-gram信息.由结果可见, LSTM_ensemble优于Multi_CNN、LSTM和BiLSTM.</p>
                </div>
                <div class="p1">
                    <p id="128">另外可以发现, 原有的DRNN直接应用到国籍预测时取得的效果较差, 只稍高于Multi_feature+MLR.而改进后的CDRNN达到所有数据集中最优结果, 相比LSTM_ensemble, CDRNN在Olympic (raw) 、Olympic (clean) 、Aminer数据集上的结果指标都具有明显提升, 分别在acc上提升2.0%, 3.8%, 1.5%, 在acc@topk上提升3.9%, 3.0%, 1.2%.这验证改进后的CDRNN能充分利用不同子序列中的字符组合信息, 在融合多个子序列过程中, 通过平均池化操作, 获取人名的全局信息, 使模型的性能达到最优.</p>
                </div>
                <div class="area_img" id="129">
                    <p class="img_tit"><b>表2 各方法在2个数据集上的分类预测结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Classification results of different methods on 2 datasets </p>
                    <p class="img_note">%</p>
                    <table id="129" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="2"><br />Olympic (raw) </td><td colspan="2"><br />Olympic (clean) </td><td colspan="2"><br />Aminer</td></tr><tr><td><br />acc</td><td>acc@<br />top5</td><td><br />acc</td><td>acc@<br />top5</td><td><br />acc</td><td>acc@<br />top3</td></tr><tr><td>Multi_feature<br />+MLR</td><td>44.1</td><td>74.8</td><td>49.3</td><td>78.2</td><td>57.1</td><td>70.7</td></tr><tr><td><br />Multi_CNN</td><td>49.5</td><td>79.7</td><td>49.7</td><td>80.5</td><td>59.9</td><td>77.2</td></tr><tr><td><br />LSTM</td><td>45.2</td><td>76.1</td><td>46.4</td><td>79.1</td><td>58.5</td><td>76.3</td></tr><tr><td><br />BiLSTM</td><td>50.2</td><td>80.1</td><td>50.1</td><td>81.7</td><td>60.5</td><td>77.9</td></tr><tr><td><br />LSTM_<br />ensemble</td><td>51.9</td><td>79.2</td><td>51.4</td><td>82.3</td><td>60.7</td><td>78.1</td></tr><tr><td><br />DRNN</td><td>45.1</td><td>74.2</td><td>49.5</td><td>78.8</td><td>58.6</td><td>75.6</td></tr><tr><td><br />CDRNN</td><td>53.9</td><td>84.1</td><td>55.2</td><td>85.3</td><td>62.2</td><td>79.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>2.5</b> 滑动窗口大小对模型的影响</h4>
                <div class="p1">
                    <p id="131">滑动窗口大小是CDRNN中的一个重要参数, 不同的窗口大小对模型捕获局部信息能力产生重要影响.为了分析窗口大小对模型性能的影响, 以Olympic数据集为例, 窗口大小分别设置为{3, 4, 5, 6, 7, 8, 9, 10}, 并依次递增.实验结果见图4.</p>
                </div>
                <div class="p1">
                    <p id="132">从图4可看出, 在raw数据集上, CDRNN窗口在<citation id="165" type="reference">[<a class="sup">5</a>,<a class="sup">7</a>]</citation>内达到最优, 在cleaned数据集上, CDRNN在<citation id="166" type="reference">[<a class="sup">4</a>,<a class="sup">6</a>]</citation>内达到最优.这是因为人名字符组成遵循一定的音节发音规律, 一个独立的音节一般都在4～7个字符范围之内, 而CDRNN通过窗口截断的形式, 较好地捕捉这类局部特征信息.</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904012_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同窗口大小对模型性能的影响" src="Detail/GetImg?filename=images/MSSB201904012_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同窗口大小对模型性能的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904012_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Performance of proposed model with different window sizes</p>

                </div>
                <h4 class="anchor-tag" id="135" name="135"><b>2.6</b> 样例分析</h4>
                <div class="p1">
                    <p id="136">为了进一步探究不同模型在国籍判别上的差异, 以LSTM、LSTM_ensemble、DRNN、CDRNN进行对比, 分别在Olympic数据集和Aminer学者数据集上抽取部分样例进行分析.Olympic和Aminer数据样例和不同模型的预测结果如表3所示.Robert L. KENNEDY的名字是按照“教名+自取名+姓”的结构规范, 在英国和加拿大中较常见, 因此也难以区分.在所有预测结果中, 预测排名前5的国家都含有英国和加拿大, 但大部分的模型都将“Robert L. KENNEDY”首先归类为加拿大, 而CDRNN能准确率预测其为英国国籍名字.</p>
                </div>
                <div class="p1">
                    <p id="137">John Johansen是一个丹麦人的名字, 由于John在英美国家的人名中较常见, 因此在预测结果中都含有英国和美国, 而Johansen按音节可拆分为Jo+han+sen, 其中han和sen在华人名字中较多出现.由于LSTM是从首到尾的编码, 记忆信息会侧重于后面字符, 因此在预测列表中含有新加坡国家.DRNN因平均池化操作, 只提取最显著的局部信息, 也将其错误预测为华人国家, 如中国.LSTM_ens和CDRNN具备丰富的语义信息, 并未将其判别为华人名字.另一方面, 丹麦 (Danmark) 与挪威 (Norway) 具有长远的历史关联, 两个国家曾有近300年的联盟共主关系, 名字命名习惯相似性较大.LSTM_ensemble将其错误归为挪威国家, CDRNN因含有更多的局部特征, 能更好地区分这两类国家的人名, 从而达到正确预测的效果.</p>
                </div>
                <div class="area_img" id="138">
                    <p class="img_tit"><b>表3 4种模型对2个数据样例的预测结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Prediction results of 4 models on 2 datasets</p>
                    <p class="img_note"></p>
                    <table id="138" border="1"><tr><td><br />数据样例</td><td>人名</td><td>真实类别</td><td>模型</td><td>预测结果</td></tr><tr><td><br />Olympic</td><td>Robert L. <br />KENNEDY</td><td>Great <br />Britain</td><td>LSTM<br />LSTM_ensemble<br />DRNN<br />CDRNN</td><td>Canada, Netherlands, <b>Great Britain</b>, Czech Republic, Switzerland<br />Canada, <b>Great Britain</b>, Australia, India, Switzerland<br />Canada, <b>Great Britain</b>, Switzerland, India, Netherlands<br /><b>Great Britain</b>, Canada, Netherlands, Australia, Belgium</td></tr><tr><td><br />Aminer</td><td>John <br />Johansen</td><td>Denmark</td><td>LSTM<br />LSTM_ensemble<br />DRNN<br />CDRNN</td><td>Great Britain, America, Australia, Canada, Singapore<br />Norway, America, <b>Denmark</b>, Germany, Great Britain<br />America, Canada, Australia, <b>Denmark</b>, China<br /><b>Denmark</b>, America, Norway, Sweden, Great Britain</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="139" name="139" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="140">本文构造基于字符级别、端到端的神经网络模型 (CDRNN) , 用于预测用户国籍.以字向量特征作为基本输入, 为了更好地捕获人名中的字符序列特征和字符组合搭配的局部特征, 引入截断式神经网络模型, 通过窗口化的形式将人名截断成多个子序列, 利用LSTM分别学习不同序列的区域特征, 并采用平均池化操作综合所有的序列特征, 从而预测用户国籍.在2个真实数据集上的实验表明, CDRNN性能更优.另外, 在实验中发现, 亚洲地区国家人名区分度较高, 而欧洲地区国家由于地理较邻近, 拥有较近的历史渊源, 名字较易混淆.除此以外, 在真实生活中, 用户会出现国籍发生更改即移民, 而人名维持不变的情况.因此, 进一步的研究工作将从以下方面开展:引入更多的线索信息, 增强模型对用户国籍预测的能力;尝试将模型运用到其它用户画像任务当中, 如用户的种族、性别预测等.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="170" type="formula" href="images/MSSB201904012_17000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">张钰莎</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="171" type="formula" href="images/MSSB201904012_17100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">张礼明</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="172" type="formula" href="images/MSSB201904012_17200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">蒋盛益</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=What&amp;#39;&amp;#39;s in a name?Using first names as features for gender inference in Tw itter">

                                <b>[1]</b> LIU W, RUTHS D.What′s in a Name?Using First Names as Features for Gender Inference in Twitter // Proc of the AAAI Spring Symposium:Analyzing Microtext.Palo Alto, USA:AAAI Press, 2013:10-16.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Inferring Gender from Names on the Web:A Comparative Evaluation of Gender Detection Methods">

                                <b>[2]</b> KARIMI F, WAGNER C, LEMMERICH F, <i>et al</i>.Inferring Gender from Names on the Web:A Comparative Evaluation of Gender Detection Methods // Proc of the 25th International Conference Companion on World Wide Web.New York, USA:ACM, 2016:53-54.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting Twitter User Demographics from Names Alone">

                                <b>[3]</b> WOOD-DOUGHTY Z, ANDREWS N, MARVIN R, <i>et al</i>.Predicting Twitter User Demographics from Names Alone // Proc of the 2nd Workshop on Computational Modeling of People′s Opinions, Personality, and Emotions in Social Media.Stroudsburg, USA:ACL, 2018:105-111.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Name-Ethnicity Classification from Open Sources">

                                <b>[4]</b> AMBEKAR A, WARD C, MOHAMMED J, <i>et al</i>.Name-Ethnicity Classification from Open Sources // Proc of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2009:49-58.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Epluribus:Ethni-city on Social Networks">

                                <b>[5]</b> CHANG J, ROSENN I, BACKSTROM L, <i>et al</i>.Epluribus:Ethni-city on Social Networks // Proc of the 4th International Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2010:18-25.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Understanding the Demographics of Twitter Users">

                                <b>[6]</b> MISLOVE A, LEHMANN S, AHN Y Y, <i>et al</i>.Understanding the Demographics of Twitter Users // Proc of the 5th International AAAI Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2012:554-557.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Name-Ethnicity Classification and Ethnicity-Sensitive Name Matching">

                                <b>[7]</b> TREERATPITUK P, GILES C L.Name-Ethnicity Classification and Ethnicity-Sensitive Name Matching // Proc of the 26th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2012:1141-1147.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=What′s in a Name?A Method for Extracting Information about Ethnicity from Names">

                                <b>[8]</b> ANDREW H J.What′s in a Name?A Method for Extracting Information about Ethnicity from Names.Political Analysis, 2015, 23 (2) :212-224.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Broadly Improving User Classification via Communication-Based Name and Location Clustering on Twitter">

                                <b>[9]</b> BERGSMA S, DREDZE M, VAN DURME B, <i>et al</i>.Broadly Improving User Classification via Communication-Based Name and Location Clustering on Twitter // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg, USA:ACL, 2013:1010-1019.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Inferring nationalities of Twitter users and studying inter-national linking">

                                <b>[10]</b> HUANG W Y, WEBER I, VIEWEG S.Inferring Nationalities of Twitter Users and Studying International Linking // Proc of the 25th ACM Conference on Hypertext and Social Media.New York, USA:ACM, 2014:237-242.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A machine learning approach to twitter user classification">

                                <b>[11]</b> PENNACCHIOTTI M, POPESCU A.A Machine Learning Approa-ch to Twitter User Classification // Proc of the 5th AAAI International Conference on Weblogs and Social Media.Palo Alto, USA:AAAI Press, 2011:281-288.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Language Identification of Names with SVMs">

                                <b>[12]</b> BHARGAVA A, KONDRAK G.Language Identification of Names with SVMs // Proc of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2010:693-696.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[13]</b> KRIZHEVSKY A, SUTSKEVER L, HINTON G E.ImageNet Cla-ssification with Deep Convolutional Neural Networks // PEREIRA F, BURGES C J C, BOTTOU L, <i>et al</i>., eds.Advances in Neural Information Processing Systems 25.Cambridge, USA:The MIT Press, 2012:1106-1114.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL]">

                                <b>[14]</b> SIMONYAN K, ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2018-02-14].https://arxiv.org/pdf/1409.1556.pdf.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient estimation of word representations in vector space">

                                <b>[15]</b> MIKOLOV T, CHEN K, CORRADO G, <i>et al</i>.Efficient Estimation of Word Representations in Vector Space[C/OL].[2018-02-14].https://arxiv.org/pdf/1301.3781.pdf.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">

                                <b>[16]</b> PENNINGTON J, SOCHER R, MANNING C D.Glove:Global Vectors for Word Representation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1532-1543.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 PEROZZI B, AL-RFOU R, SKIENA S.DeepWalk:Online Lear-ning of Social Representations // Proc of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, New York, USA:ACM, 2014:701-710.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LINE:large-scale information network embedding">

                                <b>[18]</b> TANG J, MU M, WANG M Z, <i>et al</i>.LINE:Large-Scale Information Network Embedding // Proc of the 24th International Confe-rence on World Wide Web.New York, USA:ACM, 2015:1067-1077.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nationality Classification Using Name Embeddings">

                                <b>[19]</b> YE J T, HAN S C, HU Y F, <i>et al</i>.Nationality Classification Using Name Embeddings // Proc of the ACM Conference on Information and Knowledge Management.New York, USA:ACM, 2017:1897-1906.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MDk3MzBLOUh0ak1xbzlGWk9vTERYVXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRnNYYUJNPU5pZkpaYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> HOCHREITER S, SCHMIDHUBER J.Long Short-Term Memory.Neural Computation, 1997, 9 (8) .DOI:10.1162/neco.1997.9.8.1735.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Empirical evaluation of gated recurrent neural networks on sequence modeling">

                                <b>[21]</b> CHUNG J, GULCEHRE C, CHO K H, <i>et al</i>.Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL].[2018-02-11].https://arxiv.org/pdf/1412.3555.pdf.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Name Nationality Classification with Recurrent Neural Networks">

                                <b>[22]</b> LEE J, KIM H, KO M, <i>et al</i>.Name Nationality Classification with Recurrent Neural Networks // Proc of the 26th International Joint Conference on Artificial Intelligence.Melbourne, Australia:IJCAI, 2017:2081-2087.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Disconnected Recurrent Neural Networks for Text Categorization">

                                <b>[23]</b> WANG B X.Disconnected Recurrent Neural Networks for Text Categorization // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:2311-2320.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">

                                <b>[24]</b> KIM Y.Convolutional Neural Networks for Sentence Classification // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1746-1751.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201904012" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201904012&amp;v=MDIyNjdlWmVSbkZ5emdVTDNKS0Q3WWJMRzRIOWpNcTQ5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
