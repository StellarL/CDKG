<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131439358155000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201902003%26RESULT%3d1%26SIGN%3dneDta4saAsKjhW3DSjxnR0pe9gY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201902003&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201902003&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201902003&amp;v=MjU2ODI3WWJMRzRIOWpNclk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5em5VTC9NS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#76" data-title="1 人脸视频流处理 ">1 人脸视频流处理</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#80" data-title="2 时空纹理特征级联方法 ">2 时空纹理特征级联方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#81" data-title="&lt;b&gt;2.1&lt;/b&gt; 韦伯局部描述子"><b>2.1</b> 韦伯局部描述子</a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;2.2&lt;/b&gt; 局部二值模式"><b>2.2</b> 局部二值模式</a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;2.3&lt;/b&gt; 韦伯局部二值模式"><b>2.3</b> 韦伯局部二值模式</a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;2.4&lt;/b&gt; 时空纹理特征级联算法"><b>2.4</b> 时空纹理特征级联算法</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#136" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#160" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="图1 人脸视频序列归一化">图1 人脸视频序列归一化</a></li>
                                                <li><a href="#135" data-title="图2 本文方法流程图">图2 本文方法流程图</a></li>
                                                <li><a href="#141" data-title="&lt;b&gt;表1&lt;/b&gt;&lt;b&gt;分类结果的混淆矩阵&lt;/b&gt;"><b>表1</b><b>分类结果的混淆矩阵</b></a></li>
                                                <li><a href="#154" data-title="&lt;b&gt;表2&lt;/b&gt;&lt;b&gt;6种方法在2个数据库上的准确率对比&lt;/b&gt;"><b>表2</b><b>6种方法在2个数据库上的准确率对比</b></a></li>
                                                <li><a href="#158" data-title="图3 6种方法的ROC曲线对比">图3 6种方法的ROC曲线对比</a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;表3&lt;/b&gt;&lt;b&gt;10种方法在2个数据库上的EER和HTER对比&lt;/b&gt;"><b>表3</b><b>10种方法在2个数据库上的EER和HTER对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="15">


                                    <a id="bibliography_1" title=" KOSE N, DUGELAY J L. On the Vulnerability of Face Recognition Systems to Spoofing Mask Attacks // Proc of the IEEE International Conference on Acoustics, Speech and Signal Processing. Washington, USA: IEEE, 2013: 2357-2361." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the vulnerability of face recognition systems to spoofing mask attacks">
                                        <b>[1]</b>
                                         KOSE N, DUGELAY J L. On the Vulnerability of Face Recognition Systems to Spoofing Mask Attacks // Proc of the IEEE International Conference on Acoustics, Speech and Signal Processing. Washington, USA: IEEE, 2013: 2357-2361.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_2" title=" 曹瑜, 涂玲, 毋立芳.身份认证中灰度共生矩阵和小波分析的活体人脸检测算法.信号处理, 2014, 30 (7) : 830-835. (CAO Y, TU L, WU L F. Face Liveness Detection Using Gray Level Co-occurrence Matrix and Wavelets Analysis in Identity Authentication. Journal of Signal Processing, 2014, 30 (7) : 830-835.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201407012&amp;v=MDYxNTMzenFxQnRHRnJDVVJMT2VaZVJuRnl6blVML1BQVFhJWUxHNEg5WE1xSTlFWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         曹瑜, 涂玲, 毋立芳.身份认证中灰度共生矩阵和小波分析的活体人脸检测算法.信号处理, 2014, 30 (7) : 830-835. (CAO Y, TU L, WU L F. Face Liveness Detection Using Gray Level Co-occurrence Matrix and Wavelets Analysis in Identity Authentication. Journal of Signal Processing, 2014, 30 (7) : 830-835.) 
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_3" title=" 李冰, 王宝亮, 由磊, 等.应用并联卷积神经网络的人脸防欺骗方法.小型微型计算机系统, 2017, 38 (10) : 2187-2191. (LI B, WANG B L, YOU L, &lt;i&gt;et al&lt;/i&gt;. Face Anti-spoofing Algorithm Applying with Parallel Convolutional Neural Network. Journal of Chinese Computer Systems, 2017, 38 (10) : 2187-2191.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201710003&amp;v=MDQ1OTA1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6blVML1BQVFhjZHJHNEg5Yk5yNDlGWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         李冰, 王宝亮, 由磊, 等.应用并联卷积神经网络的人脸防欺骗方法.小型微型计算机系统, 2017, 38 (10) : 2187-2191. (LI B, WANG B L, YOU L, &lt;i&gt;et al&lt;/i&gt;. Face Anti-spoofing Algorithm Applying with Parallel Convolutional Neural Network. Journal of Chinese Computer Systems, 2017, 38 (10) : 2187-2191.) 
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_4" title=" KIM G, EUM S, SUHR J K, &lt;i&gt;et al&lt;/i&gt;. Face Liveness Detection Based on Texture and Frequency Analyses // Proc of the 5th IAPR International Conference on Biometrics. Washington, USA: IEEE, 2012:67-72." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face liveness detection based on texture and frequency analyses">
                                        <b>[4]</b>
                                         KIM G, EUM S, SUHR J K, &lt;i&gt;et al&lt;/i&gt;. Face Liveness Detection Based on Texture and Frequency Analyses // Proc of the 5th IAPR International Conference on Biometrics. Washington, USA: IEEE, 2012:67-72.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_5" title=" PAN G, SUN L, WU Z H, &lt;i&gt;et al&lt;/i&gt;. Eyeblink-Based Anti-spoofing in Face Recognition from a Generic Web Camera // Proc of the 11th IEEE International Conference on Computer Vision. Washington, USA: IEEE, 2007. DOI: 10.1109/ICCV.2007.4409068." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Eyeblink-based Anti-spoofing in face recognition from a Generic Web-camera">
                                        <b>[5]</b>
                                         PAN G, SUN L, WU Z H, &lt;i&gt;et al&lt;/i&gt;. Eyeblink-Based Anti-spoofing in Face Recognition from a Generic Web Camera // Proc of the 11th IEEE International Conference on Computer Vision. Washington, USA: IEEE, 2007. DOI: 10.1109/ICCV.2007.4409068.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_6" title=" ZHAO G Y, PIETIKAINEN M. Dynamic Texture Recognition Using Local Binary Patterns with an Application to Facial Expressions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) : 915-928." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic Texture Recognition Using Local Binary Patterns with an Application to Facial Expressions">
                                        <b>[6]</b>
                                         ZHAO G Y, PIETIKAINEN M. Dynamic Texture Recognition Using Local Binary Patterns with an Application to Facial Expressions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) : 915-928.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_7" title=" WEN D, HAN H, JAIN A K. Face Spoof Detection with Image Distortion Analysis. IEEE Transactions on Information Forensics and Security, 2015, 10 (4) : 746-761." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face Spoof Detection With Image Distortion Analysis">
                                        <b>[7]</b>
                                         WEN D, HAN H, JAIN A K. Face Spoof Detection with Image Distortion Analysis. IEEE Transactions on Information Forensics and Security, 2015, 10 (4) : 746-761.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_8" title=" BASHIER H K, HOE L S, HUI L T, &lt;i&gt;et al&lt;/i&gt;. Texture Classification via Extended Local Graph Structure. Optik, 2016, 127 (2) : 638-643." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAFDD8D9B6EDBEF0A715C57ABA395E342&amp;v=MTAwNjNUM21NMmNMZmhScjZkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZod0xxOHdLOD1OaWZPZmNMT2FxWEUyNFkzWXA1N2ZnbFB6MmNVNnpvT1RYaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         BASHIER H K, HOE L S, HUI L T, &lt;i&gt;et al&lt;/i&gt;. Texture Classification via Extended Local Graph Structure. Optik, 2016, 127 (2) : 638-643.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_9" title=" PEREIRA T D F, ANJOS A, DE MARTINO J M, &lt;i&gt;et al&lt;/i&gt;. LBP-TOP Based Countermeasure Against Face Spoofing Attacks // Proc of the Asian Conference on Computer Vision. Berlin, Germany: Springer, 2012: 121-132." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LBP-TOP based countermeasure against face spoofing attacks">
                                        <b>[9]</b>
                                         PEREIRA T D F, ANJOS A, DE MARTINO J M, &lt;i&gt;et al&lt;/i&gt;. LBP-TOP Based Countermeasure Against Face Spoofing Attacks // Proc of the Asian Conference on Computer Vision. Berlin, Germany: Springer, 2012: 121-132.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_10" title=" PEREIRA T D F, KOMULAINEN J, ANJOS A, &lt;i&gt;et al&lt;/i&gt;. Face Liveness Detection Using Dynamic Texture. EURASIP Journal on Image and Video Processing, 2014. DOI:10.1186/1687-5281-2014-2." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15042700000061&amp;v=MjIzODJYT3FJOUZaT3NQREhvNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGd1hhaFU9Tmo3QmFySzlIdA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         PEREIRA T D F, KOMULAINEN J, ANJOS A, &lt;i&gt;et al&lt;/i&gt;. Face Liveness Detection Using Dynamic Texture. EURASIP Journal on Image and Video Processing, 2014. DOI:10.1186/1687-5281-2014-2.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_11" title=" CHEN J, SHAN S G, HE C, &lt;i&gt;et al&lt;/i&gt;. WLD: A Robust Local Image Descriptor. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (9) : 1705-1720." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=WLD: A Robust Local Image Descriptor">
                                        <b>[11]</b>
                                         CHEN J, SHAN S G, HE C, &lt;i&gt;et al&lt;/i&gt;. WLD: A Robust Local Image Descriptor. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (9) : 1705-1720.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_12" title=" LIU F, TANG Z M, TANG J H. WLBP: Weber Local Binary Pa-ttern for Local Image Description. Neurocomputing, 2013, 120: 325-335." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900038781&amp;v=MTg5NDNHZXJxUVRNbndaZVp1SHlqbVVMYklKRndYYWhVPU5pZk9mYks3SHRUTXBvOUZaT2dIQzNRNG9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         LIU F, TANG Z M, TANG J H. WLBP: Weber Local Binary Pa-ttern for Local Image Description. Neurocomputing, 2013, 120: 325-335.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_13" title=" MEI L, YANG D K, FENG Z X, &lt;i&gt;et al&lt;/i&gt;. WLD-TOP Based Algorithm Against Face Spoofing Attacks // Proc of the Chinese Confe-rence on Biometric Recognition. Berlin, Germany: Springer, 2015: 135-142." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=WLD-TOP based algorithm against face spoofing attacks">
                                        <b>[13]</b>
                                         MEI L, YANG D K, FENG Z X, &lt;i&gt;et al&lt;/i&gt;. WLD-TOP Based Algorithm Against Face Spoofing Attacks // Proc of the Chinese Confe-rence on Biometric Recognition. Berlin, Germany: Springer, 2015: 135-142.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_14" title=" ZHANG Z W, YAN J J, LIU S F, &lt;i&gt;et al&lt;/i&gt;. A Face Anti-spoofing Database with Diverse Attacks // Proc of the International Conference on Biometrics. Washington, USA: IEEE, 2012: 26-31." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A face antispoofing database with diverse attacks">
                                        <b>[14]</b>
                                         ZHANG Z W, YAN J J, LIU S F, &lt;i&gt;et al&lt;/i&gt;. A Face Anti-spoofing Database with Diverse Attacks // Proc of the International Conference on Biometrics. Washington, USA: IEEE, 2012: 26-31.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_15" title=" ANJOS A, KOMULAINEN J, MARCEL S, &lt;i&gt;et al&lt;/i&gt;. Face Anti-spoofing: Visual Approach // MARCEL S, NIXON M S, LI S Z, eds. Handbook of Biometric Anti-spoofing. London, UK: Springer, 2014: 65-82." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face Anti-spoofing: Visual Approach">
                                        <b>[15]</b>
                                         ANJOS A, KOMULAINEN J, MARCEL S, &lt;i&gt;et al&lt;/i&gt;. Face Anti-spoofing: Visual Approach // MARCEL S, NIXON M S, LI S Z, eds. Handbook of Biometric Anti-spoofing. London, UK: Springer, 2014: 65-82.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_16" title=" OJANSIVU V, HEIKKILA J. Blur Insensitive Texture Classification Using Local Phase Quantization // Proc of the 3rd International Conference on Image and Signal Processing. Berlin, Germany: Springer, 2008: 236-243." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Blur insensitive texture classification using local phase quantization">
                                        <b>[16]</b>
                                         OJANSIVU V, HEIKKILA J. Blur Insensitive Texture Classification Using Local Phase Quantization // Proc of the 3rd International Conference on Image and Signal Processing. Berlin, Germany: Springer, 2008: 236-243.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     OJALA T, PIETIKAINEN M, MAEMPAA T. Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) : 971-987.</a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_18" title=" BOULKENAFET Z, KOMULAINEN J, FEBG X Y, &lt;i&gt;et al&lt;/i&gt;. Scale Space Texture Analysis for Face Anti-spoofings // Proc of the International Conference on Biometrics. Washington, USA: IEEE, 2016. DOI: 10.1109/ICB.2016.7550078." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Scale space texture analysis for face anti-spoofing">
                                        <b>[18]</b>
                                         BOULKENAFET Z, KOMULAINEN J, FEBG X Y, &lt;i&gt;et al&lt;/i&gt;. Scale Space Texture Analysis for Face Anti-spoofings // Proc of the International Conference on Biometrics. Washington, USA: IEEE, 2016. DOI: 10.1109/ICB.2016.7550078.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_19" title=" AKBULUT Y, ŞENGUR A, BUDAK &#220;, &lt;i&gt;et al&lt;/i&gt;. Deep Learning Based Face Liveness Detection in Videos // Proc of the Artificial Intelligence and Data Processing Symposium. Washington, USA: IEEE, 2017: 1-4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Learning Based Face Liveness Detection in Videos">
                                        <b>[19]</b>
                                         AKBULUT Y, ŞENGUR A, BUDAK &#220;, &lt;i&gt;et al&lt;/i&gt;. Deep Learning Based Face Liveness Detection in Videos // Proc of the Artificial Intelligence and Data Processing Symposium. Washington, USA: IEEE, 2017: 1-4.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_20" title=" GAKBALLY J, MARCEL S. Face Anti-spoofing Based on General Image Quality Assessment // Proc of the 22nd IEEE International Conference on Pattern Recognition. Washington, USA: IEEE, 2014: 1173-1178." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face anti-spoofing based on general image quality assessment">
                                        <b>[20]</b>
                                         GAKBALLY J, MARCEL S. Face Anti-spoofing Based on General Image Quality Assessment // Proc of the 22nd IEEE International Conference on Pattern Recognition. Washington, USA: IEEE, 2014: 1173-1178.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_21" title=" ALOTAIBI A, MAHMOOD A. Deep Face Liveness Detection Based on Nonlinear Diffusion Using Convolution Neural Network. Signal, Image and Video Processing, 2017, 11 (4) : 713-720." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep face liveness detection based on nonlinear diffusion using convolution neural network">
                                        <b>[21]</b>
                                         ALOTAIBI A, MAHMOOD A. Deep Face Liveness Detection Based on Nonlinear Diffusion Using Convolution Neural Network. Signal, Image and Video Processing, 2017, 11 (4) : 713-720.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(02),117-123 DOI:10.16451/j.cnki.issn1003-6059.201902003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">面向活体人脸检测的时空纹理特征级联方法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%94%98%E4%BF%8A%E8%8B%B1&amp;code=25166821&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">甘俊英</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BF%9F%E6%87%BF%E5%A5%8E&amp;code=17263457&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">翟懿奎</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%A1%B9%E4%BF%90&amp;code=41184205&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">项俐</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%B9%E9%B9%A4&amp;code=40730736&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曹鹤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E5%9B%BD%E8%BE%89&amp;code=09000004&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何国辉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E5%86%9B%E8%8B%B1&amp;code=22658192&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曾军英</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B0%AD%E6%B5%B7%E8%8B%B1&amp;code=38383064&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谭海英</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%93%E6%96%87%E5%8D%9A&amp;code=40730737&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邓文博</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%94%E9%82%91%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0224516&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">五邑大学信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了解决身份认证中的安全问题, 通常采用活体人脸检测方法.为提高活体人脸检测的鲁棒性, 文中提出时空纹理特征级联方法.首先采用局部二值模式 (LBP) 计算韦伯局部描述符 (WLD) 的差分激励, 利用Prewitt算子计算WLD的方向角, 提取时空域的纹理特征.再将3个正交时空平面XY、XT、YT的纹理特征直方图进行级联, 得到动态纹理特征即时空纹理级联特征, 并对真实人脸和伪装人脸做出判定.在公开活体人脸数据库上的实验表明, 相比现有主流局部纹理特征方法, 文中方法识别率更高.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B4%BB%E4%BD%93%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">活体人脸检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部纹理特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A8%E6%80%81%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">动态纹理特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E7%A9%BA%E7%BA%B9%E7%90%86%E7%BA%A7%E8%81%94%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时空纹理级联特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    甘俊英, 博士, 教授, 主要研究方向为生物特征识别.E-mail:junyinggan@163.com.
;
                                </span>
                                <span>
                                    *翟懿奎, 博士, 副教授, 主要研究方向为生物特征识别、SAR图像识别.E-mail:yikuizhai@163.com.
;
                                </span>
                                <span>
                                    项俐, 硕士研究生, 主要研究方向为生物特征识别.E-mail:xianglizaa@163.com.
;
                                </span>
                                <span>
                                    曹鹤, 硕士研究生, 主要研究方向为生物特征识别、人脸美丽预测.E-mail:caohe115@163.com.
;
                                </span>
                                <span>
                                    何国辉, 博士, 教授, 主要研究方向为图像处理、虚拟现实、多媒体信息系统.E-mail:ghhe126@126.com.
;
                                </span>
                                <span>
                                    曾军英, 博士, 副教授, 主要研究方向为机器视觉、生物特征识别.E-mail:zengjunying@126.com.
;
                                </span>
                                <span>
                                    谭海英, 硕士研究生, 主要研究方向为生物特征识别、人脸美丽预测.E-mail:haiyingtan@163.com.
;
                                </span>
                                <span>
                                    邓文博, 硕士研究生, 主要研究方向为生物特征识别、SAR图像识别.E-mail:wenbodeng92@163.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-06-14</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.61771347, 61072127, 61372193);</span>
                                <span>广东省自然科学基金项目 (No.S2013010013311, 10152902001000002, S2011010001085, S2011040004211) 资助;</span>
                    </p>
            </div>
                    <h1>Spatial-Temporal Texture Cascaded Feature Method for Face Liveness Detection</h1>
                    <h2>
                    <span>GAN Junying</span>
                    <span>ZHAI Yikui</span>
                    <span>XIANG Li</span>
                    <span>CAO He</span>
                    <span>HE Guohui</span>
                    <span>ZENG Junying</span>
                    <span>TAN Haiying</span>
                    <span>DENG Wenbo</span>
            </h2>
                    <h2>
                    <span>School of Information Engineering, Wuyi University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the security problem in identity authentication, the face liveness detection method is always employed. Therefore, a spatial-temporal texture cascaded feature method is proposed to improve the robustness of living face detection. Firstly, local binary pattern (LBP) is utilized to calculate the differential excitation of Weber local descriptor (WLD) , and Prewitt operator is exploited to calculate the directional angle of WLD to extract texture features in time domain and space domain. Secondly, the histogram of texture features obtained from three orthogonal space-time planes, XY, XT and YT, is cascaded. Finally, the dynamic texture features, namely spatial-temporal texture cascade features, can be used to determine whether the real face or the disguised face. Experimental results on CASIA face anti-spoofing database and replay-attack database show that the proposed method obtains higher recognition rate than the existing mainstream local texture feature methods and it can be widely used in identity authentication and security monitoring systems.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Face%20Liveness%20Detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Face Liveness Detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Local%20Texture%20Feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Local Texture Feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dynamic%20Texture%20Feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dynamic Texture Feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SpatialTemporal%20Texture%20Cascaded%20Feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SpatialTemporal Texture Cascaded Feature;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    GAN Junying, Ph. D., professor. Her research interests include biometric identification.
;
                                </span>
                                <span>
                                    ZHAI Yikui, Ph.D., associate professor. His research interests include biometric identification and SAR image recognition.
;
                                </span>
                                <span>
                                    XIANG Li, master student. Her research interests include biometric identification.
;
                                </span>
                                <span>
                                    CAO He, master student. Her research interests include biometric identification and face beauty prediction.
;
                                </span>
                                <span>
                                    HE Guohui, Ph. D., professor. His research interests include image processing, virtual reality and multimedia information system.
;
                                </span>
                                <span>
                                    ZENG Junying, Ph. D., associate professor. His research interests include machine vision and biometrics identification.
;
                                </span>
                                <span>
                                    TAN Haiying, master student. Her research interests include biometric identification and face beauty prediction.
;
                                </span>
                                <span>
                                    DENG Wenbo, master student. His research interests include biometric identification and SAR image recognition.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-06-14</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No61771347, 61072127, 61372193);</span>
                                <span>Natural Science Foundation of Guangdong Province (No.S2013010013311, 10152902001000002, S2011010001085, S2011040004211);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="70">用户身份验证是保护信息的重要一步, 在这种情况下, 人脸识别因其自然、直观、易于使用等特点而得到广泛应用.近年来, 人脸识别领域取得重大进展, 该方法受姿态、光照、表情等外界因素的影响较小.然而, 人脸验证系统极易受到欺骗攻击, 如合法用户的照片、视频、3D面具<citation id="202" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.这些攻击的出现严重影响人脸验证系统的安全性<citation id="203" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="71">目前, 活体人脸检测方法主要包括基于频谱分析的活体检测、基于运动信息的活体检测及基于纹理特征的活体检测.基于频谱分析的活体检测采用多光谱成像技术、三维特征信息、频谱分析等分辨真实人脸, 原理简单, 易用性较强.基于红外感应成像的活体检测根据红外设备探测人脸表面温度的特征值以分辨真实人脸, 检测准确率较高, 但只能在特定条件下实现, 需要用户密切配合及额外硬件设备, 仅适用于门禁人脸识别系统.由于设备简单、鲁棒性高等优点, 基于纹理特征的活体检测被广泛应用, 分为基于静态纹理的活体检测和基于动态纹理的活体检测.相比静态纹理, 动态纹理不仅考虑空域的局部纹理信息, 还考虑时域的纹理信息, 提取的信息更完整, 可得到更多的有用信息.</p>
                </div>
                <div class="p1">
                    <p id="72">基于纹理特征的人脸活体检测一直是研究热点.Kim等<citation id="204" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>先通过功率谱和纹理算子分别提取人脸的频谱和纹理信息, 再利用支持向量机分类器判定活体人脸和伪装人脸.Pan等<citation id="205" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出通过统计眨眼次数进行活体人脸检测的方法, 但仅针对已挖切人眼的照片, 通过真实人眼进行伪装的效果较差.Zhao等<citation id="206" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出使用动态人脸信息进行人脸识别, 学习真实人脸局部纹理的结构和动态信息, 在空域中, 利用局部二值模式 (Local Binary Pattern, LBP) 进行人脸识别.该方法复杂度较低, 原理简单, 但容易受到噪声和光照影响.</p>
                </div>
                <div class="p1">
                    <p id="73">为了解决噪声问题, Wen等<citation id="208" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>在原LBP基础上增加动态纹理, 将XY、XT、YT这3个平面的LBP直方图进行级联, 得到动态纹理.Bashier等<citation id="207" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出简单并具有较好鲁棒性的扩展局部图像结构 (Extended Local Graph Structure, ELGS) , 对噪声具有较好的鲁棒性, 不受中心像素点影响, 可广泛应用于人脸识别和活体人脸检测等领域.</p>
                </div>
                <div class="p1">
                    <p id="74">为了提取丰富的特征信息, Pereira等<citation id="209" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出三正交平面的局部二值模式 (LBP from Three Orthogonal Planes, LBP-TOP) , 较好结合时域和空域特征信息.Pereira等<citation id="212" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出动态纹理检测活体人脸方法, 将级联人脸图像R、G、B平面的LBP直方图作为特征, 并输入到支持向量机分类器, 得到鉴别结果.此方法无需增加额外硬件设备, 对检测场景无较高要求, 因此在实际活体人脸检测中得到广泛应用.Chen等<citation id="211" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出韦伯局部描述子 (Weber Local Descriptor, WLD) , 在纹理分类等应用中展现良好的纹理特征提取能力.它与局部二元模式均属于密集型局部纹理特征, 通过计算图像中心点与其邻域点像素间灰度值差异以反映图像局部纹理变化.Liu等<citation id="210" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出韦伯局部二值模式 (Weber LBP, WLBP) , 通过LOG算子滤波处理形成差分激励算子, 同时结合局部二值模式特征, 对噪声较鲁棒.</p>
                </div>
                <div class="p1">
                    <p id="75">为了解决视频攻击下活体人脸检测鲁棒性问题, 本文提出时空纹理特征级联方法, 融合时域、空域中提取的纹理特征, 得到时空纹理级联特征, 有效实现真实人脸和伪装人脸判定.实验表明, 本文方法识别率较高, 鲁棒性较强, 具有良好的实际应用价值.</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">1 人脸视频流处理</h3>
                <div class="p1">
                    <p id="77">归一化像素差异特征 (Normalized Pixel Diffe-rence, NPD) 具有运行速度较快、无约束条件、准确率较高等优点.</p>
                </div>
                <div class="p1">
                    <p id="78">人脸视频序列归一化具体过程如图1所示.首先, 使用NPD对原始视频逐帧进行人脸检测.如果未检测到人脸, 跳到下一帧;如果检测到人脸, 判断人脸图像大小.当图像小于既定尺寸时, 检测的人脸无效并跳转到下一帧;否则, 利用双线性插值方法对人脸图像进行归一化处理, 切成相同大小, 得到待检测的人脸图像序列.</p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902003_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 人脸视频序列归一化" src="Detail/GetImg?filename=images/MSSB201902003_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 人脸视频序列归一化  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902003_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Normalization of face video sequence</p>

                </div>
                <h3 id="80" name="80" class="anchor-tag">2 时空纹理特征级联方法</h3>
                <h4 class="anchor-tag" id="81" name="81"><b>2.1</b> 韦伯局部描述子</h4>
                <div class="p1">
                    <p id="82">Mei等<citation id="214" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出使用WLD检测活体人脸, 具有较好的鲁棒性.WLD为一种纹理特征提取算法, 对光照和噪声的鲁棒性较好.Chen等<citation id="213" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出的WLD由差分激励算子和方向算子组成, 两者的联合形式表示图像的局部纹理特征.</p>
                </div>
                <div class="p1">
                    <p id="83">差分激励算子计算中心像素和所有相邻像素之间的灰度差之和及灰度值与中心像素的比率, 表示为<i>G</i><sub>ratio</sub> (<i>g</i><sub><i>c</i></sub>) .再计算差分激励, 使用反正切变换将<i>G</i><sub>ratio</sub> (<i>g</i><sub><i>c</i></sub>) 从范围[-<i>P</i>, +∞]映射到<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>-</mo><mfrac><mtext>π</mtext><mn>2</mn></mfrac><mo>, </mo><mfrac><mtext>π</mtext><mn>2</mn></mfrac></mrow></math></mathml>内, 反映图像灰度的变化量.图像中某一像素值<i>g</i><sub><i>c</i></sub>的差分激励</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>ξ</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>arctan</mi><mo stretchy="false"> (</mo><mi>G</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>a</mtext><mtext>t</mtext><mtext>i</mtext><mtext>o</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>arctan</mi><mo stretchy="false"> (</mo><mfrac><mn>1</mn><mrow><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>Ρ</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中, <i>g</i><sub><i>c</i></sub>表示中心像素值, <i>g</i><sub><i>i</i></sub>表示第<i>i</i>个邻域像素值, <i>P</i>表示邻域像素值的总数.将<i>ξ</i> (<i>g</i><sub><i>c</i></sub>) 量化为<i>K</i>段:</p>
                </div>
                <div class="p1">
                    <p id="87"><i>k</i>=mod<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>ξ</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mtext>π</mtext><mo>/</mo><mn>2</mn></mrow><mrow><mtext>π</mtext><mo>/</mo><mi>Κ</mi></mrow></mfrac></mrow></math></mathml>, <i>K</i>,      (1) </p>
                </div>
                <div class="p1">
                    <p id="89">其中mod为取模运算.</p>
                </div>
                <div class="p1">
                    <p id="90">方向表示为局部范围内水平方向与垂直方向上邻域像素点的灰度差值比值的反正切, 则中心像素的方向角</p>
                </div>
                <div class="p1">
                    <p id="91"><i>φ</i> (<i>g</i><sub><i>c</i></sub>) =arctan<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>a</mi></msubsup></mrow><mrow><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>b</mi></msubsup></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="93">其中, <i>V</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>a</mi></msubsup></mrow></math></mathml>、<i>V</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>b</mi></msubsup></mrow></math></mathml>为中心像素<i>g</i><sub><i>c</i></sub>水平、垂直方向相邻两个像素值之差.</p>
                </div>
                <div class="p1">
                    <p id="96">为了简化起见, 文献<citation id="215" type="reference">[<a class="sup">12</a>]</citation>将方向角量化到<i>T</i>个主导方向:</p>
                </div>
                <div class="p1">
                    <p id="97"><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Φ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mi>t</mi></mrow><mi>Τ</mi></mfrac><mtext>π</mtext></mrow></math></mathml>,      (2) </p>
                </div>
                <div class="p1">
                    <p id="99">其中</p>
                </div>
                <div class="p1">
                    <p id="100"><i>t</i>=mod<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><msup><mi>φ</mi><mo>′</mo></msup><mrow><mn>2</mn><mtext>π</mtext><mo>/</mo><mi>Τ</mi></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></math></mathml>, <i>T</i>, </p>
                </div>
                <div class="p1">
                    <p id="102">并且<i>φ</i>′是通过映射<i>f</i>∶<i>φ</i>→<i>φ</i>′, 将范围由<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>-</mo><mfrac><mtext>π</mtext><mn>2</mn></mfrac><mo>, </mo><mfrac><mtext>π</mtext><mn>2</mn></mfrac></mrow></math></mathml>变换至 (0, 2π) , 变换公式为</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>φ</mi><mo>′</mo></msup><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>φ</mi><mo>+</mo><mtext>π</mtext><mo>‚</mo></mtd><mtd columnalign="left"><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>a</mi></msubsup><mo>&gt;</mo><mn>0</mn><mo>, </mo><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>b</mi></msubsup><mo>&gt;</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mi>φ</mi><mo>+</mo><mtext>π</mtext><mo>, </mo></mtd><mtd columnalign="left"><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>a</mi></msubsup><mo>&lt;</mo><mn>0</mn><mo>, </mo><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>b</mi></msubsup><mo>&gt;</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mi>φ</mi><mo>, </mo></mtd><mtd columnalign="left"><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>a</mi></msubsup><mo>&lt;</mo><mn>0</mn><mo>, </mo><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>b</mi></msubsup><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mi>φ</mi><mo>+</mo><mn>2</mn><mtext>π</mtext><mo>, </mo></mtd><mtd columnalign="left"><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>a</mi></msubsup><mo>&gt;</mo><mn>0</mn><mo>, </mo><mi>V</mi><mtext> </mtext><msubsup><mrow></mrow><mi>s</mi><mi>b</mi></msubsup><mo>&lt;</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">根据式 (1) 和式 (2) , 获得差分激励<i>k</i>和方向<i>t</i>, 得到二维WLD直方图{<i>WLD</i> (<i>k</i>, <i>Φ</i><sub><i>t</i></sub>) } (<i>k</i>=0, 1, …, <i>K</i>-1;<i>Φ</i><sub><i>t</i></sub>=0, 1, …, <i>T</i>-1) .</p>
                </div>
                <h4 class="anchor-tag" id="106" name="106"><b>2.2</b> 局部二值模式</h4>
                <div class="p1">
                    <p id="107"><i>LBP</i><sub><i>P</i>, <i>R</i></sub>具有2<sup><i>P</i></sup>种模式, <i>P</i>表示半径为<i>R</i>时邻域像素点个数, 取值不同可让LBP具有多分辨率识别的特性.LBP计算复杂度较高, 而均匀LBP只有<i>T</i>=<i>P</i> (<i>P</i>-1) +2种模式, 可减少计算量, 即</p>
                </div>
                <div class="p1">
                    <p id="108" class="code-formula">
                        <mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>L</mi><mi>B</mi><mi>Ρ</mi><msubsup><mrow></mrow><mrow><mi>Ρ</mi><mo>, </mo><mi>R</mi></mrow><mrow><mi>u</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></msubsup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>F</mi><mo stretchy="false"> (</mo><mi>L</mi><mi>B</mi><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>, </mo><mi>R</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo></mtd><mtd columnalign="left"><mi>U</mi><mo stretchy="false"> (</mo><mi>L</mi><mi>B</mi><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>, </mo><mi>R</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>≤</mo><mn>2</mn></mtd></mtr><mtr><mtd columnalign="left"><mo stretchy="false"> (</mo><mi>Ρ</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mi>Ρ</mi><mo>+</mo><mn>2</mn><mo>, </mo></mtd><mtd columnalign="left"><mtext>其</mtext><mtext>它</mtext></mtd></mtr></mtable></mrow></mrow></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="109">其中</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>U</mi><mo stretchy="false"> (</mo><mi>L</mi><mi>B</mi><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>, </mo><mi>R</mi></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>Ρ</mi></munderover><mo stretchy="false"> (</mo></mstyle><mo stretchy="false">|</mo><mi>s</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>p</mi></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>s</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">|</mo><mi>s</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mi>s</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo stretchy="false">) </mo><mo>‚</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111"><i>F</i> (<i>z</i>) 表示索引函数.如果<i>U</i> (<i>x</i>) &lt;2, 当前像素通过索引函数分配标签;否则直接定义为 (<i>P</i>-1) <i>P</i>+2.通过索引函数为每个均匀模式都被分配特定标签.</p>
                </div>
                <h4 class="anchor-tag" id="112" name="112"><b>2.3</b> 韦伯局部二值模式</h4>
                <div class="p1">
                    <p id="113">WLBP描述子由改进差分激励算子<i>ξ</i>和均匀LBP组成, 可以有效结合WLD和LBP两者优势, 其通过改进差分激励算子, 并使用均匀LBP替代WLD方向角以实现.对于给定人脸图像, 改进WLBP描述子分别计算差分激励组成成分和均匀LBP组成成分, 获得差分激励特征和LBP特征, 并构建二维直方图{<i>WLBP</i> (<i>s</i>, <i>t</i>) } (<i>s</i>=1, 2, …, <i>N</i>;<i>t</i>=1, 2, …, <i>T</i>) 纹理特征, 其中, <i>s</i>表示改进差分激励中高感应区的第<i>s</i>段, <i>N</i>表示高感应区量化的总段数.此二维直方图每列对应LBP模式<i>t</i>, 每行对应一个差分激励区间, 每个小块表示差分区间<i>l</i><sub><i>s</i></sub>下均匀LBP模式<i>t</i>的频率.</p>
                </div>
                <div class="p1">
                    <p id="114">将{<i>WLBP</i> (<i>s</i>, <i>t</i>) }编码为一维直方图<i>H</i>.{<i>WLBP</i> (<i>s</i>, <i>t</i>) }的每行形成<i>H</i> (<i>s</i>) , <i>s</i>=1, 2, …, <i>T</i>, 每个<i>H</i> (<i>s</i>) 对应差分激励区间<i>l</i><sub><i>s</i></sub>.将<i>H</i> (<i>s</i>) 相连, 获得一维直方图<i>H</i>={<i>H</i><sub><i>S</i></sub>}.</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>2.4</b> 时空纹理特征级联算法</h4>
                <div class="p1">
                    <p id="116">由于LBP对噪声较敏感, 有时无法较好获取纹理特征, 而韦伯定律对光照和噪声具有较好的鲁棒性.为此, 本文采用LBP算子提取WLD的差分激励, 采用Prewitt算子提取方向角.在计算差分激励时, 采用LBP特征, 即</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>f</mi><msub><mrow></mrow><mrow><mi>L</mi><mi>B</mi><mi>Ρ</mi><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>, </mo><mi>R</mi></mrow></msub></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>c</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ρ</mi></munderover><mn>2</mn></mstyle><msup><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msup><mi>s</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Τ</mi><mi>Η</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>s</mi><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Τ</mi><mi>Η</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Τ</mi><mi>Η</mi><msub><mrow></mrow><mi>c</mi></msub><mo>≥</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Τ</mi><mi>Η</mi><msub><mrow></mrow><mi>c</mi></msub><mo>&lt;</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">其中</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>Η</mi><msub><mrow></mrow><mi>c</mi></msub><mo>=</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ρ</mi></munderover><mrow><mfrac><mrow><mi>g</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub></mrow><mrow><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub></mrow></mfrac></mrow></mstyle><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120"> (<i>x</i><sub><i>c</i></sub>, <i>y</i><sub><i>c</i></sub>) 为邻域中心像素<i>c</i>的坐标, <i>g</i><sub><i>i</i></sub>为邻域各坐标的灰度值, <i>R</i>为邻域半径, <i>P</i>为以<i>R</i>为半径的邻域像素值的总数.因此, 差分激励</p>
                </div>
                <div class="p1">
                    <p id="121"><i>ξ</i> (<i>g</i><sub><i>c</i></sub>) =arctan[<i>G</i><sub>ratio</sub> (<i>g</i><sub><i>c</i></sub>) ]=arctan[<i>f</i><sub><i>LBP</i><sub><i>P</i>, <i>R</i></sub></sub> (<i>x</i><sub><i>c</i></sub>, <i>y</i><sub><i>c</i></sub>) ].</p>
                </div>
                <div class="p1">
                    <p id="122">本文采用Prewitt算子代替原始WLD的方向算子提取梯度方向, 考虑所有邻域的像素点, 提高WLD特征的描述能力.Prewitt算子为</p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula">
                        <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mo>-</mo><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="124">此时, 方向角</p>
                </div>
                <div class="p1">
                    <p id="125"><i>φ</i> (<i>g</i><sub><i>c</i></sub>) =arctan<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi mathvariant="bold-italic">b</mi><mi mathvariant="bold-italic">l</mi><mi mathvariant="bold-italic">o</mi><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">k</mi><mo>⋅</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>1</mn></mrow></msub></mrow><mrow><mi mathvariant="bold-italic">b</mi><mi mathvariant="bold-italic">l</mi><mi mathvariant="bold-italic">o</mi><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">k</mi><mo>⋅</mo><mi mathvariant="bold-italic">F</mi><msub><mrow></mrow><mrow><mn>0</mn><mn>0</mn></mrow></msub></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="127">其中<b><i>block</i></b>为以图像某一像素值<i>g</i><sub><i>c</i></sub>为中心的3×3灰度值矩阵.</p>
                </div>
                <div class="p1">
                    <p id="128">本文提出时空纹理级联特征算法, 在3个正交时空平面XY、XT和YT中纹理特征的直方图级联, 得到时空纹理级联特征.假设图像中某一中心像素点<i>g</i><sub><i>c</i></sub> (<i>x</i>, <i>y</i>, <i>t</i>) , 其时空纹理级联特征直方图为</p>
                </div>
                <div class="p1">
                    <p id="129"><i>f</i> (<i>x</i>, <i>y</i>, <i>t</i>) =<i>SΦ</i><sub><i>t</i></sub>+<i>f</i><sub><i>LBP</i><sub><i>P</i>, <i>R</i></sub></sub> (<i>x</i>, <i>y</i>, <i>t</i>) , </p>
                </div>
                <div class="p1">
                    <p id="130">其中, (<i>x</i>, <i>y</i>, <i>t</i>) 表示XY、XT和YT平面的坐标值, 差分激励<i>ξ</i>维数为<i>S</i>, 方向角<i>φ</i>维数为<i>T</i>.第<i>i</i>个平面的时空纹理特征的直方图为</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>h</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>t</mi></mrow></munder><mi>Μ</mi></mstyle><mo stretchy="false">{</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mi>j</mi><mo stretchy="false">}</mo><mo>, </mo><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>S</mi><mi>Τ</mi><mo>-</mo><mn>1</mn><mo>‚</mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mo stretchy="false"> (</mo><mi>A</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>A</mi><mtext>为</mtext><mtext>逻</mtext><mtext>辑</mtext><mtext>真</mtext></mtd></mtr><mtr><mtd columnalign="left"><mn>1</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>A</mi><mtext>为</mtext><mtext>逻</mtext><mtext>辑</mtext><mtext>假</mtext></mtd></mtr></mtable></mrow></mrow></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="132">其中, <i>i</i>=1为XY平面, <i>i</i>=2为XT平面, <i>i</i>=3为YT平面.</p>
                </div>
                <div class="p1">
                    <p id="133">本文将<i>h</i><sub><i>i</i>, <i>j</i></sub>转换成行矢量<b><i>h</i></b><sub><i>i</i></sub>, 依次连接<b><i>h</i></b><sub><i>i</i></sub>, 构成时空纹理级联特征矩阵<b><i>H</i></b>=[<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, <b><i>h</i></b><sub>3</sub>].将三维直方图{<i>WLP</i> (<i>ξ</i><sub><i>j</i></sub>, <i>Φ</i><sub><i>t</i></sub>, <i>i</i>) } (<i>i</i>=1, 2, 3; <i>j</i>=0, 1, …, <i>S</i>-1;<i>t</i>=0, 1, …, <i>T</i>-1) 转换成一维直方图<i>H</i>.</p>
                </div>
                <div class="p1">
                    <p id="134">图2是本文方法流程图, 分别在XY、XT、YT这3个平面上提取时空域的纹理特征, 并将XY、XT、YT这3个平面的纹理特征直方图进行级联, 得到动态纹理后再分类.</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902003_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文方法流程图" src="Detail/GetImg?filename=images/MSSB201902003_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文方法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902003_135.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Flow chart of the proposed method</p>

                </div>
                <h3 id="136" name="136" class="anchor-tag">3 实验及结果分析</h3>
                <div class="p1">
                    <p id="137">为了测试本文方法对活体人脸和假冒人脸的鉴别能力, 采用公开活体人脸视频数据库CASIA FASD<citation id="217" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、Replay-Attack<citation id="216" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>进行测试.CASIA FASD数据库由50组活体人脸和伪装人脸视频组成, 包含20组训练集 (ID: C1-C20) 和30组测试集 (ID: C21-C50) .Replay-Attack数据库含有1 200幅图像视频库样本.</p>
                </div>
                <div class="p1">
                    <p id="138">通过训练SVM二分类器判定活体人脸和伪装人脸.样例分为4类:假反例 (False Negative, FN) 、真反例 (True Negative, TN) 、假正例 (False Posi-tive, FP) 、真正例 (True Positive, TP) .样本总数为4种样例数之和.假设预测结果为正例的样例总数为<i>y</i><sub>1</sub>, 预测结果为反例的样例总数为<i>y</i><sub>0</sub>, 则分类结果的混淆矩阵如表1所示.</p>
                </div>
                <div class="p1">
                    <p id="139">采用接收机工作特性 (Receiver Operating Characteristic, ROC) 曲线、准确率和半错误率 (Half Total Error Rate, HTER) 评估算法分类性能.ROC曲线的横轴为假正例率 (False Positive Rate, FPR) , 纵轴为真正例率 (True Positive Rate, TPR) , 分别定义为</p>
                </div>
                <div class="p1">
                    <p id="140" class="code-formula">
                        <mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Τ</mi><mi>Ρ</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi>F</mi><mi>Ρ</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac><mtext> </mtext><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit"><b>表1</b><b>分类结果的混淆矩阵</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Confusion matrix of classification results</p>
                    <p class="img_note"></p>
                    <table id="141" border="1"><tr><td rowspan="2"><br />实际结果</td><td colspan="2"><br />预测结果</td></tr><tr><td><br />正例</td><td>反例</td></tr><tr><td><br />正例</td><td>真正例</td><td>假反例</td></tr><tr><td><br />反例</td><td>假正例</td><td>真反例</td></tr><tr><td><br />总数</td><td><i>y</i><sub>1</sub></td><td><i>y</i><sub>0</sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="142">生物特征识别系统具有更严格的性能, 需要有较低的错误拒绝率 (False Rejection Rate, FRR) 和错误接受率 (False Acceptance Rate, FAR) .FRR为错误判断一张活体人脸为伪装人脸的可能性, FAR为将伪装人脸判为活体人脸的概率, 均由判断阈值<i>τ</i>决定, 即</p>
                </div>
                <div class="p1">
                    <p id="143" class="code-formula">
                        <mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>F</mi><mi>A</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo>, </mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>F</mi><mi>Ν</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo>, </mo><mi>D</mi><mo stretchy="false">) </mo></mrow><mrow><mi>y</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi>F</mi><mi>R</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo>, </mo><mi>D</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>F</mi><mi>Ρ</mi></mrow><mrow><mi>y</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="144">其中, <i>τ</i>为判断阈值, <i>D</i>为数据库.</p>
                </div>
                <div class="p1">
                    <p id="145">等错误率 (Equal Error Rate, EER) 为FRR与FAR相等时的平均错误概率:</p>
                </div>
                <div class="p1">
                    <p id="146" class="code-formula">
                        <mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>τ</mi><msubsup><mrow></mrow><mrow><mtext>E</mtext><mtext>E</mtext><mtext>R</mtext></mrow><mo>*</mo></msubsup><mo>=</mo><mi>arg</mi><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>τ</mi></munder><mo stretchy="false">|</mo><mi>F</mi><mi>A</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>e</mtext><mtext>v</mtext></mrow></msub><mo stretchy="false">) </mo><mo>-</mo><mi>F</mi><mi>R</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>e</mtext><mtext>v</mtext></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>E</mi><mi>E</mi><mi>R</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>F</mi><mi>A</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><msubsup><mrow></mrow><mrow><mtext>E</mtext><mtext>E</mtext><mtext>R</mtext></mrow><mo>*</mo></msubsup><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>e</mtext><mtext>v</mtext></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi>F</mi><mi>R</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><msubsup><mrow></mrow><mrow><mtext>E</mtext><mtext>E</mtext><mtext>R</mtext></mrow><mo>*</mo></msubsup><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>e</mtext><mtext>v</mtext></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="147">其中<mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>τ</mi></munder><mo stretchy="false"> (</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>τ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>为<i>g</i> (<i>τ</i>) 为最小值时<i>τ</i>的取值.</p>
                </div>
                <div class="p1">
                    <p id="149">依据测试数据集<i>D</i><sub>test</sub>中已知阈值<i>τ</i><sup>*</sup><sub>EER</sub>下的FAR与FRR, HTER可表示为两者均值:</p>
                </div>
                <div class="p1">
                    <p id="150" class="code-formula">
                        <mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Η</mi><mi>Τ</mi><mi>E</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><msubsup><mrow></mrow><mrow><mtext>E</mtext><mtext>E</mtext><mtext>R</mtext></mrow><mo>*</mo></msubsup><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>e</mtext><mtext>v</mtext></mrow></msub><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>F</mi><mi>A</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><msubsup><mrow></mrow><mrow><mtext>E</mtext><mtext>E</mtext><mtext>R</mtext></mrow><mo>*</mo></msubsup><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi>F</mi><mi>R</mi><mi>R</mi><mo stretchy="false"> (</mo><mi>τ</mi><msubsup><mrow></mrow><mrow><mtext>E</mtext><mtext>E</mtext><mtext>R</mtext></mrow><mo>*</mo></msubsup><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mtext>t</mtext><mtext>e</mtext><mtext>s</mtext><mtext>t</mtext></mrow></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="151">CASIA FASD数据库仅有测试集和训练集, 采用准确率和ROC曲线及测试集EER评判算法分类性能.Replay-Attack数据库由训练集、验证集和测试集组成, 采用测试集HTER评判算法分类性能.</p>
                </div>
                <div class="p1">
                    <p id="152">对比方法包括静态纹理LBP、WLD、WLBP和动态纹理LBP-TOP、三正交平面的韦伯局部描述子 (WLD from Three Orthogonal Planes, WLD-TOP) .6种方法的准确率对比结果如表2所示.</p>
                </div>
                <div class="p1">
                    <p id="153">以CASIA FASD数据库 (训练集ID: C1-C20、测试集ID: C21-C50) 为例, 由表2可知, WLBP融合互补性的LBP和WLD算子, 相比LBP、WLD算子, 可以提取更丰富的纹理信息, 取得更高的识别准确率.因此, 融合时域、空域信息的特征描述子比原始特征描述子具有更强鲁棒性.LBP-TOP比LBP提升1.98%, WLD-TOP比WLD提升3.37%, 本文方法比WLBP提升1.83%.总体上, 本文方法正确率达到91.45%, 相比WLBP和其它主流方法, 具有明显提升.在Replay-Attack数据库上, 本文方法获得99.81%的识别率.由此可见, 将时域、空域的纹理进行融合, 增加所提特征的有效性, 适用于活体人脸检测任务.</p>
                </div>
                <div class="area_img" id="154">
                    <p class="img_tit"><b>表2</b><b>6种方法在2个数据库上的准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Accuracy comparison of 6 methods on 2 databases %</p>
                    <p class="img_note"></p>
                    <table id="154" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="2"><br />CASIA FASD</td><td colspan="2"><br />Replay-Attack</td></tr><tr><td><br />训练集 (ID:C1-C20) <br />测试集 (ID:C21-C50) </td><td>训练集 (ID:C21-C50) <br />测试集 (ID:C1-C20) </td><td><br />训练集 (ID:Train) <br />测试集 (ID:Test) </td><td>训练集 (ID:Test) <br />测试集 (ID:Train) </td></tr><tr><td><br />LBP</td><td>80.35</td><td>76.50</td><td>84.75</td><td>81.21</td></tr><tr><td><br />LBP-TOP</td><td>82.33</td><td>79.37</td><td>92.61</td><td>91.81</td></tr><tr><td><br />WLD</td><td>85.13</td><td>85.61</td><td>-</td><td>-</td></tr><tr><td><br />WLBP</td><td>89.62</td><td>91.80</td><td>-</td><td>-</td></tr><tr><td><br />WLD-TOP</td><td>88.50</td><td>87.60</td><td>-</td><td>-</td></tr><tr><td><br />本文方法</td><td><b>91.45</b></td><td><b>94.38</b></td><td><b>99.81</b></td><td><b>99.15</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="155">图3为不同方法在CASIA FASD数据库上的ROC曲线.从ROC曲线可看出, 本文方法在10<sup>-3</sup>～10<sup>-2</sup>之间, 性能曲线呈大幅度上升, 真正率高于LBP、LBP-TOP、WLD和WLBP, 由此表明本文方法具有较高的鲁棒性.</p>
                </div>
                <div class="p1">
                    <p id="156">为了进一步验证本文方法的有效性, 增加对比方法如下:局部相位量化 (Local Phase Quantization, LPQ) <citation id="221" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、动态模式分解 (Dynamic Mode Decompo-sition, DMD) <citation id="219" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、高斯差分 (Difference of Gaussian, DoG) <citation id="220" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、局部感受野的极限学习机 (Local Receptive Fields-Extreme Learning Machine, LRF-ELM) <citation id="222" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、卷积神经网络 (Convolution Neural Network, CNN) <citation id="224" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、图像质量评估 (Image Quality Assessment, IQA) <citation id="218" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、深度卷积神经网络 (Deep CNN, DCNN) <citation id="223" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>.各方法在无背景人脸数据库中HTER和EER值如表3所示.</p>
                </div>
                <div class="p1">
                    <p id="157">由表3可见, 本文方法在CASIA FASD数据库上的EER值从最高32.4%降至9.36%, 降低23.04%.在Replay-Attack数据库上, EER值从最高25.3%降至0.73%, 降低24.57%.HTER值从最高31.1%降至1.45%, 降低29.65%.在CASIA FASD数据库上, 本文方法EER值为9.36%.在Replay-Attack数据库上, 本文方法EER值为0.73%、HTER值为1.45%.因此, 本文方法结合LBP算子和Prewitt算子的WLD纹理特征, 同时挖掘时空域信息, 在活体人脸检测方面具有较好的鲁棒性.</p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902003_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 6种方法的ROC曲线对比" src="Detail/GetImg?filename=images/MSSB201902003_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 6种方法的ROC曲线对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902003_158.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 ROC curve comparison of 6 methods</p>

                </div>
                <div class="area_img" id="159">
                    <p class="img_tit"><b>表3</b><b>10种方法在2个数据库上的EER和HTER对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Comparison of EER and HTER of 10 methods on 2 databases %</p>
                    <p class="img_note"></p>
                    <table id="159" border="1"><tr><td rowspan="2"><br />方法</td><td><br />CASIA FASD</td><td colspan="2"><br />Replay-Attack</td></tr><tr><td><br />EER</td><td><br />EER</td><td>HTER</td></tr><tr><td><br />LBP</td><td>25.4</td><td>18.0</td><td>14.6</td></tr><tr><td><br />LBP-TOP</td><td>23.9</td><td>8.5</td><td>10.5</td></tr><tr><td><br />LPQ</td><td>22.6</td><td>25.3</td><td>31.1</td></tr><tr><td><br />DMD</td><td>21.8</td><td>5.3</td><td>3.8</td></tr><tr><td><br />DoG</td><td>17</td><td>-</td><td>-</td></tr><tr><td><br />LRF-ELM</td><td>11.25</td><td>-</td><td>-</td></tr><tr><td><br />CNN</td><td>7.4</td><td>6.1</td><td>2.1</td></tr><tr><td><br />IQA</td><td>32.4</td><td>-</td><td>15.2</td></tr><tr><td><br />DCNN</td><td>10</td><td>-</td><td>-</td></tr><tr><td><br />本文方法</td><td>9.36</td><td>0.73</td><td>1.45</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="160" name="160" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="161">本文提出基于时空纹理特征级联的人脸活体检测方法, 融合时域、空域中提取的纹理特征, 用于活体人脸检测.实验表明, 相比现有主流局部纹理特征算法, 本文方法识别率更高, 鲁棒性更强, 实际应用价值更好.同时, 人脸活体检测在实际应用中还需考虑更多的干扰因素, 如视频中人脸偏移过大、夹杂摄像头噪声等, 这些都是后续研究的重点.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="15">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the vulnerability of face recognition systems to spoofing mask attacks">

                                <b>[1]</b> KOSE N, DUGELAY J L. On the Vulnerability of Face Recognition Systems to Spoofing Mask Attacks // Proc of the IEEE International Conference on Acoustics, Speech and Signal Processing. Washington, USA: IEEE, 2013: 2357-2361.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXCN201407012&amp;v=MTE4OTQ5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5em5VTC9QUFRYSVlMRzRIOVhNcUk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 曹瑜, 涂玲, 毋立芳.身份认证中灰度共生矩阵和小波分析的活体人脸检测算法.信号处理, 2014, 30 (7) : 830-835. (CAO Y, TU L, WU L F. Face Liveness Detection Using Gray Level Co-occurrence Matrix and Wavelets Analysis in Identity Authentication. Journal of Signal Processing, 2014, 30 (7) : 830-835.) 
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201710003&amp;v=MTU4MDg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpuVUwvUFBUWGNkckc0SDliTnI0OUZaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 李冰, 王宝亮, 由磊, 等.应用并联卷积神经网络的人脸防欺骗方法.小型微型计算机系统, 2017, 38 (10) : 2187-2191. (LI B, WANG B L, YOU L, <i>et al</i>. Face Anti-spoofing Algorithm Applying with Parallel Convolutional Neural Network. Journal of Chinese Computer Systems, 2017, 38 (10) : 2187-2191.) 
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face liveness detection based on texture and frequency analyses">

                                <b>[4]</b> KIM G, EUM S, SUHR J K, <i>et al</i>. Face Liveness Detection Based on Texture and Frequency Analyses // Proc of the 5th IAPR International Conference on Biometrics. Washington, USA: IEEE, 2012:67-72.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Eyeblink-based Anti-spoofing in face recognition from a Generic Web-camera">

                                <b>[5]</b> PAN G, SUN L, WU Z H, <i>et al</i>. Eyeblink-Based Anti-spoofing in Face Recognition from a Generic Web Camera // Proc of the 11th IEEE International Conference on Computer Vision. Washington, USA: IEEE, 2007. DOI: 10.1109/ICCV.2007.4409068.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic Texture Recognition Using Local Binary Patterns with an Application to Facial Expressions">

                                <b>[6]</b> ZHAO G Y, PIETIKAINEN M. Dynamic Texture Recognition Using Local Binary Patterns with an Application to Facial Expressions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2007, 29 (6) : 915-928.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face Spoof Detection With Image Distortion Analysis">

                                <b>[7]</b> WEN D, HAN H, JAIN A K. Face Spoof Detection with Image Distortion Analysis. IEEE Transactions on Information Forensics and Security, 2015, 10 (4) : 746-761.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESAFDD8D9B6EDBEF0A715C57ABA395E342&amp;v=MTc5ODRScjZkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZod0xxOHdLOD1OaWZPZmNMT2FxWEUyNFkzWXA1N2ZnbFB6MmNVNnpvT1RYaVQzbU0yY0xmaA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> BASHIER H K, HOE L S, HUI L T, <i>et al</i>. Texture Classification via Extended Local Graph Structure. Optik, 2016, 127 (2) : 638-643.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LBP-TOP based countermeasure against face spoofing attacks">

                                <b>[9]</b> PEREIRA T D F, ANJOS A, DE MARTINO J M, <i>et al</i>. LBP-TOP Based Countermeasure Against Face Spoofing Attacks // Proc of the Asian Conference on Computer Vision. Berlin, Germany: Springer, 2012: 121-132.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD15042700000061&amp;v=MDExMDhESG80b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZ3WGFoVT1OajdCYXJLOUh0WE9xSTlGWk9zUA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> PEREIRA T D F, KOMULAINEN J, ANJOS A, <i>et al</i>. Face Liveness Detection Using Dynamic Texture. EURASIP Journal on Image and Video Processing, 2014. DOI:10.1186/1687-5281-2014-2.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=WLD: A Robust Local Image Descriptor">

                                <b>[11]</b> CHEN J, SHAN S G, HE C, <i>et al</i>. WLD: A Robust Local Image Descriptor. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2010, 32 (9) : 1705-1720.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13050900038781&amp;v=MDQ5NDRaZVp1SHlqbVVMYklKRndYYWhVPU5pZk9mYks3SHRUTXBvOUZaT2dIQzNRNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> LIU F, TANG Z M, TANG J H. WLBP: Weber Local Binary Pa-ttern for Local Image Description. Neurocomputing, 2013, 120: 325-335.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=WLD-TOP based algorithm against face spoofing attacks">

                                <b>[13]</b> MEI L, YANG D K, FENG Z X, <i>et al</i>. WLD-TOP Based Algorithm Against Face Spoofing Attacks // Proc of the Chinese Confe-rence on Biometric Recognition. Berlin, Germany: Springer, 2015: 135-142.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A face antispoofing database with diverse attacks">

                                <b>[14]</b> ZHANG Z W, YAN J J, LIU S F, <i>et al</i>. A Face Anti-spoofing Database with Diverse Attacks // Proc of the International Conference on Biometrics. Washington, USA: IEEE, 2012: 26-31.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face Anti-spoofing: Visual Approach">

                                <b>[15]</b> ANJOS A, KOMULAINEN J, MARCEL S, <i>et al</i>. Face Anti-spoofing: Visual Approach // MARCEL S, NIXON M S, LI S Z, eds. Handbook of Biometric Anti-spoofing. London, UK: Springer, 2014: 65-82.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Blur insensitive texture classification using local phase quantization">

                                <b>[16]</b> OJANSIVU V, HEIKKILA J. Blur Insensitive Texture Classification Using Local Phase Quantization // Proc of the 3rd International Conference on Image and Signal Processing. Berlin, Germany: Springer, 2008: 236-243.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 OJALA T, PIETIKAINEN M, MAEMPAA T. Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2002, 24 (7) : 971-987.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Scale space texture analysis for face anti-spoofing">

                                <b>[18]</b> BOULKENAFET Z, KOMULAINEN J, FEBG X Y, <i>et al</i>. Scale Space Texture Analysis for Face Anti-spoofings // Proc of the International Conference on Biometrics. Washington, USA: IEEE, 2016. DOI: 10.1109/ICB.2016.7550078.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Learning Based Face Liveness Detection in Videos">

                                <b>[19]</b> AKBULUT Y, ŞENGUR A, BUDAK Ü, <i>et al</i>. Deep Learning Based Face Liveness Detection in Videos // Proc of the Artificial Intelligence and Data Processing Symposium. Washington, USA: IEEE, 2017: 1-4.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face anti-spoofing based on general image quality assessment">

                                <b>[20]</b> GAKBALLY J, MARCEL S. Face Anti-spoofing Based on General Image Quality Assessment // Proc of the 22nd IEEE International Conference on Pattern Recognition. Washington, USA: IEEE, 2014: 1173-1178.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep face liveness detection based on nonlinear diffusion using convolution neural network">

                                <b>[21]</b> ALOTAIBI A, MAHMOOD A. Deep Face Liveness Detection Based on Nonlinear Diffusion Using Convolution Neural Network. Signal, Image and Video Processing, 2017, 11 (4) : 713-720.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201902003" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201902003&amp;v=MjU2ODI3WWJMRzRIOWpNclk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5em5VTC9NS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
