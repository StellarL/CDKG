<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131443879873750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201904003%26RESULT%3d1%26SIGN%3dD9d6ChwVYYnGmfxQJsZ9iFMhBbk%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201904003&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201904003&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201904003&amp;v=MTI4MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5em5XN3JCS0Q3WWJMRzRIOWpNcTQ5Rlo0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#70" data-title="1 李群流形上卡尔曼滤波的实时视频稳像算法 ">1 李群流形上卡尔曼滤波的实时视频稳像算法</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="2 李群流形上的在线运动优化 ">2 李群流形上的在线运动优化</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="&lt;b&gt;2.1&lt;/b&gt; 李群流形上的视频运动表示"><b>2.1</b> 李群流形上的视频运动表示</a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;2.2&lt;/b&gt; 基于流形上卡尔曼滤波的在线运动平滑"><b>2.2</b> 基于流形上卡尔曼滤波的在线运动平滑</a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;2.3&lt;/b&gt; 在线运动补偿"><b>2.3</b> 在线运动补偿</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#125" data-title="&lt;b&gt;3.1&lt;/b&gt; 实验设置"><b>3.1</b> 实验设置</a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;3.2&lt;/b&gt; 稳像结果对比"><b>3.2</b> 稳像结果对比</a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;3.3&lt;/b&gt; 运行时间性能对比"><b>3.3</b> 运行时间性能对比</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#141" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="图1 本文算法框架">图1 本文算法框架</a></li>
                                                <li><a href="#85" data-title="图2 李群流形上的视频运动表示">图2 李群流形上的视频运动表示</a></li>
                                                <li><a href="#175" data-title="图3 李群流形卡尔曼滤波与欧氏空间卡尔曼滤波对比">图3 李群流形卡尔曼滤波与欧氏空间卡尔曼滤波对比</a></li>
                                                <li><a href="#117" data-title="图4 运动补偿示意图">图4 运动补偿示意图</a></li>
                                                <li><a href="#120" data-title="图5 裁剪示意图">图5 裁剪示意图</a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表1 不同稳像算法的平均曲率值&lt;/b&gt;"><b>表1 不同稳像算法的平均曲率值</b></a></li>
                                                <li><a href="#177" data-title="图6 室外环境下特征点运动轨迹">图6 室外环境下特征点运动轨迹</a></li>
                                                <li><a href="#136" data-title="图7 室内环境下特征点运动轨迹">图7 室内环境下特征点运动轨迹</a></li>
                                                <li><a href="#140" data-title="&lt;b&gt;表2 不同稳像算法的单帧耗时和延迟帧数&lt;/b&gt;"><b>表2 不同稳像算法的单帧耗时和延迟帧数</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" PUGLISI G, BATTIATO S.A Robust Image Alignment Algorithm for Video Stabilization Purposes.IEEE Transactions on Circuits and Systems for Video Technology, 2011, 21 (10) :1390-1400." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Robust Image Alignment Algorithm for Video Stabilization Purposes">
                                        <b>[1]</b>
                                         PUGLISI G, BATTIATO S.A Robust Image Alignment Algorithm for Video Stabilization Purposes.IEEE Transactions on Circuits and Systems for Video Technology, 2011, 21 (10) :1390-1400.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 陈启立, 宋利, 余松煜.视频稳像技术综述.电视技术, 2011, 35 (7) :15-17. (CHEN Q L, SONG L, YU S Y.Overview of Video Stabilization Technology.Television Technology, 2011, 35 (7) :15-17.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201107009&amp;v=MjkzNDhIOURNcUk5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5em5XN3JCSVQ3WWZiRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈启立, 宋利, 余松煜.视频稳像技术综述.电视技术, 2011, 35 (7) :15-17. (CHEN Q L, SONG L, YU S Y.Overview of Video Stabilization Technology.Television Technology, 2011, 35 (7) :15-17.) 
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" MATSUSHITA Y, OFEK E, GE W N, &lt;i&gt;et al&lt;/i&gt;.Full-Frame Video Stabilization with Motion Inpainting.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (7) :1150-1163." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Full-Frame Video Stabilization with Motion Inpainting">
                                        <b>[3]</b>
                                         MATSUSHITA Y, OFEK E, GE W N, &lt;i&gt;et al&lt;/i&gt;.Full-Frame Video Stabilization with Motion Inpainting.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (7) :1150-1163.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" CHEN B Y, LEE K Y, HUANG W T, &lt;i&gt;et al&lt;/i&gt;.Capturing Intention-Based Full-Frame Video Stabilization.Computer Graphics Forum, 2008, 27 (7) :1805-1814." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Capturing Intention-based Full-Frame Video Stabilization">
                                        <b>[4]</b>
                                         CHEN B Y, LEE K Y, HUANG W T, &lt;i&gt;et al&lt;/i&gt;.Capturing Intention-Based Full-Frame Video Stabilization.Computer Graphics Forum, 2008, 27 (7) :1805-1814.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" LEE K Y, CHUANG Y Y, CHEN B Y, &lt;i&gt;et al&lt;/i&gt;.Video Stabilization using Robust Feature Trajectories // Proc of the 12th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2009:1397-1404." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Video stabilization using robust featuretrajectories">
                                        <b>[5]</b>
                                         LEE K Y, CHUANG Y Y, CHEN B Y, &lt;i&gt;et al&lt;/i&gt;.Video Stabilization using Robust Feature Trajectories // Proc of the 12th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2009:1397-1404.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" GOLDSTEIN A, FATTAL R.Video Stabilization Using Epipolar Geo-metry.ACM Transactions on Graphics, 2012, 31 (5) , DOI:10.1145/2231816.2231824." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000007762&amp;v=MjA3NDl0ak5yNDlGWk9zSUMzbzdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRndjYnhzPU5pZklZN0s3SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         GOLDSTEIN A, FATTAL R.Video Stabilization Using Epipolar Geo-metry.ACM Transactions on Graphics, 2012, 31 (5) , DOI:10.1145/2231816.2231824.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" WANG Y S, LIU F, HSU P S, &lt;i&gt;et al&lt;/i&gt;.Spatially and Temporally Optimized Video Stabilization.IEEE Transactions on Visualization and Computer Graphics, 2013, 19 (8) :1354-1361." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatially and temporally optimized video sta-bilization">
                                        <b>[7]</b>
                                         WANG Y S, LIU F, HSU P S, &lt;i&gt;et al&lt;/i&gt;.Spatially and Temporally Optimized Video Stabilization.IEEE Transactions on Visualization and Computer Graphics, 2013, 19 (8) :1354-1361.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" GRUNDMANN M, KWATRA V, ESSA I.Auto-Directed Video Stabilization with Robust L1 Optimal Camera Paths // Proc of the IEEE Interntational Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2011:225-232." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Auto-Directed Video Stabilization with Robust L1 Optimal Camera Paths">
                                        <b>[8]</b>
                                         GRUNDMANN M, KWATRA V, ESSA I.Auto-Directed Video Stabilization with Robust L1 Optimal Camera Paths // Proc of the IEEE Interntational Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2011:225-232.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" LIU F, GLEICHER M, WANG J, &lt;i&gt;et al&lt;/i&gt;.Subspace Video Stabilization.ACM Transactions on Graphics, 2011, 30 (1) .DOI:10.1145/1899404.1899408." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000004435&amp;v=MjgzMTRNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZ3Y2J4cz1OaWZJWTdLN0h0ak5yNDlGWk9zTENIODhvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         LIU F, GLEICHER M, WANG J, &lt;i&gt;et al&lt;/i&gt;.Subspace Video Stabilization.ACM Transactions on Graphics, 2011, 30 (1) .DOI:10.1145/1899404.1899408.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" LIU S C, YUAN L, TAN P, &lt;i&gt;et al&lt;/i&gt;.Bundled Camera Paths for Vi-deo Stabilization.ACM Transactions on Graphics, 2013, 32 (4) .DOI:10.1145/2461912.2461995." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13110500013495&amp;v=MjQzOTJaZVp1SHlqbVVMYklKRndjYnhzPU5pZklZN0s3SDlETXFvOUZaT29NQ0hVOG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1udw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         LIU S C, YUAN L, TAN P, &lt;i&gt;et al&lt;/i&gt;.Bundled Camera Paths for Vi-deo Stabilization.ACM Transactions on Graphics, 2013, 32 (4) .DOI:10.1145/2461912.2461995.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" CENSI A, FUSIELLO A, ROBERTO V.Image Stabilization by Feature Stracking // Proc of the 10th International Conference on Image Analysis and Processing.Washington, USA:IEEE, 1999:665-667." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Stabilization by Features Tracking">
                                        <b>[11]</b>
                                         CENSI A, FUSIELLO A, ROBERTO V.Image Stabilization by Feature Stracking // Proc of the 10th International Conference on Image Analysis and Processing.Washington, USA:IEEE, 1999:665-667.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" HU R, SHI R J SHEN I F, &lt;i&gt;et al&lt;/i&gt;.Video Stabilization Using Scale-Invariant Features // Proc of the 11th International Conference on Information Visualization.Washington, USA:IEEE, 2007:871-877." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Video Stabilization Using Scale-Invariant Features">
                                        <b>[12]</b>
                                         HU R, SHI R J SHEN I F, &lt;i&gt;et al&lt;/i&gt;.Video Stabilization Using Scale-Invariant Features // Proc of the 11th International Conference on Information Visualization.Washington, USA:IEEE, 2007:871-877.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" ZHOU M Q, ASARI V K.A Fast Video Stabilization System Based on Speeded-up Robust Features // Proc of the International Symposium on Visual Computing.Berlin, Germany:Springer, 2011:428-435." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Fast Video Stabilization System Based on Speeded-up Robust Features">
                                        <b>[13]</b>
                                         ZHOU M Q, ASARI V K.A Fast Video Stabilization System Based on Speeded-up Robust Features // Proc of the International Symposium on Visual Computing.Berlin, Germany:Springer, 2011:428-435.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" KARPENKO A, JACOBS D, BAEK J, &lt;i&gt;et al&lt;/i&gt;.Digital Video Stabilization and Rolling Shutter Correction Using Gyroscopes[T/OL].[2018-12-15].http://movement.stanford.edu/papers/stabilization/karpenko_gyro.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Digital Video Stabilization and Rolling Shutter Correction Using Gyroscopes[T/OL]">
                                        <b>[14]</b>
                                         KARPENKO A, JACOBS D, BAEK J, &lt;i&gt;et al&lt;/i&gt;.Digital Video Stabilization and Rolling Shutter Correction Using Gyroscopes[T/OL].[2018-12-15].http://movement.stanford.edu/papers/stabilization/karpenko_gyro.pdf.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" HANNING G, FORSL&#214;W N, FORSS&#201;N P E, &lt;i&gt;et al&lt;/i&gt;.Stabilizing Cell Phone Video Using Inertial Measurement Sensors // Proc of the IEEE International Conference on Computer Vision Workshops.Washington, USA:IEEE, 2011:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stabilizing cell phone video using inertial measurement sensors">
                                        <b>[15]</b>
                                         HANNING G, FORSL&#214;W N, FORSS&#201;N P E, &lt;i&gt;et al&lt;/i&gt;.Stabilizing Cell Phone Video Using Inertial Measurement Sensors // Proc of the IEEE International Conference on Computer Vision Workshops.Washington, USA:IEEE, 2011:1-8.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 李凡长, 康宇.基于Lie群的机器学习理论框架.云南民族大学学报 (自然科学版) , 2004, 13 (4) :251-255. (LI F Z, KANG Y.The Study of Machine Learning Theory Frame Based on Lie Group.Journal of Yunnan Nationalities University (Natural Sciences Edition) , 2004, 13 (4) :251-255.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YNMZ200404001&amp;v=MDU2ODFyQ1VSTE9lWmVSbkZ5em5XN3JCUENQR2RMRzRIdFhNcTQ5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         李凡长, 康宇.基于Lie群的机器学习理论框架.云南民族大学学报 (自然科学版) , 2004, 13 (4) :251-255. (LI F Z, KANG Y.The Study of Machine Learning Theory Frame Based on Lie Group.Journal of Yunnan Nationalities University (Natural Sciences Edition) , 2004, 13 (4) :251-255.) 
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" 李凡长, 钱旭培, 谢琳, 等.机器学习理论及应用.北京:中国科学技术大学出版社, 2009. (LI F Z, QIIAN X P, XIE L, &lt;i&gt;et al&lt;/i&gt;.Machine Learning and Its App-lications.Beijing, China:University of Science and Technology of China Press, 2009.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787312026362001&amp;v=MjY1NzNZeERadXNQRFJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3ZzVTd2S0tGc2RYRnF6R2JDNUhOSE9x&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         李凡长, 钱旭培, 谢琳, 等.机器学习理论及应用.北京:中国科学技术大学出版社, 2009. (LI F Z, QIIAN X P, XIE L, &lt;i&gt;et al&lt;/i&gt;.Machine Learning and Its App-lications.Beijing, China:University of Science and Technology of China Press, 2009.) 
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" ROS G, GUERRERO J, SAPPA A D, &lt;i&gt;et al&lt;/i&gt;.VSLAM Pose Initia-lization via Lie Groups and Lie Algebras Optimization // Proc of the IEEE International Conference on Robotics and Automation.Washington, USA:IEEE, 2013:5720-5727." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VSLAM pose initialization via Lie groups and Lie algebras optimization">
                                        <b>[18]</b>
                                         ROS G, GUERRERO J, SAPPA A D, &lt;i&gt;et al&lt;/i&gt;.VSLAM Pose Initia-lization via Lie Groups and Lie Algebras Optimization // Proc of the IEEE International Conference on Robotics and Automation.Washington, USA:IEEE, 2013:5720-5727.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" JIA C, EVANS B L.Constrained 3D Rotation Smoothing via Glo-bal Manifold Regression for Video Stabilization.IEEE Transactions on Signal Processing, 2014, 62 (13) :3293-3304." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Constrained 3D rotation smoothing via global manifold regression for video stabilization">
                                        <b>[19]</b>
                                         JIA C, EVANS B L.Constrained 3D Rotation Smoothing via Glo-bal Manifold Regression for Video Stabilization.IEEE Transactions on Signal Processing, 2014, 62 (13) :3293-3304.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" ZHANG L, CHEN X Q, KONG X Y, &lt;i&gt;et al&lt;/i&gt;.Geodesic Video Stabilizationin Transformation Space.IEEE Transactions on Image Processing, 2017, 26 (5) :2219-2229." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Geodesic video stabilization in transformation space">
                                        <b>[20]</b>
                                         ZHANG L, CHEN X Q, KONG X Y, &lt;i&gt;et al&lt;/i&gt;.Geodesic Video Stabilizationin Transformation Space.IEEE Transactions on Image Processing, 2017, 26 (5) :2219-2229.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" HELGASON S.Differential Geometry, Liegroups, and Symmetric Spaces.Providence, USA:American Mathematical Society, 2001." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Differential Geometry,Liegroups,and Symmetric Spaces">
                                        <b>[21]</b>
                                         HELGASON S.Differential Geometry, Liegroups, and Symmetric Spaces.Providence, USA:American Mathematical Society, 2001.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" WELCH G, BISHOP G.An Introduction to the Kalman Filter[C/OL].[2018-12-18].https://courses.cs.washington.edu/courses/cse571/00au/papers/welch-bishop-kalman.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Introduction to the Kalman Filter[C/OL]">
                                        <b>[22]</b>
                                         WELCH G, BISHOP G.An Introduction to the Kalman Filter[C/OL].[2018-12-18].https://courses.cs.washington.edu/courses/cse571/00au/papers/welch-bishop-kalman.pdf.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" LI L Y, MA X H, ZHAO Z N.Real-Time Video Stabilization Based on Fast Block Matching and Improved Kalman Filter // Proc of the 5th International Conference on Intelligent Control and Information Processing.Washington, USA:IEEE, 2014:394-397." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time video stabilization based on fast block matching and improved kalman filter">
                                        <b>[23]</b>
                                         LI L Y, MA X H, ZHAO Z N.Real-Time Video Stabilization Based on Fast Block Matching and Improved Kalman Filter // Proc of the 5th International Conference on Intelligent Control and Information Processing.Washington, USA:IEEE, 2014:394-397.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" ERTURK S.Real-Time Digital Image Stabilization Using Kalman Flters.Real-Time Imaging, 2002, 8 (4) :317-328." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501085131&amp;v=MDcyNjVMYklKRndjYnhzPU5pZk9mYks3SHRETnFvOUVaT01LRFg4NG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         ERTURK S.Real-Time Digital Image Stabilization Using Kalman Flters.Real-Time Imaging, 2002, 8 (4) :317-328.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" LIU S C, TAN P, YUAN L, &lt;i&gt;et al&lt;/i&gt;.Meshflow:Minimum Latency Online Video Stabilization // Proc of the European Conference on Computer Vision.Berlin, Germany:Springer, 2016:800-815." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mesh Flow:minimum latency online video stabilization">
                                        <b>[25]</b>
                                         LIU S C, TAN P, YUAN L, &lt;i&gt;et al&lt;/i&gt;.Meshflow:Minimum Latency Online Video Stabilization // Proc of the European Conference on Computer Vision.Berlin, Germany:Springer, 2016:800-815.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" ZHANG L, ZHENG Q Z, HUANG H.Intrinsic Motion Stability Assessment for Video Stabilization.IEEE Transactions on Visua-lization and Computer Graphics, 2019, 25 (4) :1681-1692." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Intrinsic Motion Stability Assessment for Video Stabilization">
                                        <b>[26]</b>
                                         ZHANG L, ZHENG Q Z, HUANG H.Intrinsic Motion Stability Assessment for Video Stabilization.IEEE Transactions on Visua-lization and Computer Graphics, 2019, 25 (4) :1681-1692.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(04),298-305 DOI:10.16451/j.cnki.issn1003-6059.201904002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>李群流形上的在线视频稳像算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E4%BD%B3%E4%B8%BD&amp;code=39803618&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨佳丽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A5%E6%9E%97%E9%9D%99&amp;code=35421576&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">来林静</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%A3%8A&amp;code=06354449&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张磊</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E5%8D%8E&amp;code=06337427&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄华</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0188644&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京理工大学计算机学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统视频稳像算法无法兼顾高质量稳像和低延时的问题, 提出李群流形上卡尔曼滤波的实时视频稳像算法.将视频帧间运动分解为旋转分量和平移分量.旋转分量由陀螺仪数据计算的旋转矩阵表示, 平移分量由视频帧间匹配得到的平移矩阵表示, 旋转矩阵的序列和平移矩阵的序列分别对应于李群流形上的运动路径.利用李群流形上的卡尔曼滤波分别对旋转分量和平移分量进行平滑.最终通过运动补偿获得稳定的视频帧序列.实验表明, 文中算法能够兼顾延时和稳像效果, 可以在移动端实现高质量的在线视频稳像.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A7%86%E9%A2%91%E7%A8%B3%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">视频稳像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9D%8E%E7%BE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李群;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8E%E5%BB%B6%E6%97%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">低延时;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%9E%E6%97%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">实时;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%A0%E6%84%9F%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">传感器;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨佳丽, 硕士研究生, 主要研究方向为图像与视频处理.E-mail:2120161068@bit.edu.cn.;
                                </span>
                                <span>
                                    *来林静 (通讯作者) , 硕士, 助理研究员, 主要研究方向为图像与视频处理、虚拟现实.E-mail:lljing@bit.edu.cn.;
                                </span>
                                <span>
                                    张磊, 博士, 副教授, 主要研究方向为图像与视频处理.E-mail:leizhang@bit.edu.cn.;
                                </span>
                                <span>
                                    黄华, 博士, 教授, 主要研究方向为图像与视频处理.E-mail:huahuang@bit.edu.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.61772069) 资助;</span>
                    </p>
            </div>
                    <h1><b>Online Video Stabilization Algorithm on Lie Group Manifold</b></h1>
                    <h2>
                    <span>YANG Jiali</span>
                    <span>LAI Linjing</span>
                    <span>ZHANG Lei</span>
                    <span>HUANG Hua</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Technology, Beijing Institute of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The traditional video stabilization algorithms cannot achieve good performance with a low latency. Aiming at this problem, an algorithm is proposed using the Lie group manifold based Kalman filter to stabilize videos in real time. The video frame motion is separated into rotation component and translation component. The rotation component can be represented by the rotation matrix obtained via the gyroscope data, while the translation component is provided by the translation matrix computed by the matching between video frames. Both the sequence of the rotation matrices and the translation matrices can form the motion paths on the Lie group manifold. Therefore, the Lie group manifold based Kalman filter is used to smooth the rotation and translation component, respectively. Finally, the video frame sequence can be stabilized by the motion compensation. The experimental results show that the proposed algorithm achieves high online real-time video stabilization performance on the mobile device.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Video%20Stabilization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Video Stabilization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Lie%20Group&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Lie Group;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Low%20Latency&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Low Latency;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Real%20Time&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Real Time;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sensor&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sensor;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YANG Jiali, master student, Her research interests include image and video processing.;
                                </span>
                                <span>
                                    LAI Linjing ( Corresponding author) , master, assistant researcher. Her research interests include image and video processing and virtual reality.;
                                </span>
                                <span>
                                    ZHANG Lei, Ph. D., associate professor. His research interests include image and video processing.;
                                </span>
                                <span>
                                    HUANG Hua, Ph.D., professor. His research interests include image and video processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-28</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.61772069);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="66">手机、数码相机等手持设备凭借便携性, 已成为人们在日常生活中拍摄视频的首选器材.然而, 这些设备在运动环境下拍摄的视频通常会存在画面抖动的问题.抖动的视频不仅影响人们对视频内容的观看, 也不利于后续处理.因此, 视频稳像技术具有重要的实际应用价值<citation id="144" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.常用的视频稳像技术主要有机械稳像、光学稳像和数字稳像三种<citation id="145" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.虽然机械稳像和光学稳像能够达到在线实时处理的效果, 但是存在携带不便或成本较高等问题.因此, 数字稳像成为处理抖动视频的重要方式.数字稳像大多基于帧间光流<citation id="147" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>或几何变换<citation id="148" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>进行运动估计, 然后利用泛函优化<citation id="146" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等方式进行路径平滑优化<citation id="149" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 最后采用逐帧变换进行运动补偿, 得到稳定视频.为了获得较好的运动估计及平滑效果, 传统数字稳像算法<citation id="150" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>往往需要较多的缓存帧, 不适合在线处理.</p>
                </div>
                <div class="p1">
                    <p id="67">目前的手机等移动设备普遍装配陀螺仪传感器.这种传感器可以读取瞬时三维运动信息, 从而辅助在线的实时视频稳像<citation id="153" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>.Karpenko等<citation id="151" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>使用陀螺仪解决手机应用中的数字视频防抖问题, 首先通过陀螺仪采集拍摄设备的三轴旋转信息并对运动建模, 然后使用低通滤波进行运动平滑, 最后将三维空间中的运动模型投影到图像平面实现稳像处理.Hanning等<citation id="152" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>使用加速度传感器和陀螺仪传感器, 采用3D旋转畸变模型进行运动估计, 并使用扩展卡尔曼滤波器进行运动平滑.然而, 基于低通滤波的运动平滑仍需要使用一定数量的缓存帧, 导致算法存在一些延时.此外, 结合陀螺仪的方案大多忽略平移运动, 导致近距离场景拍摄视频的稳像效果不佳.</p>
                </div>
                <div class="p1">
                    <p id="68">近年来, 李群在计算机视觉中有着越来越多的应用.李凡长等<citation id="157" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>将李群表示应用到机器学习算法中, 提出李群机器学习的理论框架, 为机器学习开辟新的分支.Ros等<citation id="154" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>利用李群和李代数的概念解决视觉同时定位与建图 (Simultaneous Localization and Mapping, SLAM) 中初始3D姿态的估计问题.对于视频稳像而言, 连续的位姿变换也可以表示为李群.Jia等<citation id="155" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>通过黎曼流形平滑旋转矩阵, 将运动平滑转换为非线性流形约束回归问题.Zhang等<citation id="156" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>利用几何变换表示视频帧间运动, 在李群空间利用测地优化的方法对帧间运动进行平滑, 获得稳定的视频.但是, 上述方法均需要大量的缓存帧, 无法满足低延时稳像的要求.</p>
                </div>
                <div class="p1">
                    <p id="69">摄像机在三维空间中运动时的投影产生视频序列.因此, 视频帧间运动需要考虑摄像机在三维空间旋转和平移运动产生的影响.本文基于运动几何变换的李群表示, 提出在李群流形上进行卡尔曼滤波的低延时在线视频稳像算法.对于陀螺仪获得的旋转分量, 建立李群流形上的3D旋转运动路径模型.对于图像分析得到的平移分量, 建立李群流形上的2D图像平移运动路径模型.在此基础上, 利用几何变换所在李群流形空间的卡尔曼滤波分别对旋转矩阵和平移矩阵进行路径平滑.由于运动平滑时使用卡尔曼滤波, 可以对获取的帧进行即时处理, 满足低延时的要求.而借助运动几何变换内在流形表示, 能够保证优化结果的有效性, 实现高质量的稳像效果.实验表明, 本文算法稳像效果优于对比算法, 仅存在一帧的延迟, 能够满足低延时的要求.</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag">1 李群流形上卡尔曼滤波的实时视频稳像算法</h3>
                <div class="p1">
                    <p id="71">李群流形上卡尔曼滤波的实时视频稳像算法总体框架如图1所示, 具体分为如下三部分.</p>
                </div>
                <div class="p1">
                    <p id="72">1) 帧间运动估计.将运动分为旋转分量和平移分量两部分.在视频拍摄的同时采集陀螺仪的数据, 对于旋转分量, 利用陀螺仪给出的瞬时旋转角速度, 计算三维旋转矩阵, 对旋转分量进行建模.对于平移分量, 利用帧间图像特征点检测和匹配的算法, 计算平移变换矩阵, 对平移分量进行建模.</p>
                </div>
                <div class="p1">
                    <p id="73">2) 流形上运动路径平滑.旋转矩阵和平移矩阵各自按照时间顺序排列形成运动路径.在数学上, 旋转矩阵序列和平移矩阵序列分别对应于李群流形上的曲线.利用基于李群空间的卡尔曼滤波分别对旋转和平移变换矩阵序列进行平滑优化, 得到稳定的运动路径.</p>
                </div>
                <div class="p1">
                    <p id="74">3) 运动补偿.根据平滑前后的运动路径计算抖动视频逐帧对应的补偿变换矩阵, 经过变换后得到稳定的视频帧序列.</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904003_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法框架" src="Detail/GetImg?filename=images/MSSB201904003_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904003_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Framework of the proposed algorithm</p>

                </div>
                <h3 id="76" name="76" class="anchor-tag">2 李群流形上的在线运动优化</h3>
                <h4 class="anchor-tag" id="77" name="77"><b>2.1</b> 李群流形上的视频运动表示</h4>
                <div class="p1">
                    <p id="78">视频的运动轨迹由视频帧间的变换矩阵表示.将输入的视频帧序列表示为<b><i>I</i></b><sub>1</sub>, <b><i>I</i></b><sub>2</sub>, …, <b><i>I</i></b><sub><i>n</i></sub> (<i>n</i>为视频的帧数) .<b><i>I</i></b><sub><i>t</i>-1</sub>与<b><i>I</i></b><sub><i>t</i></sub> (<i>t</i>=1, 2, …, <i>n</i>) 的帧间变换可以由变换矩阵<b><i>H</i></b><sub><i>t</i></sub>表示, 即<b><i>I</i></b><sub><i>t</i></sub>=<b><i>I</i></b><sub><i>t</i>-1</sub><b><i>H</i></b><sub><i>t</i></sub>.定义视频帧<b><i>I</i></b><sub><i>t</i></sub>对应的相机原始运动路径为<b><i>C</i></b><sub><i>t</i></sub>, 表示从第1帧到第<i>t</i>帧之间运动信息的累积, 即<b><i>I</i></b><sub><i>t</i></sub>=<b><i>I</i></b><sub>1</sub><b><i>C</i></b><sub><i>t</i></sub>.当<i>t</i>=1时, <b><i>C</i></b><sub>1</sub>为单位矩阵.因此, 视频的运动路径可表示为</p>
                </div>
                <div class="p1">
                    <p id="79"><b><i>C</i></b><sub><i>t</i></sub>=<b><i>C</i></b><sub><i>t</i>-1</sub><b><i>H</i></b><sub><i>t</i></sub>=<b><i>H</i></b><sub>1</sub><b><i>H</i></b><sub>2</sub>…<b><i>H</i></b><sub><i>t</i></sub>.      (1) </p>
                </div>
                <div class="p1">
                    <p id="80">变换矩阵<b><i>H</i></b><sub><i>t</i></sub>包含完整的三维空间中旋转分量在图像上的投影<b><i>R</i></b><sub><i>t</i></sub>和平面内的平移分量<b><i>D</i></b><sub><i>t</i></sub>.通过分解变换矩阵<b><i>H</i></b><sub><i>t</i></sub>, 可得到旋转矩阵在图像上的投影矩阵<b><i>R</i></b><sub><i>t</i></sub>和平移矩阵<b><i>D</i></b><sub><i>t</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="81"><b><i>H</i></b><sub><i>t</i></sub>=<b><i>D</i></b><sub><i>t</i></sub><b><i>R</i></b><sub><i>t</i></sub>.      (2) </p>
                </div>
                <div class="p1">
                    <p id="82">摄像机在三维空间的旋转运动可以通过陀螺仪获得.在视频拍摄时, 陀螺仪记录相机在三维空间坐标系下的旋转角速度<i>ω</i>= (<i>ω</i><sub><i>x</i></sub>, <i>ω</i><sub><i>y</i></sub>, <i>ω</i><sub><i>z</i></sub>) <sup>T</sup>.因此, 使用陀螺仪的采样时间间隔<i>Δt</i>, 计算设备的旋转角度, 记为<i>θ</i>= (<i>θ</i><sub><i>x</i></sub>, <i>θ</i><sub><i>y</i></sub>, <i>θ</i><sub><i>z</i></sub>) <sup>T</sup>=<i>Δtω</i>.进一步, 旋转角度<i>θ</i><sub><i>x</i></sub>、<i>θ</i><sub><i>y</i></sub>、<i>θ</i><sub><i>z</i></sub>对应的旋转矩阵<b><i>R</i></b>′可通过如下欧拉公式计算:</p>
                </div>
                <div class="p1">
                    <p id="83" class="code-formula">
                        <mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><msup><mi mathvariant="bold-italic">R</mi><mo>′</mo></msup><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub><mo>-</mo><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub></mtd><mtd><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub><mo>+</mo><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub></mtd><mtd><mo>-</mo><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub></mtd></mtr><mtr><mtd><mo>-</mo><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub></mtd><mtd><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub></mtd><mtd><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub></mtd></mtr><mtr><mtd><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub><mo>+</mo><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub></mtd><mtd><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub><mo>-</mo><mi>sin</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>z</mi></msub></mtd><mtd><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>cos</mi><mi>θ</mi><msub><mrow></mrow><mi>y</mi></msub></mtd></mtr></mtable><mo>.</mo></mrow></mrow></mrow><mo>〗</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="84">旋转矩阵<b><i>R</i></b>′的序列对应于相邻帧间三维旋转变换的序列.旋转矩阵作为特殊正交群, 满足李群的定义<citation id="158" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>.数学上矩阵的集合对应的乘法和求逆运算是光滑的, 对应于李群流形结构.如图2所示, 相机在三维空间中的旋转运动可以映射为李群上的曲线.</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904003_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 李群流形上的视频运动表示" src="Detail/GetImg?filename=images/MSSB201904003_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 李群流形上的视频运动表示  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904003_085.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Video motion representation on Lie group manifold</p>

                </div>
                <div class="p1">
                    <p id="86">利用相机成像模型, 可以将相机坐标系中的旋转矩阵映射到图像平面, 得到像素坐标系中的旋转自由度表达式<b><i>R</i></b>=<b><i>KR</i></b>′<b><i>K</i></b><sup>-1</sup>, 其中<b><i>K</i></b>为相机内参矩阵.</p>
                </div>
                <div class="p1">
                    <p id="87">因为利用加速度传感器对平移建模需要二次积分运算, 二次积分运算带来的误差很大, 所以本文仅考虑图像平面内的平移.采用特征点匹配的算法在图像平面内提取匹配的特征点, 通过特征点的轨迹对平移进行建模, 平移运动对应的变换矩阵</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">D</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mi>d</mi><msub><mrow></mrow><mi>x</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mi>d</mi><msub><mrow></mrow><mi>y</mi></msub></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中<i>d</i><sub><i>x</i></sub>、<i>d</i><sub><i>y</i></sub>分别为像素坐标系内沿水平方向、垂直方向的平移量.</p>
                </div>
                <div class="p1">
                    <p id="90">数学上平移变换构成的集合作为特殊欧氏群, 同样满足李群定义<citation id="159" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, <b><i>D</i></b>的集合同样对应于李群流形结构.图像的平移运动同样可以映射为李群流形结构上的曲线.</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>2.2</b> 基于流形上卡尔曼滤波的在线运动平滑</h4>
                <div class="p1">
                    <p id="92">在视频稳像中, 既要求当前视频帧所处运动轨迹与前一帧的运动轨迹尽可能接近, 又要求当前时刻平滑后的运动轨迹与原始运动轨迹尽可能接近.卡尔曼滤波<citation id="160" type="reference"><link href="45" rel="bibliography" /><link href="47" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>利用递推估计, 通过状态变量前一时刻的估计值预测当前时刻, 然后使用当前时刻的观测值更新状态变量的预测值, 得到当前时刻的估计值.其中, 前一帧的运动轨迹对应于卡尔曼滤波中前一时刻的估计值.基于前一帧运动轨迹预测得到的当前帧运动轨迹对应于卡尔曼滤波中当前时刻的预测值.当前帧原始运动轨迹对应于当前时刻卡尔曼滤波的测量值.因此, 卡尔曼滤波可以有效应用于视频稳像的运动平滑优化.</p>
                </div>
                <div class="p1">
                    <p id="93">传统视频稳像中的卡尔曼滤波通常仅考虑图像平面内的平移和旋转, 并且仅在欧氏空间上进行滤波, 存在稳像效果不理想的问题.本文使用李群流形上的卡尔曼滤波优化视频路径.整体考虑空间中的三轴运动和平面内的两轴运动.利用李群流形上的卡尔曼滤波分别对旋转分量和平移分量进行平滑, 可得到稳定后的运动路径.</p>
                </div>
                <div class="p1">
                    <p id="94">在优化运动路径时, 本文使用位置静止的预测模型对运动路径进行平滑, 以反映瞬时旋转和平移运动.静止的预测模型对应于当前时刻位姿与前一时刻位姿尽可能接近的要求.利用卡尔曼滤波对运动路径做优化的预测模型如下:</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">q</mi><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">其中:<b><i>x</i></b><sub><i>t</i>-1|<i>t</i>-1</sub>为第<i>t</i>-1帧对应状态量的估计值, 旋转分量对应三维旋转矩阵<b><i>R</i></b>′<sub><i>t</i>-1</sub>, 平移分量对应二维平移矩阵<b><i>D</i></b><sub><i>t</i>-1</sub>;<b><i>x</i></b><sub><i>t</i>|<i>t</i>-1</sub>为第<i>t</i>帧对应的状态量的预测值, <b><i>P</i></b><sub><i>t</i>-1|<i>t</i>-1</sub>为第<i>t</i>-1帧对应的状态协方差矩阵, <b><i>P</i></b><sub><i>t</i>|<i>t</i>-1</sub>为第<i>t</i>帧对应的状态协方差矩阵的预测值, <b><i>q</i></b>为系统预测噪声的协方差.</p>
                </div>
                <div class="p1">
                    <p id="97">通过陀螺仪读数计算得到旋转矩阵和通过特征点计算得到的平移矩阵, 它们分别作为旋转分量和平移分量使用的卡尔曼滤波的测量值.卡尔曼滤波的更新模型为</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>/</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">r</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mrow><mo stretchy="false">[</mo><mi>l</mi><mi>o</mi><mi>g</mi><msub><mrow></mrow><mi mathvariant="bold-italic">G</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo></mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">G</mi><mrow><msup><mrow></mrow><mo>∨</mo></msup></mrow></msubsup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mi>e</mi><mi>x</mi><mi>p</mi><msub><mrow></mrow><mi mathvariant="bold-italic">G</mi></msub><mo stretchy="false"> (</mo><mo stretchy="false">[</mo><mi>m</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><msubsup><mrow></mrow><mi mathvariant="bold-italic">G</mi><mrow><msup><mrow></mrow><mo>∧</mo></msup></mrow></msubsup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ι</mi><mi mathvariant="bold-italic">d</mi><mo>-</mo><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo stretchy="false">|</mo><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">其中:<b><i>K</i></b><sub><i>t</i></sub>为第<i>t</i>帧对应的卡尔曼增益;<b><i>r</i></b>为测量噪声的协方差;<b><i>x</i></b><sub><i>t</i></sub>为第<i>t</i>帧对应的状态量的测量值;<b><i>x</i></b><sub><i>t</i>|<i>t</i></sub>为第<i>t</i>帧对应的状态量的估计值, 即为最终取值.<b><i>G</i></b>为当前的李群空间, 在矩阵李群<b><i>G</i></b>和李代数<i>g</i>之间存在矩阵的指数映射<i>exp</i><sub><b><i>G</i></b></sub>和对数映射<i>log</i><sub><b><i>G</i></b></sub>关系, <i>exp</i><sub><b><i>G</i></b></sub>:<i>g</i>→<b><i>R</i></b><sup><i>n</i>×<i>n</i></sup>和<i>log</i><sub><b><i>G</i></b></sub>:<b><i>R</i></b><sup><i>n</i>×<i>n</i></sup>→<i>g</i>.此外, 李代数<i>g</i>与一个<i>p</i>维矩阵李群<b><i>R</i></b><sup><i>p</i></sup>之间存在一个线性同构的关系, 该映射关系为<image id="174" type="formula" href="images/MSSB201904003_17400.jpg" display="inline" placement="inline"><alt></alt></image>.关于李代数的具体计算可参见文献<citation id="161" type="reference">[<a class="sup">21</a>]</citation></p>
                </div>
                <div class="p1">
                    <p id="100">经过李群流形上卡尔曼滤波的处理, 得到平滑的三维旋转矩阵<mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mover accent="true"><mi mathvariant="bold-italic">R</mi><mo>˜</mo></mover><mo>′</mo></msup><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>和平滑的二维平移矩阵<mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">D</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>.由式 (1) 和式 (2) 可得到滤波后的平滑运动轨迹<mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="104">使用李群流形上的卡尔曼滤波能够获得比欧氏空间中卡尔曼滤波更好的平滑效果, 这得益于李群流形比欧氏空间更严格的平滑定义.通过李群流形上卡尔曼滤波处理后的运动轨迹满足李群内在黎曼度量下的光滑路径, 从而能够得到更好的平滑效果.</p>
                </div>
                <div class="p1">
                    <p id="105">为了展示本文算法的平滑效果, 对比本文算法与欧氏空间中的卡尔曼滤波算法.分别使用本文算法和欧氏空间中卡尔曼算法对实验视频的旋转矩阵序列和平移矩阵序列进行平滑处理.在使用欧氏空间中的卡尔曼滤波算法时, 对矩阵的9个元素进行滤波平滑.</p>
                </div>
                <div class="p1">
                    <p id="106">图3为使用两种方法处理后视频的运动路径.由图可以看出, 使用欧氏空间中卡尔曼滤波处理后的运动轨迹仍存在一定程度的抖动, 而使用李群流形上卡尔曼滤波处理后的轨迹连续且平滑.这说明李群流形上卡尔曼滤波的平滑效果优于欧氏空间中的卡尔曼滤波.</p>
                </div>
                <div class="area_img" id="175">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904003_17500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 李群流形卡尔曼滤波与欧氏空间卡尔曼滤波对比" src="Detail/GetImg?filename=images/MSSB201904003_17500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 李群流形卡尔曼滤波与欧氏空间卡尔曼滤波对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904003_17500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Comparison of Kalman filter on euclidean space and Kalman filter on Lie group</p>

                </div>
                <h4 class="anchor-tag" id="112" name="112"><b>2.3</b> 在线运动补偿</h4>
                <div class="p1">
                    <p id="113">得到原始的视频运动轨迹<b><i>C</i></b><sub><i>t</i></sub>和平滑后的视频运动轨迹<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>后, 计算补偿矩阵<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">C</mi><msubsup><mrow></mrow><mi>t</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mover accent="true"><mi mathvariant="bold-italic">C</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>, 利用补偿矩阵对当前的原始视频帧<b><i>I</i></b><sub><i>t</i></sub>进行变换, 得到稳定后的视频帧<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mi>t</mi></msub><mi mathvariant="bold-italic">B</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>.运动补偿过程如图4所示.</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904003_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 运动补偿示意图" src="Detail/GetImg?filename=images/MSSB201904003_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 运动补偿示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904003_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Illustration of motion compensation</p>

                </div>
                <div class="p1">
                    <p id="118">通过变换后得到的稳定视频帧<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Ι</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>往往会存在一些黑边, 因此需要对补偿后的视频帧进行裁剪.裁剪过程如图5所示.为了保持视频帧尺寸的统一, 需要预先设定剪裁率.本文将剪裁率设置为0.8, 即对于原始长宽分别为<i>h</i>、<i>w</i>的视频帧, 剪裁后的长为0.8<i>h</i>, 宽为0.8<i>w</i>.</p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904003_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 裁剪示意图" src="Detail/GetImg?filename=images/MSSB201904003_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 裁剪示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904003_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Illustration of cropping</p>

                </div>
                <div class="p1">
                    <p id="121">在对视频帧进行补偿时, 需要保证变换后的视频帧不会在剪裁窗口内出现黑边, 这就需要控制视频帧的变换.通过算法计算的理想补偿矩阵为<b><i>B</i></b><sub><i>t</i></sub>, 使用其对视频帧进行变换可以得到理想的稳定视频帧.在理想补偿矩阵为单位矩阵<b><i>Id</i></b>时, 存在<b><i>I</i></b><sub><i>t</i></sub>=<b><i>I</i></b><sub><i>t</i></sub><b><i>Id</i></b>, 视频帧不会发生任何变化.本文的剪裁控制算法对补偿矩阵<b><i>B</i></b><sub><i>t</i></sub>和单位矩阵<b><i>Id</i></b>进行插值, 在理想补偿矩阵和单位矩阵之间找到一个既可以保证稳像效果, 又能保证剪裁后无黑边出现的新变换矩阵, 即</p>
                </div>
                <div class="area_img" id="176">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201904003_17600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="123">其中, <i>s</i>为插值的参数, 文中首先取<i>s</i>=1, 若此刻满足剪裁框内无黑边, 则<i>s</i>=1.若此刻剪裁框内仍存在黑边, 调整<i>s</i>的值为<i>s</i>-0.1, 即<i>s</i>=0.9, 继续判断剪裁框内是否存在黑边, 若此刻剪裁框内仍存在黑边, 则继续调整<i>n</i>的值为<i>s</i>-0.1, 直到<i>s</i>的取值满足剪裁框内无黑边为止.因为计算量非常小, 所以仍能够快速进行运动补偿, 不影响整体稳像的实时性.</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag">3 实验及结果分析</h3>
                <h4 class="anchor-tag" id="125" name="125"><b>3.1</b> 实验设置</h4>
                <div class="p1">
                    <p id="126">为了保证用于对比实验的视频的有效性和多样性, 使用手机实际采集两大类抖动视频:室内拍摄视频和室外拍摄视频, 作为实验数据, 其中每大类视频中又包括站立拍摄、行走拍摄两小类视频, 共计30段视频.采集到的视频帧分辨率为720×1 280, 帧率为30 fps.为了验证本文算法的有效性, 选取近年来具有代表性的3种在线低延时稳像算法进行对比, 包括Ertürk等<citation id="162" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>提出的基于卡尔曼滤波的稳像算法 (简记为Kalman filtering) 、Liu等<citation id="163" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>提出的基于网格流的稳像算法MeshFlow、拥有五轴防抖功能的商业软件MuseMage (http://www.musemage.com) .</p>
                </div>
                <div class="p1">
                    <p id="127">本文算法通过Matlab模拟实现在线实时处理过程.为了保证对比实验的公平性, 本文算法、卡尔曼滤波算法、MeshFlow均在一台配置为Inteli5-45904核处理器, 主频为3.30 GHz, 内存为8 GB的计算机上运行.由于MuseMage以APP的形式发布并通过APP的形式展示视频稳像效果, 因此, 选择将App安装在拥有A11处理器的iPhone X手机上进行实验.</p>
                </div>
                <div class="p1">
                    <p id="128">本文算法需要陀螺仪数据的辅助, 因此需要在采集实验视频时, 同时记录陀螺仪读数.算法在输入阶段同时捕获带有时间戳的视频帧和带有时间戳的陀螺仪数据, 并通过Karpenko等<citation id="164" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出的算法进行同步, 以获取有效的陀螺仪运动数据.陀螺仪数据的采样频率为100 Hz.</p>
                </div>
                <h4 class="anchor-tag" id="129" name="129"><b>3.2</b> 稳像结果对比</h4>
                <div class="p1">
                    <p id="130">Zhang等<citation id="165" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>提出无参考视频稳定评价方法, 获得的视频稳定评价结果与人眼主观评价结果的相关性达到97%.在使用评价方法时, 只需要输入稳定后的视频, 即可得到评价值.数值越小, 表示视频稳定效果越好.本文使用方法进行定量评价.在评价过程中, 选取30段视频作为样本, 对不同算法处理过的视频分别计算评价值, 最后将每种算法得到的30个结果分别对室内和室外两类场景求取平均值, 得到最终的评价结果.</p>
                </div>
                <div class="p1">
                    <p id="131">表1为不同稳像算法的定量评价结果.可以看出, 本文算法不论在室内还是室外条件下的数值都很小, 明显优于其它算法.说明无论是在室内环境还是室外环境下, 本文算法都能取得较好的稳像效果.这得益于本文算法同时考虑抖动的旋转分量和平移分量, 即使是在室内近景中平移抖动更明显的情况下, 算法仍能拥有鲁棒的稳像效果.此外, 本文算法在李群空间求解平滑路径, 相比欧氏空间, 能够得到一个更精简的域, 确保得到正确的解析解.卡尔曼滤波算法和MeshFlow仅考虑运动在图像平面内的自由度, 相比本文算法, 缺失较多信息, 导致稳像效果不理想.MuseMage虽然为五轴防抖, 但其平滑度定义在欧氏空间, 李群空间中的测地线比欧氏空间中的直线更平滑, 因此本文算法能够得到更好的稳像效果.</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表1 不同稳像算法的平均曲率值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Average curvature value of different image stabilization algorithms</p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><br />视频稳像算法</td><td>室内</td><td>室外</td></tr><tr><td><br />卡尔曼滤波</td><td>1.396</td><td>1.385</td></tr><tr><td><br />MeshFlow</td><td>1.342</td><td>1.338</td></tr><tr><td><br />MuseMage</td><td>1.428</td><td>1.419</td></tr><tr><td><br />本文算法</td><td>1.329</td><td>1.323</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="133">为了能够直观展示视频稳像算法的效果, 采用特征点跟踪的可视化显示视频帧特征点运动轨迹.从任一视频中选取50帧进行特征点跟踪, 保证能够充分刻画特征点的运动轨迹, 同时避免特征点过多而影响直观展示效果.需要注意的是, 本文对这4种算法处理后的视频分别独立提取特征点并跟踪.因此, 图中所示的特征点位置在这四幅图像中并不相同.视频越稳定, 特征点的移动越小.当特征点固定在一点上时, 稳像效果最好.图6和图7分别为室外、室内环境下4种算法通过特征点跟踪绘制的特征点运动轨迹, 其中特征点使用白色的点表示.</p>
                </div>
                <div class="p1">
                    <p id="134">由图6和图7可以看出, 卡尔曼滤波处理后的视频特征点为一条杂乱的曲线, 说明其仍然存在一定程度的抖动, 稳像效果不理想.MeshFlow处理后的视频特征点轨迹较短但更杂乱, 说明存在幅度较小但不规则的抖动, 稳像效果仍然不够理想.MuseMage处理后的视频特征点轨迹较长且较杂乱, 说明抖动程度较严重, 稳像效果较差.本文算法处理后的视频, 特征点轨迹近乎为一个点, 几乎看不到任何方向上的运动, 说明该视频几乎不存在抖动, 稳像效果较好.通过实验对比可以直观看出, 不论在室内环境还是室外坏境, 本文算法的稳像效果都明显优于其它3种算法.</p>
                </div>
                <div class="area_img" id="177">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904003_17700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 室外环境下特征点运动轨迹" src="Detail/GetImg?filename=images/MSSB201904003_17700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 室外环境下特征点运动轨迹  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904003_17700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Feature point motion trajectories in outdoor environment</p>

                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904003_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 室内环境下特征点运动轨迹" src="Detail/GetImg?filename=images/MSSB201904003_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 室内环境下特征点运动轨迹  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904003_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Feature point motion trajectories in indoor environment</p>

                </div>
                <h4 class="anchor-tag" id="137" name="137"><b>3.3</b> 运行时间性能对比</h4>
                <div class="p1">
                    <p id="138">算法统一处理分辨率为1280×720的视频.表2为不同算法的运行速度.本文算法在处理分辨率为1280×720的视频时, 单帧的处理速度仅为20 ms, 可以满足实时处理的需求.由于在获得视频帧后需要计算平滑运动轨迹, 并对图像进行运动补偿, 本文算法存在1帧的延迟.从人眼观感角度来讲, 该延迟不会带来任何观感上的不适, 可以满足低延时的要求.本文算法能够拥有处理时间较短、延迟较低的性能得益于陀螺仪数据的辅助, 借助陀螺仪读数可以大幅减少运动估计过程中的计算量, 有助于算法的实时性和低延时性.</p>
                </div>
                <div class="p1">
                    <p id="139">MeshFlow在处理720×1280视频时无法达到实时要求, 但在处理720×480视频时可达到20 毫秒/帧的速度, 此时算法只有1帧的延迟.MuseMage和卡尔曼滤波算法在处理720×1280的视频时均可达到实时要求.MuseMage处理一帧的时间为35 ms, 卡尔曼滤波算法处理一帧仅需要20 ms, 这两种算法的延迟均为1帧.由实验数据可以看出, 在对比算法中, 本文算法所需的处理时间最短, 可以满足实时及低延时的视频稳像需求.</p>
                </div>
                <div class="area_img" id="140">
                    <p class="img_tit"><b>表2 不同稳像算法的单帧耗时和延迟帧数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Single frame time consumption and delaying frame number of different image stabilization algorithms</p>
                    <p class="img_note"></p>
                    <table id="140" border="1"><tr><td><br />视频稳像算法</td><td>视频分辨率<br />/像素</td><td>运行时间<br />/ms</td><td>延迟帧数</td></tr><tr><td><br />卡尔曼滤波</td><td>720×1280</td><td>25</td><td>1</td></tr><tr><td><br />MeshFlow</td><td>720×1280<br />480×720</td><td>50<br />20</td><td>-<br />1</td></tr><tr><td><br />MuseMage</td><td>720×1280</td><td>35</td><td>1</td></tr><tr><td><br />本文算法</td><td>720×1280</td><td>20</td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="141" name="141" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="142">本文提出将卡尔曼滤波扩展至李群流形空间的低延迟实时视频稳像算法.将视频帧间运动分为旋转分量和平移分量两部分.旋转分量通过陀螺仪传感器获得的旋转矩阵表示, 平移分量通过图像特征点运动获得的平移矩阵表示, 旋转和平移矩阵的集合分别对应于李群上的曲线.利用李群流形上的卡尔曼滤波分别对旋转分量和平移分量进行平滑, 得到稳定的运动轨迹.最后, 将原始帧进行运动补偿变换, 得到运动平稳的视频.采用流形上的卡尔曼滤波, 满足在线低延时处理的要求, 而且在李群流形空间上进行优化, 得到更平滑的运动轨迹.实验表明, 本文算法能够兼顾稳像效果和低延时性.</p>
                </div>
                <div class="p1">
                    <p id="143">但是, 本文算法仍然存在一些局限性, 需要进行后续更深入的研究.例如, 本文算法忽略抖动视频中通常会出现的果冻效应, 果冻效应的存在有时会使运动估计不精确, 并导致结果中出现一些高频抖动.这将是后续的研究问题.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="170" type="formula" href="images/MSSB201904003_17000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">杨佳丽</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="171" type="formula" href="images/MSSB201904003_17100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">来林静</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="172" type="formula" href="images/MSSB201904003_17200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">张磊</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="173" type="formula" href="images/MSSB201904003_17300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">黄华</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Robust Image Alignment Algorithm for Video Stabilization Purposes">

                                <b>[1]</b> PUGLISI G, BATTIATO S.A Robust Image Alignment Algorithm for Video Stabilization Purposes.IEEE Transactions on Circuits and Systems for Video Technology, 2011, 21 (10) :1390-1400.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DSSS201107009&amp;v=MDc0NTVGYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6blc3ckJJVDdZZmJHNEg5RE1xSTk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈启立, 宋利, 余松煜.视频稳像技术综述.电视技术, 2011, 35 (7) :15-17. (CHEN Q L, SONG L, YU S Y.Overview of Video Stabilization Technology.Television Technology, 2011, 35 (7) :15-17.) 
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Full-Frame Video Stabilization with Motion Inpainting">

                                <b>[3]</b> MATSUSHITA Y, OFEK E, GE W N, <i>et al</i>.Full-Frame Video Stabilization with Motion Inpainting.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2006, 28 (7) :1150-1163.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Capturing Intention-based Full-Frame Video Stabilization">

                                <b>[4]</b> CHEN B Y, LEE K Y, HUANG W T, <i>et al</i>.Capturing Intention-Based Full-Frame Video Stabilization.Computer Graphics Forum, 2008, 27 (7) :1805-1814.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Video stabilization using robust featuretrajectories">

                                <b>[5]</b> LEE K Y, CHUANG Y Y, CHEN B Y, <i>et al</i>.Video Stabilization using Robust Feature Trajectories // Proc of the 12th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2009:1397-1404.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000007762&amp;v=MTIxMzI2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGd2NieHM9TmlmSVk3SzdIdGpOcjQ5RlpPc0lDM283b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> GOLDSTEIN A, FATTAL R.Video Stabilization Using Epipolar Geo-metry.ACM Transactions on Graphics, 2012, 31 (5) , DOI:10.1145/2231816.2231824.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatially and temporally optimized video sta-bilization">

                                <b>[7]</b> WANG Y S, LIU F, HSU P S, <i>et al</i>.Spatially and Temporally Optimized Video Stabilization.IEEE Transactions on Visualization and Computer Graphics, 2013, 19 (8) :1354-1361.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Auto-Directed Video Stabilization with Robust L1 Optimal Camera Paths">

                                <b>[8]</b> GRUNDMANN M, KWATRA V, ESSA I.Auto-Directed Video Stabilization with Robust L1 Optimal Camera Paths // Proc of the IEEE Interntational Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2011:225-232.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000004435&amp;v=MTEwODF4cz1OaWZJWTdLN0h0ak5yNDlGWk9zTENIODhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRndjYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> LIU F, GLEICHER M, WANG J, <i>et al</i>.Subspace Video Stabilization.ACM Transactions on Graphics, 2011, 30 (1) .DOI:10.1145/1899404.1899408.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13110500013495&amp;v=MDM4MjBxbzlGWk9vTUNIVThvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRndjYnhzPU5pZklZN0s3SDlETQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> LIU S C, YUAN L, TAN P, <i>et al</i>.Bundled Camera Paths for Vi-deo Stabilization.ACM Transactions on Graphics, 2013, 32 (4) .DOI:10.1145/2461912.2461995.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Stabilization by Features Tracking">

                                <b>[11]</b> CENSI A, FUSIELLO A, ROBERTO V.Image Stabilization by Feature Stracking // Proc of the 10th International Conference on Image Analysis and Processing.Washington, USA:IEEE, 1999:665-667.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Video Stabilization Using Scale-Invariant Features">

                                <b>[12]</b> HU R, SHI R J SHEN I F, <i>et al</i>.Video Stabilization Using Scale-Invariant Features // Proc of the 11th International Conference on Information Visualization.Washington, USA:IEEE, 2007:871-877.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Fast Video Stabilization System Based on Speeded-up Robust Features">

                                <b>[13]</b> ZHOU M Q, ASARI V K.A Fast Video Stabilization System Based on Speeded-up Robust Features // Proc of the International Symposium on Visual Computing.Berlin, Germany:Springer, 2011:428-435.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Digital Video Stabilization and Rolling Shutter Correction Using Gyroscopes[T/OL]">

                                <b>[14]</b> KARPENKO A, JACOBS D, BAEK J, <i>et al</i>.Digital Video Stabilization and Rolling Shutter Correction Using Gyroscopes[T/OL].[2018-12-15].http://movement.stanford.edu/papers/stabilization/karpenko_gyro.pdf.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stabilizing cell phone video using inertial measurement sensors">

                                <b>[15]</b> HANNING G, FORSLÖW N, FORSSÉN P E, <i>et al</i>.Stabilizing Cell Phone Video Using Inertial Measurement Sensors // Proc of the IEEE International Conference on Computer Vision Workshops.Washington, USA:IEEE, 2011:1-8.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YNMZ200404001&amp;v=MjA0MTZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpuVzdyQlBDUEdkTEc0SHRYTXE0OUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 李凡长, 康宇.基于Lie群的机器学习理论框架.云南民族大学学报 (自然科学版) , 2004, 13 (4) :251-255. (LI F Z, KANG Y.The Study of Machine Learning Theory Frame Based on Lie Group.Journal of Yunnan Nationalities University (Natural Sciences Edition) , 2004, 13 (4) :251-255.) 
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787312026362001&amp;v=MTM1NjNLS0ZzZFhGcXpHYkM1SE5IT3FZeERadXNQRFJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3ZzVTd2&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 李凡长, 钱旭培, 谢琳, 等.机器学习理论及应用.北京:中国科学技术大学出版社, 2009. (LI F Z, QIIAN X P, XIE L, <i>et al</i>.Machine Learning and Its App-lications.Beijing, China:University of Science and Technology of China Press, 2009.) 
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VSLAM pose initialization via Lie groups and Lie algebras optimization">

                                <b>[18]</b> ROS G, GUERRERO J, SAPPA A D, <i>et al</i>.VSLAM Pose Initia-lization via Lie Groups and Lie Algebras Optimization // Proc of the IEEE International Conference on Robotics and Automation.Washington, USA:IEEE, 2013:5720-5727.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Constrained 3D rotation smoothing via global manifold regression for video stabilization">

                                <b>[19]</b> JIA C, EVANS B L.Constrained 3D Rotation Smoothing via Glo-bal Manifold Regression for Video Stabilization.IEEE Transactions on Signal Processing, 2014, 62 (13) :3293-3304.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Geodesic video stabilization in transformation space">

                                <b>[20]</b> ZHANG L, CHEN X Q, KONG X Y, <i>et al</i>.Geodesic Video Stabilizationin Transformation Space.IEEE Transactions on Image Processing, 2017, 26 (5) :2219-2229.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Differential Geometry,Liegroups,and Symmetric Spaces">

                                <b>[21]</b> HELGASON S.Differential Geometry, Liegroups, and Symmetric Spaces.Providence, USA:American Mathematical Society, 2001.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Introduction to the Kalman Filter[C/OL]">

                                <b>[22]</b> WELCH G, BISHOP G.An Introduction to the Kalman Filter[C/OL].[2018-12-18].https://courses.cs.washington.edu/courses/cse571/00au/papers/welch-bishop-kalman.pdf.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time video stabilization based on fast block matching and improved kalman filter">

                                <b>[23]</b> LI L Y, MA X H, ZHAO Z N.Real-Time Video Stabilization Based on Fast Block Matching and Improved Kalman Filter // Proc of the 5th International Conference on Intelligent Control and Information Processing.Washington, USA:IEEE, 2014:394-397.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501085131&amp;v=MDM0MTQ5RVpPTUtEWDg0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZ3Y2J4cz1OaWZPZmJLN0h0RE5xbw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> ERTURK S.Real-Time Digital Image Stabilization Using Kalman Flters.Real-Time Imaging, 2002, 8 (4) :317-328.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mesh Flow:minimum latency online video stabilization">

                                <b>[25]</b> LIU S C, TAN P, YUAN L, <i>et al</i>.Meshflow:Minimum Latency Online Video Stabilization // Proc of the European Conference on Computer Vision.Berlin, Germany:Springer, 2016:800-815.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Intrinsic Motion Stability Assessment for Video Stabilization">

                                <b>[26]</b> ZHANG L, ZHENG Q Z, HUANG H.Intrinsic Motion Stability Assessment for Video Stabilization.IEEE Transactions on Visua-lization and Computer Graphics, 2019, 25 (4) :1681-1692.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201904003" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201904003&amp;v=MTI4MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5em5XN3JCS0Q3WWJMRzRIOWpNcTQ5Rlo0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
