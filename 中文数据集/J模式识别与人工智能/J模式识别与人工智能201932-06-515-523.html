<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131451054248750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201906004%26RESULT%3d1%26SIGN%3dHlSsaz34RzybhKN688ADRunXGxA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201906004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201906004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201906004&amp;v=MzIwODFyQ1VSTE9lWmVSbkZ5emhVN3JNS0Q3WWJMRzRIOWpNcVk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#62" data-title="1 基于加权观测的改进HMM ">1 基于加权观测的改进HMM</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#99" data-title="2 3个基本问题求解方法 ">2 3个基本问题求解方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#111" data-title="&lt;b&gt;2.1&lt;/b&gt; 概率计算问题"><b>2.1</b> 概率计算问题</a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;2.2&lt;/b&gt; 参数学习问题"><b>2.2</b> 参数学习问题</a></li>
                                                <li><a href="#185" data-title="&lt;b&gt;2.3&lt;/b&gt; 序列标注问题"><b>2.3</b> 序列标注问题</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#214" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#216" data-title="&lt;b&gt;3.1&lt;/b&gt; 实验设计"><b>3.1</b> 实验设计</a></li>
                                                <li><a href="#222" data-title="&lt;b&gt;3.2&lt;/b&gt; 参数学习验证"><b>3.2</b> 参数学习验证</a></li>
                                                <li><a href="#247" data-title="&lt;b&gt;3.3&lt;/b&gt; 序列标注算法的对比实验"><b>3.3</b> 序列标注算法的对比实验</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#261" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#65" data-title="图1 WOHMM示意图">图1 WOHMM示意图</a></li>
                                                <li><a href="#292" data-title="图2 不同迭代次数时转移矩阵的变化情况">图2 不同迭代次数时转移矩阵的变化情况</a></li>
                                                <li><a href="#293" data-title="图3 不同动作持续样本数时转移矩阵的变化情况">图3 不同动作持续样本数时转移矩阵的变化情况</a></li>
                                                <li><a href="#249" data-title="图4 不同算法在用户1至用户10上的识别率">图4 不同算法在用户1至用户10上的识别率</a></li>
                                                <li><a href="#250" data-title="图5 不同算法在所有用户上的平均识别率">图5 不同算法在所有用户上的平均识别率</a></li>
                                                <li><a href="#258" data-title="图6 不同动作持续样本数时不同算法的识别率">图6 不同动作持续样本数时不同算法的识别率</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="294">


                                    <a id="bibliography_1" title=" BULLING A, BLANKE U, SCHIELE B.A Tutorial on Human Activity Recognition Using Body-Worn Inertial Sensors.ACM Computing Surveys, 2014, 46 (3) .DOI:10.1145/2499621." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM14041100000366&amp;v=MDM4OThvL29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGb1VieFk9TmlmSVk3SzhIdFhOcm85RlpPc1BEMw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         BULLING A, BLANKE U, SCHIELE B.A Tutorial on Human Activity Recognition Using Body-Worn Inertial Sensors.ACM Computing Surveys, 2014, 46 (3) .DOI:10.1145/2499621.
                                    </a>
                                </li>
                                <li id="296">


                                    <a id="bibliography_2" title=" SCHEURER S, TEDESCO S, BROWN K N, et al.Human Activity Recognition for Emergency First Responders via Body-Worn Inertial Sensors // Proc of the 14th IEEE International Conference on Wearable and Implantable Body Sensor Networks.Washington, USA:IEEE, 2017:5-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Human Activity Recognition for Emergency First Responders via Body-Worn Inertial Sensors">
                                        <b>[2]</b>
                                         SCHEURER S, TEDESCO S, BROWN K N, et al.Human Activity Recognition for Emergency First Responders via Body-Worn Inertial Sensors // Proc of the 14th IEEE International Conference on Wearable and Implantable Body Sensor Networks.Washington, USA:IEEE, 2017:5-8.
                                    </a>
                                </li>
                                <li id="298">


                                    <a id="bibliography_3" title=" SANCHEZ V G, PFEIFFER C F, SKEIE N O.A Review of Smart House Analysis Methods for Assisting Older People Living Alone.Journal of Sensor and Actuator Networks, 2017, 6 (3) .DOI:10.3390/jsan6030011." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Review of Smart House Analysis Methods for Assisting Older People Living Alone">
                                        <b>[3]</b>
                                         SANCHEZ V G, PFEIFFER C F, SKEIE N O.A Review of Smart House Analysis Methods for Assisting Older People Living Alone.Journal of Sensor and Actuator Networks, 2017, 6 (3) .DOI:10.3390/jsan6030011.
                                    </a>
                                </li>
                                <li id="300">


                                    <a id="bibliography_4" title=" YANG Z, WU C S, ZHOU Z, et al.Mobility Increases Localizability:A Survey on Wireless Indoor Localization Using Inertial Sensors.ACM Computing Surveys, 2015, 47 (3) .DOI:10.1145/2676430." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM5133F74328AB10FC2E6EA6F603ED64D9&amp;v=MjU2OThrSU9YbVVxaEkyRE1hU1FjNldDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3THkveGF3PU5pZklZN2E1SGRLNnFJdEdadU4rZm4wNXVXVVJueg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         YANG Z, WU C S, ZHOU Z, et al.Mobility Increases Localizability:A Survey on Wireless Indoor Localization Using Inertial Sensors.ACM Computing Surveys, 2015, 47 (3) .DOI:10.1145/2676430.
                                    </a>
                                </li>
                                <li id="302">


                                    <a id="bibliography_5" title=" HAMMERLA N Y, PLOETZ T.Let′s (not) Stick Together:Pairwise Similarity Biases Cross-Validation in Activity Recognition // Proc of the ACM International Joint Conference on Pervasive and Ubiquitous Computing.New York, USA:ACM, 2015:1041-1051." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Let′s (not) Stick Together:Pairwise Similarity Biases Cross-Validation in Activity Recognition">
                                        <b>[5]</b>
                                         HAMMERLA N Y, PLOETZ T.Let′s (not) Stick Together:Pairwise Similarity Biases Cross-Validation in Activity Recognition // Proc of the ACM International Joint Conference on Pervasive and Ubiquitous Computing.New York, USA:ACM, 2015:1041-1051.
                                    </a>
                                </li>
                                <li id="304">


                                    <a id="bibliography_6" title=" WANG Z L, WU D H, GRAVINA R, et al.Kernel Fusion Based Extreme Learning Machine for Cross-Location Activity Recognition.Information Fusion, 2017, 37:1-9." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA1A0AE7EAB561B086A366615E4285E22&amp;v=MTk1MTBLNWI5Rzkyb2d3RlprS0NuMUx6eDRWbXp4N1RubmpxV2N4ZTdxUk1MaWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3THkveGF3PU5pZk9mYw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         WANG Z L, WU D H, GRAVINA R, et al.Kernel Fusion Based Extreme Learning Machine for Cross-Location Activity Recognition.Information Fusion, 2017, 37:1-9.
                                    </a>
                                </li>
                                <li id="306">


                                    <a id="bibliography_7" title=" HOSEINI-TABATABAEI S A, GLUHAK A, TAFAZOLLI R.A Survey on Smartphone-Based Systems for Opportunistic User Context Recognition.ACM Computing Surveys, 2013, 45 (3) .DOI:10.1145/2480741.2480744." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000104593&amp;v=MDE3OTY2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGb1VieFk9TmlmSVk3SzdIdGpOcjQ5Rlplc0xDWFU2b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         HOSEINI-TABATABAEI S A, GLUHAK A, TAFAZOLLI R.A Survey on Smartphone-Based Systems for Opportunistic User Context Recognition.ACM Computing Surveys, 2013, 45 (3) .DOI:10.1145/2480741.2480744.
                                    </a>
                                </li>
                                <li id="308">


                                    <a id="bibliography_8" title=" PHAN T.Improving Activity Recognition via Automatic Decision Tree Pruning // Proc of the ACM International Joint Conference on Pervasive and Ubiquitous Computing.New York, USA:ACM, 2014:827-832." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving activity recognition via automatic decision tree pruning">
                                        <b>[8]</b>
                                         PHAN T.Improving Activity Recognition via Automatic Decision Tree Pruning // Proc of the ACM International Joint Conference on Pervasive and Ubiquitous Computing.New York, USA:ACM, 2014:827-832.
                                    </a>
                                </li>
                                <li id="310">


                                    <a id="bibliography_9" title=" KRISHNAN N C, PANCHANATHAN S.Analysis of Low Resolution Accelerometer Data for Continuous Human Activity Recognition // Proc of the IEEE International Conference on Acoustics, Speech and Signal Processing.Washington, USA:IEEE, 2008:3337-3340." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analysis of low resolution accelerometer data for continuous human activity recognition">
                                        <b>[9]</b>
                                         KRISHNAN N C, PANCHANATHAN S.Analysis of Low Resolution Accelerometer Data for Continuous Human Activity Recognition // Proc of the IEEE International Conference on Acoustics, Speech and Signal Processing.Washington, USA:IEEE, 2008:3337-3340.
                                    </a>
                                </li>
                                <li id="312">


                                    <a id="bibliography_10" title=" ZHENG L X, WU D H, RUAN X Y, et al.A Novel Energy-Efficient Approach for Human Activity Recognition.Sensors, 2017, 17 (9) .DOI:10.3390/s17092064." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A novel energy-efficient approach for human activity recognition.&amp;quot;">
                                        <b>[10]</b>
                                         ZHENG L X, WU D H, RUAN X Y, et al.A Novel Energy-Efficient Approach for Human Activity Recognition.Sensors, 2017, 17 (9) .DOI:10.3390/s17092064.
                                    </a>
                                </li>
                                <li id="314">


                                    <a id="bibliography_11" title=" ZHONG M Y, WEN J H, HU P Z, et al.Advancing Android Activity Recognition Service with Markov Smoother // Proc of the IEEE International Conference on Pervasive Computing and Communication Workshops.Washington, USA:IEEE, 2015:38-43." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Advancing Android activity recognition service with Markov smoother">
                                        <b>[11]</b>
                                         ZHONG M Y, WEN J H, HU P Z, et al.Advancing Android Activity Recognition Service with Markov Smoother // Proc of the IEEE International Conference on Pervasive Computing and Communication Workshops.Washington, USA:IEEE, 2015:38-43.
                                    </a>
                                </li>
                                <li id="316">


                                    <a id="bibliography_12" title=" ZHONG M Y, WEN J H, HU P Z, et al.Advancing Android Activity Recognition Service with Markov Smoother:Practical Solutions.Pervasive and Mobile Computing, 2017, 38:60-76." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Advancing Android Activity Recognition Service with Markov Smoother:Practical Solutions">
                                        <b>[12]</b>
                                         ZHONG M Y, WEN J H, HU P Z, et al.Advancing Android Activity Recognition Service with Markov Smoother:Practical Solutions.Pervasive and Mobile Computing, 2017, 38:60-76.
                                    </a>
                                </li>
                                <li id="318">


                                    <a id="bibliography_13" title=" YOUNES R, MARTIN T L, JONES M.Activity Classification at a Higher Level:What to Do After the Classifier Does Its Best?// Proc of the ACM International Symposium on Wearable Computers.New York, USA:ACM, 2015:83-86." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Activity classification at a higher level:what to do after the classifier does its best">
                                        <b>[13]</b>
                                         YOUNES R, MARTIN T L, JONES M.Activity Classification at a Higher Level:What to Do After the Classifier Does Its Best?// Proc of the ACM International Symposium on Wearable Computers.New York, USA:ACM, 2015:83-86.
                                    </a>
                                </li>
                                <li id="320">


                                    <a id="bibliography_14" title=" WANG C H, XU Y W, LIANG H, et al.WOODY:A Post-Process Method for Smartphone-Based Activity Recognition.IEEE Access, 2018, 6:49611-49625." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=WOODY A Post-Process Method for Smartphone-Based Activity Recognition">
                                        <b>[14]</b>
                                         WANG C H, XU Y W, LIANG H, et al.WOODY:A Post-Process Method for Smartphone-Based Activity Recognition.IEEE Access, 2018, 6:49611-49625.
                                    </a>
                                </li>
                                <li id="322">


                                    <a id="bibliography_15" title=" RABINER L, JUANG B.An Introduction to Hidden Markov Mo-dels.IEEE Assp Magazine, 1986, 3 (3) :4-16." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An introduction to hidden Markov models">
                                        <b>[15]</b>
                                         RABINER L, JUANG B.An Introduction to Hidden Markov Mo-dels.IEEE Assp Magazine, 1986, 3 (3) :4-16.
                                    </a>
                                </li>
                                <li id="324">


                                    <a id="bibliography_16" title=" WEN J H, ZHONG M Y, INDULSKA J.Creating General Model for Activity Recognition with Minimum Labelled Data // Proc of the ACM International Symposium on Wearable Computers.New York, USA:ACM, 2015:87-90." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Creating General Model for Activity Recognition with Minimum Labelled Data">
                                        <b>[16]</b>
                                         WEN J H, ZHONG M Y, INDULSKA J.Creating General Model for Activity Recognition with Minimum Labelled Data // Proc of the ACM International Symposium on Wearable Computers.New York, USA:ACM, 2015:87-90.
                                    </a>
                                </li>
                                <li id="326">


                                    <a id="bibliography_17" title=" WEN J H, WANG Z Y.Learning General Model for Activity Re-cognition with Limited Labelled Data.Expert Systems with Applications, 2017, 74 (15) :19-28." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4A784231158E54D782058D110356986B&amp;v=MTgyMThmT2ZiZkpHZG5Jcll4RVplNEhlWGs5dXhFYjZEOTRRQXZqclJJMmZMU2RUYnp0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZod0x5L3hhdz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         WEN J H, WANG Z Y.Learning General Model for Activity Re-cognition with Limited Labelled Data.Expert Systems with Applications, 2017, 74 (15) :19-28.
                                    </a>
                                </li>
                                <li id="328">


                                    <a id="bibliography_18" title=" KIM Y J, KANG B N, KIM D.Hidden Markov Model Ensemble for Activity Recognition Using Tri-axis Accelerometer // Proc of the IEEE International Conference on Systems, Man, and Cybernetics.Washington, USA:IEEE, 2015:3036-3041." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hidden Markov Model Ensemble for Activity Recognition Using Tri-axis Accelerometer">
                                        <b>[18]</b>
                                         KIM Y J, KANG B N, KIM D.Hidden Markov Model Ensemble for Activity Recognition Using Tri-axis Accelerometer // Proc of the IEEE International Conference on Systems, Man, and Cybernetics.Washington, USA:IEEE, 2015:3036-3041.
                                    </a>
                                </li>
                                <li id="330">


                                    <a id="bibliography_19" title=" 汪成亮, 王小均.基于三轴传感器的老年人日常活动识别.电子学报, 2017, 45 (3) :570-576. (WANG C L, WANG X J.Daily Activity Recognition Based on Triaxial Accelerometer of Elderly People.Acta Electronica Sinica, 2017, 45 (3) :570-576.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201703010&amp;v=MDc4NjhIOWJNckk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emhVN3JNSVRmVGU3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         汪成亮, 王小均.基于三轴传感器的老年人日常活动识别.电子学报, 2017, 45 (3) :570-576. (WANG C L, WANG X J.Daily Activity Recognition Based on Triaxial Accelerometer of Elderly People.Acta Electronica Sinica, 2017, 45 (3) :570-576.) 
                                    </a>
                                </li>
                                <li id="332">


                                    <a id="bibliography_20" title=" 王昌海, 张建忠, 徐敬东, 等.基于HMM的动作识别结果可信度计算方法.通信学报, 2016, 37 (5) :143-151. (WANG C H, ZHANG J Z, XU J D, et al.Identifying the Confidence Level of Activity Recognition via HMM.Journal on Communications, 2016, 37 (5) :143-151.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201605017&amp;v=MjEyMjVMT2VaZVJuRnl6aFU3ck1NVFhUYkxHNEg5Zk1xbzlFWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         王昌海, 张建忠, 徐敬东, 等.基于HMM的动作识别结果可信度计算方法.通信学报, 2016, 37 (5) :143-151. (WANG C H, ZHANG J Z, XU J D, et al.Identifying the Confidence Level of Activity Recognition via HMM.Journal on Communications, 2016, 37 (5) :143-151.) 
                                    </a>
                                </li>
                                <li id="334">


                                    <a id="bibliography_21" title=" WANG C H, XU Y W, ZHANG J Z, et al.SW-HMM:a Method for Evaluating Confidence of Smartphone-Based Activity Recognition // Proc of the International Symposium on Parallel and Distributed Processing with Applications.Washington, USA:IEEE, 2016:2086-2091." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SW-HMM a Method for Evaluating Confidence of Smartphone-Based Activity Recognition">
                                        <b>[21]</b>
                                         WANG C H, XU Y W, ZHANG J Z, et al.SW-HMM:a Method for Evaluating Confidence of Smartphone-Based Activity Recognition // Proc of the International Symposium on Parallel and Distributed Processing with Applications.Washington, USA:IEEE, 2016:2086-2091.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(06),515-523 DOI:10.16451/j.cnki.issn1003-6059.201906004            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于加权观测的隐马尔可夫模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%98%8C%E6%B5%B7&amp;code=41999828&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王昌海</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%93%B2%E8%BE%89&amp;code=42201395&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李哲辉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%8D%9A&amp;code=42201396&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王博</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%AE%B8%E6%98%B1%E7%8E%AE&amp;code=42201397&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">许昱玮</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E4%B8%87%E4%BC%9F&amp;code=41268470&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄万伟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%83%91%E5%B7%9E%E8%BD%BB%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%BD%AF%E4%BB%B6%E5%AD%A6%E9%99%A2&amp;code=1717979&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑州轻工业大学软件学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E7%9C%81%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E4%BF%A1%E6%81%AF%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=0969443&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南省科学技术信息研究院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%9C%E5%8D%97%E5%A4%A7%E5%AD%A6%E7%BD%91%E7%BB%9C%E7%A9%BA%E9%97%B4%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0220478&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">东南大学网络空间安全学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对隐马尔可夫模型无法融合分类结果权值的问题, 文中提出加权观测隐马尔可夫模型 (WOHMM) , 并给出模型中概率计算、参数学习、序列标注三个基本问题的解决算法.使用公开数据集对参数学习和序列标注问题进行仿真实验, 结果表明, WOHMM的参数学习算法能得到更接近真实值的模型参数, 序列标注算法的效果较优.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A8%E4%BD%9C%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">动作识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">隐马尔可夫模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Baum-Welch%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Baum-Welch算法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">序列标注;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王昌海, 博士, 讲师, 主要研究方向为动作识别、可穿戴计算、移动计算等.E-mail:chw@zzuli.edu.cn.;
                                </span>
                                <span>
                                    李哲辉, 本科, 高级工程师, 主要研究方向为计算机应用技术.E-mail:qbslzh@163.com.;
                                </span>
                                <span>
                                    王博, 博士, 讲师, 主要研究方向为移动计算、云计算、大数据平台、分布式系统等.E-mail:wangb@zzuli.edu.cn.;
                                </span>
                                <span>
                                    *许昱玮 (通讯作者) , 博士, 副教授, 主要研究方向为动作识别、移动计算、无线通信等.E-mail:xuyw@nankai.edu.cn.;
                                </span>
                                <span>
                                    黄万伟, 博士, 讲师, 主要研究方向为下一代网络架构、网络安全、可重构柔性网络等.E-mail:huangww79@163.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.61872439, 61702288);</span>
                                <span>河南省重点研发与推广专项 (科技攻关) (No.192102210291, 192102210294);</span>
                                <span>河南省高等学校重点科研项目 (No.19A520043) 资助;</span>
                    </p>
            </div>
                    <h1><b>An Improved Hidden Markov Model Based on Weighted Observation</b></h1>
                    <h2>
                    <span>WANG Changhai</span>
                    <span>LI Zhehui</span>
                    <span>WANG Bo</span>
                    <span>XU Yuwei</span>
                    <span>HUANG Wanwei</span>
            </h2>
                    <h2>
                    <span>Software Engineering College, Zhengzhou University of Light Industry</span>
                    <span>Henan Provincial Institute of Scientific and Technical Information</span>
                    <span>School of Cyber Science and Engineering, Southeast University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>As the classic hidden Markov model (HMM) loses the sight of confidence of labeled results while building a sequence, a weighted observation hidden Markov model (WOHMM) is proposed. The algorithms in the steps of probability calculation, parameter learning as well as sequence labeling are described in detail. The simulation results on the public datasets show that the parameters obtained by the parameter learning algorithm of WOHMM are closer to the real values than those of HMM, and the performance of sequence labeling algorithm is superior to the state-of-the-art methods.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Activity%20Recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Activity Recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Hidden%20Markov%20Model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Hidden Markov Model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Baum-Welch%20Algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Baum-Welch Algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sequence%20Labeling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sequence Labeling;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    WANG Changhai, Ph. D., lecturer. His research interests include activity recognition, wearable computing and mobile computing.;
                                </span>
                                <span>
                                    LI Zhehui, bachelor, senior engineer. Her research interests include technology of computer applications.;
                                </span>
                                <span>
                                    WANG Bo, Ph. D., lecturer. His research interests include mobile computing, cloud computing, big data platforms and distributed systems.;
                                </span>
                                <span>
                                    XU Yuwei (Corresponding author) , Ph.D., associate professor. His research interests include activity recognition, mobile computing and wireless communications.;
                                </span>
                                <span>
                                    HUANG Wanwei, Ph.D., lecturer. His research interests include next-generation network architecture, network security and reconfigurable flexible network.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-28</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.61872439, 61702288);</span>
                                <span>Foundation and Cutting-Edge Technologies Research Program of Henan Province (No.192102210291, 192102210294);</span>
                                <span>Key Scientific Research Projects of Henan Higher School (No.19A520043);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="288">在过去的十几年中, 基于惯性传感器的人体动作识别一直是学术界及工业界的研究热点<citation id="336" type="reference"><link href="294" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.研究者通过人体携带的传感设备 (如智能衣物、智能手机等) 采集人体运动过程中产生的加速度、角速度等数据, 并利用这些数据识别日常动作, 如走路、跑步等.相关的研究成果已应用于人体跟踪<citation id="337" type="reference"><link href="296" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、健康监护<citation id="338" type="reference"><link href="298" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、室内定位<citation id="339" type="reference"><link href="300" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等方向.依赖于原始传感数据的人体动作识别由于缺少用户训练数据<citation id="340" type="reference"><link href="302" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、用户行为个性化<citation id="341" type="reference"><link href="304" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等问题, 动作识别准确率无法满足商业应用的需求.Hoseini-tabatabaei等<citation id="342" type="reference"><link href="306" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>利用与原始数据无关的动作连续性信息辅助动作识别, 可提高动作识别率.</p>
                </div>
                <div class="p1">
                    <p id="59">动作的连续性信息可从多个角度辅助动作的识别, 其中一种常见的应用形式是对识别结果序列进行平滑处理, 用于修正识别错误的结果.朴素修改策略<citation id="343" type="reference"><link href="308" rel="bibliography" /><link href="310" rel="bibliography" /><link href="312" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>具有一定效果, 但未考虑真实动作序列中动作发生转换的问题, 在动作转换频繁时效果较差.ARShell (Activity Recognition Shell) 、LCCAS (Lowest Cumulative Cost Activity Sequence) 等<citation id="344" type="reference"><link href="314" rel="bibliography" /><link href="316" rel="bibliography" /><link href="318" rel="bibliography" /><link href="320" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>融合动作连续性及动作转换概率, 在修正下一个结果时考虑每个识别结果的分类可信度.但是, 这两种方法皆以递推的方式修改样本, 只能实现局部最优, 并未考虑全局最优, 在动作转换频繁时容易出现累积误差.</p>
                </div>
                <div class="p1">
                    <p id="60">隐马尔可夫模型 (Hidden Markov Model, HMM) <citation id="345" type="reference"><link href="322" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>也可以辅助动作识别, 实现全局最优<citation id="346" type="reference"><link href="324" rel="bibliography" /><link href="326" rel="bibliography" /><link href="328" rel="bibliography" /><link href="330" rel="bibliography" /><link href="332" rel="bibliography" /><link href="334" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>, 但HMM仍存在不足.使用HMM对动作序列建模时, 样本的真实标签抽象为HMM中的隐状态, 识别结果抽象为HMM的观测值.如果通过HMM中的序列标注算法、概率计算算法实现对动作的辅助识别, 在实际应用中, 样本的识别结果不仅包含动作类别, 而且包含该样本属于不同类别的权值.对于同样的识别结果, 不同权值对结果修正及HMM参数学习影响不同, 但当前HMM无法实现这一目的.</p>
                </div>
                <div class="p1">
                    <p id="61">针对HMM无法融合分类权值信息的缺陷, Wang等<citation id="347" type="reference"><link href="320" rel="bibliography" /><link href="334" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">21</a>]</sup></citation>提出加权观测概率的概念, 修正结果, 估算识别结果的可信度.本文在综合两个研究工作的基础之上, 提出基于加权观测的改进HMM (Weighted Observation HMM, WOHMM) .给出WOHMM的形式化描述, 并解释加权观测概率的物理意义.给出WOHMM概率计算、参数学习、序列标注的解决算法.最后使用公开数据集对参数学习和序列标注问题的算法进行仿真实验.</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag">1 基于加权观测的改进HMM</h3>
                <div class="p1">
                    <p id="63">状态集表示为<i>S</i>={<i>s</i><sub>1</sub>, <i>s</i><sub>2</sub>, …, <i>s</i><sub><i>N</i></sub>}, 观测集表示为<i>R</i>={<i>r</i><sub>1</sub>, <i>r</i><sub>2</sub>, …, <i>r</i><sub><i>M</i></sub>}, 其中, <i>N</i>为隐状态的数量, <i>M</i>为观测值的数量.与HMM不同, WOHMM中增加观测向量的概念, 表示为<b><i>o</i></b>= (<i>o</i><sub><i>r</i><sub>1</sub></sub>, <i>o</i><sub><i>r</i><sub>2</sub></sub>, …, <i>o</i><sub><i>r</i><sub><i>M</i></sub></sub>) , 其中<i>o</i><sub><i>r</i><sub><i>i</i></sub></sub>表示隐状态被观测到<i>r</i><sub><i>i</i></sub>的权值, 满足0≤<i>o</i><sub><i>r</i><sub><i>i</i></sub></sub>≤1和<mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>o</mi></mstyle><msub><mrow></mrow><mrow><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>.具体到动作识别问题, <i>S</i>和<i>R</i>都对应要识别的动作集合, <b><i>o</i></b>表示对样本进行分类后, 分类器给出的样本属于不同动作类别的权值向量.WOHMM的示意图如图1所示.</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906004_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 WOHMM示意图" src="Detail/GetImg?filename=images/MSSB201906004_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 WOHMM示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906004_065.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Illustration for WOHMM</p>

                </div>
                <div class="p1">
                    <p id="66">由图1可见, 与HMM包含两个序列不同, WOHMM包含3个随时间变化的序列</p>
                </div>
                <div class="p1">
                    <p id="67" class="code-formula">
                        <mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>A</mi><mo>=</mo><mo stretchy="false">{</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">}</mo><mo>, </mo><mspace width="0.25em" /><mi>L</mi><mo>=</mo><mo stretchy="false">{</mo><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>l</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ο</mi><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="68">其中, <i>a</i><sub><i>t</i></sub>、<i>l</i><sub><i>t</i></sub>和<b><i>o</i></b><sub><i>t</i></sub>分别为<i>t</i>时刻的隐状态、观测值和观测向量, 满足<i>a</i><sub><i>t</i></sub>∈<i>S</i>和<i>l</i><sub><i>t</i></sub>∈<i>R</i>.</p>
                </div>
                <div class="p1">
                    <p id="69">对于隐状态序列<i>A</i>, 随着时间<i>t</i>的变化, 隐状态可能保持不变, 也可能转换为其它状态.不同状态间的转换概率组成状态转移矩阵:</p>
                </div>
                <div class="p1">
                    <p id="70" class="code-formula">
                        <mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Q</mi><mo>=</mo><mo stretchy="false">[</mo><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo stretchy="false">]</mo><msub><mrow></mrow><mrow><mi>Ν</mi><mo>×</mo><mi>Ν</mi></mrow></msub><mo>, </mo><mspace width="0.25em" /><mn>0</mn><mo>≤</mo><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>≤</mo><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>q</mi></mstyle><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mn>1</mn><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="71"><i>q</i><sub><i>s</i><sub><i>i</i></sub><i>s</i><sub><i>j</i></sub></sub>表示在隐藏序列中, <i>t</i>时刻为状态<i>s</i><sub><i>i</i></sub>时, <i>t</i>+1时刻为状态<i>s</i><sub><i>j</i></sub>的概率:</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">与隐藏状态序列<i>A</i>对应, <i>L</i>为观测值序列, 其中<i>l</i><sub><i>i</i></sub>为<i>t</i>=<i>i</i>时隐状态<i>a</i><sub><i>i</i></sub>的观测值.与HMM类似, 定义观测矩阵:</p>
                </div>
                <div class="p1">
                    <p id="74"><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ρ</mi><mo>=</mo><mo stretchy="false">[</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo stretchy="false">]</mo><msub><mrow></mrow><mrow><mi>Ν</mi><mo>×</mo><mi>Μ</mi></mrow></msub><mo>, </mo><mspace width="0.25em" /><mn>0</mn><mo>≤</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>≤</mo><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mi>p</mi></mstyle><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>.      (1) </p>
                </div>
                <div class="p1">
                    <p id="76"><i>p</i><sub><i>s</i><sub><i>i</i></sub><i>r</i><sub><i>j</i></sub></sub>表示隐状态<i>s</i><sub><i>i</i></sub>观测到<i>r</i><sub><i>j</i></sub>的概率:</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>l</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">为了在观测概率中融合分类权值信息, WOHMM中增加加权观测概率的概念, 用于描述在<i>t</i>时刻已知<b><i>o</i></b><sub><i>t</i></sub>= (<i>o</i><sub><i>tr</i><sub>1</sub></sub>, <i>o</i><sub><i>tr</i><sub>2</sub></sub>, …<i>o</i><sub><i>tr</i><sub><i>M</i></sub></sub>) 的条件下, <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>¯</mo></mover></math></mathml><sub><i>s</i><sub><i>i</i></sub><i>l</i><sub><i>t</i></sub></sub>表示隐状态<i>s</i><sub><i>i</i></sub>观测到<i>l</i><sub><i>t</i></sub>的概率:</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>p</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>l</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>l</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">在实际计算中, 使用先验观测概率向量<b><i>p</i></b><sub><i>s</i><sub><i>i</i></sub></sub>与<b><i>o</i></b><sub><i>t</i></sub>的余弦相似度计算得到该概率:</p>
                </div>
                <div class="p1">
                    <p id="82"><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>p</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>l</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>⋅</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">|</mo><mo stretchy="false">|</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></mathml>,      (2) </p>
                </div>
                <div class="p1">
                    <p id="84">其中, <b><i>p</i></b><sub><i>s</i><sub><i>i</i></sub></sub>= (<i>p</i><sub><i>s</i><sub><i>i</i></sub><i>r</i><sub>1</sub></sub>, <i>p</i><sub><i>s</i><sub><i>i</i></sub><i>r</i><sub>2</sub></sub>, …, <i>p</i><sub><i>s</i><sub><i>i</i></sub><i>r</i><sub><i>M</i></sub></sub>) 为式 (1) 的第<i>i</i>行, <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">p</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">|</mo></mrow></math></mathml>和<mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo></mrow></math></mathml>为对两个向量求模.</p>
                </div>
                <div class="p1">
                    <p id="87">WOHMM中加权观测概率的物理意义描述如下.<b><i>p</i></b><sub><i>s</i><sub><i>i</i></sub></sub>为根据先验知识获得的观测概率分布, 即隐状态为<i>s</i><sub><i>i</i></sub>时, 不同观测值应满足<b><i>p</i></b><sub><i>s</i><sub><i>i</i></sub></sub>, 而观测<i>t</i>时刻的样本时, 实际的观测概率分布为<b><i>o</i></b><sub><i>t</i></sub>.如果<b><i>p</i></b><sub><i>s</i><sub><i>i</i></sub></sub>与<b><i>o</i></b><sub><i>t</i></sub>的相似度较大, 说明隐状态为<i>s</i><sub><i>i</i></sub>的概率较大, 即由于<i>t</i>时刻已知实际观测向量<b><i>o</i></b><sub><i>t</i></sub>, 状态<i>s</i><sub><i>i</i></sub>观测到<i>l</i><sub><i>t</i></sub>的概率大幅增加.否则, 如果<b><i>p</i></b><sub><i>s</i><sub><i>i</i></sub></sub>与<b><i>o</i></b><sub><i>t</i></sub>的相似度较低, 认为<i>s</i><sub><i>i</i></sub>观测到<i>l</i><sub><i>t</i></sub>的概率较小.在实际应用中, <i>t</i>时刻的观测概率可使用加权观测概率<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>¯</mo></mover></math></mathml><sub><i>s</i><sub><i>i</i></sub><i>l</i><sub><i>t</i></sub></sub>替换原观测概率<i>p</i><sub><i>s</i><sub><i>i</i></sub><i>l</i><sub><i>t</i></sub></sub>, 在序列建模过程中融合分类权值信息.</p>
                </div>
                <div class="p1">
                    <p id="89">与HMM类似, 定义WOHMM中的初始状态向量, 描述<i>t</i>=1时各状态出现的概率, 初始状态向量如下:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">π</mi><mo>=</mo><mrow><mo stretchy="false"> (</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>, </mo><mi>β</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>β</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>Ν</mi></msub></mrow></msub><mo stretchy="false">) </mo></mrow><msub><mrow></mrow><mrow><mn>1</mn><mo>×</mo><mi>Ν</mi></mrow></msub><mo>, </mo><mspace width="0.25em" /><mn>0</mn><mo>≤</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>≤</mo><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>β</mi></mstyle><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>=</mo><mn>1</mn><mo>.</mo></mtd></mtr><mtr><mtd><mi>β</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>=</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">, 为<i>t</i>=1时隐状态<i>s</i><sub><i>i</i></sub>出现的概率.</p>
                </div>
                <div class="p1">
                    <p id="92">综上所述, WOHMM的参数由状态转移矩阵、观测矩阵和初始状态向量三部分组成:</p>
                </div>
                <div class="p1">
                    <p id="93"><i>λ</i>=[<b><i>P</i><i>Q</i></b><i>π</i>].</p>
                </div>
                <div class="p1">
                    <p id="94">WOHMM的3个基本问题可重新描述如下.</p>
                </div>
                <div class="p1">
                    <p id="95">1) 概率计算问题.给定WOHMM模型<i>λ</i>及观测向量序列<b><i>O</i></b>, 计算<b><i>O</i></b>对应的观测值序列<b><i>L</i></b>出现的概率<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">λ</mi><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="97">2) 参数学习问题.给定观测序列<b><i>L</i></b>和<b><i>O</i></b>, 计算最优参数<i>λ</i>.</p>
                </div>
                <div class="p1">
                    <p id="98">3) 序列标注问题.给定WOHMM模型<i>λ</i>及观测序列<b><i>L</i></b>和<b><i>O</i></b>, 计算最有可能的隐状态序列<b><i>A</i></b>.</p>
                </div>
                <h3 id="99" name="99" class="anchor-tag">2 3个基本问题求解方法</h3>
                <div class="p1">
                    <p id="100">本节遵循HMM中3个基本问题的解法, 给出WOHMM的相应算法.下面给出2个需要使用的变量.</p>
                </div>
                <div class="p1">
                    <p id="101">1) 前向概率<i>α</i><sub><i>t</i></sub> (<i>s</i><sub><i>k</i></sub>) .在已知WOHMM参数<i>λ</i>和1～<i>t</i>时刻的观测向量序列{<b><i>o</i></b><sub>1</sub>, <b><i>o</i></b><sub>2</sub>, …, <b><i>o</i></b><sub><i>t</i></sub>}的情况下, 观测值序列为{<i>l</i><sub>1</sub>, <i>l</i><sub>2</sub>, …, <i>l</i><sub><i>t</i></sub>}, <i>t</i>时刻隐状态为<i>s</i><sub><i>k</i></sub>的概率:</p>
                </div>
                <div class="area_img" id="102">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906004_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="104">由式 (2) 计算得到<mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>¯</mo></mover></math></mathml><sub><i>s</i><sub><i>k</i></sub><i>l</i><sub><i>t</i></sub></sub>.</p>
                </div>
                <div class="p1">
                    <p id="106">2) 后向概率<i>β</i><sub><i>t</i></sub> (<i>s</i><sub><i>k</i></sub>) .在已知WOHMM参数<i>λ</i>, <i>t</i>时刻隐状态<i>s</i><sub><i>k</i></sub>, <i>t</i>+1到<i>T</i>观测向量序列{<b><i>o</i></b><sub><i>t</i>+1</sub>, <b><i>o</i></b><sub><i>t</i>+2</sub>, …, <b><i>o</i></b><sub><i>T</i></sub>}时, 观测值序列为{<i>l</i><sub><i>t</i>+1</sub>, <i>l</i><sub><i>t</i>+2</sub>, …, <i>l</i><sub><i>T</i></sub>}的概率:</p>
                </div>
                <div class="area_img" id="107">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906004_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="109">由式 (2) 计算得到<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>¯</mo></mover></math></mathml><sub><i>s</i><sub><i>j</i></sub><i>l</i><sub><i>t</i>+1</sub></sub>.</p>
                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>2.1</b> 概率计算问题</h4>
                <div class="p1">
                    <p id="112">基于式 (3) 、式 (4) , WOHMM的概率计算方法如算法1所示.</p>
                </div>
                <div class="p1">
                    <p id="113"><b>算法1</b> WOHMM的概率计算算法</p>
                </div>
                <div class="area_img" id="289">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201906004_28900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="136">算法1分为三部分.第一部分为初始化, 用于计算<i>α</i><sub>1</sub> (<i>s</i><sub><i>k</i></sub>) , 由初始概率和加权观测概率的乘积计算得到.第二部分为递推, 使用<i>α</i><sub><i>t</i>-1</sub> (<i>s</i><sub><i>i</i></sub>) 计算<i>α</i><sub><i>t</i></sub> (<i>s</i><sub><i>k</i></sub>) .首先计算<i>t</i>-1时刻任意隐藏状态转换到<i>s</i><sub><i>k</i></sub>的概率;然后对这些概率求和, 得到<i>t</i>时刻隐状态为<i>s</i><sub><i>k</i></sub>的概率, 最后使用该概率乘以加权观测概率<mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>p</mi><mo>¯</mo></mover></math></mathml><sub><i>s</i><sub><i>k</i></sub><i>l</i><sub><i>t</i></sub></sub>得到<i>α</i><sub><i>t</i></sub> (<i>s</i><sub><i>k</i></sub>) .第三部分对不同隐状态观测到<i>l</i><sub><i>T</i></sub>的概率进行累加, 得到整个序列出现的概率<i>P</i><sub><i>L</i></sub>.</p>
                </div>
                <h4 class="anchor-tag" id="138" name="138"><b>2.2</b> 参数学习问题</h4>
                <div class="p1">
                    <p id="139">在WOHMM的3个参数中, 初始向量和观测概率可根据动作识别的先验知识获取, 而转移概率随用户所处环境的变化而变化.前两个参数在实际应用中无需动态更新, 后者需根据当前场景的不同实时更新, 本节主要推导转移概率的递推公式.遵循Baum-Welch算法的思路, 确定完全数据的对数似然函数<mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>log</mi></mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">λ</mi><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo></mrow></math></mathml>:</p>
                </div>
                <div class="p1">
                    <p id="141" class="code-formula">
                        <mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">λ</mi><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo>=</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mover accent="true"><mi>p</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mi>q</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mover accent="true"><mi>p</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mn>2</mn></msub><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo>⋯</mo><mi>q</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></msub><mi>a</mi><msub><mrow></mrow><mi>Τ</mi></msub></mrow></msub><mover accent="true"><mi>p</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mi>Τ</mi></msub><mi>l</mi><msub><mrow></mrow><mi>Τ</mi></msub></mrow></msub><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="142">其中, <b><i>A</i></b>为一条与<b><i>L</i></b>、<b><i>O</i></b>对应的可能状态序列, <i>λ</i>为WOHMM的参数.根据式 (5) 构造EM算法的<i>Q</i>函数:</p>
                </div>
                <div class="p1">
                    <p id="143"><mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">λ</mi><mo>, </mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi mathvariant="bold-italic">A</mi></munder><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mrow><mi>log</mi></mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">λ</mi><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo></mrow></math></mathml>,      (6) </p>
                </div>
                <div class="p1">
                    <p id="145">其中, <i>λ</i>为要极大化的WOHMM参数, <mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover></math></mathml>为当前参数估计值.将式 (5) 代入式 (6) , 得</p>
                </div>
                <div class="p1">
                    <p id="147" class="code-formula">
                        <mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Q</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">λ</mi><mo>, </mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>A</mi></munder><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mi>log</mi><mspace width="0.25em" /><mi>β</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>A</mi></munder><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mtext>l</mtext></mstyle><mtext>o</mtext><mtext>g</mtext><mspace width="0.25em" /><mi>p</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mi>l</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi mathvariant="bold-italic">A</mi></munder><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mtext>l</mtext></mstyle><mtext>o</mtext><mtext>g</mtext><mspace width="0.25em" /><mi>q</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></msub><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="148">上式包括三部分, 分别为对初始概率、观测概率、转换概率求和, 由于初始向量和观测概率不需更新, 要极大化<i>Q</i>函数, 需对第三部分极大化.展开第三部分并构造拉格朗日函数, </p>
                </div>
                <div class="p1">
                    <p id="149" class="code-formula">
                        <mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">L</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ρ</mi></mstyle></mrow></mstyle></mrow></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mi>log</mi><mspace width="0.25em" /><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>γ</mi><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>q</mi></mstyle><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="150">对<i>q</i><sub><i>s</i><sub><i>i</i></sub><i>s</i><sub><i>j</i></sub></sub>计算偏导, 并令结果为0, 得</p>
                </div>
                <div class="p1">
                    <p id="151"><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo>+</mo><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mi>γ</mi><mo>=</mo><mn>0</mn></mrow></math></mathml>,      (7) </p>
                </div>
                <div class="p1">
                    <p id="153">对<i>j</i>累加, 利用约束条件<mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>q</mi></mstyle><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>, 得</p>
                </div>
                <div class="p1">
                    <p id="155"><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="157">把上式代入式 (7) , 得</p>
                </div>
                <div class="p1">
                    <p id="158"><mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>,      (8) </p>
                </div>
                <div class="p1">
                    <p id="160">对分子和分母概率进行分解, </p>
                </div>
                <div class="p1">
                    <p id="161" class="code-formula">
                        <mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mo stretchy="false">{</mo><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>l</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">}</mo><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">) </mo><mover accent="true"><mi>q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mover accent="true"><mi>p</mi><mo>¯</mo></mover><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mi>l</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></msub><mo>⋅</mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mo stretchy="false">{</mo><mi>l</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>l</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">|</mo><mi>a</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo>, </mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">) </mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">L</mi><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mi mathvariant="bold-italic">Ο</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mo stretchy="false">{</mo><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>l</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">}</mo><mo>, </mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">) </mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mo stretchy="false"> (</mo><mo stretchy="false">{</mo><mi>l</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>l</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">|</mo><mi>a</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>, </mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>3</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="162">将式 (3) 和式 (4) 代入式 (9) 和式 (10) , 并代入式 (8) , 得</p>
                </div>
                <div class="p1">
                    <p id="163"><mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mover accent="true"><mi>α</mi><mo>˜</mo></mover></mstyle><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mover accent="true"><mi>q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mrow><mover accent="true"><mover accent="true"><mi>p</mi><mo>¯</mo></mover><mo stretchy="true">˜</mo></mover></mrow><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mi>l</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></msub><mover accent="true"><mi>β</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Τ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mover accent="true"><mi>α</mi><mo>˜</mo></mover></mstyle><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mover accent="true"><mi>β</mi><mo>˜</mo></mover><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>,      (11) </p>
                </div>
                <div class="p1">
                    <p id="165">上式即为转移概率的递推公式, 基于该公式, WOHMM的转移概率学习算法如算法2所示.</p>
                </div>
                <div class="p1">
                    <p id="166"><b>算法2</b> WOHMM中状态转移概率的学习算法</p>
                </div>
                <div class="area_img" id="290">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201906004_29000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="184">算法2的首层循环用于标识迭代次数, 该参数需根据实际问题确定.对于每次迭代, 需根据<b><i>Q</i></b>的上次迭代结果计算此次迭代中每个转移概率的值.在这个过程中利用式 (3) 和式 (4) 计算前向概率和后向概率, 利用式 (11) 得到更新后转移概率, 所有的转移概率组成本次迭代的转移矩阵<b><i>Q</i></b>.多次迭代后, 返回学习后的迭代矩阵.</p>
                </div>
                <h4 class="anchor-tag" id="185" name="185"><b>2.3</b> 序列标注问题</h4>
                <div class="p1">
                    <p id="186">遵循Viterbi算法的思路, 引入两个变量.</p>
                </div>
                <div class="p1">
                    <p id="187">1) 给定模型参数<i>λ</i>, 记1～<i>t</i>时刻的观测序列为</p>
                </div>
                <div class="p1">
                    <p id="188"><b><i>O</i></b><sub><i>t</i></sub>={<b><i>o</i></b><sub>1</sub>, <b><i>o</i></b><sub>2</sub>, …, <b><i>o</i></b><sub><i>t</i></sub>}, <i>L</i><sub><i>t</i></sub>={<i>l</i><sub>1</sub>, <i>l</i><sub>2</sub>, …, <i>l</i><sub><i>t</i></sub>}, </p>
                </div>
                <div class="p1">
                    <p id="189">在时刻<i>t</i>隐状态为<i>s</i><sub><i>i</i></sub>的所有隐状态路径中, 单个路径出现概率的最大值为<i>δ</i><sub><i>t</i></sub> (<i>s</i><sub><i>i</i></sub>) :</p>
                </div>
                <div class="area_img" id="190">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906004_19000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="192">2) 给定模型参数<i>λ</i>, 记1～<i>t</i>时刻的观测序列为</p>
                </div>
                <div class="p1">
                    <p id="193"><b><i>O</i></b><sub><i>t</i></sub>={<b><i>o</i></b><sub>1</sub>, <b><i>o</i></b><sub>2</sub>, …, <b><i>o</i></b><sub><i>t</i></sub>}, <i>L</i><sub><i>t</i></sub>={<i>l</i><sub>1</sub>, <i>l</i><sub>2</sub>, …, <i>l</i><sub><i>t</i></sub>}, </p>
                </div>
                <div class="p1">
                    <p id="194">时刻<i>t</i>的隐状态为<i>s</i><sub><i>i</i></sub>的所有单个隐状态路径中, 概率最大的路径<i>t</i>-1时刻的隐状态为<i>ψ</i><sub><i>t</i></sub> (<i>s</i><sub><i>i</i></sub>) :</p>
                </div>
                <div class="p1">
                    <p id="195" class="code-formula">
                        <mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>t</mi><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd columnalign="left"><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi></mrow></mstyle><mrow><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mo stretchy="false">[</mo><mi>δ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mi>q</mi><msub><mrow></mrow><mrow><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">]</mo><mo>, </mo></mtd><mtd columnalign="left"><mi>t</mi><mo>&gt;</mo><mn>1</mn></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="196">基于上述定义, WOHMM的序列标注算法如算法3所示.</p>
                </div>
                <div class="p1">
                    <p id="197"><b>算法3</b> WOHMM的序列标注算法</p>
                </div>
                <div class="area_img" id="291">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201906004_29100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="213">算法3分为两步:递推和回溯.在递推过程中, 对于<i>t</i>时刻的隐状态集, 需计算当每个隐状态<i>s</i><sub><i>i</i></sub>出现时, 到达该状态的最优隐状态路径的概率.概率越大, 当前时刻的隐状态为此状态的可能性越大, <i>δ</i><sub><i>t</i></sub> (<i>s</i><sub><i>i</i></sub>) 表示该概率.计算最优隐状态路径概率后, 还需记录导致该最优路径的<i>t</i>-1时刻的隐状态, 在递推完成后获取最终的隐状态路径, <i>ψ</i><sub><i>t</i></sub> (<i>s</i><sub><i>i</i></sub>) 表示该值.整个序列递推完成后, <i>δ</i><sub><i>T</i></sub>中的最大值对应的状态<i>s</i><sub><i>i</i></sub>即为最优路径在<i>T</i>时刻最优隐状态, 而<i>ψ</i><sub><i>T</i>-1</sub> (<i>s</i><sub><i>i</i></sub>) 为最优路径在<i>T</i>-1时刻的状态.此时, 通过回溯<i>ψ</i><sub><i>t</i></sub>得到最优隐状态路径.</p>
                </div>
                <h3 id="214" name="214" class="anchor-tag">3 实验及结果分析</h3>
                <div class="p1">
                    <p id="215">为了验证WOHMM在动作识别问题上的有效性, 对WOHMM进行仿真.文献<citation id="348" type="reference">[<a class="sup">21</a>]</citation>已验证概率计算算法的有效性, 本节主要对参数学习和序列标注算法进行仿真.</p>
                </div>
                <h4 class="anchor-tag" id="216" name="216"><b>3.1</b> 实验设计</h4>
                <div class="p1">
                    <p id="217">SARD数据集<citation id="349" type="reference"><link href="334" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>包含10位用户、5个手机佩带位置、7类动作、3种传感器, 约5 h的动作数据.实验选取常用的5类动作:走路、跑步、静止、上楼梯和下楼梯.在对WOHMM仿真之前, 使用分类器对样本分类, 得到分类结果序列.在分类过程中, 使用半重叠的滑动窗口划分原始数据.再对每个窗口提取特征得到一个样本.提取的特征包括合成加速度和角速度的均值、方差、平均交叉率、最大值、最小值、低10维快速傅里叶 (Fast Fourier Transformation, FFT) 频域特征.特征提取后每位用户样本数约2 000.实验中依次选择一位用户样本作为测试数据, 其它用户样本作为训练数据.</p>
                </div>
                <div class="p1">
                    <p id="218">由于动作之间的转换概率会随应用场景的不同而不同, 因此数据集中的动作序列并不能代表真实场景.为了测试本文算法对不同应用场景的适应性, 在训练和分类之前, 对动作序列进行随机重组.重组过程中每类动作的持续样本数设定为指定长度<i>len</i>, 并且动作之间的转换随机指定.重组完成后得到一个全新的动作序列.实验中通过改变<i>len</i>的值模拟不同的应用场景.训练和分类时选择当前常用的SVM分类器.对序列中的每个样本分类后, 得到该样本属于不同动作的权值向量<b><i>h</i></b>, 对向量进行归一化:</p>
                </div>
                <div class="p1">
                    <p id="219"><mathml id="220"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">o</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>k</mi></msub><mo>-</mo><mi>min</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Μ</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>min</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="221">对所有向量归一化后, 得到识别结果向量序列, 作为本文算法的输入.对于每个实验, 对序列重组100次取平均值作为最终结果.</p>
                </div>
                <h4 class="anchor-tag" id="222" name="222"><b>3.2</b> 参数学习验证</h4>
                <div class="p1">
                    <p id="223">本节通过对比算法2和Baum-Welch算法, 验证WOHMM的有效性.实验中2种算法的初始转移矩阵设置为均匀分布, 重组时样本持续长度设置为5.为了评判算法的学习效果, 使用欧拉距离和余弦相似度评估训练得到的转移矩阵是否接近实际转移矩阵.</p>
                </div>
                <div class="p1">
                    <p id="224">欧拉距离</p>
                </div>
                <div class="p1">
                    <p id="225"><mathml id="226"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>e</mtext><mtext>u</mtext><mtext>l</mtext><mtext>e</mtext><mtext>r</mtext></mrow></msub><mo>=</mo><mroot><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>q</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow><mtext> </mtext></mroot></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="227">其中, <mathml id="228"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">q</mi></mstyle><mo>ˇ</mo></mover></mrow></math></mathml>为学习得到的转移矩阵, <b><i>q</i></b>为统计得到的重组后的真实动作序列中的转移矩阵.通过定义可得, <i>d</i><sub>euler</sub>越小, 学习得到的转移矩阵越接近真实转移矩阵, 学习算法的效果也越好.</p>
                </div>
                <div class="p1">
                    <p id="229">余弦相似度</p>
                </div>
                <div class="p1">
                    <p id="230"><mathml id="231"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>s</mtext><mtext>i</mtext><mtext>n</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mi>j</mi></mrow></munder><mi>q</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mover accent="true"><mi>q</mi><mo>˜</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">Q</mi><mo>|</mo></mrow></mrow><msub><mrow></mrow><mtext>F</mtext></msub><mrow><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">Q</mi><mo>˜</mo></mover><mo stretchy="false">|</mo></mrow><msub><mrow></mrow><mtext>F</mtext></msub></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="232">其中<mathml id="233"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">Q</mi><mo>|</mo></mrow><msub><mrow></mrow><mtext>F</mtext></msub></mrow></math></mathml>为矩阵<b><i>Q</i></b>的F-范数.根据定义, <i>d</i><sub>cosin</sub>越大, 学习得到的转移矩阵与真实转移矩阵越相似, 算法的学习效果越好.随着迭代次数的增加, 转移矩阵的变化情况如图2所示.图中WOHMM为本文的算法2, Baum-Welch为经典HMM的Baum-Welch算法.</p>
                </div>
                <div class="p1">
                    <p id="238">由图2可见, 随着迭代次数的增加, 学习得到的转移矩阵与真实转移矩阵间的欧拉距离变小, 余弦相似度变大.迭代超过5次后, 两种算法趋于平缓, 这说明此时转移矩阵趋于收敛.对比WOHMM和Baum-Welch可发现, WOHMM的收敛速度略慢于Baum-Welch.在迭代次数较少时, Baum-Welch表现较好.但随着迭代次数的增加, WOHMM表现优于Baum-Welch.原因如下:观察式 (2) 可发现, 经过加权后WOHMM中不同隐状态的观测概率差异变小, WOHMM逼近最优值的步幅较小, 因此在步数较少时表现为收敛速度较慢.但正是由于逼近最优值的步幅较小, WOHMM的迭代更精细, 对最优值的逼近也更精确.因此迭代次数较多时, WOHMM表现优于Baum-Welch.</p>
                </div>
                <div class="p1">
                    <p id="239">动作发生时持续的样本数是影响序列建模算法的重要参数, 图2中将该参数设置为5.为了进一步分析学习算法对不同应用场景的适应情况, 在序列重组过程中, 动作持续样本数变化时转移矩阵的变化情况如图3所示, 其中迭代次数设置为10.</p>
                </div>
                <div class="area_img" id="292">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906004_29200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同迭代次数时转移矩阵的变化情况" src="Detail/GetImg?filename=images/MSSB201906004_29200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同迭代次数时转移矩阵的变化情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906004_29200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Transition matrixes varying with different iteration times</p>

                </div>
                <div class="area_img" id="293">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906004_29300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同动作持续样本数时转移矩阵的变化情况" src="Detail/GetImg?filename=images/MSSB201906004_29300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同动作持续样本数时转移矩阵的变化情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906004_29300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Transition matrixes varying with different activity durations</p>

                </div>
                <div class="p1">
                    <p id="245">从图3可看出, 随着动作持续样本数的增大, 两种算法学习得到的转移矩阵越来越接近真实的转移矩阵.主要原因如下:动作持续样本数较小时, 动作转换较频繁, 在结果序列中学习转移矩阵易受错误识别结果的影响.随着动作持续样本数的增大, 动作的转换规律越来越明显, 错误结果的影响越来越低, 学习算法也越易从结果序列中捕获动作转换规律, 学习的转移矩阵也越接近真实的转移矩阵.</p>
                </div>
                <div class="p1">
                    <p id="246">对比图3中两种算法的结果可发现, 当动作持续样本数为2时, WOHMM的表现略差于Baum-Welch.随着持续样本数的增大, WOHMM表现逐渐优于Baum-Welch.主要原因如下:由于WOHMM中不同隐状态的加权观测概率差异较小, 当动作持续样本数较少时, WHOMM更易受错误识别结果的影响.当动作持续样本数增大后, 错误识别结果的影响变小, WOHMM结果也变优.然而参数学习一般需要一段较长的识别结果序列, 在较长的序列中, 动作持续样本数较小的情况较少, 所以实际应用中动作样本数较小对最终学习到的参数影响不大.</p>
                </div>
                <h4 class="anchor-tag" id="247" name="247"><b>3.3</b> 序列标注算法的对比实验</h4>
                <div class="p1">
                    <p id="248">序列标注算法的目的是对给定的观测向量序列<b><i>O</i></b>进行平滑处理, 尽可能将错误的识别结果修改正确.当前有多种方法可以实现这一目的, 如经典图模型HMM、条件随机场 (Conditional Random Field, CRF) , 融合权值的LCCAS<citation id="350" type="reference"><link href="318" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、长短期记忆神经网络 (Long Short-Term Memory, LSTM) .本节通过对比算法3与当前已有算法, 验证WOHMM序列标注算法的有效性.使用不同用户的样本作为测试数据时不同算法的识别率如图4所示, 所有用户不同算法的平均识别率如图5所示, 图中的序列重组样本持续长度均设置为5.其中原结果为直接使用SVM分类的识别率, HMM、CRF、LCCAS、LSTM为使用相应序列标注方法对原结果修正后的识别率, WOHMM为本文算法结果.</p>
                </div>
                <div class="area_img" id="249">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906004_249.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同算法在用户1至用户10上的识别率" src="Detail/GetImg?filename=images/MSSB201906004_249.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同算法在用户1至用户10上的识别率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906004_249.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Recognition rates of different methods for user 1 to 10</p>

                </div>
                <div class="area_img" id="250">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906004_250.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同算法在所有用户上的平均识别率" src="Detail/GetImg?filename=images/MSSB201906004_250.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同算法在所有用户上的平均识别率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906004_250.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Mean recognition rates of different algorithms for all users</p>

                </div>
                <div class="p1">
                    <p id="252">从图4可看出, 不同算法在不同用户数据上的表现差异较大.在用户3测试数据上, LCCAS表现最佳;在用户5、用户9等部分测试数据上LSTM表现最佳;在用户1、用户2等数据集上WOHMM表现最佳.这种现象主要是由用户样本分布的差异性导致的.</p>
                </div>
                <div class="p1">
                    <p id="253">从图5的平均识别率可看出, 在所有算法中, WOHMM稍优于LSTM, 两类算法明显优于其它算法.在其余4种算法中, HMM和CRF明显优于不进行平滑处理的原结果和LCCAS.</p>
                </div>
                <div class="p1">
                    <p id="254">虽然HMM和CRF序列建模的方式不同, 但二者有一个共同点, 即两种算法皆以识别结果序列为基础, 并未考虑每个识别结果的权值, 因此两类算法的识别率相差不大.而WOHMM在搜索最优动作序列时考虑每个分类结果的权值, 尽量修改权值较低的结果, 得到比两类方法更高的识别率.</p>
                </div>
                <div class="p1">
                    <p id="255">观察图4和图5中的LCCAS可发现, 虽然平均识别率与不进行平滑处理基本持平, 但LCCAS表现波动非常大.用户5的识别率提高6%左右, 而用户1的识别率降低近9%.通过分析LCCAS可发现, 主要使用递推的方法修改识别结果, 在正确结果的权值较高时表现较优, 在正确结果的权值较低时易造成误差积累, 导致识别率波动较大, 平均识别率不高.</p>
                </div>
                <div class="p1">
                    <p id="256">LSTM为深度序列模型, 在自然语言处理领域的应用较为成功.该方法取得较好效果的前提是有大量的历史训练数据作支撑.与自然语言处理等领域不同, 人体在不同时间段内的动作及其转换关系具有不确定性且毫无规律, 因此无法使用历史动作序列训练一个适用于所有时间段的通用LSTM模型.而单一序列又无法充分训练模型, 进而无法体现深度模型的优势.相比之下, 使用动作的转换矩阵描述动作序列比训练不充分的LSTM参数更合理有效, 这也是WOHMM结果优于LSTM的主要原因.从另一个角度说, 深度模型的参数数量远多于本文算法, 训练过程需要大量计算, 由此决定深度模型不适用于计算能力较弱的可穿戴设备或智能手机.</p>
                </div>
                <div class="p1">
                    <p id="257">为了更进一步分析动作持续样本数的影响, 图6给出动作持续样本数不同时, 各算法的识别率变化情况.</p>
                </div>
                <div class="area_img" id="258">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906004_258.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同动作持续样本数时不同算法的识别率" src="Detail/GetImg?filename=images/MSSB201906004_258.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同动作持续样本数时不同算法的识别率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906004_258.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Recognition rates of different algorithms varying with different activity durations</p>

                </div>
                <div class="p1">
                    <p id="260">如图6所示, 随着动作持续样本数的增大, 不同序列标注算法的识别率逐渐增大, LSTM的增长较缓慢.主要原因如下.HMM、CRF、LCCAS和WOHMM的参数皆与动作的持续样本数直接相关, 动作持续样本数增大时, 训练得到的模型更易反映动作序列的变化规律, 进而提高识别率.但LSTM的参数与动作持续样本数并无直接关系, 模型好坏与训练样本数量及参数训练程度有关, 因此动作持续样本数对模型影响较小.综上所述, 随着动作持续样本数增大, 在动作持续时间较长的应用场景中本文算法明显优于LSTM.</p>
                </div>
                <h3 id="261" name="261" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="262">HMM在基于传感器的人体动作识别领域具有重要应用.针对HMM无法处理动作识别的权值信息, 本文提出加权观测的改进隐马尔可夫模型 (WOHMM) , 给出模型的概率计算、参数学习、序列标注的解决算法.实验中使用公开数据集对参数学习及序列标注算法进行仿真.实验表明, 相比HMM中的Baum-Welch算法, 本文的参数学习算法学习得到的动作转移矩阵更接近真实的动作转移矩阵.在动作识别的平滑处理问题上, 本文提出的序列标注算法优于图模型算法和LSTM.除了动作识别问题, 计算机领域的许多问题也可抽象为带权值信息的时间序列问题, 将WOHMM应用于这些领域是未来值得研究的课题.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="283" type="formula" href="images/MSSB201906004_28300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">王昌海</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="284" type="formula" href="images/MSSB201906004_28400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">李哲辉</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="285" type="formula" href="images/MSSB201906004_28500.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">王博</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="286" type="formula" href="images/MSSB201906004_28600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">许昱玮</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="287" type="formula" href="images/MSSB201906004_28700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">黄万伟</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="294">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM14041100000366&amp;v=MTU1OTBzUEQzby9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRm9VYnhZPU5pZklZN0s4SHRYTnJvOUZaTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> BULLING A, BLANKE U, SCHIELE B.A Tutorial on Human Activity Recognition Using Body-Worn Inertial Sensors.ACM Computing Surveys, 2014, 46 (3) .DOI:10.1145/2499621.
                            </a>
                        </p>
                        <p id="296">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Human Activity Recognition for Emergency First Responders via Body-Worn Inertial Sensors">

                                <b>[2]</b> SCHEURER S, TEDESCO S, BROWN K N, et al.Human Activity Recognition for Emergency First Responders via Body-Worn Inertial Sensors // Proc of the 14th IEEE International Conference on Wearable and Implantable Body Sensor Networks.Washington, USA:IEEE, 2017:5-8.
                            </a>
                        </p>
                        <p id="298">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Review of Smart House Analysis Methods for Assisting Older People Living Alone">

                                <b>[3]</b> SANCHEZ V G, PFEIFFER C F, SKEIE N O.A Review of Smart House Analysis Methods for Assisting Older People Living Alone.Journal of Sensor and Actuator Networks, 2017, 6 (3) .DOI:10.3390/jsan6030011.
                            </a>
                        </p>
                        <p id="300">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM5133F74328AB10FC2E6EA6F603ED64D9&amp;v=MDE0OTBOK2ZuMDV1V1VSbnprSU9YbVVxaEkyRE1hU1FjNldDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3THkveGF3PU5pZklZN2E1SGRLNnFJdEdadQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> YANG Z, WU C S, ZHOU Z, et al.Mobility Increases Localizability:A Survey on Wireless Indoor Localization Using Inertial Sensors.ACM Computing Surveys, 2015, 47 (3) .DOI:10.1145/2676430.
                            </a>
                        </p>
                        <p id="302">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Let′s (not) Stick Together:Pairwise Similarity Biases Cross-Validation in Activity Recognition">

                                <b>[5]</b> HAMMERLA N Y, PLOETZ T.Let′s (not) Stick Together:Pairwise Similarity Biases Cross-Validation in Activity Recognition // Proc of the ACM International Joint Conference on Pervasive and Ubiquitous Computing.New York, USA:ACM, 2015:1041-1051.
                            </a>
                        </p>
                        <p id="304">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESA1A0AE7EAB561B086A366615E4285E22&amp;v=MDE4MTFtYUJ1SFlmT0dRbGZDcGJRMzVORmh3THkveGF3PU5pZk9mY0s1YjlHOTJvZ3dGWmtLQ24xTHp4NFZteng3VG5uanFXY3hlN3FSTUxpZENPTnZGU2lXV3I3SklGcA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> WANG Z L, WU D H, GRAVINA R, et al.Kernel Fusion Based Extreme Learning Machine for Cross-Location Activity Recognition.Information Fusion, 2017, 37:1-9.
                            </a>
                        </p>
                        <p id="306">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000104593&amp;v=MjM4NjRieFk9TmlmSVk3SzdIdGpOcjQ5Rlplc0xDWFU2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZvVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> HOSEINI-TABATABAEI S A, GLUHAK A, TAFAZOLLI R.A Survey on Smartphone-Based Systems for Opportunistic User Context Recognition.ACM Computing Surveys, 2013, 45 (3) .DOI:10.1145/2480741.2480744.
                            </a>
                        </p>
                        <p id="308">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving activity recognition via automatic decision tree pruning">

                                <b>[8]</b> PHAN T.Improving Activity Recognition via Automatic Decision Tree Pruning // Proc of the ACM International Joint Conference on Pervasive and Ubiquitous Computing.New York, USA:ACM, 2014:827-832.
                            </a>
                        </p>
                        <p id="310">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analysis of low resolution accelerometer data for continuous human activity recognition">

                                <b>[9]</b> KRISHNAN N C, PANCHANATHAN S.Analysis of Low Resolution Accelerometer Data for Continuous Human Activity Recognition // Proc of the IEEE International Conference on Acoustics, Speech and Signal Processing.Washington, USA:IEEE, 2008:3337-3340.
                            </a>
                        </p>
                        <p id="312">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;A novel energy-efficient approach for human activity recognition.&amp;quot;">

                                <b>[10]</b> ZHENG L X, WU D H, RUAN X Y, et al.A Novel Energy-Efficient Approach for Human Activity Recognition.Sensors, 2017, 17 (9) .DOI:10.3390/s17092064.
                            </a>
                        </p>
                        <p id="314">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Advancing Android activity recognition service with Markov smoother">

                                <b>[11]</b> ZHONG M Y, WEN J H, HU P Z, et al.Advancing Android Activity Recognition Service with Markov Smoother // Proc of the IEEE International Conference on Pervasive Computing and Communication Workshops.Washington, USA:IEEE, 2015:38-43.
                            </a>
                        </p>
                        <p id="316">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Advancing Android Activity Recognition Service with Markov Smoother:Practical Solutions">

                                <b>[12]</b> ZHONG M Y, WEN J H, HU P Z, et al.Advancing Android Activity Recognition Service with Markov Smoother:Practical Solutions.Pervasive and Mobile Computing, 2017, 38:60-76.
                            </a>
                        </p>
                        <p id="318">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Activity classification at a higher level:what to do after the classifier does its best">

                                <b>[13]</b> YOUNES R, MARTIN T L, JONES M.Activity Classification at a Higher Level:What to Do After the Classifier Does Its Best?// Proc of the ACM International Symposium on Wearable Computers.New York, USA:ACM, 2015:83-86.
                            </a>
                        </p>
                        <p id="320">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=WOODY A Post-Process Method for Smartphone-Based Activity Recognition">

                                <b>[14]</b> WANG C H, XU Y W, LIANG H, et al.WOODY:A Post-Process Method for Smartphone-Based Activity Recognition.IEEE Access, 2018, 6:49611-49625.
                            </a>
                        </p>
                        <p id="322">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An introduction to hidden Markov models">

                                <b>[15]</b> RABINER L, JUANG B.An Introduction to Hidden Markov Mo-dels.IEEE Assp Magazine, 1986, 3 (3) :4-16.
                            </a>
                        </p>
                        <p id="324">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Creating General Model for Activity Recognition with Minimum Labelled Data">

                                <b>[16]</b> WEN J H, ZHONG M Y, INDULSKA J.Creating General Model for Activity Recognition with Minimum Labelled Data // Proc of the ACM International Symposium on Wearable Computers.New York, USA:ACM, 2015:87-90.
                            </a>
                        </p>
                        <p id="326">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES4A784231158E54D782058D110356986B&amp;v=MTcyMTdZeEVaZTRIZVhrOXV4RWI2RDk0UUF2anJSSTJmTFNkVGJ6dENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaHdMeS94YXc9TmlmT2ZiZkpHZG5Jcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> WEN J H, WANG Z Y.Learning General Model for Activity Re-cognition with Limited Labelled Data.Expert Systems with Applications, 2017, 74 (15) :19-28.
                            </a>
                        </p>
                        <p id="328">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hidden Markov Model Ensemble for Activity Recognition Using Tri-axis Accelerometer">

                                <b>[18]</b> KIM Y J, KANG B N, KIM D.Hidden Markov Model Ensemble for Activity Recognition Using Tri-axis Accelerometer // Proc of the IEEE International Conference on Systems, Man, and Cybernetics.Washington, USA:IEEE, 2015:3036-3041.
                            </a>
                        </p>
                        <p id="330">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZXU201703010&amp;v=MTM2MTJGeXpoVTdyTUlUZlRlN0c0SDliTXJJOUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 汪成亮, 王小均.基于三轴传感器的老年人日常活动识别.电子学报, 2017, 45 (3) :570-576. (WANG C L, WANG X J.Daily Activity Recognition Based on Triaxial Accelerometer of Elderly People.Acta Electronica Sinica, 2017, 45 (3) :570-576.) 
                            </a>
                        </p>
                        <p id="332">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXXB201605017&amp;v=MDY5MjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emhVN3JNTVRYVGJMRzRIOWZNcW85RVk0UUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 王昌海, 张建忠, 徐敬东, 等.基于HMM的动作识别结果可信度计算方法.通信学报, 2016, 37 (5) :143-151. (WANG C H, ZHANG J Z, XU J D, et al.Identifying the Confidence Level of Activity Recognition via HMM.Journal on Communications, 2016, 37 (5) :143-151.) 
                            </a>
                        </p>
                        <p id="334">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SW-HMM a Method for Evaluating Confidence of Smartphone-Based Activity Recognition">

                                <b>[21]</b> WANG C H, XU Y W, ZHANG J Z, et al.SW-HMM:a Method for Evaluating Confidence of Smartphone-Based Activity Recognition // Proc of the International Symposium on Parallel and Distributed Processing with Applications.Washington, USA:IEEE, 2016:2086-2091.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201906004" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201906004&amp;v=MzIwODFyQ1VSTE9lWmVSbkZ5emhVN3JNS0Q3WWJMRzRIOWpNcVk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
