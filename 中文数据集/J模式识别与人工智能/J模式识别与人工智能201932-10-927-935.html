<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131461104248750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201910008%26RESULT%3d1%26SIGN%3dZVA7aCF8fkqu32a6htCkA175WNQ%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201910008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201910008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201910008&amp;v=MzI0MzlHRnJDVVJMT2VaZVJuRnkva1dyM0pLRDdZYkxHNEg5ak5yNDlGYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#215" data-title="1 面向FPGA的量化方法的改进 ">1 面向FPGA的量化方法的改进</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#220" data-title="&lt;b&gt;1.1&lt;/b&gt; 量化模型精简"><b>1.1</b> 量化模型精简</a></li>
                                                <li><a href="#235" data-title="&lt;b&gt;1.2&lt;/b&gt; 网络输出量化"><b>1.2</b> 网络输出量化</a></li>
                                                <li><a href="#248" data-title="&lt;b&gt;1.3&lt;/b&gt; 批量归一化层整合"><b>1.3</b> 批量归一化层整合</a></li>
                                                <li><a href="#256" data-title="&lt;b&gt;1.4&lt;/b&gt; 激活函数近似"><b>1.4</b> 激活函数近似</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#260" data-title="2 YOLO网络加速方案 ">2 YOLO网络加速方案</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#262" data-title="&lt;b&gt;2.1&lt;/b&gt; 计算架构"><b>2.1</b> 计算架构</a></li>
                                                <li><a href="#267" data-title="&lt;b&gt;2.2&lt;/b&gt; 卷积运算并行优化"><b>2.2</b> 卷积运算并行优化</a></li>
                                                <li><a href="#276" data-title="&lt;b&gt;2.3&lt;/b&gt; 激活、池化运算流水处理"><b>2.3</b> 激活、池化运算流水处理</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#282" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#283" data-title="&lt;b&gt;3.1&lt;/b&gt; 量化方法改进的有效性验证"><b>3.1</b> 量化方法改进的有效性验证</a></li>
                                                <li><a href="#292" data-title="&lt;b&gt;3.2 FPGA&lt;/b&gt;加速结果"><b>3.2 FPGA</b>加速结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#307" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#219" data-title="图1 定点化的训练过程与前向计算过程">图1 定点化的训练过程与前向计算过程</a></li>
                                                <li><a href="#247" data-title="图2 变量&lt;i&gt;M&lt;/i&gt;近似计算分解">图2 变量<i>M</i>近似计算分解</a></li>
                                                <li><a href="#265" data-title="图3 单层网络计算结构">图3 单层网络计算结构</a></li>
                                                <li><a href="#273" data-title="图4 卷积计算并行结构">图4 卷积计算并行结构</a></li>
                                                <li><a href="#281" data-title="图5 激活、池化流水计算结构">图5 激活、池化流水计算结构</a></li>
                                                <li><a href="#289" data-title="图6 不同位宽下的量化过程">图6 不同位宽下的量化过程</a></li>
                                                <li><a href="#291" data-title="&lt;b&gt;表1 2种方法量化前后误差对比&lt;/b&gt;"><b>表1 2种方法量化前后误差对比</b></a></li>
                                                <li><a href="#297" data-title="图7 FPGA实现框架">图7 FPGA实现框架</a></li>
                                                <li><a href="#300" data-title="&lt;b&gt;表2 FPGA资源使用情况&lt;/b&gt;"><b>表2 FPGA资源使用情况</b></a></li>
                                                <li><a href="#303" data-title="&lt;b&gt;表3 3种方法耗时对比&lt;/b&gt;"><b>表3 3种方法耗时对比</b></a></li>
                                                <li><a href="#306" data-title="&lt;b&gt;表4 3种方法的FPGA实现对比&lt;/b&gt;"><b>表4 3种方法的FPGA实现对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="335">


                                    <a id="bibliography_1" title=" LECUN Y,BENGIO Y,HINTO G.Deep Learning.Nature,2015,521(7553):436-444." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep learning">
                                        <b>[1]</b>
                                         LECUN Y,BENGIO Y,HINTO G.Deep Learning.Nature,2015,521(7553):436-444.
                                    </a>
                                </li>
                                <li id="337">


                                    <a id="bibliography_2" title=" RUSSAKOVSHY O,DENG J,SU H,et al.Imagenet Large Scale Visual Recognition Challenge.International Journal of Computer Vision,2015,115(3):211-252." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Net large scale visual recognition challenge">
                                        <b>[2]</b>
                                         RUSSAKOVSHY O,DENG J,SU H,et al.Imagenet Large Scale Visual Recognition Challenge.International Journal of Computer Vision,2015,115(3):211-252.
                                    </a>
                                </li>
                                <li id="339">


                                    <a id="bibliography_3" title=" GIRSHICK R.Fast R-CNN // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2015:1440-1448." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast r-cnn">
                                        <b>[3]</b>
                                         GIRSHICK R.Fast R-CNN // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2015:1440-1448.
                                    </a>
                                </li>
                                <li id="341">


                                    <a id="bibliography_4" title=" SHELLHAMER E,LONG J,DARRELL T.Fully Convolutional Networks for Semantic Segmentation.IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(4):640-651." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">
                                        <b>[4]</b>
                                         SHELLHAMER E,LONG J,DARRELL T.Fully Convolutional Networks for Semantic Segmentation.IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(4):640-651.
                                    </a>
                                </li>
                                <li id="343">


                                    <a id="bibliography_5" title=" ZHANG Y,PEZESHKI M,BRAKEL P,et al.Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks[C/OL].[2019-05-25].https://arxiv.org/pdf/1701.02720.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks[C/OL]">
                                        <b>[5]</b>
                                         ZHANG Y,PEZESHKI M,BRAKEL P,et al.Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks[C/OL].[2019-05-25].https://arxiv.org/pdf/1701.02720.pdf.
                                    </a>
                                </li>
                                <li id="345">


                                    <a id="bibliography_6" title=" SIMONYAN K,ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2019-05-25].https://arxiv.org/pdf/1409.1556.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[6]</b>
                                         SIMONYAN K,ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2019-05-25].https://arxiv.org/pdf/1409.1556.pdf.
                                    </a>
                                </li>
                                <li id="347">


                                    <a id="bibliography_7" title=" NURVITADHI E,VENKATESH G,SIM J,et al.Can FPGAs Beat GPUs in Accelerating Next-Generation Deep Neural Networks?// Proc of the ACM/SIGDA International Symposium on Field-Programm-able Gate Arrays.New York,USA:ACM,2017:5-14." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Can FPGAs Beat GPUs in Accelerating Next-Generation Deep Neural Networks?">
                                        <b>[7]</b>
                                         NURVITADHI E,VENKATESH G,SIM J,et al.Can FPGAs Beat GPUs in Accelerating Next-Generation Deep Neural Networks?// Proc of the ACM/SIGDA International Symposium on Field-Programm-able Gate Arrays.New York,USA:ACM,2017:5-14.
                                    </a>
                                </li>
                                <li id="349">


                                    <a id="bibliography_8" title=" 吴建鑫,高斌斌,魏秀参,等.资源受限的深度学习:挑战与实践.中国科学(信息科学),2018,48(5):501-510.(WU J X,GAO B B,WEI X S,et al.Resource-Constrained Deep Learning:Challenges and Practices.Chinese Science(Information Science),2018,48(5):501-510.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201805003&amp;v=MjQ2MjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5L2tXcjNKTlRmQWRyRzRIOW5NcW85Rlo0UUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         吴建鑫,高斌斌,魏秀参,等.资源受限的深度学习:挑战与实践.中国科学(信息科学),2018,48(5):501-510.(WU J X,GAO B B,WEI X S,et al.Resource-Constrained Deep Learning:Challenges and Practices.Chinese Science(Information Science),2018,48(5):501-510.)
                                    </a>
                                </li>
                                <li id="351">


                                    <a id="bibliography_9" title=" GOKHALE V,JIN J,DUNDAR A,et al.A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks // Proc of the IEEE Confe-rence on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2014:682-687." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks">
                                        <b>[9]</b>
                                         GOKHALE V,JIN J,DUNDAR A,et al.A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks // Proc of the IEEE Confe-rence on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2014:682-687.
                                    </a>
                                </li>
                                <li id="353">


                                    <a id="bibliography_10" title=" 刘志成,祝永新,汪辉,等.基于FPGA的卷积神经网络并行加速结构设计.微电子学与计算机,2018,35(10):80-84.(LIU Z C,ZHU Y X,WANG H,et al.Parallel Acceleration Structure Design of Convolutional Neural Network Based on FPGA.Microelectronics and Computer,2018,35(10):80-84.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201810016&amp;v=MTEzMjNVUkxPZVplUm5GeS9rV3IzSk1qWFNaTEc0SDluTnI0OUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         刘志成,祝永新,汪辉,等.基于FPGA的卷积神经网络并行加速结构设计.微电子学与计算机,2018,35(10):80-84.(LIU Z C,ZHU Y X,WANG H,et al.Parallel Acceleration Structure Design of Convolutional Neural Network Based on FPGA.Microelectronics and Computer,2018,35(10):80-84.)
                                    </a>
                                </li>
                                <li id="355">


                                    <a id="bibliography_11" title=" SANKARADAS M,JAKKULA V,CADAMBI S,et al.A Massively Parallel Coprocessor for Convolutional Neural Networks // Proc of the IEEE International Conference on Application-Specific Systems.Washington,USA:IEEE,2009:53-60." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Massively Parallel Coprocessor for Convolutional Neural Networks">
                                        <b>[11]</b>
                                         SANKARADAS M,JAKKULA V,CADAMBI S,et al.A Massively Parallel Coprocessor for Convolutional Neural Networks // Proc of the IEEE International Conference on Application-Specific Systems.Washington,USA:IEEE,2009:53-60.
                                    </a>
                                </li>
                                <li id="357">


                                    <a id="bibliography_12" title=" ZHANG C,LI P,SUN G Y,et al.Optimizing FPGA-Based Accelerator Design for Deep Convolutional Neural Networks // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2015:161-170." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimizing FPGA-based acelerator dsign for deep convolutional neural networks">
                                        <b>[12]</b>
                                         ZHANG C,LI P,SUN G Y,et al.Optimizing FPGA-Based Accelerator Design for Deep Convolutional Neural Networks // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2015:161-170.
                                    </a>
                                </li>
                                <li id="359">


                                    <a id="bibliography_13" title=" 余子健.基于FPGA的卷积神经网络加速器.硕士学位论文.杭州:浙江大学,2016.(YU Z J.Convolutional Neural Network Accelerator Based on FPGA.Master Dissertation.Hangzhou,China:Zhejiang University,2016.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016066075.nh&amp;v=MDU1MzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5L2tXcjNKVkYyNkdMTytHTkhMcXBFYlA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         余子健.基于FPGA的卷积神经网络加速器.硕士学位论文.杭州:浙江大学,2016.(YU Z J.Convolutional Neural Network Accelerator Based on FPGA.Master Dissertation.Hangzhou,China:Zhejiang University,2016.)
                                    </a>
                                </li>
                                <li id="361">


                                    <a id="bibliography_14" title=" ZHANG C,PRASANNA V.Frequency Domain Acceleration of Convolutional Neural Networks on CPU-FPGA Shared Memory System // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2017:35-44." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Frequency Domain Acceleration of Convolutional Neural Networks on CPU-FPGA Shared Memory System">
                                        <b>[14]</b>
                                         ZHANG C,PRASANNA V.Frequency Domain Acceleration of Convolutional Neural Networks on CPU-FPGA Shared Memory System // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2017:35-44.
                                    </a>
                                </li>
                                <li id="363">


                                    <a id="bibliography_15" title=" DICECCO R,LACEY G,VASILJEVIC J,et al.Caffeinated FPGAs:FPGA Framework for Convolutional Neural Networks // Proc of the IEEE International Conference on Field-Programmable Technology.Washington,USA:IEEE,2016:265-268." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Caffeinated FPGAs:FPGA framework for convolutional neural networks">
                                        <b>[15]</b>
                                         DICECCO R,LACEY G,VASILJEVIC J,et al.Caffeinated FPGAs:FPGA Framework for Convolutional Neural Networks // Proc of the IEEE International Conference on Field-Programmable Technology.Washington,USA:IEEE,2016:265-268.
                                    </a>
                                </li>
                                <li id="365">


                                    <a id="bibliography_16" title=" AYDONAT U,O&#39;CONNELL S,CAPALIJA D,et al.An OpenCL&lt;sup&gt;TM&lt;/sup&gt; Deep Learning Accelerator on Arria 10 // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2017:55-64." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An OpenCLTM deep learning accelerator on arria 10">
                                        <b>[16]</b>
                                         AYDONAT U,O&#39;CONNELL S,CAPALIJA D,et al.An OpenCL&lt;sup&gt;TM&lt;/sup&gt; Deep Learning Accelerator on Arria 10 // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2017:55-64.
                                    </a>
                                </li>
                                <li id="367">


                                    <a id="bibliography_17" title=" HAN S,MAO H Z,DALLY W J.Deep Compression:Compre-ssing Deep Neural Networks with Pruning,Trained Quantization and Huffman Coding[C/OL].[2019-05-25].https://arxiv.org/pdf/1510.00149.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Compression:Compre-ssing Deep Neural Networks with Pruning,Trained Quantization and Huffman Coding[C/OL]">
                                        <b>[17]</b>
                                         HAN S,MAO H Z,DALLY W J.Deep Compression:Compre-ssing Deep Neural Networks with Pruning,Trained Quantization and Huffman Coding[C/OL].[2019-05-25].https://arxiv.org/pdf/1510.00149.pdf.
                                    </a>
                                </li>
                                <li id="369">


                                    <a id="bibliography_18" title=" CHEN W L,WILSON J,TYREE S,et al.Compressing Neural Networks with the Hashing Trick.Proceedings of Machine Learning Research,2015,37:2285-2294." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Compressing Neural Networks with the Hashing Trick">
                                        <b>[18]</b>
                                         CHEN W L,WILSON J,TYREE S,et al.Compressing Neural Networks with the Hashing Trick.Proceedings of Machine Learning Research,2015,37:2285-2294.
                                    </a>
                                </li>
                                <li id="371">


                                    <a id="bibliography_19" title=" VANHOUCKE V,SENIOR A,MAO M Z.Improving the Speed of Neural Networks on CPUs [C/OL].[2019-05-15].http://www.andrewsenior.com/papers/VanhouckeNIPS11.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving the Speed of Neural Networks on CPUs [C/OL]">
                                        <b>[19]</b>
                                         VANHOUCKE V,SENIOR A,MAO M Z.Improving the Speed of Neural Networks on CPUs [C/OL].[2019-05-15].http://www.andrewsenior.com/papers/VanhouckeNIPS11.pdf.
                                    </a>
                                </li>
                                <li id="373">


                                    <a id="bibliography_20" title=" JACOB B,KLIGYS S,CHEN B,et al.Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2018:2704-2713." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference">
                                        <b>[20]</b>
                                         JACOB B,KLIGYS S,CHEN B,et al.Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2018:2704-2713.
                                    </a>
                                </li>
                                <li id="375">


                                    <a id="bibliography_21" title=" REDMON J,DIVVALA S,GIRSHICK R,et al.You Only Look Once:Unified,Real-Time Object Detection // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2016:779-788." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">
                                        <b>[21]</b>
                                         REDMON J,DIVVALA S,GIRSHICK R,et al.You Only Look Once:Unified,Real-Time Object Detection // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2016:779-788.
                                    </a>
                                </li>
                                <li id="377">


                                    <a id="bibliography_22" title=" MIGACZ S.8-Bit Inference with TensorRT // Proc of the GPU Technology Conference.Berlin,Germany:Springer,2017:2-7." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=8-Bit Inference with TensorRT">
                                        <b>[22]</b>
                                         MIGACZ S.8-Bit Inference with TensorRT // Proc of the GPU Technology Conference.Berlin,Germany:Springer,2017:2-7.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(10),927-935 DOI:10.16451/j.cnki.issn1003-6059.201910007            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于异构FPGA的卷积网络加速器</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E9%94%A1%E9%9B%84&amp;code=42588134&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周锡雄</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%92%9F%E8%83%9C&amp;code=07605369&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">钟胜</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E4%BC%9F%E4%BF%8A&amp;code=30696114&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张伟俊</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%BB%BA%E8%BE%89&amp;code=07592486&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王建辉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%AD%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AD%A6%E9%99%A2&amp;code=0045381&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华中科技大学人工智能与自动化学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于神经网络的方法计算量通常十分庞大,限制方法在嵌入式场景领域的应用.为了解决这一问题,文中提出基于异构现场可编程门阵列的卷积网络加速器.采用滑动窗并行加速卷积计算过程,可同时处理不同输入、输出通道的卷积过程.同时结合网络量化过程进行8 bit定点加速器设计,降低计算资源的使用.实验表明,文中定点加速器运算速度较快,功耗较小,算法性能损失较小.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%8E%B0%E5%9C%BA%E5%8F%AF%E7%BC%96%E7%A8%8B%E9%97%A8%E9%98%B5%E5%88%97(FPGA)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">现场可编程门阵列(FPGA);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E9%80%9F%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加速器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B9%B6%E8%A1%8C%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">并行化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%9A%E7%82%B9%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">定点化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    周锡雄,硕士研究生,主要研究方向为深度神经网络、并行计算．E-mail:472838511@qq.com.&lt;image id="331" type="formula" href="images/MSSB201910008_33100.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    *钟胜(通讯作者),博士,教授,主要研究方向为模式识别、图像处理、实时嵌入式系统．E-mail:zhongsheng@hust.edu.cn.&lt;image id="332" type="formula" href="images/MSSB201910008_33200.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    张伟俊,博士研究生,主要研究方向为计算机视觉、模式识别．E-mail:starfire.zhang@gmail.com.&lt;image id="333" type="formula" href="images/MSSB201910008_33300.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    王建辉,博士研究生,主要研究方向为计算机视觉、机器学习、深度神经网络、并行计算．E-mail:wang.ddu@gmail.com.&lt;image id="334" type="formula" href="images/MSSB201910008_33400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-04</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(No.61806081)资助;</span>
                    </p>
            </div>
                    <h1><b>Heterogeneous FPGA Based Convolutional Network Accelerator</b></h1>
                    <h2>
                    <span>ZHOU Xixiong</span>
                    <span>ZHONG Sheng</span>
                    <span>ZHANG Weijun</span>
                    <span>WANG Jianhui</span>
            </h2>
                    <h2>
                    <span>School of Artificial Intelligence and Automation,Huazhong University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Computational complexity of neural network methods is high, and its application in embedded scenarios is limited. To solve this problem, a convolutional network accelerator based on heterogeneous field programmable gate array is proposed. The sliding window is employed to accelerate the convolution calculation process, and thus the convolution process of different input and output channels can be handled. A 8 bit fixed-point accelerator is designed combining network quantization process, and the usage of computing resources is reduced. Experiments demonstrate that the proposed fixed-point accelerator achieves a higher computing speed and a lower power consumption with a less performance loss.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Field%20Programmable%20Gate%20Array(FPGA)&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Field Programmable Gate Array(FPGA);</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Accelerator&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Accelerator;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Parallelism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Parallelism;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fixed-Point&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Fixed-Point;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHOU Xixiong,master student. His research interests include deep neural network and parallel computing.;
                                </span>
                                <span>
                                    ZHONG Sheng(Corresponding author), Ph. D.,professor. His research interests include pattern recognition, image processing and real-time embedded system.;
                                </span>
                                <span>
                                    ZHANG Weijun,Ph.D. candidate. His research interests include computer vision and pattern recognition.;
                                </span>
                                <span>
                                    WANG Jianhui,Ph.D. candidate. His research interests include computer vision,machine learning,deep neural network and parallel computing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-06-04</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China(No.61806081);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="210">卷积神经网络(Convolutional Neural Network, CNN)<citation id="379" type="reference"><link href="335" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>在机器视觉(如目标分类<citation id="380" type="reference"><link href="337" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、目标检测<citation id="381" type="reference"><link href="339" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、语义分割<citation id="382" type="reference"><link href="341" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等)及语音识别<citation id="383" type="reference"><link href="343" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>领域具有突出性能,但一般网络性能越强所需的计算量越大<citation id="384" type="reference"><link href="345" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>.图形处理器(Graphics Processing Unit, GPU)拥有大量的计算资源<citation id="385" type="reference"><link href="347" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>,可以满足现有神经网络的计算需求,成为深度学习的通用硬件平台.但是一些嵌入式应用场景(如智能手机、安防监控等)对功耗、体积、实时性等方面均具有极大限制,基于GPU实现的方案不能满足这些需求,为此,需要寻求可以实现边缘计算的解决方案<citation id="386" type="reference"><link href="349" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="211">现场可编程门阵列(Field Programmable Gate Array, FPGA)功耗低、并行度高,是深度学习算法嵌入式实现的首选平台之一.对于网络推理过程的加速,FPGA加速器关注于解决算法的实时性问题.</p>
                </div>
                <div class="p1">
                    <p id="212">从计算的数值类型上看,FPGA加速器可分为定点型加速器<citation id="387" type="reference"><link href="351" rel="bibliography" /><link href="353" rel="bibliography" /><link href="355" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>和浮点型加速器<citation id="388" type="reference"><link href="357" rel="bibliography" /><link href="359" rel="bibliography" /><link href="361" rel="bibliography" /><link href="363" rel="bibliography" /><link href="365" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>.定点型加速器采用“主控制器+并行处理单元”架构,针对卷积计算过程设计并行加速单元,实现高效的卷积计算.浮点型加速器或同样针对卷积计算过程设计并行加速单元进行计算加速,或通过变换(如快速傅里叶变化(Fast Fourier Transform, FFT)<citation id="389" type="reference"><link href="361" rel="bibliography" /><link href="363" rel="bibliography" /><link href="365" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>]</sup></citation>),将卷积计算转换为更适合硬件并行实现的过程.</p>
                </div>
                <div class="p1">
                    <p id="213">需要指出的是浮点型加速器计算效率低于定点型加速器,而定点型加速器常忽略定点网络的精度问题.为了解决精度问题,现有的量化方法更多偏向于软件实现,不考虑FPGA的计算特点,计算复杂度较高,实现效率较低<citation id="391" type="reference"><link href="367" rel="bibliography" /><link href="369" rel="bibliography" /><link href="371" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>.Jacob等<citation id="390" type="reference"><link href="373" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出Google(IAO),使用全整型(Integer Arithmetic Only, IAO)计算表达网络的前向推理过程,既满足FPGA平台的计算特点,也保证网络量化后的精度,但计算存在冗余.</p>
                </div>
                <div class="p1">
                    <p id="214">为了满足网络推理计算速度的要求,本文提出基于异构FPGA的卷积网络加速器,采用定点计算,加速YOLO-tiny网络<citation id="392" type="reference"><link href="375" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>.为了兼顾定点计算的精度要求,结合FPGA的计算特点,精简Google(IAO)量化算法,在简化计算的同时保证网络性能.</p>
                </div>
                <h3 id="215" name="215" class="anchor-tag">1 面向FPGA的量化方法的改进</h3>
                <div class="p1">
                    <p id="216">现有神经网络中的操作数均为浮点形式,若仅从数值层面进行浮点到定点数的转换,受有限字长效应影响,产生不可避免的截断误差,进而造成较大的计算误差,网络性能损失严重.数值的量化位宽越低,对计算资源的使用越少,但这种效应越突出.面向资源有限的FPGA平台需要折衷的解决方案,现有的量化方法恰能解决这个问题.</p>
                </div>
                <div class="p1">
                    <p id="217">Google(IAO)<citation id="393" type="reference"><link href="373" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>可以量化网络输入、输出、权重,简化批量归一化(Batch Normalization, BN)层的计算,使量化后的网络推理过程仅用定点计算表达,兼顾降低计算资源的使用及保证量化后的性能.但其量化后的网络推理过程相对冗余,还可以进行计算层面的简化.本文以简化计算为目的,根据现有的网络量化框架,结合FPGA平台的计算特点,合理简化算法的量化模型,采取移位计算处理激活函数,在保障量化网络性能的同时,使网络的推理过程更适合FPGA平台实现.</p>
                </div>
                <div class="p1">
                    <p id="218">定点网络的训练过程及前向推理过程如图1所示.网络定点化算法利用训练过程保证网络性能,量化过程逐层进行.浮点推理过程是为了获取数值的动态范围,进而进行量化过程,当这一层网络量化完毕后,需要将输出的定点结果反量化为浮点型,再进行下一层的量化过程,不断重复.这种基于训练的量化方法存在量化操作与反量化操作,但在实际前向推理过程中,这两个操作相互抵消,保证量化后的网络推理过程使用形式表达.</p>
                </div>
                <div class="area_img" id="219">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910008_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 定点化的训练过程与前向计算过程" src="Detail/GetImg?filename=images/MSSB201910008_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 定点化的训练过程与前向计算过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910008_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Processes of fixed-point training and forward inference</p>

                </div>
                <h4 class="anchor-tag" id="220" name="220"><b>1.1</b> 量化模型精简</h4>
                <div class="p1">
                    <p id="221">本文根据英伟达(NVIDIA)的量化方案<citation id="394" type="reference"><link href="377" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>,直接采取绝对值极值进行动态量化,不设置饱和裁剪,结合Google(IAO)量化框架,利用训练过程弥补量化误差,具体量化模型如下:</p>
                </div>
                <div class="p1">
                    <p id="222" class="code-formula">
                        <mathml id="222"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>A</mi><mo>=</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>A</mi><mo>⋅</mo><mi>Q</mi><mo>_</mo><mi>A</mi></mtd></mtr><mtr><mtd><mo>∀</mo><mi>a</mi><mo>∈</mo><mi>A</mi><mo>,</mo><mo stretchy="false">|</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mo stretchy="false">|</mo><mi>a</mi><mo stretchy="false">|</mo><mo>,</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>A</mi><mo>=</mo><mfrac><mrow><mn>2</mn><mo stretchy="false">|</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">|</mo></mrow><mrow><mn>2</mn><msup><mrow></mrow><mi>n</mi></msup></mrow></mfrac><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="223">其中,<i>A</i>为量化前的浮点数,<i>Q</i>_<i>A</i>为量化后的整数,<i>scale</i>_<i>A</i>为量化系数,需要通过统计数值的绝对值极值求得.本文选择的量化位宽<i>n</i>=8,通过上式可将参数量化至[-127,127],当然,通过调整<i>n</i>的大小也可改变量化位宽.</p>
                </div>
                <div class="p1">
                    <p id="224">在本文模型中,量化后网络的前向推理过程可以表达为2个整数矩阵的乘积的形式:</p>
                </div>
                <div class="p1">
                    <p id="225"><i><b>W</b></i>×<i><b>X</b></i>=<i>scale</i>_<i>W</i>·<i>scale</i>_<i>X</i>·<i><b>QW</b></i>×<i><b>QX</b></i>,</p>
                </div>
                <div class="p1">
                    <p id="226">其中,<i><b>QW</b></i>表示量化后的权重,<i>scale</i>_<i>W</i>表示权重的量化系数,<i><b>QX</b></i>表示量化后的输入,<i>scale</i>_<i>X</i>表示输入的量化系数.Google(IAO)的量化模型为</p>
                </div>
                <div class="p1">
                    <p id="227"><i>A</i>=<i>scale</i>_<i>A</i>(<i>Q</i>_<i>A</i>-<i>ZERO</i>_<i>A</i>),</p>
                </div>
                <div class="p1">
                    <p id="228">其中,<i>scale</i>_<i>A</i>表示量化系数,<i>ZERO</i>_<i>A</i>表示量化零点.</p>
                </div>
                <div class="p1">
                    <p id="229">在该模型下前向推理过程可表示为</p>
                </div>
                <div class="p1">
                    <p id="230"><i>M</i>(<i><b>QW</b></i>×<i><b>QX</b></i>-<i><b>QW</b></i>×<i><b>ZERO</b></i>_<i><b>X</b></i>-<i><b>ZERO</b></i>_<i><b>W</b></i>×<i><b>QX</b></i>+<i><b>ZERO</b></i>_<i><b>W</b></i>×<i><b>ZERO</b></i>_<i><b>X</b></i>),</p>
                </div>
                <div class="p1">
                    <p id="232">其中:<i>M</i>为标量,表示量化系数的乘积,</p>
                </div>
                <div class="p1">
                    <p id="233"><i>M</i>=<i>scale</i>_<i>W</i>·<i>scale</i>_<i>X</i>.</p>
                </div>
                <div class="p1">
                    <p id="234"><i><b>QW</b></i>为量化后的权重矩阵,<i><b>ZERO</b></i>_<i><b>W</b></i>为权重零点矩阵,<i><b>QX</b></i>为量化后的输入矩阵,<i><b>ZERO</b></i>_<i><b>X</b></i>为输入的零点矩阵.不难看出精简后的模型可以减少至少75%的计算量.</p>
                </div>
                <h4 class="anchor-tag" id="235" name="235"><b>1.2</b> 网络输出量化</h4>
                <div class="p1">
                    <p id="236">一般而言,量化只针对权重或输入进行量化,通过这种量化方式,可以使用FPGA平台对单层的计算进行加速,但在计算前,需要将浮点型权重及输入量化成定点才能供给FPGA,不能在FPGA上实现全流程的网络加速.Google(IAO)不仅对输入、权重进行量化,对网络的输出也进行量化,使输出结果可以直接用于下一层的计算,不需要转换过程.对于卷积网络的输出,是权重与输入特征图卷积的结果,套用量化模型,量化过程如下:</p>
                </div>
                <div class="p1">
                    <p id="237" class="code-formula">
                        <mathml id="237"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><mo>_</mo><mi>Y</mi><mo>=</mo><mfrac><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>W</mi><mo>⋅</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>X</mi></mrow><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>Y</mi></mrow></mfrac><mo>⋅</mo><mi>Q</mi><mo>_</mo><mi>W</mi><mo>⋅</mo><mi>Q</mi><mo>_</mo><mi>X</mi><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="238">其中,<i>Q</i>_<i>Y</i>为输出的量化结果,<i>scale</i>_<i>Y</i>为输出的量化系数,<i>Q</i>_<i>W</i>为量化权重,<i>Q</i>_<i>X</i>为量化输入.</p>
                </div>
                <div class="p1">
                    <p id="239">输出的量化计算会出现在前向推理过程中,由于该计算过程存在浮点运算操作,为了保证网络的前向推理过程只涉及定点计算,需要对该过程进行近似计算.不难看出浮点计算主要由量化尺度参数导致,令变量<i>M</i>代替浮点计算部分,</p>
                </div>
                <div class="p1">
                    <p id="240" class="code-formula">
                        <mathml id="240"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mo>=</mo><mfrac><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>W</mi><mo>⋅</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>X</mi></mrow><mrow><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>_</mo><mi>Y</mi></mrow></mfrac><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="241">在此,需要对<i>M</i>进行近似计算.</p>
                </div>
                <div class="p1">
                    <p id="242">对<i>M</i>反复乘或除以2,最终令0.5&lt;<i>M</i><sup><i>Δ</i></sup>&lt;1,其中<i>M</i><sup><i>Δ</i></sup>为<i>M</i>反复乘除2之后的结果.设<i>a</i>初值为0,<i>v</i>的初值为24,<i>M</i>每次乘2使<i>a</i>加1,<i>M</i>每次除2使<i>a</i>减1,最后令</p>
                </div>
                <div class="p1">
                    <p id="243"><i>C</i>=<i>round</i>(2<sup><i>v</i></sup><i>M</i><sup><i>Δ</i></sup>), <i>S</i>=<i>v</i>+<i>a</i>.</p>
                </div>
                <div class="p1">
                    <p id="244">由此可令网络的输出表达为全整型运算,具体可用</p>
                </div>
                <div class="p1">
                    <p id="245"><i>Q</i>_<i>Y</i>=(<i>QW</i>·<i>QX</i>·<i>C</i>)≫<i>S</i></p>
                </div>
                <div class="p1">
                    <p id="246">表示,其中≫<i>S</i>表示向右移<i>S</i>位.分解过程如图2所示.</p>
                </div>
                <div class="area_img" id="247">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910008_247.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 变量M近似计算分解" src="Detail/GetImg?filename=images/MSSB201910008_247.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 变量<i>M</i>近似计算分解  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910008_247.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Approximate computational decomposition of variable <i>M</i></p>

                </div>
                <h4 class="anchor-tag" id="248" name="248"><b>1.3</b> 批量归一化层整合</h4>
                <div class="p1">
                    <p id="249">BN层能加速训练的收敛过程,但存在浮点计算,不适合FPGA实现.对于YOLO-tiny网络,BN层跟随卷积层形成“Conv层-BN层”的结构,即</p>
                </div>
                <div class="p1">
                    <p id="250" class="code-formula">
                        <mathml id="250"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mtext> </mtext><msup><mrow></mrow><mrow><mtext>B</mtext><mtext>Ν</mtext></mrow></msup><mo stretchy="false">(</mo><mi>f</mi><mtext> </mtext><msup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>v</mtext></mrow></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mi>f</mi><mtext> </mtext><msup><mrow></mrow><mrow><mtext>B</mtext><mtext>Ν</mtext></mrow></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>γ</mi><mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow><mrow><msqrt><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac><mo>+</mo><mi>β</mi><mo>,</mo><mspace width="0.25em" /><mi>f</mi><mtext> </mtext><msup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>v</mtext></mrow></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>w</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="251">为了兼容BN层的计算,可通过归并方式,将BN层的参数归并到卷积层的参数中,归并过程如下:</p>
                </div>
                <div class="p1">
                    <p id="252" class="code-formula">
                        <mathml id="252"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>w</mi><mo>_</mo><mspace width="0.25em" /><mi>f</mi><mi>o</mi><mi>l</mi><mi>d</mi><mo>=</mo><mfrac><mrow><mi>w</mi><mi>γ</mi></mrow><mrow><msqrt><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac><mo>,</mo></mtd></mtr><mtr><mtd><mi>β</mi><mo>_</mo><mspace width="0.25em" /><mi>f</mi><mi>o</mi><mi>l</mi><mi>d</mi><mo>=</mo><mi>β</mi><mo>-</mo><mfrac><mrow><mi>μ</mi><mi>γ</mi></mrow><mrow><msqrt><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>ε</mi></mrow></msqrt></mrow></mfrac><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="253">其中,<i>w</i>_ <i>fold</i>为归并后的卷积层权重,<i>β</i>_ <i>fold</i>为归并后的偏置,<i>σ</i>为标准差,<i>μ</i>为均值,<i>ε</i>为分母附加项,防止分母为0.这种归并手段可省去BN层的计算,进而表达成单独的卷积计算过程:</p>
                </div>
                <div class="p1">
                    <p id="254" class="code-formula">
                        <mathml id="254"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mtext> </mtext><msup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>n</mtext><mtext>v</mtext><mo>-</mo><mtext>B</mtext><mtext>Ν</mtext></mrow></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>w</mi></mstyle></mrow></mstyle><mo>_</mo><mspace width="0.25em" /><mi>f</mi><mi>o</mi><mi>l</mi><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>β</mi><mo>_</mo><mspace width="0.25em" /><mi>f</mi><mi>o</mi><mi>l</mi><mi>d</mi><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="255">卷积的计算过程可以通过量化模型转成全整型计算,使FPGA可兼容带有BN层的网络结构.</p>
                </div>
                <h4 class="anchor-tag" id="256" name="256"><b>1.4</b> 激活函数近似</h4>
                <div class="p1">
                    <p id="257">YOLO-tiny网络的激活函数选为PReLU,激活函数同样会引入浮点操作.为了避免这种计算,保障前向推理过程的全整型计算.采用移位近似计算代替原有计算:</p>
                </div>
                <div class="p1">
                    <p id="258" class="code-formula">
                        <mathml id="258"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>x</mi><mo>,</mo></mtd><mtd columnalign="left"><mi>x</mi><mo>&gt;</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>.</mo><mn>1</mn><mi>x</mi><mo>,</mo></mtd><mtd columnalign="left"><mi>x</mi><mo>≤</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow><mo>⇒</mo><mi>y</mi><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>x</mi><mo>,</mo></mtd><mtd columnalign="left"><mi>x</mi><mo>&gt;</mo><mn>0</mn></mtd></mtr><mtr><mtd columnalign="left"><mfrac><mrow><mi>x</mi><mo>+</mo><mn>2</mn><mi>x</mi></mrow><mrow><mn>2</mn><msup><mrow></mrow><mn>5</mn></msup></mrow></mfrac><mo>,</mo></mtd><mtd columnalign="left"><mi>x</mi><mo>≤</mo><mn>0</mn></mtd></mtr></mtable></mrow></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="259">其中系数均为2的幂次方,可通过移位进行计算.</p>
                </div>
                <h3 id="260" name="260" class="anchor-tag">2 YOLO网络加速方案</h3>
                <div class="p1">
                    <p id="261">第1节的量化方法对网络权重、输入、输出进行量化,再通过BN层合并及激活函数的近似计算,使网络推理过程可使用全整型计算表达,量化后的网络能利用FPGA进行推理过程的全流程加速.在此基础上,结合网络的结构特点,采用多并行模式组合的手段,利用滑动窗进行高效的定点加速器设计.由于网络能通过复用单层的计算结构进行全流程的推理计算,因此网络加速器的设计可以围绕单层网络结构开展.</p>
                </div>
                <h4 class="anchor-tag" id="262" name="262"><b>2.1</b> 计算架构</h4>
                <div class="p1">
                    <p id="263">由于CNN的层间运算具有独立性,各层运算具有高度相似性,因此可以通过复用单层运算资源以实现完整的CNN计算.</p>
                </div>
                <div class="p1">
                    <p id="264">不失一般性,本文对计算架构的研究重点是单层神经元的计算优化.CNN 的单层计算单元流水线结构如图3所示.</p>
                </div>
                <div class="area_img" id="265">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910008_265.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 单层网络计算结构" src="Detail/GetImg?filename=images/MSSB201910008_265.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 单层网络计算结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910008_265.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Single layer network computing architecture</p>

                </div>
                <div class="p1">
                    <p id="266">单层计算单元的运算包括卷积层、BN层、激活层、池化层计算.这四层网络能形成流水线计算结构.在开始单层网络的计算前需要根据网络的参数控制存储控制器从外存中不断获取输入数据及权重,再进行卷积运算,图3中显示的合并BN层的操作在网络定点化过程中就已经将BN层的参数合并至卷积层,不需要消耗额外的计算资源.卷积层需要进行大量的乘法及加法运算,可使用多种并行组合的方式进行高效计算,激活层及池化层的计算可以复用卷积层输出结果,利用滑动窗进行流水计算.当池化、激活完成后可将最终结果存到片上随机存取存储器(Random Access Memory, RAM),再由RAM一次性搬运至片外存储器,进行下一层的计算.</p>
                </div>
                <h4 class="anchor-tag" id="267" name="267"><b>2.2</b> 卷积运算并行优化</h4>
                <div class="p1">
                    <p id="268">本文采用滑动窗思想,组合卷积层3种不同的并行策略,包括输入并行、像素并行及输出并行,设计并行卷积运算结构.这种结构能分别在3种维度上任意配置不同的并行度,具备高度的灵活性,可针对不同的目标器件自由组合.</p>
                </div>
                <div class="p1">
                    <p id="269">卷积计算并行结构如图4所示.利用滑动窗并行处理<i>M</i>幅输入特征图.滑动窗指图中的特征模板,输入特征图按照逐行逐列的顺序进入级联的行缓存中,当第一个行缓存存满一行的数据量时,就把上一行的数据灌入下一个行缓存,随着像素的流动,可在每个行缓存的出口处获得对应模板大小的数据,形成一个滑动窗.</p>
                </div>
                <div class="p1">
                    <p id="270">这种处理模式能实现卷积的流水处理,伴随像素流动,特征模板中的数值动态更新,图中模板大小为3×3.这种计算方式需要使用较多的存储资源用于构建滑动窗,随着卷积模板的扩大,消耗的资源增多.</p>
                </div>
                <div class="p1">
                    <p id="271">像素并行策略为同时完成4个连续像素的卷积过程需要的滑动窗.由于顶层接口为32 bit,而实际像素为8 bit,因此利用3×3模板能存储同时进行4像素卷积过程所需的输入特征图.当卷积模板扩大时,相应的滑动窗也随之扩大.</p>
                </div>
                <div class="p1">
                    <p id="272">输出并行策略并行处理<i>N</i>幅输出特征图,相同的输入特征图与<i>N</i>组输出通道的权重计算卷积,可求得不同的输出特征图.在获取输入特征图的前提下,通过载入不同输出特征图对应的权重,完成不同输出特征的计算过程,这种并行度方式通过资源的复制可实现较高的并行处理效率.</p>
                </div>
                <div class="area_img" id="273">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910008_273.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 卷积计算并行结构" src="Detail/GetImg?filename=images/MSSB201910008_273.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 卷积计算并行结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910008_273.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Convolution computing parallel architecture</p>

                </div>
                <div class="p1">
                    <p id="274">本文使用的YOLO-tiny网络按卷积过程的差异分为第一层卷积、中间层卷积、最后一层卷积.这里的卷积过程包含卷积运算、BN运算、激活和池化运算.第一层卷积处理的输入为RGB图像,模板为3×3,计算量占据整个网络的2.6%.由于每个周期能同时输入RGB通道的数据,因此可以使用输入并行策略实现卷积过程,每个周期能完成27次int8乘法.中间层卷积的模板为3×3,需要兼容处理不同的激活、池化过程,计算量占据整个网络的96.3%,需要使用较大的并行力度,提升计算效率.</p>
                </div>
                <div class="p1">
                    <p id="275">本文对于中间层卷积过程采用输入并行、输出并行、像素并行这3种并行度组合的模式设计,同时处理4幅输入特征图、4幅输出特征图、4个像素,每个周期可以完成576次int8乘法.最后一层卷积过程处理的模板大小为1×1,无需激活、池化过程,占据的计算量为1.1%.本文使用输入并行、像素并行的方式进行处理,同时处理4个输入特征图、4个像素的卷积计算,每个周期可以完成16次int8乘法.</p>
                </div>
                <h4 class="anchor-tag" id="276" name="276"><b>2.3</b> 激活、池化运算流水处理</h4>
                <div class="p1">
                    <p id="277">针对本文的网络结构,激活函数采用PReLU,BN层后可以选择使用激活函数及不使用激活函数两种处理方式,池化层采用最大值池化,同样存在使用池化及不使用池化两种处理方式.此外不同池化层的步长不统一,分步长为1及步长为2两种情况.为了能实现流水式处理激活层及池化层,本文构建的流水线结构如图5所示.</p>
                </div>
                <div class="p1">
                    <p id="278">卷积层输出的结果累加上偏置之后,进行激活过程,激活函数使用移位近似计算.通过数据选择器兼并使用激活或不使用激活这两种方式,再利用2×2的滑动窗进行极大值池化,利用数据选择器兼并池化或不池化这两种处理方式,最后将数据正确写到输出缓存区.</p>
                </div>
                <div class="p1">
                    <p id="279">另外,由于不同步长的池化操作输出的像素数目不一致,步长为2的池化过程隔行隔列输出一个像素,而步长为1的池化过程每行每列均有对应输出,为了保证能正确产生写数据地址,应对不同池化步长,需要调整输出地址.</p>
                </div>
                <div class="p1">
                    <p id="280">图5展示4号像素激活、池化操作的处理过程.按照上述流程,伴随数据流动,每个周期均能产生相应的处理结果.由于在激活阶段只完成激活函数分母部分的运算,经过池化操作写到存储单元时,需要将数据向右移5位再写入.</p>
                </div>
                <div class="area_img" id="281">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910008_281.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 激活、池化流水计算结构" src="Detail/GetImg?filename=images/MSSB201910008_281.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 激活、池化流水计算结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910008_281.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Activation and pooling pipeline computing structure</p>

                </div>
                <h3 id="282" name="282" class="anchor-tag">3 实验及结果分析</h3>
                <h4 class="anchor-tag" id="283" name="283"><b>3.1</b> 量化方法改进的有效性验证</h4>
                <div class="p1">
                    <p id="284">量化位宽越低,网络性能损失越大,这是由数值的表达精度决定的.量化方法的存在是为了在追求低位宽数值表达的同时,保证低位宽的数值计算不严重影响网络性能.虽然数值越宽,对计算性能的影响越小,但达不到减少计算资源的目的.本文以8 bit的量化位宽为界,向下不断降低位宽是出于两个目的:1)探究合适的低量化位宽,2)探究本文在Google(IAO)上简化措施的合理性.</p>
                </div>
                <div class="p1">
                    <p id="285">本文精简Google(IAO)的量化方法,使网络量化后能直接利用FPGA平台进行运算,解决定点加速器的数值计算问题.为了说明改进的合理性,对比本文方法与Google(IAO)在3种量化位宽下的量化误差.</p>
                </div>
                <div class="p1">
                    <p id="286">本文方法使用YOLO-tiny网络进行20类目标的检测、识别,统计量化位宽分别为8、7、5下的量化误差.采用VOC2012、VOC2007数据集进行训练.实验数据集包含20类目标,共计21 503幅标注数据.每次迭代训练的图像数量为32,动量为0.9,学习率为0.001,训练的图像批次为300 000次,前200 000次为网络预训练过程,后100 000次为量化过程,预训练过程是为了保障量化过程尽快收敛.</p>
                </div>
                <div class="p1">
                    <p id="287">Google(IAO)使用MobileNet进行人脸的年龄判别,统计对应量化位宽下的量化误差.量化误差是指以量化前的浮点结果为基准,记录量化前后的网络判别准确率变化.</p>
                </div>
                <div class="p1">
                    <p id="288">不同位宽下的量化过程如图6所示,分为不经过量化的原始网络、8 bit量化的网络、7 bit量化的网络、5 bit量化的网络,计算4种网络的平均精确率均值(Mean Average Precision, mAP).由图可见,量化后的网络存在一定的性能损失,量化比特数越低,网络性能下降越快.具体地,原始网络的mAP值稳定在0.45,8 bit网络的mAP值稳定在0.43,7 bit网络的mAP值稳定在0.4,5 bit网络的mAP值稳定在0.18.</p>
                </div>
                <div class="area_img" id="289">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910008_289.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同位宽下的量化过程" src="Detail/GetImg?filename=images/MSSB201910008_289.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同位宽下的量化过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910008_289.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Quantization processes with different bit widths</p>

                </div>
                <div class="p1">
                    <p id="290">Google(IAO)和本文方法的量化误差如表1所示.对比量化位宽为8 bit时的量化误差,本文方法为2%,仅比Google(IAO)降低0.7%,二者量化误差相近.由此可以说明,本文精简量化算法后,一定条件下仍能保障网络的性能.从计算量上可见,由于使用简化的量化模型,相比Google(IAO),本文方法使量化后的网络推理过程的计算量减少75%,提高网络的计算效率.</p>
                </div>
                <div class="area_img" id="291">
                    <p class="img_tit"><b>表1 2种方法量化前后误差对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Error comparison of 2 methods before and after quantization</p>
                    <p class="img_note"></p>
                    <table id="291" border="1"><tr><td rowspan="2"><br />方法</td><td colspan="3"><br />量化位宽</td></tr><tr><td><br />8bit</td><td>7bit</td><td>5bit</td></tr><tr><td><br />Google(IAO)/%</td><td>-1.3</td><td>-1.2</td><td>-4.4</td></tr><tr><td><br />本文方法/%</td><td>-2</td><td>-5</td><td>-27</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="292" name="292"><b>3.2 FPGA</b>加速结果</h4>
                <div class="p1">
                    <p id="293">本文根据YOLO-tiny网络的结构,针对不同的卷积模板尺寸、卷积层属性、池化操作、激活操作过程设计3个基本的并行处理单元(Process Element, PE),分别针对首层网络、中间层网络及末层网络.</p>
                </div>
                <div class="p1">
                    <p id="294">以ZYNQ系列FPGA作为硬件平台,实现基于“主控制器+并行处理单元”的卷积网络部署框架,如图7所示.</p>
                </div>
                <div class="p1">
                    <p id="295">图7中并行处理单元使用ZYNQ中可编程逻辑部分(Programmable Logic, PL)实现,主要负责卷积网络的前向推理.主控制器由ZYNQ中的可编程软件(PS(Programmable System), ARM硬核)承担,主要负责系统的调度.整个系统均放在单个FPGA上实现,使用SD(Secure Digital Memory Card)卡作为图像数据及权重的存储介质,使用DDR3(Double Data Rate 3)作为外部存储,计算数据先从SD卡搬运至DDR中,再从DDR搬运到卷积加速器的输入缓存中.</p>
                </div>
                <div class="p1">
                    <p id="296">图7中的AXI(Advanced Extensible Interface)协议低速总线用于传输指令,AXI总线用于传输数据,卷积加速器作为AXI协议总线上的一个IP核,可从中获取数据及控制指令.</p>
                </div>
                <div class="area_img" id="297">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910008_297.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 FPGA实现框架" src="Detail/GetImg?filename=images/MSSB201910008_297.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 FPGA实现框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910008_297.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Implementation framework of FPGA</p>

                </div>
                <div class="p1">
                    <p id="298">本文利用HLS2016.1作为设计工具,设计定点卷积网络加速器,使用vivado2016.1综合工具进行编译、布局、布线,FPGA具体型号为XC7Z045.对比FPGA,使用CPU(Central Processing Unit)实现的软件版本,CPU型号为i5-6300HQ,工作主频为2.8 GHz,采用模型与FPGA实现的模型均为量化后的YOLO-tiny模型.网络的输入尺寸为256×256,BN层均提前合并至卷积层中,软件使用Visual Studio 2010编译器.</p>
                </div>
                <div class="p1">
                    <p id="299">FPGA的资源使用情况如表2所示.由表可见,查找表(Look Up Table, LUT)资源使用率为54.3%,块存储器(Block RAM, BRAM)资源使用率为44.13%,寄存器(Flip-Flop, FF)资源使用率为37.30%,使用最多的为DSP处理模块(DSP48E)资源,约为76.67%.</p>
                </div>
                <div class="area_img" id="300">
                    <p class="img_tit"><b>表2 FPGA资源使用情况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Usage of resources in FPGA</p>
                    <p class="img_note"></p>
                    <table id="300" border="1"><tr><td><br /></td><td>BRAM_36K</td><td>DSP48E</td><td>FF</td><td>LUT</td></tr><tr><td><br />使用数量</td><td>240.5</td><td>690</td><td>163072</td><td>118785</td></tr><tr><td><br />可用数量</td><td>545</td><td>900</td><td>437200</td><td>218600</td></tr><tr><td><br />占用率/%</td><td>44.13</td><td>76.67</td><td>37.30</td><td>54.34</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="301">定点加速器的最高时钟频率为123 MHz,一次网络的前向计算需要的乘加次数为1.48 G,耗时为0.218 s,对应地,加速器所能达到的计算效率为6.85 GMAC/s.而在CPU上,无加速的软件版本进行一次前向推理耗时4.199 s,使用通用矩阵乘(General Matrix Multiplication, GEMM)加速的版本耗时1.072 s.</p>
                </div>
                <div class="p1">
                    <p id="302">相比无加速的软件版本,FPGA实现19倍加速比.相比GEMM加速的软件版本,FPGA实现4.87倍加速比,具体如表3所示.</p>
                </div>
                <div class="area_img" id="303">
                    <p class="img_tit"><b>表3 3种方法耗时对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Time consuming comparison of 3 methods </p>
                    <p class="img_note"></p>
                    <table id="303" border="1"><tr><td><br />方法</td><td>耗时</td></tr><tr><td><br />CPU(i5-6300HQ)使用GEMM</td><td>1.072</td></tr><tr><td><br />CPU(i5-6300HQ)不使用GEMM</td><td>4.199</td></tr><tr><td><br />FPGA(XC7Z045)</td><td>0.220</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="304">FPGA的功耗是利用综合工具Vivado2016.1进行评估的结果,片上功耗为5.757 W.而CPU的功耗为45 W,FPGA的能耗仅为12.8%.此外,本文也对比现有方法的FPGA加速的实现对比,具体如表4所示.</p>
                </div>
                <div class="p1">
                    <p id="305">文献<citation id="395" type="reference">[<a class="sup">11</a>]</citation>方法和文献<citation id="396" type="reference">[<a class="sup">13</a>]</citation>方法中两个加速器处理网络均为小型网络,前者包含4层卷积层、2层池化层,后者包含2层卷积层、2层全连接层.本文使用的基准网络为大型的YOLO-tiny检测网络,包含BN层,结构更复杂,更具备应用价值.本文使用的计算位宽为8 bit,同等计算量下对资源需求更少,使加速器在有限资源下的计算性能更强,最终的计算性能可达到6.85 GMAC/s.</p>
                </div>
                <div class="area_img" id="306">
                    <p class="img_tit"><b>表4 3种方法的FPGA实现对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Implementation comparison of FPGAs of 3 methods</p>
                    <p class="img_note"></p>
                    <table id="306" border="1"><tr><td><br /></td><td>文献[11]方法</td><td>文献[13]方法</td><td>本文方法</td></tr><tr><td><br />计算精度</td><td>16bit定点</td><td>32浮点</td><td>8bit定点</td></tr><tr><td><br />FPGA型号</td><td>VC5VLX330T</td><td>VC5VLX110T</td><td>XC7Z045</td></tr><tr><td><br />FPGA资源</td><td>51840slices+<br />192DSP</td><td>17280slices+<br />64DSP</td><td>54650slices+<br />900DSP</td></tr><tr><td><br />FPGA频率/MHz</td><td>115</td><td>75</td><td>123</td></tr><tr><td><br />存储器/MB</td><td>DDR2@230</td><td>SDRAM@75</td><td>DDR3@666</td></tr><tr><td><br /> 计算性能/GMAC/s</td><td>3.37</td><td>0.915</td><td>6.85</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="307" name="307" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="308">本文以YOLO-tiny网络为基础,实现定点卷积加速器,同时兼顾加速器的速度与精度两方面的性能.在精度上针对现有的量化算法进行合理简化,使网络的计算过程对FPGA更友好.在速度上利用滑动窗设计思想,组合多种并行模式实现高效的卷积计算.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="335">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep learning">

                                <b>[1]</b> LECUN Y,BENGIO Y,HINTO G.Deep Learning.Nature,2015,521(7553):436-444.
                            </a>
                        </p>
                        <p id="337">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Net large scale visual recognition challenge">

                                <b>[2]</b> RUSSAKOVSHY O,DENG J,SU H,et al.Imagenet Large Scale Visual Recognition Challenge.International Journal of Computer Vision,2015,115(3):211-252.
                            </a>
                        </p>
                        <p id="339">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast r-cnn">

                                <b>[3]</b> GIRSHICK R.Fast R-CNN // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2015:1440-1448.
                            </a>
                        </p>
                        <p id="341">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fully convolutional networks for semantic segmentation">

                                <b>[4]</b> SHELLHAMER E,LONG J,DARRELL T.Fully Convolutional Networks for Semantic Segmentation.IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(4):640-651.
                            </a>
                        </p>
                        <p id="343">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks[C/OL]">

                                <b>[5]</b> ZHANG Y,PEZESHKI M,BRAKEL P,et al.Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks[C/OL].[2019-05-25].https://arxiv.org/pdf/1701.02720.pdf.
                            </a>
                        </p>
                        <p id="345">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[6]</b> SIMONYAN K,ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2019-05-25].https://arxiv.org/pdf/1409.1556.pdf.
                            </a>
                        </p>
                        <p id="347">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Can FPGAs Beat GPUs in Accelerating Next-Generation Deep Neural Networks?">

                                <b>[7]</b> NURVITADHI E,VENKATESH G,SIM J,et al.Can FPGAs Beat GPUs in Accelerating Next-Generation Deep Neural Networks?// Proc of the ACM/SIGDA International Symposium on Field-Programm-able Gate Arrays.New York,USA:ACM,2017:5-14.
                            </a>
                        </p>
                        <p id="349">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZKX201805003&amp;v=MjE1MzgzSk5UZkFkckc0SDluTXFvOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rV3I=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 吴建鑫,高斌斌,魏秀参,等.资源受限的深度学习:挑战与实践.中国科学(信息科学),2018,48(5):501-510.(WU J X,GAO B B,WEI X S,et al.Resource-Constrained Deep Learning:Challenges and Practices.Chinese Science(Information Science),2018,48(5):501-510.)
                            </a>
                        </p>
                        <p id="351">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks">

                                <b>[9]</b> GOKHALE V,JIN J,DUNDAR A,et al.A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks // Proc of the IEEE Confe-rence on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2014:682-687.
                            </a>
                        </p>
                        <p id="353">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201810016&amp;v=MTYxMTh0R0ZyQ1VSTE9lWmVSbkZ5L2tXcjNKTWpYU1pMRzRIOW5OcjQ5RVlvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 刘志成,祝永新,汪辉,等.基于FPGA的卷积神经网络并行加速结构设计.微电子学与计算机,2018,35(10):80-84.(LIU Z C,ZHU Y X,WANG H,et al.Parallel Acceleration Structure Design of Convolutional Neural Network Based on FPGA.Microelectronics and Computer,2018,35(10):80-84.)
                            </a>
                        </p>
                        <p id="355">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Massively Parallel Coprocessor for Convolutional Neural Networks">

                                <b>[11]</b> SANKARADAS M,JAKKULA V,CADAMBI S,et al.A Massively Parallel Coprocessor for Convolutional Neural Networks // Proc of the IEEE International Conference on Application-Specific Systems.Washington,USA:IEEE,2009:53-60.
                            </a>
                        </p>
                        <p id="357">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimizing FPGA-based acelerator dsign for deep convolutional neural networks">

                                <b>[12]</b> ZHANG C,LI P,SUN G Y,et al.Optimizing FPGA-Based Accelerator Design for Deep Convolutional Neural Networks // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2015:161-170.
                            </a>
                        </p>
                        <p id="359">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016066075.nh&amp;v=MDIwODJDVVJMT2VaZVJuRnkva1dyM0pWRjI2R0xPK0dOSExxcEViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 余子健.基于FPGA的卷积神经网络加速器.硕士学位论文.杭州:浙江大学,2016.(YU Z J.Convolutional Neural Network Accelerator Based on FPGA.Master Dissertation.Hangzhou,China:Zhejiang University,2016.)
                            </a>
                        </p>
                        <p id="361">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Frequency Domain Acceleration of Convolutional Neural Networks on CPU-FPGA Shared Memory System">

                                <b>[14]</b> ZHANG C,PRASANNA V.Frequency Domain Acceleration of Convolutional Neural Networks on CPU-FPGA Shared Memory System // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2017:35-44.
                            </a>
                        </p>
                        <p id="363">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Caffeinated FPGAs:FPGA framework for convolutional neural networks">

                                <b>[15]</b> DICECCO R,LACEY G,VASILJEVIC J,et al.Caffeinated FPGAs:FPGA Framework for Convolutional Neural Networks // Proc of the IEEE International Conference on Field-Programmable Technology.Washington,USA:IEEE,2016:265-268.
                            </a>
                        </p>
                        <p id="365">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An OpenCLTM deep learning accelerator on arria 10">

                                <b>[16]</b> AYDONAT U,O'CONNELL S,CAPALIJA D,et al.An OpenCL<sup>TM</sup> Deep Learning Accelerator on Arria 10 // Proc of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays.New York,USA:ACM,2017:55-64.
                            </a>
                        </p>
                        <p id="367">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Compression:Compre-ssing Deep Neural Networks with Pruning,Trained Quantization and Huffman Coding[C/OL]">

                                <b>[17]</b> HAN S,MAO H Z,DALLY W J.Deep Compression:Compre-ssing Deep Neural Networks with Pruning,Trained Quantization and Huffman Coding[C/OL].[2019-05-25].https://arxiv.org/pdf/1510.00149.pdf.
                            </a>
                        </p>
                        <p id="369">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Compressing Neural Networks with the Hashing Trick">

                                <b>[18]</b> CHEN W L,WILSON J,TYREE S,et al.Compressing Neural Networks with the Hashing Trick.Proceedings of Machine Learning Research,2015,37:2285-2294.
                            </a>
                        </p>
                        <p id="371">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving the Speed of Neural Networks on CPUs [C/OL]">

                                <b>[19]</b> VANHOUCKE V,SENIOR A,MAO M Z.Improving the Speed of Neural Networks on CPUs [C/OL].[2019-05-15].http://www.andrewsenior.com/papers/VanhouckeNIPS11.pdf.
                            </a>
                        </p>
                        <p id="373">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference">

                                <b>[20]</b> JACOB B,KLIGYS S,CHEN B,et al.Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2018:2704-2713.
                            </a>
                        </p>
                        <p id="375">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=You Only Look Once:Unified,Real-Time Object Detection">

                                <b>[21]</b> REDMON J,DIVVALA S,GIRSHICK R,et al.You Only Look Once:Unified,Real-Time Object Detection // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2016:779-788.
                            </a>
                        </p>
                        <p id="377">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=8-Bit Inference with TensorRT">

                                <b>[22]</b> MIGACZ S.8-Bit Inference with TensorRT // Proc of the GPU Technology Conference.Berlin,Germany:Springer,2017:2-7.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201910008" />
        <input id="dpi" type="hidden" value="96" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201910008&amp;v=MzI0MzlHRnJDVVJMT2VaZVJuRnkva1dyM0pLRDdZYkxHNEg5ak5yNDlGYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
