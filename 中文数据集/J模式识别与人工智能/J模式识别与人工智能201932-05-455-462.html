<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131448636123750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201905010%26RESULT%3d1%26SIGN%3dPx74GDgopbLpMktvq0wHORc1%252bA0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201905010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201905010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201905010&amp;v=MTIxNjJDVVJMT2VaZVJuRnl6Z1ZicktLRDdZYkxHNEg5ak1xbzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#75" data-title="1 结合外部知识的动态多层次语义抽取网络模型 ">1 结合外部知识的动态多层次语义抽取网络模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="&lt;b&gt;1.1 文本内容与问题的匹配&lt;/b&gt;"><b>1.1 文本内容与问题的匹配</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;1.2 指针网络确定答案范围&lt;/b&gt;"><b>1.2 指针网络确定答案范围</b></a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;1.3 问题答案排序&lt;/b&gt;"><b>1.3 问题答案排序</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;1.4 引入外部知识&lt;/b&gt;"><b>1.4 引入外部知识</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;1.5 最终答案生成&lt;/b&gt;"><b>1.5 最终答案生成</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#182" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#201" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="图1 网络模型结构">图1 网络模型结构</a></li>
                                                <li><a href="#86" data-title="图2 改进的GRU模型">图2 改进的GRU模型</a></li>
                                                <li><a href="#184" data-title="&lt;b&gt;表1 实验数据集&lt;/b&gt;"><b>表1 实验数据集</b></a></li>
                                                <li><a href="#194" data-title="&lt;b&gt;表2 各模型在MS-MARCO测试集上的结果对比&lt;/b&gt;"><b>表2 各模型在MS-MARCO测试集上的结果对比</b></a></li>
                                                <li><a href="#197" data-title="&lt;b&gt;表3 各模型在DuReader测试集上的结果对比&lt;/b&gt;"><b>表3 各模型在DuReader测试集上的结果对比</b></a></li>
                                                <li><a href="#200" data-title="&lt;b&gt;表4 在2个数据集上本文模型各阶段的主要改进对模型性能的影响对比&lt;/b&gt;"><b>表4 在2个数据集上本文模型各阶段的主要改进对模型性能的影响对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" HERMANN K M, KOCISKY T, GREFENSTETTE E, &lt;i&gt;et al&lt;/i&gt;.Tea-ching Machines to Read and Comprehend // CORTES C, LAWRENCE N D, LEE D D, &lt;i&gt;et al&lt;/i&gt;., eds.Advances in Neural Information Processing Systems 28.Cambridge, USA:The MIT Press, 2015:1693-1701." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Teaching machines to read and comprehend">
                                        <b>[1]</b>
                                         HERMANN K M, KOCISKY T, GREFENSTETTE E, &lt;i&gt;et al&lt;/i&gt;.Tea-ching Machines to Read and Comprehend // CORTES C, LAWRENCE N D, LEE D D, &lt;i&gt;et al&lt;/i&gt;., eds.Advances in Neural Information Processing Systems 28.Cambridge, USA:The MIT Press, 2015:1693-1701.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" HOCHREITER S, SCHMIDHUBER J.Long Short-Term Memory.Neural Computation, 1997, 9 (8) :1735-1780." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MDIzODc5SHRqTXFvOUZaT29MRFhVeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGc1NieEE9TmlmSlpiSw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         HOCHREITER S, SCHMIDHUBER J.Long Short-Term Memory.Neural Computation, 1997, 9 (8) :1735-1780.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" HILL F, BORDES A, CHOPRA S, &lt;i&gt;et al&lt;/i&gt;.The Goldilocks Principle:Reading Children′s Books with Explicit Memory Representations[C/OL].[2018-08-20].https://arxiv.org/pdf/1511.02301.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Goldilocks Principle:Reading Children′s Books with Explicit Memory Representations[C/OL]">
                                        <b>[3]</b>
                                         HILL F, BORDES A, CHOPRA S, &lt;i&gt;et al&lt;/i&gt;.The Goldilocks Principle:Reading Children′s Books with Explicit Memory Representations[C/OL].[2018-08-20].https://arxiv.org/pdf/1511.02301.pdf.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" WESTON J, CHOPRA S, BORDES A.Memory Networks[C/OL].[2018-08-20].https://arxiv.org/pdf/1410.3916.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Memory Networks[C/OL]">
                                        <b>[4]</b>
                                         WESTON J, CHOPRA S, BORDES A.Memory Networks[C/OL].[2018-08-20].https://arxiv.org/pdf/1410.3916.pdf.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" RAJPURKAR P, ZHANG J, LOPYREV K, &lt;i&gt;et al&lt;/i&gt;.Squad:100, 000+ Questions for Machine Comprehension of Text // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2016:2383-2392." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Squad:100,000+questions for machine comprehension of text">
                                        <b>[5]</b>
                                         RAJPURKAR P, ZHANG J, LOPYREV K, &lt;i&gt;et al&lt;/i&gt;.Squad:100, 000+ Questions for Machine Comprehension of Text // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2016:2383-2392.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" NGUYEN T, ROSENBERG M, SONG X, &lt;i&gt;et al&lt;/i&gt;.MS MARCO:A Human Generated Machine Reading Comprehension Dataset[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.09268.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=MS MARCO:A Human Generated Machine Reading Comprehension Dataset[C/OL]">
                                        <b>[6]</b>
                                         NGUYEN T, ROSENBERG M, SONG X, &lt;i&gt;et al&lt;/i&gt;.MS MARCO:A Human Generated Machine Reading Comprehension Dataset[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.09268.pdf.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" HE W, LIU K, LIU J, &lt;i&gt;et al&lt;/i&gt;.DuReader:A Chinese Machine Rea-ding Comprehension Dataset from Real-World Applications[C/OL].[2018-08-20].https://arxiv.org/pdf/1711.05073.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DuReader:A Chinese Machine Rea-ding Comprehension Dataset from Real-World Applications[C/OL]">
                                        <b>[7]</b>
                                         HE W, LIU K, LIU J, &lt;i&gt;et al&lt;/i&gt;.DuReader:A Chinese Machine Rea-ding Comprehension Dataset from Real-World Applications[C/OL].[2018-08-20].https://arxiv.org/pdf/1711.05073.pdf.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" WANG S H, JIANG J.Machine Comprehension Using Match-LSTM and Answer Pointer[C/OL].[2018-08-20].https://arxiv.org/pdf/1608.07905.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Machine Comprehension Using Match-LSTM and Answer Pointer[C/OL]">
                                        <b>[8]</b>
                                         WANG S H, JIANG J.Machine Comprehension Using Match-LSTM and Answer Pointer[C/OL].[2018-08-20].https://arxiv.org/pdf/1608.07905.pdf.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" SEO M, KEMBHAVI A, FARHADI A, &lt;i&gt;et al&lt;/i&gt;.Bidirectional Attention Flow for Machine Comprehension[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01603.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bidirectional Attention Flow for Machine Comprehension[C/OL]">
                                        <b>[9]</b>
                                         SEO M, KEMBHAVI A, FARHADI A, &lt;i&gt;et al&lt;/i&gt;.Bidirectional Attention Flow for Machine Comprehension[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01603.pdf.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" XIONG C M, ZHONG V, SOCHER R.Dynamic Coattention Networks for Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01604.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic Coattention Networks for Question Answering[C/OL]">
                                        <b>[10]</b>
                                         XIONG C M, ZHONG V, SOCHER R.Dynamic Coattention Networks for Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01604.pdf.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" DUNN M, SAGUN L, HIGGINS M, &lt;i&gt;et al&lt;/i&gt;.SearchQA:A New Q&amp;amp;A Dataset Augmented with Context from a Search Engine[C/OL].[2018-08-20].https://arxiv.org/pdf/1704.05179.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SearchQA:A New Q&amp;amp;A Dataset Augmented with Context from a Search Engine[C/OL]">
                                        <b>[11]</b>
                                         DUNN M, SAGUN L, HIGGINS M, &lt;i&gt;et al&lt;/i&gt;.SearchQA:A New Q&amp;amp;A Dataset Augmented with Context from a Search Engine[C/OL].[2018-08-20].https://arxiv.org/pdf/1704.05179.pdf.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" YU Y, ZHANG W, HASAN K, &lt;i&gt;et al&lt;/i&gt;.End-to-End Reading Com-prehension with Dynamic Answer Chunk Ranking[C/OL].[2018-08-20].https://arxiv.org/pdf/1610.09996v2.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=End-to-End Reading Com-prehension with Dynamic Answer Chunk Ranking[C/OL]">
                                        <b>[12]</b>
                                         YU Y, ZHANG W, HASAN K, &lt;i&gt;et al&lt;/i&gt;.End-to-End Reading Com-prehension with Dynamic Answer Chunk Ranking[C/OL].[2018-08-20].https://arxiv.org/pdf/1610.09996v2.pdf.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" LEE K, KWIATKOWSKI T, PARIKH A, &lt;i&gt;et al&lt;/i&gt;.Learning Recu-rrent Span Representations for Extractive Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01436.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning Recu-rrent Span Representations for Extractive Question Answering[C/OL]">
                                        <b>[13]</b>
                                         LEE K, KWIATKOWSKI T, PARIKH A, &lt;i&gt;et al&lt;/i&gt;.Learning Recu-rrent Span Representations for Extractive Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01436.pdf.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" WANG S H, YU M, JIANG J, &lt;i&gt;et al&lt;/i&gt;.Evidence Aggregation for Answer Re-ranking in Open-Domain Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1711.05116.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Evidence Aggregation for Answer Re-ranking in Open-Domain Question Answering[C/OL]">
                                        <b>[14]</b>
                                         WANG S H, YU M, JIANG J, &lt;i&gt;et al&lt;/i&gt;.Evidence Aggregation for Answer Re-ranking in Open-Domain Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1711.05116.pdf.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" LONG T, BENGIO E, LOWE R, &lt;i&gt;et al&lt;/i&gt;.World Knowledge for Reading Comprehension:Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2017:825-834." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=World Knowledge for Reading Comprehension:Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions">
                                        <b>[15]</b>
                                         LONG T, BENGIO E, LOWE R, &lt;i&gt;et al&lt;/i&gt;.World Knowledge for Reading Comprehension:Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2017:825-834.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" CHO K, VAN MERRIENBOER B, GULCEHRE C, &lt;i&gt;et al&lt;/i&gt;.Lea-rning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1724-1734." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning phrase representations using RNN encoder-decoder for Statistical machine translation">
                                        <b>[16]</b>
                                         CHO K, VAN MERRIENBOER B, GULCEHRE C, &lt;i&gt;et al&lt;/i&gt;.Lea-rning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1724-1734.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" LIN C Y.ROUGE:A Package for Automatic Evaluation of Summaries.Text Summarization Branches Out[C/OL].[2018-08-20].https://www.aclweb.org/anthology/W04-1013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ROUGE:A Package for Automatic Evaluation of Summaries.Text Summarization Branches Out[C/OL]">
                                        <b>[17]</b>
                                         LIN C Y.ROUGE:A Package for Automatic Evaluation of Summaries.Text Summarization Branches Out[C/OL].[2018-08-20].https://www.aclweb.org/anthology/W04-1013.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" PAPINENI K, ROUKOS S, WARD T, &lt;i&gt;et al&lt;/i&gt;.BLEU:A Method for Automatic Evaluation of Machine Translation // Proc of the 40th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2002:311-318." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=B1EU: a method for automatic evaluation of machine translation">
                                        <b>[18]</b>
                                         PAPINENI K, ROUKOS S, WARD T, &lt;i&gt;et al&lt;/i&gt;.BLEU:A Method for Automatic Evaluation of Machine Translation // Proc of the 40th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2002:311-318.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" KINGMA D P, BA J.Adam:A Method for Stochastic Optimization[C/OL].[2018-08-20].https://arxiv.org/pdf/1412.6980.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adam:a method for stochastic optimization">
                                        <b>[19]</b>
                                         KINGMA D P, BA J.Adam:A Method for Stochastic Optimization[C/OL].[2018-08-20].https://arxiv.org/pdf/1412.6980.pdf.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" SHEN Y L, HUANG P S, GAO J F, &lt;i&gt;et al&lt;/i&gt;.Reasonet:Learning to Stop Reading in Machine Comprehension // Proc of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2017:1047-1055." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Reasonet Learning to stop reading in machine comprehension">
                                        <b>[20]</b>
                                         SHEN Y L, HUANG P S, GAO J F, &lt;i&gt;et al&lt;/i&gt;.Reasonet:Learning to Stop Reading in Machine Comprehension // Proc of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2017:1047-1055.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" WEISSENBORN D, WIESE G, SEIFFE L.Making Neural QA as Simple as Possible But Not Simpler // Proc of the 21st Conference on Computational Natural Language Learning.Stroudsburg, USA:ACL, 2017:271-280." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Making Neural QA as Simple as Possible but not Simpler">
                                        <b>[21]</b>
                                         WEISSENBORN D, WIESE G, SEIFFE L.Making Neural QA as Simple as Possible But Not Simpler // Proc of the 21st Conference on Computational Natural Language Learning.Stroudsburg, USA:ACL, 2017:271-280.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" WANG W H, YANG N, WEI F R, &lt;i&gt;et al&lt;/i&gt;.Gated Self-matching Networks for Reading Comprehension and Question Answering // Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017, I:189-198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gated Self-Matching Networks for Reading Comprehension and Question Answering">
                                        <b>[22]</b>
                                         WANG W H, YANG N, WEI F R, &lt;i&gt;et al&lt;/i&gt;.Gated Self-matching Networks for Reading Comprehension and Question Answering // Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017, I:189-198.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" TAN C Q, WEI F R, YANG N, &lt;i&gt;et al&lt;/i&gt;.S-NET:From Answer Extraction to Answer Generation for Machine Reading Comprehension[C/OL].[2018-08-20].https://arxiv.org/pdf/1706.04815.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=S-NET:From Answer Extraction to Answer Generation for Machine Reading Comprehension[C/OL]">
                                        <b>[23]</b>
                                         TAN C Q, WEI F R, YANG N, &lt;i&gt;et al&lt;/i&gt;.S-NET:From Answer Extraction to Answer Generation for Machine Reading Comprehension[C/OL].[2018-08-20].https://arxiv.org/pdf/1706.04815.pdf.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" WANG Y Z, LIU K, LIU J, &lt;i&gt;et al&lt;/i&gt;.Multi-passage Machine Reading Comprehension with Cross-Passage Answer Verification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:1918-1927." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification">
                                        <b>[24]</b>
                                         WANG Y Z, LIU K, LIU J, &lt;i&gt;et al&lt;/i&gt;.Multi-passage Machine Reading Comprehension with Cross-Passage Answer Verification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:1918-1927.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" HE K M, ZHANG X Y, REN S Q, &lt;i&gt;et al&lt;/i&gt;.Deep Residual Learning for Image Recognition[C/OL].[2018-08-20].https://arxiv.org/pdf/1512.03385.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition[C/OL]">
                                        <b>[25]</b>
                                         HE K M, ZHANG X Y, REN S Q, &lt;i&gt;et al&lt;/i&gt;.Deep Residual Learning for Image Recognition[C/OL].[2018-08-20].https://arxiv.org/pdf/1512.03385.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(05),455-462 DOI:10.16451/j.cnki.issn1003-6059.201905008            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合外部知识的动态多层次语义抽取网络模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%9C%E6%96%87%E8%B6%85&amp;code=25921039&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姜文超</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BA%84%E5%BF%97%E5%88%9A&amp;code=41999551&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">庄志刚</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B6%82%E6%97%AD%E5%B9%B3&amp;code=41999552&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">涂旭平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%A9%E4%BC%A0%E6%9D%B0&amp;code=36582262&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">利传杰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%B5%B7%E6%B3%A2&amp;code=33496328&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘海波</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E9%99%A2&amp;code=0139774&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东工业大学计算机学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E7%94%B5%E5%AD%90%E5%B7%A5%E4%B8%9A%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=1638385&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东电子工业研究院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E5%B9%BF%E4%BF%A1%E9%80%9A%E4%BF%A1%E6%9C%8D%E5%8A%A1%E6%9C%89%E9%99%90%E5%85%AC%E5%8F%B8&amp;code=0139774&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东广信通信服务有限公司</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对复杂多文本机器阅读理解任务中的语义理解与答案提取问题, 提出结合外部知识的动态多层次语义理解与答案抽取模型.首先利用改进的门控单元循环神经网络匹配文本内容与问题集, 分别在向量化文本内容及问题集上实施多维度动态双向注意力机制分析, 提高语义匹配精度.然后利用动态指针网络确定问题答案范围, 改进网络模型语义匹配效率, 降低答案提取冗余度.最后结合外部知识与经验改进候选答案精准性排序, 得到最终答案.实验表明文中模型的语义匹配与答案提取精度显著提升, 对不同领域的复杂文本阅读理解任务具有较高的鲁棒性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%20(MRC)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机器阅读理解 (MRC) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">语义匹配;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A8%E6%80%81%E5%8F%8C%E5%90%91%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">动态双向注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">外部知识;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *姜文超 (通讯作者) , 博士, 讲师, 主要研究方向为云计算、复杂网络、数据挖掘.E-mail:jiangwenchao@gdut.edu.cn.;
                                </span>
                                <span>
                                    庄志刚, 硕士研究生, 主要研究方向为计算机视觉、图像识别、数据挖掘.E-mail:mutingtao2014@gmail.com.;
                                </span>
                                <span>
                                    涂旭平, 博士, 副研究员, 主要研究方向为云计算、分布式系统、大数据分析等.E-mail:tuxp@g-cloud.com.cn.;
                                </span>
                                <span>
                                    利传杰, 硕士, 高级工程师, 主要研究方向为计算机视觉、图像识别、数据挖掘.E-mail:licj@gz2000.net.;
                                </span>
                                <span>
                                    刘海波, 硕士研究生, 主要研究方向为计算机视觉、图像识别、数据挖掘.E-mail:bo895142503@163.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-09-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.11601006);</span>
                                <span>广东省自然科学基金项目 (No.2018A030313061);</span>
                                <span>广东省科技计划项目 (No.2017B030305003, 2017B010124001, 2017B090901005);</span>
                                <span>广东省协同创新与平台环境建设项目 (No.2017A070712016) 资助;</span>
                    </p>
            </div>
                    <h1><b>Dynamic Multiple-level Semantic Extraction Model Based on External Knowledge</b></h1>
                    <h2>
                    <span>JIANG Wenchao</span>
                    <span>ZHUANG Zhigang</span>
                    <span>TU Xuping</span>
                    <span>LI Chuanjie</span>
                    <span>LIU Haibo</span>
            </h2>
                    <h2>
                    <span>School of Computers, Guangdong University of Technology</span>
                    <span>Guangdong Electronics Industry Institute</span>
                    <span>Guangdong Guangxin Communications Services Company Ltd.</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To resolve the problems of semantic understanding and answer extraction in complex multiple context machine reading comprehension environments, a dynamic multiple-level semantic extraction model based on external knowledge is presented. Firstly, the optimized gated single cyclic neural network model is utilized to match the text as well as the problem set. Then, the dynamic multiple-dimension bidirectional attention mechanism analysis is implemented on the text and the problem set respectively to improve the semantic matching precision. Next, a dynamic pointer network is utilized to determine the rank of the answers to the questions. Finally, the candidate answers are sorted based on external knowledge and experiences, and the precision of the final answer is improved further. The experimental results show that problem-answer matching accuracy of the proposed model is significantly improved compared with the mainstream models. Furthermore, the proposed model obtains higher robustness in complex reading comprehension tasks in different application scenes.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Machine%20Reading%20Comprehension%20(MRC)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Machine Reading Comprehension (MRC) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Semantic%20Matching&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Semantic Matching;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dynamic%20Bidirectional%20Attention%20Mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dynamic Bidirectional Attention Mechanism;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=External%20Knowledge&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">External Knowledge;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    JIANG Wenchao ( corresponding author) , Ph. D. , lecturer. His research interests include cloud computing, complex network and data mining;
                                </span>
                                <span>
                                    ZHUANG Zhigang, master student. His research interests include computer vision, image recognition and data mining.;
                                </span>
                                <span>
                                    TU Xuping, Ph. D. , associate researcher. His research interests include cloud computing, distributed system and big data analysis.;
                                </span>
                                <span>
                                    LI Chuanjie, master, senior engineer. His research interests include computer vision, image recognition and data mining.;
                                </span>
                                <span>
                                    LIU Haibo, master student. His research interests include computer vision, image recognition and data mining.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-09-15</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.11601006);</span>
                                <span>Natural Science Foundation of Guangdong Province (No.2018A030313061);</span>
                                <span>Guangdong Science and Technology Plan (No.2017B030305003, 2017B010124001, 2017B090901005);</span>
                                <span>Collaborative Innovation and Platform Environment Construction Project of Guangdong Province (No.2017A070712016);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="70">随着大数据与人工智能技术的发展, 基于大数据和人工智能的机器阅读理解 (Machine Reading Comprehension, MRC) 已成为研究热点.起初由于受到数据集规模限制, MRC研究主要针对完形填空任务.Hermann等<citation id="205" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>提出基于长短期记忆网络 (Long Short-Term Memory, LSTM) <citation id="206" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>的MRC, 推理文本中相关词汇或短语的出现概率, 寻找可能的答案.Hill等<citation id="207" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出记忆网络 (Memory Network) 框架, 在完形填空等任务上取得不错效果.Weston等<citation id="208" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>引入图像处理邻域的注意力机制, 解决MRC任务的文本处理问题, 通过在多个维度上建立文本特征表示, 提取与问题相关的文本内容, 大幅提升答案准确率.SQuAD (Stanford Question Answering Dataset) <citation id="209" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、MS-MARCO (Microsoft Machine Reading Comprehension) <citation id="210" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>及中文数据集DuReader<citation id="211" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等大型文本数据集的出现, 使得MRC相关研究迅速发展.SQuAD、MS-MARCO、DuReader数据集通过人工标注建立大量问题及其答案测试数据, 提供MRC精准性对比及判断依据.</p>
                </div>
                <div class="p1">
                    <p id="71">针对单文本MRC问题的研究, Wang等<sup></sup><citation id="212" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出匹配型长短期记忆网络 (match-Long Short-Term Memory, match-LSTM) 模型, 利用网络的记忆功能对上下文语义进行推理, 将文本内容与问题进行关联匹配, 得到MRC问题的答案.Seo等<citation id="213" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>将注意力机制运用到MRC任务中, 在文本的不同维度上得到不同的特征表示, 进一步提高问题与文本内容的匹配程度.Xiong等<citation id="214" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>为了确定答案在完整文本中的位置, 设计指针网络, 减少答案的冗余度, 并从语义上进一步精简和提炼生成的答案.当前针对单文本的MRC研究已较成熟, Dunn等<citation id="215" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和Nguyen等<citation id="216" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>适当改进单文本上的MRC模型, 解决主题不明确的实体问答集, 在SQuAD数据集上的问答测试表现已接近人类水平<citation id="217" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="72">为了进一步扩展MRC任务模型的应用领域, 解决基于多文本的MRC问题, Yu等<citation id="218" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和Lee等<citation id="219" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>通过排序与相关文本分片, 实现SQuAD数据集上问题的相关回答.Wang等<citation id="220" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>给出一种管道方法, 先将多文本排序, 并从中得到问题的相关答案.He等<citation id="221" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>试图纳入搜索引擎机制, 以便通过更接近真实情况的参数设置设计 MRC 任务, 使用搜索引擎检索多篇文本, 让 MRC 模型阅读这些文章并给出最终答案.此外, 为了使MRC模型更智能, Long等<citation id="222" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出基于外部描述的层次LSTM网络结构, 用于预测和求解内容存在缺失的实体数据集.</p>
                </div>
                <div class="p1">
                    <p id="73">然而, 上述复杂多文本MRC模型在实际应用中问题与答案的匹配度仍然较低, 造成模型训练时出现“答非所问”现象.Cho等<citation id="223" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出以循环神经网络 (Recurrent Neural Network, RNN) 为基础的词向量化模型, 然而其门控循环单元 (Gated Recurrent Unit, GRU) 缺乏复杂文本长信息的记忆功能.针对复杂文本训练任务, 问题内容与文本信息可能存在歧义, 现有模型未能有效解决歧义内容的语义匹配问题.随着数据规模不断增大, 文本数据集的复杂性进一步提高, 问题答案往往存在于多个关联的文本中, 在模型训练时难以在单一文本中确定问题答案的有效范围, 导致预测答案出现冗余信息.目前, 在多文本MRC问题求解研究中, 缺少必要的外部知识支撑, 对于某些在文本中缺乏相关信息却可以根据常识得到答案的问题, 模型未能充分利用外部常识准确匹配结果.</p>
                </div>
                <div class="p1">
                    <p id="74">针对多文本机器阅读理解MRC问题, 本文提出结合外部知识的动态多层次语义抽取网络模型.首先, 利用改进的门控单元循环神经网络匹配文本内容及问题集, 分别在向量化文本内容及问题集上分析多维度动态双向注意力机制, 提高歧义词汇的语义匹配精度.然后, 利用动态指针网络确定问题答案范围, 改进网络模型语义匹配效率, 降低答案提取冗余度.最后, 结合外部知识与经验改进候选答案精准性排序, 得到最终问题答案.实验表明, 本文模型的语义匹配与答案提取精度显著提升, 对于不同背景的复杂文本阅读理解任务具有较高的鲁棒性.</p>
                </div>
                <h3 id="75" name="75" class="anchor-tag">1 结合外部知识的动态多层次语义抽取网络模型</h3>
                <div class="p1">
                    <p id="76">MRC问题的常规处理过程如下.1) 给定大量文本数据, 对文本内容及相应问题进行编码, 将文本内容向量化处理并存储于模型容器中.2) 对于经过编码的问题及文本内容进行相关度匹配, 初步得到预测结果和答案.3) 利用文本内容与问题语义的关联分析, 排序初步答案.4) 将向量化的问题答案解码恢复为文本格式, 得到最终的问题答案.</p>
                </div>
                <div class="p1">
                    <p id="77">针对上述MRC常规处理流程, 本文模型首先改进匹配层、问题答案定界层及最终答案生成层, 引入外部先验知识层, 对多个可能答案进行二次校对, 进一步提高问题答案的完整性和准确性.模型包括5个模块:1) 问题与文本内容匹配, 2) 通过指针网络确定答案范围, 3) 问题答案排序, 4) 引入外部知识, 5) 生成最终答案.具体模型结构如图1所示.</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905010_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 网络模型结构" src="Detail/GetImg?filename=images/MSSB201905010_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 网络模型结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905010_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Network model structure</p>

                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>1.1 文本内容与问题的匹配</b></h4>
                <div class="p1">
                    <p id="80">文本内容与问题的匹配分为如下步骤:1) 改进GRU模型;2) 利用改进的GRU 模型进行文本词嵌入处理;3) 利用动态注意力机制得到文本与问题的相似矩阵;4) 整合跨文本的消息内容.通过上述4步, 提高问题与对应的文本内容信息的语义匹配, 在文本中提取更高精度的答案内容.</p>
                </div>
                <div class="p1">
                    <p id="81">1) 改进GRU模型.当给定大量文本数据时, 需对文本内容及相应问题进行词嵌入处理.GRU为LSTM的一个变体, 简化神经网络模型, 结构中仅含更新门和重置门.由于GRU模型缺乏复杂文本长信息的记忆功能, 本文在原有GRU模型基础上增添两个门限函数<i>z</i><sub><i>j</i></sub>和<i>r</i><sub><i>j</i></sub>, 通过文本内容与相应的答案匹配的相似度设定阈值, 进一步丢弃匹配文本中的非主要信息, 以便有效保留文本信息.具体公式如下:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>z</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>z</mi></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">]</mo><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>z</mi></msub><mi mathvariant="bold-italic">x</mi><mo stretchy="false">]</mo></mrow><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>z</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>r</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>r</mi></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">]</mo><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>r</mi></mrow></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">其中:<b><i>W</i></b>、<b><i>U</i></b>为网络模型参数;<b><i>b</i></b><sub><i>z</i></sub>、<b><i>b</i></b><sub><i>r</i></sub>为函数偏置单元向量, 网络中隐藏层设置新的节点函数;<b><i>b</i></b>为隐藏层偏置向量, <b><i>h</i></b><sub><i>t</i>-1</sub>为网络的隐藏层<b><i>h</i></b><sub><i>t</i></sub>的前一层函数, 函数映射关系表示网络层各阶段文本信息保存的内容矩阵, </p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow><mo>=</mo><mi>Φ</mi><mo stretchy="false"> (</mo><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>x</mi></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mi mathvariant="bold-italic">W</mi></mrow><msub><mrow></mrow><mi>h</mi></msub><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>z</mi><msub><mrow></mrow><mi>j</mi></msub><mo>⊙</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>^</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>z</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>⊙</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">当文本内容与答案相关度超过设定阈值时, 通过<i>r</i><sub><i>j</i></sub>门保留相应的文本信息;当文本内容与答案相关度低于设定阈值时, 通过<i>z</i><sub><i>j</i></sub>门删除相应的文本记忆信息, 从而使模型网络对于文本有效信息的记录能力最大化.修改部分如图2所示.</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905010_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 改进的GRU模型" src="Detail/GetImg?filename=images/MSSB201905010_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 改进的GRU模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905010_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Improved GRU</p>

                </div>
                <div class="p1">
                    <p id="87">2) 词嵌入.设置文本内容及问题表示分别为</p>
                </div>
                <div class="p1">
                    <p id="88"><i>P</i>={<i>W</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup></mrow></math></mathml>}<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></mrow></math></mathml>, <i>Q</i>={<i>W</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup></mrow></math></mathml>}<mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="93">利用改进的GRU模型分别生成文本内容<i>P</i>及问题<i>Q</i>的特征表示<b><i>u</i></b><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup></mrow></math></mathml>与<b><i>u</i></b><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup></mrow></math></mathml>:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup><mo>=</mo><mrow><mi>B</mi><mi>i</mi><mi>G</mi><mi>R</mi><mi>U</mi></mrow><msub><mrow></mrow><mi>Q</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mi>Q</mi></msubsup><mo>, </mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">e</mi><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup><mo>, </mo><mrow><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">h</mi><mi mathvariant="bold-italic">a</mi></mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup><mo stretchy="false">]</mo><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>=</mo><mrow><mi>B</mi><mi>i</mi><mi>G</mi><mi>R</mi><mi>U</mi></mrow><msub><mrow></mrow><mi>Ρ</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mi>Ρ</mi></msubsup><mo>, </mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">e</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>, </mo><mrow><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">h</mi><mi mathvariant="bold-italic">a</mi></mrow><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo stretchy="false">]</mo><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">其中<b><i>e</i></b><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup></mrow></math></mathml>、<b><i>cha</i></b><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup></mrow></math></mathml>分别表示词与词组的特征矩阵.</p>
                </div>
                <div class="p1">
                    <p id="100">3) 利用动态注意力机制得到相似矩阵.为了匹配问题与文本中的相关内容, 运用双向注意力流动机制模型检测文本所有内容与答案的匹配度.同时, 为了提高匹配的精确度, 优化模型作用域, 只作用在文本中与问题相关的内容, 并且在相关内容的维度上进行多层次切分, 分别为“词-词”维度匹配、“词组-词组”维度匹配、“段落-段落”维度匹配, 解决模型语义匹配单一问题, 降低语义分歧.各个维度分别生成相应的匹配矩阵, 〈文本-问题〉相似矩阵<b><i>S</i></b>∈<b>R</b><sup><i>T</i>×<i>J</i></sup>, 〈问题-文本〉相似矩阵<b><i>S</i></b>′∈<b>R</b><sup><i>M</i>×<i>N</i></sup>, <i>T</i>、<i>J</i>、<i>M</i>、<i>N</i>均为相似矩阵的特征维度, 相似矩阵</p>
                </div>
                <div class="p1">
                    <p id="101"><i>S</i><sub><i>t</i>, <i>j</i></sub>=<i>α</i> (<b><i>H</i></b><sub>:<i>t</i></sub>, <b><i>U</i></b><sub>:<i>j</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="102">其中, <i>α</i>为训练模型时设定的标量函数, <b><i>H</i></b><sub>:<i>t</i></sub>, <b><i>U</i></b><sub>:<i>j</i></sub>分别为<i>t</i>维、 <i>j</i>维的特征矩阵.</p>
                </div>
                <div class="p1">
                    <p id="103">4) 整合跨文本的信息内容.由于问题答案可能出现在多文本的多个不同位置而并非一段连续的区域, 为了能够有效整合各部分的答案信息, 在网络模型中增加match-LSTM, 并在文本段落利用注意力机制, 整合文本中关于问题答案的内容:</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>g</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>, </mo><mrow><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">h</mi><mi mathvariant="bold-italic">a</mi></mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup><mo stretchy="false">]</mo><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mo stretchy="false">[</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>, </mo><mrow><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">h</mi><mi mathvariant="bold-italic">a</mi></mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup><mo stretchy="false">]</mo><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⊙</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>, </mo><mrow><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">h</mi><mi mathvariant="bold-italic">a</mi></mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup><mo stretchy="false">]</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>=</mo><mi>B</mi><mi>i</mi><mi>L</mi><mi>S</mi><mi>Τ</mi><mi>Μ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mi>Ρ</mi></msubsup><mo>, </mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>, </mo><mrow><mi mathvariant="bold-italic">c</mi><mi mathvariant="bold-italic">h</mi><mi mathvariant="bold-italic">a</mi></mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup><mo stretchy="false">]</mo><msup><mrow></mrow><mo>*</mo></msup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">其中, <b><i>g</i></b><sub><i>t</i></sub>为网络的门限函数, <b><i>v</i></b><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup></mrow></math></mathml>为与问题相关的文本内容, <b><i>W</i></b><sub><i>g</i></sub>为文本与问题相似度的权重矩阵.</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>1.2 指针网络确定答案范围</b></h4>
                <div class="p1">
                    <p id="108">由于初始文本内容与问题的匹配不足以得到准确答案, 本文结合文本与答案的语义信息, 使用动态指针网络模型最小化文本中与答案相关的文本范围, 提高问题答案的准确率.模型中的指针网络原理是将文本内容的词频向量作为判断文本内容与问题有效匹配的标准, 确定匹配的起始位置与终止位置.此层利用前一层模块中将文本问题序列化之后得到的问题特征矩阵, 使用指针网络对问答任务在文本中的答案定位步骤如下.1) 利用问题的特征矩阵作为输入, 得到指针网络起始层.2) 网络隐藏层记录问题答案与问题的相关程度, 去除冗余信息.3) 在网络全连接层中输出得到答案的可能终止位置.4) 得到文本中答案的精确范围.</p>
                </div>
                <div class="p1">
                    <p id="109">1) 初始化网络起始层.利用问题的特征矩阵<b><i>r</i></b><sup><i>Q</i></sup>作为指针网络的起始层, 模型的池化层需要进行初始化处理.利用</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>i</mi><mi>Q</mi></msubsup><mo>=</mo><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mi>u</mi><mi>Q</mi></msubsup><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>j</mi><mi>Q</mi></msubsup><mo>+</mo><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mi>v</mi><mi>Q</mi></msubsup><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mi>r</mi><mi>Q</mi></msubsup><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">可得到指针网络的起始层</p>
                </div>
                <div class="p1">
                    <p id="112"><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">r</mi><msup><mrow></mrow><mi>Q</mi></msup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>a</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>i</mi><mi>Q</mi></msubsup></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="114">其中, <b><i>u</i></b><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>Q</mi></msubsup></mrow></math></mathml>表示网络中的问题内容, <i>a</i><sub><i>i</i></sub>定义为答案的起始位置的可能性.</p>
                </div>
                <div class="p1">
                    <p id="116">2) 隐藏层与全连接层结合得到答案终止位置:</p>
                </div>
                <div class="p1">
                    <p id="117"><b><i>g</i></b><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>=<b><i>V</i></b><sup>T</sup>tanh (<b><i>W</i></b><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>h</mi><mi>Ρ</mi></msubsup></mrow></math></mathml>[<b><i>v</i></b><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>Ρ</mi></msubsup></mrow></math></mathml>, <b><i>h</i></b><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mi>a</mi></msubsup></mrow></math></mathml>]) , </p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>a</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>t</mi><mi>a</mi></msubsup><mo>=</mo><mi>G</mi><mi>R</mi><mi>U</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mi>a</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">其中, <b><i>g</i></b><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>为网络的全连接层输出, <i>a</i><mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup></mrow></math></mathml>定义为答案的终止位置的可能性, <b><i>h</i></b><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>a</mi></msubsup></mrow></math></mathml>为网络中的隐藏层函数, 用于得到答案内容与对应问题的映射关系, <b><i>h</i></b><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mi>a</mi></msubsup></mrow></math></mathml>表示设置关于问题答案的RNN网络模型中的隐藏层函数, 问题关于文本的注意力池化层向量</p>
                </div>
                <div class="p1">
                    <p id="128"><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>a</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mi mathvariant="bold-italic">v</mi><msubsup><mrow></mrow><mi>i</mi><mi>Ρ</mi></msubsup></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="130">完成上述工作后, 定义一个指针范围目标函数</p>
                </div>
                <div class="p1">
                    <p id="131"><mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>A</mtext><mtext>n</mtext><mtext>s</mtext><mtext>p</mtext><mtext>o</mtext><mtext>i</mtext><mtext>n</mtext><mtext>t</mtext></mrow></msub><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false"> (</mo></mstyle><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>α</mi><msubsup><mrow></mrow><mrow><mi>p</mi><msup><mrow></mrow><mn>1</mn></msup></mrow><mn>1</mn></msubsup><mo>+</mo><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>α</mi><msubsup><mrow></mrow><mrow><mi>p</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mn>2</mn></msubsup><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="133">其中<i>p</i><sup>1</sup>、 <i>p</i><sup>2</sup>为问题答案起始与终止位置.在模型训练中优化该目标函数的最小值, 提高问题答案的准确率.</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134"><b>1.3 问题答案排序</b></h4>
                <div class="p1">
                    <p id="135">在分别匹配问题与相关文本内容的相似度及确定指针网络定位问题答案的范围后, 对于多个文本中可能出现的多个答案, 还需进一步进行有序组合、排序以确定最终的问题答案.将问题<b><i>r</i></b><sup><i>Q</i></sup>及段落文本<b><i>r</i></b><sup><i>P</i></sup>归一化后, 作为模型的输入并分别匹配相似度, 排序层中的全连接层输出如下:</p>
                </div>
                <div class="p1">
                    <p id="136"><b><i>g</i></b><sub><i>j</i></sub>=<b><i>v</i></b><sup>T</sup><sub><i>g</i></sub> (tanh (<b><i>W</i></b><sub><i>g</i></sub>[<b><i>r</i></b><sup><i>Q</i></sup>, <b><i>r</i></b><sup><i>P</i></sup>]) , <b><i>h</i></b><mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow><mi>α</mi></msubsup></mrow></math></mathml>) .</p>
                </div>
                <div class="p1">
                    <p id="138">然后将匹配函数正则化, </p>
                </div>
                <div class="p1">
                    <p id="139"><mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="141">缩短任务训练时间.根据最终的匹配结果得到问题关于文本内容的排序, 优化答案匹配度目标函数</p>
                </div>
                <div class="p1">
                    <p id="142" class="code-formula">
                        <mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>Ρ</mtext><mtext>a</mtext><mtext>s</mtext><mtext>R</mtext><mtext>a</mtext><mtext>n</mtext><mtext>k</mtext></mrow></msub><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mo stretchy="false">[</mo></mstyle><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mrow><mover accent="true"><mi>g</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow><mo stretchy="false">) </mo><mo>+</mo><mi>y</mi></mrow><msub><mrow></mrow><mi>i</mi></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mover accent="true"><mi>g</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">]</mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="143">其中<i>k</i>为文本总数量.</p>
                </div>
                <h4 class="anchor-tag" id="144" name="144"><b>1.4 引入外部知识</b></h4>
                <div class="p1">
                    <p id="145">外部知识相当于人类完成阅读理解任务时所需的常识或其它必备经验.通过对MS-MARCO、DuRead-er数据集的研究, 发现某些问题的答案并非仅靠文本内容就能得到.引入必要的外部知识, 并结合文本内容推断问题答案, 将对MRC问题的精确求解提供必要的常识和经验.Wikilinks数据集包含一系列复杂实体的文本聚类数据, 通过在此数据集中提取问题中的实体集得到相关的外部知识, Wikilinks数据集中的各实体集在问题中出现的概率定义如下:</p>
                </div>
                <div class="p1">
                    <p id="147"><mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><mo>=</mo><mover accent="true"><mi>e</mi><mo>˜</mo></mover><mo stretchy="false">|</mo><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mi>t</mi><mi>Ρ</mi></msubsup><mo>, </mo><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mi>t</mi><mrow><mtext>k</mtext><mtext>n</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msubsup><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>i</mi><mi>a</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">W</mi><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="149">其中, <i>e</i>、<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>e</mi><mo>˜</mo></mover></math></mathml>分别为问题与数据集中的实体集, <b><i>W</i></b><sup>know</sup><sub><i>t</i></sub>为外部知识的特征表示, <b><i>W</i></b>为网络超参数, <b><i>b</i></b><sub><i>p</i></sub>为函数偏置项.在得到问题多个相关实体集的实际出现概率后, 对选定实体文本内容与答案相关性进行排序:</p>
                </div>
                <div class="p1">
                    <p id="151"><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>e</mi><mo>=</mo><mover accent="true"><mi>e</mi><mo stretchy="true">˜</mo></mover><mo stretchy="false">|</mo><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mi>t</mi><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mn>1</mn><mi>m</mi></msubsup><mi>Ρ</mi></mstyle><msup><mrow></mrow><mrow><mtext>k</mtext><mtext>n</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msup></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mi>t</mi><mi>A</mi></msubsup><mo stretchy="false">) </mo><mo>=</mo><mi>σ</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><msubsup><mrow></mrow><mi>i</mi><mi>a</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">W</mi><mo>+</mo><mi mathvariant="bold-italic">r</mi><msup><mrow></mrow><mi>a</mi></msup><mi mathvariant="bold-italic">W</mi><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="153">其中, <b><i>W</i></b><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mn>1</mn><mi>m</mi></msubsup><mi>Ρ</mi></mstyle><msup><mrow></mrow><mrow><mtext>k</mtext><mtext>n</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msup></mrow></msubsup></mrow></math></mathml>、<b><i>W</i></b><mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>A</mi></msubsup></mrow></math></mathml>分别为外部知识中各个实体集及文本答案, <b><i>r</i></b><sup><i>a</i></sup>为答案的特征矩阵, <b><i>b</i></b><sub><i>a</i></sub>为答案相关的偏置项.在采集外部知识的复杂文本内容时, 需对应相关的问题内容, 通过<b><i>S</i></b><sub><i>t</i>, <i>i</i></sub>=<i>α</i> (<b><i>H</i></b><sub>:<i>t</i></sub>, <b><i>U</i></b><sub>:<i>i</i></sub>) 给出外部知识多个文本不同阈值, 生成相似矩阵以得到外部知识与问题的相关度, 从而为问题提供最大的文本信息支持.根据输出结果确定外部实体集的最大概率, 得到答案的目标优化函数, </p>
                </div>
                <div class="p1">
                    <p id="156"><mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>W</mtext><mtext>o</mtext><mtext>r</mtext><mtext>l</mtext><mtext>d</mtext><mtext>k</mtext><mtext>n</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msub><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mi>log</mi></mrow></mstyle><msub><mrow></mrow><mn>2</mn></msub><mi>p</mi><msubsup><mrow></mrow><mrow><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>v</mi></msubsup></mrow><mi>v</mi></msubsup></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="158">由此得到与答案相关度最高的文本内容.</p>
                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>1.5 最终答案生成</b></h4>
                <div class="p1">
                    <p id="160">由于对文本进行词嵌入处理, 在答案生成之前首先要基于GRU模型对答案数据进行解码.解码方法如下:</p>
                </div>
                <div class="p1">
                    <p id="161" class="code-formula">
                        <mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">[</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>↼</mo></mover><msubsup><mrow></mrow><mn>1</mn><mi>Ρ</mi></msubsup></mrow><mo>, </mo><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>↼</mo></mover><msubsup><mrow></mrow><mn>1</mn><mi>Q</mi></msubsup></mrow><mo stretchy="false">]</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>G</mi><mi>R</mi><mi>U</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="162">其中, <b><i>d</i></b><sub>0</sub>为GRU网络中起始隐藏层, <b><i>d</i></b><sub><i>t</i></sub>为GRU网络各层隐藏函数.为了提高训练速度, 在池化层之前设置全连接层<b><i>g</i></b><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>作为池化层的预处理, </p>
                </div>
                <div class="p1">
                    <p id="164"><b><i>g</i></b><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>=<b><i>v</i></b><sup>T</sup><sub><i>a</i></sub>tanh (<b><i>U</i></b><sub><i>a</i></sub><b><i>h</i></b><sub><i>j</i></sub>+<b><i>W</i></b><sub><i>a</i></sub><b><i>d</i></b><sub><i>t</i>-1</sub>) , </p>
                </div>
                <div class="p1">
                    <p id="166"><i>a</i><mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup></mrow></math></mathml>定义为对文本词向量的特征缩放函数:</p>
                </div>
                <div class="p1">
                    <p id="168"><mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="170">然后由<i>a</i><mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup></mrow></math></mathml>与<b><i>h</i></b><sub><i>i</i></sub>共同构成文本向量<b><i>c</i></b><sub><i>t</i></sub>的输入, </p>
                </div>
                <div class="p1">
                    <p id="172"><mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="bold-italic">a</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="174">结合词嵌入及基于注意力机制的文本向量, 通过隐藏层的softmax机制预测答案的最大可能性如下:</p>
                </div>
                <div class="p1">
                    <p id="175" class="code-formula">
                        <mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>y</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mtext>s</mtext><mtext>o</mtext><mtext>f</mtext><mtext>t</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">a</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>r</mi></msub><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>r</mi></msub><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>r</mi></msub><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mi>max</mi><mo stretchy="false">{</mo><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>, </mo><mn>2</mn><mi>j</mi><mo>-</mo><mn>1</mn><mo>, </mo></mrow></msub><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>, </mo><mn>2</mn><mi>j</mi></mrow></msub><mo stretchy="false">}</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="176">同时, 通过优化代价函数<i>L</i><sub>end</sub>, 生成最终的答案模型</p>
                </div>
                <div class="p1">
                    <p id="177"><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>e</mtext><mtext>n</mtext><mtext>d</mtext></mrow></msub><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>X</mi><mo>, </mo><mi>Y</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>D</mi></mrow></munder><mrow><mi>log</mi></mrow></mstyle><msub><mrow></mrow><mn>2</mn></msub><mi>p</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo stretchy="false">|</mo><mi>X</mi><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="179">在结合外部知识的多文本MRC问题中, 最终的训练任务是优化最终的目标函数</p>
                </div>
                <div class="p1">
                    <p id="180"><i>L</i>=<i>L</i><sub>Anspoint</sub>+<i>γ</i><sub>1</sub><i>L</i><sub>PasRank</sub>+<i>γ</i><sub>2</sub><i>L</i><sub>Worldknow</sub>+<i>γ</i><sub>3</sub><i>L</i><sub>end</sub>, </p>
                </div>
                <div class="p1">
                    <p id="181">其中<i>γ</i><sub>1</sub>、<i>γ</i><sub>2</sub>、<i>γ</i><sub>3</sub>为网络设置的各层参数.</p>
                </div>
                <h3 id="182" name="182" class="anchor-tag">2 实验及结果分析</h3>
                <div class="p1">
                    <p id="183">为了使模型的应用更贴近现实情况, 如表1所示, 在对比当前MRC研究中多个数据集及其属性特征之后, 本文实验测试采用英文数据集MS-MARCO和中文数据集DuReader作为实验对象, MS-MARCO、DuReader数据集均为公开、具备人工标注答案的大型测试数据集.MS-MARCO数据集包含 10 万个问题和答案数据, 数据来源基于Bing搜索引擎和小娜虚拟助手的真实、匿名查询数据.相比SQuAD数据集, MS-MARCO数据集答案组成结构可与文本本身不同, 并且答案可能分布在多个文本中.DuReader数据集为公开、训练中文MRC任务的中文数据集, 包含来自百度搜索的30万个真实问题, 每个问题对应5个候选文档文本及人工标注答案.本文选取Wikilinks数据集作为外部知识数据集.</p>
                </div>
                <div class="area_img" id="184">
                    <p class="img_tit"><b>表1 实验数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Experimental datasets</p>
                    <p class="img_note"></p>
                    <table id="184" border="1"><tr><td>名称</td><td>文本<br />规模</td><td>问题<br />规模</td><td>问题<br />来源</td><td>文本<br />来源</td><td>答案<br />组成</td></tr><tr><td><br />RACE</td><td>50000</td><td>870000</td><td>英语<br />考试</td><td>英语<br />考试</td><td>选择题</td></tr><tr><td>SQuAD</td><td>536000</td><td>100000</td><td>网页<br />收集</td><td>维基<br />百科</td><td>连续文<br />本片段</td></tr><tr><td><br />CNN&amp;<br />Dailymail</td><td>287000</td><td>1259000</td><td>完形<br />填空</td><td>新闻<br />报导</td><td>实体</td></tr><tr><td><br />DuReader</td><td>1000000</td><td>300000</td><td>日志<br />文件</td><td>网页<br />数据</td><td>人工<br />标注</td></tr><tr><td><br />MS-MARCO</td><td>500000</td><td>100000</td><td>日志<br />文件</td><td>网页<br />数据</td><td>人工<br />标注</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="185">将MS-MARCO、DuReader数据集随机切分为训练集80%、测试集10%、开发集10%, 将Wikilinks数据集清洗整理作为外部知识的补充.为了将文本流分解成词, 采用Standford CoreNLP作为处理框架, 根据数据集的语言特性及语义特点选择不同的语言分析工具模块.为了实现模型的评测系统, 引入机器翻译的ROUGE-L<citation id="224" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>及BLEU-1<citation id="225" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>, 结合参考答案, 对模型预测的问题答案进行评分, 衡量模型性能.</p>
                </div>
                <div class="p1">
                    <p id="186">对于MS-MARCO数据集, 训练前利用word2vec神经网络模型将文本词向量设定为200维的矩阵规模, 字符向量设定为50维的矩阵规模.网络模型中所有隐藏层中的矩阵规模设置为100, 权重设置为0.000 2, 最终评价函数中<i>γ</i><sub>1</sub>=0.4, <i>γ</i><sub>2</sub>=0.2, <i>γ</i><sub>3</sub>=0.4.为了防止模型学习效率过低或收敛过慢, 采用Adam算法<citation id="226" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>将初始学习率设置为0.000 2, 并将每次训练的最小样本大小规定为32.</p>
                </div>
                <div class="p1">
                    <p id="187">对于DuReader数据集, 首先从多个文本中利用相似矩阵得到与问题相关性最大的段落, 然后对所选段落进行排序, 利用所选段落构成文本信息以适应模型训练.将该数据集的词向量初始化为300维的矩阵, 所有隐藏层中的矩阵规模设置为150, 权重设置为0.000 3, 将初始的学习率设置为0.000 2, 并将每次训练的最小样本大小规定为32.同样为了解决由于网络层数加深使准确率下降的问题, 在网络模型中增加高速神经网络 (Highway Network) 层.</p>
                </div>
                <div class="p1">
                    <p id="188">对比模型包括ReasoNet (Reasoning Network) <citation id="227" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、FastQAEXT (Fast Question Answering Text) <citation id="228" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、 R-Net (Recurrent Neural Network) <citation id="229" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>、 S-Net (Sequence-to-Sequence Neural Networks) <citation id="230" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>、 Verification Mo-del<citation id="231" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>、BiRNN (Bi-directional  Recurrent Neural Net-work) 、Match-LSTM、BiDAF (Bidirectional Attention Flow) 、PageRank+BiDAF.各模型在MS-MARCO测试集上的评分结果如表2所示.</p>
                </div>
                <div class="area_img" id="194">
                    <p class="img_tit"><b>表2 各模型在MS-MARCO测试集上的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Performance comparison of models on MS-MARCOtest set</p>
                    <p class="img_note"></p>
                    <table id="194" border="1"><tr><td><br />模型</td><td>ROUGE-L</td><td>BLEU-1</td></tr><tr><td><br />ReasoNet</td><td>38.81</td><td>39.86</td></tr><tr><td><br />FastQAEXT</td><td>33.67</td><td>33.93</td></tr><tr><td><br />R-Net</td><td>42.89</td><td>42.22</td></tr><tr><td><br />S-Net</td><td>45.23</td><td>43.78</td></tr><tr><td><br />Verification model</td><td>46.15</td><td>44.47</td></tr><tr><td><br />本文单模型</td><td>46.26</td><td>44.49</td></tr><tr><td><br />本文集成模型</td><td>46.56</td><td>45.47</td></tr><tr><td><br />人类表现</td><td>47</td><td>46</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="195">由于模型对各项参数进行优化, 并且引入外部知识以辅助生成问题答案, 因此从表2 可 看 到 本 文单模型ROUGE-L指标达到46.26, BLEU-1指标达到44.49, 性能更优.本文集成模型通过多次优化修改网 络 各 项 超 参 数, 综合得到最佳ROUGE-L指标为46.56, 最 佳BLEU-1指 标 为45.47, 性 能 优 于 其 它模型.</p>
                </div>
                <div class="p1">
                    <p id="196">为了使本文模型在DuReader数据集上取得更高指标, 得到更精确的MRC答案, 本文在匹配文本内容与问题时采用多种方法进行测试对比, 最终得到文本切片排序与双向门循环单元 (Bidirectional Gated Recurrent Unit, BiGRU) 改进模型结合的方法的性能最佳.各模型在DuReader测试集上的评分结果如表3所示, 由于训练前对中文文本进行切片处理, 将相关文本内容进行排序, 提高文本内容与问题答案的相关性, 因此在本文单模型中ROUGE-L指标达到45.16, BLEU-1指标达到41.06, 答案生成准确率明显优于其它模型.</p>
                </div>
                <div class="area_img" id="197">
                    <p class="img_tit"><b>表3 各模型在DuReader测试集上的结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Results comparison of different preprocessing methods on DuReader test set</p>
                    <p class="img_note"></p>
                    <table id="197" border="1"><tr><td><br />模型</td><td>ROUGE-L</td><td>BLEU-1</td></tr><tr><td><br />BiRNN</td><td>39.11</td><td>30.08</td></tr><tr><td><br />Match-LSTM</td><td>39.23</td><td>35.56</td></tr><tr><td><br />BiDAF</td><td>40.36</td><td>36.77</td></tr><tr><td><br />PageRank+BiDAF</td><td>41.35</td><td>37.21</td></tr><tr><td><br />本文模型</td><td>45.16</td><td>41.06</td></tr><tr><td><br />人类表现</td><td>56.12</td><td>57.43</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="198">通过表2与表3可知, 本文模型在MS-MARCO、DuReader测试集上性能较优.为了进一步提高MRC问题求解的准确性, 进一步引入外部知识, 缩小指针网络定位答案的范围, 模型性能提高至45.16%, 本文选取Wikilinks数据集作为最终模型的外部知识集, 得到问题答案的精确率.</p>
                </div>
                <div class="p1">
                    <p id="199">此外, 本文模型可根据数据集的不同特点, 选择性引入深度学习模型中的残差网络 (Residual Network) 层<citation id="232" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>及Highway Network层, 分别添加在神经网络中的输入层与输出层之间, 有效降低模型在网络层数不断增加过程中存在的梯度损失和精确度下降问题, 表4详细给出本文模型在各个阶段的优化改进及其对模型性能的总体影响与效果提升的相关数据.</p>
                </div>
                <div class="area_img" id="200">
                    <p class="img_tit"><b>表4 在2个数据集上本文模型各阶段的主要改进对模型性能的影响对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Effect of main improvement of model at each stage on performance on datasets</p>
                    <p class="img_note"></p>
                    <table id="200" border="1"><tr><td><br />模型阶段</td><td>数据集</td><td>BLEU-1</td><td>ROUGE-L</td></tr><tr><td><br />改进BiGRU+指针网络</td><td>MS-MARCO<br />DuReader</td><td>40.31<br />35.44</td><td>43.09<br />39.82</td></tr><tr><td><br />改进BiGRU+指针网络+Residual Network</td><td>MS-MARCO</td><td>41.54</td><td>44.92</td></tr><tr><td><br />改进BiGRU+指针网络+Highway Network</td><td>DuReader</td><td>35.69</td><td>40.03</td></tr><tr><td><br />改进BiGRU+指针网络+Residual Network+外部知识</td><td>MS-MARCO</td><td>43.51</td><td>46.02</td></tr><tr><td><br />改进BiGRU+指针网络+Highway Network+外部知识</td><td>DuReader</td><td>36.88</td><td>41.31</td></tr><tr><td><br />最终模型</td><td>MS-MARCO <br />DuReader</td><td>44.49<br />37.22</td><td>46.26<br />41.47</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="201" name="201" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="202">针对复杂多文本机器阅读理解<i>MRC</i>问题, 本文提出结合外部知识的动态多层次网络答案抽取模型.利用改进的门控单元循环神经网络作为匹配模型, 提高文本内容及问题集的匹配效率.运用动态双向注意力机制在向量化文本内容以及问题集的多个维度上设置不同的文本权重, 提高匹配精度.运用动态指针网络确定问题答案可能范围, 降低答案冗余度.通过融合外部知识和经验, 进一步提高答案与问题的匹配准确度.在<i>MS</i>-<i>MARCO</i>英文数据集及<i>Du</i>-<i>Reader</i>中文数据集上的实验测试表明, 本文模型性能提升显著, 对不同领域的复杂文本阅读理解问题具有较高鲁棒性.</p>
                </div>
                <div class="p1">
                    <p id="204">本文网络模型在外部知识的引入与文本信息组合过程中仍存在组合方法和语义理解的不足, 造成<i>MRC</i>任务的准确率与人类认知水准仍有一定差距.后续研究将会继续改进外部知识的引入方法, 得到与问题更高的匹配度, 期望在多文本机器阅读理解<i>MRC</i>任务上趋近人类认知水平.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="234" type="formula" href="images/MSSB201905010_23400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">姜文超</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="236" type="formula" href="images/MSSB201905010_23600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">庄志刚</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="238" type="formula" href="images/MSSB201905010_23800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">涂旭平</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="240" type="formula" href="images/MSSB201905010_24000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">利传杰</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="242" type="formula" href="images/MSSB201905010_24200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">刘海波</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Teaching machines to read and comprehend">

                                <b>[1]</b> HERMANN K M, KOCISKY T, GREFENSTETTE E, <i>et al</i>.Tea-ching Machines to Read and Comprehend // CORTES C, LAWRENCE N D, LEE D D, <i>et al</i>., eds.Advances in Neural Information Processing Systems 28.Cambridge, USA:The MIT Press, 2015:1693-1701.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MTc2NjhVTGJJSkZzU2J4QT1OaWZKWmJLOUh0ak1xbzlGWk9vTERYVXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> HOCHREITER S, SCHMIDHUBER J.Long Short-Term Memory.Neural Computation, 1997, 9 (8) :1735-1780.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Goldilocks Principle:Reading Children′s Books with Explicit Memory Representations[C/OL]">

                                <b>[3]</b> HILL F, BORDES A, CHOPRA S, <i>et al</i>.The Goldilocks Principle:Reading Children′s Books with Explicit Memory Representations[C/OL].[2018-08-20].https://arxiv.org/pdf/1511.02301.pdf.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Memory Networks[C/OL]">

                                <b>[4]</b> WESTON J, CHOPRA S, BORDES A.Memory Networks[C/OL].[2018-08-20].https://arxiv.org/pdf/1410.3916.pdf.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Squad:100,000+questions for machine comprehension of text">

                                <b>[5]</b> RAJPURKAR P, ZHANG J, LOPYREV K, <i>et al</i>.Squad:100, 000+ Questions for Machine Comprehension of Text // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2016:2383-2392.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=MS MARCO:A Human Generated Machine Reading Comprehension Dataset[C/OL]">

                                <b>[6]</b> NGUYEN T, ROSENBERG M, SONG X, <i>et al</i>.MS MARCO:A Human Generated Machine Reading Comprehension Dataset[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.09268.pdf.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DuReader:A Chinese Machine Rea-ding Comprehension Dataset from Real-World Applications[C/OL]">

                                <b>[7]</b> HE W, LIU K, LIU J, <i>et al</i>.DuReader:A Chinese Machine Rea-ding Comprehension Dataset from Real-World Applications[C/OL].[2018-08-20].https://arxiv.org/pdf/1711.05073.pdf.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Machine Comprehension Using Match-LSTM and Answer Pointer[C/OL]">

                                <b>[8]</b> WANG S H, JIANG J.Machine Comprehension Using Match-LSTM and Answer Pointer[C/OL].[2018-08-20].https://arxiv.org/pdf/1608.07905.pdf.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bidirectional Attention Flow for Machine Comprehension[C/OL]">

                                <b>[9]</b> SEO M, KEMBHAVI A, FARHADI A, <i>et al</i>.Bidirectional Attention Flow for Machine Comprehension[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01603.pdf.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic Coattention Networks for Question Answering[C/OL]">

                                <b>[10]</b> XIONG C M, ZHONG V, SOCHER R.Dynamic Coattention Networks for Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01604.pdf.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SearchQA:A New Q&amp;amp;A Dataset Augmented with Context from a Search Engine[C/OL]">

                                <b>[11]</b> DUNN M, SAGUN L, HIGGINS M, <i>et al</i>.SearchQA:A New Q&amp;A Dataset Augmented with Context from a Search Engine[C/OL].[2018-08-20].https://arxiv.org/pdf/1704.05179.pdf.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=End-to-End Reading Com-prehension with Dynamic Answer Chunk Ranking[C/OL]">

                                <b>[12]</b> YU Y, ZHANG W, HASAN K, <i>et al</i>.End-to-End Reading Com-prehension with Dynamic Answer Chunk Ranking[C/OL].[2018-08-20].https://arxiv.org/pdf/1610.09996v2.pdf.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning Recu-rrent Span Representations for Extractive Question Answering[C/OL]">

                                <b>[13]</b> LEE K, KWIATKOWSKI T, PARIKH A, <i>et al</i>.Learning Recu-rrent Span Representations for Extractive Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1611.01436.pdf.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Evidence Aggregation for Answer Re-ranking in Open-Domain Question Answering[C/OL]">

                                <b>[14]</b> WANG S H, YU M, JIANG J, <i>et al</i>.Evidence Aggregation for Answer Re-ranking in Open-Domain Question Answering[C/OL].[2018-08-20].https://arxiv.org/pdf/1711.05116.pdf.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=World Knowledge for Reading Comprehension:Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions">

                                <b>[15]</b> LONG T, BENGIO E, LOWE R, <i>et al</i>.World Knowledge for Reading Comprehension:Rare Entity Prediction with Hierarchical LSTMs Using External Descriptions // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2017:825-834.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning phrase representations using RNN encoder-decoder for Statistical machine translation">

                                <b>[16]</b> CHO K, VAN MERRIENBOER B, GULCEHRE C, <i>et al</i>.Lea-rning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1724-1734.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ROUGE:A Package for Automatic Evaluation of Summaries.Text Summarization Branches Out[C/OL]">

                                <b>[17]</b> LIN C Y.ROUGE:A Package for Automatic Evaluation of Summaries.Text Summarization Branches Out[C/OL].[2018-08-20].https://www.aclweb.org/anthology/W04-1013.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=B1EU: a method for automatic evaluation of machine translation">

                                <b>[18]</b> PAPINENI K, ROUKOS S, WARD T, <i>et al</i>.BLEU:A Method for Automatic Evaluation of Machine Translation // Proc of the 40th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2002:311-318.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adam:a method for stochastic optimization">

                                <b>[19]</b> KINGMA D P, BA J.Adam:A Method for Stochastic Optimization[C/OL].[2018-08-20].https://arxiv.org/pdf/1412.6980.pdf.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Reasonet Learning to stop reading in machine comprehension">

                                <b>[20]</b> SHEN Y L, HUANG P S, GAO J F, <i>et al</i>.Reasonet:Learning to Stop Reading in Machine Comprehension // Proc of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2017:1047-1055.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Making Neural QA as Simple as Possible but not Simpler">

                                <b>[21]</b> WEISSENBORN D, WIESE G, SEIFFE L.Making Neural QA as Simple as Possible But Not Simpler // Proc of the 21st Conference on Computational Natural Language Learning.Stroudsburg, USA:ACL, 2017:271-280.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gated Self-Matching Networks for Reading Comprehension and Question Answering">

                                <b>[22]</b> WANG W H, YANG N, WEI F R, <i>et al</i>.Gated Self-matching Networks for Reading Comprehension and Question Answering // Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017, I:189-198.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=S-NET:From Answer Extraction to Answer Generation for Machine Reading Comprehension[C/OL]">

                                <b>[23]</b> TAN C Q, WEI F R, YANG N, <i>et al</i>.S-NET:From Answer Extraction to Answer Generation for Machine Reading Comprehension[C/OL].[2018-08-20].https://arxiv.org/pdf/1706.04815.pdf.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification">

                                <b>[24]</b> WANG Y Z, LIU K, LIU J, <i>et al</i>.Multi-passage Machine Reading Comprehension with Cross-Passage Answer Verification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:1918-1927.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Residual Learning for Image Recognition[C/OL]">

                                <b>[25]</b> HE K M, ZHANG X Y, REN S Q, <i>et al</i>.Deep Residual Learning for Image Recognition[C/OL].[2018-08-20].https://arxiv.org/pdf/1512.03385.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201905010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201905010&amp;v=MTIxNjJDVVJMT2VaZVJuRnl6Z1ZicktLRDdZYkxHNEg5ak1xbzlFWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
