<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131451012530000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201906001%26RESULT%3d1%26SIGN%3dM0K73Dh%252fD2WCKVpP0dBewyuNns0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201906001&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201906001&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201906001&amp;v=MDAxNDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVTdySUtEN1liTEc0SDlqTXFZOUZaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#85" data-title="1 最优输运 ">1 最优输运</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#86" data-title="&lt;b&gt;1.1 Wasserstein&lt;/b&gt;距离"><b>1.1 Wasserstein</b>距离</a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;1.2&lt;/b&gt; 对偶&lt;b&gt;Sinkhorn&lt;/b&gt;散度"><b>1.2</b> 对偶<b>Sinkhorn</b>散度</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#141" data-title="2 基于最优输运的迁移学习 ">2 基于最优输运的迁移学习</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#142" data-title="&lt;b&gt;2.1&lt;/b&gt; 算法框架"><b>2.1</b> 算法框架</a></li>
                                                <li><a href="#169" data-title="&lt;b&gt;2.2 Wasserstein&lt;/b&gt;距离和对偶&lt;b&gt;Sinkhorn&lt;/b&gt;散度情形的推导"><b>2.2 Wasserstein</b>距离和对偶<b>Sinkhorn</b>散度情形的推导</a></li>
                                                <li><a href="#275" data-title="&lt;b&gt;2.3 &lt;i&gt;l&lt;/i&gt;&lt;/b&gt;&lt;sub&gt;&lt;b&gt;2&lt;/b&gt;&lt;/sub&gt;正则的&lt;b&gt;Wasserstein&lt;/b&gt;距离"><b>2.3 <i>l</i></b><sub><b>2</b></sub>正则的<b>Wasserstein</b>距离</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#377" data-title="3 基于迁移学习的人群计数 ">3 基于迁移学习的人群计数</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#380" data-title="&lt;b&gt;3.1&lt;/b&gt; 跨摄像头间人群信息的迁移"><b>3.1</b> 跨摄像头间人群信息的迁移</a></li>
                                                <li><a href="#391" data-title="&lt;b&gt;3.2&lt;/b&gt; 适用于迁移框架的透视权重矩阵"><b>3.2</b> 适用于迁移框架的透视权重矩阵</a></li>
                                                <li><a href="#410" data-title="&lt;b&gt;3.3&lt;/b&gt; 基于迁移学习的人群计数步骤"><b>3.3</b> 基于迁移学习的人群计数步骤</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#425" data-title="4 实验及结果分析 ">4 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#426" data-title="&lt;b&gt;4.1&lt;/b&gt; 人群数据集及设定"><b>4.1</b> 人群数据集及设定</a></li>
                                                <li><a href="#433" data-title="&lt;b&gt;4.2&lt;/b&gt; 与其它迁移算法的对比"><b>4.2</b> 与其它迁移算法的对比</a></li>
                                                <li><a href="#437" data-title="&lt;b&gt;4.3&lt;/b&gt; 在人群计数任务上的适用性"><b>4.3</b> 在人群计数任务上的适用性</a></li>
                                                <li><a href="#441" data-title="&lt;b&gt;4.4&lt;/b&gt; 运行速度"><b>4.4</b> 运行速度</a></li>
                                                <li><a href="#444" data-title="&lt;b&gt;4.5&lt;/b&gt; 消融实验"><b>4.5</b> 消融实验</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#452" data-title="5 结束语 ">5 结束语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#385" data-title="图1 块的图例">图1 块的图例</a></li>
                                                <li><a href="#398" data-title="图2 透视权重矩阵求解方法">图2 透视权重矩阵求解方法</a></li>
                                                <li><a href="#435" data-title="&lt;b&gt;表1 6种算法的实验结果对比&lt;/b&gt;"><b>表1 6种算法的实验结果对比</b></a></li>
                                                <li><a href="#439" data-title="&lt;b&gt;表2 3种算法的效果对比&lt;/b&gt;"><b>表2 3种算法的效果对比</b></a></li>
                                                <li><a href="#443" data-title="&lt;b&gt;表3 Optlearn与KLIEP运行时间对比&lt;/b&gt;"><b>表3 Optlearn与KLIEP运行时间对比</b></a></li>
                                                <li><a href="#447" data-title="&lt;b&gt;表4 以块为数据单位的必要性&lt;/b&gt;"><b>表4 以块为数据单位的必要性</b></a></li>
                                                <li><a href="#450" data-title="&lt;b&gt;表5 迁移步骤的必要性&lt;/b&gt;"><b>表5 迁移步骤的必要性</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="502">


                                    <a id="bibliography_1" title=" FERNANDO B, HABRARD A, SEBBAN M, et al.Unsupervised Visual Domain Adaptation Using Subspace Alignment // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2013:2960-2967." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unsupervised visual domain adaptation using subspace alignment">
                                        <b>[1]</b>
                                         FERNANDO B, HABRARD A, SEBBAN M, et al.Unsupervised Visual Domain Adaptation Using Subspace Alignment // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2013:2960-2967.
                                    </a>
                                </li>
                                <li id="504">


                                    <a id="bibliography_2" title=" ALJUNDI R, EMONET R, MUSELET D, et al.Landmarks-Based Kernelized Subspace Alignment for Unsupervised Domain Adaptation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2015:56-63." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Landmarks-based kernelized subspace alignment for unsupervised domain adaptation">
                                        <b>[2]</b>
                                         ALJUNDI R, EMONET R, MUSELET D, et al.Landmarks-Based Kernelized Subspace Alignment for Unsupervised Domain Adaptation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2015:56-63.
                                    </a>
                                </li>
                                <li id="506">


                                    <a id="bibliography_3" title=" LU H, ZHANG L, CAO Z G, et al.When Unsupervised Domain Adaptation Meets Tensor Representations // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2017:599-608." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=When unsupervised domain adaptation meets tensor representations">
                                        <b>[3]</b>
                                         LU H, ZHANG L, CAO Z G, et al.When Unsupervised Domain Adaptation Meets Tensor Representations // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2017:599-608.
                                    </a>
                                </li>
                                <li id="508">


                                    <a id="bibliography_4" title=" 张倩, 李明, 王雪松, 等.一种面向多源领域的实例迁移学习.自动化学报, 2014, 40 (6) :1176-1183. (ZHANG Q, LI M, WANG X S, et al.Instance-Based Transfer Learning for Multi-source Domains.Acta Automatica Sinica, 2014, 40 (6) :1176-1183.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201406015&amp;v=Mjc4ODdlWmVSbkZ5emhVN3JJS0NMZlliRzRIOVhNcVk5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         张倩, 李明, 王雪松, 等.一种面向多源领域的实例迁移学习.自动化学报, 2014, 40 (6) :1176-1183. (ZHANG Q, LI M, WANG X S, et al.Instance-Based Transfer Learning for Multi-source Domains.Acta Automatica Sinica, 2014, 40 (6) :1176-1183.) 
                                    </a>
                                </li>
                                <li id="510">


                                    <a id="bibliography_5" title=" 张景祥, 王士同, 邓赵红, 等.融合异构特征的子空间迁移学习算法.自动化学报, 2014, 40 (2) :236-246. (ZHANG J X, WANG S T, DENG Z H, et al.A Subspace Transfer Learning Algorithm Integrating Heterogeneous Features.Acta Automatica Sinica, 2014, 40 (2) :236-246.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201402008&amp;v=Mjk4NjBGckNVUkxPZVplUm5GeXpoVTdySUtDTGZZYkc0SDlYTXJZOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         张景祥, 王士同, 邓赵红, 等.融合异构特征的子空间迁移学习算法.自动化学报, 2014, 40 (2) :236-246. (ZHANG J X, WANG S T, DENG Z H, et al.A Subspace Transfer Learning Algorithm Integrating Heterogeneous Features.Acta Automatica Sinica, 2014, 40 (2) :236-246.) 
                                    </a>
                                </li>
                                <li id="512">


                                    <a id="bibliography_6" title=" SUGIYAMA M, NAKAJIMA S, KASHIMA H, et al.Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation // SCH&#214;LKOPF B, PLATT J, HOFMANN T, eds.Advances in Neural Information Processing Systems 20.Cambridge, USA:The MIT Press, 2007:1433-1440." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Direct Importance Estimation with Model Selec-tion and Its Application to Covariate Shift Adaptation">
                                        <b>[6]</b>
                                         SUGIYAMA M, NAKAJIMA S, KASHIMA H, et al.Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation // SCH&#214;LKOPF B, PLATT J, HOFMANN T, eds.Advances in Neural Information Processing Systems 20.Cambridge, USA:The MIT Press, 2007:1433-1440.
                                    </a>
                                </li>
                                <li id="514">


                                    <a id="bibliography_7" title=" SUN B, FENG J S, SAENKO K.Return of Frustratingly Easy Domain Adaptation[C/OL].[2019-02-26].https://arxiv.org/pdf/1511.05547.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Return of Frustratingly Easy Domain Adaptation[C/OL]">
                                        <b>[7]</b>
                                         SUN B, FENG J S, SAENKO K.Return of Frustratingly Easy Domain Adaptation[C/OL].[2019-02-26].https://arxiv.org/pdf/1511.05547.pdf.
                                    </a>
                                </li>
                                <li id="516">


                                    <a id="bibliography_8" title=" GONG B Q, SHI Y, SHA F, et al.Geodesic Flow Kernel for Unsupervised Domain Adaptation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2012:2066-2073." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Geodesic flow kernel for unsupervised domain adaptation">
                                        <b>[8]</b>
                                         GONG B Q, SHI Y, SHA F, et al.Geodesic Flow Kernel for Unsupervised Domain Adaptation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2012:2066-2073.
                                    </a>
                                </li>
                                <li id="518">


                                    <a id="bibliography_9" title=" COURTY N, FLAMARY R, TUIA D.Domain Adaptation with Re-gularized Optimal Transport // Proc of the Joint European Confe-rence on Machine Learning and Knowledge Discovery in Databases.Berlin, Germany:Springer, 2014:274-289" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Domain Adaptation with Re-gularized Optimal Transport">
                                        <b>[9]</b>
                                         COURTY N, FLAMARY R, TUIA D.Domain Adaptation with Re-gularized Optimal Transport // Proc of the Joint European Confe-rence on Machine Learning and Knowledge Discovery in Databases.Berlin, Germany:Springer, 2014:274-289
                                    </a>
                                </li>
                                <li id="520">


                                    <a id="bibliography_10" title=" TAN B, SONG Y Q, ZHONG E H, et al.Transitive Transfer Learning // Proc of the 21th ACM SIGKDD International Confe-rence on Knowledge Discovery and Data Mining.New York, USA:ACM, 2015:1155-1164." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Transitive Transfer Learning">
                                        <b>[10]</b>
                                         TAN B, SONG Y Q, ZHONG E H, et al.Transitive Transfer Learning // Proc of the 21th ACM SIGKDD International Confe-rence on Knowledge Discovery and Data Mining.New York, USA:ACM, 2015:1155-1164.
                                    </a>
                                </li>
                                <li id="522">


                                    <a id="bibliography_11" title=" TAN B, ZHANG Y, PAN S J, et al.Distant Domain Transfer Learning // Proc of the 31st AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2017:2604-2610." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distant domain transfer learning">
                                        <b>[11]</b>
                                         TAN B, ZHANG Y, PAN S J, et al.Distant Domain Transfer Learning // Proc of the 31st AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2017:2604-2610.
                                    </a>
                                </li>
                                <li id="524">


                                    <a id="bibliography_12" title=" ARJOVSKY M, CHINTALA S, BOTTOU L.Wasserstein Generative Adversarial Networks // Proc of the 34th International Confe-rence on Machine Learning.New York, USA:ACM, 2017:214-223." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wasserstein Generative Adversarial Networks">
                                        <b>[12]</b>
                                         ARJOVSKY M, CHINTALA S, BOTTOU L.Wasserstein Generative Adversarial Networks // Proc of the 34th International Confe-rence on Machine Learning.New York, USA:ACM, 2017:214-223.
                                    </a>
                                </li>
                                <li id="526">


                                    <a id="bibliography_13" title=" GULRAJANI I, AHMED F, ARJOVSKY M, et al.Improved Training of Wasserstein Gans[C/OL].[2019-02-26].https://arxiv.org/pdf/1704.00028.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved Training of Wasserstein Gans[C/OL]">
                                        <b>[13]</b>
                                         GULRAJANI I, AHMED F, ARJOVSKY M, et al.Improved Training of Wasserstein Gans[C/OL].[2019-02-26].https://arxiv.org/pdf/1704.00028.pdf.
                                    </a>
                                </li>
                                <li id="528">


                                    <a id="bibliography_14" title=" CUTURI M.Sinkhorn Distances:Lightspeed Computation of Optimal Transport // BURGES C J C, BOTTOU L, WELLING M, et al., eds.Advances in Neural Information Processing Systems 26.Cambridge, USA:The MIT Press, 2013:2292-2300." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sinkhorn Distances:Lightspeed Computation of Optimal Transport">
                                        <b>[14]</b>
                                         CUTURI M.Sinkhorn Distances:Lightspeed Computation of Optimal Transport // BURGES C J C, BOTTOU L, WELLING M, et al., eds.Advances in Neural Information Processing Systems 26.Cambridge, USA:The MIT Press, 2013:2292-2300.
                                    </a>
                                </li>
                                <li id="530">


                                    <a id="bibliography_15" title=" BLONDEL M, SEGUY V, ROLET A.Smooth and Sparse Optimal Transport[C/OL].[2019-02-26].https://arxiv.org/pdf/1710.06276.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Smooth and Sparse Optimal Transport[C/OL]">
                                        <b>[15]</b>
                                         BLONDEL M, SEGUY V, ROLET A.Smooth and Sparse Optimal Transport[C/OL].[2019-02-26].https://arxiv.org/pdf/1710.06276.pdf.
                                    </a>
                                </li>
                                <li id="532">


                                    <a id="bibliography_16" title=" ZHAO P, ZHOU Z H.Label Distribution Learning by Optimal Transport[C/OL].[2019-02-26].https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/aaai18ladot.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Label Distribution Learning by Optimal Transport[C/OL]">
                                        <b>[16]</b>
                                         ZHAO P, ZHOU Z H.Label Distribution Learning by Optimal Transport[C/OL].[2019-02-26].https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/aaai18ladot.pdf.
                                    </a>
                                </li>
                                <li id="534">


                                    <a id="bibliography_17" title=" SANJABI M, BA J, RAZAVIYAYN M, et al.On the Convergence and Robustness of Training GANs with Regularized Optimal Transport // BENGIO S, WALLACH H M, LAROCHELLE H, et al., eds.Advances in Neural Information Processing Systems 31.Cambridge, USA:The MIT Press, 2018:7091-7101." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the Convergence and Robustness of Training GANs with Regularized Optimal Transport">
                                        <b>[17]</b>
                                         SANJABI M, BA J, RAZAVIYAYN M, et al.On the Convergence and Robustness of Training GANs with Regularized Optimal Transport // BENGIO S, WALLACH H M, LAROCHELLE H, et al., eds.Advances in Neural Information Processing Systems 31.Cambridge, USA:The MIT Press, 2018:7091-7101.
                                    </a>
                                </li>
                                <li id="536">


                                    <a id="bibliography_18" title=" ZHAO T, NEVATIA R, WU B.Segmentation and Tracking of Multiple Humans in Crowded Environments.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2008, 30 (7) :1198-1211." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Segmentation and Tracking of Multiple Humans in Crowded Environments">
                                        <b>[18]</b>
                                         ZHAO T, NEVATIA R, WU B.Segmentation and Tracking of Multiple Humans in Crowded Environments.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2008, 30 (7) :1198-1211.
                                    </a>
                                </li>
                                <li id="538">


                                    <a id="bibliography_19" title=" DOLLAR P, WOJEK C, SCHIELE B, et al.Pedestrian Detection:An Evaluation of the State of the Art.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (4) :743-761." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pedestrian Detection: An Evaluation of the State of the Art">
                                        <b>[19]</b>
                                         DOLLAR P, WOJEK C, SCHIELE B, et al.Pedestrian Detection:An Evaluation of the State of the Art.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (4) :743-761.
                                    </a>
                                </li>
                                <li id="540">


                                    <a id="bibliography_20" title=" GE W, COLLINS R T.Marked Point Processes for Crowd Counting // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2009:2913-2920." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Marked point processes for crowd counting">
                                        <b>[20]</b>
                                         GE W, COLLINS R T.Marked Point Processes for Crowd Counting // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2009:2913-2920.
                                    </a>
                                </li>
                                <li id="542">


                                    <a id="bibliography_21" title=" CHAN A B, LIANG Z S J, VASCONCELOS N.Privacy Preserving Crowd Monitoring:Counting People without People Models or Tracking // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2008.DOI:10.1109/CVPR.2008.4587569." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Privacy preservingcrowd monitoring:counting people without people models ortracking">
                                        <b>[21]</b>
                                         CHAN A B, LIANG Z S J, VASCONCELOS N.Privacy Preserving Crowd Monitoring:Counting People without People Models or Tracking // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2008.DOI:10.1109/CVPR.2008.4587569.
                                    </a>
                                </li>
                                <li id="544">


                                    <a id="bibliography_22" title=" CHAN A B, VASCONCELOS N.Bayesian Poisson Regression for Crowd Counting // Proc of the 12th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2009:545-551." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bayesian Poisson regression for crowd counting">
                                        <b>[22]</b>
                                         CHAN A B, VASCONCELOS N.Bayesian Poisson Regression for Crowd Counting // Proc of the 12th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2009:545-551.
                                    </a>
                                </li>
                                <li id="546">


                                    <a id="bibliography_23" title=" CHAN A B, VASCONCELOS N.Counting People with Low-Level Features and Bayesian Regression.IEEE Transactions on Image Processing, 2012, 21 (4) :2160-2177." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Counting People With Low-Level Features and Bayesian Regression">
                                        <b>[23]</b>
                                         CHAN A B, VASCONCELOS N.Counting People with Low-Level Features and Bayesian Regression.IEEE Transactions on Image Processing, 2012, 21 (4) :2160-2177.
                                    </a>
                                </li>
                                <li id="548">


                                    <a id="bibliography_24" title=" CHEN K, GONG S G, XIANG T, et al.Cumulative Attribute Space for Age and Crowd Density Estimation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2013:2467-2474." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cumulative attribute space for age and crowd density estimation">
                                        <b>[24]</b>
                                         CHEN K, GONG S G, XIANG T, et al.Cumulative Attribute Space for Age and Crowd Density Estimation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2013:2467-2474.
                                    </a>
                                </li>
                                <li id="550">


                                    <a id="bibliography_25" title=" TAN B, ZHANG J P, WANG L.Semi-supervised Elastic Net for Pedestrian Counting.Pattern Recognition, 2011, 44 (10/11) :2297-2304." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738129&amp;v=MDAwMTJxWTlGWStnSERYNHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRm9VYnhJPU5pZk9mYks3SHRETg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         TAN B, ZHANG J P, WANG L.Semi-supervised Elastic Net for Pedestrian Counting.Pattern Recognition, 2011, 44 (10/11) :2297-2304.
                                    </a>
                                </li>
                                <li id="552">


                                    <a id="bibliography_26" title=" XIA W, ZHANG J P, KRUGER U.Semisupervised Pedestrian Counting with Temporal and Spatial Consistencies.IEEE Transactions on Intelligent Transportation Systems, 2015, 16 (4) :1705-1715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semisupervised pedestrian counting with temporal and spatial consistencies">
                                        <b>[26]</b>
                                         XIA W, ZHANG J P, KRUGER U.Semisupervised Pedestrian Counting with Temporal and Spatial Consistencies.IEEE Transactions on Intelligent Transportation Systems, 2015, 16 (4) :1705-1715.
                                    </a>
                                </li>
                                <li id="554">


                                    <a id="bibliography_27" title=" ZHOU Q, ZHANG J P, CHE L F, et al.Crowd Counting with Limited Labeling through Submodular Frame Selection.IEEE Transactions on Intelligent Transportation Systems, 2019, 20 (5) :1728-1738." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Crowd Counting with Limited Labeling through Submodular Frame Selection">
                                        <b>[27]</b>
                                         ZHOU Q, ZHANG J P, CHE L F, et al.Crowd Counting with Limited Labeling through Submodular Frame Selection.IEEE Transactions on Intelligent Transportation Systems, 2019, 20 (5) :1728-1738.
                                    </a>
                                </li>
                                <li id="556">


                                    <a id="bibliography_28" title=" 覃勋辉, 王修飞, 周曦, 等.多种人群密度场景下的人群计数.中国图象图形学报, 2013, 18 (4) :392-398. (QIN X H, WANG X F, ZHOU X, et al.Counting People in Various Crowed Density Scenes Using Support Vector Regression.Journal of Image and Graphics, 2013, 18 (4) :392-398.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201304006&amp;v=MDcwMjBQeXJmYkxHNEg5TE1xNDlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6aFU3ckk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[28]</b>
                                         覃勋辉, 王修飞, 周曦, 等.多种人群密度场景下的人群计数.中国图象图形学报, 2013, 18 (4) :392-398. (QIN X H, WANG X F, ZHOU X, et al.Counting People in Various Crowed Density Scenes Using Support Vector Regression.Journal of Image and Graphics, 2013, 18 (4) :392-398.) 
                                    </a>
                                </li>
                                <li id="558">


                                    <a id="bibliography_29" title=" SINDAGI V A, PATEL V M.Generating High-Quality Crowd Density Maps Using Contextual Pyramid CNNs // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2017, I:1879-1888." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generating high-quality crowd density maps using contextual pyramid cnns">
                                        <b>[29]</b>
                                         SINDAGI V A, PATEL V M.Generating High-Quality Crowd Density Maps Using Contextual Pyramid CNNs // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2017, I:1879-1888.
                                    </a>
                                </li>
                                <li id="560">


                                    <a id="bibliography_30" title=" SAM D B, SURYA S, BABU R V.Switching Convolutional Neural Network for Crowd Counting // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:4031-4039." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Switching convolutional neural network for crowd counting">
                                        <b>[30]</b>
                                         SAM D B, SURYA S, BABU R V.Switching Convolutional Neural Network for Crowd Counting // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:4031-4039.
                                    </a>
                                </li>
                                <li id="562">


                                    <a id="bibliography_31" title=" ZHANG Y Y, ZHOU D S, CHEN S Q, et al.Single-Image Crowd Counting via Multi-column Convolutional Neural Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:589-597." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single-Image Crowd Counting via Multi-Column Convolutional Neural Network">
                                        <b>[31]</b>
                                         ZHANG Y Y, ZHOU D S, CHEN S Q, et al.Single-Image Crowd Counting via Multi-column Convolutional Neural Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:589-597.
                                    </a>
                                </li>
                                <li id="564">


                                    <a id="bibliography_32" title=" KANG D, DHAR D, CHAN A B.Crowd Counting by Adapting Convolutional Neural Networks with Side Information[C/OL].[2019-02-26].https://arxiv.org/pdf/1611.06748.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Crowd Counting by Adapting Convolutional Neural Networks with Side Information[C/OL]">
                                        <b>[32]</b>
                                         KANG D, DHAR D, CHAN A B.Crowd Counting by Adapting Convolutional Neural Networks with Side Information[C/OL].[2019-02-26].https://arxiv.org/pdf/1611.06748.pdf.
                                    </a>
                                </li>
                                <li id="566">


                                    <a id="bibliography_33" title=" 时增林, 叶阳东, 吴云鹏, 等.基于序的空间金字塔池化网络的人群计数方法.自动化学报, 2016, 42 (6) :866-874. (SHI Z L, YE Y D, WU Y P, et al.Crowd Counting Using Rank-based Spatial Pyramid Pooling Network.Acta Automatica Sinica, 2016, 42 (6) :866-874.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201606007&amp;v=MjQ4MTZxQnRHRnJDVVJMT2VaZVJuRnl6aFU3cklLQ0xmWWJHNEg5Zk1xWTlGWTRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[33]</b>
                                         时增林, 叶阳东, 吴云鹏, 等.基于序的空间金字塔池化网络的人群计数方法.自动化学报, 2016, 42 (6) :866-874. (SHI Z L, YE Y D, WU Y P, et al.Crowd Counting Using Rank-based Spatial Pyramid Pooling Network.Acta Automatica Sinica, 2016, 42 (6) :866-874.) 
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(06),481-493 DOI:10.16451/j.cnki.issn1003-6059.201906001            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于最优输运的迁移学习</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%BD%A6%E4%BB%A4%E5%A4%AB&amp;code=42201394&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">车令夫</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%94%B0%E5%AE%87%E5%9D%A4&amp;code=41804985&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">田宇坤</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E6%B5%B7%E5%B9%B3&amp;code=41804947&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱海平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%86%9B%E5%B9%B3&amp;code=15179633&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张军平</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%8D%E6%97%A6%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2%E4%B8%8A%E6%B5%B7%E5%B8%82%E6%99%BA%E8%83%BD%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0075855&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">复旦大学计算机科学技术学院上海市智能信息处理重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>迁移学习的目的是将源领域学习的信息迁移至目标领域.针对目标领域为源领域的子流形的情形, 文中提出迁移学习算法 (Optlearn) .算法为源领域求取一组权重, 期望带权的源领域和目标领域尽可能相似.采用最优输运理论, 减小带权源领域和目标领域间的差异.在最优输运理论上, 改进对偶Sinkhorn散度, 适用于子流形情形, 同时提出快速计算算法.通过人群计数任务测试文中算法, 在避免对每个固定摄像头进行标注的巨大开销的同时, Optlearn获得较好的计数性能.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">迁移学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%80%E4%BC%98%E8%BE%93%E8%BF%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">最优输运;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E7%BE%A4%E8%AE%A1%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人群计数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%90%E6%B5%81%E5%BD%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">子流形;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    车令夫, 硕士研究生, 主要研究方向为机器学习、计算机视觉、智能交通系统、人群计数.E-mail:lfche16@fudan.edu.cn.;
                                </span>
                                <span>
                                    田宇坤, 硕士研究生, 主要研究方向为机器学习、计算机视觉、智能交通系统、人群计数.E-mail:yktian17@fudan.edu.cn.;
                                </span>
                                <span>
                                    朱海平, 博士研究生, 主要研究方向为机器学习、计算机视觉.E-mail:hpzhu14@fudan.edu.cn.;
                                </span>
                                <span>
                                    *张军平 (通讯作者) , 博士, 教授, 主要研究方向为机器学习、智能交通系统、图像处理.E-mail:jpzhang@fudan.edu.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.61673118);</span>
                                <span>上海浦江人才计划 (No.16PJD009) 资助;</span>
                    </p>
            </div>
                    <h1><b>Optimal Transport Based Transfer Learning</b></h1>
                    <h2>
                    <span>CHE Lingfu</span>
                    <span>TIAN Yukun</span>
                    <span>ZHU Haiping</span>
                    <span>ZHANG Junping</span>
            </h2>
                    <h2>
                    <span>Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The goal of transfer learning is to transfer information learned from the source domain to the target domain. A transfer learning method, Optlearn, is proposed for the case of the target domain being a sub-manifold of the source domain. The source domain is weighted to make the weighted source domain and the target domain as similar as possible. The optimal transport theory is employed to minimize the difference between the weighted source domain and the target domain. Furthermore, the dual-Sinkhorn divergence is improved to suit the sub-manifold. Meanwhile, a fast computing algorithm is proposed for Optlearn. The proposed algorithm is tested on the task of pedestrian counting. Experimental results show that Optlearn obtains good counting accuracy as well as avoids the high cost of labeling data for each fixed camera.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Transfer%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Transfer Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Optimal%20Transport&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Optimal Transport;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Pedestrian%20Counting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Pedestrian Counting;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sub%20Manifold&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sub Manifold;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHE Lingfu, master student. His research interests include machine learning, computer vision, intelligent transportation system and crowd counting.;
                                </span>
                                <span>
                                    TIAN Yukun, master student. His research interests include machine learning, computer vision, intelligent transportation system and crowd counting.;
                                </span>
                                <span>
                                    ZHU Haiping, Ph. D. candidate. His research interests include machine learning and computer vision.;
                                </span>
                                <span>
                                    ZHANG Junping (Corresponding author) , Ph. D., professor. His research interests include machine learning, intelligent transportation system and image processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.61673118);</span>
                                <span>Shanghai Pujiang Program (No.16PJD009);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="80">近年来, 随着机器学习算法的不断更迭, 训练数据的标注任务也在不断加重.迁移学习可以将与任务有一定关联的数据集信息迁移到该任务上, 减少对该任务标注数据的需求.其中, 目标领域 (目标任务对应的领域) 和源领域 (被迁移给目标任务提供信息的领域) 的具体关联形式是一个关键点.每个迁移学习方法都专注于处理特定的一类关联.文献<citation id="568" type="reference">[<a class="sup">1</a>]</citation>～文献<citation id="569" type="reference">[<a class="sup">3</a>]</citation>假设两个领域可以映射到同个子空间中.张倩等<citation id="570" type="reference"><link href="508" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>考虑有多个源领域且源、目标领域数据分布相似的情形.张景祥等<citation id="571" type="reference"><link href="510" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>假设每个领域都可以看成是共享和特有两个子空间的组合.Sugiyama等<citation id="572" type="reference"><link href="512" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>考虑两个领域处于同一空间中但具有不同的概率分布的情形.文献<citation id="573" type="reference">[<a class="sup">7</a>]</citation>～文献<citation id="574" type="reference">[<a class="sup">9</a>]</citation>假设能够找到一个从源领域到目标领域的映射.文献<citation id="575" type="reference">[<a class="sup">10</a>]</citation>和文献<citation id="576" type="reference">[<a class="sup">11</a>]</citation>考虑源领域和目标领域相差较大的情形, 并通过添加中间领域进行迁移.然而, 在现有的迁移学习方法中, 很少能够处理目标领域是源领域的“子流形”的情形.“子流形”是本文仿照“子集”构造的概念, 假设源领域和目标领域的离散数据都分别隐式地源于一个连续流形, 并且目标领域数据对应的流形全部落在源领域对应的流形内部.</p>
                </div>
                <div class="p1">
                    <p id="81">最优输运理论可以分析概率分布之间的关系, 并寻找一种输运方案.输运方案指把两个分布中的一个转换成另一个的方案, 最优输运需要在两分布间所有可能的输运方案中寻找代价最小的方案.最优输运理论可以推导Wasserstein距离, 是概率分布间良定义的距离, 其中一个应用是在生成对抗网络 (Generative Adversarial Networks, GAN) 领域中.文献<citation id="577" type="reference">[<a class="sup">12</a>]</citation>和文献<citation id="578" type="reference">[<a class="sup">13</a>]</citation>利用GAN构建Wasserstein生成对抗网络 (WGAN) .</p>
                </div>
                <div class="p1">
                    <p id="82">最优输运的计算十分耗时.因此, 文献<citation id="579" type="reference">[<a class="sup">14</a>]</citation>和文献<citation id="580" type="reference">[<a class="sup">15</a>]</citation>尝试对最优输运问题进行变化、松弛, 给出较快速的算法.基于这些工作, Courty等<citation id="581" type="reference"><link href="518" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出迁移学习算法, Zhao等<citation id="582" type="reference"><link href="532" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>在标签分布学习上进行应用, Sanjabi等<citation id="583" type="reference"><link href="534" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>改进WGAN.然而, 目前已知的求解最优输运问题 (或是变化后的最优输运问题) 的方法都是迭代算法, 在实际应用时, 无法进一步求得算法得到的输运方案关于实际任务参数的梯度.</p>
                </div>
                <div class="p1">
                    <p id="83">现有的人群计数方法主要分为3类:基于行人检测的方法、基于低维特征回归的方法和基于深度卷积神经网络的方法.基于行人检测的方法<citation id="585" type="reference"><link href="536" rel="bibliography" /><link href="538" rel="bibliography" /><link href="540" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>对图像进行扫描, 识别其中每个行人, 在简单场景下可以快速、准确地给出人群计数结果, 但实际任务中人群的遮挡和叠盖极大影响对行人的识别, 人数较多时, 计算量消耗较高.Chan等<citation id="584" type="reference"><link href="542" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>提出基于低维特征回归的方法, 后续文献<citation id="586" type="reference"><link href="544" rel="bibliography" /><link href="546" rel="bibliography" /><link href="548" rel="bibliography" /><link href="550" rel="bibliography" /><link href="552" rel="bibliography" /><link href="554" rel="bibliography" /><link href="556" rel="bibliography" /><sup>[<a class="sup">22</a>,<a class="sup">23</a>,<a class="sup">24</a>,<a class="sup">25</a>,<a class="sup">26</a>,<a class="sup">27</a>,<a class="sup">28</a>]</sup></citation>延续其思路, 直接从图像中提取低维特征, 使用低维特征和人数标签信息训练回归模型.利用来自固定摄像头的先验信息, 受遮挡和互相叠盖的影响较小, 计算量也不受人数影响.不足之处在于需要为每个摄像头单独训练一个回归模型, 因此需要为每个摄像头标注数据, 人力消耗较大.基于深度卷积神经网络的方法<citation id="587" type="reference"><link href="558" rel="bibliography" /><link href="560" rel="bibliography" /><link href="562" rel="bibliography" /><link href="564" rel="bibliography" /><link href="566" rel="bibliography" /><sup>[<a class="sup">29</a>,<a class="sup">30</a>,<a class="sup">31</a>,<a class="sup">32</a>,<a class="sup">33</a>]</sup></citation>直接训练一个端到端的神经网络, 预测每个像素上的人群密度.由于深度网络的高拟合能力, 该方法比前两种方法效果更好.然而, 基于深度卷积神经网络的方法很少利用固定摄像头的先验信息.针对第2类方法中的数据标注问题, 本文设计迁移训练思路:对任一固定摄像头, 其标注信息可以由某个公共数据集向其迁移的信息替代.若公共数据集大致包含所有可能的人群信息, 对于每个目标摄像头, 所有可能拍摄到的人群都包含在此公共数据集中, 符合“子流形”情形.</p>
                </div>
                <div class="p1">
                    <p id="84">本文提出一个针对目标领域是源领域的“子流形”的迁移算法——基于最优输运的迁移学习算法 (Optimal Transport Based Transfer Learning, Optlearn) .对最优输运理论中的对偶Sinkhorn散度进行一定的改进, 适用于“子流形”, 并给出快速求解的算法.本文给出能够避免对每个固定摄像头都进行数据标注的人群计数方案.</p>
                </div>
                <h3 id="85" name="85" class="anchor-tag">1 最优输运</h3>
                <h4 class="anchor-tag" id="86" name="86"><b>1.1 Wasserstein</b>距离</h4>
                <div class="p1">
                    <p id="87">约定使用</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mi>δ</mi></mstyle><msub><mrow></mrow><mrow><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></msub><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munderover><mi>δ</mi></mstyle><msub><mrow></mrow><mrow><mi>x</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></msub><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">表示两个不同的离散分布.其中:离散点<i>x</i><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>和<i>x</i><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>在同一度量空间中;<i>δ</i>为指示函数, </p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msub><mrow></mrow><mrow><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>x</mi><mo>=</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mi>x</mi><mo>≠</mo><mi>x</mi><msub><mrow></mrow><mn>0</mn></msub></mtd></mtr></mtable></mrow></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">为了方便理解, 这里将<b><i>P</i></b><sub><i>s</i></sub> (<b><i>P</i></b><sub><i>t</i></sub>同理) 看成是货物的分布, <i>x</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>为货物仓库位置, <i>p</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>为该仓库的储量, 总货物储量为1.给定单位输运代价函数<i>Cost</i> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>) , 表示从位置<i>x</i><sub>1</sub>向位置<i>x</i><sub>2</sub>输运单位质量货物花费的代价.可以得到单位输运代价矩阵<b><i>C</i></b>∈<b>R</b><sup><i>n</i><sub><i>s</i></sub>×<i>n</i><sub><i>t</i></sub></sup>, 其中, <i>c</i><sub><i>ij</i></sub>=<i>Cost</i> (<i>x</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>, <i>x</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>) 表示从<i>x</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>向<i>x</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>输运单位质量货物花费的代价.最优输运问题考虑如何通过输运将货物分布由<b><i>P</i></b><sub><i>s</i></sub>变为<b><i>P</i></b><sub><i>t</i></sub>, 使输运的总代价最小.</p>
                </div>
                <div class="p1">
                    <p id="100">为了将最优输运问题具体化, 这里约定使用矩阵<i>γ</i>∈<b>R</b><sup><i>n</i><sub><i>s</i></sub>×<i>n</i><sub><i>t</i></sub></sup>表示输运方案, <i>γ</i><sub><i>ij</i></sub>表示从<i>x</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>向<i>x</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>输运的货物的总量.输运方案<i>γ</i>需要满足</p>
                </div>
                <div class="p1">
                    <p id="103"><i>γ</i><b>1</b><sub><i>n</i><sub><i>t</i></sub></sub>=<b><i>P</i></b><sub><i>s</i></sub>, <i>γ</i><sup>T</sup><b>1</b><sub><i>n</i><sub><i>s</i></sub></sub>=<b><i>P</i></b><sub><i>t</i></sub>, <i>γ</i>≥<b>0</b>.</p>
                </div>
                <div class="p1">
                    <p id="104">所以, <b><i>P</i></b><sub><i>s</i></sub>到<b><i>P</i></b><sub><i>t</i></sub>的所有可能的输运方案构成的集合为</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">需要注意的是, <i>γ</i>的所有元素之和必定等于总货物量, 即是1, 因此<i>γ</i>可以看作是一个离散分布.</p>
                </div>
                <div class="p1">
                    <p id="107">基于输运方案<i>γ</i>的定义, <i>γ</i>对应的总输运代价可以定义为</p>
                </div>
                <div class="p1">
                    <p id="108"><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munderover><mi>C</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="110">为了简便起见, 后文中使用<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mrow></mrow></mstyle></mrow></math></mathml>·代替<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munderover><mrow></mrow></mstyle></mrow></math></mathml>·.</p>
                </div>
                <div class="p1">
                    <p id="113">最优输运是在所有可能的输运方案<i>Γ</i> (<b><i>P</i></b><sub><i>s</i></sub>, <b><i>P</i></b><sub><i>t</i></sub>) 中找到总输运代价最小的方案<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover></math></mathml>:</p>
                </div>
                <div class="p1">
                    <p id="115"><mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="117">若单位输运代价函数<i>Cost</i> (<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>) 为一个距离函数, 可证明最优输运代价是分布间的良定义的距离, 即为Wasserstein距离, 数学形式如下:</p>
                </div>
                <div class="p1">
                    <p id="118"><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>.</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>1.2</b> 对偶<b>Sinkhorn</b>散度</h4>
                <div class="p1">
                    <p id="121">尽管Wasserstein距离在数学上是良定义的, 但是, 在目标最优输运问题中有过多的不等式约束, 导致求解耗时巨大.另外, 由于最后求解的输运方案过于稀疏, 导致其易受噪声影响, 对于高维空间的情形不能有效反映分布间的远近.</p>
                </div>
                <div class="p1">
                    <p id="122">为了解决上述问题, Cuturi等<citation id="588" type="reference"><link href="528" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出正则化形式的最优输运代价:</p>
                </div>
                <div class="p1">
                    <p id="123"><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="125"><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mi>log</mi></mrow><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>是个负信息熵项, 可以避免最优输运方案中有过多的0, 同时, 这一项使整个损失函数具有凸性.这个凸性是Cuturi等<citation id="589" type="reference"><link href="528" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出的快速求解算法能成立的关键因素.类似Wasserstein距离, 该输运代价的最小值同样可以用于衡量两个概率分布之间的远近, 尽管其不再符合距离的数学定义.这个最小值, 称为对偶Sinkhorn散度.对偶Sinkhorn散度的数学形式为</p>
                </div>
                <div class="p1">
                    <p id="127"><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msubsup><mrow></mrow><mi>c</mi><mi>λ</mi></msubsup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>c</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>.      (1) </p>
                </div>
                <div class="p1">
                    <p id="129">Cuturi等<citation id="590" type="reference"><link href="528" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>给出一种有效的求解方法处理上述最小化问题, 具体求解过程如下.</p>
                </div>
                <div class="p1">
                    <p id="130">对于目标最小化问题 (1) , 首先忽略约束<i>γ</i>∈<i>Γ</i> (<b><i>P</i></b><sub><i>s</i></sub>, <b><i>P</i></b><sub><i>t</i></sub>) 中<i>γ</i>≥<b>0</b>这一不等式约束, 仅考虑<i>γ</i><b>1</b><sub><i>n</i><sub><i>t</i></sub></sub>=<b><i>P</i></b><sub><i>s</i></sub>和<i>γ</i><sup>T</sup><b>1</b><sub><i>n</i><sub><i>s</i></sub></sub>=<b><i>P</i></b><sub><i>t</i></sub>这两个等式约束.忽略不等式约束的最小化问题的拉格朗日函数为</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>L</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>+</mo><mi mathvariant="bold-italic">α</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi mathvariant="bold-italic">β</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="132">其中<i>α</i>、 <i>β</i>为拉格朗日乘子向量.</p>
                </div>
                <div class="p1">
                    <p id="133">接下来, 由∂<i>L</i>/∂<i>γ</i><sub><i>ij</i></sub>=0的条件推出</p>
                </div>
                <div class="p1">
                    <p id="134" class="code-formula">
                        <mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>-</mo><mi>λ</mi><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>⋅</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mi>λ</mi><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>-</mo><mi>λ</mi><mi>β</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="135">进一步, 可得<i>γ</i>满足</p>
                </div>
                <div class="area_img" id="136">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="138">由上述形式可以发现, <i>γ</i>≥<b>0</b>这个不等式约束必定被满足, 因此不再需要考虑.所以, 上述操作有效避开不等式约束<i>γ</i>≥<b>0</b>.最后, 只需要把上述形式代入等式约束<i>γ</i><b>1</b><sub><i>n</i><sub><i>t</i></sub></sub>=<b><i>P</i></b><sub><i>s</i></sub>和<i>γ</i><sup>T</sup><b>1</b><sub><i>n</i><sub><i>s</i></sub></sub>=<b><i>P</i></b><sub><i>t</i></sub>以求解<b><i>u</i></b>和<b><i>v</i></b>即可.Cuturi等<citation id="591" type="reference"><link href="528" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>给出Sinkhorn不动点迭代法以求解</p>
                </div>
                <div class="p1">
                    <p id="139"><mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo>, </mo><mi mathvariant="bold-italic">v</mi><mo stretchy="false">) </mo><mo>←</mo><mo stretchy="false"> (</mo><mfrac><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>.</mo></mrow><mrow><mi mathvariant="bold-italic">Κ</mi><mi mathvariant="bold-italic">v</mi></mrow></mfrac><mo>, </mo><mfrac><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>.</mo></mrow><mrow><mi mathvariant="bold-italic">Κ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">u</mi></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <h3 id="141" name="141" class="anchor-tag">2 基于最优输运的迁移学习</h3>
                <h4 class="anchor-tag" id="142" name="142"><b>2.1</b> 算法框架</h4>
                <div class="p1">
                    <p id="143">Optlearn最基本的假设为目标领域是源领域的“子流形”.Optlearn给源领域上每个数据一个权重, 并将带权的源领域看成一个离散分布.同时, 算法把目标领域也看成是一个离散分布 (每个数据点具有相同概率) .Optlearn的目标可以定为:寻找一组源领域权重, 使两个分布尽可能相近.</p>
                </div>
                <div class="p1">
                    <p id="144">为了方便后续讨论, 进行一些记号约定.本文使用<mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo stretchy="false">|</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">}</mo></mrow></math></mathml>表示源领域, <mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">|</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">}</mo></mrow></math></mathml>表示目标领域, 其中, <i>x</i><mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>、<i>x</i><mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup></mrow></math></mathml>分别表示源领域和目标领域中的数据点, <i>n</i><sub><i>s</i></sub>、<i>n</i><sub><i>t</i></sub>表示源领域和目标领域中数据点个数.<b><i>C</i></b>∈<b>R</b><sup><i>n</i><sub><i>s</i></sub>×<i>n</i><sub><i>t</i></sub></sup>表示<i>X</i><sub><i>s</i></sub>、<i>X</i><sub><i>t</i></sub>间的距离矩阵, <i>C</i><sub><i>ij</i></sub>=<i>distance</i> (<i>x</i><mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>, <i>x</i><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>) .</p>
                </div>
                <div class="p1">
                    <p id="151">Optlearn将带权源领域和目标领域看作两个离散分布.目标领域<i>X</i><sub><i>t</i></sub>可以看作是以所有数据点构成集合为支撑的均匀离散分布</p>
                </div>
                <div class="p1">
                    <p id="152" class="code-formula">
                        <mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munderover><mrow><mfrac><mrow><mi>δ</mi><msub><mrow></mrow><mrow><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup></mrow></msub></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac></mrow></mstyle><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="153">源领域<i>X</i><sub><i>s</i></sub>加上一组权重{<b><i>p</i></b><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>}<sub><i>i</i></sub> (<b><i>p</i></b><mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>为数据<i>x</i><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>对应的权重, <mathml id="157"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi mathvariant="bold-italic">p</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>=</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>可以看作是以所有数据点为支撑的离散分布</p>
                </div>
                <div class="p1">
                    <p id="158" class="code-formula">
                        <mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mi>δ</mi></mstyle><msub><mrow></mrow><mrow><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></msub><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="159">每组可能的权重都对应一个离散分布.在之后的讨论中, 本文使用<b>P</b><sub><i>s</i></sub>表示所有可能的带权源领域离散分布:</p>
                </div>
                <div class="p1">
                    <p id="160"><mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">Ρ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Ρ</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mi>δ</mi></mstyle><msub><mrow></mrow><mrow><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></msub><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo stretchy="false">}</mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="162">Optlearn在<b>P</b><sub><i>s</i></sub>中找到一个与目标领域<b><i>P</i></b><sub><i>t</i></sub>差异尽可能小的分布<mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Ρ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>s</mi></msub></mrow></math></mathml>.于是, Optlearn的最根本的目标函数可以写为</p>
                </div>
                <div class="p1">
                    <p id="164"><mathml id="165"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>Ρ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mspace width="0.25em" /><mi>D</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>.      (3) </p>
                </div>
                <div class="p1">
                    <p id="166">其中<i>D</i> (·, ·) 为分布之间的散度函数.</p>
                </div>
                <div class="p1">
                    <p id="167">考虑到目标领域是源领域的“子流形”, 本文希望算法得出的源领域权重{<b><i>p</i></b><mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>}<sub><i>i</i></sub>是稀疏的, 即对于源领域中位于目标领域对应的子流形之外的数据, 对应的权重应为0.这种稀疏性可使后续算法更少地受到噪音影响, 大幅加速后续算法的训练过程.</p>
                </div>
                <h4 class="anchor-tag" id="169" name="169"><b>2.2 Wasserstein</b>距离和对偶<b>Sinkhorn</b>散度情形的推导</h4>
                <div class="p1">
                    <p id="171">一个可行的<i>D</i> (·, ·) 的选项是Wasserstein距离.如果采用Wasserstein距离, 目标函数 (3) 可改写为</p>
                </div>
                <div class="p1">
                    <p id="172"><mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Ρ</mi></mstyle><mo>︿</mo></mover></mrow><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="174">其中</p>
                </div>
                <div class="p1">
                    <p id="175" class="code-formula">
                        <mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="176">为最优输运问题中对输运方案的限制条件, <i>γ</i>≥<b>0</b>为矩阵<i>γ</i>中所有元素都非负.</p>
                </div>
                <div class="p1">
                    <p id="177">对于上述目标函数, 最小值点 (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) 可以直接构造如下:</p>
                </div>
                <div class="p1">
                    <p id="178"><mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mi>δ</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mi>i</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">Ρ</mi><msubsup><mrow></mrow><mi>s</mi><mo>*</mo></msubsup><mo>=</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mo>*</mo></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="180">其中<mathml id="181"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>i</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>i</mi></munder><mspace width="0.25em" /><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>.对最小值点的证明如下.</p>
                </div>
                <div class="p1">
                    <p id="182"><b>证明</b> 首先, 易验证<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>∈<b><i>P</i></b><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>∈<i>Γ</i> (<b><i>P</i></b><sub><i>s</i></sub>, <b><i>P</i></b><sub><i>t</i></sub>) , (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) 为目标函数定义域的一个合法取值.故只需要证明 (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) 的确为目标函数的最小值点.</p>
                </div>
                <div class="p1">
                    <p id="183">从<i>i</i><sub><i>j</i></sub>的定义可知<i>C</i><sub><i>ij</i></sub>≥<i>C</i><sub><i>i</i><sub><i>j</i></sub><i>j</i></sub>, 所以, 对任意一个合法的 (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) , </p>
                </div>
                <div class="area_img" id="184">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_18400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="186">成立.由<i>γ</i><sup>*</sup><sub><i>ij</i></sub>的定义, </p>
                </div>
                <div class="p1">
                    <p id="187"><mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mi>δ</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mi>i</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mo stretchy="false"> (</mo></mstyle><mi>C</mi><msub><mrow></mrow><mrow><mrow><mi>i</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo>⋅</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="189">成立.联立式 (4) 和式 (5) , 可推出, 对任何合法的 (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) , </p>
                </div>
                <div class="p1">
                    <p id="190" class="code-formula">
                        <mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>≥</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="191">成立.所以 (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) 的确是目标函数的最小值点.</p>
                </div>
                <div class="p1">
                    <p id="192">上述结果 (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) 的不足在于稀疏性过强.输运方案<i>γ</i><sup>*</sup><sub><i>ij</i></sub>本质上是目标领域的每个数据点向距其最近的一个源领域的数据点迁移<mathml id="193"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac></mrow></math></mathml>的概率.于是, 算法中最多<i>n</i><sub><i>t</i></sub>个源领域的数据点会得到正权重.故用Wasserstein距离作为散度函数<i>D</i> (·, ·) 不可行.</p>
                </div>
                <div class="p1">
                    <p id="194">虽然Wasserstein距离在本问题中不适用, 但是上述推导说明采用类似最优输运问题推导的损失函数是有能力直接得到稀疏的权重, 只是直接采用Wasserstein距离会进入过度稀疏的极端情况.</p>
                </div>
                <div class="p1">
                    <p id="195">另一个可行的散度函数<i>D</i> (·, ·) 为对偶Sin- khorn散度.相比Wasserstein距离, 对偶Sinkhorn散度能克服输运方案过于稀疏的问题, 故使用对偶Sinkhorn散度作为散度函数<i>D</i> (·, ·) , 能够解决之前的过度稀疏的问题.</p>
                </div>
                <div class="p1">
                    <p id="196">采用对偶Sinkhorn散度, 目标函数 (3) 变形为</p>
                </div>
                <div class="area_img" id="197">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_19700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="199">为了分析目标函数 (6) , 本文提出引理 1.</p>
                </div>
                <div class="p1">
                    <p id="200"><b>引理1</b> 对于任意连续凸函数<i>f</i>, </p>
                </div>
                <div class="p1">
                    <p id="201"><mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="203">成立, 并且公式的左侧和右侧具有相同的最小值.</p>
                </div>
                <div class="p1">
                    <p id="204"><b>证明</b> 很明显</p>
                </div>
                <div class="p1">
                    <p id="205" class="code-formula">
                        <mathml id="205"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr><mtr><mtd><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="206">都是凸闭集, 因此<mathml id="207"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo></mrow></math></mathml>和<mathml id="208"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo></mrow></math></mathml>都存在.</p>
                </div>
                <div class="p1">
                    <p id="209">注意到</p>
                </div>
                <div class="p1">
                    <p id="210" class="code-formula">
                        <mathml id="210"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo><mo>⊆</mo></mtd></mtr><mtr><mtd><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="211">于是, f (<i>γ</i>) 在<i>Γ</i> (<b><i>P</i></b><sub><i>s</i></sub>, <b><i>P</i></b><sub><i>t</i></sub>) 中的最小值大于等于其在<mathml id="212"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo></mrow></math></mathml>中的最小值, 即</p>
                </div>
                <div class="p1">
                    <p id="213"><mathml id="214"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo><mo>≥</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munder></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="215">进一步可以推知</p>
                </div>
                <div class="p1">
                    <p id="216"><mathml id="217"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>inf</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mspace width="0.25em" /><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>≥</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munder></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo></mrow></math></mathml>,      (8) </p>
                </div>
                <div class="p1">
                    <p id="218">公式左侧使用<mathml id="219"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>inf</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder></mrow></math></mathml>而不是<mathml id="220"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder></mrow></math></mathml>是因为其最小值点存在性尚未证明.</p>
                </div>
                <div class="p1">
                    <p id="221">对于目标公式 (7) 右侧的极值点<i>γ</i><sup>*</sup>, 构造</p>
                </div>
                <div class="p1">
                    <p id="222"><b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>= (<i>γ</i><sup>*</sup><b>1</b><sub><i>n</i><sub><i>t</i></sub></sub>) <sup>T</sup>.</p>
                </div>
                <div class="p1">
                    <p id="223">易证<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>∈<b><i>P</i></b><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>∈<i>Γ</i> (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <b><i>P</i></b><sub><i>t</i></sub>) , 于是</p>
                </div>
                <div class="area_img" id="224">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="226">成立.</p>
                </div>
                <div class="p1">
                    <p id="227">综合式 (8) 和式 (9) 可知</p>
                </div>
                <div class="p1">
                    <p id="228"><mathml id="229"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mspace width="0.25em" /><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munder></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo></mrow></math></mathml>.      (10) </p>
                </div>
                <div class="p1">
                    <p id="230">同时, (<b><i>P</i></b><sup>*</sup><sub><i>s</i></sub>, <i>γ</i><sup>*</sup>) 为目标公式 (7) 左侧的最小值点.式 (10) 左侧使用<mathml id="231"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder></mrow></math></mathml>是因为已经确定有至少一个最小值点.</p>
                </div>
                <div class="p1">
                    <p id="232">设式 (7) 左侧的一个最小值点为 (<b><i>P</i></b><mathml id="233"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mrow><mo>*</mo><mo>*</mo></mrow></msubsup></mrow></math></mathml>, <i>γ</i><sup>**</sup>) , 下面证明<i>γ</i><sup>**</sup>为式 (7) 右侧的最小值点.</p>
                </div>
                <div class="p1">
                    <p id="234">很显然, <i>γ</i><sup>**</sup>为式 (7) 右侧的一个合法取值:</p>
                </div>
                <div class="p1">
                    <p id="235"><mathml id="236"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mrow><mo>*</mo><mo>*</mo></mrow></msup><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msubsup><mrow></mrow><mi>s</mi><mrow><mo>*</mo><mo>*</mo></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>⊆</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="237">于是</p>
                </div>
                <div class="p1">
                    <p id="238" class="code-formula">
                        <mathml id="238"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mrow><mo>*</mo><mo>*</mo></mrow></msup><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mspace width="0.25em" /><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munder></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn></mrow></munder><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="239">成立.故<i>γ</i><sup>**</sup>的确是式 (7) 右侧的最小值点.</p>
                </div>
                <div class="p1">
                    <p id="240">综上所述, 可知<mathml id="241"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Ρ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>为式 (7) 左侧的最小值点当且仅当<mathml id="242"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover></math></mathml>为式 (7) 右侧的最小值点.需要注意的是, <i>f</i>为凸函数, <mathml id="243"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">γ</mi><mo>≥</mo><mn>0</mn><mo stretchy="false">}</mo></mrow></math></mathml>为凸闭集, 故式 (7) 右侧有唯一最小值点.进一步, 式 (7) 左侧也只有唯一最小值点.因此, 使用<mathml id="244"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder></mrow></math></mathml>这一符号合理.</p>
                </div>
                <div class="p1">
                    <p id="245">由引理1可知, 对目标函数的求解可变换为对下述问题的求解:</p>
                </div>
                <div class="area_img" id="246">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_24600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="248">本文仿照对偶Sinkhorn散度的求解方法, 解出式 (11) 中<mathml id="249"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover></math></mathml>的结果:</p>
                </div>
                <div class="p1">
                    <p id="250"><mathml id="251"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>γ</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mo stretchy="false"> (</mo><mi>λ</mi><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mo>-</mo><mo stretchy="false"> (</mo><mi>λ</mi><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="252">求解过程如下.</p>
                </div>
                <div class="p1">
                    <p id="253">为了求解式 (11) 中的<mathml id="254"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover></math></mathml>, 仿照对偶Sinkhorn散度的求解方法, 先忽略不等式约束, 考虑如下的一个最小化问题:</p>
                </div>
                <div class="p1">
                    <p id="255"><mathml id="256"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mo>*</mo></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munder><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>,      (12) </p>
                </div>
                <div class="p1">
                    <p id="257">其拉格朗日函数为</p>
                </div>
                <div class="p1">
                    <p id="258"><mathml id="259"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="260">考虑偏导数, 有</p>
                </div>
                <div class="p1">
                    <p id="261" class="code-formula">
                        <mathml id="261"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mo>=</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mo stretchy="false"> (</mo><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo>+</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mn>0</mn><mo>, </mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mi>L</mi></mrow><mrow><mo>∂</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>l</mi><mi>j</mi></mrow></msub><mo>-</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo>=</mo><mn>0</mn><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="262">联立上述两式, 可解出</p>
                </div>
                <div class="p1">
                    <p id="263"><mathml id="264"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mo>-</mo><mo stretchy="false"> (</mo><mi>λ</mi><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mo>-</mo><mo stretchy="false"> (</mo><mi>λ</mi><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="265">需要注意的是, 可以验证</p>
                </div>
                <div class="p1">
                    <p id="266"><i>γ</i><sup>*</sup>∈{<i>γ</i><sup>T</sup><b>1</b><sub><i>n</i><sub><i>s</i></sub></sub>=<b><i>P</i></b><sub><i>t</i></sub>, <i>γ</i>≥<b>0</b>}⊆{<i>γ</i><sup>T</sup><b>1</b><sub><i>n</i><sub><i>s</i></sub></sub>=<b><i>P</i></b><sub><i>t</i></sub>}, </p>
                </div>
                <div class="p1">
                    <p id="267">故<i>γ</i><sup>*</sup>也是式 (12) 在{<i>γ</i><sup>T</sup><b>1</b><sub><i>n</i><sub><i>s</i></sub></sub>=<b><i>P</i></b><sub><i>t</i></sub>, <i>γ</i>≥<b>0</b>}上的最小值点.故为式 (11) 的最小值点, 所以<mathml id="268"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover><mo>=</mo><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mo>*</mo></msup><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="269">进一步, <mathml id="270"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Ρ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>s</mi></msub></mrow></math></mathml>的结果为</p>
                </div>
                <div class="p1">
                    <p id="271"><mathml id="272"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>p</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mo>-</mo><mo stretchy="false"> (</mo><mi>λ</mi><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mo>-</mo><mo stretchy="false"> (</mo><mi>λ</mi><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="273">显然, <mathml id="274"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Ρ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>s</mi></msub></mrow></math></mathml>的所有权重都严格大于0, 这与本文期望的稀疏性相违背.输运方案<i>γ</i>可以看成是<i>X</i><sub><i>s</i></sub>×<i>X</i><sub><i>t</i></sub>上的离散分布, 而对偶Sinkhorn散度引入的负信息熵项, 有使这个分布更平均的作用.这改善直接采用Wasserstein距离时过稀疏的问题, 但又导致非稀疏的不足.因此, 本文推测, 如果能找到一个介于Wasserstein距离和对偶Sinkhorn散度间的折衷方案, 可能就能达到研究的目标.</p>
                </div>
                <h4 class="anchor-tag" id="275" name="275"><b>2.3 <i>l</i></b><sub><b>2</b></sub>正则的<b>Wasserstein</b>距离</h4>
                <div class="p1">
                    <p id="276">对于对偶Sinkhorn散度, 负信息熵项的凸性是能使分布更平均的关键因素.因为凸性加上<mathml id="277"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>的条件, 意味着可用Jensen不等式证明<mathml id="278"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>的最小值点为<mathml id="279"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="280">另一方面, 通过计算偏导数:</p>
                </div>
                <div class="p1">
                    <p id="281"><mathml id="282"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo>∂</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mo>∂</mo><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mo>=</mo><mn>1</mn><mo>+</mo><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="283">可以发现在<i>γ</i><sub><i>ij</i></sub>=0时, 对应的偏导数为-∞.这表明以对偶Sinkhorn散度为散度函数<i>D</i> (·, ·) 时, 解出的最小值点对应的<i>γ</i><sub><i>ij</i></sub>必定严格为正, 进而导致2.2节中对偶Sinkhorn散度得到的结果非稀疏的现象.</p>
                </div>
                <div class="p1">
                    <p id="284">受上述两个分析的启发, 本文提出使用<i>l</i><sub>2</sub>正则项代替对偶Sinkhorn散度中负信息熵项的方案.同信息熵正则项一样, <i>l</i><sub>2</sub>正则项也有凸性, 但其在0点的偏导数有限, 故其较好地符合上述两个分析所提的关键点.</p>
                </div>
                <div class="p1">
                    <p id="285">于是, 目标函数 (3) 可写为</p>
                </div>
                <div class="p1">
                    <p id="286"><mathml id="287"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Ρ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>γ</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></math></mathml>.      (13) </p>
                </div>
                <div class="p1">
                    <p id="288">利用引理1, 求解目标函数 (13) 的问题可转化为</p>
                </div>
                <div class="area_img" id="289">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_28900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="291">若要求解<mathml id="292"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">γ</mi></mstyle><mo>︿</mo></mover><mo>, </mo></mrow></math></mathml>直接采用2.2节的对偶Sinkhorn散度形式的求解方法并不可行.求解方法的关键点在于绕开不等式约束, 即先忽略不等式约束<i>γ</i>≥<b>0</b> (相当于先扩大定义域范围) , 再利用拉格朗日乘子法进行求解, 最后说明得到的最小值点满足不等式约束<i>γ</i>≥<b>0</b>.但对于式 (14) , 若通过同样的思路求解, 解出的结果有可能不满足<i>γ</i>≥<b>0</b>.</p>
                </div>
                <div class="p1">
                    <p id="293">为了解决这一问题, 本文构造迭代式的方法.首先, 需要忽略不等式约束<i>γ</i>≥<b>0</b>.然后, 迭代进行以下步骤:1) 使用拉格朗日乘子法求最小值点;2) 找到求出的解中不满足的不等式约束;3) 将这些未被满足的不等式约束转换成等式约束并将它们加到目标函数中.当不再有不满足的不等式约束时, 上述迭代过程终止.</p>
                </div>
                <div class="p1">
                    <p id="294">为了便于理解, 上述思路整理在算法1中.算法中<i>k</i>表示迭代次数, <i>A</i><sub><i>k</i></sub>表示所有在第<i>k</i>次之前的迭代中发现的所有不满足约束条件<i>γ</i><sub><i>ij</i></sub>≥0的坐标 (<i>i</i>, <i>j</i>) 构成的集合.</p>
                </div>
                <div class="p1">
                    <p id="295"><b>算法1</b> Optlearn</p>
                </div>
                <div class="area_img" id="501">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201906001_50100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="501">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201906001_50101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="303">在算法1中, 本文跳过对下述优化问题的求解:</p>
                </div>
                <div class="p1">
                    <p id="304"><mathml id="305"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mi>k</mi></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munder></mrow></mstyle><mrow><mo>∀</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder></mrow></mstyle><mrow><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></munder><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">) </mo></mrow></math></mathml>.      (15) </p>
                </div>
                <div class="p1">
                    <p id="306">上式可通过拉格朗日乘子法求解.约定</p>
                </div>
                <div class="p1">
                    <p id="307" class="code-formula">
                        <mathml id="307"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∉</mo><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">}</mo><mo>, </mo><mspace width="0.25em" /><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><mi>i</mi><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">}</mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="308">解可写为</p>
                </div>
                <div class="p1">
                    <p id="309"><mathml id="310"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup><mo>=</mo><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">|</mo></mrow></mfrac><mo stretchy="false"> (</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>l</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="311">求解过程如下.</p>
                </div>
                <div class="p1">
                    <p id="312">对于∀ (<i>i</i>, <i>j</i>) ∈<i>A</i><sub><i>k</i></sub>, 将式 (15) 中的<i>γ</i><sub><i>ij</i></sub>用0代入, 可得</p>
                </div>
                <div class="p1">
                    <p id="313"><mathml id="314"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">γ</mi><msup><mrow></mrow><mi>k</mi></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac></mrow></munder><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">) </mo></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="315">其拉格朗日函数</p>
                </div>
                <div class="p1">
                    <p id="316"><mathml id="317"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></munder><mo stretchy="false"> (</mo></mstyle><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mi>λ</mi></mfrac><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">) </mo><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="318">对上式求偏导, 有</p>
                </div>
                <div class="area_img" id="319">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_31900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="321">由式 (16) 知</p>
                </div>
                <div class="p1">
                    <p id="322"><mathml id="323"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>.      (17) </p>
                </div>
                <div class="p1">
                    <p id="324">联立式 (16) , 有</p>
                </div>
                <div class="p1">
                    <p id="325"><mathml id="326"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>l</mi><mi>j</mi></mrow></msub><mo>+</mo><mo stretchy="false">|</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">|</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>γ</mi></mstyle><msub><mrow></mrow><mrow><mi>l</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="327">进一步可推得</p>
                </div>
                <div class="p1">
                    <p id="328"><mathml id="329"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mi>λ</mi><mn>2</mn></mfrac><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">|</mo></mrow></mfrac><mo stretchy="false"> (</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>l</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="330">将上式代入式 (17) , 有</p>
                </div>
                <div class="p1">
                    <p id="331"><mathml id="332"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">|</mo></mrow></mfrac><mo stretchy="false"> (</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>l</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="333">此即为<i>γ</i><sup><i>k</i></sup>的解.</p>
                </div>
                <div class="p1">
                    <p id="334">Optlearn的一大优点是运算速度较快, 因为它并不是基于梯度的迭代算法, 而是一个接近求闭式解的算法.尽管Optlearn需要迭代, 但在实际实验中, 迭代次数都不多于20.</p>
                </div>
                <div class="p1">
                    <p id="335">由算法过程可知, 只要迭代次数多于1, 得到的输运方案<i>γ</i>一定稀疏, 而这会进一步使<mathml id="336"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Ρ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mover accent="true"><mi mathvariant="bold-italic">γ</mi><mo>^</mo></mover><mn>1</mn><msub><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub></mrow></math></mathml>稀疏</p>
                </div>
                <div class="p1">
                    <p id="337">最后, 本文给出引理2, 说明Optlearn的正确性.</p>
                </div>
                <div class="p1">
                    <p id="338"><b>引理2</b> 算法1一定能够在有限次迭代内收敛, 一定能够收敛到目标函数 (13) 的最小值点.</p>
                </div>
                <div class="p1">
                    <p id="339"><b>证明</b> 在本次证明中, 约定使用<i>γ</i><mathml id="340"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup></mrow></math></mathml>和<i>α</i><mathml id="341"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>k</mi></msubsup></mrow></math></mathml>表示第<i>k</i>次迭代中<i>γ</i>和<i>α</i>的结果.</p>
                </div>
                <div class="p1">
                    <p id="342">首先需要证明算法1不会陷入无限循环.这里使用反证法, 假设算法1可能会陷入无限循环.</p>
                </div>
                <div class="p1">
                    <p id="343">根据<i>A</i><sub><i>k</i></sub>的定义, 可知<i>A</i><sub><i>k</i>+1</sub>⊇<i>A</i><sub><i>k</i></sub>.又根据循环终止条件和无限循环的假设, 能够推断<i>A</i><sub><i>k</i>+1</sub>≠<i>A</i><sub><i>k</i></sub>.故<i>A</i><sub><i>k</i>+1</sub>⊉<i>A</i><sub><i>k</i></sub>.进一步, 由数学归纳法, 可推知<mathml id="344"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>∀</mo><mi>k</mi><mo>, </mo><mo stretchy="false">|</mo><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mo>≥</mo><mi>k</mi><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="345">但很显然, </p>
                </div>
                <div class="p1">
                    <p id="346" class="code-formula">
                        <mathml id="346"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub><mo>⊆</mo><mo stretchy="false">{</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">}</mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="347">故<mathml id="348"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>A</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">|</mo><mo>&lt;</mo><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub><mo>×</mo><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>.矛盾!所以算法1不会陷入无限循环.</p>
                </div>
                <div class="p1">
                    <p id="349">在接下来的证明中, 假设算法在第<i>k</i><sub>0</sub>次迭代终止.证明算法1得到的的确是目标函数 (2) 的最小值点.目标函数 (2) 的广义拉格朗日函数如下:</p>
                </div>
                <div class="area_img" id="350">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906001_35000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="352">人工构造上述广义拉格朗日函数的一个解如下:</p>
                </div>
                <div class="p1">
                    <p id="353" class="code-formula">
                        <mathml id="353"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mover accent="true"><mi>γ</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msubsup><mo>, </mo><mspace width="0.25em" /><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo>=</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msubsup></mtd></mtr><mtr><mtd><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>0</mn><mo>, </mo></mtd><mtd columnalign="left"><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msubsup><mo>, </mo></mtd><mtd columnalign="left"><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∉</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub></mtd></mtr></mtable></mrow></mrow></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="354">下面证明这个构造的解满足所有的KKT条件.</p>
                </div>
                <div class="p1">
                    <p id="355">在KKT条件中, 如下条件都是能够直接通过将解的值代入以验证:</p>
                </div>
                <div class="p1">
                    <p id="356" class="code-formula">
                        <mathml id="356"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mfrac><mrow><mo>∂</mo><mi>Κ</mi></mrow><mrow><mo>∂</mo><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac><mo stretchy="false">|</mo></mrow><msub><mrow></mrow><mrow><mi>γ</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></msub><mo>=</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>2</mn><mi>λ</mi></mfrac><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo>-</mo><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mn>0</mn><mo>, </mo></mtd></mtr><mtr><mtd><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mo>*</mo></msubsup><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub><mspace width="0.25em" /><mi>j</mi></mrow></msub><mo stretchy="false">|</mo></mrow></mfrac><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub><mspace width="0.25em" /><mi>j</mi></mrow></msub></mrow></munder><mi>C</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mfrac><mn>2</mn><mi>λ</mi></mfrac><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo stretchy="false">) </mo><mo>≠</mo><mn>0</mn><mo>, </mo></mtd></mtr><mtr><mtd><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo stretchy="false"> (</mo><mo>-</mo><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>-</mo><mn>0</mn><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn><mo>, </mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>γ</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>-</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo>=</mo><mn>0</mn><mo>, </mo></mtd></mtr><mtr><mtd><mo>-</mo><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>-</mo><mn>0</mn><mo>≤</mo><mn>0</mn><mo>, </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="357">所以只需要验证<i>μ</i><sup>*</sup><sub><i>j</i></sub>≥0.</p>
                </div>
                <div class="p1">
                    <p id="358">由<i>A</i><sub><i>k</i>+1</sub>⊇<i>A</i><sub><i>k</i></sub>的性质, 可以推知<i>B</i><sub><i>k</i></sub>⊇<i>B</i><sub><i>k</i>+1</sub>.因此, <i>B</i><sub><i>kj</i></sub>⊇<i>B</i><sub> (<i>k</i>+1) <i>j</i></sub>, 更进一步, <i>B</i><sub><i>kj</i></sub>可分为不相交的两部分</p>
                </div>
                <div class="p1">
                    <p id="359" class="code-formula">
                        <mathml id="359"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub><mo>+</mo><mo stretchy="false"> (</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="360">由<i>A</i><sub><i>k</i>+1</sub>的定义, 可推知</p>
                </div>
                <div class="p1">
                    <p id="361">∀ (<i>i</i>, <i>j</i>) ∈ (<i>A</i><sub><i>k</i>+1</sub>-<i>A</i><sub><i>k</i></sub>) , <i>γ</i><mathml id="362"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>&lt;0.</p>
                </div>
                <div class="p1">
                    <p id="363">因此</p>
                </div>
                <div class="p1">
                    <p id="364">∀ (<i>i</i>, <i>j</i>) ∈ (<i>B</i><sub><i>k</i></sub>-<i>B</i><sub><i>k</i>+1</sub>) , <i>γ</i><mathml id="365"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>&lt;0.</p>
                </div>
                <div class="p1">
                    <p id="366">更进一步, 可推出</p>
                </div>
                <div class="p1">
                    <p id="367">∀<i>i</i>∈ (<i>B</i><sub><i>kj</i></sub>-<i>B</i><sub> (<i>k</i>+1) <i>j</i></sub>) , <i>γ</i><mathml id="368"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>&lt;0.</p>
                </div>
                <div class="p1">
                    <p id="369">由上述两点和式 (17) 可知, </p>
                </div>
                <div class="p1">
                    <p id="370" class="code-formula">
                        <mathml id="370"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></munder><mi>γ</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub></mrow></munder><mi>γ</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mtd></mtr><mtr><mtd><mo>⇒</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub></mrow></munder><mi>γ</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub></mrow></munder><mo stretchy="false"> (</mo></mstyle><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mi>k</mi></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub></mrow></munder><mo stretchy="false"> (</mo></mstyle><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>⇒</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub></mrow></munder><mo stretchy="false"> (</mo></mstyle><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mi>k</mi></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>≥</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo><mi>j</mi></mrow></msub></mrow></munder><mo stretchy="false"> (</mo></mstyle><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>⇒</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mi>k</mi></msubsup><mo>≤</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="371">成立.</p>
                </div>
                <div class="p1">
                    <p id="372">另一边, 从<i>B</i><sub><i>k</i></sub>的定义, 可知</p>
                </div>
                <div class="p1">
                    <p id="373" class="code-formula">
                        <mathml id="373"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mo>∀</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∉</mo><mi>B</mi><msub><mrow></mrow><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub><mo>, </mo><mo>∃</mo><mover accent="true"><mi>k</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo>, </mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mo stretchy="false"> (</mo><mi>B</mi><msub><mrow></mrow><mrow><mover accent="true"><mi>k</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></msub><mo>-</mo><mi>B</mi><msub><mrow></mrow><mrow><mover accent="true"><mi>k</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="374">进一步, 由这一结论和式 (17) 可知, </p>
                </div>
                <div class="p1">
                    <p id="375" class="code-formula">
                        <mathml id="375"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mtext> </mtext><mo>-</mo><mfrac><mi>λ</mi><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mover accent="true"><mi>k</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo>=</mo><mi>γ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mover accent="true"><mi>k</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn></mrow></msubsup><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mo>⇒</mo><mi>μ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mo>*</mo></msubsup><mo>=</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msubsup><mo>≥</mo><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mi>k</mi><msub><mrow></mrow><mn>0</mn></msub><mo>-</mo><mn>1</mn></mrow></msubsup><mo>≥</mo><mo>⋯</mo><mo>≥</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mi>C</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>α</mi><msubsup><mrow></mrow><mi>j</mi><mrow><mover accent="true"><mi>k</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mn>1</mn></mrow></msubsup><mo>&gt;</mo><mn>0</mn><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="376">现已证明∀ (<i>i</i>, <i>j</i>) ∉<i>B</i><sub><i>k</i><sub>0</sub></sub>, <i>μ</i><sup>*</sup><sub><i>ij</i></sub>&gt;0.而对于 (<i>i</i>, <i>j</i>) ∈<i>B</i><sub><i>k</i><sub>0</sub></sub>, 可直接从定义中得出<i>μ</i><sup>*</sup><sub><i>ij</i></sub>=0.故∀ (<i>i</i>, <i>j</i>) , <i>μ</i><sup>*</sup><sub><i>ij</i></sub>≥0.所以, 对于构造的 (<i>γ</i><sup>*</sup><sub><i>ij</i></sub>, <i>α</i><sup>*</sup><sub><i>j</i></sub>, <i>μ</i><sup>*</sup><sub><i>ij</i></sub>) , 式 (18) 所有的KKT条件都满足.进一步, <i>γ</i><sup>*</sup><sub><i>ij</i></sub>的确是原目标函数 (2) 的最小值点.</p>
                </div>
                <h3 id="377" name="377" class="anchor-tag">3 基于迁移学习的人群计数</h3>
                <div class="p1">
                    <p id="378">应用迁移学习解决人群计数任务的想法主要源于现有的基于低维特征回归的人群计数方法都要求在同一个固定摄像头上进行训练和测试的现状.由于需要进行人群计数的摄像头的数量可能非常多, 对每个固定摄像头进行数据标注并不现实, 因此, 本文寻找能避免对每个摄像头进行标注的方法, 而应用迁移学习的思路是一种可能的方案.</p>
                </div>
                <div class="p1">
                    <p id="379">假设世界上所有可能的人群图像构成一个高维空间中的连续流形, 每个摄像头所能拍摄的所有可能的人群图像可认为是其中的一个子流形, 则Optlearn可用于人群计数任务.</p>
                </div>
                <h4 class="anchor-tag" id="380" name="380"><b>3.1</b> 跨摄像头间人群信息的迁移</h4>
                <div class="p1">
                    <p id="381">对人群计数任务进行迁移学习最关键的一点是要找到跨摄像头间人群图像的关联性.</p>
                </div>
                <div class="p1">
                    <p id="382">现有的基于低维特征回归的人群计数工作大多是以整张照片为单位进行后续的步骤——以整张照片和其中人数为训练数据, 直接预测整张照片中的总人数, 并基于此计算平均绝对误差 (Mean Absolute Error, MAE) 和平均平方误差 (Mean Square Error, MSE) .然而, 整张照片之间的关联性并不强, 每张照片内可能含有多个人群及过多的背景信息, 因此, 两张照片包含的信息可能相差极大.</p>
                </div>
                <div class="p1">
                    <p id="383">但是, 实际上人群之间具有很高的关联性.对于人群的轮廓, 只要两个人群具有大致相同的拍摄角度、大致相似的人的站位分布, 它们的轮廓会非常像.并且, 实际上在进行人群计数时, 人的关注点也只在人群轮廓上.</p>
                </div>
                <div class="p1">
                    <p id="384">综上所述, 本文以“块”作为单位.“块”定义为图像的前景掩码的连续分支, 如图1所示.显而易见, 一个“块”包含有限几个人构成的小人群, 因此“块”中的人群模式非常有限, 使算法更易找出人群模式之间的共性.</p>
                </div>
                <div class="area_img" id="385">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906001_385.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 块的图例" src="Detail/GetImg?filename=images/MSSB201906001_385.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 块的图例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906001_385.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Examples of blobs</p>

                </div>
                <div class="p1">
                    <p id="386">基于“块”的定义, 源领域<i>X</i><sub><i>s</i></sub>={<i>x</i><mathml id="387"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>}和目标领域<i>X</i><sub><i>t</i></sub>={<i>x</i><mathml id="388"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>}的数据定义如下:<i>x</i><mathml id="389"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>为源领域图像中的“块”提取的特征, <i>x</i><mathml id="390"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>为目标领域图像中的“块”提取的特征 (本文直接采用文献<citation id="592" type="reference">[<a class="sup">21</a>]</citation>的特征提取方法) .进一步, 可以直接应用Optlearn为源领域中每个“块”求一个权重, 然后将正权重“块”当作目标领域的数据使用.</p>
                </div>
                <h4 class="anchor-tag" id="391" name="391"><b>3.2</b> 适用于迁移框架的透视权重矩阵</h4>
                <div class="p1">
                    <p id="392">在人群计数的图像中, 由于摄像头角度及人在摄像头中分布的变动, 人在照片中的大小、身材比例可能不同, 这本质是透视问题.这种现象极大影响低维特征回归结果的准确性.为了解决这个问题, Chan等<citation id="593" type="reference"><link href="542" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>提出透视权重矩阵的概念, 主要思路是给图像的每个像素一个权重, 反映该像素的透视程度, 在提取低维特征的过程中使用该权重.对于基于面积的特征, 提取过程中求像素个数变为求像素总权重;对于基于边长的特征, 操作类似, 只是权重需要变为平方根.实际上, 在基于深度神经网络的方法中, Kang等<citation id="594" type="reference"><link href="564" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>也使用透视权重矩阵的信息.在某种意义上, 透视权重矩阵相当于总结一些摄像头所对的场景的先验信息.</p>
                </div>
                <div class="p1">
                    <p id="393">Chan等<citation id="595" type="reference"><link href="542" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>给出求透视权重矩阵的方法, 需要基于一些背景信息.首先框出一段路面<i>abcd</i>, 见图2.需要注意的是, 框路面的时候要求边<i>ab</i>和边<i>cd</i>与照片的底边平行.然后, 求出路面在<i>ab</i>和<i>cd</i>处的宽度<mathml id="394"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>a</mi><mi>b</mi><mo stretchy="false">|</mo></mrow></math></mathml>和<mathml id="395"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>c</mi><mi>d</mi><mo stretchy="false">|</mo></mrow></math></mathml>.在<i>ab</i>上寻找一个人, 记其高度为<i>h</i><sub>1</sub>;在<i>cd</i>上寻找一个人, 记其高度为<i>h</i><sub>2</sub>.再给定<i>ab</i>上像素点的权重为1, 给定<i>cd</i>上像素点的权重为<mathml id="396"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>h</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">|</mo><mi>a</mi><mi>b</mi><mo stretchy="false">|</mo></mrow><mrow><mi>h</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">|</mo><mi>c</mi><mi>d</mi><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></mathml>.最后, 对于其它的像素点, 通过在边<i>ab</i>和边<i>cd</i>间进行线性插值求取权重.本文基于之前选出的两人的数据, 通过线性插值拟合人在这个点的高度<i>h</i>及这个像素点处对应的路面宽度<i>s</i>, 则该像素点处权重为<mathml id="397"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>h</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">|</mo><mi>a</mi><mi>b</mi><mo stretchy="false">|</mo></mrow><mrow><mi>h</mi><mi>s</mi></mrow></mfrac><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="area_img" id="398">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906001_398.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 透视权重矩阵求解方法[21]" src="Detail/GetImg?filename=images/MSSB201906001_398.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 透视权重矩阵求解方法<citation id="596" type="reference"><link href="542" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation><sup></sup>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906001_398.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Solution of perspective map<citation id="597" type="reference"><link href="542" rel="bibliography" /><sup>[21]</sup></citation><sup></sup></p>

                </div>
                <div class="p1">
                    <p id="399">上述方法结果会随着边<i>ab</i>选取的变化而变化, 因此不适用于跨摄像头间迁移的情形.因为多个摄像头下各自选取的<i>ab</i>几乎不可能是对齐的.一种解决方案是采用Kang等<citation id="598" type="reference"><link href="564" rel="bibliography" /><sup>[<a class="sup">32</a>]</sup></citation>的基于额外信息 (包括摄像头的角度、离地高度等) 直接计算透视权重矩阵的方法.但是, 由于现在所有基于固定摄像头的人群数据集都未记录摄像头的角度、离地高度等信息, 本文只能进行如下处理.</p>
                </div>
                <div class="p1">
                    <p id="400">为了避免边<i>ab</i>选取的变化影响透视权重矩阵, 可将像素点的权重<mathml id="401"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>h</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">|</mo><mi>a</mi><mi>b</mi><mo stretchy="false">|</mo></mrow><mrow><mi>h</mi><mi>s</mi></mrow></mfrac></mrow></math></mathml>的分母变为1, 即最终像素点的权重变为<mathml id="402"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mi>h</mi><mi>s</mi></mrow></mfrac></mrow></math></mathml>.这样可使<i>ab</i>的选取不再影响最终透视权重矩阵的结果.但是, 这带来的问题是路面的真实宽度会影响最终透视权重矩阵的结果, 因为之前分子分母中各有一项路面宽度, 可以互相抵消, 但是现在不能抵消.为了解决这个新产生的问题, 本文采取人的宽度代替路面宽度的方法.人的宽度同路面宽度一样, 也可用来确定图像在每个像素上的横向缩放比例, 但人的宽度在跨摄像头的情况下也是对齐的.所以本文求透视权重矩阵的方案如下.</p>
                </div>
                <div class="p1">
                    <p id="403">1) 记录图2中<i>ab</i>上人的高度<i>h</i><sub>1</sub>和宽度<i>w</i><sub>1</sub>, <i>cd</i>上人的高度<i>h</i><sub>2</sub>和宽度<i>w</i><sub>2</sub>.</p>
                </div>
                <div class="p1">
                    <p id="404">2) 令<i>ab</i>上像素点的权重为<mathml id="405"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mi>h</mi><msub><mrow></mrow><mn>1</mn></msub><mi>w</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mo>, </mo><mi>c</mi><mi>d</mi></mrow></math></mathml>上像素点的权重为<mathml id="406"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mi>h</mi><msub><mrow></mrow><mn>2</mn></msub><mi>w</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="407">3) 对于图像上任一像素点, 通过在<i>ab</i>和<i>cd</i>间进行插值, 拟合在该像素点上的人应该的高度<i>h</i>和宽度<i>w</i>, 权重定为<mathml id="408"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mi>h</mi><mi>w</mi></mrow></mfrac><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="409">需要说明的是, 在实际中由于人的宽度并不是特别稳定, 为了更好的精度, 本文实际上框出多人 (约20个) , 并记录高度和宽度, 然后对于每个像素点通过线性回归确定该像素点上的人应该的高度<i>h</i>和宽度<i>w</i>, 而不是两点间的线性插值.</p>
                </div>
                <h4 class="anchor-tag" id="410" name="410"><b>3.3</b> 基于迁移学习的人群计数步骤</h4>
                <div class="p1">
                    <p id="411">在基于迁移学习的人群计数步骤中, 除了迁移步骤和在跨摄像头情形下必须要改动的步骤以外, 其余步骤 (低维特征提取和回归等步骤) 都是直接使用Chan等<citation id="599" type="reference"><link href="542" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>的方法.</p>
                </div>
                <div class="p1">
                    <p id="412">首先需要对目标领域和源领域进行一些说明.这里的源领域是任意的人群计数图像构成的集合.目标领域是在理想中目标固定摄像头所摄的所有可能的人群计数图像的集合.但在实际操作中, 目标领域是一些由该固定摄像头拍摄的人群计数照片 (在某种意义上这算是“采样”) .本迁移框架最终可得到一个能够对目标领域上所有可能的人群计数图像进行预测的模型.</p>
                </div>
                <div class="p1">
                    <p id="413">在训练过程中, 框架要求输入源领域图像及标注信息每个块的人数, 以及目标领域的一些图像 (目标领域不需要任何标注信息) .训练过程主要包含以下步骤.</p>
                </div>
                <div class="p1">
                    <p id="414">1) 对源领域和目标领域的图像进行前景掩码的提取.</p>
                </div>
                <div class="p1">
                    <p id="415">2) 基于前景掩码计算源领域和目标领域的“块”.</p>
                </div>
                <div class="p1">
                    <p id="416">3) 基于对齐的透视权重矩阵计算源领域中所有块的特征<i>X</i><sub><i>s</i></sub>={<i>x</i><mathml id="417"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>}和目标领域中所有块的特征<i>X</i><sub><i>t</i></sub>={<i>x</i><mathml id="418"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup></mrow></math></mathml>}, 特征提取方法同文献<citation id="600" type="reference">[<a class="sup">21</a>]</citation>.</p>
                </div>
                <div class="p1">
                    <p id="419">4) 对源领域的特征进行标准化, 并利用源领域的方差和标准差对目标领域进行同样的处理.</p>
                </div>
                <div class="p1">
                    <p id="420">5) 计算输运代价矩阵<b><i>C</i></b>, 直接使用特征的欧氏距离作为输运代价.</p>
                </div>
                <div class="p1">
                    <p id="421">6) 调用Optlearn, 为源领域求出一组权重.</p>
                </div>
                <div class="p1">
                    <p id="422">7) 以源领域中所有正权重数据及其人数标签为训练集, 训练一个高斯过程回归模型 (回归模型同文献<citation id="601" type="reference">[<a class="sup">21</a>]</citation>) .</p>
                </div>
                <div class="p1">
                    <p id="423">高斯模型就是目标摄像头上的预测模型.需要注意的是, 模型用于预测“块”的人数, 在测试时, 需对测试图像进行“块”的切割并对每个块进行预测, 再相加所有“块”的预测结果, 得到最终结果.</p>
                </div>
                <div class="p1">
                    <p id="424">上述流程不需要任何的目标摄像头的带标签数据, 只需要一个公用的有标注的源领域, 因此可以避免对每个固定摄像头进行标注的问题.</p>
                </div>
                <h3 id="425" name="425" class="anchor-tag">4 实验及结果分析</h3>
                <h4 class="anchor-tag" id="426" name="426"><b>4.1</b> 人群数据集及设定</h4>
                <div class="p1">
                    <p id="427">实验选用3个人群计数数据集:UCSD数据集、Fudan数据集和Mall数据集, 用于测试本文的人群迁移框架.每次实验使用其中一个数据集为源领域, 另选其中一个为目标领域.当某个数据集用作源领域时, 所有数据都用于迁移, 标签信息在训练过程中可见.当某个数据集用作目标领域时, 分为不相交的两部分:一部分称作“迁移部分”, 用于迁移学习的步骤;另一部分称作“测试部分”, 作为最终的测试集.在训练过程中目标领域的数据集的所有标签信息均不可见.</p>
                </div>
                <div class="p1">
                    <p id="428">为了降低“迁移部分”和“测试部分”在时间上的关联性, 把UCSD数据集标号为1～1200的图像、Fudan数据集上标号为1～500的图像和Mall数据集标号为1～600的图像划分为“迁移部分”, 把UCSD数据集上标号为1201～4000的图像、Fudan数据集上标号为501～1500的图像和Mall数据集标号为601～2000的图像划分为“测试部分”.</p>
                </div>
                <div class="p1">
                    <p id="429">在一些实验中, 为了说明基于迁移的人群计数方法与在目标摄像头上直接标记数据进行训练的方法的效果差异, 在对比结果中加入标记为“传统回归模型”的结果.该结果使用目标领域对应的数据集的“迁移部分”进行训练, 忽略目标领域标签信息在训练过程中均不可见的要求, 使用“测试部分”进行测试.这个结果与源领域彻底无关.</p>
                </div>
                <div class="p1">
                    <p id="430">本文使用平均绝对误差 (MAE) 和平均平方误差 (MSE) 作为衡量预测结果和实际结果差异的指标, 数学形式的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="431" class="code-formula">
                        <mathml id="431"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><mi>A</mi><mi>E</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><msup><mrow></mrow><mi>p</mi></msup><mo>, </mo><mi mathvariant="bold-italic">y</mi><msup><mrow></mrow><mi>l</mi></msup><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mo stretchy="false">|</mo></mstyle><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo>-</mo><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>l</mi></msubsup><mo stretchy="false">|</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>Μ</mi><mi>S</mi><mi>E</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">y</mi><msup><mrow></mrow><mi>p</mi></msup><mo>, </mo><mi mathvariant="bold-italic">y</mi><msup><mrow></mrow><mi>l</mi></msup><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mrow><mo stretchy="false"> (</mo><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>p</mi></msubsup><mo>-</mo><mi>y</mi><msubsup><mrow></mrow><mi>i</mi><mi>l</mi></msubsup><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="432">其中, <b><i>y</i></b><sup><i>p</i></sup>为图像预测人数构成的向量, <b><i>y</i></b><sup><i>l</i></sup>为图像实际人数向量, <i>n</i>为测试数据的数量.</p>
                </div>
                <h4 class="anchor-tag" id="433" name="433"><b>4.2</b> 与其它迁移算法的对比</h4>
                <div class="p1">
                    <p id="434">对比算法如下:Kullback-Leibler重要性估计过程 (Kullback-Leibler Importance Estimation Procedure, KLIEP) <citation id="602" type="reference"><link href="512" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 子空间对齐 (Subspace Alignment, SA) <citation id="603" type="reference"><link href="502" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 相关性对齐 (Correlation Alignment, CORAL) <citation id="604" type="reference"><link href="514" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>, 基于地标选择的子空间对齐 (Landmarks Selection-Based Subspace Alignment, LSSA) <citation id="605" type="reference"><link href="504" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.为了更好地说明各迁移算法的效果, 在实验中加上一组传统回归模型的结果.在UCSD、Fudan数据集之间迁移的实验结果如表1所示.</p>
                </div>
                <div class="area_img" id="435">
                    <p class="img_tit"><b>表1 6种算法的实验结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Experimental result comparison of 6 algorithms</p>
                    <p class="img_note"></p>
                    <table id="435" border="1"><tr><td rowspan="2"><br />算法</td><td colspan="2"><br />UCSD→Fudan</td><td colspan="2"><br />Fudan→UCSD</td></tr><tr><td><br />MAE</td><td>MSE</td><td><br />MAE</td><td>MSE</td></tr><tr><td><br />Optlearn</td><td>1.19</td><td>2.37</td><td>1.87</td><td>5.68</td></tr><tr><td><br />KLIEP</td><td>1.45</td><td>3.29</td><td>2.06</td><td>6.59</td></tr><tr><td><br />SA</td><td>2.05</td><td>7.09</td><td>5.00</td><td>36.21</td></tr><tr><td><br />CORAL</td><td>1.63</td><td>5.34</td><td>3.32</td><td>16.79</td></tr><tr><td><br />LSSA</td><td>1.61</td><td>4.68</td><td>4.82</td><td>46.63</td></tr><tr><td><br />传统回归模型</td><td>0.72</td><td>0.93</td><td>1.84</td><td>5.85</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="436">由表1可知, Optlearn效果最好, KLIEP其次, 这两种算法的效果与直接在目标领域上训练并测试的传统回归模型效果相差不大, 而剩余3种算法的效果较差.这种现象的原因是迁移算法针对的源领域和目标领域间的关联方式不同.KLIEP假设目标领域和源领域在同一空间中但数据分布不同, 这种假设与Optlearn的“子流形”假设有一定的兼容性.一方面, “子流形”是数据分布不同的一种特殊情况, 另一方面, 目标领域和源领域在同一空间中也是目标领域是源领域的子流形的一种特殊情况.因此, KLIEP效果与Optlearn效果相近.剩余3种算法的假设不同, SA和LSSA假设可以找到两个映射, 将源领域和目标领域映射到一个公共空间中, 而CORAL假设可以找到一个将源领域数据映射到目标领域中的映射.因此, 这3种算法在人群计数任务上得到的效果与Optlearn、KLIEP的效果相差很大.这也说明3种算法基于的假设并不适用于人群计数任务, 因此在之后的实验中, 本文不会再测试这3种算法.</p>
                </div>
                <h4 class="anchor-tag" id="437" name="437"><b>4.3</b> 在人群计数任务上的适用性</h4>
                <div class="p1">
                    <p id="438">为了说明Optlearn及本文的跨摄像头的人群迁移思路的确适用于人群计数任务, 本节在UCSD、Fudan、Mall数据集两两之间进行迁移实验, 对比本文的人群迁移框架的效果与在目标领域上直接训练的传统回归模型的效果.由于4.2节中实验结果说明KLIEP效果与Optlearn效果相近, 故本节对Optlearn和KLIEP都进行测试.结果见表2.</p>
                </div>
                <div class="area_img" id="439">
                    <p class="img_tit"><b>表2 3种算法的效果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Results comparison of 3 algorithms</p>
                    <p class="img_note"></p>
                    <table id="439" border="1"><tr><td rowspan="2"><br /></td><td colspan="2"><br />传统回归模型</td><td colspan="2"><br />Optlearn</td><td colspan="2"><br />KLIEP</td></tr><tr><td><br />MAE</td><td>MSE</td><td><br />MAE</td><td>MSE</td><td><br />MAE</td><td>MSE</td></tr><tr><td>UCSD→Fudan</td><td>0.72</td><td>0.93</td><td>1.19</td><td>2.37</td><td>1.45</td><td>3.29</td></tr><tr><td><br />Fudan→UCSD</td><td>1.84</td><td>5.85</td><td>1.87</td><td>5.68</td><td>2.06</td><td>6.59</td></tr><tr><td><br />UCSD→Mall</td><td>3.63</td><td>18.50</td><td>2.91</td><td>17.79</td><td>3.22</td><td>20.31</td></tr><tr><td><br />Mall→UCSD</td><td>1.84</td><td>5.85</td><td>2.09</td><td>7.09</td><td>2.14</td><td>7.55</td></tr><tr><td><br />Mall→Fudan</td><td>0.72</td><td>0.93</td><td>1.02</td><td>1.77</td><td>1.22</td><td>2.65</td></tr><tr><td><br />Fudan→Mall</td><td>3.63</td><td>18.50</td><td>3.52</td><td>19.51</td><td>5.07</td><td>36.05</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="440">由表2可知, Optlearn得到的效果与在目标领域上直接训练的传统回归模型的效果只有微小差异.甚至在UCSD→Mall的情形中, 表现优于直接在Mall数据集上训练的传统回归模型, 这足以说明Optlearn对人群计数任务的适用性及人群迁移思路的有效性.将Optlearn换为KLIEP, 得到的效果稍微有所降低 (除了Fudan→Mall情形中KLIEP崩溃之外) , 这也能进一步说明人群迁移思路的有效性.</p>
                </div>
                <h4 class="anchor-tag" id="441" name="441"><b>4.4</b> 运行速度</h4>
                <div class="p1">
                    <p id="442">为了说明Optlearn运算速度较快的特点, 本节对比Optlearn与KLIEP在迁移过程中的耗时.所有实验都在同一台服务器上, 服务器配置为16核Intel (R) Xeon (R) CPU E5520@2.27 GHz.实验结果如表3所示.由表可知, Optlearn在运行速度上更优.</p>
                </div>
                <div class="area_img" id="443">
                    <p class="img_tit"><b>表3 Optlearn与KLIEP运行时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Running time comparison of Optlearn and KLIEP s</p>
                    <p class="img_note"></p>
                    <table id="443" border="1"><tr><td><br /></td><td>Optlearn</td><td>KLIEP</td></tr><tr><td><br />UCSD→Fudan</td><td>8.46</td><td>38.3</td></tr><tr><td><br />Fudan→UCSD</td><td>5.49</td><td>1924</td></tr><tr><td><br />UCSD→Mall</td><td>82.14</td><td>1290</td></tr><tr><td><br />Mall→UCSD</td><td>39.50</td><td>1938</td></tr><tr><td><br />Mall→Fudan</td><td>7.99</td><td>89.99</td></tr><tr><td><br />Fudan→Mall</td><td>10.29</td><td>959.3</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="444" name="444"><b>4.5</b> 消融实验</h4>
                <div class="p1">
                    <p id="445">为了说明本文的人群迁移思路中以“块”为数据单位的必要性和迁移步骤的必要性, 进行消融实验, 说明不以“块”作为数据单位和跳过迁移步骤都不可行.</p>
                </div>
                <div class="p1">
                    <p id="446">在以“块”作为数据单位的消融实验中.以单幅图像为数据单位进行迁移, 并使用与本文同样的回归模型进行回归, 然后与以本文迁移思路得到的结果进行对比.由于KLIEP对人群迁移也有较好的适用性, 所以除了Optlearn之外, 也对KLIEP进行实验, 结果见表4.</p>
                </div>
                <div class="area_img" id="447">
                    <p class="img_tit"><b>表4 以块为数据单位的必要性</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Necessity of taking blobs as data units</p>
                    <p class="img_note"></p>
                    <table id="447" border="1"><tr><td rowspan="2"><br /></td><td colspan="2"><br />UCSD→Fudan</td><td colspan="2"><br />Fudan→UCSD</td></tr><tr><td><br />MAE</td><td>MSE</td><td><br />MAE</td><td>MSE</td></tr><tr><td><br />Optlearn+<br />“块”为数据单位</td><td>1.19</td><td>2.37</td><td>1.87</td><td>5.68</td></tr><tr><td><br />KLIEP+<br />“块”为数据单位</td><td>1.45</td><td>3.29</td><td>2.06</td><td>6.59</td></tr><tr><td><br />Optlearn+<br />图像为数据单位</td><td>5.42</td><td>44.24</td><td>20.20</td><td>484.40</td></tr><tr><td><br />KLIEP+<br />图像为数据单位</td><td>5.01</td><td>37.88</td><td>18.70</td><td>409.93</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="448">由表4可知, 无论是Optlearn还是KLIEP, 在以单幅图像为数据单位的情况下都会崩溃, 这说明不是某个迁移算法的问题, 而是在这种情形下, 跨数据集 (即跨摄像头) 间的数据缺乏关联性, 因此迁移学习会失败.这表明以“块”作为数据单位的必要性.</p>
                </div>
                <div class="p1">
                    <p id="449">在迁移步骤必要性的消融实验中, 对于“子流形”假设的争议点在于, 如果跳过迁移步骤直接在源领域对应的流形上训练模型, 是否也能在目标领域取得良好的预测效果.为了说明迁移步骤必要性, 对比人群迁移思路的预测效果和不进行迁移操作直接使用源领域数据进行训练的预测效果.实验结果如表5所示.</p>
                </div>
                <div class="area_img" id="450">
                    <p class="img_tit"><b>表5 迁移步骤的必要性</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Necessity of transfer step</p>
                    <p class="img_note"></p>
                    <table id="450" border="1"><tr><td rowspan="2"><br /></td><td colspan="2"><br />UCSD→Fudan</td><td colspan="2"><br />Fudan→UCSD</td></tr><tr><td><br />MAE</td><td>MSE</td><td><br />MAE</td><td>MSE</td></tr><tr><td><br />人群迁移思路</td><td>1.19</td><td>2.37</td><td>1.87</td><td>5.68</td></tr><tr><td><br />不迁移</td><td>5.89</td><td>52.68</td><td>2.89</td><td>12.17</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="451">由表5可知, 不进行迁移操作, 得到的结果远不如本文算法.产生这种情况的主要原因是由于领域间巨大的分布差异.在源领域上, 能够用于目标领域的数据仅占很小一部分, 大部分数据在目标领域对应的流形之外.以整个源领域为训练数据而训练的回归模型, 主要受来自目标领域对应的流形之外的数据的影响, 因此, 最终得到的回归模型更倾向于照顾这些“子流形”之外的数据.所以, 在本文的人群迁移思路中, 迁移步骤是必要的.</p>
                </div>
                <h3 id="452" name="452" class="anchor-tag">5 结束语</h3>
                <div class="p1">
                    <p id="453">本文提出针对“子流形”情形的迁移学习算法 (Optlearn) , 也提出基于迁移学习的不用为每个固定摄像头进行数据标注的人群计数算法.对于Optlearn, 基于最优输运理论, 通过将对偶Sinkhorn散度中的信息熵项换成<i>l</i><sub>2</sub>正则项, 达到让Optlearn能够过滤子流形之外的数据的目的.同时, 为Optlearn给出一个高效的求解方法.该求解方法是一种类似于求闭式解的方法, 所以速度较快.本文也证明这种求解方法的确能得到正确结果.本文将Optlearn用于人群计数的任务, 提出不需要对目标固定摄像头进行标注的, 基于迁移学习的人群计数思路.不同于之前的人群计数算法使用图像作为数据单位的做法, 而以“块”为数据单位, 增强不属于同一固定摄像头的数据间的关联性.最终的实验结果表明本文思路在人群计数任务上能够得到可行的结果, 且Optlearn的人群计数效果最好.</p>
                </div>
                <div class="p1">
                    <p id="454">本文提出的工作尚有一些不足的地方.在Optlearn中, 本文的求解方法不是一个普适的方法, 其证明用到本问题中独有的性质 (如式 (17) ) , 因此, 若之后想对本文算法进行变形 (如加正则项) 用于其它问题, 求解方法可能需要重新设计.另外, 在人群迁移中, 本文只在现有的基于固定摄像头的人群计数数据集上进行实验, 这些数据集的人群密度都不高, 因此本文的“块”的定义未带来问题.实际上, 对“块”的定义还是有待讨论, 当人群较密集时, 将一片人群分成多个块可能更有效.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="497" type="formula" href="images/MSSB201906001_49700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">车令夫</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="498" type="formula" href="images/MSSB201906001_49800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">田宇坤</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="499" type="formula" href="images/MSSB201906001_49900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">朱海平</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="500" type="formula" href="images/MSSB201906001_50000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">张军平</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="502">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unsupervised visual domain adaptation using subspace alignment">

                                <b>[1]</b> FERNANDO B, HABRARD A, SEBBAN M, et al.Unsupervised Visual Domain Adaptation Using Subspace Alignment // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2013:2960-2967.
                            </a>
                        </p>
                        <p id="504">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Landmarks-based kernelized subspace alignment for unsupervised domain adaptation">

                                <b>[2]</b> ALJUNDI R, EMONET R, MUSELET D, et al.Landmarks-Based Kernelized Subspace Alignment for Unsupervised Domain Adaptation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2015:56-63.
                            </a>
                        </p>
                        <p id="506">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=When unsupervised domain adaptation meets tensor representations">

                                <b>[3]</b> LU H, ZHANG L, CAO Z G, et al.When Unsupervised Domain Adaptation Meets Tensor Representations // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2017:599-608.
                            </a>
                        </p>
                        <p id="508">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201406015&amp;v=MDYxODRZYkc0SDlYTXFZOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVTdySUtDTGY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 张倩, 李明, 王雪松, 等.一种面向多源领域的实例迁移学习.自动化学报, 2014, 40 (6) :1176-1183. (ZHANG Q, LI M, WANG X S, et al.Instance-Based Transfer Learning for Multi-source Domains.Acta Automatica Sinica, 2014, 40 (6) :1176-1183.) 
                            </a>
                        </p>
                        <p id="510">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201402008&amp;v=MTIwNjk5WE1yWTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6aFU3cklLQ0xmWWJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 张景祥, 王士同, 邓赵红, 等.融合异构特征的子空间迁移学习算法.自动化学报, 2014, 40 (2) :236-246. (ZHANG J X, WANG S T, DENG Z H, et al.A Subspace Transfer Learning Algorithm Integrating Heterogeneous Features.Acta Automatica Sinica, 2014, 40 (2) :236-246.) 
                            </a>
                        </p>
                        <p id="512">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Direct Importance Estimation with Model Selec-tion and Its Application to Covariate Shift Adaptation">

                                <b>[6]</b> SUGIYAMA M, NAKAJIMA S, KASHIMA H, et al.Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation // SCHÖLKOPF B, PLATT J, HOFMANN T, eds.Advances in Neural Information Processing Systems 20.Cambridge, USA:The MIT Press, 2007:1433-1440.
                            </a>
                        </p>
                        <p id="514">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Return of Frustratingly Easy Domain Adaptation[C/OL]">

                                <b>[7]</b> SUN B, FENG J S, SAENKO K.Return of Frustratingly Easy Domain Adaptation[C/OL].[2019-02-26].https://arxiv.org/pdf/1511.05547.pdf.
                            </a>
                        </p>
                        <p id="516">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Geodesic flow kernel for unsupervised domain adaptation">

                                <b>[8]</b> GONG B Q, SHI Y, SHA F, et al.Geodesic Flow Kernel for Unsupervised Domain Adaptation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2012:2066-2073.
                            </a>
                        </p>
                        <p id="518">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Domain Adaptation with Re-gularized Optimal Transport">

                                <b>[9]</b> COURTY N, FLAMARY R, TUIA D.Domain Adaptation with Re-gularized Optimal Transport // Proc of the Joint European Confe-rence on Machine Learning and Knowledge Discovery in Databases.Berlin, Germany:Springer, 2014:274-289
                            </a>
                        </p>
                        <p id="520">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Transitive Transfer Learning">

                                <b>[10]</b> TAN B, SONG Y Q, ZHONG E H, et al.Transitive Transfer Learning // Proc of the 21th ACM SIGKDD International Confe-rence on Knowledge Discovery and Data Mining.New York, USA:ACM, 2015:1155-1164.
                            </a>
                        </p>
                        <p id="522">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distant domain transfer learning">

                                <b>[11]</b> TAN B, ZHANG Y, PAN S J, et al.Distant Domain Transfer Learning // Proc of the 31st AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2017:2604-2610.
                            </a>
                        </p>
                        <p id="524">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wasserstein Generative Adversarial Networks">

                                <b>[12]</b> ARJOVSKY M, CHINTALA S, BOTTOU L.Wasserstein Generative Adversarial Networks // Proc of the 34th International Confe-rence on Machine Learning.New York, USA:ACM, 2017:214-223.
                            </a>
                        </p>
                        <p id="526">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved Training of Wasserstein Gans[C/OL]">

                                <b>[13]</b> GULRAJANI I, AHMED F, ARJOVSKY M, et al.Improved Training of Wasserstein Gans[C/OL].[2019-02-26].https://arxiv.org/pdf/1704.00028.pdf.
                            </a>
                        </p>
                        <p id="528">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sinkhorn Distances:Lightspeed Computation of Optimal Transport">

                                <b>[14]</b> CUTURI M.Sinkhorn Distances:Lightspeed Computation of Optimal Transport // BURGES C J C, BOTTOU L, WELLING M, et al., eds.Advances in Neural Information Processing Systems 26.Cambridge, USA:The MIT Press, 2013:2292-2300.
                            </a>
                        </p>
                        <p id="530">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Smooth and Sparse Optimal Transport[C/OL]">

                                <b>[15]</b> BLONDEL M, SEGUY V, ROLET A.Smooth and Sparse Optimal Transport[C/OL].[2019-02-26].https://arxiv.org/pdf/1710.06276.pdf.
                            </a>
                        </p>
                        <p id="532">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Label Distribution Learning by Optimal Transport[C/OL]">

                                <b>[16]</b> ZHAO P, ZHOU Z H.Label Distribution Learning by Optimal Transport[C/OL].[2019-02-26].https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/aaai18ladot.pdf.
                            </a>
                        </p>
                        <p id="534">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the Convergence and Robustness of Training GANs with Regularized Optimal Transport">

                                <b>[17]</b> SANJABI M, BA J, RAZAVIYAYN M, et al.On the Convergence and Robustness of Training GANs with Regularized Optimal Transport // BENGIO S, WALLACH H M, LAROCHELLE H, et al., eds.Advances in Neural Information Processing Systems 31.Cambridge, USA:The MIT Press, 2018:7091-7101.
                            </a>
                        </p>
                        <p id="536">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Segmentation and Tracking of Multiple Humans in Crowded Environments">

                                <b>[18]</b> ZHAO T, NEVATIA R, WU B.Segmentation and Tracking of Multiple Humans in Crowded Environments.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2008, 30 (7) :1198-1211.
                            </a>
                        </p>
                        <p id="538">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pedestrian Detection: An Evaluation of the State of the Art">

                                <b>[19]</b> DOLLAR P, WOJEK C, SCHIELE B, et al.Pedestrian Detection:An Evaluation of the State of the Art.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2012, 34 (4) :743-761.
                            </a>
                        </p>
                        <p id="540">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Marked point processes for crowd counting">

                                <b>[20]</b> GE W, COLLINS R T.Marked Point Processes for Crowd Counting // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2009:2913-2920.
                            </a>
                        </p>
                        <p id="542">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Privacy preservingcrowd monitoring:counting people without people models ortracking">

                                <b>[21]</b> CHAN A B, LIANG Z S J, VASCONCELOS N.Privacy Preserving Crowd Monitoring:Counting People without People Models or Tracking // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2008.DOI:10.1109/CVPR.2008.4587569.
                            </a>
                        </p>
                        <p id="544">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bayesian Poisson regression for crowd counting">

                                <b>[22]</b> CHAN A B, VASCONCELOS N.Bayesian Poisson Regression for Crowd Counting // Proc of the 12th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2009:545-551.
                            </a>
                        </p>
                        <p id="546">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Counting People With Low-Level Features and Bayesian Regression">

                                <b>[23]</b> CHAN A B, VASCONCELOS N.Counting People with Low-Level Features and Bayesian Regression.IEEE Transactions on Image Processing, 2012, 21 (4) :2160-2177.
                            </a>
                        </p>
                        <p id="548">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cumulative attribute space for age and crowd density estimation">

                                <b>[24]</b> CHEN K, GONG S G, XIANG T, et al.Cumulative Attribute Space for Age and Crowd Density Estimation // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2013:2467-2474.
                            </a>
                        </p>
                        <p id="550">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600738129&amp;v=MzA4MzVQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGb1VieEk9TmlmT2ZiSzdIdEROcVk5RlkrZ0hEWDR3b0JNVDZUNA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> TAN B, ZHANG J P, WANG L.Semi-supervised Elastic Net for Pedestrian Counting.Pattern Recognition, 2011, 44 (10/11) :2297-2304.
                            </a>
                        </p>
                        <p id="552">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semisupervised pedestrian counting with temporal and spatial consistencies">

                                <b>[26]</b> XIA W, ZHANG J P, KRUGER U.Semisupervised Pedestrian Counting with Temporal and Spatial Consistencies.IEEE Transactions on Intelligent Transportation Systems, 2015, 16 (4) :1705-1715.
                            </a>
                        </p>
                        <p id="554">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Crowd Counting with Limited Labeling through Submodular Frame Selection">

                                <b>[27]</b> ZHOU Q, ZHANG J P, CHE L F, et al.Crowd Counting with Limited Labeling through Submodular Frame Selection.IEEE Transactions on Intelligent Transportation Systems, 2019, 20 (5) :1728-1738.
                            </a>
                        </p>
                        <p id="556">
                            <a id="bibliography_28" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201304006&amp;v=MjU4OTR6cXFCdEdGckNVUkxPZVplUm5GeXpoVTdySVB5cmZiTEc0SDlMTXE0OUZZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[28]</b> 覃勋辉, 王修飞, 周曦, 等.多种人群密度场景下的人群计数.中国图象图形学报, 2013, 18 (4) :392-398. (QIN X H, WANG X F, ZHOU X, et al.Counting People in Various Crowed Density Scenes Using Support Vector Regression.Journal of Image and Graphics, 2013, 18 (4) :392-398.) 
                            </a>
                        </p>
                        <p id="558">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generating high-quality crowd density maps using contextual pyramid cnns">

                                <b>[29]</b> SINDAGI V A, PATEL V M.Generating High-Quality Crowd Density Maps Using Contextual Pyramid CNNs // Proc of the IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2017, I:1879-1888.
                            </a>
                        </p>
                        <p id="560">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Switching convolutional neural network for crowd counting">

                                <b>[30]</b> SAM D B, SURYA S, BABU R V.Switching Convolutional Neural Network for Crowd Counting // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:4031-4039.
                            </a>
                        </p>
                        <p id="562">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single-Image Crowd Counting via Multi-Column Convolutional Neural Network">

                                <b>[31]</b> ZHANG Y Y, ZHOU D S, CHEN S Q, et al.Single-Image Crowd Counting via Multi-column Convolutional Neural Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:589-597.
                            </a>
                        </p>
                        <p id="564">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Crowd Counting by Adapting Convolutional Neural Networks with Side Information[C/OL]">

                                <b>[32]</b> KANG D, DHAR D, CHAN A B.Crowd Counting by Adapting Convolutional Neural Networks with Side Information[C/OL].[2019-02-26].https://arxiv.org/pdf/1611.06748.pdf.
                            </a>
                        </p>
                        <p id="566">
                            <a id="bibliography_33" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201606007&amp;v=MTA5ODFDTGZZYkc0SDlmTXFZOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVTdySUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[33]</b> 时增林, 叶阳东, 吴云鹏, 等.基于序的空间金字塔池化网络的人群计数方法.自动化学报, 2016, 42 (6) :866-874. (SHI Z L, YE Y D, WU Y P, et al.Crowd Counting Using Rank-based Spatial Pyramid Pooling Network.Acta Automatica Sinica, 2016, 42 (6) :866-874.) 
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201906001" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201906001&amp;v=MDAxNDVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVTdySUtEN1liTEc0SDlqTXFZOUZaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
