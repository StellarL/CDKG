<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131445460498750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201904010%26RESULT%3d1%26SIGN%3dk1ixXfiZfb9CoMn8Q0ysYPUEeig%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201904010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201904010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201904010&amp;v=MTAxNjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1VMelBLRDdZYkxHNEg5ak1xNDlFWklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#93" data-title="1 基于深度学习的芯片图像超分辨率重建算法 ">1 基于深度学习的芯片图像超分辨率重建算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#94" data-title="&lt;b&gt;1.1&lt;/b&gt; 网络结构"><b>1.1</b> 网络结构</a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;1.2&lt;/b&gt; 卷积神经网络模块"><b>1.2</b> 卷积神经网络模块</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#118" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#181" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#102" data-title="图1 本文算法的网络结构">图1 本文算法的网络结构</a></li>
                                                <li><a href="#111" data-title="图2 卷积神经网络模块的网络结构">图2 卷积神经网络模块的网络结构</a></li>
                                                <li><a href="#120" data-title="图3 样本集中的芯片示例图像">图3 样本集中的芯片示例图像</a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表1 5种算法对芯片图像重建的峰值信噪比&lt;/b&gt;"><b>表1 5种算法对芯片图像重建的峰值信噪比</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;表2 5种算法对芯片图像重建的结构相似度&lt;/b&gt;"><b>表2 5种算法对芯片图像重建的结构相似度</b></a></li>
                                                <li><a href="#224" data-title="图4 芯片图像重建效果图1">图4 芯片图像重建效果图1</a></li>
                                                <li><a href="#224" data-title="图4 芯片图像重建效果图1">图4 芯片图像重建效果图1</a></li>
                                                <li><a href="#225" data-title="图5 芯片图像重建效果图2">图5 芯片图像重建效果图2</a></li>
                                                <li><a href="#225" data-title="图5 芯片图像重建效果图2">图5 芯片图像重建效果图2</a></li>
                                                <li><a href="#226" data-title="图6 芯片图像重建效果图3">图6 芯片图像重建效果图3</a></li>
                                                <li><a href="#227" data-title="图7 自然图像的重建效果图">图7 自然图像的重建效果图</a></li>
                                                <li><a href="#227" data-title="图7 自然图像的重建效果图">图7 自然图像的重建效果图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 倪林, 李少青, 马瑞聪, 等.硬件木马检测与防护.数字通信, 2014, 41 (1) :59-63, 68. (NI L, LI S Q, MA R C, &lt;i&gt;et al&lt;/i&gt;.Hardware Trojans Detection and Protection.Digital Communication, 2014, 41 (1) :59-63, 68.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SZTX201401016&amp;v=MDczMzNvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UE5qZmZkckc0SDlYTXI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         倪林, 李少青, 马瑞聪, 等.硬件木马检测与防护.数字通信, 2014, 41 (1) :59-63, 68. (NI L, LI S Q, MA R C, &lt;i&gt;et al&lt;/i&gt;.Hardware Trojans Detection and Protection.Digital Communication, 2014, 41 (1) :59-63, 68.) 
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 许强, 蒋兴浩, 姚立红, 等.硬件木马检测与防范研究综述.网络与信息安全学报, 2017, 3 (4) :DOI:10.11959/j.issn.2096-109x.2017.00160. (XU Q, JIANG X H, YAO L H, &lt;i&gt;et al&lt;/i&gt;.Overview of the Detection and Prevention Study of Hardware Trojans.Chinese Journal of Network and Information Security, 2017, 3 (4) :DOI:10.11959/j.issn.2096-109x.2017.00160.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXAQ201704001&amp;v=MDgxNzZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UE1qWEtmN0c0SDliTXE0OUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         许强, 蒋兴浩, 姚立红, 等.硬件木马检测与防范研究综述.网络与信息安全学报, 2017, 3 (4) :DOI:10.11959/j.issn.2096-109x.2017.00160. (XU Q, JIANG X H, YAO L H, &lt;i&gt;et al&lt;/i&gt;.Overview of the Detection and Prevention Study of Hardware Trojans.Chinese Journal of Network and Information Security, 2017, 3 (4) :DOI:10.11959/j.issn.2096-109x.2017.00160.) 
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 王侃, 陈浩, 管旭光, 等.硬件木马防护技术研究.网络与信息安全学报, 2017, 3 (9) :DOI:10.11959/j.issn.2096-109x.2017.00197. (WANG K, CHEN H, GUAN X G, &lt;i&gt;et al&lt;/i&gt;.Research on Hardware Trojan Defense.Chinese Journal of Network and Information Security, 2017, 3 (9) :DOI:10.11959/j.issn.2096-109x.2017.00197.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXAQ201709001&amp;v=MDQ0NThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1VMelBNalhLZjdHNEg5Yk1wbzlGWlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         王侃, 陈浩, 管旭光, 等.硬件木马防护技术研究.网络与信息安全学报, 2017, 3 (9) :DOI:10.11959/j.issn.2096-109x.2017.00197. (WANG K, CHEN H, GUAN X G, &lt;i&gt;et al&lt;/i&gt;.Research on Hardware Trojan Defense.Chinese Journal of Network and Information Security, 2017, 3 (9) :DOI:10.11959/j.issn.2096-109x.2017.00197.) 
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 苏衡, 周杰, 张志浩.超分辨率图像重建方法综述.自动化学报, 2013, 39 (8) :1202-1213. (SU H, ZHOU J, ZHANG Z H.Survey of Super-Resolution Image Reconstruction Methods.Acta Automatica Sinica, 2013, 39 (8) :1202-1213.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201308005&amp;v=MDk2OTR6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UEtDTGZZYkc0SDlMTXA0OUZZWVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         苏衡, 周杰, 张志浩.超分辨率图像重建方法综述.自动化学报, 2013, 39 (8) :1202-1213. (SU H, ZHOU J, ZHANG Z H.Survey of Super-Resolution Image Reconstruction Methods.Acta Automatica Sinica, 2013, 39 (8) :1202-1213.) 
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" SCHULTZ R R, STEVENSON R L.A Bayesian Approach to Image Expansion for Improved Definition.IEEE Transactions on Image Processing, 1994, 3 (3) :233-242." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Bayesian approach to image expansion for improved definition">
                                        <b>[5]</b>
                                         SCHULTZ R R, STEVENSON R L.A Bayesian Approach to Image Expansion for Improved Definition.IEEE Transactions on Image Processing, 1994, 3 (3) :233-242.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" HOU H, ANDREWS H.Cubic Splines for Image Interpolation and Digital Filtering.IEEE Transactions on Acoustics, Speech, and Signal Processing, 1978, 26 (6) :508-517." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cubic splines for image interpolation and digital filtering">
                                        <b>[6]</b>
                                         HOU H, ANDREWS H.Cubic Splines for Image Interpolation and Digital Filtering.IEEE Transactions on Acoustics, Speech, and Signal Processing, 1978, 26 (6) :508-517.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" LI X, ORCHARD M T.New Edge-Directed Interpolation.IEEE Transactions on Image Processing, 2001, 10 (10) :1521-1527." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=New edge-directed interpolation">
                                        <b>[7]</b>
                                         LI X, ORCHARD M T.New Edge-Directed Interpolation.IEEE Transactions on Image Processing, 2001, 10 (10) :1521-1527.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" WANG Q, WARD R K.A New Orientation-Adaptive Interpolation Method.IEEE Transactions on Image Processing, 2007, 16 (4) :889-900." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A New Orientation-Adaptive Interpolation Method">
                                        <b>[8]</b>
                                         WANG Q, WARD R K.A New Orientation-Adaptive Interpolation Method.IEEE Transactions on Image Processing, 2007, 16 (4) :889-900.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" HUANG T S, TSAI R Y.Multiframe Image Restoration and Registration // HUANG T S, ed.Advances in Computer Vision and Image Processing.London, UK:JAI Press, 1984:317-339." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiframe image restoration and registration">
                                        <b>[9]</b>
                                         HUANG T S, TSAI R Y.Multiframe Image Restoration and Registration // HUANG T S, ed.Advances in Computer Vision and Image Processing.London, UK:JAI Press, 1984:317-339.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" IRANI M, PELEG S.Improving Resolution by Image Registration.CVGIP:Graphical Models and Image Processing, 1991, 53 (3) :231-239." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving resolution by image registration">
                                        <b>[10]</b>
                                         IRANI M, PELEG S.Improving Resolution by Image Registration.CVGIP:Graphical Models and Image Processing, 1991, 53 (3) :231-239.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" STARK H, OSKOUI P.High-Resolution Image Recovery from Image-Plane Arrays, Using Convex Projections.Journal of the Optical Society of America A, 1989, 6 (11) :1715-1726." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-resolution image recovery from image-plane arrays, using convex projections">
                                        <b>[11]</b>
                                         STARK H, OSKOUI P.High-Resolution Image Recovery from Image-Plane Arrays, Using Convex Projections.Journal of the Optical Society of America A, 1989, 6 (11) :1715-1726.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" SCHULTZ R R, STEVENSON R L.Improved Definition Video Frame Enhancement // Proc of the International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 1995, IV:2169-2172." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved Definition Video Frame Enhancement">
                                        <b>[12]</b>
                                         SCHULTZ R R, STEVENSON R L.Improved Definition Video Frame Enhancement // Proc of the International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 1995, IV:2169-2172.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" ELAD M, FEUER A.Restoration of a Single Superresolution Image from Several Blurred, Noisy, and Undersampled Measured Images.IEEE Transactions on Image Processing, 1997, 6 (12) :1646-1658." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Restoration of single superresolution image from several blurred, noisy, and undersampled measured images">
                                        <b>[13]</b>
                                         ELAD M, FEUER A.Restoration of a Single Superresolution Image from Several Blurred, Noisy, and Undersampled Measured Images.IEEE Transactions on Image Processing, 1997, 6 (12) :1646-1658.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" CHANG H, YEUNG D Y, XIONG Y M.Super-Resolution through Neighbor Embedding // Proc of the IEEE Computer Society Confe-rence on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2004, I:275-282." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Super-resolution throughneighbor embedding">
                                        <b>[14]</b>
                                         CHANG H, YEUNG D Y, XIONG Y M.Super-Resolution through Neighbor Embedding // Proc of the IEEE Computer Society Confe-rence on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2004, I:275-282.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" BEVILACQUA M, ROUMY A, GUILLEMOT C, &lt;i&gt;et al&lt;/i&gt;.Low-Complexity Single-Image Super-Resolution Based on Nonnegative Neigh-bor Embedding[C/OL].[2018-06-30].http://www.bmva.org/bmvc/2012/BMVC/paper135/abstract135.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low-Complexity Single-Image Super-Resolution based on Nonnegative Neighbor Embedding">
                                        <b>[15]</b>
                                         BEVILACQUA M, ROUMY A, GUILLEMOT C, &lt;i&gt;et al&lt;/i&gt;.Low-Complexity Single-Image Super-Resolution Based on Nonnegative Neigh-bor Embedding[C/OL].[2018-06-30].http://www.bmva.org/bmvc/2012/BMVC/paper135/abstract135.pdf.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" FAN W, YEUNG D Y.Image Hallucination Using Neighbor Embedding over Visual Primitive Manifolds // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2007.DOI:10.1109/CVPR.2007.383001." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image hallucination using neighbor embedding over visual primitive manifolds">
                                        <b>[16]</b>
                                         FAN W, YEUNG D Y.Image Hallucination Using Neighbor Embedding over Visual Primitive Manifolds // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2007.DOI:10.1109/CVPR.2007.383001.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     YANG J C, WRIGHT J, HUANG T S, &lt;i&gt;et al&lt;/i&gt;.Image Super-Resolution via Sparse Representation.IEEE Transactions on Image Processing, 2010, 19 (11) :2861-2873.</a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" ZEYDE R, ELAD M, PROTTER M.On Single Image Scale-Up Using Sparse-Representations // Proc of the International Confe-rence on Curves and Surfaces.Berlin, Germany:Springer, 2010:711-730." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On single image scale-up using sparse-representations">
                                        <b>[18]</b>
                                         ZEYDE R, ELAD M, PROTTER M.On Single Image Scale-Up Using Sparse-Representations // Proc of the International Confe-rence on Curves and Surfaces.Berlin, Germany:Springer, 2010:711-730.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" TIMOFTE R, DE SMET V, VAN GOOL L.Anchored Neighborhood Regression for Fast Example-Based Super-Resolution // Proc of the IEEE International Conference on Computer Vision.Wa-shington, USA:IEEE, 2013:1920-1927." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Anchored neighborhood regression for fast example-based super-resolution">
                                        <b>[19]</b>
                                         TIMOFTE R, DE SMET V, VAN GOOL L.Anchored Neighborhood Regression for Fast Example-Based Super-Resolution // Proc of the IEEE International Conference on Computer Vision.Wa-shington, USA:IEEE, 2013:1920-1927.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" DONG C, LOY C C, HE K M, &lt;i&gt;et al&lt;/i&gt;.Learning a Deep Convolutional Network for Image Super-Resolution // Proc of the European Conference on Computer Vision.Berlin, Germany:Springer, 2014:184-199." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning a deep convolutional network for image super-resolution">
                                        <b>[20]</b>
                                         DONG C, LOY C C, HE K M, &lt;i&gt;et al&lt;/i&gt;.Learning a Deep Convolutional Network for Image Super-Resolution // Proc of the European Conference on Computer Vision.Berlin, Germany:Springer, 2014:184-199.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" 肖进胜, 刘恩雨, 朱力, 等.改进的基于卷积神经网络的图像超分辨率算法.光学学报, 2017, 37 (3) :103-111. (XIAO J S, LIU E Y, ZHU L, &lt;i&gt;et al&lt;/i&gt;.Improved Image Super-Resolution Algorithm Based on Convolutional Neural Network.Acta Optica Sinica, 2017, 37 (3) :103-111.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201703012&amp;v=MjM4MTlQSWpYVGJMRzRIOWJNckk5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdVTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         肖进胜, 刘恩雨, 朱力, 等.改进的基于卷积神经网络的图像超分辨率算法.光学学报, 2017, 37 (3) :103-111. (XIAO J S, LIU E Y, ZHU L, &lt;i&gt;et al&lt;/i&gt;.Improved Image Super-Resolution Algorithm Based on Convolutional Neural Network.Acta Optica Sinica, 2017, 37 (3) :103-111.) 
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" 胡长胜, 詹曙, 吴从中.基于深度特征学习的图像超分辨率重建.自动化学报, 2017, 43 (5) :814-821. (HU C S, ZHAN S, WU C Z.Image Super-Resolution Based on Deep Learning Features.Acta Automatica Sinica, 2017, 43 (5) :814-821.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201705013&amp;v=MDMxNjBGckNVUkxPZVplUm5GeXpnVUx6UEtDTGZZYkc0SDliTXFvOUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         胡长胜, 詹曙, 吴从中.基于深度特征学习的图像超分辨率重建.自动化学报, 2017, 43 (5) :814-821. (HU C S, ZHAN S, WU C Z.Image Super-Resolution Based on Deep Learning Features.Acta Automatica Sinica, 2017, 43 (5) :814-821.) 
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" >
                                        <b>[23]</b>
                                     DONG C, LOY C C, TANG X O.Accelerating the Super-Resolution Convolutional Neural Network // Proc of the 14th European Conference on Computer Vision.Berlin, Germany:Springer, 2016:391-407.</a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" SHI W Z, CABALLERO J, HUSZ&#193;R F, &lt;i&gt;et al&lt;/i&gt;.Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:1874-1883." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network">
                                        <b>[24]</b>
                                         SHI W Z, CABALLERO J, HUSZ&#193;R F, &lt;i&gt;et al&lt;/i&gt;.Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:1874-1883.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" KIM J, LEE J K, LEE K M.Accurate Image Super-Resolution Using Very Deep Convolutional Networks // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:1646-1654." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accurate image super-resolution using very deep convolutional networks">
                                        <b>[25]</b>
                                         KIM J, LEE J K, LEE K M.Accurate Image Super-Resolution Using Very Deep Convolutional Networks // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:1646-1654.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" KIM J, LEE J K, LEE K M.Deeply-Recursive Convolutional Network for Image Super-Resolution // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washinton, USA:IEEE, 2016:1637-1645." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deeply-Recursive Convolutional Network for Image Super-Resolution">
                                        <b>[26]</b>
                                         KIM J, LEE J K, LEE K M.Deeply-Recursive Convolutional Network for Image Super-Resolution // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washinton, USA:IEEE, 2016:1637-1645.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title=" TAI Y, YANG J, LIU X M.Image Super-Resolution via Deep Recursive Residual Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:2790-2798." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution via deep recursive residual network">
                                        <b>[27]</b>
                                         TAI Y, YANG J, LIU X M.Image Super-Resolution via Deep Recursive Residual Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:2790-2798.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_28" title=" LAI W S, HUANG J B, AHUJA N, &lt;i&gt;et al&lt;/i&gt;.Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:5835-5843." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution">
                                        <b>[28]</b>
                                         LAI W S, HUANG J B, AHUJA N, &lt;i&gt;et al&lt;/i&gt;.Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:5835-5843.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_29" title=" ZHANG K, ZUO W M, ZHANG L.Learning a Single Convolutional Super-Resolution Network for Multiple Degradations // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:3262-3271." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning a Single Convolutional Super-Resolution Network for Multiple Degradations">
                                        <b>[29]</b>
                                         ZHANG K, ZUO W M, ZHANG L.Learning a Single Convolutional Super-Resolution Network for Multiple Degradations // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:3262-3271.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_30" title=" LEDIG C, THEIS L, HUSZ&#193;R F, &lt;i&gt;et al&lt;/i&gt;.Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:4681-4690." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Photo-realistic single image super-resolution using a generative adversarial network">
                                        <b>[30]</b>
                                         LEDIG C, THEIS L, HUSZ&#193;R F, &lt;i&gt;et al&lt;/i&gt;.Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:4681-4690.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_31" title=" 邵保泰, 汤心溢, 金璐, 等.基于生成对抗网络的单帧红外图像超分辨算法.红外与毫米波学报, 2018, 37 (4) :427-432. (SHAO B T, TANG X Y, JIN L, &lt;i&gt;et al&lt;/i&gt;.Single Frame Infrared Image Super-Resolution Algorithm Based on Generating Adversarial Nets.Journal of Infrared and Millimeter Waves, 2018, 37 (4) :427-432.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201804009&amp;v=MTA0MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdVTHpQTFRyU1pyRzRIOW5NcTQ5RmJZUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[31]</b>
                                         邵保泰, 汤心溢, 金璐, 等.基于生成对抗网络的单帧红外图像超分辨算法.红外与毫米波学报, 2018, 37 (4) :427-432. (SHAO B T, TANG X Y, JIN L, &lt;i&gt;et al&lt;/i&gt;.Single Frame Infrared Image Super-Resolution Algorithm Based on Generating Adversarial Nets.Journal of Infrared and Millimeter Waves, 2018, 37 (4) :427-432.) 
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_32" title=" 许少华, 路阳, 席海青, 等.样本先验知识在神经网络训练中的应用.大庆石油学院学报, 2004, 28 (6) :66-69, 114. (XU S H, LU Y, XI H Q, &lt;i&gt;et al&lt;/i&gt;.Application of Sample Prior Knowledge to Neural Network Training.Journal of Daqing Petroleum Institute, 2004, 28 (6) :66-69, 114.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQSY200406022&amp;v=MDY5MDhIdFhNcVk5SFpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdVTHpQSVR6WWQ3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[32]</b>
                                         许少华, 路阳, 席海青, 等.样本先验知识在神经网络训练中的应用.大庆石油学院学报, 2004, 28 (6) :66-69, 114. (XU S H, LU Y, XI H Q, &lt;i&gt;et al&lt;/i&gt;.Application of Sample Prior Knowledge to Neural Network Training.Journal of Daqing Petroleum Institute, 2004, 28 (6) :66-69, 114.) 
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_33" title=" 陈翀伟, 陈德钊, 叶向群, 等.基于先验知识的前馈网络对原油实沸点蒸馏曲线的仿真.高校化学工程学报, 2001, 4 (15) :351-356. (CHEN C W, CHEN D Z, YE X Q, &lt;i&gt;et al&lt;/i&gt;.Feedforward Network Based on Prior Knowledge and Its Application in Modeling the True Boiling Point Curve of the Crude Oil.Journal of Chemical Engineering of Chinese Universities, 2001, 4 (15) :351-356.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXHX200104008&amp;v=MjM2NDc0SHRETXE0OUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UElqWERkckc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[33]</b>
                                         陈翀伟, 陈德钊, 叶向群, 等.基于先验知识的前馈网络对原油实沸点蒸馏曲线的仿真.高校化学工程学报, 2001, 4 (15) :351-356. (CHEN C W, CHEN D Z, YE X Q, &lt;i&gt;et al&lt;/i&gt;.Feedforward Network Based on Prior Knowledge and Its Application in Modeling the True Boiling Point Curve of the Crude Oil.Journal of Chemical Engineering of Chinese Universities, 2001, 4 (15) :351-356.) 
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_34" title=" 吴媛媛, 何小海, 孙琰玥, 等.基于小波局部适应插值IBP算法的视频超分辨率重建.四川大学学报 (自然科学版) , 2011, 48 (2) :349-355. (WU Y Y, HE X H, SUN Y Y, &lt;i&gt;et al&lt;/i&gt;.Video Super-Resolution Reconstruction Based on Local-Adaptation Interpolation Wavelet Transform IBP Algorithm.Journal of Sichuan University (Natural Science Edition) , 2011, 48 (2) :349-355.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCDX201102021&amp;v=MTc1NDdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1VMelBOaTdQZHJHNEg5RE1yWTlIWllRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[34]</b>
                                         吴媛媛, 何小海, 孙琰玥, 等.基于小波局部适应插值IBP算法的视频超分辨率重建.四川大学学报 (自然科学版) , 2011, 48 (2) :349-355. (WU Y Y, HE X H, SUN Y Y, &lt;i&gt;et al&lt;/i&gt;.Video Super-Resolution Reconstruction Based on Local-Adaptation Interpolation Wavelet Transform IBP Algorithm.Journal of Sichuan University (Natural Science Edition) , 2011, 48 (2) :349-355.) 
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_35" title=" 王春霞, 苏红旗, 范郭亮.图像超分辨率重建技术综述.计算机技术与发展, 2011, 21 (5) :124-127. (WANG C X, SU H Q, FAN G L.Overview on Super Resolution Image Reconstruction.Computer Technology and Development, 2011, 21 (5) :124-127.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201105034&amp;v=MjYyOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UE1pZk5kTEc0SDlETXFvOUdZSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[35]</b>
                                         王春霞, 苏红旗, 范郭亮.图像超分辨率重建技术综述.计算机技术与发展, 2011, 21 (5) :124-127. (WANG C X, SU H Q, FAN G L.Overview on Super Resolution Image Reconstruction.Computer Technology and Development, 2011, 21 (5) :124-127.) 
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_36" title=" PASCANU R, MIKOLOV T, BENGIO Y.On the Difficulty of Training Recurrent Neural Networks // Proc of the 30th International Conference on Machine Learning.New York, USA:ACM, 2013, III:1310-1318." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the difficulty of training recurrent neural networks">
                                        <b>[36]</b>
                                         PASCANU R, MIKOLOV T, BENGIO Y.On the Difficulty of Training Recurrent Neural Networks // Proc of the 30th International Conference on Machine Learning.New York, USA:ACM, 2013, III:1310-1318.
                                    </a>
                                </li>
                                <li id="75">


                                    <a id="bibliography_37" title=" MARTIN D, FOWLKES C, TAL D, &lt;i&gt;et al&lt;/i&gt;.A Database of Human Segmented Natural Images and Its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics // Proc of the 8th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2001:416-423." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A database of human seg-mented natural images and its application to evaluating seg-mentation algorithms and measuring ecological statistics">
                                        <b>[37]</b>
                                         MARTIN D, FOWLKES C, TAL D, &lt;i&gt;et al&lt;/i&gt;.A Database of Human Segmented Natural Images and Its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics // Proc of the 8th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2001:416-423.
                                    </a>
                                </li>
                                <li id="77">


                                    <a id="bibliography_38" title=" 林顺达.Chen-Mobius变换在图像处理应用中的GUI实现.科技资讯, 2013 (36) :1-3. (LIN S D.The Realization of Image Processing on the Based of Chen-Mobius in GUI Interface.Science and Technology Information, 2013 (36) :1-3.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZXLJ201336002&amp;v=MDQzNTJPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdVTHpQUHpYSFpMRzRIOUxQcVk5RlpvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[38]</b>
                                         林顺达.Chen-Mobius变换在图像处理应用中的GUI实现.科技资讯, 2013 (36) :1-3. (LIN S D.The Realization of Image Processing on the Based of Chen-Mobius in GUI Interface.Science and Technology Information, 2013 (36) :1-3.) 
                                    </a>
                                </li>
                                <li id="79">


                                    <a id="bibliography_39" title=" LAI W S, HUANG J B, AHUJA N, &lt;i&gt;et al&lt;/i&gt;.Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks[J/OL].[2018-07-30].https://arxiv.org/pdf/1710.01992.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks">
                                        <b>[39]</b>
                                         LAI W S, HUANG J B, AHUJA N, &lt;i&gt;et al&lt;/i&gt;.Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks[J/OL].[2018-07-30].https://arxiv.org/pdf/1710.01992.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(04),353-360 DOI:10.16451/j.cnki.issn1003-6059.201904008            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度学习的芯片图像超分辨率重建</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8C%83%E6%98%8E%E6%98%8E&amp;code=41555412&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">范明明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%A0%E6%BA%90&amp;code=40135515&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">池源</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E9%93%AD%E6%B4%A5&amp;code=31549811&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张铭津</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E4%BA%91%E6%9D%BE&amp;code=10169332&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李云松</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%BB%BC%E5%90%88%E4%B8%9A%E5%8A%A1%E7%BD%91%E7%90%86%E8%AE%BA%E5%8F%8A%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0008505&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安电子科技大学综合业务网理论及关键技术国家重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B7%A5%E4%B8%9A%E5%92%8C%E4%BF%A1%E6%81%AF%E5%8C%96%E9%83%A8%E7%94%B5%E5%AD%90%E7%AC%AC%E4%BA%94%E7%A0%94%E7%A9%B6%E6%89%80%E7%94%B5%E5%AD%90%E5%85%83%E5%99%A8%E4%BB%B6%E5%8F%AF%E9%9D%A0%E6%80%A7%E7%89%A9%E7%90%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E6%8A%80%E6%9C%AF%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=1506162&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">工业和信息化部电子第五研究所电子元器件可靠性物理及其应用技术重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>考虑到卷积神经网络可以通过训练过程引入图像的先验知识, 文中提出基于深度学习的芯片图像超分辨率重建.利用卷积神经网络改善迭代反投影法的初始估计图像, 通过迭代过程引入图像序列间的互补信息, 建立芯片图像的样本集.实验表明, 在不同放大倍数下, 改进算法的客观评价指标平均值均较高, 在芯片图像中的电路密集处, 改进算法的主观视觉感受也较好.同时, 文中算法适用于自然图像.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E9%87%8D%E5%BB%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超分辨率重建;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%AD%E4%BB%A3%E5%8F%8D%E6%8A%95%E5%BD%B1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">迭代反投影;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%8A%AF%E7%89%87%E7%A1%AC%E4%BB%B6%E6%9C%A8%E9%A9%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">芯片硬件木马;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    范明明, 硕士研究生, 主要研究方向为图像处理、模式识别.E-mail:mmfanxidian@163.com.;
                                </span>
                                <span>
                                    池源, 博士, 工程师, 主要研究方向为集成电路设计、芯片可靠性、芯片安全性.E-mail:chiyuan4213@126.com.;
                                </span>
                                <span>
                                    *张铭津 (通讯作者) , 博士, 讲师, 主要研究方向为模式识别、人工智能.E-mail:mjinzhang@xidian.edu.cn.;
                                </span>
                                <span>
                                    李云松, 博士, 教授, 主要研究方向为图像处理、芯片设计、高性能计算.E-mai:ysli@mail.xidian.edu.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-07-30</p>

                    <p>

                            <b>基金：</b>
                                                        <span>陕西省自然科学基础研究计划一般项目 (No.2018JQ6028);</span>
                                <span>中央高校基本科研业务费项目 (No.XJS17109, JBX180102);</span>
                                <span>中国博士后科学基金面上资助项目 (No.2017M623125);</span>
                                <span>电子元器件可靠性物理及其应用技术重点实验室开放基金项目 (No.17D03-ZHD201701) 资助;</span>
                    </p>
            </div>
                    <h1><b>Chip Image Super-Resolution Reconstruction Based on Deep Learning</b></h1>
                    <h2>
                    <span>FAN Mingming</span>
                    <span>CHI Yuan</span>
                    <span>ZHANG Mingjin</span>
                    <span>LI Yunsong</span>
            </h2>
                    <h2>
                    <span>State Key Laboratory of Integrated Service Networks, Xidian University</span>
                    <span>Science and Technology on Reliability Physics and Application of Electronic Component Laboratory, the Fifth Electronics Research Institute of Ministry of Industry and Information Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Since the convolutional neural networks can introduce the prior knowledge of the chip image in the training stage, a chip image super-resolution algorithm is proposed. A convolutional neural network is utilized to improve the initial reconstruction image of the iterative method, the complementary information between image sequences is employed through an iterative process and a chip sample set is built. Experimental results show that the proposed method produces clearer chip images with close packing and yields higher average values of the objective evaluation indicators. Furthermore, the proposed algorithm performs well on nature images.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Super-Resolution%20Reconstruction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Super-Resolution Reconstruction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20Neural%20Network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional Neural Network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Iterative%20Back%20Projection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Iterative Back Projection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Chip%20Hardware%20Trojan&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Chip Hardware Trojan;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    FAN Mingming, master student. Her research interests include image processing and pattern recognition.;
                                </span>
                                <span>
                                    CHI Yuan, Ph.D., engineer. His research interests include integrated circuits design, chip reliability and chip security.;
                                </span>
                                <span>
                                    ZHANG Mingjin ( Corresponding author) , Ph. D., lecturer. Her research interests include pattern recognition and artificial intelligence.;
                                </span>
                                <span>
                                    LI Yunsong, Ph. D., professor. His research interests include image processing, chip design and high performance computing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-07-30</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by Natural Science Plan Basic Research in Shaanxi Province of China (No.2018JQ6028);</span>
                                <span>Fundamental Research Funds for the Central Universities (No.XJS17109, JBX180102);</span>
                                <span>Chinese Postdoctoral Science Foundation (No.2017M623125);</span>
                                <span>Open Fund for Key Laboratory of Reliability Physics and Its Application of Technology Electronical Component (No.17D03-ZHD201701);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="89">目前我国的半导体行业中关键部分的高端芯片仍依赖于进口, 我国集成电路设计和制造工艺技术并不完善, 所以在芯片设计和生产环节引入的硬件木马问题不容忽视, 硬件木马<citation id="183" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>指的是潜伏在原始电路中的微小恶意电路, 在特殊条件下触发, 可以改变电路功能, 导致信息泄露甚至摧毁系统的严重后果.因此, 硬件木马的检测尤为重要.目前, 已有基于反向解剖、功能检测和旁路分析等多种检测技术<citation id="184" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 其中, 高效的检测手段是基于芯片反向解剖的检测技术<citation id="185" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 即将高倍显微镜拍摄的芯片照片与母版微观图片进行相同的切割并对比, 若有元器件和金属线被改动, 说明存在恶意植入的硬件木马.这种技术检验彻底, 正检率较高<citation id="186" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.然而, 拍摄高分辨率的芯片图像时存在诸多干扰因素, 获取的图像分辨率较低, 因此提升图像的分辨率, 在不提高拍摄成本的同时确保检测的正确率, 是当前硬件木马检测的重要研究问题.</p>
                </div>
                <div class="p1">
                    <p id="90">针对这个问题, 通常需要使用图像超分辨率 (Super-Resolution, SR) 重建技术<citation id="187" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>.SR重建技术是运用软件算法处理一幅或多幅低分辨率 (Low-Resolution, LR) 图像, 最终重建一幅高分辨率 (High-Resolution, HR) 图像的技术.从研究方法上, SR技术可分为基于插值的方法<citation id="188" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>、基于重建的方法<citation id="189" type="reference"><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>和基于学习的方法<citation id="190" type="reference"><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>.基于插值的方法普遍存在明显的锯齿效应.基于重建的方法虽然考虑到图像的退化模型, 并结合图像的先验知识, 性能得到较大改善, 但是应用于芯片图像时效果不佳.基于学习的方法的主要思想是学习LR图像和HR图像之间的对应关系.</p>
                </div>
                <div class="p1">
                    <p id="91">随着机器学习的兴起, 出现基于深度学习的超分辨率重建算法<citation id="200" type="reference"><link href="41" rel="bibliography" /><link href="43" rel="bibliography" /><link href="45" rel="bibliography" /><link href="47" rel="bibliography" /><link href="49" rel="bibliography" /><link href="51" rel="bibliography" /><link href="53" rel="bibliography" /><link href="55" rel="bibliography" /><link href="57" rel="bibliography" /><link href="59" rel="bibliography" /><link href="61" rel="bibliography" /><link href="63" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>,<a class="sup">24</a>,<a class="sup">25</a>,<a class="sup">26</a>,<a class="sup">27</a>,<a class="sup">28</a>,<a class="sup">29</a>,<a class="sup">30</a>,<a class="sup">31</a>]</sup></citation>.Dong等<citation id="191" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出SRCNN (Super-Resolution Convolutional Neural Network) , 仅利用三层卷积神经网络模拟非线性映射, 感受野大小受到限制, 高频细节仍较平滑, 需训练的参数过多, 训练难度较大.文献<citation id="192" type="reference">[<a class="sup">21</a>]</citation>～文献<citation id="193" type="reference">[<a class="sup">23</a>]</citation>改进SRCNN.Shi等<citation id="194" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>提出ESPCN (Efficient Sub-pixel Convolutional Neural Network) , 可避免在较高的分辨率上进行卷积操作, 提高卷积效率.Kim等<citation id="195" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>提出VDSR (Very Deep Super-Resolution) , 在训练时只学习LR、HR图像之间的高频残差, 训练网络收敛速度更快.此外, DRCN (Deeply-Recursive Convolutional Network) <citation id="196" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>和DRRN (Deep Recursive Residual Network) <citation id="197" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>也借鉴残差学习的思想.LapSRN (Laplacian Pyramid Super-Resolution Networks) <citation id="198" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>改进拉普拉斯金字塔结构.Zhang等<citation id="199" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>提出将模糊核和噪声水平作为网络输入的维度拉伸策略, 有效处理多种图像退化类型.最近, 在超分辨率重建领域中引入生成对抗式网络<citation id="201" type="reference"><link href="61" rel="bibliography" /><link href="63" rel="bibliography" /><sup>[<a class="sup">30</a>,<a class="sup">31</a>]</sup></citation>, 更注重图像整体结构的相似, 所以重建图像视觉效果较逼真.</p>
                </div>
                <div class="p1">
                    <p id="92">虽然在处理普通自然图像时, 基于深度学习的方法性能表现较优, 但在重建由密集电路组成的芯片图像时, 并不能较好处理图像的细节部分.于是, 本文提出基于深度学习的芯片图像超分辨率重建算法, 结合卷积神经网络和迭代反投影法<citation id="202" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 利用基于卷积神经网络的超分辨率重建算法进一步重建迭代反投影法中利用插值法得到的初始估计图像, 提高最终的重建效果.该算法既引入深度学习的先验知识, 又利用低分辨率图像序列之间的互补信息.实验表明, 本文算法的性能具有明显提升.</p>
                </div>
                <h3 id="93" name="93" class="anchor-tag">1 基于深度学习的芯片图像超分辨率重建算法</h3>
                <h4 class="anchor-tag" id="94" name="94"><b>1.1</b> 网络结构</h4>
                <div class="p1">
                    <p id="95">迭代反投影法中最终的重建图像与初始估计图像密切相关, 一般地, 由输入的LR图像经过插值 (双立方插值法等) 得到HR初始估计图像, 而传统的插值算法原理简单, 存在边缘模糊和锯齿现象, 初始估计图像较差, 限制算法的重建效果.</p>
                </div>
                <div class="p1">
                    <p id="96">基于卷积神经网络的算法依赖网络训练时选择的样本集, 忽略待重建图像本身可利用的信息, 如果训练的样本集任意大, 训练所得的网络可以以任意精度逼近任何分段可微的连续函数<citation id="203" type="reference"><link href="65" rel="bibliography" /><link href="67" rel="bibliography" /><sup>[<a class="sup">32</a>,<a class="sup">33</a>]</sup></citation>.但是实际选择的样本集总是有限的, 又往往带有噪声, 由此训练的模型不能准确预测原模型, 甚至出现违背先验知识的情况.迭代反投影法恰好可利用低分辨率图像序列间的相似性、冗余性.</p>
                </div>
                <div class="p1">
                    <p id="97">本文提出结合迭代反投影法与卷积神经网络的算法, 网络结构如图1所示, 其中虚框内为卷积神经网络模块的网络结构.</p>
                </div>
                <div class="p1">
                    <p id="98">首先, 从<i>K</i>幅原始的低分辨率图像{<i>x</i><sub><i>k</i></sub>}中选择其中一幅作为参考图像<i>x</i><sub>0</sub>, 估计LR图像序列{<i>x</i><sub><i>k</i></sub>}与参考图像<i>x</i><sub>0</sub>的子像素位移量{ (<i>a</i><sub>0</sub>, <i>b</i><sub>0</sub>) <sub><i>k</i></sub>}.然后使用双立方插值法对参考图像<i>x</i><sub>0</sub>进行<i>L</i>倍上采样处理, 得到内插后的低分辨率图像<i>x</i>.将图像<i>x</i>输入卷积神经网络模块, 经过20层卷积层后输出预测的残差图像<i>f</i> (<i>x</i>) , 将<i>f</i> (<i>x</i>) +<i>x</i>作为迭代反投影法的初始估计图像<i>y</i><sup>0</sup>.再根据LR图像序列间的位移量{ (<i>a</i><sub>0</sub>, <i>b</i><sub>0</sub>) <sub><i>k</i></sub>}和参数<i>L</i>对初始估计图像进行降质, 得到模拟LR图像序列{<i>x</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mn>0</mn></msubsup></mrow></math></mathml>}.若输入的LR图像序列和模拟的LR图像序列相同, 初始估计图像就是得到的重建HR图像, 否则, 将模拟误差{ (<i>x</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mn>0</mn></msubsup></mrow></math></mathml>-<i>x</i><sub><i>k</i></sub>) }结合反投影算子<i>H</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mi>B</mi><mi>Ρ</mi></mrow></msubsup></mrow></math></mathml>投影到初始估计图像上, 使重建图像更接近原始图像, 选取的反投影算子<i>H</i><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mrow><mi>B</mi><mi>Ρ</mi></mrow></msubsup></mrow></math></mathml>为图像退化的逆操作.</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法的网络结构" src="Detail/GetImg?filename=images/MSSB201904010_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法的网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Network structure of the proposed algorithm</p>

                </div>
                <div class="p1">
                    <p id="105">将上述过程循环迭代, <i>n</i>表示迭代次数, 每迭代一次<i>n</i>值加1, 当迭代<i>n</i>次后误差函数<i>ε</i>小于设定阈值, 则输出当前的高分辨率重建图像<i>y</i><sup><i>n</i>+1</sup>, 误差函数<citation id="204" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>为</p>
                </div>
                <div class="p1">
                    <p id="106"><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><mo>=</mo><mfrac><mrow><mrow><mrow><mo>|</mo><mrow><mi>y</mi><msup><mrow></mrow><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi>y</mi><msup><mrow></mrow><mi>n</mi></msup></mrow><mo>|</mo></mrow></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mrow><mrow><mo>|</mo><mrow><mi>y</mi><msup><mrow></mrow><mi>n</mi></msup></mrow><mo>|</mo></mrow></mrow><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow></math></mathml>.</p>
                </div>
                <h4 class="anchor-tag" id="108" name="108"><b>1.2</b> 卷积神经网络模块</h4>
                <div class="p1">
                    <p id="109">基于深度学习的图像超分辨重建可从大量的训练样本数据集中获得较多先验知识<citation id="205" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>, 而芯片中包含的元器件和金属线等结构呈现在图像时又很相似, 所以考虑采用基于卷积神经网络的方法重建图像, 当输入芯片图像时, 利用训练后得到的先验知识对图像的高频细节进行补充.</p>
                </div>
                <div class="p1">
                    <p id="110">SRCNN<citation id="206" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>仅利用3个卷积层, 实现从低分辨率图像到高分辨率图像的端到端映射, 但仍存在局限性:感受野较小, 用于恢复细节部分的信息不足;参数训练难度较大, 训练收敛较慢;网络只能用于一种尺度因子.Kim等<citation id="207" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>针对上述问题进行改进, 增加网络的深度 (20层) , 有助于学习更本质的图像特征, 感受野随网络层数的加深而增大, 各层卷积核大小均为3×3, 故深度为<i>D</i>的网络的感受野为 (2<i>D</i>+1) × (2<i>D</i>+1) .感受野增大, 可根据更多信息推断目标像素点.图像每经历一次卷积操作, 输出的特征映射大小都会缩小, 于是采用零填充的方法.为了加快网络的收敛速度, 提高初始学习率, 而且由于LR图像的低频信息和HR图像的低频信息相近, 故仅学习两者的高频残差.采用自适应梯度裁剪的方法<citation id="208" type="reference"><link href="73" rel="bibliography" /><sup>[<a class="sup">36</a>]</sup></citation>避免因学习率的增大导致梯度爆炸.最后将不同尺度因子的图像混合训练, 训练的模型可对LR图像进行不同倍数的超分辨率重建.卷积神经网络模块的网络结构如图2所示.</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 卷积神经网络模块的网络结构" src="Detail/GetImg?filename=images/MSSB201904010_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 卷积神经网络模块的网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Network structure of convolutional neural network module</p>

                </div>
                <div class="p1">
                    <p id="113">将高分辨率图像进行降质处理后, 得到低分辨率图像, 再将低分辨率图像使用双立方插值法进行内插, 将高分辨率图像和内插后的低分辨率图像两两配对作为训练样本.使用<i>y</i>表示高分辨率图像, <i>x</i>表示内插后的低分辨率图像, 给定训练样本集{<i>x</i><sup> (<i>i</i>) </sup>, <i>y</i><sup> (<i>i</i>) </sup>}<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>, 定义一个残差图像<i>r</i>=<i>y</i>-<i>x</i>, 目的是使网络预测的残差图像<i>f</i> (<i>x</i>) 与真实的残差图像<i>r</i>尽可能接近, 故最小化的目标是<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>|</mo><mrow><mi>r</mi><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>, 定义损失函数:</p>
                </div>
                <div class="p1">
                    <p id="116"><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>r</mi><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>.</p>
                </div>
                <h3 id="118" name="118" class="anchor-tag">2 实验及结果分析</h3>
                <div class="p1">
                    <p id="119">本文算法主要针对芯片的低分辨率图像, 共收集77幅芯片图像样本.为了验证本文算法同样适用于自然图像, 对文献<citation id="209" type="reference">[<a class="sup">17</a>]</citation>使用过的91幅图像数据集和Martin等<citation id="210" type="reference"><link href="75" rel="bibliography" /><sup>[<a class="sup">37</a>]</sup></citation>建立的200幅图像的数据集进行训练, 图3为样本集中的部分芯片图像.此外, 为了增加样本数量, 将样本集中的图像进行不同角度的旋转和不同倍数的下采样.</p>
                </div>
                <div class="area_img" id="120">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 样本集中的芯片示例图像" src="Detail/GetImg?filename=images/MSSB201904010_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 样本集中的芯片示例图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_120.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Sample image of chip in sample set</p>

                </div>
                <div class="p1">
                    <p id="121">卷积神经网络共有20层卷积层, 第1层和第20层采用3×3×64的卷积核, 其它层采用64×3×3×64的卷积核, 训练的批尺寸为32, 动量参数为0.9, 权重衰减参数为0.000 1.</p>
                </div>
                <div class="p1">
                    <p id="122">为了衡量本文算法的重建性能, 需要制定一个统一的评价机制.图像质量的评价指标分为2类:主观评价和客观评价.主观评价是人眼对图像直接观察, 凭借主观意识对图像的优劣进行评分, 客观评价是依据模型给出的量化指标, 模拟人类视觉系统衡量图像质量<citation id="211" type="reference"><link href="77" rel="bibliography" /><sup>[<a class="sup">38</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="123">采用主观视觉感受及峰值信噪比 (Peak Sig-nal-to-Noise Ratio, PSNR) 和结构相似度 (Structu-ral Similarity Index, SSIM) 两个客观评价指标评价本文算法.PSNR在像素级别上对图像质量进行评价, 值越大, 说明重建效果越好.SSIM更注重图像整体结构的相似性, 值在0～1之间, 同样是值越大越好.</p>
                </div>
                <div class="p1">
                    <p id="124">为了模拟迭代反投影法输入的LR图像序列, 首先对HR图像进行子像素位移, 再使用双立方插值法进行下采样处理, 将生成的序列作为原始LR图像序列.为了便于对比, 对比算法也采用双立方插值法进行下采样.本文选择双立方插值法<citation id="212" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、SRCNN<citation id="213" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、VDSR<citation id="214" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>和MSLapSRN<citation id="215" type="reference"><link href="79" rel="bibliography" /><sup>[<a class="sup">39</a>]</sup></citation>为对比算法.对8幅芯片图像分别进行2倍、3倍和4倍的超分辨率重建, 将峰值信噪比的平均值记录在表1中, 将结构相似度的平均值记录在表2中.</p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表1 5种算法对芯片图像重建的峰值信噪比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 PSNR of chip image reconstruction by 5 algorithms </p>
                    <p class="img_note">dB</p>
                    <table id="125" border="1"><tr><td>倍数</td><td>双立方<br />插值法</td><td>SRCNN</td><td>VDSR</td><td>MSLapSRN</td><td>本文算法</td></tr><tr><td><br />2</td><td>23.0477</td><td>24.9451</td><td>28.1731</td><td>26.4008</td><td>30.7317</td></tr><tr><td><br />3</td><td>21.4563</td><td>22.7378</td><td>25.7636</td><td>24.2473</td><td>28.2861</td></tr><tr><td><br />4</td><td>20.6090</td><td>21.4421</td><td>23.9097</td><td>23.0461</td><td>27.0847</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit"><b>表2 5种算法对芯片图像重建的结构相似度</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 SSIM of chip image reconstruction by 5 algorithms</p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td>倍数</td><td>双立方<br />插值法</td><td>SRCNN</td><td>VDSR</td><td>MSLapSRN</td><td>本文算法</td></tr><tr><td><br />2</td><td>0.5964</td><td>0.6862</td><td>0.7673</td><td>0.7064</td><td>0.9015</td></tr><tr><td><br />3</td><td>0.4721</td><td>0.5514</td><td>0.6596</td><td>0.5897</td><td>0.8567</td></tr><tr><td><br />4</td><td>0.4042</td><td>0.4668</td><td>0.5743</td><td>0.5215</td><td>0.8305</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="127">从两个客观评价指标上看, 双立方插值法的表现最差, 不同重建倍数下, 客观评价指标平均值均最低.SRCNN的指标平均值略高于双立方插值法.VDSR在重建倍数为2时的峰值信噪比较高, 但结构相似度相对较低, 原因是重建图像与原始图像在整体结构上的相似度不高.MSLapSRN (Multi-scale Laplacian Pyramid Super-Resolution Networks) 在重建自然图像时性能较优, 但在重建芯片图像时评价指标低于VDSR.本文算法的客观评价指标均最佳, 重建性能也有明显提高.</p>
                </div>
                <div class="p1">
                    <p id="128">再在测试图像中选择3幅图像, 并截取这3幅图像的重建图像中电路密集的关键位置, 以重建倍数为3时的结果为例.通过对比, 直观感受各算法的重建性能差异, 芯片图像重建效果图如图4～图6所示.</p>
                </div>
                <div class="area_img" id="224">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 芯片图像重建效果图1" src="Detail/GetImg?filename=images/MSSB201904010_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 芯片图像重建效果图1  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Chip image reconstruction rendering 1</p>

                </div>
                <div class="area_img" id="224">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_22401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 芯片图像重建效果图1" src="Detail/GetImg?filename=images/MSSB201904010_22401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 芯片图像重建效果图1  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_22401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Chip image reconstruction rendering 1</p>

                </div>
                <div class="area_img" id="225">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_22500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 芯片图像重建效果图2" src="Detail/GetImg?filename=images/MSSB201904010_22500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 芯片图像重建效果图2  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_22500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Chip image reconstruction rendering 2</p>

                </div>
                <div class="area_img" id="225">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_22501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 芯片图像重建效果图2" src="Detail/GetImg?filename=images/MSSB201904010_22501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 芯片图像重建效果图2  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_22501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Chip image reconstruction rendering 2</p>

                </div>
                <div class="area_img" id="226">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_22600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 芯片图像重建效果图3" src="Detail/GetImg?filename=images/MSSB201904010_22600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 芯片图像重建效果图3  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_22600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Chip image reconstruction rendering 3</p>

                </div>
                <div class="p1">
                    <p id="161">3幅芯片局部图像都是电路密集区域, 是可能存在硬件木马的关键位置, 重点对这种位置的图像进行超分辨率重建.双立方插值法重建的3幅图像主观感受非常模糊, VDSR得到的图像电路线条亮度最高且不存在明显的边缘模糊的问题, 整体效果类似于进行图像增强处理, 故视觉效果较好, 但它出现3个致命的问题:</p>
                </div>
                <div class="p1">
                    <p id="162">1) 当多条线路并列时, 重建图像呈现平滑的片状结构, 无法分辨电路结构, 如图4 (d) .</p>
                </div>
                <div class="p1">
                    <p id="163">2) 芯片中的部分电路重建效果清晰, 另一部分相对模糊, 如图5 (d) .</p>
                </div>
                <div class="p1">
                    <p id="164">3) 当出现图6 (a) 中一条长线下紧密并列一条短线的情况, 重建图像中的长线会从中间中断并连接短线, 如图6 (d) .</p>
                </div>
                <div class="p1">
                    <p id="165">从图中可看出, SRCNN和MSLapSRN也存在同样问题, 这些问题不利于芯片硬件木马的排查工作, 而本文算法的重建图像在电路密集处仍能清晰看出电路的条数和结构, 较好解决上述问题.</p>
                </div>
                <div class="p1">
                    <p id="166">另外, 本文算法用于自然图像时也取得较好效果.下面选择1幅自然图像进行对比实验, 测试结果如图7所示.</p>
                </div>
                <div class="area_img" id="227">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_22700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 自然图像的重建效果图" src="Detail/GetImg?filename=images/MSSB201904010_22700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 自然图像的重建效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_22700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Natural image reconstruction rendering</p>

                </div>
                <div class="area_img" id="227">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201904010_22701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 自然图像的重建效果图" src="Detail/GetImg?filename=images/MSSB201904010_22701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 自然图像的重建效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201904010_22701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Natural image reconstruction rendering</p>

                </div>
                <div class="p1">
                    <p id="180">从重建效果图可得, 双立方插值法的重建结果存在明显的锯齿效应, 如图7 (b) .SRCNN重建“栏杆”效果尚可, 但重建的“墙体”部分较模糊, 如 (c) .VDSR重建图像的细节较平滑, 故“栏杆”部分的主观感受较模糊, 但边缘处不存在明显的边缘效应, 如 (d) .MSLapSRN的边缘处重建效果在5种算法里最佳, 但“栏杆”处同样存在图像细节平滑的问题, 如 (e) .本文算法重建的线条等细节部分及边缘处都清晰和生动, 如 (f) .综上所述, 本文算法同样提升自然图像的重建性能.</p>
                </div>
                <h3 id="181" name="181" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="182">本文提出结合迭代反投影法的迭代思想和卷积神经网络的算法, 既可通过大量训练样本集引入图像的先验知识, 又可利用输入图像序列间的互补信息, 为了解决芯片低分辨率图像的超分辨率重建问题, 建立新的芯片图像的样本集.为了测试本文算法的重建性能, 进行一系列实验, 并对比4种原有算法, 一方面凭主观视觉感受评定重建图像的优劣, 另一方面使用峰值信噪比和结构相似度客观评估重建性能.实验验证表明, 本文算法可以更好地重建芯片图像中易于出现硬件木马的密集电路处的图像, 对自然图像也有较好的重建效果.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="220" type="formula" href="images/MSSB201904010_22000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">范明明</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="221" type="formula" href="images/MSSB201904010_22100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">池源</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="222" type="formula" href="images/MSSB201904010_22200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">张铭津</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="223" type="formula" href="images/MSSB201904010_22300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">李云松</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SZTX201401016&amp;v=MTU1ODVMT2VaZVJuRnl6Z1VMelBOamZmZHJHNEg5WE1ybzlFWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 倪林, 李少青, 马瑞聪, 等.硬件木马检测与防护.数字通信, 2014, 41 (1) :59-63, 68. (NI L, LI S Q, MA R C, <i>et al</i>.Hardware Trojans Detection and Protection.Digital Communication, 2014, 41 (1) :59-63, 68.) 
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXAQ201704001&amp;v=MjQ5OTJPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdVTHpQTWpYS2Y3RzRIOWJNcTQ5RlpZUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 许强, 蒋兴浩, 姚立红, 等.硬件木马检测与防范研究综述.网络与信息安全学报, 2017, 3 (4) :DOI:10.11959/j.issn.2096-109x.2017.00160. (XU Q, JIANG X H, YAO L H, <i>et al</i>.Overview of the Detection and Prevention Study of Hardware Trojans.Chinese Journal of Network and Information Security, 2017, 3 (4) :DOI:10.11959/j.issn.2096-109x.2017.00160.) 
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXAQ201709001&amp;v=MTY2MjFqWEtmN0c0SDliTXBvOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UE0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 王侃, 陈浩, 管旭光, 等.硬件木马防护技术研究.网络与信息安全学报, 2017, 3 (9) :DOI:10.11959/j.issn.2096-109x.2017.00197. (WANG K, CHEN H, GUAN X G, <i>et al</i>.Research on Hardware Trojan Defense.Chinese Journal of Network and Information Security, 2017, 3 (9) :DOI:10.11959/j.issn.2096-109x.2017.00197.) 
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201308005&amp;v=MDk4MTVxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdVTHpQS0NMZlliRzRIOUxNcDQ5RllZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 苏衡, 周杰, 张志浩.超分辨率图像重建方法综述.自动化学报, 2013, 39 (8) :1202-1213. (SU H, ZHOU J, ZHANG Z H.Survey of Super-Resolution Image Reconstruction Methods.Acta Automatica Sinica, 2013, 39 (8) :1202-1213.) 
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Bayesian approach to image expansion for improved definition">

                                <b>[5]</b> SCHULTZ R R, STEVENSON R L.A Bayesian Approach to Image Expansion for Improved Definition.IEEE Transactions on Image Processing, 1994, 3 (3) :233-242.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cubic splines for image interpolation and digital filtering">

                                <b>[6]</b> HOU H, ANDREWS H.Cubic Splines for Image Interpolation and Digital Filtering.IEEE Transactions on Acoustics, Speech, and Signal Processing, 1978, 26 (6) :508-517.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=New edge-directed interpolation">

                                <b>[7]</b> LI X, ORCHARD M T.New Edge-Directed Interpolation.IEEE Transactions on Image Processing, 2001, 10 (10) :1521-1527.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A New Orientation-Adaptive Interpolation Method">

                                <b>[8]</b> WANG Q, WARD R K.A New Orientation-Adaptive Interpolation Method.IEEE Transactions on Image Processing, 2007, 16 (4) :889-900.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiframe image restoration and registration">

                                <b>[9]</b> HUANG T S, TSAI R Y.Multiframe Image Restoration and Registration // HUANG T S, ed.Advances in Computer Vision and Image Processing.London, UK:JAI Press, 1984:317-339.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving resolution by image registration">

                                <b>[10]</b> IRANI M, PELEG S.Improving Resolution by Image Registration.CVGIP:Graphical Models and Image Processing, 1991, 53 (3) :231-239.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-resolution image recovery from image-plane arrays, using convex projections">

                                <b>[11]</b> STARK H, OSKOUI P.High-Resolution Image Recovery from Image-Plane Arrays, Using Convex Projections.Journal of the Optical Society of America A, 1989, 6 (11) :1715-1726.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved Definition Video Frame Enhancement">

                                <b>[12]</b> SCHULTZ R R, STEVENSON R L.Improved Definition Video Frame Enhancement // Proc of the International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 1995, IV:2169-2172.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Restoration of single superresolution image from several blurred, noisy, and undersampled measured images">

                                <b>[13]</b> ELAD M, FEUER A.Restoration of a Single Superresolution Image from Several Blurred, Noisy, and Undersampled Measured Images.IEEE Transactions on Image Processing, 1997, 6 (12) :1646-1658.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Super-resolution throughneighbor embedding">

                                <b>[14]</b> CHANG H, YEUNG D Y, XIONG Y M.Super-Resolution through Neighbor Embedding // Proc of the IEEE Computer Society Confe-rence on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2004, I:275-282.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low-Complexity Single-Image Super-Resolution based on Nonnegative Neighbor Embedding">

                                <b>[15]</b> BEVILACQUA M, ROUMY A, GUILLEMOT C, <i>et al</i>.Low-Complexity Single-Image Super-Resolution Based on Nonnegative Neigh-bor Embedding[C/OL].[2018-06-30].http://www.bmva.org/bmvc/2012/BMVC/paper135/abstract135.pdf.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image hallucination using neighbor embedding over visual primitive manifolds">

                                <b>[16]</b> FAN W, YEUNG D Y.Image Hallucination Using Neighbor Embedding over Visual Primitive Manifolds // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2007.DOI:10.1109/CVPR.2007.383001.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 YANG J C, WRIGHT J, HUANG T S, <i>et al</i>.Image Super-Resolution via Sparse Representation.IEEE Transactions on Image Processing, 2010, 19 (11) :2861-2873.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On single image scale-up using sparse-representations">

                                <b>[18]</b> ZEYDE R, ELAD M, PROTTER M.On Single Image Scale-Up Using Sparse-Representations // Proc of the International Confe-rence on Curves and Surfaces.Berlin, Germany:Springer, 2010:711-730.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Anchored neighborhood regression for fast example-based super-resolution">

                                <b>[19]</b> TIMOFTE R, DE SMET V, VAN GOOL L.Anchored Neighborhood Regression for Fast Example-Based Super-Resolution // Proc of the IEEE International Conference on Computer Vision.Wa-shington, USA:IEEE, 2013:1920-1927.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning a deep convolutional network for image super-resolution">

                                <b>[20]</b> DONG C, LOY C C, HE K M, <i>et al</i>.Learning a Deep Convolutional Network for Image Super-Resolution // Proc of the European Conference on Computer Vision.Berlin, Germany:Springer, 2014:184-199.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXXB201703012&amp;v=MjY3MTBiTXJJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UElqWFRiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 肖进胜, 刘恩雨, 朱力, 等.改进的基于卷积神经网络的图像超分辨率算法.光学学报, 2017, 37 (3) :103-111. (XIAO J S, LIU E Y, ZHU L, <i>et al</i>.Improved Image Super-Resolution Algorithm Based on Convolutional Neural Network.Acta Optica Sinica, 2017, 37 (3) :103-111.) 
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201705013&amp;v=MDU5MDlqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdVTHpQS0NMZlliRzRIOWJNcW85RVo0UUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 胡长胜, 詹曙, 吴从中.基于深度特征学习的图像超分辨率重建.自动化学报, 2017, 43 (5) :814-821. (HU C S, ZHAN S, WU C Z.Image Super-Resolution Based on Deep Learning Features.Acta Automatica Sinica, 2017, 43 (5) :814-821.) 
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" >
                                    <b>[23]</b>
                                 DONG C, LOY C C, TANG X O.Accelerating the Super-Resolution Convolutional Neural Network // Proc of the 14th European Conference on Computer Vision.Berlin, Germany:Springer, 2016:391-407.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network">

                                <b>[24]</b> SHI W Z, CABALLERO J, HUSZÁR F, <i>et al</i>.Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:1874-1883.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accurate image super-resolution using very deep convolutional networks">

                                <b>[25]</b> KIM J, LEE J K, LEE K M.Accurate Image Super-Resolution Using Very Deep Convolutional Networks // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:1646-1654.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deeply-Recursive Convolutional Network for Image Super-Resolution">

                                <b>[26]</b> KIM J, LEE J K, LEE K M.Deeply-Recursive Convolutional Network for Image Super-Resolution // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washinton, USA:IEEE, 2016:1637-1645.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution via deep recursive residual network">

                                <b>[27]</b> TAI Y, YANG J, LIU X M.Image Super-Resolution via Deep Recursive Residual Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:2790-2798.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution">

                                <b>[28]</b> LAI W S, HUANG J B, AHUJA N, <i>et al</i>.Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:5835-5843.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning a Single Convolutional Super-Resolution Network for Multiple Degradations">

                                <b>[29]</b> ZHANG K, ZUO W M, ZHANG L.Learning a Single Convolutional Super-Resolution Network for Multiple Degradations // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2017:3262-3271.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Photo-realistic single image super-resolution using a generative adversarial network">

                                <b>[30]</b> LEDIG C, THEIS L, HUSZÁR F, <i>et al</i>.Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:4681-4690.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_31" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HWYH201804009&amp;v=MDI2NDRackc0SDluTXE0OUZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UExUclM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[31]</b> 邵保泰, 汤心溢, 金璐, 等.基于生成对抗网络的单帧红外图像超分辨算法.红外与毫米波学报, 2018, 37 (4) :427-432. (SHAO B T, TANG X Y, JIN L, <i>et al</i>.Single Frame Infrared Image Super-Resolution Algorithm Based on Generating Adversarial Nets.Journal of Infrared and Millimeter Waves, 2018, 37 (4) :427-432.) 
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_32" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DQSY200406022&amp;v=MjI4MDFUellkN0c0SHRYTXFZOUhab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UEk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[32]</b> 许少华, 路阳, 席海青, 等.样本先验知识在神经网络训练中的应用.大庆石油学院学报, 2004, 28 (6) :66-69, 114. (XU S H, LU Y, XI H Q, <i>et al</i>.Application of Sample Prior Knowledge to Neural Network Training.Journal of Daqing Petroleum Institute, 2004, 28 (6) :66-69, 114.) 
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_33" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXHX200104008&amp;v=MTYwMzJxNDlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1VMelBJalhEZHJHNEh0RE0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[33]</b> 陈翀伟, 陈德钊, 叶向群, 等.基于先验知识的前馈网络对原油实沸点蒸馏曲线的仿真.高校化学工程学报, 2001, 4 (15) :351-356. (CHEN C W, CHEN D Z, YE X Q, <i>et al</i>.Feedforward Network Based on Prior Knowledge and Its Application in Modeling the True Boiling Point Curve of the Crude Oil.Journal of Chemical Engineering of Chinese Universities, 2001, 4 (15) :351-356.) 
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_34" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SCDX201102021&amp;v=MzA0ODRkckc0SDlETXJZOUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVUx6UE5pN1A=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[34]</b> 吴媛媛, 何小海, 孙琰玥, 等.基于小波局部适应插值IBP算法的视频超分辨率重建.四川大学学报 (自然科学版) , 2011, 48 (2) :349-355. (WU Y Y, HE X H, SUN Y Y, <i>et al</i>.Video Super-Resolution Reconstruction Based on Local-Adaptation Interpolation Wavelet Transform IBP Algorithm.Journal of Sichuan University (Natural Science Edition) , 2011, 48 (2) :349-355.) 
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_35" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WJFZ201105034&amp;v=MTQwODNVUkxPZVplUm5GeXpnVUx6UE1pZk5kTEc0SDlETXFvOUdZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[35]</b> 王春霞, 苏红旗, 范郭亮.图像超分辨率重建技术综述.计算机技术与发展, 2011, 21 (5) :124-127. (WANG C X, SU H Q, FAN G L.Overview on Super Resolution Image Reconstruction.Computer Technology and Development, 2011, 21 (5) :124-127.) 
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the difficulty of training recurrent neural networks">

                                <b>[36]</b> PASCANU R, MIKOLOV T, BENGIO Y.On the Difficulty of Training Recurrent Neural Networks // Proc of the 30th International Conference on Machine Learning.New York, USA:ACM, 2013, III:1310-1318.
                            </a>
                        </p>
                        <p id="75">
                            <a id="bibliography_37" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A database of human seg-mented natural images and its application to evaluating seg-mentation algorithms and measuring ecological statistics">

                                <b>[37]</b> MARTIN D, FOWLKES C, TAL D, <i>et al</i>.A Database of Human Segmented Natural Images and Its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics // Proc of the 8th IEEE International Conference on Computer Vision.Washington, USA:IEEE, 2001:416-423.
                            </a>
                        </p>
                        <p id="77">
                            <a id="bibliography_38" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZXLJ201336002&amp;v=MDMzOTMzenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1VMelBQelhIWkxHNEg5TFBxWTlGWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[38]</b> 林顺达.Chen-Mobius变换在图像处理应用中的GUI实现.科技资讯, 2013 (36) :1-3. (LIN S D.The Realization of Image Processing on the Based of Chen-Mobius in GUI Interface.Science and Technology Information, 2013 (36) :1-3.) 
                            </a>
                        </p>
                        <p id="79">
                            <a id="bibliography_39" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks">

                                <b>[39]</b> LAI W S, HUANG J B, AHUJA N, <i>et al</i>.Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks[J/OL].[2018-07-30].https://arxiv.org/pdf/1710.01992.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201904010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201904010&amp;v=MTAxNjR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1VMelBLRDdZYkxHNEg5ak1xNDlFWklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
