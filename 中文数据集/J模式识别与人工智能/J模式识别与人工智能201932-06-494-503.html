<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131451028155000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201906002%26RESULT%3d1%26SIGN%3dmUki5Gt9vx8NJQ9X2J%252bOgGS4m7g%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201906002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201906002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201906002&amp;v=MDk0MTVoVTdyTEtEN1liTEc0SDlqTXFZOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#73" data-title="1 相关知识 ">1 相关知识</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#123" data-title="2 非凸的低秩张量正则 ">2 非凸的低秩张量正则</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#146" data-title="3 迭代加权核范数算法及收敛性分析 ">3 迭代加权核范数算法及收敛性分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#147" data-title="&lt;b&gt;3.1&lt;/b&gt; 迭代加权核范数算法"><b>3.1</b> 迭代加权核范数算法</a></li>
                                                <li><a href="#246" data-title="&lt;b&gt;3.2&lt;/b&gt; 收敛性分析"><b>3.2</b> 收敛性分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#291" data-title="4 实验及结果分析 ">4 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#296" data-title="&lt;b&gt;4.1&lt;/b&gt; 合成数据低秩张量恢复"><b>4.1</b> 合成数据低秩张量恢复</a></li>
                                                <li><a href="#308" data-title="&lt;b&gt;4.2&lt;/b&gt; 图像恢复"><b>4.2</b> 图像恢复</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#337" data-title="5 结 束 语 ">5 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#113" data-title="图1 &lt;i&gt;n&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&#215;&lt;i&gt;n&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;&#215;&lt;i&gt;n&lt;/i&gt;&lt;sub&gt;3&lt;/sub&gt;张量的T-SVD形式">图1 <i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub>张量的T-SVD形式</a></li>
                                                <li><a href="#306" data-title="图2 合成数据上的张量恢复性能对比">图2 合成数据上的张量恢复性能对比</a></li>
                                                <li><a href="#387" data-title="图3 真实图像上4种算法的恢复效果对比">图3 真实图像上4种算法的恢复效果对比</a></li>
                                                <li><a href="#387" data-title="图3 真实图像上4种算法的恢复效果对比">图3 真实图像上4种算法的恢复效果对比</a></li>
                                                <li><a href="#334" data-title="图4 真实图像上4种算法的PSNR值和运行时间对比">图4 真实图像上4种算法的PSNR值和运行时间对比</a></li>
                                                <li><a href="#336" data-title="图5 100张图像上4种算法的PSNR值和运行时间对比">图5 100张图像上4种算法的PSNR值和运行时间对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="388">


                                    <a id="bibliography_1" title=" CUI A G, PENG J G, LI H Y.Exact Recovery Low-Rank Matrix via Transformed Affine Matrix Rank Minimization.Neurocomputing, 2018, 319:1-12." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES23DDE81F829D6912EE507D2D05EDC261&amp;v=MDQyOTA3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaHdMeS94YW89TmlmT2ZiRzdhcVc1cDQ0emJPa0dlSG93emhSbW56cDlUd3ZnMkJJd0RNYm5SN3llQ09OdkZTaVdXcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         CUI A G, PENG J G, LI H Y.Exact Recovery Low-Rank Matrix via Transformed Affine Matrix Rank Minimization.Neurocomputing, 2018, 319:1-12.
                                    </a>
                                </li>
                                <li id="390">


                                    <a id="bibliography_2" title=" HUANG S M, WOLKOWICZ H.Low-Rank Matrix Completion Using Nuclear Norm Minimization and Facial Reduction.Journal of Global Optimization, 2018, 72 (1) :5-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low-Rank Matrix Completion Using Nuclear Norm Minimization and Facial Reduction">
                                        <b>[2]</b>
                                         HUANG S M, WOLKOWICZ H.Low-Rank Matrix Completion Using Nuclear Norm Minimization and Facial Reduction.Journal of Global Optimization, 2018, 72 (1) :5-26.
                                    </a>
                                </li>
                                <li id="392">


                                    <a id="bibliography_3" title=" DAVENPORT M A, ROMBERG J.An Overview of Low-Rank Matrix Recovery from Incomplete Observations.IEEE Journal of Selected Topics in Signal Processing, 2016, 10 (4) :608-622." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An overview of low-rank matrix recovery from incomplete observations">
                                        <b>[3]</b>
                                         DAVENPORT M A, ROMBERG J.An Overview of Low-Rank Matrix Recovery from Incomplete Observations.IEEE Journal of Selected Topics in Signal Processing, 2016, 10 (4) :608-622.
                                    </a>
                                </li>
                                <li id="394">


                                    <a id="bibliography_4" title=" YU S, YIQUAN W Q.Subspace Clustering Based on Latent Low Rank Representation with Frobenius Norm Minimization.Neurocomputing, 2018, 275:2479-2489." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB15D2534F44AA72FE7D5FBFC670C4411&amp;v=MDQyMDBJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3THkveGFvPU5pZk9mY0c1RzZYT3FveEJFdThMZlEwK3pXQm03VXQ0UGcyVTN4UXllY0dRUWJ1ZUNPTnZGU2lXV3I3Sg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         YU S, YIQUAN W Q.Subspace Clustering Based on Latent Low Rank Representation with Frobenius Norm Minimization.Neurocomputing, 2018, 275:2479-2489.
                                    </a>
                                </li>
                                <li id="396">


                                    <a id="bibliography_5" title=" LIU G C, LIN Z C, YAN S C, et al.Robust Recovery of Subspace Structures by Low-Rank Representation.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (1) :171-184." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust Recovery of Subspace Structures by Low-Rank Representation">
                                        <b>[5]</b>
                                         LIU G C, LIN Z C, YAN S C, et al.Robust Recovery of Subspace Structures by Low-Rank Representation.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (1) :171-184.
                                    </a>
                                </li>
                                <li id="398">


                                    <a id="bibliography_6" title=" CAND&#200;S E J, LI X D, MA Y, et al.Robust Principal Component Analysis.Journal of the ACM, 2011, 58 (3) .DOI:10.1145/1970392.1970395." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001869&amp;v=Mjc5MzdMYklKRm9VYnhBPU5pZklZN0s3SHRqTnI0OUZaT3NPQkhvd29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         CAND&#200;S E J, LI X D, MA Y, et al.Robust Principal Component Analysis.Journal of the ACM, 2011, 58 (3) .DOI:10.1145/1970392.1970395.
                                    </a>
                                </li>
                                <li id="400">


                                    <a id="bibliography_7" title=" LIN X F, WEI G .Accelerated Reweighted Nuclear Norm Minimization Algorithm for Low Rank Matrix Recovery.Signal Processing, 2015, 114:24-33." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122400158681&amp;v=MDQyNjFNbndaZVp1SHlqbVVMYklKRm9VYnhBPU5pZk9mYks5SDlQT3E0OUZaZTRIQ25RNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         LIN X F, WEI G .Accelerated Reweighted Nuclear Norm Minimization Algorithm for Low Rank Matrix Recovery.Signal Processing, 2015, 114:24-33.
                                    </a>
                                </li>
                                <li id="402">


                                    <a id="bibliography_8" title=" LU C Y, LIN Z C, YAN S C.Smoothed Low Rank and Sparse Matrix Recovery by Iteratively Reweighted Least Squares Minimization.IEEE Transactions on Image Processing, 2015, 24 (2) :646-654." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Smoothed low rank and sparse matrix recovery by iteratively reweighted least squares minimization">
                                        <b>[8]</b>
                                         LU C Y, LIN Z C, YAN S C.Smoothed Low Rank and Sparse Matrix Recovery by Iteratively Reweighted Least Squares Minimization.IEEE Transactions on Image Processing, 2015, 24 (2) :646-654.
                                    </a>
                                </li>
                                <li id="404">


                                    <a id="bibliography_9" title=" HAN D R, YUAN X M.A Note on the Alternating Direction Method of Multipliers.Journal of Optimization Theory and Applications, 2012, 155 (1) :227-238." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD121024002802&amp;v=MjEyNDlqN0Jhcks2SDlIT3E0OUZadU1QRGhNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3ZzVTd2TUlGc1dO&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         HAN D R, YUAN X M.A Note on the Alternating Direction Method of Multipliers.Journal of Optimization Theory and Applications, 2012, 155 (1) :227-238.
                                    </a>
                                </li>
                                <li id="406">


                                    <a id="bibliography_10" title=" TOH K C, YUN S W.An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Linear Least Squares Problems.Pacific Journal of Optimization, 2010, 6 (3) :615-640." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems">
                                        <b>[10]</b>
                                         TOH K C, YUN S W.An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Linear Least Squares Problems.Pacific Journal of Optimization, 2010, 6 (3) :615-640.
                                    </a>
                                </li>
                                <li id="408">


                                    <a id="bibliography_11" title=" LU C Y, TANG J H, YAN S C, et al.Nonconvex Nonsmooth Low Rank Minimization via Iteratively Reweighted Nuclear Norm.IEEE Transactions on Image Processing, 2016, 25 (2) :829-839." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonconvex Non-smooth Low-Rank Minimization via Iteratively Reweighted Nuclear Norm">
                                        <b>[11]</b>
                                         LU C Y, TANG J H, YAN S C, et al.Nonconvex Nonsmooth Low Rank Minimization via Iteratively Reweighted Nuclear Norm.IEEE Transactions on Image Processing, 2016, 25 (2) :829-839.
                                    </a>
                                </li>
                                <li id="410">


                                    <a id="bibliography_12" title=" CAND&#201;S E J, TAO T.The Power of Convex Relaxation:Near-Optimal Matrix Completion.IEEE Transactions on Information Theory, 2010, 56 (5) :2053-2080." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Power of Convex Relaxation: Near-Optimal Matrix Completion">
                                        <b>[12]</b>
                                         CAND&#201;S E J, TAO T.The Power of Convex Relaxation:Near-Optimal Matrix Completion.IEEE Transactions on Information Theory, 2010, 56 (5) :2053-2080.
                                    </a>
                                </li>
                                <li id="412">


                                    <a id="bibliography_13" title=" LEE J, CHOE Y.Low Rank Matrix Recovery via Augmented Lagrange Multiplier with Nonconvex Minimization // Proc of the 12th IEEE Image, Video, and Multidimensional Signal Processing Workshop.Washington, USA:IEEE, 2016.DOI:10.1109/IVMSPW.2016.7528217." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low Rank Matrix Recovery via Augmented Lagrange Multiplier with Nonconvex Minimization">
                                        <b>[13]</b>
                                         LEE J, CHOE Y.Low Rank Matrix Recovery via Augmented Lagrange Multiplier with Nonconvex Minimization // Proc of the 12th IEEE Image, Video, and Multidimensional Signal Processing Workshop.Washington, USA:IEEE, 2016.DOI:10.1109/IVMSPW.2016.7528217.
                                    </a>
                                </li>
                                <li id="414">


                                    <a id="bibliography_14" title=" ZHAO T, WANG Z R, LIU H.A Nonconvex Optimization Framework for Low Rank Matrix Estimation // JORDAN M I, LECUN Y, SOLLA S A, eds.Advances in Neural Information Processing Systems 28.Cambridge, USA:The MIT Press, 2015:559-567." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Nonconvex Optimization Framework for Low Rank Matrix Estimation">
                                        <b>[14]</b>
                                         ZHAO T, WANG Z R, LIU H.A Nonconvex Optimization Framework for Low Rank Matrix Estimation // JORDAN M I, LECUN Y, SOLLA S A, eds.Advances in Neural Information Processing Systems 28.Cambridge, USA:The MIT Press, 2015:559-567.
                                    </a>
                                </li>
                                <li id="416">


                                    <a id="bibliography_15" title=" CHEN W G, LI Y L.Stable Recovery of Low-Rank Matrix via Nonconvex Schatten p-Minimization.Science China (mathematics) , 2015, 58 (12) :2643-2654." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JAXG201512015&amp;v=MTQxODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6aFU3cktMeXpUYWJHNEg5VE5yWTlFWVlRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         CHEN W G, LI Y L.Stable Recovery of Low-Rank Matrix via Nonconvex Schatten p-Minimization.Science China (mathematics) , 2015, 58 (12) :2643-2654.
                                    </a>
                                </li>
                                <li id="418">


                                    <a id="bibliography_16" title=" LU C Y, FENG J S, CHEN Y D, et al.Tensor Robust Principal Component Analysis:Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:5249-5257." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor Robust Principal Component Analysis:Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization">
                                        <b>[16]</b>
                                         LU C Y, FENG J S, CHEN Y D, et al.Tensor Robust Principal Component Analysis:Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:5249-5257.
                                    </a>
                                </li>
                                <li id="420">


                                    <a id="bibliography_17" title=" GOLDFARB D, QIN Z W.Robust Low-Rank Tensor Recovery:Models and Algorithms.SIAM Journal on Matrix Analysis and Applications, 2014, 35 (1) :225-253." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust low-rank tensor recovery:models and algorithms">
                                        <b>[17]</b>
                                         GOLDFARB D, QIN Z W.Robust Low-Rank Tensor Recovery:Models and Algorithms.SIAM Journal on Matrix Analysis and Applications, 2014, 35 (1) :225-253.
                                    </a>
                                </li>
                                <li id="422">


                                    <a id="bibliography_18" title=" KILMER M E, MARTIN C D.Factorization Strategies for Third-Order Tensors.Linear Algebra and Its Applications, 2011, 435 (3) :641-658." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600897114&amp;v=MTI1OTFOcVk5RmJPSUlEWDA5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZvVWJ4QT1OaWZPZmJLN0h0RA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         KILMER M E, MARTIN C D.Factorization Strategies for Third-Order Tensors.Linear Algebra and Its Applications, 2011, 435 (3) :641-658.
                                    </a>
                                </li>
                                <li id="424">


                                    <a id="bibliography_19" title=" LU C Y, FENG J S, CHEN Y D, et al.Tensor Robust Principal Component Analysis with a New Tensor Nuclear Norm[J/OL].[2018-12-12].https://arxiv.org/pdf/1804.03728v1.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor Robust Principal Component Analysis with a New Tensor Nuclear Norm">
                                        <b>[19]</b>
                                         LU C Y, FENG J S, CHEN Y D, et al.Tensor Robust Principal Component Analysis with a New Tensor Nuclear Norm[J/OL].[2018-12-12].https://arxiv.org/pdf/1804.03728v1.pdf.
                                    </a>
                                </li>
                                <li id="426">


                                    <a id="bibliography_20" title=" LIU J, MUSIALSKI P, WONKA P, et al.Tensor Completion for Estimating Missing Values in Visual Data.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (1) :208-220." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor Completion for Estimating Missing Values in Visual Data">
                                        <b>[20]</b>
                                         LIU J, MUSIALSKI P, WONKA P, et al.Tensor Completion for Estimating Missing Values in Visual Data.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (1) :208-220.
                                    </a>
                                </li>
                                <li id="428">


                                    <a id="bibliography_21" title=" LU C Y, FENG J S, LIN Z C, et al.Exact Low Tubal Rank Tensor Recovery from Gaussian Measurements // Proc of the 27th International Joint Conference on Artificial Intelligence.New York, USA:ACM, 2018:2504-2510." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exact Low Tubal Rank Tensor Recovery from Gaussian Measurements">
                                        <b>[21]</b>
                                         LU C Y, FENG J S, LIN Z C, et al.Exact Low Tubal Rank Tensor Recovery from Gaussian Measurements // Proc of the 27th International Joint Conference on Artificial Intelligence.New York, USA:ACM, 2018:2504-2510.
                                    </a>
                                </li>
                                <li id="430">


                                    <a id="bibliography_22" title=" LU C Y, ZHU C B, XU C Y, et al.Generalized Singular Value Thresholding // Proc of the 29th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2015:1805-1811." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generalized Singular Value Thresholding">
                                        <b>[22]</b>
                                         LU C Y, ZHU C B, XU C Y, et al.Generalized Singular Value Thresholding // Proc of the 29th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2015:1805-1811.
                                    </a>
                                </li>
                                <li id="432">


                                    <a id="bibliography_23" title=" BECK A, TEBOULLE M.A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems.SIAM Journal on Imaging Sciences, 2009, 2 (1) :183-202." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems">
                                        <b>[23]</b>
                                         BECK A, TEBOULLE M.A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems.SIAM Journal on Imaging Sciences, 2009, 2 (1) :183-202.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(06),494-503 DOI:10.16451/j.cnki.issn1003-6059.201906002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于<i>l</i></b><sub><b><i>P</i></b></sub><b>范数的非凸低秩张量最小化</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%8F%E9%9B%85%E8%8C%B9&amp;code=40820990&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏雅茹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E8%80%BF%E8%80%BF&amp;code=25121026&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘耿耿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%96%87%E7%8A%80&amp;code=42201393&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘文犀</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E4%B8%B9%E7%BA%A2&amp;code=06685676&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱丹红</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%A6%8F%E5%B7%9E%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0094575&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">福州大学数学与计算机科学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在低秩矩阵、张量最小化问题中, 凸函数容易求得最优解, 而非凸函数可以得到更低秩的局部解.文中基于非凸替换函数的低秩张量恢复问题, 提出基于<i>l</i><sub><i>p</i></sub>范数的非凸张量模型.采用迭代加权核范数算法求解模型, 实现低秩张量最小化.在合成数据和真实图像上的大量实验验证文中方法的恢复性能.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8E%E7%A7%A9%E5%BC%A0%E9%87%8F%E6%81%A2%E5%A4%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">低秩张量恢复;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%87%B8%E6%83%A9%E7%BD%9A%E5%87%BD%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非凸惩罚函数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3El%3C%2Fi%3E%3Csub%3E%3Ci%3Ep%3C%2Fi%3E%3C%2Fsub%3E%E8%8C%83%E6%95%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>l</i><sub><i>p</i></sub>范数;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%AD%E4%BB%A3%E5%8A%A0%E6%9D%83%E6%A0%B8%E8%8C%83%E6%95%B0%E7%AE%97%E6%B3%95%20(IRNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">迭代加权核范数算法 (IRNN) ;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *苏雅茹 (通讯作者) , 博士, 讲师, 主要研究方向为机器学习、模式识别.Email:yarusu@fzu.edu.cn.;
                                </span>
                                <span>
                                    刘耿耿, 博士, 副教授, 主要研究方向为计算智能及其应用.E-mail:liugenggeng@fzu.edu.cn.;
                                </span>
                                <span>
                                    刘文犀, 博士, 副教授, 主要研究方向为计算机视觉.Email:wenxi.liu@hotmail.com.;
                                </span>
                                <span>
                                    朱丹红, 硕士, 讲师, 主要研究方向为医学人工智能.Email:zhudh@fzu.edu.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.61877010, 11501114);</span>
                                <span>福建省自然科学基金项目 (No.2016J01295, 2016J05155, 2018J01796) 资助;</span>
                    </p>
            </div>
                    <h1><b>Nonconvex Low-Rank Tensor Minimization Based on <i>l</i></b><sub><b><i>P</i></b></sub><b>Norm</b></h1>
                    <h2>
                    <span>SU Yaru</span>
                    <span>LIU Genggeng</span>
                    <span>LIU Wenxi</span>
                    <span>ZHU Danhong</span>
            </h2>
                    <h2>
                    <span>College of Mathematics and Computer Science, Fuzhou University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>For the low-rank matrix and tensor minimization problem, the optimal solution of convex function can be obtained easily, and the better low-rank solution can be obtained from the local minimum of the corresponding nonconvex function. The low-rank tensor recovery problem based on the nonconvex function is studied in this paper. A nonconvex low-rank tensor model based on <i>l</i><sub><i>p</i></sub> norm is proposed. In addition, tensor based iteratively reweighted nuclear norm algorithm is proposed to solve the nonconvex low-rank tensor minimization problem. The weighted singular value thresholding problem is solved by the tensor based iteratively reweighted nuclear norm algorithm. The objective function value monotonically decreases and its convergence can be theoretically proved. The recovery performance of the proposed method is demonstrated by comprehensive experiments on both synthetic data and real images.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Low-Rank%20Tensor%20Recovery&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Low-Rank Tensor Recovery;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nonconvex%20Penalty%20Function&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nonconvex Penalty Function;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%3Ci%3El%3C%2Fi%3E%3Csub%3E%3Ci%3Ep%3C%2Fi%3E%3C%2Fsub%3E%20Norm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank"><i>l</i><sub><i>p</i></sub> Norm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Iteratively%20Reweighted%20Nuclear%20Norm%20(IRNN)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Iteratively Reweighted Nuclear Norm (IRNN) ;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    SU Yaru (Corresponding author) , Ph. D., lecturer. Her research interests include machine learning and pattern recognition.;
                                </span>
                                <span>
                                    LIU Genggeng, Ph.D., associate professor. His research interests include computational intelligence and its application.;
                                </span>
                                <span>
                                    LIU Wenxi, Ph. D., associate professor. His research interests include computer vision.;
                                </span>
                                <span>
                                    ZHU Danhong, master, lecturer. Her research interests include medical artificial intelligence.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.61877010, 11501114);</span>
                                <span>Natural Science Foundation of Fujian Province (No.2016J01295, 2016J05155, 2018J01796);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="70">信息技术的快速发展使人们面临海量、高维、复杂的数据, 对这些数据的采集、存储、分析与处理给人们带来挑战.如何表示数据是数据分析与处理工作面临的首要问题, 充分利用数据的结构信息是数据表示的关键.现实世界的数据表达能力越来越丰富, 结构越来越复杂, 例如图文并茂的web数据、多媒体数据、多光谱数据等.以向量、矩阵的方式表示数据已无法充分表达这些数据的结构特征, 张量作为向量和矩阵向更高阶段的自然推广, 能更准确地表示数据的本质结构.</p>
                </div>
                <div class="p1">
                    <p id="71">如何从缺失、污染的复杂数据中恢复原始数据是机器学习和计算机视觉领域的研究热点.近年来, 低秩矩阵最小化问题得到广泛研究, 应用于图像视频恢复<citation id="439" type="reference"><link href="388" rel="bibliography" /><link href="390" rel="bibliography" /><link href="392" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>、图像分割<citation id="434" type="reference"><link href="394" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、运动分割<citation id="435" type="reference"><link href="396" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、背景建模<citation id="436" type="reference"><link href="398" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等.该类问题的模型一般基于对矩阵的秩进行松弛, 采用核范数作为矩阵的秩的凸逼近, 采用多项式时间算法求解<citation id="440" type="reference"><link href="400" rel="bibliography" /><link href="402" rel="bibliography" /><link href="404" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>.Toh等<citation id="437" type="reference"><link href="406" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>采用加速近邻梯度算法 (Accelerated Proximal Gradient Algorithm, APGL) 求解一个核范数正则化最小二乘问题.然而, 凸的矩阵核范数可能是矩阵秩较松的近似<citation id="441" type="reference"><link href="408" rel="bibliography" /><link href="410" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>.采用非凸函数可以更好地逼近矩阵的秩, 获得更优的低秩解<citation id="442" type="reference"><link href="412" rel="bibliography" /><link href="414" rel="bibliography" /><link href="416" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>.Lu等<citation id="438" type="reference"><link href="408" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>采用凹近似函数, 提出迭代加权核范数 (Iteratively Reweighted Nuclear Norm, IRNN) , 实现低秩矩阵最小化.相比凸模型及算法, 低秩矩阵恢复效果明显增强.</p>
                </div>
                <div class="p1">
                    <p id="72">近年来, 低秩张量恢复问题作为低秩矩阵恢复问题在更高维空间上的推广得到广泛关注<citation id="444" type="reference"><link href="418" rel="bibliography" /><link href="420" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>.低秩张量恢复问题通常也是转化为求解一个凸优化问题.Lu等<citation id="443" type="reference"><link href="418" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出张量核范数作为张量的管秩 (Tubal Rank) 的凸逼近, 并使用标准的交替方向乘子法 (Alternating Direction Method of Multipliers, ADMM) 求解相应的凸模型.然而, 张量的核范数为张量的管秩的较松的逼近.相应凸模型的解可能不是好的近似.本文利用张量核函数定义的特殊性质, 提出基于<i>l</i><sub><i>p</i></sub>范数的张量的管秩的非凸近似函数, 并提出迭代加权核范数算法, 求解提出的非凸模型.人工数据集上的实验表明, 相比凸模型, 本文的非凸模型及解法取得更明显的恢复效果.图像恢复实验也验证算法取得更好的恢复结果.</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag">1 相关知识</h3>
                <div class="p1">
                    <p id="74">本节引入一些关于张量的符号及基本定义.张量使用花体字母表示, 如<b>A</b>;矩阵使用黑体大写字母表示, 如<b><i>A</i></b>;矢量使用黑体小写字母表示, 如<b><i>a</i></b>;标量使用小写字母表示, 如<i>a</i>.<b><i>I</i></b><sub><i>n</i></sub>表示大小为<i>n</i>×<i>n</i>的单位矩阵.对于一个三维张量<b>A</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, [<b>A</b>]<sub><i>ijk</i></sub>或<i>a</i><sub><i>ijk</i></sub>表示它的第 (<i>i</i>, <i>j</i>, <i>k</i>) 个元素, <b>A</b> (<i>i</i>, ∶, ∶) , <b>A</b> (∶, <i>i</i>, ∶) 和<b>A</b> (∶, ∶, <i>i</i>) 分别表示第<i>i</i>个水平、侧面和正面切片, 正面切片<b>A</b> (∶, ∶, <i>i</i>) 通常紧凑表示为<b><i>A</i></b><sup> (<i>i</i>) </sup>, <b>A</b> (<i>i</i>, <i>j</i>, ∶) 表示管 (Tube) .</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold">A</mi><mo>|</mo></mrow><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></munder><mo stretchy="false">|</mo></mstyle><mi>a</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">表示<i>l</i><sub>1</sub>范数, </p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold">A</mi><mo>|</mo></mrow><msub><mrow></mrow><mi>∞</mi></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></munder><mo stretchy="false">|</mo><mi>a</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></msub><mo stretchy="false">|</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">表示无穷范数, </p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold">A</mi><mo>|</mo></mrow><msub><mrow></mrow><mtext>F</mtext></msub><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></munder><mi>a</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">表示Frobenius范数.对于</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">A</mi><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub><mo>×</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msup><mo>, </mo><mrow><mi mathvariant="bold">B</mi><mo>∈</mo></mrow><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub><mo>×</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msup><mo>, </mo><mo>〈</mo><mi mathvariant="bold">A</mi><mo>, </mo><mi mathvariant="bold">B</mi><mo>〉</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></munder><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></msub><mi>b</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi><mi>k</mi></mrow></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">表示<b>A</b>和<b>B</b>的内积.</p>
                </div>
                <div class="p1">
                    <p id="83">对于<b>A</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, 使用Matlab命令<i>fft</i>, 得到<b>A</b>沿第3维的傅里叶变换结果<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">A</mi><mo>¯</mo></mover></math></mathml>, 即</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold">A</mi><mo>¯</mo></mover><mo>=</mo><mi>f</mi><mi>f</mi><mi>t</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">A</mi><mo>, </mo><mo stretchy="false">[</mo><mo stretchy="false">]</mo><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">同样地, 可以使用反傅里叶变换<i>ifft</i>得到<b>A</b>, 即</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">A</mi><mo>=</mo><mi>i</mi><mi>f</mi><mi>f</mi><mi>t</mi><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold">A</mi><mo>¯</mo></mover><mo>, </mo><mo stretchy="false">[</mo><mo stretchy="false">]</mo><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">定义块对角矩阵<mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>¯</mo></mover></math></mathml>, 它的对角线上的每个块是<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">A</mi><mo>¯</mo></mover></math></mathml>的正面切片<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup></mrow></math></mathml>, 即</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>¯</mo></mover><mo>=</mo><mi>b</mi><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold">A</mi><mo>¯</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd><mo>⋱</mo></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd></mtd><mtd><mover accent="true"><mi mathvariant="bold-italic">A</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo></mrow></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">张量<b>A</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>的块循环矩阵是一种张量矩阵化方式, 大小为<i>n</i><sub>1</sub><i>n</i><sub>3</sub>×<i>n</i><sub>2</sub><i>n</i><sub>3</sub>, 定义为</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>b</mi><mi>c</mi><mi>i</mi><mi>r</mi><mi>c</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">A</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo></mrow></msup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></msup></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋮</mo></mtd><mtd></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo></mrow></msup></mtd><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd><mo>⋯</mo></mtd><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">还需要定义2个操作:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><mi>n</mi><mi>f</mi><mi>o</mi><mi>l</mi><mi>d</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">A</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo></mrow></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mspace width="0.25em" /><mi>f</mi><mi>o</mi><mi>l</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>u</mi><mi>n</mi><mi>f</mi><mi>o</mi><mi>l</mi><mi>d</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">A</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold">A</mi><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">基于上述符号, 有两个3维张量的张量乘法, 定义如下.</p>
                </div>
                <div class="p1">
                    <p id="98"><b>定义1</b>张量乘法<citation id="445" type="reference"><link href="422" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation> 令<b>A</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, <b>B</b>∈<b>R</b><sup><i>n</i><sub>2</sub>×<i>l</i>×<i>n</i><sub>3</sub></sup>, 张量乘法<b>A</b>*<b>B</b>为大小为<i>n</i><sub>1</sub>×<i>l</i>×<i>n</i><sub>3</sub>的张量, 定义为</p>
                </div>
                <div class="p1">
                    <p id="99"><b>A</b>*<b>B</b>=<i>fold</i> (<i>bcirc</i> (<b>A</b>) ·<i>unfold</i> (<b>B</b>) ) .</p>
                </div>
                <div class="p1">
                    <p id="100">一个大小为<i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub>的3维张量可以看作是一个大小为<i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>的矩阵, 其中每个元素都是一个沿着第三维的管 (Tube) .因此, 张量乘法与矩阵乘法类似, 只是使用循环卷积取代元素之间的乘法运算.当<i>n</i><sub>3</sub>=1时, 张量乘法退化为标准矩阵乘法.</p>
                </div>
                <div class="p1">
                    <p id="101"><b>定义2</b>共轭转置<citation id="446" type="reference"><link href="422" rel="bibliography" /><link href="424" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation> 大小为<i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub>的张量<b>A</b>的共轭转置是大小为<i>n</i><sub>2</sub>×<i>n</i><sub>1</sub>×<i>n</i><sub>3</sub>的张量<b>A</b><sup>*</sup>, 它首先共轭转置每个正面切片, 然后把转置后序号从2到<i>n</i><sub>3</sub>的正面切片按逆序排列 (第1个正面切片的位置不变) .</p>
                </div>
                <div class="p1">
                    <p id="102"><b>定义3</b>单位张量<citation id="447" type="reference"><link href="422" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation><b>I</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>为单位张量, 它的第一个正面切片是大小为<i>n</i>×<i>n</i>的单位矩阵, 其它正面切片都是零矩阵.</p>
                </div>
                <div class="p1">
                    <p id="103"><b>定义4</b>正交张量<citation id="448" type="reference"><link href="422" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation> 如果<b>Q</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>满足</p>
                </div>
                <div class="p1">
                    <p id="104"><b>Q</b><sup>*</sup>*<b>Q</b>=<b>Q</b>*<b>Q</b><sup>*</sup>=<b>I</b>, </p>
                </div>
                <div class="p1">
                    <p id="105">它是正交的.</p>
                </div>
                <div class="p1">
                    <p id="106"><b>定义5</b><i>f</i>-对角张量<citation id="449" type="reference"><link href="422" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation> 如果一个三阶张量的每个正面切片都是对角矩阵, 称其为<i>f</i>-对角张量.</p>
                </div>
                <div class="p1">
                    <p id="107"><b>定理1</b> 张量奇异值分解 (Tensor-Singular Value Decomposition, T-SVD) <citation id="450" type="reference"><link href="424" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation> 令<b>A</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, 可分解为</p>
                </div>
                <div class="p1">
                    <p id="108"><b>A</b>=<b>U</b>*<b>S</b>*<b>V</b><sup>*</sup>, </p>
                </div>
                <div class="p1">
                    <p id="109">其中, <b>U</b>为大小为<i>n</i><sub>1</sub>×<i>n</i><sub>1</sub>×<i>n</i><sub>3</sub>的正交张量, <b>V</b>为大小为<i>n</i><sub>2</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub>的正交张量, <b>S</b>为大小为<i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub>的<i>f</i>-对角张量.</p>
                </div>
                <div class="p1">
                    <p id="110">图1给出T-SVD分解的直观形式<citation id="451" type="reference"><link href="422" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>.T-SVD可以利用傅里叶变换快速计算.首先对<b>A</b>沿第3维进行傅里叶变换, 得到<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">A</mi><mo>¯</mo></mover></math></mathml>, 然后分别对<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">A</mi><mo>¯</mo></mover></math></mathml>的每个正面切片进行矩阵奇异值分解 (Singular Value Decom-position, SVD) , 得到相应的3个张量, 最后对3个分量进行反傅里叶变换, 得到T-SVD的结果.值得注意的是, 矩阵的SVD分解是在复数域上操作, 但反傅里叶变换后必须得到实数.具体的快速计算细节可参见文献<citation id="452" type="reference">[<a class="sup">20</a>]</citation>.</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906002_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 n1&#215;n2&#215;n3张量的T-SVD形式" src="Detail/GetImg?filename=images/MSSB201906002_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 <i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub>张量的T-SVD形式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906002_113.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 T-SVD of <i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub> tensor</p>

                </div>
                <div class="p1">
                    <p id="114"><b>定义6</b>张量管秩<citation id="453" type="reference"><link href="424" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation> 令<b>A</b>=<b>U</b>*<b>S</b>*<b>V</b><sup>*</sup>为<b>A</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>的T-SVD分解.张量的管秩 (Tubal Rank) , 记为</p>
                </div>
                <div class="p1">
                    <p id="115"><i>rank</i><sub><i>t</i></sub> (<b>A</b>) =#{<i>i</i>∶<b>S</b> (<i>i</i>, <i>i</i>, ∶) }, </p>
                </div>
                <div class="p1">
                    <p id="116">定义为<b>S</b>中非零管的个数.</p>
                </div>
                <div class="p1">
                    <p id="117"><b>定义7</b>张量核范数<citation id="454" type="reference"><link href="424" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation> 令<b>A</b>=<b>U</b>*<b>S</b>*<b>V</b><sup>*</sup>为<b>A</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>的T-SVD分解, 张量的核范数记为<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold">A</mi><mo>|</mo></mrow><msub><mrow></mrow><mo>*</mo></msub></mrow></math></mathml>, 定义为</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula"><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold">A</mi><mo>|</mo></mrow><msub><mrow></mrow><mo>*</mo></msub></mrow></math></mathml>:<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mo>〈</mo><mi mathvariant="bold">S</mi><mo>, </mo><mi mathvariant="bold">Ι</mi><mo>〉</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mi mathvariant="bold">S</mi></mstyle><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>i</mi><mo>, </mo><mn>1</mn><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="122">其中<i>r</i>=<i>rank</i><sub><i>t</i></sub> (<b>A</b>) .由于张量的T-SVD可计算, 因此张量的核范数也可计算.张量核范数性质良好, 应用于解决张量鲁棒PCA<citation id="455" type="reference"><link href="424" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>及张量填充 (Tensor Completion) <citation id="456" type="reference"><link href="426" rel="bibliography" /><link href="428" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>问题.这类凸模型最大优点在于其可以计算最优解, 但由于凸的张量核范数只是张量秩的一种近似, 在很多情形下这种近似可能太松.因此, 本文考虑使用非凸的函数更好地近似张量的秩, 获得更好的局部解.</p>
                </div>
                <h3 id="123" name="123" class="anchor-tag">2 非凸的低秩张量正则</h3>
                <div class="p1">
                    <p id="124">本节提出非凸的低秩正则函数, 更好地近似张量的秩.再提出迭代加权核范数算法, 求解相应的非凸模型并给出收敛性保证.给定一个三维张量<b>X</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, 根据前面的定义, <b>X</b>沿第3维进行离散傅里叶变换, 得到</p>
                </div>
                <div class="p1">
                    <p id="125" class="code-formula">
                        <mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold">X</mi><mo>¯</mo></mover><mo>=</mo><mi>f</mi><mi>f</mi><mi>t</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo>, </mo><mo stretchy="false">[</mo><mo stretchy="false">]</mo><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="126"><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">X</mi><mo>¯</mo></mover></math></mathml>对应的块对角矩阵为</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><mo>=</mo><mi>b</mi><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold">X</mi><mo>¯</mo></mover><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd><mo>⋱</mo></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd></mtd><mtd><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">) </mo></mrow></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo>×</mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></msup><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="129">对角线上的每个块是<mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">X</mi><mo>¯</mo></mover></math></mathml>的正面切片<mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup></mrow></math></mathml>.张量核范数有如下重要性质<citation id="457" type="reference"><link href="424" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold">X</mi><mo>|</mo></mrow><msub><mrow></mrow><mo>*</mo></msub><mo>∶</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup></mrow><mo>|</mo></mrow></mrow></mstyle><msub><mrow></mrow><mo>*</mo></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>σ</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中</p>
                </div>
                <div class="area_img" id="135">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906002_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="136"><image id="386" type="formula" href="images/MSSB201906002_38600.jpg" display="inline" placement="inline"><alt></alt></image>表示<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msup></mrow></math></mathml>的第<i>i</i>个奇异值.基于上述性质, 提出如下基于<i>l</i><sub><i>p</i></sub>范数的非凸的正则函数:</p>
                </div>
                <div class="p1">
                    <p id="139" class="code-formula">
                        <mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mi>p</mi></msup></mrow></mstyle></mrow></mstyle><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="140">其中0&lt;<i>p</i>&lt;1.基于上述正则函数, 本文考虑求解如下非凸低秩张量最优化模型:</p>
                </div>
                <div class="p1">
                    <p id="141" class="code-formula">
                        <mathml id="141"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>=</mo><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mi>p</mi></msup></mrow></mstyle></mrow></mstyle><mo>+</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="142">其中, 函数<i>f</i>为某种损失函数, 具体形式视模型而定.为了简化符号及后面讨论, 进一步把上述模型简化成</p>
                </div>
                <div class="p1">
                    <p id="143" class="code-formula">
                        <mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>g</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>λ</mi></msub><mo stretchy="false"> (</mo><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>+</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="144">其中<i>g</i><sub><i>λ</i></sub> (<i>x</i>) =<i>λx</i><sup><i>p</i></sup>, 这里只需要考虑<i>x</i>≥0的情形, 因为矩阵奇异值非负.</p>
                </div>
                <div class="p1">
                    <p id="145">模型 (1) 非凸, 目标函数中的两项分别定义在傅里叶空间 (复数域) 和原空间 (实数域) 上.这些因素使这个问题变得更复杂.本文方法受到非凸稀疏表示和非凸低秩矩阵的最优化方法启发, 但又有一些关键区别, 例如, 需要在实数域和复数域上交叉操作, 总是需要保证反傅里叶变换后的张量仍是实数.</p>
                </div>
                <h3 id="146" name="146" class="anchor-tag">3 迭代加权核范数算法及收敛性分析</h3>
                <h4 class="anchor-tag" id="147" name="147"><b>3.1</b> 迭代加权核范数算法</h4>
                <div class="p1">
                    <p id="148">为了保证算法收敛性, 对问题 (1) 有如下假设.</p>
                </div>
                <div class="p1">
                    <p id="149">A1假设:<i>g</i>∶<b>R→R</b><sup>+</sup>在[0, ∞) 上是连续、单调递增的凹函数, 可能非平滑.</p>
                </div>
                <div class="p1">
                    <p id="150">A2假设:<i>f</i>∶<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>→<b>R</b><sup>+</sup>为<i>C</i><sup>1, 1</sup>上的连续的平滑函数, 即梯度是Lipschitz连续的:</p>
                </div>
                <div class="p1">
                    <p id="151" class="code-formula">
                        <mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mrow><mo>|</mo><mrow><mo>∇</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>-</mo><mo>∇</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">Y</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow><msub><mrow></mrow><mtext>F</mtext></msub><mo>≤</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold">X</mi><mo>-</mo><mi mathvariant="bold">Y</mi></mrow><mo>|</mo></mrow></mrow><msub><mrow></mrow><mtext>F</mtext></msub><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="152">对于任意<b>X</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, <b>Y</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>成立, 其中, <i>L</i> (<i>f</i>) &gt;0称为∇<i>f</i>的Lipschitz常数, <i>f</i> (<b>X</b>) 可以非凸.</p>
                </div>
                <div class="p1">
                    <p id="153">A3假设:若<mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold">X</mi><mo>|</mo></mrow><msub><mrow></mrow><mtext>F</mtext></msub><mo>→</mo><mi>∞</mi></mrow></math></mathml>, 则<i>F</i> (<b>X</b>) →∞.</p>
                </div>
                <div class="p1">
                    <p id="155">模型 (1) 中的函数<i>g</i><sub><i>λ</i></sub> (<i>x</i>) 满足假设A1.考虑张量填充问题, 采用损失函数</p>
                </div>
                <div class="p1">
                    <p id="156" class="code-formula">
                        <mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>Ω</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo>-</mo><mi mathvariant="bold">Μ</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="157">其中, <i>Ω</i>为样本的索引集, <b>P</b><sub><i>Ω</i></sub>∶<b>R</b><sup><i>m</i>×<i>n</i></sup>→<b>R</b><sup><i>m</i>×<i>n</i></sup>为一个线性算子, 保持<i>Ω</i>内的项不变, <i>Ω</i>外的项为零.</p>
                </div>
                <div class="p1">
                    <p id="158">为了方便描述, 令<mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup></mrow></math></mathml>表示<mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup></mrow></math></mathml>的第<i>k</i>次迭代, 使用<i>σ</i><mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>和 (<i>σ</i><mathml id="162"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>分别表示<mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo></mrow></math></mathml>和<mathml id="164"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo></mrow></math></mathml>.根据矩阵奇异值性质, 有</p>
                </div>
                <div class="p1">
                    <p id="165"><i>σ</i><mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>j</mi></msubsup></mrow></math></mathml>≥<i>σ</i><mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>j</mi></msubsup></mrow></math></mathml>≥…≥<i>σ</i><mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>j</mi></msubsup></mrow></math></mathml>≥0.      (2) </p>
                </div>
                <div class="p1">
                    <p id="169">因为<i>g</i><sub><i>λ</i></sub>在[0, ∞) 上是凹函数, 根据定义可得</p>
                </div>
                <div class="p1">
                    <p id="170"><i>g</i><sub><i>λ</i></sub> (<i>σ</i><mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) ≤<i>g</i><sub><i>λ</i></sub> ( (<i>σ</i><mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>) + (<i>w</i><mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup> (<i>σ</i><mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>- (<i>σ</i><mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>) ,      (3) </p>
                </div>
                <div class="p1">
                    <p id="176">其中</p>
                </div>
                <div class="p1">
                    <p id="177"> (<i>w</i><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>∈∂<i>g</i><sub><i>λ</i></sub> (<i>σ</i><mathml id="179"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>) , </p>
                </div>
                <div class="p1">
                    <p id="180">根据性质 (2) 及超梯度的反单调性<citation id="458" type="reference"><link href="408" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 可得</p>
                </div>
                <div class="p1">
                    <p id="181">0≤ (<i>w</i><mathml id="182"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>≤ (<i>w</i><mathml id="183"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>≤…≤ (<i>w</i><mathml id="184"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>.</p>
                </div>
                <div class="p1">
                    <p id="185">性质 (3) 促使本文使用右边代替左边, 求解一个问题 (1) 的替代问题:</p>
                </div>
                <div class="p1">
                    <p id="186" class="code-formula">
                        <mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold">X</mi><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>+</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>λ</mi></msub><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo>-</mo><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>+</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="187">然而上述问题仍不易求解.根据假设A2, ∇<i>f</i>是Lipschitz连续的, 可以考虑对<i>f</i>进行线性化, 并加一项近邻项:</p>
                </div>
                <div class="area_img" id="188">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906002_18800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="190">其中, <i>μ</i>&gt;<i>L</i> (<i>f</i>) , 为了保证算法收敛, 由后面的收敛证明推出.将式 (5) 代入式 (4) , </p>
                </div>
                <div class="area_img" id="191">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906002_19100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="193">问题 (6) 仍非凸, 但却有闭式解.</p>
                </div>
                <div class="p1">
                    <p id="194"><b>引理1</b> 对于任意<i>λ</i>&gt;0, <b>Y</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, </p>
                </div>
                <div class="p1">
                    <p id="195"><i>m</i>=min (<i>n</i><sub>1</sub>, <i>n</i><sub>2</sub>) , </p>
                </div>
                <div class="p1">
                    <p id="196">张量<b>W</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>为<i>f</i>-对角张量, 每个正面切片的对角线上元素</p>
                </div>
                <div class="p1">
                    <p id="197"><b><i>W</i></b><sup> (<i>j</i>) </sup>=diag (<i>w</i><mathml id="198"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>j</mi></msubsup></mrow></math></mathml>, <i>w</i><mathml id="199"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>j</mi></msubsup></mrow></math></mathml>, …, <i>w</i><mathml id="200"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>j</mi></msubsup></mrow></math></mathml>) , </p>
                </div>
                <div class="p1">
                    <p id="201">满足0≤<i>w</i><mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>j</mi></msubsup></mrow></math></mathml>≤<i>w</i><mathml id="203"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>j</mi></msubsup></mrow></math></mathml>≤…≤<i>w</i><mathml id="204"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>m</mi><mi>j</mi></msubsup></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="205">考虑如下问题:</p>
                </div>
                <div class="p1">
                    <p id="206"><mathml id="207"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>λ</mi><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup></mrow></mstyle></mrow></mstyle><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold">X</mi><mo>-</mo><mi mathvariant="bold">Y</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="208">的最优解为</p>
                </div>
                <div class="p1">
                    <p id="209"><b>X</b>=<b>U</b>*<i>T</i><sub><i>λ</i><b>W</b></sub> (<b>S</b>) *<b>V</b><sup>*</sup>, </p>
                </div>
                <div class="p1">
                    <p id="210">其中</p>
                </div>
                <div class="p1">
                    <p id="211"><b>Y</b>=<b>U</b>*<b>S</b>*<b>V</b><sup>*</sup>, </p>
                </div>
                <div class="p1">
                    <p id="212">为<b>Y</b>的T-SVD分解, </p>
                </div>
                <div class="p1">
                    <p id="213" class="code-formula">
                        <mathml id="213"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msub><mrow></mrow><mrow><mi>λ</mi><mi mathvariant="bold">W</mi></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold">S</mi><mo stretchy="false">) </mo><mo>=</mo><mi>i</mi><mi>f</mi><mi>f</mi><mi>t</mi><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold">S</mi><mo>¯</mo></mover><mo>-</mo><mi>λ</mi><mi mathvariant="bold">W</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mo>+</mo></msub><mo>, </mo><mo stretchy="false">[</mo><mo stretchy="false">]</mo><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="214"><b>证明</b> 首先注意到要求的解<b>X</b>为一个实数张量.张量<mathml id="215"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">S</mi><mo>¯</mo></mover></math></mathml>的每个正面切片是矩阵的奇异值, 因此都是实数, 根据张量<b>W</b>的性质可知<mathml id="216"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold">S</mi><mo>¯</mo></mover><mo>-</mo><mi>λ</mi><mi mathvariant="bold">W</mi><mo stretchy="false">) </mo><msub><mrow></mrow><mo>+</mo></msub></mrow></math></mathml>也是实数.再依据文献<citation id="459" type="reference">[<a class="sup">19</a>]</citation>中的引理2.1可知<i>T</i><sub><i>λ</i><b>W</b></sub> (<b>S</b>) 也是实数张量.其次, 问题 (7) 等价于</p>
                </div>
                <div class="p1">
                    <p id="217" class="code-formula">
                        <mathml id="217"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>λ</mi><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><mo stretchy="false">|</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mo stretchy="false"> (</mo></mstyle><mi>λ</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">|</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup></mrow><mo stretchy="false">|</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="218">根据矩阵的SVD分解<citation id="460" type="reference"><link href="430" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>可知, <mathml id="219"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>Τ</mi><msub><mrow></mrow><mrow><mi>λ</mi><mi mathvariant="bold">W</mi></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold">S</mi><mo stretchy="false">) </mo></mrow><mo stretchy="true">¯</mo></mover></mrow></math></mathml>的第<b>j</b>个正面切片就是上述问题的第<b>j</b>个子问题的解.证毕.</p>
                </div>
                <div class="p1">
                    <p id="220">有了问题 (6) 的解, 就有完整的求解问题 (1) 的<b><i>IRNN</i></b>, 算法步骤如下.</p>
                </div>
                <div class="p1">
                    <p id="221"><b>算法1 <i>IRNN</i></b>求解问题 (1) </p>
                </div>
                <div class="p1">
                    <p id="222"><b>输入</b> μ&gt;<b>L (f) —∇f</b> (<b>X</b>) 的Lipschitz常数</p>
                </div>
                <div class="p1">
                    <p id="223"><b>输出</b><i>X</i><sup>*</sup></p>
                </div>
                <div class="p1">
                    <p id="224"><b>初始化</b><i>k</i>=0, <b>X</b><sup><i>k</i></sup>, (<i>w</i><mathml id="225"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i></sup>, <i>i</i>=1, 2, …, <i>m</i></p>
                </div>
                <div class="p1">
                    <p id="226">重复以下两步骤直至收敛:</p>
                </div>
                <div class="p1">
                    <p id="227">step 1 求解问题 (6) 更新<b>X</b><sup><i>k</i>+1</sup>.</p>
                </div>
                <div class="p1">
                    <p id="228">计算<mathml id="229"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold">Y</mi><mo>¯</mo></mover><mo>=</mo><mi>f</mi><mi>f</mi><mi>t</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">Y</mi><mo>, </mo><mo stretchy="false">[</mo><mo stretchy="false">]</mo><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="230">对<mathml id="231"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">Y</mi><mo>¯</mo></mover></math></mathml>的每个正面切片计算SVD.</p>
                </div>
                <div class="p1">
                    <p id="232" class="code-formula">
                        <mathml id="232"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>f</mtext><mtext>o</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>i</mi><mo>=</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mrow><mo>[</mo><mrow><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>]</mo></mrow><mspace width="0.25em" /><mtext>d</mtext><mtext>o</mtext></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="233">[<b>U</b>, <b>S</b>, <b>V</b>]=SVD<mathml id="234"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">Y</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup></mrow><mo stretchy="false">) </mo><mo>;</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="235" class="code-formula">
                        <mathml id="235"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mi mathvariant="bold">U</mi><mo>⋅</mo><mo stretchy="false"> (</mo><mi mathvariant="bold">S</mi><mo>-</mo><mi>λ</mi><mi mathvariant="bold">W</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><msub><mrow></mrow><mo>+</mo></msub><mo>⋅</mo><mi mathvariant="bold">V</mi><msup><mrow></mrow><mo>*</mo></msup><mo>;</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="236">end for</p>
                </div>
                <div class="p1">
                    <p id="237" class="code-formula">
                        <mathml id="237"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>f</mtext><mtext>o</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>i</mi><mo>=</mo><mrow><mo>[</mo><mrow><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><mo>]</mo></mrow><mo>+</mo><mn>1</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mspace width="0.25em" /><mtext>d</mtext><mtext>o</mtext></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="238" class="code-formula">
                        <mathml id="238"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>j</mi><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub><mo>-</mo><mi>i</mi><mo>+</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo>;</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="239"><i>end for</i></p>
                </div>
                <div class="p1">
                    <p id="240">计算<mathml id="241"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold">X</mi><mo>=</mo><mi>f</mi><mi>f</mi><mi>t</mi><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold">X</mi><mo>¯</mo></mover><mo>, </mo><mo stretchy="false">[</mo><mo stretchy="false">]</mo><mo>, </mo><mn>3</mn><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="242">step 2 更新权重.对<i>j</i>=1, 2, …, <i>n</i><sub>3</sub>, <i>i</i>=1, 2, …, <i>m</i>, </p>
                </div>
                <div class="p1">
                    <p id="243">计算</p>
                </div>
                <div class="p1">
                    <p id="244"> (<i>w</i><mathml id="245"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup></mrow></math></mathml>) <sup><i>k</i>+1</sup>∈∂<i>g</i><sub><i>λ</i></sub> (<i>σ</i><sub><i>i</i></sub> ( (<b><i>X</i></b><sup><i>k</i>+1</sup>) <sup> (<i>j</i>) </sup>) ) .</p>
                </div>
                <h4 class="anchor-tag" id="246" name="246"><b>3.2</b> 收敛性分析</h4>
                <div class="p1">
                    <p id="247">先介绍超梯度的概念.次梯度是凸函数的梯度在非平滑点的扩展, 超梯度是非凸函数的梯度在非平滑点的扩展.如果<i>g</i> (<b><i>x</i></b>) 是凹的并且在<b><i>x</i></b>可微, 可知</p>
                </div>
                <div class="p1">
                    <p id="248"><i>g</i> (<b><i>x</i></b>) +〈∇<i>g</i> (<b><i>x</i></b>) , <b><i>y</i></b>-<b><i>x</i></b>〉≥<i>g</i> (<b><i>y</i></b>) </p>
                </div>
                <div class="p1">
                    <p id="249">如果<i>g</i> (<b><i>x</i></b>) 是凹的并且在<b><i>x</i></b>非平滑, 梯度扩展到超梯度<citation id="461" type="reference"><link href="408" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="250"><b>定义8</b> 令<i>g</i>∶<b>R</b><sup><i>n</i></sup>→<b>R</b>是凹的, 向量<b><i>v</i></b>为<i>g</i> (<b><i>x</i></b>) 在点<b><i>x</i></b>∈<b>R</b><sup>n</sup>的超梯度, 对于每个<b><i>y</i></b>∈<b>R</b><sup><i>n</i></sup>, </p>
                </div>
                <div class="p1">
                    <p id="251"><i>g</i> (<b><i>x</i></b>) +〈<b><i>v</i></b>, <b><i>y</i></b>-<b><i>x</i></b>〉≥<i>g</i> (<b><i>y</i></b>) .</p>
                </div>
                <div class="p1">
                    <p id="252">成立.</p>
                </div>
                <div class="p1">
                    <p id="253">如果<i>g</i> (<b><i>x</i></b>) 在<b><i>x</i></b>非平滑, <i>g</i> (<b><i>x</i></b>) 在<i>x</i>的超梯度可能不唯一, 所有超梯度的集合称为<i>g</i> (<b><i>x</i></b>) 在<b><i>x</i></b>的超微分, 并记为∂<i>g</i> (<b><i>x</i></b>) .如果<i>g</i> (<b><i>x</i></b>) 在<b><i>x</i></b>可微, ∇<i>g</i> (<b><i>x</i></b>) 是唯一的超梯度, 即</p>
                </div>
                <div class="p1">
                    <p id="254">∂<i>g</i> (<b><i>x</i></b>) ={∇<i>g</i> (<b><i>x</i></b>) }.</p>
                </div>
                <div class="p1">
                    <p id="255">对于凹函数<i>g</i>, -<i>g</i>是凸的, 反之亦然.根据这个事实, <i>g</i>的超梯度和-<i>g</i>的次梯度之间有如下关系.</p>
                </div>
                <div class="p1">
                    <p id="256"><b>引理2</b> 令<i>g</i> (<b><i>x</i></b>) 是凹的, 并且<i>h</i> (<b><i>x</i></b>) =-<i>g</i> (<b><i>x</i></b>) , 对于任意</p>
                </div>
                <div class="p1">
                    <p id="257"><b><i>v</i></b>∈∂<i>g</i> (<b><i>x</i></b>) , <b><i>u</i></b>=-<b><i>v</i></b>∈∂<i>h</i> (<b><i>x</i></b>) , </p>
                </div>
                <div class="p1">
                    <p id="258">反之亦然.</p>
                </div>
                <div class="p1">
                    <p id="259">引理2给出的超梯度和次梯度的关系可以引出超梯度的性质.对于任意<b><i>u</i></b><sub>1</sub>∈∂<i>h</i> (<b><i>x</i></b>) , <b><i>u</i></b><sub>2</sub>∈∂<i>h</i> (<b><i>y</i></b>) , 凸函数<i>h</i>的次微分是单调算子, 即</p>
                </div>
                <div class="p1">
                    <p id="260">〈<b><i>u</i></b><sub>1</sub>-<b><i>u</i></b><sub>2</sub>, <b><i>x</i>-<i>y</i></b>〉≥0.</p>
                </div>
                <div class="p1">
                    <p id="261">凹函数的超微分具有相反的性质, 称为反单调算子.</p>
                </div>
                <div class="p1">
                    <p id="262"><b>引理3</b><citation id="462" type="reference"><link href="432" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation> 对于任意<b><i>v</i></b><sub>1</sub>∈∂<i>g</i> (<b><i>x</i></b>) , <b><i>v</i></b><sub>2</sub>∈∂<i>g</i> (<b><i>y</i></b>) , 凹函数<i>g</i>的超微分是反单调算子, 即</p>
                </div>
                <div class="p1">
                    <p id="263">〈<b><i>v</i></b><sub>1</sub>-<b><i>v</i></b><sub>2</sub>, <b><i>x</i></b>-<b><i>y</i></b>〉≤0.      (8) </p>
                </div>
                <div class="p1">
                    <p id="264">引理3是收敛证明的一个重要引理.假设<i>g</i> (<b><i>x</i></b>) 满足假设A1, 当<b><i>x</i></b>≤<b><i>y</i></b>时, 由式 (8) 可得</p>
                </div>
                <div class="p1">
                    <p id="265"><b><i>v</i></b><sub>1</sub>≥<b><i>v</i></b><sub>2</sub>, <b><i>v</i></b><sub>1</sub>∈∂<i>g</i> (<b><i>x</i></b>) , <b><i>v</i></b><sub>2</sub>∈∂<i>g</i> (<b><i>y</i></b>) , </p>
                </div>
                <div class="p1">
                    <p id="266">即<i>g</i>的超梯度在[0, ∞) 上单调递减.</p>
                </div>
                <div class="p1">
                    <p id="267"><b>引理4</b> 设<i>f</i>∶<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>→<b>R</b>为连续可微函数, 具有Lipschitz连续梯度和Lipschitz常数<i>L</i> (<i>f</i>) , 那么, 对∀<b>X</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, <b>Y</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, <i>μ</i>≥<i>L</i> (<i>f</i>) , 有</p>
                </div>
                <div class="p1">
                    <p id="268"><mathml id="269"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>≤</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">Y</mi><mo stretchy="false">) </mo><mo>+</mo><mo>〈</mo><mi mathvariant="bold">X</mi><mo>-</mo><mi mathvariant="bold">Y</mi><mo>, </mo><mo>∇</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">Y</mi><mo stretchy="false">) </mo><mo>〉</mo><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold">X</mi><mo>-</mo><mi mathvariant="bold">Y</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mrow></math></mathml>.      (9) </p>
                </div>
                <div class="p1">
                    <p id="270"><b>定理2</b> 假设式 (1) 中的<i>g</i><sub><i>λ</i></sub>和<i>f</i>满足A1～A3假设, 算法1中生成的序列{<b>X</b><sup><i>k</i></sup>}满足:</p>
                </div>
                <div class="p1">
                    <p id="271">1) <i>F</i> (<b>X</b><sup><i>k</i></sup>) 单调递减, 即</p>
                </div>
                <div class="p1">
                    <p id="272" class="code-formula">
                        <mathml id="272"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo><mo>-</mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">) </mo><mo>≥</mo><mfrac><mrow><mi>μ</mi><mo>-</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup><mo>-</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>≥</mo><mn>0</mn><mo>;</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="273" class="code-formula">
                        <mathml id="273"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>2</mn><mo stretchy="false">) </mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>lim</mi></mrow></mstyle><mrow><mi>k</mi><mo>→</mo><mi>∞</mi></mrow></munder><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup><mo>-</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">) </mo><mo>=</mo><mn>0</mn><mo>;</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="274">3) 序列{<b>X</b><sup><i>k</i></sup>}有界.</p>
                </div>
                <div class="p1">
                    <p id="275"><b>证明</b> 首先, 根据A2假设, ∇<i>f</i>是Lipschitz连续的, 利用性质 (9) , 有</p>
                </div>
                <div class="area_img" id="276">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906002_27600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="278">然后, 根据<b>X</b><sup><i>k</i>+1</sup>是式 (6) 的最优解, 有</p>
                </div>
                <div class="p1">
                    <p id="279" class="code-formula">
                        <mathml id="279"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo>〈</mo><mo>∇</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo><mo>, </mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup><mo>〉</mo><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>≤</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="280">等价于</p>
                </div>
                <div class="p1">
                    <p id="281" class="code-formula">
                        <mathml id="281"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mo>〈</mo><mo>∇</mo><mi>f</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false">) </mo><mo>, </mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup><mo>-</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>〉</mo><mo>≥</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo>-</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>w</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mi>k</mi></msup><mo>-</mo><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mfrac><mi>μ</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="282">结合式 (3) 、式 (10) 及式 (11) , 有</p>
                </div>
                <div class="area_img" id="283">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201906002_28300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="285">因此, <i>F</i> (<b>X</b><sup><i>k</i></sup>) 为单调递减序列.进一步地, 令式 (12) 对所有<i>k</i>≥1求和, 可得</p>
                </div>
                <div class="p1">
                    <p id="286" class="code-formula">
                        <mathml id="286"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>μ</mi><mo>-</mo><mi>L</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo>+</mo><mi>∞</mi></mrow></munderover><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>-</mo><mi mathvariant="bold">X</mi><mtext> </mtext><msup><mrow></mrow><mi>k</mi></msup></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>≤</mo><mi>F</mi><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><msup><mtext> </mtext><mo>′</mo></msup><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="287">因为<i>μ</i>≥<i>L</i> (<i>f</i>) , 故</p>
                </div>
                <div class="p1">
                    <p id="288"><b>X</b><sup><i>k</i>+1</sup>-<b>X</b><sup><i>k</i></sup>→0.</p>
                </div>
                <div class="p1">
                    <p id="289">另外, 根据假设A3, {<b>X</b><sup><i>k</i></sup>}为有界序列, 有界序列必有收敛子列.</p>
                </div>
                <div class="p1">
                    <p id="290">定理2给出IRNN的收敛性.IRNN使目标函数值单调递减.由于{<b>X</b><sup><i>k</i></sup>}有界, 必然存在收敛子列, 进一步可知{<b>X</b><sup><i>k</i></sup>}的任何聚点为式 (1) 的平稳点.与文献<citation id="463" type="reference">[<a class="sup">11</a>]</citation>不同的是, 本文张量版本的IRNN在计算上更复杂.需要先从实数空间变换到傅里叶空间, 在这个复域上进行矩阵SVD并截断, 再应用反傅里叶变换回原来的实数空间.这里反变换需要保证仍得到实数张量.本文证明更一般化, 因此矩阵奇异值是定义在复数空间的矩阵上.所以算法和收敛性证明都要不断在实数和复数域上不断操作.</p>
                </div>
                <h3 id="291" name="291" class="anchor-tag">4 实验及结果分析</h3>
                <div class="p1">
                    <p id="292">本节通过在张量数据 (合成数据和真实图像) 上的低秩张量填充实验验证算法的有效性.模型 (1) 采用<i>g</i><sub><i>λ</i></sub> (<i>x</i>) =<i>λx</i><sup><i>p</i></sup>, 0&lt;<i>p</i>&lt;1, 并采用张量填充的损失函数.具体模型如下:</p>
                </div>
                <div class="p1">
                    <p id="293" class="code-formula">
                        <mathml id="293"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>λ</mi><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">X</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow></msup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mi>p</mi></msup><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>Ω</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo>-</mo><mi mathvariant="bold">Μ</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="294">其中, 损失函数的梯度是Lipschitz连续的, 相应的Lipschitz常数<i>L</i> (<i>f</i>) =1.将上述“基于<i>l</i><sub><i>p</i></sub> (0&lt;<i>p</i>&lt;1) 范数的非凸张量模型+算法1”记为迭代加权核范数 (Iteratively Reweighted Nuclear Norm, IRNN_ Lp (T) ) .</p>
                </div>
                <div class="p1">
                    <p id="295">在算法1中, <i>μ</i>设置为1.1, <i>λ</i>的初始值设为较大的值<i>λ</i><sub>0</sub>, 并且以<i>λ</i>=<i>η</i><sup><i>k</i></sup><i>λ</i><sub>0</sub> (<i>η</i>&lt;1) 动态减小, 直到达到一个预先给定的目标值<i>λ</i><sub><i>t</i></sub>, <b>X</b>的初始值设置为零张量, <i>p</i>从候选集中选择具有良好性能的参数.</p>
                </div>
                <h4 class="anchor-tag" id="296" name="296"><b>4.1</b> 合成数据低秩张量恢复</h4>
                <div class="p1">
                    <p id="297">本次实验采用合成张量数据, 验证IRNN_Lp (T) 的恢复性能.对比模型采用基于张量核范数 (Tensor Nuclear Norm, TNN) 的凸模型+ADMM<citation id="464" type="reference"><link href="428" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, 记为TNN_ADMM, 模型如下:</p>
                </div>
                <div class="p1">
                    <p id="298" class="code-formula">
                        <mathml id="298"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold">X</mi></munder><mspace width="0.25em" /><mi>λ</mi><mrow><mo>|</mo><mi mathvariant="bold">X</mi><mo>|</mo></mrow><msub><mrow></mrow><mo>*</mo></msub><mo>, </mo><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>Ω</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold">X</mi><mo stretchy="false">) </mo><mo>=</mo><mi mathvariant="bold">Ρ</mi><msub><mrow></mrow><mi>Ω</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold">Μ</mi><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="299">实验采用Lu等<citation id="465" type="reference"><link href="430" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>提出的方式随机产生管秩, 分别取5～15的11个张量<b>M</b>∈<b>R</b><sup><i>n</i><sub>1</sub>×<i>n</i><sub>2</sub>×<i>n</i><sub>3</sub></sup>, 张量的大小<i>n</i><sub>1</sub>=<i>n</i><sub>2</sub>=<i>n</i><sub>3</sub>=50, 每个张量随机丢失50%的元素.</p>
                </div>
                <div class="p1">
                    <p id="300">对每个只有部分元素已知的低秩张量, 分别采用IRNN_Lp (T) 和TNN_ADMM进行张量恢复得到<mathml id="301"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold">X</mi></mstyle><mo>︿</mo></mover><mo>.</mo></mrow></math></mathml>由于原张量<b>M</b>已知, 因此可以采用相对错误率<mathml id="302"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mo stretchy="false">|</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold">X</mi></mstyle><mo>︿</mo></mover><mo>-</mo><mi mathvariant="bold">Μ</mi><mo stretchy="false">|</mo><msub><mrow></mrow><mtext>F</mtext></msub></mrow><mrow><mrow><mo>|</mo><mi mathvariant="bold">Μ</mi><mo>|</mo></mrow><msub><mrow></mrow><mtext>F</mtext></msub></mrow></mfrac></mrow></math></mathml>评估恢复性能.</p>
                </div>
                <div class="p1">
                    <p id="303">类似于之前的一些工作<citation id="466" type="reference"><link href="428" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, 当相对错误率小于1e-3时, <mathml id="304"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold">X</mi></mstyle><mo>︿</mo></mover></mrow></math></mathml>视为对<b>M</b>的成功恢复.对于IRNN_Lp (T) , <i>μ</i>=1.1, <i>λ</i><sub>0</sub>取张量<b>M</b>中最大元素, <i>η</i>=0.9, <i>λ</i><sub><i>t</i></sub>= (1e-6) <i>λ</i><sub>0</sub>, <i>p</i>=0.5.TNN_ADMM采用Lu等<citation id="467" type="reference"><link href="430" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>建议的参数设置.</p>
                </div>
                <div class="p1">
                    <p id="305">对每个秩, 实验重复进行50次, 得到秩取值不同时不同算法的恢复成功率, 如图2所示.</p>
                </div>
                <div class="area_img" id="306">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906002_306.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 合成数据上的张量恢复性能对比" src="Detail/GetImg?filename=images/MSSB201906002_306.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 合成数据上的张量恢复性能对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906002_306.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Comparison of tensor recovery on synthetic data</p>

                </div>
                <div class="p1">
                    <p id="307">由图2可知, 相比TNN_ADMM, IRNN_Lp (T) 明显具有更好的恢复性能, 这是因为非凸替换函数比凸替换函数更接近张量的秩.该实验验证本文算法的有效性, 可以获得比凸模型更好的解.</p>
                </div>
                <h4 class="anchor-tag" id="308" name="308"><b>4.2</b> 图像恢复</h4>
                <div class="p1">
                    <p id="309">实验采用真实彩色图像, 验证IRNN_Lp (T) 的恢复性能, 对比模型算法包括:</p>
                </div>
                <div class="p1">
                    <p id="310">1) 基于<i>l</i><sub><i>p</i></sub>范数的非凸矩阵模型+IRNN<citation id="468" type="reference"><link href="408" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 记为IRNN_Lp (M) ;</p>
                </div>
                <div class="p1">
                    <p id="311">2) 基于矩阵核范数的凸模型+APGL<citation id="469" type="reference"><link href="406" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 记为APGL;</p>
                </div>
                <div class="p1">
                    <p id="312">3) TNN_ADMM<citation id="470" type="reference"><link href="426" rel="bibliography" /><link href="428" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="313">实验随机抽取Berkeley Segmentation数据集上的真实彩色图像进行测试.由于被测试的彩色图像有3个通道, 因此为一个3阶张量.本文设置随机丢失50%的元素.图像通常不是低秩的, 但最高的奇异值主导最主要信息<citation id="471" type="reference"><link href="416" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 因此, 仍可以通过低秩性质近似恢复损坏的图像.彩色图像 (张量) 含有3个通道 (矩阵) , APGL和IRNN_Lp (M) 低秩矩阵恢复算法可对每个通道 (矩阵) 独立应用算法求解, 最后合并得到恢复图像.TNN_ADMM和IRNN_Lp (T) 可直接对三个通道 (张量) 应用算法求解.类似诸多已有工作<citation id="472" type="reference"><link href="408" rel="bibliography" /><link href="424" rel="bibliography" /><link href="426" rel="bibliography" /><link href="428" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>, 实验采用最常用的峰值信噪比 (Peak Signal-to-Noise Ratio, PSNR) 评估恢复性能, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="314" class="code-formula">
                        <mathml id="314"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>S</mi><mi>Ν</mi><mi>R</mi><mo>=</mo><mn>1</mn><mn>0</mn><mi>lg</mi><mrow><mo> (</mo><mrow><mfrac><mrow><mrow><mo>|</mo><mi mathvariant="bold">Μ</mi><mo>|</mo></mrow><msubsup><mrow></mrow><mi>∞</mi><mn>2</mn></msubsup></mrow><mrow><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mn>1</mn></msub><mi>n</mi><msub><mrow></mrow><mn>2</mn></msub><mi>n</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mo stretchy="false">|</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold">X</mi></mstyle><mo>︿</mo></mover><mo>-</mo><mi mathvariant="bold">Μ</mi><mo stretchy="false">|</mo><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="315">PSNR值越高, 恢复性能越好.</p>
                </div>
                <div class="p1">
                    <p id="316">实验过程调整算法参数, 以获得最优参数及结果.对于IRNN_Lp (T) , <i>μ</i>=1.1, <i>λ</i><sub>0</sub>取<b>M</b>中最大元素, <i>η</i>=0.8, <i>λ</i><sub><i>t</i></sub>= (1e-4) <i>λ</i><sub>0</sub>, <i>p</i>=0.5.IRNN_Lp (M) 、APGL和TNN_ADMM均采用作者提供的代码及相应参数设置.</p>
                </div>
                <div class="p1">
                    <p id="317">图3为5幅原始图像上不同算法恢复结果对比.图4为相应的PSNR值和运行时间.图5为100幅图像上PSNR值和运行时间对比.由图3～图5可看出, IRNN_Lp (T) 具有更高的PSNR值, 表明具有更强的图像恢复能力.这不仅来自于张量结构建模, 更来自于非凸的函数能更好地逼近张量的管秩.运行时间对比可以看出本文方法比凸的TNN_ADMM更高效.</p>
                </div>
                <div class="area_img" id="387">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906002_38700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 真实图像上4种算法的恢复效果对比" src="Detail/GetImg?filename=images/MSSB201906002_38700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 真实图像上4种算法的恢复效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906002_38700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Recovery effect comparison of 4 algorithms on real images</p>

                </div>
                <div class="area_img" id="387">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906002_38701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 真实图像上4种算法的恢复效果对比" src="Detail/GetImg?filename=images/MSSB201906002_38701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 真实图像上4种算法的恢复效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906002_38701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Recovery effect comparison of 4 algorithms on real images</p>

                </div>
                <div class="area_img" id="334">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906002_33400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 真实图像上4种算法的PSNR值和运行时间对比" src="Detail/GetImg?filename=images/MSSB201906002_33400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 真实图像上4种算法的PSNR值和运行时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906002_33400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Comparison of PSNR values and running time of 4 algorithms on real images</p>

                </div>
                <div class="area_img" id="336">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201906002_33600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 100张图像上4种算法的PSNR值和运行时间对比" src="Detail/GetImg?filename=images/MSSB201906002_33600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 100张图像上4种算法的PSNR值和运行时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201906002_33600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Comparison of PSNR values and running time of 4 algorithms on 100 images</p>

                </div>
                <h3 id="337" name="337" class="anchor-tag">5 结 束 语</h3>
                <div class="p1">
                    <p id="338">本文研究基于非凸替换函数<i>l</i><sub><i>p</i></sub> (0&lt;<i>p</i>&lt;1) 范数的低秩张量恢复问题.由于非凸函数比凸函数更容易得到更低秩的近似解, 张量比矩阵更好地建模数据, 本文提出基于<i>l</i><sub><i>p</i></sub>范数的非凸低秩张量模型, 并提出迭代加权核范数张量算法, 用于求解非凸低秩张量最小化, 同时给出收敛性分析.在合成数据和真实彩色图像上的实验表明, 本文模型及相应的求解算法比凸张量模型及求解算法的恢复性能更强.在真实彩色图像上进一步对比不同的低秩矩阵模型和张量模型, 结果表明, 本文算法具有更好的恢复性能.今后从求解算法的角度可以考虑如何加速, 例如不用凹函数的线性近似, 而直接求解近邻算子.另一方面, 从模型的应用出发, 考虑低秩张量模型在视频分析上的应用.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="382" type="formula" href="images/MSSB201906002_38200.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">苏雅茹</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="383" type="formula" href="images/MSSB201906002_38300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">刘耿耿</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="384" type="formula" href="images/MSSB201906002_38400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">刘文犀</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="385" type="formula" href="images/MSSB201906002_38500.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">朱丹红</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="388">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES23DDE81F829D6912EE507D2D05EDC261&amp;v=MDQ3NTVtYUJ1SFlmT0dRbGZDcGJRMzVORmh3THkveGFvPU5pZk9mYkc3YXFXNXA0NHpiT2tHZUhvd3poUm1uenA5VHd2ZzJCSXdETWJuUjd5ZUNPTnZGU2lXV3I3SklGcA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> CUI A G, PENG J G, LI H Y.Exact Recovery Low-Rank Matrix via Transformed Affine Matrix Rank Minimization.Neurocomputing, 2018, 319:1-12.
                            </a>
                        </p>
                        <p id="390">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low-Rank Matrix Completion Using Nuclear Norm Minimization and Facial Reduction">

                                <b>[2]</b> HUANG S M, WOLKOWICZ H.Low-Rank Matrix Completion Using Nuclear Norm Minimization and Facial Reduction.Journal of Global Optimization, 2018, 72 (1) :5-26.
                            </a>
                        </p>
                        <p id="392">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An overview of low-rank matrix recovery from incomplete observations">

                                <b>[3]</b> DAVENPORT M A, ROMBERG J.An Overview of Low-Rank Matrix Recovery from Incomplete Observations.IEEE Journal of Selected Topics in Signal Processing, 2016, 10 (4) :608-622.
                            </a>
                        </p>
                        <p id="394">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB15D2534F44AA72FE7D5FBFC670C4411&amp;v=MzA1MTFKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZod0x5L3hhbz1OaWZPZmNHNUc2WE9xb3hCRXU4TGZRMCt6V0JtN1V0NFBnMlUzeFF5ZWNHUVFidWVDT052RlNpV1dyNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> YU S, YIQUAN W Q.Subspace Clustering Based on Latent Low Rank Representation with Frobenius Norm Minimization.Neurocomputing, 2018, 275:2479-2489.
                            </a>
                        </p>
                        <p id="396">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust Recovery of Subspace Structures by Low-Rank Representation">

                                <b>[5]</b> LIU G C, LIN Z C, YAN S C, et al.Robust Recovery of Subspace Structures by Low-Rank Representation.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (1) :171-184.
                            </a>
                        </p>
                        <p id="398">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000001869&amp;v=MDQxNTFJWTdLN0h0ak5yNDlGWk9zT0JIb3dvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRm9VYnhBPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> CANDÈS E J, LI X D, MA Y, et al.Robust Principal Component Analysis.Journal of the ACM, 2011, 58 (3) .DOI:10.1145/1970392.1970395.
                            </a>
                        </p>
                        <p id="400">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122400158681&amp;v=MDMzMjFMYklKRm9VYnhBPU5pZk9mYks5SDlQT3E0OUZaZTRIQ25RNG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> LIN X F, WEI G .Accelerated Reweighted Nuclear Norm Minimization Algorithm for Low Rank Matrix Recovery.Signal Processing, 2015, 114:24-33.
                            </a>
                        </p>
                        <p id="402">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Smoothed low rank and sparse matrix recovery by iteratively reweighted least squares minimization">

                                <b>[8]</b> LU C Y, LIN Z C, YAN S C.Smoothed Low Rank and Sparse Matrix Recovery by Iteratively Reweighted Least Squares Minimization.IEEE Transactions on Image Processing, 2015, 24 (2) :646-654.
                            </a>
                        </p>
                        <p id="404">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD121024002802&amp;v=MTA3MDhEaE04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWnU5dUZDdnNVN3ZNSUZzV05qN0Jhcks2SDlIT3E0OUZadU1Q&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> HAN D R, YUAN X M.A Note on the Alternating Direction Method of Multipliers.Journal of Optimization Theory and Applications, 2012, 155 (1) :227-238.
                            </a>
                        </p>
                        <p id="406">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems">

                                <b>[10]</b> TOH K C, YUN S W.An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Linear Least Squares Problems.Pacific Journal of Optimization, 2010, 6 (3) :615-640.
                            </a>
                        </p>
                        <p id="408">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonconvex Non-smooth Low-Rank Minimization via Iteratively Reweighted Nuclear Norm">

                                <b>[11]</b> LU C Y, TANG J H, YAN S C, et al.Nonconvex Nonsmooth Low Rank Minimization via Iteratively Reweighted Nuclear Norm.IEEE Transactions on Image Processing, 2016, 25 (2) :829-839.
                            </a>
                        </p>
                        <p id="410">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Power of Convex Relaxation: Near-Optimal Matrix Completion">

                                <b>[12]</b> CANDÉS E J, TAO T.The Power of Convex Relaxation:Near-Optimal Matrix Completion.IEEE Transactions on Information Theory, 2010, 56 (5) :2053-2080.
                            </a>
                        </p>
                        <p id="412">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low Rank Matrix Recovery via Augmented Lagrange Multiplier with Nonconvex Minimization">

                                <b>[13]</b> LEE J, CHOE Y.Low Rank Matrix Recovery via Augmented Lagrange Multiplier with Nonconvex Minimization // Proc of the 12th IEEE Image, Video, and Multidimensional Signal Processing Workshop.Washington, USA:IEEE, 2016.DOI:10.1109/IVMSPW.2016.7528217.
                            </a>
                        </p>
                        <p id="414">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Nonconvex Optimization Framework for Low Rank Matrix Estimation">

                                <b>[14]</b> ZHAO T, WANG Z R, LIU H.A Nonconvex Optimization Framework for Low Rank Matrix Estimation // JORDAN M I, LECUN Y, SOLLA S A, eds.Advances in Neural Information Processing Systems 28.Cambridge, USA:The MIT Press, 2015:559-567.
                            </a>
                        </p>
                        <p id="416">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JAXG201512015&amp;v=MDY2MTNZOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVTdyS0x5elRhYkc0SDlUTnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> CHEN W G, LI Y L.Stable Recovery of Low-Rank Matrix via Nonconvex Schatten p-Minimization.Science China (mathematics) , 2015, 58 (12) :2643-2654.
                            </a>
                        </p>
                        <p id="418">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor Robust Principal Component Analysis:Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization">

                                <b>[16]</b> LU C Y, FENG J S, CHEN Y D, et al.Tensor Robust Principal Component Analysis:Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2016:5249-5257.
                            </a>
                        </p>
                        <p id="420">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust low-rank tensor recovery:models and algorithms">

                                <b>[17]</b> GOLDFARB D, QIN Z W.Robust Low-Rank Tensor Recovery:Models and Algorithms.SIAM Journal on Matrix Analysis and Applications, 2014, 35 (1) :225-253.
                            </a>
                        </p>
                        <p id="422">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600897114&amp;v=MTM4OThNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZvVWJ4QT1OaWZPZmJLN0h0RE5xWTlGYk9JSURYMDlvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> KILMER M E, MARTIN C D.Factorization Strategies for Third-Order Tensors.Linear Algebra and Its Applications, 2011, 435 (3) :641-658.
                            </a>
                        </p>
                        <p id="424">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor Robust Principal Component Analysis with a New Tensor Nuclear Norm">

                                <b>[19]</b> LU C Y, FENG J S, CHEN Y D, et al.Tensor Robust Principal Component Analysis with a New Tensor Nuclear Norm[J/OL].[2018-12-12].https://arxiv.org/pdf/1804.03728v1.pdf.
                            </a>
                        </p>
                        <p id="426">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor Completion for Estimating Missing Values in Visual Data">

                                <b>[20]</b> LIU J, MUSIALSKI P, WONKA P, et al.Tensor Completion for Estimating Missing Values in Visual Data.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2013, 35 (1) :208-220.
                            </a>
                        </p>
                        <p id="428">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exact Low Tubal Rank Tensor Recovery from Gaussian Measurements">

                                <b>[21]</b> LU C Y, FENG J S, LIN Z C, et al.Exact Low Tubal Rank Tensor Recovery from Gaussian Measurements // Proc of the 27th International Joint Conference on Artificial Intelligence.New York, USA:ACM, 2018:2504-2510.
                            </a>
                        </p>
                        <p id="430">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generalized Singular Value Thresholding">

                                <b>[22]</b> LU C Y, ZHU C B, XU C Y, et al.Generalized Singular Value Thresholding // Proc of the 29th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2015:1805-1811.
                            </a>
                        </p>
                        <p id="432">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems">

                                <b>[23]</b> BECK A, TEBOULLE M.A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems.SIAM Journal on Imaging Sciences, 2009, 2 (1) :183-202.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201906002" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201906002&amp;v=MDk0MTVoVTdyTEtEN1liTEc0SDlqTXFZOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
