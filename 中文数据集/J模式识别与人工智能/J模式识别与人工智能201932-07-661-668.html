<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131453967530000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201907010%26RESULT%3d1%26SIGN%3dp9y%252bRV2p7jeOOe4HVNsCnptzADo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201907010&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201907010&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201907010&amp;v=MDM1OTBSbkZ5emhWTDNQS0Q3WWJMRzRIOWpNcUk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="1 用户偏好神经建模框架 ">1 用户偏好神经建模框架</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;1.1 符号及定义&lt;/b&gt;"><b>1.1 符号及定义</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;1.2 整体框架&lt;/b&gt;"><b>1.2 整体框架</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;1.3 用户的偏好特征&lt;/b&gt;"><b>1.3 用户的偏好特征</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;1.4 偏好传播&lt;/b&gt;"><b>1.4 偏好传播</b></a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;1.5 基于注意力的用户偏好抽取&lt;/b&gt;"><b>1.5 基于注意力的用户偏好抽取</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;1.6 框架优化&lt;/b&gt;"><b>1.6 框架优化</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;1.7 算法步骤&lt;/b&gt;"><b>1.7 算法步骤</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#175" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#212" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="表1 符号标识及说明">表1 符号标识及说明</a></li>
                                                <li><a href="#70" data-title="图1 用户的历史交互记录">图1 用户的历史交互记录</a></li>
                                                <li><a href="#77" data-title="图2 NUPM的整体框架">图2 NUPM的整体框架</a></li>
                                                <li><a href="#178" data-title="表2 实验数据集">表2 实验数据集</a></li>
                                                <li><a href="#192" data-title="表3 在点击率预测场景下各方法AUC和ACC的结果">表3 在点击率预测场景下各方法AUC和ACC的结果</a></li>
                                                <li><a href="#196" data-title="表4 三元组集的大小对实验结果的影响">表4 三元组集的大小对实验结果的影响</a></li>
                                                <li><a href="#199" data-title="表5 最大跳数对实验结果的影响">表5 最大跳数对实验结果的影响</a></li>
                                                <li><a href="#279" data-title="表6 相关性概率P&lt;sub&gt;i&lt;/sub&gt;对实验结果的影响">表6 相关性概率P<sub>i</sub>对实验结果的影响</a></li>
                                                <li><a href="#281" data-title="图3 d对实验结果的影响">图3 d对实验结果的影响</a></li>
                                                <li><a href="#282" data-title="图4 λ&lt;sub&gt;2&lt;/sub&gt;对实验结果的影响">图4 λ<sub>2</sub>对实验结果的影响</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="229">


                                    <a id="bibliography_1" title="HE X N, LIAO L Z, ZHANG H W, et al.Neural Collaborative Filtering//Proc of the 26th International Conference on World Wide Web.New York, USA:ACM, 2017:173-182." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural collaborative filtering">
                                        <b>[1]</b>
                                        HE X N, LIAO L Z, ZHANG H W, et al.Neural Collaborative Filtering//Proc of the 26th International Conference on World Wide Web.New York, USA:ACM, 2017:173-182.
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_2" title="WANG X, HE X N, FENG F L, et al.TEM:Tree-Enhanced Embedding Model for Explainable Recommendation//Proc of the 27th International Conference on World Wide Web.New York, USA:ACM, 2018:1543-1552." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=TEM:Tree-Enhanced Embedding Model for Explainable Recommendation">
                                        <b>[2]</b>
                                        WANG X, HE X N, FENG F L, et al.TEM:Tree-Enhanced Embedding Model for Explainable Recommendation//Proc of the 27th International Conference on World Wide Web.New York, USA:ACM, 2018:1543-1552.
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_3" title="BAYER I, HE X N, KANAGAL B, et al.A Generic Coordinate Descent Framework for Learning from Implicit Feedback//Proc of the 26th International Conference on World Wide Web.New York, USA:ACM, 2017:1341-1350." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Generic Coordinate Descent Framework for Learning from Implicit Feedback">
                                        <b>[3]</b>
                                        BAYER I, HE X N, KANAGAL B, et al.A Generic Coordinate Descent Framework for Learning from Implicit Feedback//Proc of the 26th International Conference on World Wide Web.New York, USA:ACM, 2017:1341-1350.
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_4" title="WANG H W, ZHANG F Z, HOU M, et al.SHINE:Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction//Proc of the 11th International Conference on Web Search and Data Mining.New York, USA:ACM, 2018:592-600." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SHINE:Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction">
                                        <b>[4]</b>
                                        WANG H W, ZHANG F Z, HOU M, et al.SHINE:Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction//Proc of the 11th International Conference on Web Search and Data Mining.New York, USA:ACM, 2018:592-600.
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_5" title="JAMALI M, ESTER M.A Matrix Factorization Technique with Trust Propagation for Recommendation in Social Networks//Proc of the4th ACM Conference on Recommender Systems.New York, USA:ACM, 2010:135-142." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Matrix Factorization Technique with Trust Propagation for Recommendation in Social Networks">
                                        <b>[5]</b>
                                        JAMALI M, ESTER M.A Matrix Factorization Technique with Trust Propagation for Recommendation in Social Networks//Proc of the4th ACM Conference on Recommender Systems.New York, USA:ACM, 2010:135-142.
                                    </a>
                                </li>
                                <li id="239">


                                    <a id="bibliography_6" title="ZHANG F Z, YUAN N J, LIAN D F, et al.Collaborative Knowledge Base Embedding for Recommender Systems//Proc of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2016:353-362." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaborative knowledge base embedding for recommender systems">
                                        <b>[6]</b>
                                        ZHANG F Z, YUAN N J, LIAN D F, et al.Collaborative Knowledge Base Embedding for Recommender Systems//Proc of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2016:353-362.
                                    </a>
                                </li>
                                <li id="241">


                                    <a id="bibliography_7" title="SUN Z, YANG J, ZHANG J, et al.Recurrent Knowledge Graph Embedding for Effective Recommendation//Proc of the 12th ACMConference on Recommender Systems.New York, USA:ACM, 2018:297-305." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recurrent Knowledge Graph Embedding for Effective Recommendation">
                                        <b>[7]</b>
                                        SUN Z, YANG J, ZHANG J, et al.Recurrent Knowledge Graph Embedding for Effective Recommendation//Proc of the 12th ACMConference on Recommender Systems.New York, USA:ACM, 2018:297-305.
                                    </a>
                                </li>
                                <li id="243">


                                    <a id="bibliography_8" title="WANG H W, ZHANG F Z, WANG J L, et al.Ripple Net:Propagating User Preferences on the Knowledge Graph for Recommender Systems//Proc of the 27th International Conference on Information and Knowledge Management.New York, USA:ACM, 2018:417-426." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ripple Net:Propagating User Preferences on the Knowledge Graph for Recommender Systems">
                                        <b>[8]</b>
                                        WANG H W, ZHANG F Z, WANG J L, et al.Ripple Net:Propagating User Preferences on the Knowledge Graph for Recommender Systems//Proc of the 27th International Conference on Information and Knowledge Management.New York, USA:ACM, 2018:417-426.
                                    </a>
                                </li>
                                <li id="245">


                                    <a id="bibliography_9" title="RENDLE S.Factorization Machines with Lib FM.ACM Transactions on Intelligent Systems and Technology, 2012, 3 (3) .DOI:10.1145/2168752.2168771." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000005874&amp;v=MTkwMzk9TmlmSVk3SzdIdGpOcjQ5RlpPc0tCSHM5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZvVGFCVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        RENDLE S.Factorization Machines with Lib FM.ACM Transactions on Intelligent Systems and Technology, 2012, 3 (3) .DOI:10.1145/2168752.2168771.
                                    </a>
                                </li>
                                <li id="247">


                                    <a id="bibliography_10" title="YU X, REN X, SUN Y Z, et al.Personalized Entity Recommendation:A Heterogeneous Information Network Approach//Proc of the 7th ACM International Conference on Web Search and Data Mining.New York, USA:ACM, 2014:283-292." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Personalized entity recommendation:A heterogeneous information network approach">
                                        <b>[10]</b>
                                        YU X, REN X, SUN Y Z, et al.Personalized Entity Recommendation:A Heterogeneous Information Network Approach//Proc of the 7th ACM International Conference on Web Search and Data Mining.New York, USA:ACM, 2014:283-292.
                                    </a>
                                </li>
                                <li id="249">


                                    <a id="bibliography_11" title="ZHAO H, YAO Q M, LI J D, et al.Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks//Proc of the 23th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2017:635-644." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks">
                                        <b>[11]</b>
                                        ZHAO H, YAO Q M, LI J D, et al.Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks//Proc of the 23th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2017:635-644.
                                    </a>
                                </li>
                                <li id="251">


                                    <a id="bibliography_12" title="WANG H W, ZHANG F Z, XIE X, et al.DKN:Deep Knowledge-Aware Network for News Recommendation//Proc of the27th International Conference on World Wide Web.New York, USA:ACM, 2018:1835-1844." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;DKN:deep knowledge-Aware network for news recommendation.&amp;quot;">
                                        <b>[12]</b>
                                        WANG H W, ZHANG F Z, XIE X, et al.DKN:Deep Knowledge-Aware Network for News Recommendation//Proc of the27th International Conference on World Wide Web.New York, USA:ACM, 2018:1835-1844.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(07),661-668 DOI:10.16451/j.cnki.issn1003-6059.201907010            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于知识图谱的用户偏好神经建模框架</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E6%A1%82%E6%98%8E&amp;code=41459761&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱桂明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AE%BE%E8%BE%B0%E5%BF%A0&amp;code=17547134&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宾辰忠</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8F%A4%E5%A4%A9%E9%BE%99&amp;code=10611130&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">古天龙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E7%82%9C&amp;code=24425572&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈炜</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BE%E4%B8%AD%E6%B5%A9&amp;code=41459760&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贾中浩</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E5%AD%A6%E9%99%A2&amp;code=0269119&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学计算机与信息安全学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%A1%82%E6%9E%97%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E5%B9%BF%E8%A5%BF%E5%8F%AF%E4%BF%A1%E8%BD%AF%E4%BB%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">桂林电子科技大学广西可信软件重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对目前基于特征和基于路径的知识图谱感知推荐方法的不足, 文中提出端到端的将知识图谱引入推荐系统的用户偏好神经建模框架 (NUPM) .该框架以用户在知识图谱中的历史访问项目为偏好起点, 通过知识图谱中实体间的关系链接传播用户偏好, 学习用户的潜在偏好, 同时使用注意力网络融合各传播阶段偏好特征以构建最终的用户偏好向量.在真实数据集上的对比实验表明文中框架在个性化推荐中对用户偏好刻画的有效性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">推荐系统;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">知识图谱;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%81%8F%E5%A5%BD%E4%BC%A0%E6%92%AD&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">偏好传播;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    朱桂明, 硕士研究生, 主要研究方向为机器学习、数据挖掘、推荐系统.E-mail:18770914075@163.com.;
                                </span>
                                <span>
                                    *宾辰忠 (通讯作者) , 博士研究生, 讲师, 主要研究方向为数据挖掘、智能推荐.E-mail:binchenzhong@163.com.;
                                </span>
                                <span>
                                    古天龙, 博士, 教授, 主要研究方向为知识工程、符号推理.E-mail:cctlgu@guet.edu.cn.;
                                </span>
                                <span>
                                    陈炜, 硕士研究生, 主要研究方向为机器学习、数据挖掘、推荐系统.E-mail:w_chen369@163.com.;
                                </span>
                                <span>
                                    贾中浩, 硕士研究生, 主要研究方向为机器学习、数据挖掘、推荐系统.E-mail:1090994959@qq.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-04-17</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.U1711263, U1501252, 61572146);</span>
                                <span>广西自然科学基金项目 (No.2016GXNSFDA380006, AC16380122);</span>
                                <span>广西创新驱动重大专项项目 (No.AA17202024);</span>
                                <span>广西信息科学实验中心平台建设项目 (No.PT1601);</span>
                                <span>广西高校中青年教师基础能力提升项目 (No.2018KY0203) 资助;</span>
                    </p>
            </div>
                    <h1><b>Neural User Preference Modeling Framework Based on Knowledge Graph</b></h1>
                    <h2>
                    <span>ZHU Guiming</span>
                    <span>BIN Chenzhong</span>
                    <span>GU Tianlong</span>
                    <span>CHEN Wei</span>
                    <span>JIA Zhonghao</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Information Security, Guilin University of Electronic Technology</span>
                    <span>Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>An end-to-end neural user preference modeling framework incorporating knowledge graph into recommender systems, neural user preference modeling framework based on knowledge graph (NUPM) , is proposed aiming at the limitations of the current feature-based and path-based knowledge aware recommendation method. Historical interaction items of users in knowledge graph are considered as preference origin of NUPM. Then, potential preferences of users are learned by propagating user interests through relational links between entities in knowledge graph. Furthermore, an attention network is exploited to combine the preference features of different propagation stages to construct final user preference vector. The experimental results on real dataset show the effectiveness of NUPM in personalized recommendation for characterizing user preference.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Recommender%20System&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Recommender System;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Knowledge%20Graph&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Knowledge Graph;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Preference%20Propagation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Preference Propagation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Attention%20Mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Attention Mechanism;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHU Guiming, master student. His research interests include machine learning, data mining and recommender system.;
                                </span>
                                <span>
                                    BIN Chenzhong ( Corresponding author) , Ph. D. candidate, lecturer. His research interests include data mining and intelligent recommendation.;
                                </span>
                                <span>
                                    GU Tianlong, Ph. D. , professor. His research interests include knowledge engineering and symbolic reasoning.;
                                </span>
                                <span>
                                    CHEN Wei, master student. His research interests include machine learning, data mining and recommender system.;
                                </span>
                                <span>
                                    JIA Zhonghao, master student. His research interests include machine learning, data mining and recommender system.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-04-17</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.U1711263, U1501252, 61572146);</span>
                                <span>Natural Science Foundation of Guangxi Province (No.2016GXNSFDA380006, AC16380122);</span>
                                <span>Innovation-Driven Major Projects of Guangxi Province (NoAA17202024);</span>
                                <span>Guangxi Information Science Experiment Center Platform Construction Project (No.PT1601);</span>
                                <span>Basic Ability Promotion Project for Young and Middle-aged Teachers in Universities of Guangxi (No.2018KY0203);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="43">基于协同过滤 (Collaborative Filtering) 的推荐系统只使用用户和项目的历史交互信息 (显示或隐式反馈) 作为输入<citation id="253" type="reference"><link href="229" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 这带来两个问题:1) 在真实的应用场景中, 用户和项目的交互数据通常非常稀疏.使用如此稀疏的交互数据预测大量未知的项目会极大增加算法过拟合的风险.2) 对于新加入的用户或项目, 由于系统无历史交互信息, 无法准确建模用户的兴趣偏好, 也无法给用户推送个性化的信息, 这种情况称为冷启动 (Cold Start) 问题.</p>
                </div>
                <div class="p1">
                    <p id="44">解决数据稀疏性和冷启动问题的一个常见思路是在推荐算法中额外引入一些辅助信息.常用的辅助信息有用户画像<citation id="254" type="reference"><link href="231" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、项目属性<citation id="256" type="reference"><link href="233" rel="bibliography" /><link href="235" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>及社交网络<citation id="255" type="reference"><link href="237" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等.在各种辅助信息中, 知识图谱因为对实体和概念具有更高的覆盖率及更丰富的语义关系, 吸引研究者们的关注<citation id="257" type="reference"><link href="239" rel="bibliography" /><link href="241" rel="bibliography" /><link href="243" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="45">目前将知识图谱引入推荐系统的方法可以分为两类:基于特征的方法和基于路径的方法.基于特征的方法统一地将用户和项目的特征作为推荐算法的输入<citation id="258" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>.这类方法通过知识图谱特征学习得到实体 (用户、项目) 和关系的低维特征表示, 并应用到推荐任务中, 但是这类方法不是专门为知识图谱设计的, 因此不能有效利用知识图谱的所有信息.基于路径的方法将知识图谱视为一个有向异构图, 构建项目之间基于元路径的特征<citation id="260" type="reference"><link href="247" rel="bibliography" /><link href="249" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>.基于路径的方法以更有效、直观的方式利用知识图谱的结构信息, 然而, 该类方法严重依赖手工提取的特征以表示路径的语义.此外, 这类方法无法应用到实体不属于同一个领域 (如新闻推荐中的实体可能属于多个不同的领域) 的场景中<citation id="259" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 元路径无法在实体不属于同一个领域的情况下被预定义.</p>
                </div>
                <div class="p1">
                    <p id="46">本文提出基于知识图谱的用户偏好神经建模框架 (Neural User Preference Modeling Framework Based on Knowledge Graph, NUPM) .与上述工作不同之处在于, 本文结合基于路径的方法和基于特征的方法, 通过知识图谱中包含的丰富的语义信息建模用户偏好, 再利用注意力网络区分用户不同阶段下的偏好特征, 以此生成用户的偏好向量.相比现有方法, NUPM能够自动获取路径中实体间的语义关系及实体和关系的序列依赖关系, 在知识图谱传播用户的偏好中以一种更自然有效的方式结合知识图谱与个性化推荐任务, 注意力网络的使用使生成的推荐更准确和多样化.</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag">1 用户偏好神经建模框架</h3>
                <h4 class="anchor-tag" id="48" name="48"><b>1.1 符号及定义</b></h4>
                <div class="p1">
                    <p id="49">表1给出本文使用的全部符号.</p>
                </div>
                <div class="area_img" id="50">
                    <p class="img_tit">表1 符号标识及说明 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Symbol identification and description</p>
                    <p class="img_note"></p>
                    <table id="50" border="1"><tr><td><br />符号</td><td>说明</td></tr><tr><td><br /><i>U</i>={<i>u</i><sub>1</sub>, <i>u</i><sub>2</sub>, …, <i>u</i><sub><i>m</i></sub>}</td><td>用户集</td></tr><tr><td><br /><i>V</i>={<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, …, <i>v</i><sub><i>n</i></sub>}</td><td>项目集</td></tr><tr><td><br /><b><i>Y</i></b></td><td>用户-项目交互矩阵</td></tr><tr><td><br /><i>ε</i>={<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, …, <i>e</i><sub><i>k</i></sub>}</td><td>实体集</td></tr><tr><td><br /><i>R</i>={<i>r</i><sub>1</sub>, <i>r</i><sub>2</sub>, …, <i>r</i><sub><i>g</i></sub>}</td><td>实体关系集</td></tr><tr><td><br /><i>G</i></td><td>知识图谱</td></tr><tr><td><br /><i>L</i></td><td>知识图谱中链接的集合</td></tr><tr><td><br /><i>A</i></td><td>实体类型集合</td></tr><tr><td><br /><i>ε</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></td><td>用户<i>u</i>在<i>k</i>跳下的相关实体集</td></tr><tr><td><br /><i>S</i><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></td><td>用户<i>u</i>在<i>k</i>跳下的三元组集</td></tr><tr><td><br /><i>H</i><sub><i>u</i></sub>={<i>h</i><sub>1</sub>, <i>h</i><sub>2</sub>, …, <i>h</i><sub><i>T</i></sub>}</td><td>用户<i>u</i>的历史交互记录</td></tr><tr><td><br /><i>P</i><sub><i>i</i></sub></td><td>相关性概率</td></tr><tr><td><br /><b><i>O</i></b><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></td><td>用户<i>u</i> 在<i>k</i>跳下的偏好特征</td></tr><tr><td><br /><i>Att</i></td><td>注意力网络</td></tr><tr><td><br /><i>w</i><sub><i>k</i></sub></td><td><i>k</i>跳偏好特征的权重</td></tr><tr><td><br /><b><i>u</i></b></td><td>用户<i>u</i>的偏好向量</td></tr><tr><td><br /><i>y</i><sub><i>uv</i></sub></td><td>用户<i>u</i>与项目<i>v</i>交互的概率</td></tr><tr><td><br /><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo stretchy="false"> (</mo><mi>u</mi><mo>, </mo><mi>v</mi><mo stretchy="false">|</mo><mi>Θ</mi><mo stretchy="false">) </mo></mrow></math></td><td>预测函数</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="51">用户-项目交互矩阵<mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Y</mi><mo>=</mo><mo stretchy="false">{</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>u</mi><mi>v</mi></mrow></msub><mo stretchy="false">|</mo><mi>u</mi><mo>∈</mo><mi>U</mi><mo>, </mo><mi>v</mi><mo>∈</mo><mi>V</mi><mspace width="0.25em" /><mo stretchy="false">}</mo></mrow></math></mathml>:当用户<i>u</i>和项目<i>v</i>有过交互时, <i>y</i><sub><i>uv</i></sub>= 1;否则, <i>y</i><sub><i>uv</i></sub>=0.除了用户-项目交互矩阵<b><i>Y</i></b>, 还需要知识图谱<i>G</i>, <i>G</i>由大量的实体-关系-实体三元组 (<i>h</i>, <i>r</i>, <i>t</i>) 组成, 其中<i>h</i>、<i>r</i>、<i>t</i>分别为知识图谱三元组的头实体、关系、尾实体.</p>
                </div>
                <div class="p1">
                    <p id="53"><b>定义1</b>知识图谱<i>G</i> 定义<i>ε</i>= {<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, …, <i>e</i><sub><i>k</i></sub>}表示实体, <i>R</i> = {<i>r</i><sub>1</sub>, <i>r</i><sub>2</sub>, …, <i>r</i><sub><i>g</i></sub>}表示实体关系集.知识图谱<i>G</i>= (<i>ε</i>, <i>L</i>) 为具有实体类型映射函数ϕ∶<i>ε</i>→<i>A</i>以及链接类型映射函数<i>ψ</i>∶<i>L</i>→<i>R</i>的有向图.每个实体<i>e</i>∈<i>ε</i>都属于一种实体类型ϕ (<i>e</i>) ∈ <i>A</i>, 每个链接<i>l</i>∈<i>L</i>都属于一种链接类型<i>ψ</i> (<i>l</i>) ∈ <i>R</i>.</p>
                </div>
                <div class="p1">
                    <p id="54">本文研究的知识图谱可以看作是一种异构信息网络, 即知识图谱中包含不止1种实体和实体间的关系, 也即<mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>A</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo>, </mo><mo stretchy="false">|</mo><mi>R</mi><mo stretchy="false">|</mo><mo>&gt;</mo><mn>1</mn><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="56"><b>定义2</b>相关实体集<i>ε</i><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>给定用户-项目的交互矩阵<b><i>Y</i></b>, 知识图谱<i>G</i>, 用户<i>u</i>的<i>k</i>跳相关实体集定义如下:</p>
                </div>
                <div class="p1">
                    <p id="58" class="code-formula">
                        <mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>ε</mi><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mo stretchy="false">{</mo><mi>t</mi><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>G</mi><mspace width="0.25em" /><mo>&amp;</mo><mspace width="0.25em" /><mi>h</mi><mo>∈</mo><mi>ε</mi><msubsup><mrow></mrow><mi>u</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>k</mi><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Τ</mi><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="59">其中<mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ε</mi><msubsup><mrow></mrow><mi>u</mi><mn>0</mn></msubsup><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mi>Η</mi><msub><mrow></mrow><mi>u</mi></msub><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mo stretchy="false">{</mo><mi>v</mi><mo stretchy="false">|</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>u</mi><mi>v</mi></mrow></msub><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mn>1</mn><mo stretchy="false">}</mo></mrow></math></mathml>, 即用户<i>u</i>的历史交互记录可以看作是用户<i>u</i>在知识图谱<i>G</i>中的种子项目集.</p>
                </div>
                <div class="p1">
                    <p id="61">相关实体可以看作是用户兴趣在知识图谱上的自然扩展.给定相关实体的定义, 用户<i>u</i>的<i>k</i>跳三元组集定义如下.</p>
                </div>
                <div class="p1">
                    <p id="62"><b>定义3</b>三元组集<i>S</i><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>用户<i>u</i>的<i>k</i>跳三元组集<i>S</i><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>定义为从<i>ε</i><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>开始的三元组集:</p>
                </div>
                <div class="p1">
                    <p id="66" class="code-formula">
                        <mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>S</mi><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup><mspace width="0.25em" /><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>G</mi><mspace width="0.25em" /><mo>&amp;</mo><mspace width="0.25em" /><mi>h</mi><mo>∈</mo><mi>ε</mi><msubsup><mrow></mrow><mi>u</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">}</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>k</mi><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mn>1</mn><mo>, </mo><mn>2</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>Τ</mi><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="67">图1为用户的历史交互记录.若《拯救大兵瑞恩》为用户<i>u</i>历史看过的其中一部电影, 则用户<i>u</i>的1跳相关实体集<i>ε</i><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>为</p>
                </div>
                <div class="p1">
                    <p id="69">{剧情, 美国, 斯皮尔伯格, 汤姆汉克斯}, </p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 用户的历史交互记录" src="Detail/GetImg?filename=images/MSSB201907010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 用户的历史交互记录  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907010_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Historical interaction of user</p>

                </div>
                <div class="p1">
                    <p id="71">2跳相关实体集<i>ε</i><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>为</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">{辛德勒名单, 荒岛余生, 阿甘正传, 幸福终点站}.</p>
                </div>
                <div class="p1">
                    <p id="74">随着跳数<i>k</i>的增大, 一个项目的三元组集可能会变得非常大, 极大增加计算开销.因此, 在实际应用中, 最大跳数<i>T</i>一般不会很大.在本文实验中<i>T</i>=2, 因为距离用户历史交互项目太远的实体可能会带来额外的噪声, 同时也会增加算法复杂度.</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>1.2 整体框架</b></h4>
                <div class="p1">
                    <p id="76">NUPM的整体框架如图2所示.具体地, NUPM首先接收某位用户历史访问的项目及待推荐的项目.将用户的历史交互记录<i>H</i><sub><i>u</i></sub>作为知识图谱中的种子项目, 沿着知识图谱中的链接迭代地向外扩展得到不同跳数下的用户偏好特征.考虑到不同跳数下的用户偏好特征对表征该用户偏好向量的重要程度不同, 本文将上述用户偏好特征与项目的表示向量同时输入到注意力网络中, 计算不同跳数下用户偏好特征的权重, 通过计算不同跳数下用户偏好特征的加权和得到用户最终的偏好向量.再将用户偏好向量与候选项目的表示向量进行内积运算, 得到用户与该项目交互 (点击、浏览等) 的概率.</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907010_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 NUPM的整体框架" src="Detail/GetImg?filename=images/MSSB201907010_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 NUPM的整体框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907010_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Overall framework of NUPM</p>

                </div>
                <h4 class="anchor-tag" id="78" name="78"><b>1.3 用户的偏好特征</b></h4>
                <div class="p1">
                    <p id="79">基于协同过滤 (Collaborative filtering) 的方法首先学习用户和项目的隐层表示, 再直接通过内积的方法计算预测的用户对项目的评分.在NUPM中为了更准确地建模用户和项目的交互, 本文通过在知识图谱上传播用户兴趣, 发掘用户的潜在偏好.</p>
                </div>
                <div class="p1">
                    <p id="80">如图2所示, 每个项目<i>v</i>都有一个对应的向量表示<b><i>v</i></b>∈<b>R</b><sup><i>d</i></sup>, 其中<i>d</i>为向量表示的维度, 一个项目的向量表示由该项目的属性生成.给定项目<i>v</i>的特征向量<b><i>v</i></b>及用户<i>u</i>的某个历史交互项目<i>h</i><sub><i>k</i></sub> (<i>k</i>=1, 2, …, <i>T</i> ) , 在知识图谱<i>G</i>上以<i>h</i><sub><i>k</i></sub>为种子项目, 沿着<i>h</i><sub><i>k</i></sub>的链接扩展得到1跳三元组集<i>S</i><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>, 通过计算候选项目<i>v</i>, <i>S</i><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>中三元组的头实体<i>h</i><sub><i>i</i></sub>及关系<i>r</i><sub><i>i</i></sub>间的相似性为<i>S</i><mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>中的每个三元组 (<i>h</i><sub><i>i</i></sub>, <i>r</i><sub><i>i</i></sub>, <i>t</i><sub><i>i</i></sub>) 都生成一个相关性概率<i>P</i><sub><i>i</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="84"><i>P</i><sub><i>i</i></sub>=softmax<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">v</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">v</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>S</mi><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></munder><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">v</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">r</mi><mi mathvariant="bold-italic">h</mi><mo stretchy="false">) </mo></mrow></mfrac><mspace width="0.25em" /><mo>, </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="86">其中, <b><i>r</i></b><sub><i>i</i></sub>∈<b>R</b><sup><i>d</i>×<i>d</i></sup>为关系<i>r</i><sub><i>i</i></sub>的向量表示, <i>h</i><sub><i>i</i></sub>∈<b>R</b><sup><i>d</i></sup>为头实体<i>h</i><sub><i>i</i></sub>的向量表示, softmax确保所有计算的相关性概率之和为1.<i>P</i><sub><i>i</i></sub>可以认为是项目<i>v</i>和头实体<i>h</i><sub><i>i</i></sub>在关系<i>r</i><sub><i>i</i></sub>上的相似度.需要注意的是计算上述相关性概率<i>P</i><sub><i>i</i></sub>时必须考虑到关系<i>r</i><sub><i>i</i></sub>, 因为在不同的关系下, 项目<i>v</i>和头实体<i>h</i><sub><i>i</i></sub>的相似度可能不同.例如图1中《拯救大兵瑞恩》和《辛德勒名单》, 当考虑导演和类型时, 它们高度相似, 但是从主演的角度它们完全不同.</p>
                </div>
                <div class="p1">
                    <p id="87">在得到1跳三元组集<i>S</i><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>中的每个三元组 (<i>h</i><sub><i>i</i></sub>, <i>r</i><sub><i>i</i></sub>, <i>t</i><sub><i>i</i></sub>) 相关性概率后, 对于1跳三元组集<i>S</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>中所有三元组 (<i>h</i><sub><i>i</i></sub>, <i>r</i><sub><i>i</i></sub>, <i>t</i><sub><i>i</i></sub>) 的尾实体<i>t</i><sub><i>i</i></sub>, 通过对应的相关性概率<i>P</i><sub><i>i</i></sub>进行加权求和, 得到用户<i>u</i>在1跳下的偏好特征<b><i>O</i></b><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>:</p>
                </div>
                <div class="p1">
                    <p id="91"><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ο</mi><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>h</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>∈</mo><mi>S</mi><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></munder><mi>Ρ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>,      (2) </p>
                </div>
                <div class="p1">
                    <p id="93">其中<b><i>t</i></b><sub><i>i</i></sub>∈<b>R</b><sup><i>d</i></sup>为尾实体<i>t</i><sub><i>i</i></sub>的向量表示.</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>1.4 偏好传播</b></h4>
                <div class="p1">
                    <p id="95">通过式 (1) 和式 (2) 中的操作可以将用户<i>u</i>的兴趣偏好从他的历史交互记录<i>H</i><sub><i>u</i></sub>沿着1跳三元组集<i>S</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>中的链接传播到他的1跳相关实体<i>ε</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>中, 这个过程称为用户<i>u</i>的偏好传播.</p>
                </div>
                <div class="p1">
                    <p id="98">通过将式 (1) 中项目<i>v</i>的表示向量<b><i>v</i></b>替换为用户<i>u</i>在1跳下的偏好特征<b><i>O</i></b><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>以重复上述偏好传播过程.如图2所示, 将<b><i>O</i></b><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>作为用户<i>u</i>的历史兴趣沿着2跳三元组集<i>S</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>中的链接传播到用户的2跳相关实体<i>ε</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>中, 重复式 (1) 和式 (2) 中的操作, 以此得到用户<i>u</i>的2跳偏好特征<b><i>O</i></b><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>.该过程迭代地在用户<i>u</i>的<i>k</i>跳三元组<i>S</i><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml> (<i>k</i> = 1, 2, …, <i>T</i>) 上执行.因此, 一位用户的偏好从他的历史交互记录<i>H</i><sub><i>u</i></sub>传播到距他的历史交互记录<i>T</i>跳远的实体<i>ε</i><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>Τ</mi></msubsup></mrow></math></mathml>上, 由此可以得到用户<i>u</i>在不同跳数<i>k</i>下的偏好特征:<b><i>O</i></b><mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>, <b><i>O</i></b><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>, …, <b><i>O</i></b><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>Τ</mi></msubsup></mrow></math></mathml>.用户<i>u</i>相对于项目<i>v</i>最终的偏好向量<b><i>u</i></b>可以通过简单地累加上述不同跳数下的用户偏好特征得到:</p>
                </div>
                <div class="p1">
                    <p id="109"><b><i>u</i></b>=<b><i>O</i></b><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>+ <b><i>O</i></b><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>+ … + <b><i>O</i></b><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>Τ</mi></msubsup></mrow></math></mathml>.      (3) </p>
                </div>
                <div class="p1">
                    <p id="113">理论上随着跳数<i>k</i>的增加, 最后一跳下的用户<i>u</i>的偏好特征<b><i>O</i></b><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>Τ</mi></msubsup></mrow></math></mathml>包含前面所有偏好特征的信息.但是, 类似于水波的传播, 距离水波中心越远, 波纹越小, 前面的偏好特征信息可能会在<b><i>O</i></b><sup>T</sup><sub><i>u</i></sub>处减弱, 因此必须将所有跳数下的偏好特征进行叠加.</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>1.5 基于注意力的用户偏好抽取</b></h4>
                <div class="p1">
                    <p id="116">1.4节方法未考虑到不同跳数下用户<i>u</i>的偏好特征<b><i>O</i></b><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>对表征用户最终的偏好向量<b><i>u</i></b>的重要程度的不同.如图2所示, 为了更全面地表征用户的偏好, 本文提出在计算得到用户<i>u</i>不同跳数下的偏好特征<b><i>O</i></b><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>, <b><i>O</i></b><mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>, …, <b><i>O</i></b><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>Τ</mi></msubsup></mrow></math></mathml>后, 将上述偏好特征和项目<i>v</i>的向量表示<b><i>v</i></b>同时输入到一个注意力网络<i>Att</i>中以建模不同跳数下用户<i>u</i>的偏好特征<b><i>O</i></b><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>对用户<i>u</i>最终的偏好向量<b><i>u</i></b>的不同影响.通过注意力网络<i>Att</i>计算不同跳数<i>k</i>下用户<i>u</i>的偏好特征<b><i>O</i></b><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>的权重<i>w</i><sub><i>k</i></sub>:</p>
                </div>
                <div class="area_img" id="123">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201907010_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="125">注意力网络<i>Att</i>将不同跳数<i>k</i>下的偏好特征<b><i>O</i></b><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>和项目<i>v</i>的表示向量<b><i>v</i></b>作为输入, 输出不同跳数<i>k</i>下的偏好特征<b><i>O</i></b><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>对应的权重<i>w</i><sub><i>k</i></sub>.再将用户<i>u</i>不同跳数下的特征表示<b><i>O</i></b><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>1</mn></msubsup></mrow></math></mathml>, <b><i>O</i></b><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>, …, <b><i>O</i></b><mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>Τ</mi></msubsup></mrow></math></mathml>分别与对应的权重<i>w</i><sub><i>k</i></sub>进行加权求和, 得到最终用户<i>u</i>相对于项目<i>v</i>的偏好向量<b><i>u</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="131"><mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mi mathvariant="bold-italic">Ο</mi><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>.      (5) </p>
                </div>
                <div class="p1">
                    <p id="133">给定用户<i>u</i>的偏好向量<b><i>u</i></b>及项目<i>v</i>的向量表示<b><i>v</i></b>, 用户<i>u</i>与项目<i>v</i>交互的概率<i>y</i><sub><i>uv</i></sub>通过计算用户<i>u</i>的偏好向量<b><i>u</i></b>和项目<i>v</i>的向量表示<b><i>v</i></b>间的内积得到:</p>
                </div>
                <div class="p1">
                    <p id="134"><i>y</i><sub><i>uv</i></sub>=<i>σ</i> (<b><i>u</i></b><sup>T</sup><b><i>v</i></b>) ,      (6) </p>
                </div>
                <div class="p1">
                    <p id="135">其中<i>σ</i> (<i>x</i>) = (1+<i>e</i><sup>-<i>x</i></sup>) <sup>-1</sup>为sigmoid函数.</p>
                </div>
                <div class="p1">
                    <p id="136">NUPM利用知识图谱包含的丰富实体和语义关系, 通过偏好传播辅助建模用户偏好, 在一定程度上解决数据稀疏性问题, 增加推荐结果的准确性和多样性.NUPM具有一定的通用性, 在电影、音乐、书籍、新闻等场景下都可以通过构建相应领域的知识图谱, 建模用户的兴趣偏好.</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137"><b>1.6 框架优化</b></h4>
                <div class="p1">
                    <p id="138">给定知识图谱<i>G</i>和隐式反馈矩阵<b><i>Y</i></b>, 框架优化的目标是最大化框架参数<i>θ</i>的后验概率:</p>
                </div>
                <div class="p1">
                    <p id="139"><mathml id="140"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>max</mi></mrow><mspace width="0.25em" /><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">|</mo><mi>G</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo></mrow></math></mathml>,      (7) </p>
                </div>
                <div class="p1">
                    <p id="141">其中<i>Θ</i>包括所有实体、关系和项目的嵌入.因此等价于最大化:</p>
                </div>
                <div class="p1">
                    <p id="142" class="code-formula">
                        <mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">|</mo><mi>G</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Θ</mi><mo>, </mo><mi>G</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo></mrow><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>G</mi><mo>, </mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>∝</mo></mtd></mtr><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo>, </mo><mi>G</mi><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="143">根据Bayes理论, <i>p</i> (<i>Θ</i>) 表示框架参数<i>Θ</i>的先验概率, 参考文献<citation id="261" type="reference">[<a class="sup">6</a>]</citation>, 本文将<i>p</i> (<i>Θ</i>) 设为具有0均值及一个对角协方差矩阵的高斯分布:</p>
                </div>
                <div class="p1">
                    <p id="144"><i>p</i> (<i>Θ</i>) =<i>N</i> (0, <i>λ</i><mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml><i>I</i>) .      (9) </p>
                </div>
                <div class="p1">
                    <p id="146"><mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">) </mo></mrow></math></mathml>为当给定<i>Θ</i>时知识图谱<i>G</i>的似然函数.在NUPM中使用张量因子分解为知识图谱特征学习定义似然函数:</p>
                </div>
                <div class="p1">
                    <p id="148" class="code-formula">
                        <mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∏</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>ε</mi><mo>×</mo><mi>R</mi><mo>×</mo><mi>ε</mi></mrow></munder><mi>p</mi></mstyle><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∏</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>ε</mi><mo>×</mo><mi>R</mi><mo>×</mo><mi>ε</mi></mrow></munder><mi>Ν</mi></mstyle><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>h</mi><mo>, </mo><mi>r</mi><mo>, </mo><mi>t</mi></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">h</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi>R</mi><mi>t</mi><mo>, </mo><mi>λ</mi><msubsup><mrow></mrow><mn>2</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="149">当 (<i>h</i>, <i>r</i>, <i>t</i>) ∈<i>G</i>时, <i>I</i><sub><i>h</i>, <i>r</i>, <i>t</i></sub>=1;否则, <i>I</i><sub><i>h</i>, <i>r</i>, <i>t</i></sub>=0.基于式 (10) 知识图谱特征学习中的实体-实体对及偏好传播中的项目-实体对的得分函数可以统一于同个计算框架中.式 (8) 中的最后一项<mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo>, </mo><mi>G</mi><mo stretchy="false">) </mo></mrow></math></mathml>为当给定框架参数<i>Θ</i>和知识图谱<i>G</i>时隐式反馈<b><i>Y</i></b>的似然函数, 定义为Bernoulli分布的乘积:</p>
                </div>
                <div class="p1">
                    <p id="151" class="code-formula">
                        <mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo>, </mo><mi>G</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mstyle displaystyle="true"><munder><mo>∏</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo>, </mo><mi mathvariant="bold-italic">v</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>Y</mi></mrow></munder><mi>σ</mi></mstyle><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mrow><mi>u</mi><mi>v</mi></mrow></msub></mrow></msup><mo>⋅</mo><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mrow><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>u</mi><mi>v</mi></mrow></msub></mrow></msup><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="152">取式 (8) 的负对数, NUPM的损失函数</p>
                </div>
                <div class="p1">
                    <p id="153" class="code-formula">
                        <mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>min</mi></mrow><mspace width="0.25em" /><mi>L</mi><mo>=</mo><mo>-</mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo stretchy="false">) </mo><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Y</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">Θ</mi><mo>, </mo><mi>G</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><mo>, </mo><mi mathvariant="bold-italic">v</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>Y</mi></mrow></munder><mo>-</mo></mstyle><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>u</mi><mi>v</mi></mrow></msub><mspace width="0.25em" /><mrow><mi>log</mi></mrow><mspace width="0.25em" /><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mrow><mi>u</mi><mi>v</mi></mrow></msub><mo stretchy="false">) </mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>σ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">v</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mn>2</mn></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow></munder><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mi>r</mi></msub><mo>-</mo><mi mathvariant="bold-italic">E</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">R</mi><mi mathvariant="bold-italic">E</mi></mrow><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">V</mi><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">E</mi><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mi>R</mi></mrow></munder><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">R</mi><mo>|</mo></mrow></mrow></mstyle><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">) </mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="154">其中, <b><i>V</i></b>、<b><i>E</i></b>分别为所有项目、实体的特征矩阵, <b><i>R</i></b>为关系<i>r</i>的特征矩阵.在式 (12) 中第1项衡量真实值和预测值间的交叉熵损失, 第2项衡量知识图谱<i>I</i><sub><i>r</i></sub>与矩阵<b><i>E</i></b><sup>T</sup><b><i>R</i></b><b><i>E</i></b>间的均方误差, 第3项用于防止过拟合的正则化项.</p>
                </div>
                <div class="p1">
                    <p id="155">考虑到很难直接优化上述损失函数, 本文采用随机梯度下降 (Stochastic Gradient Descent, SGD) 迭代优化损失函数.在每次训练过程中, 为了使计算更高效, 随机从<b><i>Y</i></b>中采样最小批次的正 (负) 记录及从<i>G</i>采样正 (负) 例三元组.计算损失<i>L</i>相对于框架参数<i>Θ</i>的梯度, 再通过反向传播算法更新所有的参数.</p>
                </div>
                <h4 class="anchor-tag" id="156" name="156"><b>1.7 算法步骤</b></h4>
                <div class="p1">
                    <p id="157">算法1为用户偏好神经建模的学习过程, 输入用户-项目交互矩阵和知识图谱, 通过反向传播计算损失函数有关的梯度, 输出预测函数.</p>
                </div>
                <div class="area_img" id="278">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201907010_27800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="278">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201907010_27801.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mn>2</mn></msubsup></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="175" name="175" class="anchor-tag">2 实验及结果分析</h3>
                <div class="p1">
                    <p id="176">本文使用GroupLens Research采集的从20世纪90年代末到21世纪初由MovieLens用户提供的电影评分数据.这些数据包括电影评分、电影元数据 (风格类型和年代) 及关于用户的人口统计学数据 (年龄、邮编、性别和职业等) .MovieLens-1M是推荐领域广泛使用的基准数据集, 包含约1百万条用户在电影网站上的显式评分数据, 范围为1～5.</p>
                </div>
                <div class="p1">
                    <p id="177">本文使用文献<citation id="262" type="reference">[<a class="sup">8</a>]</citation>中已经预处理过的数据集进行实验.由于MovieLens-1M为显式反馈数据集, 在实验中将其全部转化为隐式反馈数据, 即将每条用户评过分的记录标记为1 (评分大于等于4分的作为用户有过评分, 小于4分认为没有评分) , 同时为每位用户采样与正例相同数量且用户未交互的项目标记为0.使用文献<citation id="263" type="reference">[<a class="sup">8</a>]</citation>中已构建好的MovieLens-1M知识图谱, 使用用户和项目向量表示的ID作为原始输入, 数据统计如表2所示.</p>
                </div>
                <div class="area_img" id="178">
                    <p class="img_tit">表2 实验数据集 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Basic statistics of experimental dataset</p>
                    <p class="img_note"></p>
                    <table id="178" border="1"><tr><td><br />数据类型</td><td>元素</td><td>统计值</td></tr><tr><td><br />用户-项目交互</td><td>用户<br />项目<br />评分<br />数据密度/%</td><td>6036<br />2445<br />753772<br />5.1080</td></tr><tr><td><br />知识图谱</td><td>实体<br />关系<br />前3跳三元组</td><td>182011<br />12<br />517057</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="179">对比基线方法如下.</p>
                </div>
                <div class="p1">
                    <p id="180">1) 用于推荐系统的协同知识库嵌入 (Collabora-tive Knowledge Base Embedding for Recommender Systems, CKE) <citation id="264" type="reference"><link href="239" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>.将协同过滤与结构化知识、文本知识、图像等信息统一于一个框架中进行推荐.</p>
                </div>
                <div class="p1">
                    <p id="182">2) 用于新闻推荐的深度知识感知网络 (Deep Knowledge-Aware Network for News Recommendation, DKN) <citation id="265" type="reference"><link href="251" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.把词向量、实体向量及实体上下文向量作为多个通道在CNN框架下进行融合, 用于点击率预测.</p>
                </div>
                <div class="p1">
                    <p id="183">3) 用于情感链接预测的标签异构信息网络 (Signed Heterogeneous Information Network Embed-ding for Sentiment Link Prediction, SHINE) <citation id="266" type="reference"><link href="235" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>.设计深度自编码器, 结合语义网络、社交网络和用户画像网络, 用于名人推荐.</p>
                </div>
                <div class="p1">
                    <p id="185">4) 使用LibFM因子分解机 (Factorization Mach-ines with LibFM, 简记为LibFM) <citation id="267" type="reference"><link href="245" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>, 它广泛使用的用于点击率预测的基于特征的因子分解框架.实验中将用户ID、项目ID和相应的通过TransR (Learning Entity and Relation Embeddings for Knowledge Graph Completion) 学习的实体特征向量一起作为LibFM的输入.</p>
                </div>
                <div class="p1">
                    <p id="187">实验中设置最大跳数<i>T</i> = 2, 项目和知识图谱向量表示维度<i>d</i>=16,  学习率<i>η</i> = 0.008.超参数<i>λ</i><sub>1</sub> = 10<sup>-7</sup>, <i>λ</i><sub>2</sub> = 0.01.为了公平考虑, 所有对比基线方法的维度设置相同, 而基线方法的其它超参数设置基于网格搜索.</p>
                </div>
                <div class="p1">
                    <p id="188">训练、评估、测试的比率为6∶2∶2.每个实验重复3次取平均值作为最后结果.实验主要在点击率预测场景中验证本文框架的有效性, 使用训练好的框架用于测试集中的每条交互记录, 输出最终的预测概率.</p>
                </div>
                <div class="p1">
                    <p id="189">使用曲线下面积 (Area Under Curve, AUC) 和准确率 (Accuracy, ACC) 评估点击率预测的表现.实验在Tesla P100-SXM2-16GB平台上, 通过Tensorflow实现.</p>
                </div>
                <div class="p1">
                    <p id="190">所有方法在点击率预测场景下的结果如表3所示.由表3可见, CKE由于缺少文本和图像信息, 仅依靠结构化知识提取的特征信息不足以充分刻画用户特征, 所以性能差于LibFM.DKN在所有方法中表现最差, 这是因为DKN主要用于新闻推荐, 新闻标题长于电影名, 可以编码更多的语义信息.在电影推荐中由于电影名较短, 因此不能较好地从电影名中获取有用信息.SHINE性能只优于DKN, 因为在该实验数据中缺少社交网络和用户画像网络.LibFM作为一种通用的推荐算法, 表现较好, 只稍差于NUPM, 这表明LibFM可以较好地从知识图谱中充分利用语义信息.NUPM性能最优, 相比其它基线方法, 在AUC和ACC评价指标上分别有4.04%～40.15%, 5.30%～45.16%的性能提升, 这进一步验证本文方法的有效性.</p>
                </div>
                <div class="area_img" id="192">
                    <p class="img_tit">表3 在点击率预测场景下各方法AUC和ACC的结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Results of AUC and ACC in click rate prediction scenarios</p>
                    <p class="img_note"></p>
                    <table id="192" border="1"><tr><td><br />模型</td><td>AUC</td><td>与NUPM<br />相比/%</td><td>ACC</td><td>与NUPM<br />相比/%</td></tr><tr><td><br />CKE</td><td>0.796</td><td>-16.58</td><td>0.739</td><td>-15.70</td></tr><tr><td><br />DKN</td><td>0.655</td><td>-40.15</td><td>0.589</td><td>-45.16</td></tr><tr><td><br />SHINE</td><td>0.778</td><td>-19.28</td><td>0.732</td><td>-16.80</td></tr><tr><td><br />LibFM</td><td>0.892</td><td>-4.04</td><td>0.812</td><td>-5.30</td></tr><tr><td><br />NUPM</td><td>0.928</td><td>-</td><td>0.855</td><td>-</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="193">用户每一跳下的三元组集<i>S</i><mathml id="194"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>的大小也会对实验结果产生影响, <i>S</i><mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>过大会极大增加计算开销, 太小则无法获取足够的语义信息.因此本文进一步研究一位用户每一跳三元组集的大小对AUC和ACC的影响, 结果如表4所示.</p>
                </div>
                <div class="area_img" id="196">
                    <p class="img_tit">表4 三元组集的大小对实验结果的影响 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Influence of triple set size on experimental results</p>
                    <p class="img_note"></p>
                    <table id="196" border="1"><tr><td><br />三元组集大小</td><td>AUC</td><td>ACC</td></tr><tr><td><br />2</td><td>0.906</td><td>0.829</td></tr><tr><td><br />4</td><td>0.913</td><td>0.837</td></tr><tr><td><br />8</td><td>0.919</td><td>0.845</td></tr><tr><td><br />16</td><td>0.922</td><td>0.848</td></tr><tr><td><br />32</td><td>0.925</td><td>0.851</td></tr><tr><td><br />64</td><td>0.928</td><td>0.855</td></tr><tr><td><br />128</td><td>0.927</td><td>0.854</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="197">从表4可见, 随着三元组集的增大, AUC和ACC都有所增加, 这是因为随着三元组集的增大, 从知识图谱中能够编码更多的语义信息, 但是当三元组集增加到一定程度时可能会引入额外的无用信息, 所以AUC和ACC不再增加.</p>
                </div>
                <div class="p1">
                    <p id="198">跳数<i>k</i>的变化也会对最终的AUC和ACC结果产生影响, 结果如表5所示.由表可见, 当<i>k</i> = 2时性能最佳, 这是因为当<i>k</i>很小时很难发掘长距离实体间的相关性和依赖性, 当<i>k</i>很大时会因为距离用户历史交互项目太远的实体带来额外的噪声, 导致性能下降, 当<i>k</i> = 2, 3时能够较好地平衡<i>k</i>过大或过小的影响.</p>
                </div>
                <div class="area_img" id="199">
                    <p class="img_tit">表5 最大跳数对实验结果的影响 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Effect of maximum hops on experimental results</p>
                    <p class="img_note"></p>
                    <table id="199" border="1"><tr><td><br />最大跳数<i>T</i></td><td>AUC</td><td>ACC</td></tr><tr><td><br />1</td><td>0.927</td><td>0.853</td></tr><tr><td><br />2</td><td>0.928</td><td>0.855</td></tr><tr><td><br />3</td><td>0.925</td><td>0.851</td></tr><tr><td><br />4</td><td>0.926</td><td>0.851</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="200">为了进一步研究相关性概率<i>P</i><sub><i>i</i></sub>对建模用户偏好的影响, 在计算用户不同跳数下的偏好特征<b><i>O</i></b><mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>k</mi></msubsup></mrow></math></mathml>时, 去掉<i>P</i><sub><i>i</i></sub>, 即将三元组集中的所有尾实体<i>t</i><sub><i>i</i></sub>求平均, 结果如表6所示.由表6可见, 有相关性概率的结果明显优于简单地对尾实体求平均.因为只是对尾实体求平均, 未能考虑到实体之间的关系链接, 未能充分利用知识图谱包含的丰富语义关系, 此外未计算头实体与尾实体间的相似性, 不能较好地表示用户的偏好特征2.</p>
                </div>
                <div class="area_img" id="279">
                                            <p class="img_tit">
                                                表6 相关性概率P<sub>i</sub>对实验结果的影响
                                                    <br />
                                                Table 6 Effect of P<sub>i</sub>on experimental results
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907010_27900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/MSSB201907010_27900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907010_27900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表6 相关性概率Pi对实验结果的影响" src="Detail/GetImg?filename=images/MSSB201907010_27900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="280">最后研究向量表示的维度d和知识图谱特征学习项的训练权重λ<sub>2</sub>对AUC和ACC的影响．d的变化范围为2～64，λ<sub>2</sub>的范围为0～1，同时保持其它参数不变，实验结果如图3和图4所示．</p>
                </div>
                <div class="p1">
                    <p id="204">从图3可以看出, 随着维度<i>d</i>的增加, AUC和ACC都平稳上升, 这是因为具有更大维度的特征向量能够编码更多有用的信息, 但是当<i>d</i>大于16时AUC和ACC都开始下降, 因为可能产生过拟合.</p>
                </div>
                <div class="area_img" id="281">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907010_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 d对实验结果的影响" src="Detail/GetImg?filename=images/MSSB201907010_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 d对实验结果的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907010_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Effect of d on experimental results</p>

                </div>
                <div class="area_img" id="282">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907010_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 λ2对实验结果的影响" src="Detail/GetImg?filename=images/MSSB201907010_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 λ<sub>2</sub>对实验结果的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907010_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig 4 Effect ofλ<sub>2</sub>on experimental results</p>

                </div>
                <div class="p1">
                    <p id="211">从图4可以看出, 当<i>λ</i><sub>2</sub>=0.01时AUC和ACC表现最佳.这是因为当知识图谱特征学习项<i>λ</i><sub>2</sub>取很小值时不足以提供有效的正则化约束, 当<i>λ</i><sub>2</sub>很大时可能会误导目标函数.</p>
                </div>
                <h3 id="212" name="212" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="213">为了解决知识图谱感知推荐方法的不足, 本文提出融合基于特征的方法、基于路径的方法和注意力机制于知识图谱感知推荐中.具体地, 本文提出端到端的面向个性化推荐的用户偏好神经建模框架 (NUPM) , 该框架可以方便有效地将知识图谱引入推荐系统, 通过在知识图谱上传播用户兴趣, 自动发掘用户的潜在偏好.注意力网络的使用能够自适应地区分在不同传播阶段用户偏好特征对表征该用户最终偏好向量的重要性.通过偏好传播解决基于特征和基于路径的知识感知推荐方法的不足, 结合基于特征的方法、基于路径的方法及注意力机制, 应用于知识图谱感知推荐中.在公开数据集上的实验结果表明本文方法的性能较优, 进一步验证本文方法的有效性.今后将进一步研究如何高效表征实体-关系的交互, 如何将该框架应用到实际场景中.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="269" type="" href="images/MSSB201907010_26900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">朱桂明</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="271" type="" href="images/MSSB201907010_27100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">宾辰忠</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="273" type="" href="images/MSSB201907010_27300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">古天龙</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="276" type="" href="images/MSSB201907010_27600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">陈炜</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="277" type="" href="images/MSSB201907010_27700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">贾中浩</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="229">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural collaborative filtering">

                                <b>[1]</b>HE X N, LIAO L Z, ZHANG H W, et al.Neural Collaborative Filtering//Proc of the 26th International Conference on World Wide Web.New York, USA:ACM, 2017:173-182.
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=TEM:Tree-Enhanced Embedding Model for Explainable Recommendation">

                                <b>[2]</b>WANG X, HE X N, FENG F L, et al.TEM:Tree-Enhanced Embedding Model for Explainable Recommendation//Proc of the 27th International Conference on World Wide Web.New York, USA:ACM, 2018:1543-1552.
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Generic Coordinate Descent Framework for Learning from Implicit Feedback">

                                <b>[3]</b>BAYER I, HE X N, KANAGAL B, et al.A Generic Coordinate Descent Framework for Learning from Implicit Feedback//Proc of the 26th International Conference on World Wide Web.New York, USA:ACM, 2017:1341-1350.
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SHINE:Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction">

                                <b>[4]</b>WANG H W, ZHANG F Z, HOU M, et al.SHINE:Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction//Proc of the 11th International Conference on Web Search and Data Mining.New York, USA:ACM, 2018:592-600.
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Matrix Factorization Technique with Trust Propagation for Recommendation in Social Networks">

                                <b>[5]</b>JAMALI M, ESTER M.A Matrix Factorization Technique with Trust Propagation for Recommendation in Social Networks//Proc of the4th ACM Conference on Recommender Systems.New York, USA:ACM, 2010:135-142.
                            </a>
                        </p>
                        <p id="239">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaborative knowledge base embedding for recommender systems">

                                <b>[6]</b>ZHANG F Z, YUAN N J, LIAN D F, et al.Collaborative Knowledge Base Embedding for Recommender Systems//Proc of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2016:353-362.
                            </a>
                        </p>
                        <p id="241">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recurrent Knowledge Graph Embedding for Effective Recommendation">

                                <b>[7]</b>SUN Z, YANG J, ZHANG J, et al.Recurrent Knowledge Graph Embedding for Effective Recommendation//Proc of the 12th ACMConference on Recommender Systems.New York, USA:ACM, 2018:297-305.
                            </a>
                        </p>
                        <p id="243">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ripple Net:Propagating User Preferences on the Knowledge Graph for Recommender Systems">

                                <b>[8]</b>WANG H W, ZHANG F Z, WANG J L, et al.Ripple Net:Propagating User Preferences on the Knowledge Graph for Recommender Systems//Proc of the 27th International Conference on Information and Knowledge Management.New York, USA:ACM, 2018:417-426.
                            </a>
                        </p>
                        <p id="245">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000005874&amp;v=MTU0OTFtVUxiSUpGb1RhQlU9TmlmSVk3SzdIdGpOcjQ5RlpPc0tCSHM5b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>RENDLE S.Factorization Machines with Lib FM.ACM Transactions on Intelligent Systems and Technology, 2012, 3 (3) .DOI:10.1145/2168752.2168771.
                            </a>
                        </p>
                        <p id="247">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Personalized entity recommendation:A heterogeneous information network approach">

                                <b>[10]</b>YU X, REN X, SUN Y Z, et al.Personalized Entity Recommendation:A Heterogeneous Information Network Approach//Proc of the 7th ACM International Conference on Web Search and Data Mining.New York, USA:ACM, 2014:283-292.
                            </a>
                        </p>
                        <p id="249">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks">

                                <b>[11]</b>ZHAO H, YAO Q M, LI J D, et al.Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks//Proc of the 23th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York, USA:ACM, 2017:635-644.
                            </a>
                        </p>
                        <p id="251">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;DKN:deep knowledge-Aware network for news recommendation.&amp;quot;">

                                <b>[12]</b>WANG H W, ZHANG F Z, XIE X, et al.DKN:Deep Knowledge-Aware Network for News Recommendation//Proc of the27th International Conference on World Wide Web.New York, USA:ACM, 2018:1835-1844.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201907010" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201907010&amp;v=MDM1OTBSbkZ5emhWTDNQS0Q3WWJMRzRIOWpNcUk5RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
