<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131453884873750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201907008%26RESULT%3d1%26SIGN%3dIstMYKXgA7zSCnOAHq69HQWvMnc%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201907008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201907008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201907008&amp;v=MDMwMTZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVkx6QktEN1liTEc0SDlqTXFJOUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#76" data-title="1 基于多维信息融合的实体链接模型 ">1 基于多维信息融合的实体链接模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#82" data-title="2 特征提取融合 ">2 特征提取融合</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="&lt;b&gt;2.1 符号特征&lt;/b&gt;"><b>2.1 符号特征</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;2.2 类别特征&lt;/b&gt;"><b>2.2 类别特征</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;2.3 实体的语义结构特征&lt;/b&gt;"><b>2.3 实体的语义结构特征</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;2.4 CatBoost&lt;/b&gt;&lt;b&gt;简介&lt;/b&gt;"><b>2.4 CatBoost</b><b>简介</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#121" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#122" data-title="&lt;b&gt;3.1 实验数据集及实验设置&lt;/b&gt;"><b>3.1 实验数据集及实验设置</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;3.2 SimpleQuestions&lt;/b&gt;&lt;b&gt;实验参数设置&lt;/b&gt;"><b>3.2 SimpleQuestions</b><b>实验参数设置</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;3.3 SimpleQuestions&lt;/b&gt;&lt;b&gt;数据集实验结果&lt;/b&gt;"><b>3.3 SimpleQuestions</b><b>数据集实验结果</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;3.4 Free917、WebQuestions&lt;/b&gt;&lt;b&gt;数据集实验结果&lt;/b&gt;"><b>3.4 Free917、WebQuestions</b><b>数据集实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#166" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="图1 MDIIEL模型流程图">图1 MDIIEL模型流程图</a></li>
                                                <li><a href="#81" data-title="图2 MDIIEL模型特征提取流程图">图2 MDIIEL模型特征提取流程图</a></li>
                                                <li><a href="#102" data-title="图3 问句类型分类模型结构">图3 问句类型分类模型结构</a></li>
                                                <li><a href="#271" data-title="图4 2个模型示意图">图4 2个模型示意图</a></li>
                                                <li><a href="#135" data-title="图5 3种模型使用2种评估方法的准确率对比">图5 3种模型使用2种评估方法的准确率对比</a></li>
                                                <li><a href="#141" data-title="表1 TransE模型关键参数设置">表1 TransE模型关键参数设置</a></li>
                                                <li><a href="#142" data-title="表2 GRU分类模型关键参数设置">表2 GRU分类模型关键参数设置</a></li>
                                                <li><a href="#143" data-title="表3 Catboost模型参数设置">表3 Catboost模型参数设置</a></li>
                                                <li><a href="#148" data-title="表4 Trans E模型训练结果">表4 Trans E模型训练结果</a></li>
                                                <li><a href="#150" data-title="表5 6种方法实验结果对比">表5 6种方法实验结果对比</a></li>
                                                <li><a href="#158" data-title="表6 删除某种特征后实验结果对比">表6 删除某种特征后实验结果对比</a></li>
                                                <li><a href="#162" data-title="表7 Free917数据集上不同模型结合MDIIEL前后的性能对比">表7 Free917数据集上不同模型结合MDIIEL前后的性能对比</a></li>
                                                <li><a href="#165" data-title="表8 WebQuestions数据集上不同模型结合MDIIEL前后的性能对比">表8 WebQuestions数据集上不同模型结合MDIIEL前后的性能对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="189">


                                    <a id="bibliography_1" title="陆伟, 武川.实体链接研究综述.情报学报, 2015, 34 (1) :105-112. (LU W, WU C.Literature Review on Entity Linking.Journal of the China Society for Scientific and Technical Information, 2015, 34 (1) :105-112.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBXB201501012&amp;v=Mjk4MDBGckNVUkxPZVplUm5GeXpoVkx6Qk5DL1RiTEc0SDlUTXJvOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        陆伟, 武川.实体链接研究综述.情报学报, 2015, 34 (1) :105-112. (LU W, WU C.Literature Review on Entity Linking.Journal of the China Society for Scientific and Technical Information, 2015, 34 (1) :105-112.) 
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_2" title="SHEN W, WANG J Y, HAN J W.Entity Linking with a Knowledge Base:Issues, Techniques, and Solutions.IEEE Transactions on Knowledge and Data Engineering, 2015, 27 (2) :443-460." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Entity linking with a knowledge base:issues,techniques,and solutions">
                                        <b>[2]</b>
                                        SHEN W, WANG J Y, HAN J W.Entity Linking with a Knowledge Base:Issues, Techniques, and Solutions.IEEE Transactions on Knowledge and Data Engineering, 2015, 27 (2) :443-460.
                                    </a>
                                </li>
                                <li id="193">


                                    <a id="bibliography_3" title="STERN R, SAGOT B, BCHET F.A Joint Named Entity Recognition and Entity Linking System//Proc of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data.Stroudsburg, USA:ACL, 2012:52-60." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Joint Named Entity Recognition and Entity Linking System">
                                        <b>[3]</b>
                                        STERN R, SAGOT B, BCHET F.A Joint Named Entity Recognition and Entity Linking System//Proc of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data.Stroudsburg, USA:ACL, 2012:52-60.
                                    </a>
                                </li>
                                <li id="195">


                                    <a id="bibliography_4" title="SIL A, YATES A.Re-ranking for Joint Named-Entity Recognition and Linking//Proc of the 22nd ACM International Conference on Information and Knowledge Management.New York, USA:ACM, 2013:2369-2374." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Re-ranking for joint named-entity recognition and linking">
                                        <b>[4]</b>
                                        SIL A, YATES A.Re-ranking for Joint Named-Entity Recognition and Linking//Proc of the 22nd ACM International Conference on Information and Knowledge Management.New York, USA:ACM, 2013:2369-2374.
                                    </a>
                                </li>
                                <li id="197">


                                    <a id="bibliography_5" title="BORDES A, USUNIER N, CHOPRA S, et al.Large-Scale Simple Question Answering with Memory Networks[C/OL].[2019-01-01].https://arxiv.org/pdf/1506.02075.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large-Scale Simple Question Answering with Memory Networks[C/OL]">
                                        <b>[5]</b>
                                        BORDES A, USUNIER N, CHOPRA S, et al.Large-Scale Simple Question Answering with Memory Networks[C/OL].[2019-01-01].https://arxiv.org/pdf/1506.02075.pdf.
                                    </a>
                                </li>
                                <li id="199">


                                    <a id="bibliography_6" title="GOLUB D, HE X D.Character-Level Question Answering with Attention[C/OL].[2019-01-01].https://arxiv.org/pdf/1604.00727.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Character-Level Question Answering with Attention[C/OL]">
                                        <b>[6]</b>
                                        GOLUB D, HE X D.Character-Level Question Answering with Attention[C/OL].[2019-01-01].https://arxiv.org/pdf/1604.00727.pdf.
                                    </a>
                                </li>
                                <li id="201">


                                    <a id="bibliography_7" title="YIN W P, YU M, XIANG B, et al.Simple Question Answering by Attentive Convolutional Neural Network[C/OL].[2019-01-01].https://arxiv.org/pdf/1606.03391.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simple Question Answering by Attentive Convolutional Neural Network[C/OL]">
                                        <b>[7]</b>
                                        YIN W P, YU M, XIANG B, et al.Simple Question Answering by Attentive Convolutional Neural Network[C/OL].[2019-01-01].https://arxiv.org/pdf/1606.03391.pdf.
                                    </a>
                                </li>
                                <li id="203">


                                    <a id="bibliography_8" title="LUKOVNIKOV D, FISCHER A, LEHMANN J, et al.Neural Network-Based Question Answering over Knowledge Graphs on Word and Character Level//Proc of the 26th International Conference on World Wide Web.Berlin, Germany:Springer, 2017:1211-1220." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural Network-based Question Answering over Knowledge Graphs on Word and Character Level">
                                        <b>[8]</b>
                                        LUKOVNIKOV D, FISCHER A, LEHMANN J, et al.Neural Network-Based Question Answering over Knowledge Graphs on Word and Character Level//Proc of the 26th International Conference on World Wide Web.Berlin, Germany:Springer, 2017:1211-1220.
                                    </a>
                                </li>
                                <li id="205">


                                    <a id="bibliography_9" title="YU M, YIN W P, HASAN K, et al.Improved Neural Relation Detection for Knowledge Base Question Answering//Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017, I:571-581." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved Neural Relation Detection for Knowledge Base Question Answering">
                                        <b>[9]</b>
                                        YU M, YIN W P, HASAN K, et al.Improved Neural Relation Detection for Knowledge Base Question Answering//Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017, I:571-581.
                                    </a>
                                </li>
                                <li id="207">


                                    <a id="bibliography_10" title="PROKHORENKOVA L, GUSEV G, VOROBEV A, et al.Cat Boost:Unbiased Boosting with Categorical Features[C/OL].[2019-01-01].https://arxiv.org/pdf/1706.09516.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cat Boost:Unbiased Boosting with Categorical Features[C/OL]">
                                        <b>[10]</b>
                                        PROKHORENKOVA L, GUSEV G, VOROBEV A, et al.Cat Boost:Unbiased Boosting with Categorical Features[C/OL].[2019-01-01].https://arxiv.org/pdf/1706.09516.pdf.
                                    </a>
                                </li>
                                <li id="209">


                                    <a id="bibliography_11" title="詹晨迪, 凌震华, 戴礼荣.面向知识库问答中复述问句评分的词向量构建方法.模式识别与人工智能, 2016, 29 (9) :825-831. (ZHAN C D, LING Z H, DAI L R.Learning Word Embeddings for Paraphrase Scoring in Knowledge Base Based Question Answering.Pattern Recognition and Artificial Intelligence, 2016, 29 (9) :825-831.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201609007&amp;v=MDkyMTVxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emhWTHpCS0Q3WWJMRzRIOWZNcG85Rlk0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                        詹晨迪, 凌震华, 戴礼荣.面向知识库问答中复述问句评分的词向量构建方法.模式识别与人工智能, 2016, 29 (9) :825-831. (ZHAN C D, LING Z H, DAI L R.Learning Word Embeddings for Paraphrase Scoring in Knowledge Base Based Question Answering.Pattern Recognition and Artificial Intelligence, 2016, 29 (9) :825-831.) 
                                    </a>
                                </li>
                                <li id="211">


                                    <a id="bibliography_12" title="PENNINGTON J, SOCHER R, MANNING C.Glove:Global Vectors for Word Representation//Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1532-1543." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">
                                        <b>[12]</b>
                                        PENNINGTON J, SOCHER R, MANNING C.Glove:Global Vectors for Word Representation//Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1532-1543.
                                    </a>
                                </li>
                                <li id="213">


                                    <a id="bibliography_13" title="吴运兵, 朱丹红, 廖祥文, 等.路径张量分解的知识图谱推理算法.模式识别与人工智能, 2017, 30 (5) :473-480. (WU Y B, ZHU D H, LIAO X W, et al.Knowledge Graph Reasoning Based on Paths of Tensor Factorization.Pattern Recognition and Artificial Intelligence, 2017, 30 (5) :473-480." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201705011&amp;v=MjM4NzlCS0Q3WWJMRzRIOWJNcW85RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emhWTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                        吴运兵, 朱丹红, 廖祥文, 等.路径张量分解的知识图谱推理算法.模式识别与人工智能, 2017, 30 (5) :473-480. (WU Y B, ZHU D H, LIAO X W, et al.Knowledge Graph Reasoning Based on Paths of Tensor Factorization.Pattern Recognition and Artificial Intelligence, 2017, 30 (5) :473-480.
                                    </a>
                                </li>
                                <li id="215">


                                    <a id="bibliography_14" title="BORDES A, USUNIER N, GARCIA-DURAN A, et al.Translating Embeddings for Modeling Multi-relational Data[C/OL].[2019-01-01].http://www.thespermwhale.com/jaseweston/papers/CR_paper_nips13.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Translating Embeddings for Modeling Multi-relational Data[C/OL]">
                                        <b>[14]</b>
                                        BORDES A, USUNIER N, GARCIA-DURAN A, et al.Translating Embeddings for Modeling Multi-relational Data[C/OL].[2019-01-01].http://www.thespermwhale.com/jaseweston/papers/CR_paper_nips13.pdf.
                                    </a>
                                </li>
                                <li id="217">


                                    <a id="bibliography_15" title="WANG Z, ZHANG J W, FENG J L, et al.Knowledge Graph Embedding by Translating on Hyperplanes//Proc of the 28th AAAIConference on Artificial Intelligence.Palo Alto, USA:AAAIPress, 2014:1112-1119." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Knowledge graph embedding by translating on hyperplanes">
                                        <b>[15]</b>
                                        WANG Z, ZHANG J W, FENG J L, et al.Knowledge Graph Embedding by Translating on Hyperplanes//Proc of the 28th AAAIConference on Artificial Intelligence.Palo Alto, USA:AAAIPress, 2014:1112-1119.
                                    </a>
                                </li>
                                <li id="219">


                                    <a id="bibliography_16" title="LIN Y K, LIU Z Y, SUN M S, et al.Learning Entity and Relation Embeddings for Knowledge Graph Completion//Proc of the 29th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2015:2181-2187." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning entity and relation embeddings for knowledge graph completion">
                                        <b>[16]</b>
                                        LIN Y K, LIU Z Y, SUN M S, et al.Learning Entity and Relation Embeddings for Knowledge Graph Completion//Proc of the 29th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2015:2181-2187.
                                    </a>
                                </li>
                                <li id="221">


                                    <a id="bibliography_17" title="JI G L, HE S Z, XU L H, et al.Knowledge Graph Embedding via Dynamic Mapping Matrix//Proc of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL, 2015, I:687-696." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Knowledge Graph Embedding via Dynamic Mapping Matrix">
                                        <b>[17]</b>
                                        JI G L, HE S Z, XU L H, et al.Knowledge Graph Embedding via Dynamic Mapping Matrix//Proc of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL, 2015, I:687-696.
                                    </a>
                                </li>
                                <li id="223">


                                    <a id="bibliography_18" title="CAI Q Q, YATES A.Large-Scale Semantic Parsing via Schema Matching and Lexicon Extension//Proc of the 51st Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2013, 1:423-433." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Large-scale Semantic Parsing via Schema Matching and Lex-icon Extension">
                                        <b>[18]</b>
                                        CAI Q Q, YATES A.Large-Scale Semantic Parsing via Schema Matching and Lexicon Extension//Proc of the 51st Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2013, 1:423-433.
                                    </a>
                                </li>
                                <li id="225">


                                    <a id="bibliography_19" title="BERANT J, CHOU A, FROSTIG R, et al.Semantic Parsing on Freebase from Question-Answer Pairs//Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2013:1533-1544." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semantic parsing on freebase from question-answer pairs">
                                        <b>[19]</b>
                                        BERANT J, CHOU A, FROSTIG R, et al.Semantic Parsing on Freebase from Question-Answer Pairs//Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2013:1533-1544.
                                    </a>
                                </li>
                                <li id="227">


                                    <a id="bibliography_20" title="QIU Y Q, LI M L, WANG Y Z, et al.Hierarchical Type Constrained Topic Entity Detection for Knowledge Base Question Answering//Proc of the Companion of the Web Conference.Berlin, Germany:Springer, 2018:35-36." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical Type Constrained Topic Entity Detection for Knowledge Base Question Answering">
                                        <b>[20]</b>
                                        QIU Y Q, LI M L, WANG Y Z, et al.Hierarchical Type Constrained Topic Entity Detection for Knowledge Base Question Answering//Proc of the Companion of the Web Conference.Berlin, Germany:Springer, 2018:35-36.
                                    </a>
                                </li>
                                <li id="229">


                                    <a id="bibliography_21" title="BAST H, HAUSSMANN E.More Accurate Question Answering on Freebase//Proc of the 24th ACM International Conference on Information and Knowledge Management.New York, USA:ACM, 2015:1431-1440." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=More Accurate Question Answering on Freebase">
                                        <b>[21]</b>
                                        BAST H, HAUSSMANN E.More Accurate Question Answering on Freebase//Proc of the 24th ACM International Conference on Information and Knowledge Management.New York, USA:ACM, 2015:1431-1440.
                                    </a>
                                </li>
                                <li id="231">


                                    <a id="bibliography_22" title="CHEN B, AN B, SUN L, et al.Semi-Supervised Lexicon Learning for Wide-Coverage Semantic Parsing//Proc of the 27th International Conference on Computational Linguistics.Stroudsburg, USA:ACL, 2018:892-904." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-Supervised Lexicon Learning for Wide-Coverage Semantic Parsing">
                                        <b>[22]</b>
                                        CHEN B, AN B, SUN L, et al.Semi-Supervised Lexicon Learning for Wide-Coverage Semantic Parsing//Proc of the 27th International Conference on Computational Linguistics.Stroudsburg, USA:ACL, 2018:892-904.
                                    </a>
                                </li>
                                <li id="233">


                                    <a id="bibliography_23" title="XU K, REDDY S, FENG Y S, et al.Question Answering on Freebase via Relation Extraction and Textual Evidence//Proc of the54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2016, I:2326-2336." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Question answering on freebase via relation extraction and textual evidence">
                                        <b>[23]</b>
                                        XU K, REDDY S, FENG Y S, et al.Question Answering on Freebase via Relation Extraction and Textual Evidence//Proc of the54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2016, I:2326-2336.
                                    </a>
                                </li>
                                <li id="235">


                                    <a id="bibliography_24" title="JAIN S.Question Answering over Knowledge Base Using Factual Memory Networks//Proc of the NAACL Student Research Workshop.Stroudsburg, USA:ACL, 2016:109-115." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Question answering over knowledge base using factual memory networks">
                                        <b>[24]</b>
                                        JAIN S.Question Answering over Knowledge Base Using Factual Memory Networks//Proc of the NAACL Student Research Workshop.Stroudsburg, USA:ACL, 2016:109-115.
                                    </a>
                                </li>
                                <li id="237">


                                    <a id="bibliography_25" title="WANG Y, ZHANG R C, XU C, et al.The APVA-TURBOApproach to Question Answering in Knowledge Base//Proc of the27th International Conference on Computational Linguistics.Stroudsburg, USA:ACL, 2018:1998-2009." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The APVA-TURBOApproach to Question Answering in Knowledge Base">
                                        <b>[25]</b>
                                        WANG Y, ZHANG R C, XU C, et al.The APVA-TURBOApproach to Question Answering in Knowledge Base//Proc of the27th International Conference on Computational Linguistics.Stroudsburg, USA:ACL, 2018:1998-2009.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(07),642-651 DOI:10.16451/j.cnki.issn1003-6059.201907008            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于多维信息融合的知识库问答实体链接</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E5%AE%87%E6%B6%9B&amp;code=42447458&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曾宇涛</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9E%97%E8%B0%A2%E9%9B%84&amp;code=42447460&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">林谢雄</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9D%B3%E5%B0%8F%E9%BE%99&amp;code=26681578&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">靳小龙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B8%AD%E9%B9%8F%E5%BC%BC&amp;code=30535253&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">席鹏弼</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%85%83%E5%8D%93&amp;code=24307899&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王元卓</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E6%89%80%E4%B8%AD%E7%A7%91%E9%99%A2%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0142480&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院计算技术研究所中科院网络数据科学与技术重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%8E%E6%8E%A7%E5%88%B6%E5%AD%A6%E9%99%A2&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学计算机与控制学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>知识库问答实体链接任务需要将问句内容精准链接到知识库中实体.当前方法大多难以兼顾链接实体的召回率和精确率, 并且仅能根据文本信息对实体进行区分筛选.因此, 文中在合并子步骤的基础上, 提出融合多维度特征的知识库问答实体链接模型 (MDIIEL) .通过表示学习方法, 将文本符号、实体和问句类型、实体在知识库中语义结构表达等信息整合并引至实体链接任务中, 加强对相似实体的区分, 在提高准确率的同时降低候选集的大小.实验表明, MDIIEL模型在实体链接任务性能上具有整体性提升, 在大部分指标上取得较优的链接结果.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">实体链接;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AE%9E%E4%BD%93%E6%B6%88%E6%AD%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">实体消歧;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">表示学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A5%E8%AF%86%E5%BA%93%E8%AF%AD%E4%B9%89%E7%BB%93%E6%9E%84%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">知识库语义结构特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    曾宇涛, 硕士研究生, 主要研究方向为知识图谱、自然语言处理.E-mail:zengyutao18s@ict.ac.cn.;
                                </span>
                                <span>
                                    林谢雄, 硕士, 主要研究方向为知识图谱、自然语言处理.E-mail:linxiexiong@software.ict.ac.cn.;
                                </span>
                                <span>
                                    *靳小龙 (通讯作者) , 博士, 教授, 主要研究方向为知识图谱、知识工程等.E-mail:jinxiaolong@ict.ac.cn.;
                                </span>
                                <span>
                                    席鹏弼, 博士研究生, 主要研究方向为知识图谱、自然语言处理.E-mail:xipengbi@ict.ac.cn.;
                                </span>
                                <span>
                                    王元卓, 博士, 教授, 主要研究方向为网络大数据分析、开放知识计算等.E-mail:wangyuanzhuo@ict.ac.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (No.2017YFB1002302);</span>
                                <span>国家自然科学基金项目 (No.61772501, 61572473, 61572469, 91646120) 资助;</span>
                    </p>
            </div>
                    <h1><b>Multi-dimensional Information Integration Based Entity Linking for Knowledge Base Question Answering</b></h1>
                    <h2>
                    <span>ZENG Yutao</span>
                    <span>LIN Xiexiong</span>
                    <span>JIN Xiaolong</span>
                    <span>XI Pengbi</span>
                    <span>WANG Yuanzhuo</span>
            </h2>
                    <h2>
                    <span>CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences</span>
                    <span>School of Computer and Control Engineering, University of Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The entity linking task of knowledge base question answering (KBQA) is to accurately link the content of questions to the entities in the knowledge base. Recall rate and accuracy of linked entities cannot be balanced by most of the current methods, and only the text information is applied to distinguish and filter the entities. Therefore, a multi-dimensional information integration based entity linking for KBQA (MDIIEL) combining multi-dimensional features based on merging substeps is proposed in this paper. By representing learning methods, information such as text symbols, entities and question types, and semantic structure expressions of entities in the knowledge base are integrated and introduced into the entity linking task. The differentiation of similar entities is strengthened, and candidate sets are reduced while the accuracy is improved. The experiment proves that the MDIIEL model makes a holistic improvement on the entity linking task compared with the current methods, and it achieves the best current linking results on most indicators.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Entity%20Linking&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Entity Linking;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Entity%20Disambiguation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Entity Disambiguation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Representation%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Representation Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Semantic%20Structure%20Feature%20of%20Knowledge%20Base&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Semantic Structure Feature of Knowledge Base;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZENG Yutao, master student. His research interests include knowledge graph and natural language processing.;
                                </span>
                                <span>
                                    LIN Xiexiong, master. His research interests include knowledge graph and natural language processing.;
                                </span>
                                <span>
                                    JIN Xiaolong ( Corresponding author) , Ph. D. , professor. His research interests include knowledge graph and knowledge engineering.;
                                </span>
                                <span>
                                    XI Pengbi, Ph. D. candidate. His research interests include knowledge graph and natural language processing.;
                                </span>
                                <span>
                                    WANG Yuanzhuo, Ph. D. , professor. His research interests include web data analysis and open knowledge computing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-28</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Key R&amp;D Program of China (No.2017YFB1002302);</span>
                                <span>National Natural Science Foundation of China (No.61772501, 61572473, 61572469, 91646120);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="66">在知识库问答 (Knowledge Base Question Answe-ring, KBQA) 任务中, 通常给定一个问句, 解析问句的文本及语义, 然后根据问句中的关键词和语义关系从知识库召回候选答案实体或候选答案三元组.该任务一般可划分为两个子任务:实体链接和关系预测.</p>
                </div>
                <div class="p1">
                    <p id="68">实体链接主要用于获得答案三元组中的主语部分, 关系预测通过结合实体链接的结果, 找到问句中涉及的关系, 最终确定候选答案三元组.实体链接部分一般包含两个关键步骤:指称识别和实体消歧<citation id="239" type="reference"><link href="189" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.指称识别旨在分析问句, 从中获取可能指向知识库中特定实体的提及词 (Entity Mention) .而实体消歧是筛选实体提及词、检索知识库后得到的候选实体集, 找出其中真正和问句相关的实体, 并以此作为后续步骤的基础<citation id="240" type="reference"><link href="191" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="69">为了提高实体提及词检索性能, 一般通过维基百科等内容构建相应的受控词表或别名集合, 提高实体检索的召回率.此外, 为了减小实体指称识别过程中错误积累并传递至实体消歧部分, 学者们尝试结合指称识别和实体消歧并同时进行.Stern等<citation id="241" type="reference"><link href="193" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>令指称识别和实体消歧同步进行, 相互学习错误结果并加以标记.Sil等<citation id="242" type="reference"><link href="195" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出指称识别和消歧联合求解框架, 通过基础的命名实体识别系统和实体链接系统得到指称-实体对, 重排序得到最终的实体链接结果.</p>
                </div>
                <div class="p1">
                    <p id="70">随着SimpleQuestions<citation id="243" type="reference"><link href="197" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等主流数据集的发布, 知识库的规模得到较大提升, 更多研究开始将数据需求更大的机器学习算法引入实体链接过程.Golub等<citation id="244" type="reference"><link href="199" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出基于character-level的神经网络编解码框架, 解决传统基于word-level的编解码方法中出现未登录词 (Out of Vocabulary, OOV) 问题, 由此减小对获取正确问句实体提及词的干扰.</p>
                </div>
                <div class="p1">
                    <p id="71">另外, 为了保证实体提及词的召回率, 传统方法在搜索过程中往往会得到大量非正确候选提及词, 不仅对后续模型带来一定的噪声, 还严重影响模型性能, 因此研究者们对这些召回的候选提及词进行初步的排序筛选.Yin等<citation id="245" type="reference"><link href="201" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出注意力最大池化-卷积神经网络 (Attentive Max Pooling-Convolutional Neu-ral Network, AMP-CNN) 模型, 专门针对实体链接部分提出Active和Passive两种方法.Passive方法通过符号规则, 以问句中的每个词为搜索单元, 搜索知识库, 得到初步候选实体集合, 再根据最长公共子串等信息对候选实体和实体提及词进行评分.Active方法是在Passive方法的基础上, 通过训练双向长短期记忆-条件随机场 (Bi-directional Ling Short-Term Memory-Conditional Random Field, BiLSTM-CRF) 模型学习问句和候选提及词的得分, 预判候选提及词的重要性, 再对知识库中实体进行检索.</p>
                </div>
                <div class="p1">
                    <p id="73">而在实体消歧中, Lukovnikov等<citation id="246" type="reference"><link href="203" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>在循环神经网络 (Recurrent Neural Network, RNN) 编解码模型中通过问句中<i>n</i>-gram形式分别对知识库进行候选提及实体的搜索召回, 再通过相似度和包含规则进行筛选, 得到候选提及实体集合.Yu等<citation id="247" type="reference"><link href="205" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>在实体链接和关系预测中添加一步Entity Re-ranking, 通过结合关系预测的结果对实体链接进行再优化, 但存在计算量较大、效率较低的问题.</p>
                </div>
                <div class="p1">
                    <p id="74">上述方法或者将指称识别和实体消歧步骤切分明确, 难以兼顾精确率和召回率, 或者仅使用传统方法, 链接效果较差.并且这些方法大多仅基于问句、实体的符号层面信息, 对于实体和问句答案类型信息、实体在知识库中的语义和路径结构等隐含信息利用较少, 对于同名实体或极相似实体较难进行有效区分.</p>
                </div>
                <div class="p1">
                    <p id="75">针对这些不足, 本文在合并指称识别和实体消歧的基础上, 提出基于多维信息融合的实体链接模型 (Multi-dimensional Information Integration Based Entity Linking for KBQA, MDIIEL) .通过表示学习方法, 引入知识库中实体的语义路径向量表达, 并与实体类型、问句类型表达、符号层面信息进行整合, 相互补充, 更精确区分同名或近似实体.模型最终在SimpleQuestions、WebQuestions、Free917问答数据集实体链接指标上取得整体性的提升, 在大部分指标上取得当前最佳的实体链接结果.</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag">1 基于多维信息融合的实体链接模型</h3>
                <div class="p1">
                    <p id="77">MDIIEL模型包括问句搜索词的提取、初步候选实体的召回、多粒度特征的提取和模型学习4部分, 如图1所示.</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907008_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 MDIIEL模型流程图" src="Detail/GetImg?filename=images/MSSB201907008_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 MDIIEL模型流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907008_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Flow chart of MDIIEL model</p>

                </div>
                <div class="p1">
                    <p id="79">首先通过对问句进行处理得到搜索词, 再根据搜索词从知识库中检索并召回实体名字中包含搜索词的实体, 构成初步候选实体集合<i>CE</i><sub>1</sub>, 得到的候选实体与问句构成样本, 对每个样本从符号、类别与语义3个粒度提取特征, 最后将特征矩阵输入模型进行训练学习, 得到Top-<i>K</i>候选实体集合<i>CE</i><sub>2</sub>.在MDIIEL模型中, 获得候选提及词实体集合<i>CE</i><sub>2</sub>可分成生成候选集和筛选两步.首先, 获得问句的搜索词并检索知识库以生成候选集.为了减小对筛选部分的影响, 本文尽可能简单处理搜索词的获取, 而后转化为搜索词模糊匹配问题, 由此得到初步候选集合.而在对初步候选集进行筛选时可将问题定义为给定候选集合和问句, 从候选集挑选与问句最接近的Top-<i>K</i>实体.针对这个定义, 既可建模成排序问题模型, 也可建模成二分类模型.本文将该问题建模成二分类问题以处理, 在训练集中将正确的候选实体当作目标类别“1”, 其它非正确的候选实体都当作目标类别“0”, 在对测试集进行预测时, 对候选实体集合的元素分类成“1”的概率进行排序, 选取Top-<i>K</i>实体, 即与对应问句最接近的<i>K</i>个候选提及词实体.由于未指称识别步骤, 而直接排序, 得到实体链接结果, 避免误差积累传递.</p>
                </div>
                <div class="p1">
                    <p id="80">建模的二分类模型中包括提取特征和分类模型学习两部分, 其中提取特征包括符号特征、类别特征、实体在知识库中语义结构特征等.符号信息类特征包括问句最长公共子串占比、候选实体词在问题集合的tf-idf数据和关键词词频等.类别特征包括实体类别的提取及问题与实体类别的关联, 其中问题与类型的关联关系获取是通过构建基于文本向量的双向门控循环单元 (Bi-directional Gated Recurrent Unit, BiGRU) 分类模型实现.实体的知识库语义结构表达通过基于翻译的知识图谱表示学习模型对SimpleQuestions子数据集FB2M进行训练学习得到.提取特征完毕后将特征矩阵输入到CatBoost模型<citation id="248" type="reference"><link href="207" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>中进行第二次评分筛选.MDIIEL模型中特征提取详细结构如图2所示.</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907008_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 MDIIEL模型特征提取流程图" src="Detail/GetImg?filename=images/MSSB201907008_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 MDIIEL模型特征提取流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907008_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Flow chart of feature extraction of MDIIEL model</p>

                </div>
                <h3 id="82" name="82" class="anchor-tag">2 特征提取融合</h3>
                <div class="p1">
                    <p id="83">通过提取融合不同层次特征对候选实体集合进行筛选为模型重点.在对问句进行预处理 (分词, 去除停用词、多余标点, 小写化等) 后得到初步搜索词, 之后使用词性标注、tf-idf方法处理得到最终搜索词, 由此在知识库中进行模糊匹配搜索, 得到初始候选集合<i>CE</i><sub>1</sub>.将候选集<i>CE</i><sub>1</sub>中的每个实体与问句构成样本, 分别对这些样本提取符号特征、类别特征和实体知识图谱表达特征 (即知识库语义结构特征) .</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>2.1 符号特征</b></h4>
                <div class="p1">
                    <p id="85">基于符号的特征是指通过句子中包含的词和字符的信息进行提取.这里基于符号的特征包括最长公共子串的占比、最长公共词语的占比、实体在问句集合的tf-idf值和实体关联问句关键词的词频.</p>
                </div>
                <div class="p1">
                    <p id="86">最长公共子串的占比特征提取首先计算问句和候选实体名两个语句之间的最长公共子串, 记作<i>δ</i>, 分别计算<i>δ</i>部分占问句的比例<mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mi>q</mi><mi>δ</mi></mrow></msub><mo>=</mo><mo stretchy="false">|</mo><mi>δ</mi><mo stretchy="false">|</mo><mo>/</mo><mo stretchy="false">|</mo><mi>q</mi><mo stretchy="false">|</mo></mrow></math></mathml>, 计算<i>δ</i>部分占候选实体的比例<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mi>e</mi><mi>δ</mi></mrow></msub><mo>=</mo><mo stretchy="false">|</mo><mi>δ</mi><mo stretchy="false">|</mo><mo>/</mo><mo stretchy="false">|</mo><mi>e</mi><mo stretchy="false">|</mo></mrow></math></mathml>.由于<i>CE</i><sub>1</sub>召回的候选实体是基于词语模糊匹配, 只要有部分词语相关就会被召回.因此, 问题最长公共子串占问题和实体的比例在一定程度上反映候选实体与问句的相关性.</p>
                </div>
                <div class="p1">
                    <p id="89">与最长公共子串类似, 最长公共词语是先对问句和候选实体进行分词, 以词为单位计算最长公共词语, 记作<i>σ</i>, 而后分别计算<i>σ</i>占问题部分比例<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>q</mtext><mtext>σ</mtext></mrow></msub><mo>=</mo><mo stretchy="false">|</mo><mi>σ</mi><mo stretchy="false">|</mo><mo>/</mo><mo stretchy="false">|</mo><mi>q</mi><mo stretchy="false">|</mo></mrow></math></mathml>和<i>σ</i>占实体部分比例<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mtext>e</mtext><mtext>σ</mtext></mrow></msub><mo>=</mo><mo stretchy="false">|</mo><mi>σ</mi><mo stretchy="false">|</mo><mo>/</mo><mo stretchy="false">|</mo><mi>e</mi><mo stretchy="false">|</mo></mrow></math></mathml>, 这两个特征与前两个类似, 差别在于前两者基于字符级别, 后两者基于单词级别, 提供两种层面的符号信息.</p>
                </div>
                <div class="p1">
                    <p id="92">基于符号的特征还包括实体在问句集合中的tf-idf值:将所有问句作为文档集合, 每个问句作为一个文档, 先后对问句集合中的词计算词频率</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mi>f</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub><mo>=</mo><mi>n</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msub><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>k</mi></munder><mi>n</mi></mstyle><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>j</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">和逆文档频率</p>
                </div>
                <div class="p1">
                    <p id="95" class="code-formula">
                        <mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>i</mi><mi>d</mi><mi>f</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>lg</mi></mrow><mo stretchy="false"> (</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>D</mi><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mo stretchy="false">{</mo><mi>j</mi><mo>∶</mo><mi>t</mi><msub><mrow></mrow><mi>j</mi></msub><mo>∈</mo><mi>d</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">}</mo><mo stretchy="false">|</mo></mrow></mfrac><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="96">然后, 将两者相乘得到tf-idf矩阵<i>tfidf</i><sub><i>i</i>, <i>j</i></sub>=<i>tf</i><sub><i>i</i>, <i>j</i></sub>×<i>idf</i><sub><i>i</i></sub>.再对候选实体进行分词, 对于该实体中的每个词可在tf-idf矩阵中得到其值, 将实体名中每个词计算得到的值取平均得到实体名tf-idf特征的值.</p>
                </div>
                <div class="p1">
                    <p id="97">与上述实体名的tf-idf值类似, 在符号信息层面, 实体名包含搜索词词频特征的提取, 通过数据集中问句的tf-idf矩阵, 对问句中抽取得到的搜索词集合中每个词计算相应的词频值, 后取平均得到实体中包含的搜索词的tf-idf值.</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98"><b>2.2 类别特征</b></h4>
                <div class="p1">
                    <p id="99">一般符号特征能在一定程度上筛选实体名差异较大的实体, 难以筛选的部分主要集中在同名实体部分.在Freebase的大型知识库中, 同名实体的存在非常普遍, 因此单纯基于符号的特征已无法较好地区分这些候选实体, 因此, 在模型中通过加入类型特征和知识库语义特征进一步区别这类实体.</p>
                </div>
                <div class="p1">
                    <p id="100">模型中类别特征包括实体类别特征和问题类别特征.实体类别特征直接采用实体类别信息作为标签, 如使用Freebase中notable_for谓词对应值, 并将对应值转为知识库中的语义表达向量, 作为实体类型.对于问题类别特征, 并无类别概念, 这里所指的问题类别特征是将问题与实体类别进行关联, 即将该问句预测得到的答案实体类型作为该问题的类型.由此通过建立多分类模型, 将问句内容与实体类别关联, 得到问句答案实体的预测类型.此外, 针对数据集中问句数量有限和问句中无关词语引入噪声等问题, 通过复述原问句的方法加以处理<citation id="249" type="reference"><link href="209" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="101">Freebase中notable_for谓词对应上千种类实体类别, 能满足分类需求.问句类型模型如图3所示.</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907008_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 问句类型分类模型结构" src="Detail/GetImg?filename=images/MSSB201907008_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 问句类型分类模型结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907008_102.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Structure of question type classification model</p>

                </div>
                <div class="p1">
                    <p id="103">对类别建立词典索引, 并对问句分词, 通过字符层面和全局向量的词嵌入 (Global Vectors for Word Representation, GloVe) 模型<citation id="250" type="reference"><link href="211" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>编码得到词向量表达, 通过BiGRU进行文本的多分类模型学习, 对模型输出结果执行Softmax归一化, 得到问句的类别特征.</p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>2.3 实体的语义结构特征</b></h4>
                <div class="p1">
                    <p id="105">在传统候选实体的筛选方法中, 大部分只关注文本层面信息, 多数知识库只作为一个搜索并返回实体的数据库, 而知识库本身包含很多语义结构层面的信息<citation id="251" type="reference"><link href="213" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.例如, 若两个实体之间存在关系, 表示这两个实体间“距离”更接近, 知识图谱表示学习的方法将知识库单元映射到向量空间, 通过向量之间的距离刻画知识库中实体和关系之间的“亲疏”关系.对于候选实体集合中存在大量同名实体和相似实体的问题, 引入知识库的向量表达信息能有助于更好区分这些语义接近的实体, 获得更好的实体链接性能.</p>
                </div>
                <div class="p1">
                    <p id="106">对于知识库中的基本语义单元, 常以三元组的形式建模, 而三元组通常表示为 (<b><i>h</i>, <i>r</i>, <i>t</i></b>) , 其中, <b><i>h</i></b>表示头实体, <b><i>r</i></b>表示知识库中的关系, <b><i>t</i></b>表示尾实体.<b><i>h</i>, <i>r</i>, <i>t</i></b>都是以向量的形式表示, 三元组的建模假设头实体向量<b><i>h</i></b>和尾实体向量<b><i>t</i></b>在经过某种与关系向量<b><i>r</i></b>相关的映射后得到的向量应尽可能相等.因此, 为了刻画这个模型假设, 模型应用基于间隔 (Distance-Based) 的评分方式, 以此衡量在映射空间上两个实体之间的距离, 刻画在知识库中两个实体之间的相关程度.通常定义基于三元组的能量函数为<i>f</i><sub><i>r</i></sub> (<b><i>h</i>, <i>t</i></b>) , 对应模型训练的目标函数</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi mathvariant="bold-italic">h</mi><mo>, </mo><mi mathvariant="bold-italic">t</mi></mrow></munder><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><msup><mi mathvariant="bold-italic">h</mi><mo>′</mo></msup><mo>, </mo><msup><mi mathvariant="bold-italic">t</mi><mo>′</mo></msup></mrow></munder><mrow><mi>max</mi></mrow></mstyle></mrow></mstyle><mo stretchy="false"> (</mo><mn>0</mn><mo>, </mo><mspace width="0.25em" /><mi>f</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><mo>, </mo><mi mathvariant="bold-italic">t</mi><mo stretchy="false">) </mo><mo>+</mo><mi>γ</mi><mo>-</mo><mi>f</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><msup><mi mathvariant="bold-italic">h</mi><mo>′</mo></msup><mo>, </mo><msup><mi mathvariant="bold-italic">t</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">其中, <b><i>h</i></b>′表示负样本头实体, <b><i>t</i></b>′表示负样本尾实体, 即随机产生的错误或不存在的三元组.在这类知识库表示学习模型中较经典的是TransE (Translating Embedding) <citation id="252" type="reference"><link href="215" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>以及相关的扩展模型.</p>
                </div>
                <div class="p1">
                    <p id="109">TransE模型为基于翻译的知识库表示学习模型中较典型、应用较普遍的一个代表, 计算效率较高, 预测性能较优.其基于假设<b><i>h</i></b>+<b><i>r</i></b>≈<b><i>t</i></b>, 算法的主要思想如图4 (a) 所示, 三元组中的实体和关系在同一语义空间内成加性关系.对应的得分函数定义为向量<b><i>h</i></b>+<b><i>r</i></b>与向量<b><i>t</i></b>的距离:</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">h</mi><mo>, </mo><mi mathvariant="bold-italic">t</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>-</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">h</mi><mo>+</mo><mi mathvariant="bold-italic">r</mi><mo>-</mo><mi mathvariant="bold-italic">t</mi></mrow><mo>|</mo></mrow></mrow><msub><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msub><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">TransH (Translation on Hyperplanes) 模型<citation id="253" type="reference"><link href="217" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>针对TransE模型中一对多、多对一情况的不足进行改进, 引入关系所属的超平面概念, 如图4 (b) 所示, 将头实体和尾实体向量投影到关系所在的超平面, 再在超平面上完成翻译过程.</p>
                </div>
                <div class="area_img" id="271">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907008_27100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 2个模型示意图" src="Detail/GetImg?filename=images/MSSB201907008_27100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 2个模型示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907008_27100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Illustration of 2 models</p>

                </div>
                <div class="p1">
                    <p id="113">此外, TransR (Translation in Relation Space) 模型<citation id="254" type="reference"><link href="219" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>基于TransE, 通过引入关系所属空间, 通过矩阵<b><i>M</i></b><sub><i>r</i></sub>将实体映射到对应的关系所属空间, 再在这个空间上完成翻译过程.TransD (Translation via Dynamic Mapping Matrix) 模型<citation id="255" type="reference"><link href="221" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>针对上述模型中普遍默认关系只有一种语义表达的缺陷, 提出基于动态矩阵 (Dynamic Matrix) 方法, 将关系的语义和头尾实体向量表达相关联, 实现关系的多语义表达, 其在关系数量相对较少时性能显著.</p>
                </div>
                <div class="p1">
                    <p id="114">通常, 基于知识图谱表示学习的模型一般在WN18K、FB15K数据集上进行训练, 但SimpleQues-tions数据集中的2个训练集FB2M、FB5M实体数量是FB15K的上百倍, 三元组数量更是上千倍.要想对如此规模的知识库进行语义表示, 除了需要增加实体维度, 也要相应提高训练轮数等.同时, 也需根据SimpleQuestions数据集中FB2M、FB5M两个知识库子集数据的具体情况和特点, 选择最适合的模型.</p>
                </div>
                <h4 class="anchor-tag" id="116" name="116"><b>2.4 CatBoost</b><b>简介</b></h4>
                <div class="p1">
                    <p id="117">在得到符号、类型、语义结构层面的特征信息后, 将这些特征融合并输入至评分模型中, 得到与问句最相关的Top-<i>K</i>实体.本文使用近些年颇受关注的CatBoost模型作为主体的评分模型.</p>
                </div>
                <div class="p1">
                    <p id="118">CatBoost模型是Yandex公司于2017年开源的梯度提升决策树 (Gradient Boosting Decision Tree, GBDT) 模型, 目的是为更好处理类别型特征 (Categorical Features) .</p>
                </div>
                <div class="p1">
                    <p id="119">对于离散型的类别特征, GBDT常将其转化为数值标签后, 直接取平均值作为节点分裂的标准.然而这种方法具有明显缺陷, 标签平均值无法确切表示类型特征的信息.针对此CatBoost模型, 通过统计类别频率和设置超参数的方式, 引入统计信息和先验知识, 将类别特征转化为数值特征.此外, CatBoost模型还通过组合不同类别, 生成信息的组合特征, 丰富特征维度.在模型迭代方面, CatBoost进行相应改进, 采用排序提升的方式计算残差, 能较好地防止模型过拟合.</p>
                </div>
                <div class="p1">
                    <p id="120">此外, CatBoost模型在优化模型训练方面, 支持图形处理器 (Graphic Processing Unit, GPU) 训练、中央处理器 (Central Processing Unit, CPU) 评分, 相比XGBoost (Extreme Gradient Boosting) 、LightGBM (Light Gradient Boosting Machine) 等集成模型, 在精度和性能方面具有一定提升.本文综合考虑待获取特征的特点和训练样本的数量, 使用CatBoost模型作为主体评分模型.</p>
                </div>
                <h3 id="121" name="121" class="anchor-tag">3 实验及结果分析</h3>
                <h4 class="anchor-tag" id="122" name="122"><b>3.1 实验数据集及实验设置</b></h4>
                <div class="p1">
                    <p id="123">为了研究MDIIEL模型对实体链接任务性能的提升效果, 在SimpleQuestions、Free917<citation id="256" type="reference"><link href="223" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>和Web-Questions<citation id="257" type="reference"><link href="225" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>这3个主流的知识库问答数据集上进行相关实验, 并与知识库问答领域相关研究工作的结果进行对比.</p>
                </div>
                <div class="p1">
                    <p id="125">SimpleQuestions (SQ) 数据集为基于Freebase构建的公开问答数据集, 分为FB2M和FB5M两个子集, 并以7∶2∶1的比例划分为训练集、测试集、验证集, 包含有75 910条训练数据、21 687条测试数据、10 845条验证数据、5 000 000个Freebase实体和关系.</p>
                </div>
                <div class="p1">
                    <p id="126">Free917数据集通过手工编写方式构建, 覆盖81个领域的917个问题, 其中每个问句对应1条SPARQL查询语句, 指向知识库中答案, 训练集和测试集的比例为7∶3.</p>
                </div>
                <div class="p1">
                    <p id="127">WebQuestions (WQ) 数据集为通过Google Suggest API爬取得到的5 810条问题, 较口语化, 覆盖各个常见领域, 答案通过众包的方式生成, 训练集、测试集分别占65%和35%.</p>
                </div>
                <div class="p1">
                    <p id="128">由于Free917、WebQuestions数据集远小于SimpleQuestions数据集, 因此当前大部分基于这两个数据集的工作都未明确给出问答中实体链接部分的指标结果, 而是给出问答整体的结果, 无法直接对比.</p>
                </div>
                <div class="p1">
                    <p id="129">本文将实验分为两类:1) 基于SimpleQuestions数据集, 直接使用MDIIEL模型进行实体链接, 并对比当前工作的链接结果; 2) 基于Free917、WebQues- tions数据集, 在实验中将其它工作的实体链接部分替换为MDIIEL模型, 通过对比替换前后评价指标的变化, 评估MDIIEL模型在其它数据集上的性能提升效果.</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>3.2 SimpleQuestions</b><b>实验参数设置</b></h4>
                <div class="p1">
                    <p id="131">本文将SimpleQuestions数据集中答案部分的subject作为正确候选提及词实体, 构成实验的训练集和测试集.实验中需训练调整的参数主要分为知识库表示学习部分的训练参数、问题类别的网络参数和整体评分模型的参数.</p>
                </div>
                <div class="p1">
                    <p id="132">在知识库表示学习的训练中, 本文对比涉及到的3种Trans系列模型.考虑到FB2M、FB5M数据子集中数据量为Trans系列模型标准数据集的上千倍, 对比测试时将向量空间限定为50维, 迭代次数限制在1 000轮以内, 评估一定空间和时间开销下3种模型的大体性能, 如图5所示.</p>
                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907008_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 3种模型使用2种评估方法的准确率对比" src="Detail/GetImg?filename=images/MSSB201907008_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 3种模型使用2种评估方法的准确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907008_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Accuracy comparison among 3 models using 2 evaluation methods</p>

                </div>
                <div class="p1">
                    <p id="137">图5中raw和filter两种评估方法的区别在于, filter在准确率评估时去除一对多、多对一情况对测试影响, 测试结果的可信度更高.hit@<i>K</i> (<i>K</i>=1, 3, 10) 指标表示正确实体排在前<i>K</i>以内的比例, 比例越高说明预测结果越准确.从结果可见, 在一定时间、空间限制下, TransE模型性能最优.</p>
                </div>
                <div class="p1">
                    <p id="138">而在原理上, TransD和TransR都是将关系和实体嵌入不同的语义空间, 但是在Freebase中实体和关系并无明显区别, 而在FB2M、FB5M中实体数量是关系数量的上千倍, 关系实体的空间维数过大, 这会造成准确率的下降.此外, TransD、TransR模型需对不同空间的向量表达进行映射, 增加额外运算.虽然在后续的测试中发现, 在适当调整参数后, TransD模型能达到并超过TransE模型的性能, 但是由于计算量太大, 对时间及硬件资源的开销较大.</p>
                </div>
                <div class="p1">
                    <p id="139">因此, 综合上述测试结果和对硬件资源的考虑, 本文最终选取TransE模型作为训练知识库向量表达的方法.</p>
                </div>
                <div class="p1">
                    <p id="140">通过调整, 得到模型中3个部分的参数设置:基于知识图谱的表示学习采用TransE模型, 在FB2M、FB5M数据子集上进行编码表达, 关键参数设置如表1所示.问题的类别特征提取采用基于GRU的多分类模型, 模型关键参数设置如表2所示.得到模型所需各类特征向量后, 输入全连接层, 并输入CatBoost模型评分, 训练得到的CatBoost模型关键参数如表3所示.</p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit">表1 TransE模型关键参数设置 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Key parameters setting of TransE model</p>
                    <p class="img_note"></p>
                    <table id="141" border="1"><tr><td>参数</td><td>迭代轮数</td><td>实体维度</td><td>关系维度</td><td>批大小</td><td>间隔</td><td>学习率</td><td>线程数</td></tr><tr><td>值</td><td>3000</td><td>200</td><td>100</td><td>1000</td><td>1</td><td>0.001</td><td>64</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit">表2 GRU分类模型关键参数设置 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Key parameters setting of GRU model</p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td>参数</td><td>样本训练负数</td><td>批大小</td><td>字符维度</td><td>字符隐层</td><td>词维度</td><td>句子隐层</td><td>层数</td><td>丢弃率</td></tr><tr><td>值</td><td>5</td><td>32</td><td>50</td><td>128</td><td>50</td><td>128</td><td>2</td><td>0.8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="143">
                    <p class="img_tit">表3 Catboost模型参数设置 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Parameters setting of Catboost model</p>
                    <p class="img_note"></p>
                    <table id="143" border="1"><tr><td><br />参数</td><td>最大树深度</td><td>迭代次数</td><td>学习率</td><td>损失函数</td></tr><tr><td><br />值</td><td>6</td><td>3000</td><td>0.01</td><td>Logloss</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="144" name="144"><b>3.3 SimpleQuestions</b><b>数据集实验结果</b></h4>
                <div class="p1">
                    <p id="145">实验中知识库语义表达部分评价指标采用hit@<i>K</i>和所有正确三元组平均排名Mean Rank (MR) , hit@<i>K</i>越高、MR越小, 表示模型性能越好.模型整体结果评价指标采用top-<i>K</i>准确率, 即在前<i>K</i>个实体中正确实体的覆盖率.由于知识库问答中实体链接步骤旨在筛选得到top-<i>K</i>个实体作为之后关系预测模型的输入, 而<i>K</i>一般取10、20或更大, 因此在本任务中需重点关注<i>K</i>≥10时正确实体的覆盖率.</p>
                </div>
                <div class="p1">
                    <p id="146">实验得到本文模型在评价指标下的得分, 并在相同数据集相同指标下与先前的工作进行对比.</p>
                </div>
                <div class="p1">
                    <p id="147">训练得到的TransE模型训练结果如表4所示.由表可见, 在hit@10指标上, 2种评价方法 (raw、filter) 中头实体head的准确率都达到30%以上, 而尾实体tail的准确率都超过50%, 在FB2M数据子集近200万实体中平均排序MR为前3%, 性能较优.另外, 由于Trans系列模型一般在WN18K、FB15K等较小的知识库中进行编码表达, 与模型中使用的FB2M、FB5M知识库相比过小, 因此这几个数据集的准确率对比的意义不大.</p>
                </div>
                <div class="area_img" id="148">
                    <p class="img_tit">表4 Trans E模型训练结果 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Training results of Trans E model</p>
                    <p class="img_note"></p>
                    <table id="148" border="1"><tr><td rowspan="2"><br />指标</td><td colspan="3"><br />raw</td><td colspan="3"><br />filter</td></tr><tr><td><br />head</td><td>tail</td><td>average</td><td><br />head</td><td>tail</td><td>average</td></tr><tr><td>MRR/%</td><td>21.53</td><td>35.19</td><td>28.36</td><td>26.82</td><td>41.49</td><td>34.15</td></tr><tr><td>MR</td><td>106419.15</td><td>19655.83</td><td>63037.49</td><td>80917.05</td><td>15142.34</td><td>48029.69</td></tr><tr><td><br />hit@10/%</td><td>31.57</td><td>51.47</td><td>41.52</td><td>34.87</td><td>54.17</td><td>44.52</td></tr><tr><td><br />hit@3/%</td><td>24.83</td><td>40.69</td><td>32.76</td><td>28.88</td><td>45.56</td><td>37.22</td></tr><tr><td><br />hit@1/%</td><td>15.97</td><td>26.36</td><td>21.17</td><td>22.36</td><td>34.35</td><td>28.36</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="149">在实体链接整体性能的实验中选取文中提及的基于<i>SimpleQuestions</i>数据集的知识库问答经典研究, 并对比<i>state</i>-<i>of</i>-<i>the</i>-<i>art</i>方法, 结果如表5所示.从结果对比可看出, <i>MDIIEL</i>模型在知识库问答实体链接任务中具有一定提升作用.虽然在<i>top</i>-1覆盖率上仍有不足, 但在K≥5时, 性能提高较明显, 在<i>top</i>-5、<i>top</i>-10、<i>top</i>-20、<i>top</i>-50指标上都超过现有最好水平, 表现出模型在处理相似实体方面的区分性能良好.此外, 在相同覆盖率要求下, 模型的候选集实体数量更少, 这对提高知识库问答后续步骤性能帮助较大.</p>
                </div>
                <div class="area_img" id="150">
                    <p class="img_tit">表5 6种方法实验结果对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Experimental result comparison of 6 methods</p>
                    <p class="img_note"></p>
                    <table id="150" border="1"><tr><td colspan="2">方法</td><td>top-1</td><td>top-5</td><td>top-10</td><td>top-20</td><td>top-50</td></tr><tr><td colspan="2">Freebase API</td><td>40.9</td><td>-</td><td>64.3</td><td>69.3</td><td>75.7</td></tr><tr><td colspan="2">文献[6]方法</td><td>52.9</td><td>-</td><td>74.0</td><td>77.8</td><td>82.0</td></tr><tr><td>文献[7]方法</td><td>Passive <br />Active</td><td>56.6<br />73.6</td><td>71.1<br />85.0</td><td>75.2<br />87.4</td><td>81.0<br />88.8</td><td>85.7<br />90.4</td></tr><tr><td colspan="2">文献[9]方法</td><td>79.0</td><td>-</td><td>89.5</td><td>90.9</td><td>92.5</td></tr><tr><td colspan="2"><br />文献[20]方法</td><td>81.1</td><td>-</td><td>91.7</td><td>93.4</td><td>95.1</td></tr><tr><td colspan="2"><br />本文方法</td><td>79.4</td><td>91.5</td><td>93.4</td><td>94.8</td><td>96.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="151">在实验结果中, 对预测错误的样本抽样分析, 发现主要类型如下.</p>
                </div>
                <div class="p1">
                    <p id="152">1) 问题不存在搜索关键词, 对数据进行统计后发现约有0.399%的问题无法提取搜索关键词, 这类问题很难得到准确的候选实体.</p>
                </div>
                <div class="p1">
                    <p id="153">2) 候选实体集合中有多个实体的名字和类型完全一致, 在知识库中的局部结构也很接近, 大都是同样的关系.</p>
                </div>
                <div class="p1">
                    <p id="154">3) 根据tf-idf筛选搜索词时直接过滤正确搜索词, 导致初始候选集合中不存在正确实体, 即便之后有效筛选也无法获得正确结果.</p>
                </div>
                <div class="p1">
                    <p id="155">4) 问题指代不清且实体存在包含关系以及相似类别, 这种情况主要影响top-1正确实体覆盖率.</p>
                </div>
                <div class="p1">
                    <p id="156">另外, 由于没有对问句中出现的关系信息进行进一步的获取和利用, top-1实体的正确实体覆盖率提升不大, 和当前最佳结果也有近2%的差距, 这是模型的一个不足之处.如果能在实体链接部分引入问句关系的语义信息, 关系预测任务和实体链接任务进行一定整合, 会很大程度减小文中四类错误样本带来的影响, 同时提升<i>K</i>&lt;5时top-<i>K</i>准确率.</p>
                </div>
                <div class="p1">
                    <p id="157">为了测试3种不同层面特征对模型结果的影响, 对分别去除某方面特征的情况进行实验, 分析不同特征对模型的影响程度, 测试结果如表6所示.由表可见, 在三种特征中, 符号特征相对影响最大, 去掉后实体覆盖率最低, 符合实际认知.类型和语义结构的重要程度相当, 语义结构特征对top-5、top-10等<i>K</i> ≥ 5的情况影响较大, 而类型特征对<i>K</i>&lt;5的情况影响较大.三者结合后, 整体的准确率都得到提升, 可相互补充.</p>
                </div>
                <div class="area_img" id="158">
                                            <p class="img_tit">
                                                表6 删除某种特征后实验结果对比
                                                    <br />
                                                Table 6 Comparison of experimental results after removing different types of features
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907008_15800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/MSSB201907008_15800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907008_15800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表6 删除某种特征后实验结果对比" src="Detail/GetImg?filename=images/MSSB201907008_15800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>3.4 Free917、WebQuestions</b><b>数据集实验结果</b></h4>
                <div class="p1">
                    <p id="160">由于Free917、WebQuestions数据集最后的答案三元组皆指向freebase知识库中的实体和关系, 因此该部分实验的知识库语义结构表达直接采用SimpleQuestions数据集中训练得到的结果.另外, 该部分涉及的模型较多, 数据集数据量较小, 问句分类模型和整体CatBoost评分模型的训练、参数调整较简单, 因此本文直接给出不同方法使用MDIIEL模型替换原有实体链接部分前后的性能指标对比.</p>
                </div>
                <div class="p1">
                    <p id="161">基于Free917数据集的模型在加入MDIIEL进行实体链接后性能如表7所示.由于Free917中问题较少且规范, 因此在实验中选择MDIIEL筛选得到的前3个实体, 即<i>K</i>=3.在使用MDIIEL后, 原来模型的召回率都有一定提升, 但可能由于数据量太小, 选择<i>K</i>=3会引入一定噪音, 文献<citation id="258" type="reference">[<a class="sup">21</a>]</citation>方法结合MDIIEL后准确率反而下降, 不过整体的F1有所提升.</p>
                </div>
                <div class="area_img" id="162">
                    <p class="img_tit">表7 Free917数据集上不同模型结合MDIIEL前后的性能对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 7 Performance comparison of different models before and after integration with MDIIEL on Free917 dataset</p>
                    <p class="img_note"></p>
                    <table id="162" border="1"><tr><td><br />模型</td><td>准确率</td><td>召回率</td><td>F1</td></tr><tr><td><br />文献[18]方法</td><td>67.0</td><td>59.0</td><td>62.7</td></tr><tr><td><br />文献[21]方法</td><td>76.4</td><td>65.9</td><td>70.8</td></tr><tr><td><br />文献[22]方法</td><td>71.5</td><td>67.9</td><td>69.7</td></tr><tr><td><br />MDIIEL+文献[18]方法</td><td>69.3</td><td>61.2</td><td>65.0</td></tr><tr><td><br />MDIIEL+文献[21]方法</td><td>75.8</td><td>67.2</td><td>71.2</td></tr><tr><td><br />MDIIEL+文献[22]方法</td><td>72.9</td><td>68.4</td><td>70.6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="163">基于WebQuestions数据集的模型在加入MDIIEL进行实体链接后性能对比如表8所示.该数据集是从Google Suggest API得到, 通过人工众包的方式获得答案, 相比Free917, 质量较差.但MDIIEL对语法、实体名简写等情况并不敏感, 因此加入MDIIEL模型进行初步筛选可以有效提高原来模型的性能.表中文献<citation id="259" type="reference">[<a class="sup">25</a>]</citation>方法由于会循环迭代获得语义信息, 加入MDIIEL后性能提升并不明显.实验中考虑问句质量及样本数目, 截取MDIIEL模型生成的前10个实体作为后续步骤输入, 即<i>K</i>=10.</p>
                </div>
                <div class="p1">
                    <p id="164">综上所述, MDIIEL模型通过引入类型、语义结构等隐含信息, 同时合并指称识别步骤并直接进行实体链接, 有效提升召回实体的质量, 间接提升整体问答性能.</p>
                </div>
                <div class="area_img" id="165">
                    <p class="img_tit">表8 WebQuestions数据集上不同模型结合MDIIEL前后的性能对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 8 Performance comparison of different models before and after integration with MDIIEL on WQ dataset</p>
                    <p class="img_note"></p>
                    <table id="165" border="1"><tr><td><br />模型</td><td>F1</td></tr><tr><td><br />文献[23]方法</td><td>53.3</td></tr><tr><td><br />文献[24]方法</td><td>55.7</td></tr><tr><td><br />文献[25]方法</td><td>63.4</td></tr><tr><td><br />MDIIEL+文献[23]方法</td><td>56.5</td></tr><tr><td><br />MDIIEL+文献[24]方法</td><td>58.1</td></tr><tr><td><br />MDIIEL+文献[25]方法</td><td>63.7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="166" name="166" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="167">知识库问答中的实体链接是后续关系预测等工作的重要铺垫.如果不能对相似实体进行合理区分, 问答准确率会大受影响.在传统候选实体生成筛选过程中, 指称识别和实体消歧步骤切分明确, 容易造成误差传递.对于实体的区分往往局限于词频、名称等字面信息, 未将实体类型、知识库本身重要的结构信息加以整合, 相互补充.本文通过合并指称识别和实体消歧, 结合表示学习方法, 将知识库语义结构信息引入模型, 同符号、类型层面的特征信息相互整合, 实现对相似实体进行更细致的区分.对比现有研究表明, 该模型在实体链接大部分指标上都具有整体性提升.在今后的工作中将进一步引入问句关系编码等信息, 将实体链接和关系预测这两个知识库问答子任务进行适当融合, 提高模型的整体效果和性能.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="266" type="" href="images/MSSB201907008_26600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">曾宇涛</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="267" type="" href="images/MSSB201907008_26700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">林谢雄</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="268" type="" href="images/MSSB201907008_26800.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">靳小龙</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="269" type="" href="images/MSSB201907008_26900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">席鹏弼</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="270" type="" href="images/MSSB201907008_27000.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">王元卓</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="189">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QBXB201501012&amp;v=MDMwNjRiTEc0SDlUTXJvOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVkx6Qk5DL1Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>陆伟, 武川.实体链接研究综述.情报学报, 2015, 34 (1) :105-112. (LU W, WU C.Literature Review on Entity Linking.Journal of the China Society for Scientific and Technical Information, 2015, 34 (1) :105-112.) 
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Entity linking with a knowledge base:issues,techniques,and solutions">

                                <b>[2]</b>SHEN W, WANG J Y, HAN J W.Entity Linking with a Knowledge Base:Issues, Techniques, and Solutions.IEEE Transactions on Knowledge and Data Engineering, 2015, 27 (2) :443-460.
                            </a>
                        </p>
                        <p id="193">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Joint Named Entity Recognition and Entity Linking System">

                                <b>[3]</b>STERN R, SAGOT B, BCHET F.A Joint Named Entity Recognition and Entity Linking System//Proc of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data.Stroudsburg, USA:ACL, 2012:52-60.
                            </a>
                        </p>
                        <p id="195">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Re-ranking for joint named-entity recognition and linking">

                                <b>[4]</b>SIL A, YATES A.Re-ranking for Joint Named-Entity Recognition and Linking//Proc of the 22nd ACM International Conference on Information and Knowledge Management.New York, USA:ACM, 2013:2369-2374.
                            </a>
                        </p>
                        <p id="197">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large-Scale Simple Question Answering with Memory Networks[C/OL]">

                                <b>[5]</b>BORDES A, USUNIER N, CHOPRA S, et al.Large-Scale Simple Question Answering with Memory Networks[C/OL].[2019-01-01].https://arxiv.org/pdf/1506.02075.pdf.
                            </a>
                        </p>
                        <p id="199">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Character-Level Question Answering with Attention[C/OL]">

                                <b>[6]</b>GOLUB D, HE X D.Character-Level Question Answering with Attention[C/OL].[2019-01-01].https://arxiv.org/pdf/1604.00727.pdf.
                            </a>
                        </p>
                        <p id="201">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simple Question Answering by Attentive Convolutional Neural Network[C/OL]">

                                <b>[7]</b>YIN W P, YU M, XIANG B, et al.Simple Question Answering by Attentive Convolutional Neural Network[C/OL].[2019-01-01].https://arxiv.org/pdf/1606.03391.pdf.
                            </a>
                        </p>
                        <p id="203">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural Network-based Question Answering over Knowledge Graphs on Word and Character Level">

                                <b>[8]</b>LUKOVNIKOV D, FISCHER A, LEHMANN J, et al.Neural Network-Based Question Answering over Knowledge Graphs on Word and Character Level//Proc of the 26th International Conference on World Wide Web.Berlin, Germany:Springer, 2017:1211-1220.
                            </a>
                        </p>
                        <p id="205">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved Neural Relation Detection for Knowledge Base Question Answering">

                                <b>[9]</b>YU M, YIN W P, HASAN K, et al.Improved Neural Relation Detection for Knowledge Base Question Answering//Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017, I:571-581.
                            </a>
                        </p>
                        <p id="207">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cat Boost:Unbiased Boosting with Categorical Features[C/OL]">

                                <b>[10]</b>PROKHORENKOVA L, GUSEV G, VOROBEV A, et al.Cat Boost:Unbiased Boosting with Categorical Features[C/OL].[2019-01-01].https://arxiv.org/pdf/1706.09516.pdf.
                            </a>
                        </p>
                        <p id="209">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201609007&amp;v=MDYyMDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVkx6QktEN1liTEc0SDlmTXBvOUZZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b>詹晨迪, 凌震华, 戴礼荣.面向知识库问答中复述问句评分的词向量构建方法.模式识别与人工智能, 2016, 29 (9) :825-831. (ZHAN C D, LING Z H, DAI L R.Learning Word Embeddings for Paraphrase Scoring in Knowledge Base Based Question Answering.Pattern Recognition and Artificial Intelligence, 2016, 29 (9) :825-831.) 
                            </a>
                        </p>
                        <p id="211">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">

                                <b>[12]</b>PENNINGTON J, SOCHER R, MANNING C.Glove:Global Vectors for Word Representation//Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2014:1532-1543.
                            </a>
                        </p>
                        <p id="213">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201705011&amp;v=MjkzNTBiTXFvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVkx6QktEN1liTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b>吴运兵, 朱丹红, 廖祥文, 等.路径张量分解的知识图谱推理算法.模式识别与人工智能, 2017, 30 (5) :473-480. (WU Y B, ZHU D H, LIAO X W, et al.Knowledge Graph Reasoning Based on Paths of Tensor Factorization.Pattern Recognition and Artificial Intelligence, 2017, 30 (5) :473-480.
                            </a>
                        </p>
                        <p id="215">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Translating Embeddings for Modeling Multi-relational Data[C/OL]">

                                <b>[14]</b>BORDES A, USUNIER N, GARCIA-DURAN A, et al.Translating Embeddings for Modeling Multi-relational Data[C/OL].[2019-01-01].http://www.thespermwhale.com/jaseweston/papers/CR_paper_nips13.pdf.
                            </a>
                        </p>
                        <p id="217">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Knowledge graph embedding by translating on hyperplanes">

                                <b>[15]</b>WANG Z, ZHANG J W, FENG J L, et al.Knowledge Graph Embedding by Translating on Hyperplanes//Proc of the 28th AAAIConference on Artificial Intelligence.Palo Alto, USA:AAAIPress, 2014:1112-1119.
                            </a>
                        </p>
                        <p id="219">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning entity and relation embeddings for knowledge graph completion">

                                <b>[16]</b>LIN Y K, LIU Z Y, SUN M S, et al.Learning Entity and Relation Embeddings for Knowledge Graph Completion//Proc of the 29th AAAI Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2015:2181-2187.
                            </a>
                        </p>
                        <p id="221">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Knowledge Graph Embedding via Dynamic Mapping Matrix">

                                <b>[17]</b>JI G L, HE S Z, XU L H, et al.Knowledge Graph Embedding via Dynamic Mapping Matrix//Proc of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL, 2015, I:687-696.
                            </a>
                        </p>
                        <p id="223">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Large-scale Semantic Parsing via Schema Matching and Lex-icon Extension">

                                <b>[18]</b>CAI Q Q, YATES A.Large-Scale Semantic Parsing via Schema Matching and Lexicon Extension//Proc of the 51st Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2013, 1:423-433.
                            </a>
                        </p>
                        <p id="225">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semantic parsing on freebase from question-answer pairs">

                                <b>[19]</b>BERANT J, CHOU A, FROSTIG R, et al.Semantic Parsing on Freebase from Question-Answer Pairs//Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2013:1533-1544.
                            </a>
                        </p>
                        <p id="227">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical Type Constrained Topic Entity Detection for Knowledge Base Question Answering">

                                <b>[20]</b>QIU Y Q, LI M L, WANG Y Z, et al.Hierarchical Type Constrained Topic Entity Detection for Knowledge Base Question Answering//Proc of the Companion of the Web Conference.Berlin, Germany:Springer, 2018:35-36.
                            </a>
                        </p>
                        <p id="229">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=More Accurate Question Answering on Freebase">

                                <b>[21]</b>BAST H, HAUSSMANN E.More Accurate Question Answering on Freebase//Proc of the 24th ACM International Conference on Information and Knowledge Management.New York, USA:ACM, 2015:1431-1440.
                            </a>
                        </p>
                        <p id="231">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-Supervised Lexicon Learning for Wide-Coverage Semantic Parsing">

                                <b>[22]</b>CHEN B, AN B, SUN L, et al.Semi-Supervised Lexicon Learning for Wide-Coverage Semantic Parsing//Proc of the 27th International Conference on Computational Linguistics.Stroudsburg, USA:ACL, 2018:892-904.
                            </a>
                        </p>
                        <p id="233">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Question answering on freebase via relation extraction and textual evidence">

                                <b>[23]</b>XU K, REDDY S, FENG Y S, et al.Question Answering on Freebase via Relation Extraction and Textual Evidence//Proc of the54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2016, I:2326-2336.
                            </a>
                        </p>
                        <p id="235">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Question answering over knowledge base using factual memory networks">

                                <b>[24]</b>JAIN S.Question Answering over Knowledge Base Using Factual Memory Networks//Proc of the NAACL Student Research Workshop.Stroudsburg, USA:ACL, 2016:109-115.
                            </a>
                        </p>
                        <p id="237">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The APVA-TURBOApproach to Question Answering in Knowledge Base">

                                <b>[25]</b>WANG Y, ZHANG R C, XU C, et al.The APVA-TURBOApproach to Question Answering in Knowledge Base//Proc of the27th International Conference on Computational Linguistics.Stroudsburg, USA:ACL, 2018:1998-2009.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201907008" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201907008&amp;v=MDMwMTZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVkx6QktEN1liTEc0SDlqTXFJOUY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
