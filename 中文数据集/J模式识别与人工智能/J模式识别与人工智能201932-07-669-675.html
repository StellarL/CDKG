<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131453988936250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201907011%26RESULT%3d1%26SIGN%3dfNqMB9%252bnv4wC7%252bD%252fCy8wSnpQjb0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201907011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201907011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201907011&amp;v=MDI5Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVkwzQktEN1liTEc0SDlqTXFJOUVaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#83" data-title="1 多特征融合的图像质量评价方法 ">1 多特征融合的图像质量评价方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#87" data-title="&lt;b&gt;1.1 对比度局域相似图&lt;/b&gt;"><b>1.1 对比度局域相似图</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;1.2 视觉显著性全局相似图&lt;/b&gt;"><b>1.2 视觉显著性全局相似图</b></a></li>
                                                <li><a href="#100" data-title="&lt;b&gt;1.3 相位一致性相似度图&lt;/b&gt;"><b>1.3 相位一致性相似度图</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;1.4 梯度幅度相似度图&lt;/b&gt;"><b>1.4 梯度幅度相似度图</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;1.5 质量评价模型&lt;/b&gt;"><b>1.5 质量评价模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#118" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#119" data-title="&lt;b&gt;2.1 标准图像库及评价标准&lt;/b&gt;"><b>2.1 标准图像库及评价标准</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;2.2 与典型算法的统计对比分析&lt;/b&gt;"><b>2.2 与典型算法的统计对比分析</b></a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;2.3 独立性实验&lt;/b&gt;"><b>2.3 独立性实验</b></a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;2.4 不同回归方法预测性能对比&lt;/b&gt;"><b>2.4 不同回归方法预测性能对比</b></a></li>
                                                <li><a href="#151" data-title="&lt;b&gt;2.5 散点图&lt;/b&gt;"><b>2.5 散点图</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#171" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#86" data-title="图1 本文方法流程图">图1 本文方法流程图</a></li>
                                                <li><a href="#122" data-title="表1 图像数据库相关信息">表1 图像数据库相关信息</a></li>
                                                <li><a href="#134" data-title="表2 10种方法在4个图像数据库上的性能对比">表2 10种方法在4个图像数据库上的性能对比</a></li>
                                                <li><a href="#137" data-title="表3 10种方法在4个数据库上的综合性能对比">表3 10种方法在4个数据库上的综合性能对比</a></li>
                                                <li><a href="#144" data-title="表4 本文方法的交叉验证性能">表4 本文方法的交叉验证性能</a></li>
                                                <li><a href="#149" data-title="表5 不同回归方法的预测性能">表5 不同回归方法的预测性能</a></li>
                                                <li><a href="#203" data-title="图2 本文方法在LIVE数据库上的预测一致性散点图">图2 本文方法在LIVE数据库上的预测一致性散点图</a></li>
                                                <li><a href="#203" data-title="图2 本文方法在LIVE数据库上的预测一致性散点图">图2 本文方法在LIVE数据库上的预测一致性散点图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" WANG Z, BOVIK A C.Modern Image Quality Assessment.San Rafael, USA:Morgan &amp;amp; Claypool, 2006." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modern Image Quality Assessment">
                                        <b>[1]</b>
                                         WANG Z, BOVIK A C.Modern Image Quality Assessment.San Rafael, USA:Morgan &amp;amp; Claypool, 2006.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" WANG Z, BOVIK A C, LU L G.Why Is Image Quality Assessment so Difficult // Proc of the IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 2002, IV:3313-3316." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Why is image qualityassessment sodifficult?">
                                        <b>[2]</b>
                                         WANG Z, BOVIK A C, LU L G.Why Is Image Quality Assessment so Difficult // Proc of the IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 2002, IV:3313-3316.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" WANG Z, BOVIK A C, SHEIKH H R, &lt;i&gt;et al&lt;/i&gt;.Image Quality Assessment:From Error Visibility to Structural Similarity.IEEE Transactions on Image Processing, 2004, 13 (4) :600-612." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image quality assessment: from error visibility to structural similarity">
                                        <b>[3]</b>
                                         WANG Z, BOVIK A C, SHEIKH H R, &lt;i&gt;et al&lt;/i&gt;.Image Quality Assessment:From Error Visibility to Structural Similarity.IEEE Transactions on Image Processing, 2004, 13 (4) :600-612.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" WANG Z, SIMONCELLI E P, BOVIK A C.Multiscale Structural Similarity for Image Quality Assessment // Proc of the IEEE Confe-rence Record of the 37th Asilomar Conference on Signals, Systems and Computers.Washington, USA:IEEE, 2003, II:9-12." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-scalestructural similarity for image quality assessment">
                                        <b>[4]</b>
                                         WANG Z, SIMONCELLI E P, BOVIK A C.Multiscale Structural Similarity for Image Quality Assessment // Proc of the IEEE Confe-rence Record of the 37th Asilomar Conference on Signals, Systems and Computers.Washington, USA:IEEE, 2003, II:9-12.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" CHEN G H, YANG C L, XIE S L, &lt;i&gt;et al&lt;/i&gt;.Gradient-Based Structural Similarity for Image Quality Assessment // Proc of the International Conference on Image Processing.Washington, USA:IEEE, 2006:2929-2932." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gradient-based structural similarity for image quality assessment">
                                        <b>[5]</b>
                                         CHEN G H, YANG C L, XIE S L, &lt;i&gt;et al&lt;/i&gt;.Gradient-Based Structural Similarity for Image Quality Assessment // Proc of the International Conference on Image Processing.Washington, USA:IEEE, 2006:2929-2932.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" WANG Z, SIMONCELLI E P.Translation Insensitive Image Similarity in Complex Wavelet Domain // Proc of the IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 2005, II:573-576." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Translation insensitiveimage similarity in complex wavelet domain">
                                        <b>[6]</b>
                                         WANG Z, SIMONCELLI E P.Translation Insensitive Image Similarity in Complex Wavelet Domain // Proc of the IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 2005, II:573-576.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" LI C F, BOVIK A C.Three-Component Weighted Structural Similarity Index.Proc of SPIE, 2009, 7242.DOI:10.1117/12.811821." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Three-component weighted structural similarity index&amp;quot;">
                                        <b>[7]</b>
                                         LI C F, BOVIK A C.Three-Component Weighted Structural Similarity Index.Proc of SPIE, 2009, 7242.DOI:10.1117/12.811821.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" WANG Z, LI Q.Information Content Weighting for Perceptual Image Quality Assessment.IEEE Transactions on Image Process, 2011, 20 (5) :1185-1198." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Information Content Weighting for Perceptual Image Quality Assessment">
                                        <b>[8]</b>
                                         WANG Z, LI Q.Information Content Weighting for Perceptual Image Quality Assessment.IEEE Transactions on Image Process, 2011, 20 (5) :1185-1198.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" DAMERA-VENKATA N, KITE T D, GEISLER W S, &lt;i&gt;et al&lt;/i&gt;.Image Quality Assessment Based on a Degradation Model.IEEE Transactions on Image Processing, 2000, 9 (4) :636-650." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image quality assessment based on a degradation model">
                                        <b>[9]</b>
                                         DAMERA-VENKATA N, KITE T D, GEISLER W S, &lt;i&gt;et al&lt;/i&gt;.Image Quality Assessment Based on a Degradation Model.IEEE Transactions on Image Processing, 2000, 9 (4) :636-650.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" CHANDLER D M, HEMAMI S S.VSNR:A Wavelet-Based Vi-sual Signal-to-Noise Ratio for Natural Images.IEEE Transactions on Image Processing, 2007, 16 (9) :2284-2298." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VSNR: A Wavelet-Based Visual Signal-to-Noise Ratio for Natural Images">
                                        <b>[10]</b>
                                         CHANDLER D M, HEMAMI S S.VSNR:A Wavelet-Based Vi-sual Signal-to-Noise Ratio for Natural Images.IEEE Transactions on Image Processing, 2007, 16 (9) :2284-2298.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" SHEIKH H R, BOVIK A C, VECIANA D.An Information Fidelity Criterion for Image Quality Assessment Using Natural Scene Statistics.IEEE Transactions on Image Process, 2005, 14 (12) :2117-2128." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An information fidelity criterion for image quality assessment using natural scene statistics">
                                        <b>[11]</b>
                                         SHEIKH H R, BOVIK A C, VECIANA D.An Information Fidelity Criterion for Image Quality Assessment Using Natural Scene Statistics.IEEE Transactions on Image Process, 2005, 14 (12) :2117-2128.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" SHEIKH H R, BOVIK A C.Image Information and Visual Quality.IEEE Transactions on Image Process, 2006, 15 (2) :430-444." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image information and visual quality">
                                        <b>[12]</b>
                                         SHEIKH H R, BOVIK A C.Image Information and Visual Quality.IEEE Transactions on Image Process, 2006, 15 (2) :430-444.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" LARSON E C, CHANDLER D M.Most Apparent Distortion:Full-Reference Image Quality Assessment and the Role of Strategy.Journal of Electronic Imaging, 2010, 19 (1) .DOI:10.1117/1.3267105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Most apparent distortion: full-reference image quality assessment and the role of strategy">
                                        <b>[13]</b>
                                         LARSON E C, CHANDLER D M.Most Apparent Distortion:Full-Reference Image Quality Assessment and the Role of Strategy.Journal of Electronic Imaging, 2010, 19 (1) .DOI:10.1117/1.3267105.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" ZHANG L, ZHANG L, MOU X Q, &lt;i&gt;et al&lt;/i&gt;.FSIM:A Feature Similarity Index for Image Quality Assessment.IEEE Transactions on Image Processing, 2011, 20 (8) :2378-2386." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=FSIM: A Feature Similarity Index for Image Quality Assessment">
                                        <b>[14]</b>
                                         ZHANG L, ZHANG L, MOU X Q, &lt;i&gt;et al&lt;/i&gt;.FSIM:A Feature Similarity Index for Image Quality Assessment.IEEE Transactions on Image Processing, 2011, 20 (8) :2378-2386.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" ZHANG L, SHEN Y, LI H Y.VSI:A Visual Saliency-Induced Index for Perceptual Image Quality Assessment.IEEE Transactions on Image Processing, 2014, 23 (10) :4270-4281." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=VSI:A Visual Saliency Induced Index for Perceptual Image Quality Assessment">
                                        <b>[15]</b>
                                         ZHANG L, SHEN Y, LI H Y.VSI:A Visual Saliency-Induced Index for Perceptual Image Quality Assessment.IEEE Transactions on Image Processing, 2014, 23 (10) :4270-4281.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" LIU A M, LIN W S, NARWARIA M.Image Quality Assessment Based on Gradient Similarity.IEEE Transactions on Image Proce-ssing, 2012, 21 (4) :1500-1512." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Quality Assessment Based on Gradient Similarity">
                                        <b>[16]</b>
                                         LIU A M, LIN W S, NARWARIA M.Image Quality Assessment Based on Gradient Similarity.IEEE Transactions on Image Proce-ssing, 2012, 21 (4) :1500-1512.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" XUE W F, ZHANG L, MOU X Q, &lt;i&gt;et al&lt;/i&gt;.Gradient Magnitude Si-milarity Deviation:A Highly Efficient Perceptual Image Quality Index.IEEE Transactions on Image Processing, 2014, 23 (2) :684-695." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gradient magnitude similarity deviation:A highly efficient perceptual image quality index">
                                        <b>[17]</b>
                                         XUE W F, ZHANG L, MOU X Q, &lt;i&gt;et al&lt;/i&gt;.Gradient Magnitude Si-milarity Deviation:A Highly Efficient Perceptual Image Quality Index.IEEE Transactions on Image Processing, 2014, 23 (2) :684-695.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" WANG T H, ZHANG L, JIA H Z, &lt;i&gt;et al&lt;/i&gt;.Multiscale Contrast Similarity Deviation:An Effective and Efficient Index for Perceptual Image Quality Assessment.Signal Processing:Image Communication, 2016, 45:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multiscale contrast similarity deviation:An effective and efficient index for perceptual image quality assessment">
                                        <b>[18]</b>
                                         WANG T H, ZHANG L, JIA H Z, &lt;i&gt;et al&lt;/i&gt;.Multiscale Contrast Similarity Deviation:An Effective and Efficient Index for Perceptual Image Quality Assessment.Signal Processing:Image Communication, 2016, 45:1-9.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" PONOMARENKO N, IEREMEIEV O, LUKIN V, &lt;i&gt;et al&lt;/i&gt;.Color Image Database TID2013:Peculiarities and Preliminary Results // Proc of the European Workshop on Visual Information Processing.Washington, USA:IEEE, 2013:106-111." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Color image database TID2013:peculiarities and preliminary results,&amp;quot;">
                                        <b>[19]</b>
                                         PONOMARENKO N, IEREMEIEV O, LUKIN V, &lt;i&gt;et al&lt;/i&gt;.Color Image Database TID2013:Peculiarities and Preliminary Results // Proc of the European Workshop on Visual Information Processing.Washington, USA:IEEE, 2013:106-111.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" JEFFREY L.A Visual Discrimination Model for Imaging System Design and Evaluation // PELI E, ed.Visual Models for Target Detection and Recognition.Singapore, Singapore:World Scientific, 1995:207-220." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A visual discrimination model for imaging system design and evaluation">
                                        <b>[20]</b>
                                         JEFFREY L.A Visual Discrimination Model for Imaging System Design and Evaluation // PELI E, ed.Visual Models for Target Detection and Recognition.Singapore, Singapore:World Scientific, 1995:207-220.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" SAFRANEK R J, JOHNSTON J D.A Perceptually Tuned Sub-band Image Coder with Imaging Dependent Quantization and Post-Quantization Data Compression // Proc of the IEEE Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 1989:1945-1948." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A perceptually tuned sub-band image coder with image dependent quantization and post-quantization data compression">
                                        <b>[21]</b>
                                         SAFRANEK R J, JOHNSTON J D.A Perceptually Tuned Sub-band Image Coder with Imaging Dependent Quantization and Post-Quantization Data Compression // Proc of the IEEE Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 1989:1945-1948.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" HOU X D, ZHANG L Q.Saliency Detection:A Spectral Residual Approach // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2007.DOI:10.1109/CVPR.2007.383267." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Saliency detection:a spectral residual approach">
                                        <b>[22]</b>
                                         HOU X D, ZHANG L Q.Saliency Detection:A Spectral Residual Approach // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2007.DOI:10.1109/CVPR.2007.383267.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" KOVESI P.Image Features from Phase Congruency.Journal of Computer Vision, 1999, 1 (3) :1-26." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image features from phase congruency">
                                        <b>[23]</b>
                                         KOVESI P.Image Features from Phase Congruency.Journal of Computer Vision, 1999, 1 (3) :1-26.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" 贾惠珍, 孙权森, 王同罕.结合感知特征和自然场景统计的无参考图像质量评价.中国图象图形学报, 2014, 19 (6) :859-867. (JIA H Z, SUN Q S, WANG T H.Blind Image Quality Assessment Based on Perceptual Features and Natural Scene Statistics.Journal of Image and Graphics, 2014, 19 (6) :859-867.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201406006&amp;v=MjU5NzFuRnl6aFZMM0FQeXJmYkxHNEg5WE1xWTlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         贾惠珍, 孙权森, 王同罕.结合感知特征和自然场景统计的无参考图像质量评价.中国图象图形学报, 2014, 19 (6) :859-867. (JIA H Z, SUN Q S, WANG T H.Blind Image Quality Assessment Based on Perceptual Features and Natural Scene Statistics.Journal of Image and Graphics, 2014, 19 (6) :859-867.) 
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" 吴帅, 徐勇, 赵东宁.基于深度卷积网络的目标检测综述.模式识别与人工智能, 2018, 31 (4) :335-346. (WU S, XU Y, ZHAO D N.Survey of Object Detection Based on Deep Convolutional Network.Pattern Recognition and Artificial Intelligence, 2018, 31 (4) :335-346.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201804006&amp;v=MDM3NTZxQnRHRnJDVVJMT2VaZVJuRnl6aFZMM0FLRDdZYkxHNEg5bk1xNDlGWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         吴帅, 徐勇, 赵东宁.基于深度卷积网络的目标检测综述.模式识别与人工智能, 2018, 31 (4) :335-346. (WU S, XU Y, ZHAO D N.Survey of Object Detection Based on Deep Convolutional Network.Pattern Recognition and Artificial Intelligence, 2018, 31 (4) :335-346.) 
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" NGUYEN A, KIM J, OH H, &lt;i&gt;et al&lt;/i&gt;.Deep Visual Saliency on Stere-oscopic Images.IEEE Transactions on Image Processing, 2019, 28 (4) :1939-1953." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Visual Saliency on Stere-oscopic Images">
                                        <b>[26]</b>
                                         NGUYEN A, KIM J, OH H, &lt;i&gt;et al&lt;/i&gt;.Deep Visual Saliency on Stere-oscopic Images.IEEE Transactions on Image Processing, 2019, 28 (4) :1939-1953.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title=" BASAK D, PAL S, PATRANABIS D C.Support Vector Regression.Neural Information Processing, 2007, 11 (10) :203-224." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Support Vector Regression">
                                        <b>[27]</b>
                                         BASAK D, PAL S, PATRANABIS D C.Support Vector Regression.Neural Information Processing, 2007, 11 (10) :203-224.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_28" title=" WANG T H, ZHANG L, JIA H Z.An Effective General-Purpose NR-IQA Model Using Natural Scene Statistics (NSS) of the Luminance Relative Order.Signal Processing (Image Communication) , 2019, 71:100-109." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Effective General-Purpose NR-IQA Model Using Natural Scene Statistics (NSS) of the Luminance Relative Order">
                                        <b>[28]</b>
                                         WANG T H, ZHANG L, JIA H Z.An Effective General-Purpose NR-IQA Model Using Natural Scene Statistics (NSS) of the Luminance Relative Order.Signal Processing (Image Communication) , 2019, 71:100-109.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_29" title=" BREIMAN L.Random Forests.Machine Learning, 2001, 45 (1) :5-32." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MTM4NDJ3T1kzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNIbFY3dlBJbFk9Tmo3QmFyTzRIdEhOckl0Rlp1&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[29]</b>
                                         BREIMAN L.Random Forests.Machine Learning, 2001, 45 (1) :5-32.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_30" title=" TOMANDL D, SCHOBER A.A Modified General Regression Neural Network (MGRNN) with New, Efficient Training Algorithms as a Robust ′Black Box′-Tool for Data Analysis.Neural Networks, 2001, 14 (8) :1023-1034." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070463&amp;v=MTY0ODQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGb1RhQm89TmlmT2ZiSzdIdERPckk5RlpPd1BDSG82b0JNVA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[30]</b>
                                         TOMANDL D, SCHOBER A.A Modified General Regression Neural Network (MGRNN) with New, Efficient Training Algorithms as a Robust ′Black Box′-Tool for Data Analysis.Neural Networks, 2001, 14 (8) :1023-1034.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(07),669-675 DOI:10.16451/j.cnki.issn1003-6059.201907011            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>多特征融合的图像质量评价方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BE%E6%83%A0%E7%8F%8D&amp;code=39002157&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贾惠珍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%90%8C%E7%BD%95&amp;code=39002156&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王同罕</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%82%85%E9%B9%8F&amp;code=26960073&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">傅鹏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%9C%E5%8D%8E%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E6%B1%9F%E8%A5%BF%E7%9C%81%E6%94%BE%E5%B0%84%E6%80%A7%E5%9C%B0%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E5%B7%A5%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0042235&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">东华理工大学江西省放射性地学大数据技术工程实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0077991&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京理工大学计算机科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了规避图像质量评价中的视觉特征和池化策略难以选取和解释的问题, 在提取参考图像和失真图像的多种底层特征的基础上, 采用机器学习的方法自动预测真实图像质量, 提出多特征融合的图像质量评价方法.针对参考图像和失真图像分别提取相位一致性、梯度、视觉显著性、对比度特征, 计算4种特征的相似度图, 提取相似度图的均值和方差特征, 最后采用支持向量回归评价文中方法.在LIVE、CSIQ、TID2008和TID2013图像库上的实验表明, 文中方法的主客观一致性较好.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BA%95%E5%B1%82%E7%89%B9%E5%BE%81%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">底层特征相似度图;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">统计特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B1%A0%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">池化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *贾惠珍 (通讯作者) , 博士, 讲师, 主要研究方向为图像处理、模式识别.E-mail:hzjianlg@126.com.;
                                </span>
                                <span>
                                    王同罕, 博士, 讲师, 主要研究方向为图像处理、模式识别.E-mail:thwang_seu@163.com.;
                                </span>
                                <span>
                                    傅鹏, 博士, 讲师, 主要研究方向为图像处理、模式识别.E-mail:fupeng@njust.edu.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-28</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.61762004);</span>
                                <span>江西省教育厅科学技术研究项目 (No.GJJ170455);</span>
                                <span>东华理工大学江西省放射性地学大数据技术工程实验室开放基金项目 (No.JELRGBDT201702) ;东华理工大学博士启动基金项目 (No.DHBK2016119, DHBK2016120) 资助;</span>
                    </p>
            </div>
                    <h1><b>Multi-feature Fusion Based Image Quality Assessment Method</b></h1>
                    <h2>
                    <span>JIA Huizhen</span>
                    <span>WANG Tonghan</span>
                    <span>FU Peng</span>
            </h2>
                    <h2>
                    <span>Jiangxi Engineering Laboratory on Radioactive Geoscience and Big Data Technology, East China University of Technology</span>
                    <span>School of Computer Science and Engineering, Nanjing University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To avoid the difficulties in choosing and explaining the visual features and pooling strategies in image quality assessment, a reference images quality assessment method based on multi-feature fusion is proposed. Various underlying features of reference and distorted images are extracted, and a machine learning method is applied to predict the quality of real images. Firstly, phase congruency, gradient, visual saliency and contrast of reference and distorted images are extracted. Then similarity maps of four features are calculated, respectively. The mean and variance characteristics of these similarity maps are extracted. Finally, the assessment model is learned by support vector regression. The experimental results on four benchmark databases demonstrate a high coherence between subjective and objective assessment by the proposed method.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Low-level%20Feature%20Similarity%20Map&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Low-level Feature Similarity Map;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Statistical%20Features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Statistical Features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Pooling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Pooling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Support%20Vector%20Machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Support Vector Machine;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    JIA Huizhen ( Corresponding author) , Ph. D. , lecturer. Her research interests include image processing and pattern recognition.;
                                </span>
                                <span>
                                    WANG Tonghan, Ph. D. , lecturer. His research interests include image processing and pattern recognition.;
                                </span>
                                <span>
                                    FU Peng, Ph. D. , lecturer. His research interests include image processing and pattern recognition.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-11-28</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.61762004);</span>
                                <span>Science and Technology Project Founded by Education Department of Jiangxi Province (No.GJJ170455);</span>
                                <span>Open Fund of Jiangxi Engineering Laboratory on Radioactive Geoscience and Big Data Technology (No.JELRGBDT201702) ;Ph.D.Research Startup Foundation of East China University of Technology (No.DHBK2016119, DH BK2016120);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="78">在图像相关领域中，图像质量评价 (Image Quality Assessment, IQA) 主要分为主观评价和客观评价两种方式．主观评价方式通过人类视觉系统进行评价，较准确，但不稳定，耗时，代价较高，难以操作．客观评价方法对人类视觉系统的感知原理进行建模，通过模型评价图像质量，具有批量处理、结果稳定和可重现的优点．根据对原图像依赖程度，客观评价方法有:全参考图像质量评价 (Full-Reference IQA, FR-IQA) 、部分参考图像质量评价 (ReducedReference IQA，RR-IQA) 和无参考图像质量评价 (No-Reference IQA, NR-IQA) <sup><a class="sup">[1]</a></sup>．本文主要研究FR-IQA.</p>
                </div>
                <div class="p1">
                    <p id="79">FR-IQA可衡量图像处理算法的优劣性.根据设计思想主要分为基于像素域的方法、基于人类视觉系统的方法及基于工程学的方法.基于像素域方法通过测量对应像素的误差得到失真测度, 典型方法有均方误差 (Mean Squared Error, MSE) 和峰值信噪比 (Peak Signal-to-Noise Ratio, PSNR) .该方法计算简单, 意义简明, 但由于忽略人类视觉系统 (Human Visual System, HVS) 特性, 评价性能不佳<citation id="174" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="80">为此, 研究者提出基于HVS的算法, 根据HVS感知原理构建数学模型, 获得质量评价测度.由于HVS的复杂性, 很多关键机理还无法完全理解, 评价效果有限, 因此学者们提出大量基于工程学的方法<citation id="186" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation> , 将HVS看作“黑箱子”, 通过对输入和输出的关系进行建模, 得到与人眼判断高度一致且计算快速的评价测度.根据视觉特性提取相应特征, 计算图像质量相似度图, 采用巧妙的池化策略得到失真图像质量评价测度, 典型算法包括结构相似度 (Structural Similarity, SSIM) <citation id="175" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、多尺度结构相似度 (Multiscale SSIM, MS-SSIM) <citation id="176" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、信息加权结构相似度 (Information Content Weighted SSIM, IW-SSIM) <citation id="177" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、信息保真度 (Information Fidelity Criterion, IFC) <citation id="178" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、视觉信息保真度 (Visual Information Fidelity, VIF) <citation id="179" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、最明显失真 (Most Apparent Distortion, MAD) <citation id="180" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation> 、特征结构相似度 (Feature-Similarity Index, FSIM) <citation id="181" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation> 、视觉显著性 (Visual Saliency-Based Index, VSI) <citation id="182" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、梯度幅值相似方差 (Gradient Magnitude Similarity Deviation, GMSD) <citation id="183" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>、多尺度对比度相似方差 (Mul-tiscale Contrast Similarity Deviation, MCSD) <sup></sup><citation id="184" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>和文献<citation id="185" type="reference">[<a class="sup">19</a>]</citation>方法.上述方法设计重点包括:提取可以反映视觉特性的视觉特征;采取合适的池化策略.</p>
                </div>
                <div class="p1">
                    <p id="81">当前算法采用的视觉特征主要有相位一致性、梯度、对比度、视觉显著性等其中的一种或两种, 采取的池化策略有平均策略、加权平均策略、标准方差策略等, 但是选取哪些特征、为何选取及采用何种池化策略均是问题的难点, 同时存在难以解释这一问题.</p>
                </div>
                <div class="p1">
                    <p id="82">本文尝试绕开这一思想, 采用机器学习方法自动学习视觉特征与主观分数的对应关系, 提出多特征融合的图像质量评价方法.由于支持向量机回归 (Support Vector Machine Regression, SVR) 在解决高维问题方面具有良好性能, 故采用SVR学习方法.在LIVE、CSIQ、TID2008和TID2013图像库上实验表明本文方法具有较好的主客观一致性.</p>
                </div>
                <h3 id="83" name="83" class="anchor-tag">1 多特征融合的图像质量评价方法</h3>
                <div class="p1">
                    <p id="85">多特征融合的图像质量评价方法分别提取参考图像和失真图像的4个特征图:相位一致性、梯度、视觉显著性、对比度图.在此基础上, 得到对应的相似度图, 提取4幅特征相似度图的均值与方差, 构成特征向量, 采用SVR学习图像预测模型并预测图像, 具体方法流程图如图1所示.</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907011_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文方法流程图" src="Detail/GetImg?filename=images/MSSB201907011_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文方法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907011_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Flow chart of the proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="87" name="87"><b>1.1 对比度局域相似图</b></h4>
                <div class="p1">
                    <p id="88">作为图像的一个固有属性, 对比度在一定程度上反映图像质量, 因为较高质量的图像具有合适的对比度<citation id="187" type="reference"><link href="41" rel="bibliography" /><link href="43" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>, 鉴于均方根误差的对比度主要适用于自然图像, 本文方法采用该对比度:</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mo>=</mo><mrow><mo stretchy="false">[</mo><mfrac><mn>1</mn><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover><mo stretchy="false">) </mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">其中, <i>I</i><sub><i>i</i></sub>为图像<i>I</i>的第<i>i</i>个像素, <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover></math></mathml>为图像像素均值, <i>N</i>为图像像素个数.设参考图像和失真图像的局部对比度图 (Local Contrast Similarity, LCS) 分别记为<i>C</i><sub><i>r</i></sub>和<i>C</i><sub><i>d</i></sub>, 则LCS定义为</p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>C</mi><mi>S</mi><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mn>2</mn><mi>C</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>C</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mrow><mrow><mo stretchy="false"> (</mo><mi>C</mi><msubsup><mrow></mrow><mi>r</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>C</mi><msubsup><mrow></mrow><mi>d</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93">其中, <i>c</i><sub>1</sub>为一整数, 增加公式稳定性.</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>1.2 视觉显著性全局相似图</b></h4>
                <div class="p1">
                    <p id="95">视觉显著性通常作为一种加权策略以使用, 用于构造视觉显著性相似图, 考虑到高效性问题, 本文采用谱残差 (Spectral Residual, SR) 模型<citation id="188" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>获得视觉显著图.</p>
                </div>
                <div class="p1">
                    <p id="96">参考图像和失真图像的显著图分别记为<i>VS</i><sub><i>r</i></sub>和<i>VS</i><sub><i>d</i></sub>, 相应相似度图定义为</p>
                </div>
                <div class="p1">
                    <p id="97" class="code-formula">
                        <mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>V</mi><mi>S</mi><mi>S</mi><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mn>2</mn><mi>v</mi><mi>s</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>v</mi><mi>s</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>v</mi><mi>s</mi><msubsup><mrow></mrow><mi>r</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>v</mi><mi>s</mi><msubsup><mrow></mrow><mi>d</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="98">其中, <i>c</i><sub>2</sub>为一个正数, 增加公式的稳定性.</p>
                </div>
                <div class="p1">
                    <p id="99">为了增加有效性, 对图像进行均值滤波和下采样 (采样步长为2) , 再计算视觉显著性.</p>
                </div>
                <h4 class="anchor-tag" id="100" name="100"><b>1.3 相位一致性相似度图</b></h4>
                <div class="p1">
                    <p id="101">相位一致性是指在图像的变换域 (傅里叶变换) , 相似的特征通常在某一阶段出现的频率较高, 将相位一致的点看作特征降低因亮度、对比度等带来的影响, 本文方法采取文献<citation id="189" type="reference">[<a class="sup">23</a>]</citation>中的计算方式:</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mi>c</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>n</mi></munder><mi>W</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>⌊</mo><mi>A</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi>Δ</mi><mi>Φ</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Τ</mi><mo>⌋</mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mi>n</mi></munder><mi>A</mi></mstyle><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>+</mo><mi>ε</mi></mrow></mfrac><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">公式中参数的计算方法详见文献<citation id="190" type="reference">[<a class="sup">24</a>]</citation>.</p>
                </div>
                <div class="p1">
                    <p id="104">参考图像和失真图像的相位一致性图分别记为<i>pc</i><sub><i>r</i></sub>和<i>pc</i><sub><i>d</i></sub>, 全局视觉显著性相似度图<i>PCSS</i> (<i>i</i>) 可定义为</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>C</mi><mi>S</mi><mi>S</mi><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mn>2</mn><mi>p</mi><mi>c</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>p</mi><mi>c</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mrow><mi>p</mi><mi>c</mi><msubsup><mrow></mrow><mi>r</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><mi>c</mi><msubsup><mrow></mrow><mi>d</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>3</mn></msub></mrow></mfrac><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">其中<i>c</i><sub>3</sub>用于保持公式的稳定.</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>1.4 梯度幅度相似度图</b></h4>
                <div class="p1">
                    <p id="108">由于梯度在一定程度上反映图像中细节和纹理的相应变化, 已应用于各种图像质量评价方法中, 如梯度相似法 (Gradient Simarity Based Metric, GSM) <citation id="191" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、GMSD<citation id="192" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>等, 这 些 评 价 模 型 具 有较好的评价性能.基于此种情况, 本文采用梯度幅度衡量图像的失真程度.常用的梯度算子如Sobel、Roberts、Prewitt、Scharr等, 本文的梯度由Prewitt算子获得.参考图像和失真图像分别使用<i>I</i><sub><i>r</i></sub>和<i>I</i><sub><i>d</i></sub>表示如下:</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>r</mi></msub><mo>=</mo><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>r</mi></msub><mo>⊗</mo><mi>h</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>r</mi></msub><mo>⊗</mo><mi>h</mi><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msqrt><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mi>d</mi></msub><mo>=</mo><msqrt><mrow><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>d</mi></msub><mo>⊗</mo><mi>h</mi><msub><mrow></mrow><mi>x</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mrow><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>d</mi></msub><mo>⊗</mo><mi>h</mi><msub><mrow></mrow><mi>y</mi></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msqrt><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">其中, 符号⨂表示卷积运算, <i>m</i><sub><i>r</i></sub>表示参考图像梯度图, <i>m</i><sub><i>d</i></sub>表示失真图像梯度图, 得到对应的梯度幅度相似度图:</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mi>S</mi><mi>S</mi><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mn>2</mn><mi>g</mi><msub><mrow></mrow><mi>r</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mi>g</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>4</mn></msub></mrow><mrow><mi>g</mi><msubsup><mrow></mrow><mi>r</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>g</mi><msubsup><mrow></mrow><mi>d</mi><mn>2</mn></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>+</mo><mi>c</mi><msub><mrow></mrow><mn>4</mn></msub></mrow></mfrac><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">其中<i>c</i><sub>4</sub>为一个常量.GSS图使用逐像素计算, 梯度幅度的计算采取局域分块的方式.当<i>g</i><sub><i>r</i></sub> (<i>i</i>) 和<i>g</i><sub><i>d</i></sub> (<i>i</i>) 相同时, <i>GSS</i> (<i>i</i>) 达到最大值1.</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>1.5 质量评价模型</b></h4>
                <div class="p1">
                    <p id="115">在得到图像的LCS、VSS、PCSS和GSS图后, 分别提取4幅图的均值<i>m</i><sub><i>i</i></sub>和标准方差<i>sd</i><sub><i>i</i></sub> (<i>i</i>=1, 2, 3, 4) 形成一个8维的特征向量:</p>
                </div>
                <div class="p1">
                    <p id="116"><i>χ</i>=[<i>m</i><sub>1</sub>, <i>sd</i><sub>1</sub>, <i>m</i><sub>2</sub>, <i>sd</i><sub>2</sub>, <i>m</i><sub>3</sub>, <i>sd</i><sub>3</sub>, <i>m</i><sub>4</sub>, <i>sd</i><sub>4</sub>], </p>
                </div>
                <div class="p1">
                    <p id="117">图像质量可看作该特征向量的函数, 定义为<i>Q</i>=<i>f</i> (<i>x</i>) , 其中, <i>f</i> 为待学习的模型, 即关于特征和图像质量的映射函数.为了估计函数<i>f</i>, 可以使用深度学习的方法<citation id="194" type="reference"><link href="51" rel="bibliography" /><link href="53" rel="bibliography" /><sup>[<a class="sup">25</a>,<a class="sup">26</a>]</sup></citation> , 但考虑到SVR<citation id="193" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation> 在解决高维问题方面的良好性能, 本文采用SVR学习映射关系, 利用径向基作为核函数.</p>
                </div>
                <h3 id="118" name="118" class="anchor-tag">2 实验及结果分析</h3>
                <h4 class="anchor-tag" id="119" name="119"><b>2.1 标准图像库及评价标准</b></h4>
                <div class="p1">
                    <p id="120">本文在4种标准图像数据库——LIVE (http://live.ece.utexas.edu/research/quality) 、CSIQ<citation id="195" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、TID2008 (https://videocharity.com/PDF/mre2009tid.pdf) 和TID2013<citation id="196" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation> 上进行实验, 验证本文方法的有效性.数据库的相关信息如表1所示, 其中MOS为平均主观分数 (Subjective Mean Opinion Scores) , DMOS为差异平均主观分数 (Difference Mean Opionion Scores, DMOS) .</p>
                </div>
                <div class="area_img" id="122">
                    <p class="img_tit">表1 图像数据库相关信息 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Relevant information of image databases</p>
                    <p class="img_note"></p>
                    <table id="122" border="1"><tr><td>名称</td><td>参考图像个数</td><td>失真图像个数</td><td>失真类型</td><td>观察者个数</td><td>图像类型</td><td>图像格式</td><td>主观分数值范围</td></tr><tr><td>LIVE</td><td>29</td><td>779</td><td>5</td><td>161</td><td>彩色</td><td>bmp</td><td>DMOS:[0～100]</td></tr><tr><td>CSIQ</td><td>30</td><td>866</td><td>6</td><td>35</td><td>彩色</td><td>png</td><td>DMOS:[0～1]</td></tr><tr><td><br />TID2008</td><td>25</td><td>1700</td><td>17</td><td>838</td><td>彩色</td><td>bmp</td><td>MOS:[0～9]</td></tr><tr><td><br />TID2013</td><td>25</td><td>3000</td><td>24</td><td>971</td><td>彩色</td><td>bmp</td><td>MOS:[0～9]</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="123">常用的评价指标如下: 斯皮尔曼相关系数 (<i>Spearman</i>′<i>s Rank Correlation Coefficient</i>, <i>SROCC</i>) 、肯德尔相关系数 (<i>Kendall</i>′<i>s Rank Correlation Coefficient</i>, <i>KROCC</i>) 、皮尔森相关系数 (<i>Pearson</i>′<i>s Correlation Coefficient</i>, <i>PLCC</i>) 和均方根误差 (<i>Root MSE</i>, <i>RMSE</i>) .</p>
                </div>
                <div class="p1">
                    <p id="124"><i>SROCC</i>和<i>KROCC</i>评价本文方法在单调方面的性能, <i>PLCC</i>衡量精确性, <i>RMSE</i>为误差评价子.前3个指标的值越接近1越佳, <i>RMSE</i>值越低则评价的准确率越高.</p>
                </div>
                <div class="p1">
                    <p id="125">为使预测的图像质量分数和已有的主观分数在同一量级, 使用前需对后两个指标做如下处理<citation id="197" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>:</p>
                </div>
                <div class="area_img" id="202">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201907011_20200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="129">其中</p>
                </div>
                <div class="p1">
                    <p id="130">α<sub>i</sub> (i=1, 2, 3, 4, 5) </p>
                </div>
                <div class="p1">
                    <p id="131">为待拟合的参数, x 为原始的图像质量预测值, p (x) 为处理后的值.</p>
                </div>
                <h4 class="anchor-tag" id="132" name="132"><b>2.2 与典型算法的统计对比分析</b></h4>
                <div class="p1">
                    <p id="133">为了说明本文方法的有效性, 采用代表性的9种FR-IQA作为对比, 具体如下:SSIM、IW-SSIM、VIF、MAD、FSIM、GSM、GMSD、VSI和MCSD.FSIM和VSI针对彩色图像设计, 其它方法针对灰度图像.本文方法与代表性方法在4个数据库上的结果如表2所示, 表现最佳的3种方法结果使用黑体数字表示.</p>
                </div>
                <div class="area_img" id="134">
                    <p class="img_tit">表2 10种方法在4个图像数据库上的性能对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Performance comparison of 10 methods on 4 image databases</p>
                    <p class="img_note"></p>
                    <table id="134" border="1"><tr><td>数据库</td><td>评价指标</td><td>SSIM</td><td>IW-SSIM</td><td>VIF</td><td>MAD</td><td>FSIM</td><td>GMSD</td><td>VSI</td><td>MCSD</td><td>本文方法</td></tr><tr><td>LIVE</td><td>SROCC<br />KROCC<br />PLCC<br />RMSE</td><td>0.9479<br />0.7963<br />0.9449<br />8.9455</td><td>0.9567<br />0.8175<br />0.9522<br />8.3473</td><td>0.9636<br />0.8282<br />0.9604<br />7.6137</td><td><b>0.9672<br />0.8427<br />0.9688<br />6.7672</b></td><td>0.9634<br />0.8337<br />0.9597<br />7.6780</td><td>0.9603<br />0.8268<br />0.9603<br />7.6214</td><td>0.9524<br />0.8058<br />0.9482<br />8.6816</td><td><b>0.9668<br />0.8407<br />0.9675<br />6.9079</b></td><td><b>0.9757<br />0.8680<br />0.9765<br />5.8243</b></td></tr><tr><td>CSIQ</td><td>SROCC<br />KROCC<br />PLCC<br />RMSE</td><td>0.8756<br />0.6907<br />0.8613<br />0.1334</td><td>0.9213<br />0.7529<br />0.9144<br />0.1063</td><td>0.9195<br />0.7537<br />0.9277<br />0.0980</td><td>0.9466<br />0.7970<br />0.9502<br />0.0818</td><td>0.9242<br />0.7690<br />0.9120<br />0.1077</td><td><b>0.9570<br />0.8122<br />0.9541<br />0.0786</b></td><td>0.9423<br />0.7857<br />0.9279<br />0.0979</td><td><b>0.9592<br />0.8171<br />0.9560<br />0.0770</b></td><td><b>0.9624<br />0.8311<br />0.9667<br />0.0670</b></td></tr><tr><td>TID2008</td><td>SROCC<br />KROCC<br />PLCC<br />RMSE</td><td>0.7749<br />0.5768<br />0.7732<br />0.8511</td><td>0.8559<br />0.6636<br />0.8579<br />0.6895</td><td>0.7491<br />0.5861<br />0.8084<br />0.7899</td><td>0.8340<br />0.6445<br />0.8308<br />0.7468</td><td>0.8804<br />0.6975<br />0.8738<br />0.6527</td><td>0.8907<br />0.7092<br /><b>0.8788</b><br />0.6404</td><td><b>0.8979<br />0.7123</b><br />0.8762<br /><b>0.6466</b></td><td><b>0.8911<br />0.7133<br />0.8844<br />0.6263</b></td><td><b>0.9097<br />0.7400<br />0.9156<br />0.5389</b></td></tr><tr><td>TID2013</td><td>SROCC<br />KROCC<br />PLCC<br />RMSE</td><td>0.7417<br />0.5588<br />0.7895<br />0.7608</td><td>0.7779<br />0.5977<br />0.8319<br />0.6880</td><td>0.6769<br />0.5147<br />0.7720<br />0.7880</td><td>0.7807<br />0.6035<br />0.8267<br />0.6975</td><td>0.8015<br />0.6289<br /><b>0.8589<br />0.6349</b></td><td>0.8044<br />0.6339<br />0.8553<br />0.6423</td><td><b>0.8965<br />0.7183<br />0.9000<br />0.5404</b></td><td><b>0.8089<br />0.6385</b><br />0.8565<br />0.6399</td><td><b>0.8135<br />0.6484<br />0.8751<br />0.5971</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="135">由表2可见, 本文方法在4个数据库上取得较好的预测性能.在<i>LIVE</i>、<i>CSIQ</i>、<i>TID</i>2008图像库上, 本文方法均取得最优性能, 而其它算法通常只在某一数据库上性能较优, 例如:<i>MAD</i>在<i>LIVE</i>数据库上性能较优, 但在其余数据库上性能不佳.<i>VSI</i>在彩色 图 像 数 据 库 (<i>TID</i>2008、<i>TID</i>2013数据 库) 上 性 能 较优, 但在<i>LIVE</i>、<i>CSIQ</i>数据库上表现一般.由于本文方法未特别考虑彩色信息, 针对彩色失真类型较多的数据库, 如<i>TID</i>2013数据库, 性能劣于<i>VSI</i>.</p>
                </div>
                <div class="p1">
                    <p id="136">根据文献<citation id="198" type="reference">[<a class="sup">8</a>]</citation>的建议和计算方法, 采用加权方式获得在4个图像库上的综合性能.相关结果如表3所示, 表中最佳指标值使用黑体数字标记.</p>
                </div>
                <div class="area_img" id="137">
                    <p class="img_tit">表3 10种方法在4个数据库上的综合性能对比 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Performance comparison of 10 methods on 4 image databases</p>
                    <p class="img_note"></p>
                    <table id="137" border="1"><tr><td>评价指标</td><td>SSIM</td><td>IW-SSIM</td><td>VIF</td><td>MAD</td><td>FSIM</td><td>GMSD</td><td>VSI</td><td>MCSD</td><td>本文方法</td></tr><tr><td>SROCC</td><td>0.7942</td><td>0.8403</td><td>0.7646</td><td>0.8405</td><td>0.8593</td><td>0.8675</td><td><b>0.9100</b></td><td>0.8708</td><td>0.8795</td></tr><tr><td>KROCC</td><td>0.6108</td><td>0.6635</td><td>0.6049</td><td>0.6703</td><td>0.6915</td><td>0.7021</td><td><b>0.7366</b></td><td>0.7077</td><td>0.7248</td></tr><tr><td><br />PLCC</td><td>0.8140</td><td>0.8649</td><td>0.8261</td><td>0.8621</td><td>0.8825</td><td>0.8880</td><td>0.9033</td><td>0.8912</td><td><b>0.9109</b></td></tr><tr><td><br />RMSE</td><td>1.7042</td><td>1.5494</td><td>1.5324</td><td>1.3719</td><td>1.4324</td><td>1.4217</td><td>1.5080</td><td>1.3290</td><td><b>1.1509</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="138">由表3可看出, 在<i>SROCC</i>和<i>KROCC</i>两项指标上, 本文方法差于<i>VSI</i>, 而在<i>PLCC</i>和<i>RMSE</i>上优于其它算法.由于<i>VSI</i>在设计时主要针对彩色图像, 本文方法主要针对灰度图像, 而<i>TID</i>2013图像库中有多个彩色失真类型, 这导致本文方法在4个数据库上的综合性能不占绝对优势, 相比其它算法, 本文方法的预测一致性较好.</p>
                </div>
                <h4 class="anchor-tag" id="139" name="139"><b>2.3 独立性实验</b></h4>
                <div class="p1">
                    <p id="140">由于机器学习的评价方法具有一定数据依赖性, 为了验证其依赖程度, 相关实验如下.</p>
                </div>
                <div class="p1">
                    <p id="141">1) 训练集为<i>LIVE</i>图像库, 测试集分别为<i>CSIQ</i>、<i>TID</i>2008、<i>TID</i>2013图像库.</p>
                </div>
                <div class="p1">
                    <p id="142">2) 训练集为<i>TID</i>2013图像库, 测试集分别为<i>LIVE</i>、<i>CSIQ</i>、<i>TID</i>2008图像库.</p>
                </div>
                <div class="p1">
                    <p id="143">实验结果如表4所示.</p>
                </div>
                <div class="area_img" id="144">
                    <p class="img_tit">表4 本文方法的交叉验证性能 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Cross-validation performance of the proposed method</p>
                    <p class="img_note"></p>
                    <table id="144" border="1"><tr><td rowspan="2"><br />评价<br />指标</td><td colspan="3"><br />LIVE</td><td colspan="3"><br />TID2013</td></tr><tr><td><br />CSIQ</td><td>TID2008</td><td>TID2013</td><td><br />LIVE</td><td>CSIQ</td><td>TID2008</td></tr><tr><td>SROCC</td><td>0.9575</td><td>0.8910</td><td>0.8130</td><td>0.9672</td><td>0.9562</td><td>0.9081</td></tr><tr><td>KROCC</td><td>0.8150</td><td>0.7071</td><td>0.6441</td><td>0.8394</td><td>0.8126</td><td>0.7349</td></tr><tr><td><br />PLCC</td><td>0.9584</td><td>0.8878</td><td>0.8704</td><td>0.9619</td><td>0.9578</td><td>0.9139</td></tr><tr><td><br />RMSE</td><td>0.0749</td><td>0.6175</td><td>0.6104</td><td>7.4729</td><td>0.0754</td><td>0.5448</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="145">由表4可见, 本文方法的交叉验证性能较优, 性能与在各数据库单独训练测试的结果相当, 表明数据独立性较优, 即不依赖具体数据库.</p>
                </div>
                <h4 class="anchor-tag" id="146" name="146"><b>2.4 不同回归方法预测性能对比</b></h4>
                <div class="p1">
                    <p id="147">为了进一步验证提取特征的鲁棒性, 对比常见的回归方法——支持向量机回归 (<i>SVR</i>) 、随机森林 (<i>Random Forest</i>, <i>RF</i>) <citation id="199" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>和广义回归神经网络 (<i>Gen</i>-<i>eral Regression Neural Network</i>, <i>GRNN</i>) <citation id="200" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>的预测性能.<i>SVR</i>高效处理高维特征向量的能力使其广泛运用于图像质量评价当中<citation id="201" type="reference"><link href="49" rel="bibliography" /><link href="57" rel="bibliography" /><sup>[<a class="sup">24</a>,<a class="sup">28</a>]</sup></citation> .随机森林综合每棵树的预测结果, 对于分类采取少数服从多数的原则, 对回归取其平均值.<i>RF</i> 具有良好的避免过拟合性的性能.广义回归神经网络具有随着样本数量的增加而逐渐收敛于最优回归平面的优良性能.</p>
                </div>
                <div class="p1">
                    <p id="148">表5为在<i>LIVE</i>数据库上采用3种回归方法时的预测性能对比, 最佳结果使用黑体数字表示.</p>
                </div>
                <div class="area_img" id="149">
                    <p class="img_tit">表5 不同回归方法的预测性能 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Prediction performance of different regression methods</p>
                    <p class="img_note"></p>
                    <table id="149" border="1"><tr><td><br />评价指标</td><td>SVR</td><td>RF</td><td>GRNN</td></tr><tr><td><br />SROCC</td><td><b>0.9757</b></td><td>0.9730</td><td>0.9715</td></tr><tr><td><br />KROCC</td><td><b>0.8680</b></td><td>0.8594</td><td>0.8540</td></tr><tr><td><br />PLCC</td><td><b>0.9765</b></td><td>0.9738</td><td>0.9710</td></tr><tr><td><br />RMSE</td><td><b>5.8243</b></td><td>6.2250</td><td>6.5491</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="150">由表5可见, 3种回归方法在提取特征上均取得不错性能, 说明本文方法提取的特征具有较好的鲁棒性, 同时<i>SVR</i>具有三者中的最优预测性能, 说明本文采取<i>SVR</i>预测性能的正确性.</p>
                </div>
                <h4 class="anchor-tag" id="151" name="151"><b>2.5 散点图</b></h4>
                <div class="p1">
                    <p id="152">一个好的评价模型应针对不同类型的失真图像具有较好的一致性, 本节验证本文方法在不同失真类型上的预测一致性.考虑篇幅问题, 主要针对<i>LIVE</i>数据库上的失真类型进行实验.通过式 (1) 拟合得到曲线, 结果如图2所示.</p>
                </div>
                <div class="area_img" id="203">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907011_20300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文方法在LIVE数据库上的预测一致性散点图" src="Detail/GetImg?filename=images/MSSB201907011_20300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文方法在LIVE数据库上的预测一致性散点图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907011_20300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Scatter plots of prediction consistency of the proposed method on LIVE Database</p>

                </div>
                <div class="area_img" id="203">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201907011_20301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文方法在LIVE数据库上的预测一致性散点图" src="Detail/GetImg?filename=images/MSSB201907011_20301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文方法在LIVE数据库上的预测一致性散点图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201907011_20301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Scatter plots of prediction consistency of the proposed method on LIVE Database</p>

                </div>
                <div class="p1">
                    <p id="167"><i>LIVE</i>数据库共有779幅失真图像, 含5种失真类型, 选取618幅图像作为训练集, 161幅 (其中<i>JPEG</i>为35幅, <i>JPEG</i>2000为36幅, 剩下失真图像各30幅) 作为测试集.</p>
                </div>
                <div class="p1">
                    <p id="168">从图2可看出, 本文方法在各失真类型和所有失真上具有较好的预测一致性, 表现为散点图具有较好的紧凑性和线性.故本文方法具有较优的预测性能.</p>
                </div>
                <div class="p1">
                    <p id="169">本节分别从预测的主观一致性、数据库独立性、不同回归方法对比和预测一致性的散点图等方面进行详细实验, 结果表明本文方法在上述方面具有较优的综合性能.</p>
                </div>
                <div class="p1">
                    <p id="170">同时, 本文方法在一定程度上克服人为不好选取池化策略和特征的问题.综上所述, 本文方法具有较优的鲁棒性和独立性, 能较好应用于实际场景和图像处理系统.</p>
                </div>
                <h3 id="171" name="171" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="172">为了克服选取何种特征和采用何种池化策略这一难题, 本文提出特征融合的图像质量评价方法, 采用参考图像和失真图像的4个底层特征 (相位一致性、梯度、视觉显著性、对比度) 相似度图的统计特征作为图像特征, 利用支持向量回归方法学习方法和预测图像质量.在4个图像库上较系统地验证本文方法在主观判断的一致性、数据库独立性和鲁棒性等方面的性能, 结果表明, 相比主流算法, 本文方法具有较好的预测性能.但是, 由于方法未考虑颜色信息, 因此对具有彩色失真的图像评价效果不佳, 如何融入颜色信息以设计评价算法将是今后改进的重点.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modern Image Quality Assessment">

                                <b>[1]</b> WANG Z, BOVIK A C.Modern Image Quality Assessment.San Rafael, USA:Morgan &amp; Claypool, 2006.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Why is image qualityassessment sodifficult?">

                                <b>[2]</b> WANG Z, BOVIK A C, LU L G.Why Is Image Quality Assessment so Difficult // Proc of the IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 2002, IV:3313-3316.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image quality assessment: from error visibility to structural similarity">

                                <b>[3]</b> WANG Z, BOVIK A C, SHEIKH H R, <i>et al</i>.Image Quality Assessment:From Error Visibility to Structural Similarity.IEEE Transactions on Image Processing, 2004, 13 (4) :600-612.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-scalestructural similarity for image quality assessment">

                                <b>[4]</b> WANG Z, SIMONCELLI E P, BOVIK A C.Multiscale Structural Similarity for Image Quality Assessment // Proc of the IEEE Confe-rence Record of the 37th Asilomar Conference on Signals, Systems and Computers.Washington, USA:IEEE, 2003, II:9-12.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gradient-based structural similarity for image quality assessment">

                                <b>[5]</b> CHEN G H, YANG C L, XIE S L, <i>et al</i>.Gradient-Based Structural Similarity for Image Quality Assessment // Proc of the International Conference on Image Processing.Washington, USA:IEEE, 2006:2929-2932.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Translation insensitiveimage similarity in complex wavelet domain">

                                <b>[6]</b> WANG Z, SIMONCELLI E P.Translation Insensitive Image Similarity in Complex Wavelet Domain // Proc of the IEEE International Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 2005, II:573-576.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Three-component weighted structural similarity index&amp;quot;">

                                <b>[7]</b> LI C F, BOVIK A C.Three-Component Weighted Structural Similarity Index.Proc of SPIE, 2009, 7242.DOI:10.1117/12.811821.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Information Content Weighting for Perceptual Image Quality Assessment">

                                <b>[8]</b> WANG Z, LI Q.Information Content Weighting for Perceptual Image Quality Assessment.IEEE Transactions on Image Process, 2011, 20 (5) :1185-1198.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image quality assessment based on a degradation model">

                                <b>[9]</b> DAMERA-VENKATA N, KITE T D, GEISLER W S, <i>et al</i>.Image Quality Assessment Based on a Degradation Model.IEEE Transactions on Image Processing, 2000, 9 (4) :636-650.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VSNR: A Wavelet-Based Visual Signal-to-Noise Ratio for Natural Images">

                                <b>[10]</b> CHANDLER D M, HEMAMI S S.VSNR:A Wavelet-Based Vi-sual Signal-to-Noise Ratio for Natural Images.IEEE Transactions on Image Processing, 2007, 16 (9) :2284-2298.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An information fidelity criterion for image quality assessment using natural scene statistics">

                                <b>[11]</b> SHEIKH H R, BOVIK A C, VECIANA D.An Information Fidelity Criterion for Image Quality Assessment Using Natural Scene Statistics.IEEE Transactions on Image Process, 2005, 14 (12) :2117-2128.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image information and visual quality">

                                <b>[12]</b> SHEIKH H R, BOVIK A C.Image Information and Visual Quality.IEEE Transactions on Image Process, 2006, 15 (2) :430-444.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Most apparent distortion: full-reference image quality assessment and the role of strategy">

                                <b>[13]</b> LARSON E C, CHANDLER D M.Most Apparent Distortion:Full-Reference Image Quality Assessment and the Role of Strategy.Journal of Electronic Imaging, 2010, 19 (1) .DOI:10.1117/1.3267105.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=FSIM: A Feature Similarity Index for Image Quality Assessment">

                                <b>[14]</b> ZHANG L, ZHANG L, MOU X Q, <i>et al</i>.FSIM:A Feature Similarity Index for Image Quality Assessment.IEEE Transactions on Image Processing, 2011, 20 (8) :2378-2386.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=VSI:A Visual Saliency Induced Index for Perceptual Image Quality Assessment">

                                <b>[15]</b> ZHANG L, SHEN Y, LI H Y.VSI:A Visual Saliency-Induced Index for Perceptual Image Quality Assessment.IEEE Transactions on Image Processing, 2014, 23 (10) :4270-4281.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Quality Assessment Based on Gradient Similarity">

                                <b>[16]</b> LIU A M, LIN W S, NARWARIA M.Image Quality Assessment Based on Gradient Similarity.IEEE Transactions on Image Proce-ssing, 2012, 21 (4) :1500-1512.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gradient magnitude similarity deviation:A highly efficient perceptual image quality index">

                                <b>[17]</b> XUE W F, ZHANG L, MOU X Q, <i>et al</i>.Gradient Magnitude Si-milarity Deviation:A Highly Efficient Perceptual Image Quality Index.IEEE Transactions on Image Processing, 2014, 23 (2) :684-695.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multiscale contrast similarity deviation:An effective and efficient index for perceptual image quality assessment">

                                <b>[18]</b> WANG T H, ZHANG L, JIA H Z, <i>et al</i>.Multiscale Contrast Similarity Deviation:An Effective and Efficient Index for Perceptual Image Quality Assessment.Signal Processing:Image Communication, 2016, 45:1-9.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Color image database TID2013:peculiarities and preliminary results,&amp;quot;">

                                <b>[19]</b> PONOMARENKO N, IEREMEIEV O, LUKIN V, <i>et al</i>.Color Image Database TID2013:Peculiarities and Preliminary Results // Proc of the European Workshop on Visual Information Processing.Washington, USA:IEEE, 2013:106-111.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A visual discrimination model for imaging system design and evaluation">

                                <b>[20]</b> JEFFREY L.A Visual Discrimination Model for Imaging System Design and Evaluation // PELI E, ed.Visual Models for Target Detection and Recognition.Singapore, Singapore:World Scientific, 1995:207-220.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A perceptually tuned sub-band image coder with image dependent quantization and post-quantization data compression">

                                <b>[21]</b> SAFRANEK R J, JOHNSTON J D.A Perceptually Tuned Sub-band Image Coder with Imaging Dependent Quantization and Post-Quantization Data Compression // Proc of the IEEE Conference on Acoustics, Speech, and Signal Processing.Washington, USA:IEEE, 1989:1945-1948.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Saliency detection:a spectral residual approach">

                                <b>[22]</b> HOU X D, ZHANG L Q.Saliency Detection:A Spectral Residual Approach // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington, USA:IEEE, 2007.DOI:10.1109/CVPR.2007.383267.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image features from phase congruency">

                                <b>[23]</b> KOVESI P.Image Features from Phase Congruency.Journal of Computer Vision, 1999, 1 (3) :1-26.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201406006&amp;v=MDg5MTR6cXFCdEdGckNVUkxPZVplUm5GeXpoVkwzQVB5cmZiTEc0SDlYTXFZOUZZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> 贾惠珍, 孙权森, 王同罕.结合感知特征和自然场景统计的无参考图像质量评价.中国图象图形学报, 2014, 19 (6) :859-867. (JIA H Z, SUN Q S, WANG T H.Blind Image Quality Assessment Based on Perceptual Features and Natural Scene Statistics.Journal of Image and Graphics, 2014, 19 (6) :859-867.) 
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201804006&amp;v=MTE5MTZxQnRHRnJDVVJMT2VaZVJuRnl6aFZMM0FLRDdZYkxHNEg5bk1xNDlGWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> 吴帅, 徐勇, 赵东宁.基于深度卷积网络的目标检测综述.模式识别与人工智能, 2018, 31 (4) :335-346. (WU S, XU Y, ZHAO D N.Survey of Object Detection Based on Deep Convolutional Network.Pattern Recognition and Artificial Intelligence, 2018, 31 (4) :335-346.) 
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Visual Saliency on Stere-oscopic Images">

                                <b>[26]</b> NGUYEN A, KIM J, OH H, <i>et al</i>.Deep Visual Saliency on Stere-oscopic Images.IEEE Transactions on Image Processing, 2019, 28 (4) :1939-1953.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Support Vector Regression">

                                <b>[27]</b> BASAK D, PAL S, PATRANABIS D C.Support Vector Regression.Neural Information Processing, 2007, 11 (10) :203-224.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Effective General-Purpose NR-IQA Model Using Natural Scene Statistics (NSS) of the Luminance Relative Order">

                                <b>[28]</b> WANG T H, ZHANG L, JIA H Z.An Effective General-Purpose NR-IQA Model Using Natural Scene Statistics (NSS) of the Luminance Relative Order.Signal Processing (Image Communication) , 2019, 71:100-109.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_29" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDMyNjVqN0Jhck80SHRITnJJdEZadXdPWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ0hsVjd2UElsWT1O&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[29]</b> BREIMAN L.Random Forests.Machine Learning, 2001, 45 (1) :5-32.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_30" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300070463&amp;v=MjQyMjhDSG82b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZvVGFCbz1OaWZPZmJLN0h0RE9ySTlGWk93UA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[30]</b> TOMANDL D, SCHOBER A.A Modified General Regression Neural Network (MGRNN) with New, Efficient Training Algorithms as a Robust ′Black Box′-Tool for Data Analysis.Neural Networks, 2001, 14 (8) :1023-1034.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201907011" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201907011&amp;v=MDI5Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpoVkwzQktEN1liTEc0SDlqTXFJOUVaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
