<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131448545498750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201905005%26RESULT%3d1%26SIGN%3d%252f1QnE0CjX%252fMc1eXKNPBT9PCnUKU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201905005&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201905005&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201905005&amp;v=MTA5NzJGeXpnVmIzUEtEN1liTEc0SDlqTXFvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#59" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="&lt;b&gt;1.1 谱聚类&lt;/b&gt;"><b>1.1 谱聚类</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;1.2 Nystr&#246;m&lt;/b&gt;&lt;b&gt;方法&lt;/b&gt;"><b>1.2 Nyström</b><b>方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#116" data-title="2 基于加权集成Nystr&#246;m采样的谱聚类算法 ">2 基于加权集成Nyström采样的谱聚类算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#117" data-title="&lt;b&gt;2.1 加权&lt;/b&gt;&lt;b&gt;Nystr&#246;m&lt;/b&gt;&lt;b&gt;方法&lt;/b&gt;"><b>2.1 加权</b><b>Nyström</b><b>方法</b></a></li>
                                                <li><a href="#172" data-title="&lt;b&gt;2.2 基于&lt;/b&gt;&lt;b&gt;Nystr&#246;m&lt;/b&gt;&lt;b&gt;方法聚类的集成框架&lt;/b&gt;"><b>2.2 基于</b><b>Nyström</b><b>方法聚类的集成框架</b></a></li>
                                                <li><a href="#184" data-title="&lt;b&gt;2.3 算法步骤&lt;/b&gt;"><b>2.3 算法步骤</b></a></li>
                                                <li><a href="#200" data-title="&lt;b&gt;2.4 复杂性分析&lt;/b&gt;"><b>2.4 复杂性分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#206" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#235" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#199" data-title="图1 算法整体框架图">图1 算法整体框架图</a></li>
                                                <li><a href="#210" data-title="&lt;b&gt;表1 UCI数据集信息&lt;/b&gt;"><b>表1 UCI数据集信息</b></a></li>
                                                <li><a href="#231" data-title="&lt;b&gt;表2 5种算法在5个数据集上的%error对比&lt;/b&gt;"><b>表2 5种算法在5个数据集上的%error对比</b></a></li>
                                                <li><a href="#232" data-title="&lt;b&gt;表3 5种算法在5个数据集上的CA对比&lt;/b&gt;"><b>表3 5种算法在5个数据集上的CA对比</b></a></li>
                                                <li><a href="#233" data-title="&lt;b&gt;表4 5种算法在5个数据集上的NMI 对比&lt;/b&gt;"><b>表4 5种算法在5个数据集上的NMI 对比</b></a></li>
                                                <li><a href="#234" data-title="&lt;b&gt;表5 5种算法在5个数据集上的运行时间对比&lt;/b&gt;"><b>表5 5种算法在5个数据集上的运行时间对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="5">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     MEI J P, WANG Y T, CHEN L H, &lt;i&gt;et al&lt;/i&gt;.Large Scale Document Categorization with Fuzzy Clustering.IEEE Transactions on Fuzzy Systems, 2017, 25 (5) :1239-1251.</a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_2" title=" 邱云飞, 费博雯, 刘大千.基于概率模型的重叠子空间聚类算法.模式识别与人工智能, 2017, 30 (7) :609-621. (QIU Y F, FEI B W, LIU D Q.Overlapping Subspace Clustering Based on Probabilistic Model.Pattern Recognition and Artificial Intelligence, 2017, 30 (7) :609-621.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201707004&amp;v=MzAxNzJGeXpnVmIzUEtEN1liTEc0SDliTXFJOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         邱云飞, 费博雯, 刘大千.基于概率模型的重叠子空间聚类算法.模式识别与人工智能, 2017, 30 (7) :609-621. (QIU Y F, FEI B W, LIU D Q.Overlapping Subspace Clustering Based on Probabilistic Model.Pattern Recognition and Artificial Intelligence, 2017, 30 (7) :609-621.) 
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_3" title=" 叶茂, 刘文芬.基于快速地标采样的大规模谱聚类算法.电子与信息学报, 2017, 39 (2) :278-284. (YE M, LIU W F.Large Scale Spectral Clustering Based on Fast Landmark Sampling.Journal of Electronics and Information Techno-logy, 2017, 39 (2) :278-284.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201702004&amp;v=MzEzMzNZOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVmIzUElUZlNkckc0SDliTXI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         叶茂, 刘文芬.基于快速地标采样的大规模谱聚类算法.电子与信息学报, 2017, 39 (2) :278-284. (YE M, LIU W F.Large Scale Spectral Clustering Based on Fast Landmark Sampling.Journal of Electronics and Information Techno-logy, 2017, 39 (2) :278-284.) 
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_4" title=" 周林, 平西建, 徐森, 等.基于谱聚类的聚类集成算法.自动化学报, 2012, 38 (8) :1335-1342. (ZHOU L, PING X J, XU S, &lt;i&gt;et al&lt;/i&gt;.Cluster Ensemble Based on Spectral Clustering.Acta Automatica Sinica, 2012, 38 (8) :1335-1342.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201208013&amp;v=MDk1Njg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVmIzUEtDTGZZYkc0SDlQTXA0OUVaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         周林, 平西建, 徐森, 等.基于谱聚类的聚类集成算法.自动化学报, 2012, 38 (8) :1335-1342. (ZHOU L, PING X J, XU S, &lt;i&gt;et al&lt;/i&gt;.Cluster Ensemble Based on Spectral Clustering.Acta Automatica Sinica, 2012, 38 (8) :1335-1342.) 
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_5" title=" 丁世飞, 贾洪杰, 史忠植.基于自适应Nystr&#246;m采样的大数据谱聚类算法.软件学报, 2014, 25 (9) :2037-2049. (DING S F, JIA H J, SHI Z Z.Spectral Clustering Algorithm Based on Adaptive Nystr&#246;m Sampling for Big Data Analysis.Journal of Software, 2014, 25 (9) :2037-2049.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201409012&amp;v=MzI1NDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdWYjNQTnlmVGJMRzRIOVhNcG85RVpvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         丁世飞, 贾洪杰, 史忠植.基于自适应Nystr&#246;m采样的大数据谱聚类算法.软件学报, 2014, 25 (9) :2037-2049. (DING S F, JIA H J, SHI Z Z.Spectral Clustering Algorithm Based on Adaptive Nystr&#246;m Sampling for Big Data Analysis.Journal of Software, 2014, 25 (9) :2037-2049.) 
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     WILLIAMS C K I, SEEGER M.Using the Nystr&#246;m Method to Speed up Kernel Machines // Proc of the 13th International Conference on Neural Information Processing Systems.Cambridge, USA:The MIT Press, 2000:661-667.</a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     FOWLKES C, BELONGIE S, CHUNG F, &lt;i&gt;et al&lt;/i&gt;.Spectral Grouping Using the Nystr&#246;m Method.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (2) :214-225.</a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     WILLIAMS C K I, SEEGER M.The Effect of the Input Density Distribution on Kernel-Based Classifiers // Proc of the 17th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers, 2000:1159-1166.</a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     DRINEAS P, MAHONEY M W.On the Nystr&#246;m Method for Approximating a Gram Matrix for Improved Kernel-Based Learning.Journal of Machine Learning Research, 2005, 6:2153-2175.</a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                     OUIMET M, BENGIO Y.Greedy Spectral Embedding[C/OL].[2018-12-12].http://www.gatsby.ucl.ac.uk/aistats/fullpapers/209.pdf.</a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     ZHANG K, TSANG I W, KWOK J T.Improved Nystr&#246;m Low-Rank Approximation and Error Analysis // Proc of the 25th International Conference on Machine Learning.New York, USA:ACM, 2008:1232-1239.</a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     ZHANG K, KWOK J T.Clustered Nystr&#246;m Method for Large Scale Manifold Learning and Dimension Reduction.IEEE Transactions on Neural Networks, 2010, 21 (10) :1576-1587.</a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     KUMAR S, MOHRI M, TALWALKAR A.Sampling Methods for the Nystr&#246;m Method.Journal of Machine Learning Research, 2012, 13:981-1006.</a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     SHI J B, MALIK J.Normalized Cuts and Image Segmentation.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (8) :888-905.</a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     BOUTSIDIS C, MAHONEY M W, DRINEAS P.An Improved Approximation Algorithm for the Column Subset Selection Problem // Proc of the 20th Annual ACM-SIAM Symposium on Discrete Algorithms.New York, USA:ACM, 2009:968-977.</a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_16" title=" 唐伟, 周志华.基于Bagging的选择性聚类集成.软件学报, 2005, 16 (4) :496-502. (TANG W, ZHOU Z H.Bagging-Based Selective Cluster Ensemble.Journal of Software, 2005, 16 (4) :496-502.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200504002&amp;v=MDUyNjZPZVplUm5GeXpnVmIzUE55ZlRiTEc0SHRUTXE0OUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         唐伟, 周志华.基于Bagging的选择性聚类集成.软件学报, 2005, 16 (4) :496-502. (TANG W, ZHOU Z H.Bagging-Based Selective Cluster Ensemble.Journal of Software, 2005, 16 (4) :496-502.) 
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     FERN X Z, LIN W.Cluster Ensemble Selection.Statistical Analysis and Data Mining, 2008, 1 (3) :128-141.</a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_18" title=" 刘展杰, 陈晓云.局部子空间聚类.自动化学报, 2016, 42 (8) :1238-1247. (LIU Z J, CHEN X Y.Local Subspace Clustering.Acta Automatica Sinica, 2016, 42 (8) :1238-1247.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201608011&amp;v=MDUxNTZWYjNQS0NMZlliRzRIOWZNcDQ5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         刘展杰, 陈晓云.局部子空间聚类.自动化学报, 2016, 42 (8) :1238-1247. (LIU Z J, CHEN X Y.Local Subspace Clustering.Acta Automatica Sinica, 2016, 42 (8) :1238-1247.) 
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_19" title=" 邱云飞, 杨倩, 唐晓亮.基于粒子群优化的软子空间聚类算法.模式识别与人工智能, 2015, 28 (10) :903-912. (QIU Y F, YANG Q, TANG X L.Soft Subspace Clustering Based on Particle Swarm Optimization.Pattern Recognition and Artificial Intelligence, 2015, 28 (10) :903-912.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201510005&amp;v=MDc2MTZWYjNQS0Q3WWJMRzRIOVROcjQ5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         邱云飞, 杨倩, 唐晓亮.基于粒子群优化的软子空间聚类算法.模式识别与人工智能, 2015, 28 (10) :903-912. (QIU Y F, YANG Q, TANG X L.Soft Subspace Clustering Based on Particle Swarm Optimization.Pattern Recognition and Artificial Intelligence, 2015, 28 (10) :903-912.) 
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_20" >
                                        <b>[20]</b>
                                     ZHANG X C, YOU Q Z.Clusterability Analysis and Incremental Sampling for Nystr&#246;m Extension Based Spectral Clustering // Proc of the 11th IEEE International Conference on Data Mining.Wa-shington, USA:IEEE, 2011:942-951.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(05),420-428 DOI:10.16451/j.cnki.issn1003-6059.201905004            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于加权集成Nyström采样的谱聚类算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B1%E4%BA%91%E9%A3%9E&amp;code=07922846&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邱云飞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E7%95%85&amp;code=07933289&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘畅</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%BE%BD%E5%AE%81%E5%B7%A5%E7%A8%8B%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6&amp;code=0034851&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">辽宁工程技术大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对Nyström方法在谱聚类应用中存在聚类效果不稳定、样本代表性较弱的问题, 提出基于加权集成Nyström采样的谱聚类算法.首先利用统计杠杆分数区别数据间的重要程度, 对数据进行加权.然后基于权重采用加权<i>K</i>-means中心点采样, 得到多组采样点.再引入集成框架, 利用集群并行运行Nyström方法构建近似核矩阵.最后利用岭回归方法组合各个近似核矩阵, 产生比标准Nyström方法更准确的低秩近似.在UCI数据集上的测试实验表明, 文中算法取得较理想的聚类结果.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B0%B1%E8%81%9A%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">谱聚类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nystr%C3%B6m%E9%87%87%E6%A0%B7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nyström采样;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BB%9F%E8%AE%A1%E6%9D%A0%E6%9D%86%E5%88%86%E6%95%B0%E5%8A%A0%E6%9D%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">统计杠杆分数加权;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9B%86%E6%88%90Nystr%C3%B6m&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">集成Nyström;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *邱云飞 (通讯作者) , 博士, 教授, 主要研究方向为数据挖掘、智能数据处理.E-mail:7415575@qq.com.;
                                </span>
                                <span>
                                    刘畅, 硕士研究生, 主要研究方向为数据挖掘、智能数据处理.E-mail:2296223024@qq.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-27</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (No.71771111) 资助;</span>
                    </p>
            </div>
                    <h1><b>Spectral Clustering Algorithm Based on Weighted Ensemble Nyström Sampling</b></h1>
                    <h2>
                    <span>QIU Yunfei</span>
                    <span>LIU Chang</span>
            </h2>
                    <h2>
                    <span>School of Software, Liaoning Technical University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Since most Nyström methods have problems of unstable clustering effect and weak representativeness in spectral clustering application, a spectral clustering algorithm based on weighted ensemble Nyström sampling is proposed. Firstly, the statistical leverage score is used to distinguish the importance of data and the data are weighted. Then, based on these weights, the weighted <i>K</i>-means center point sampling is used to obtain multiple sets of sampling points. The integration framework is introduced, and the approximate kernel matrix is constructed using the cluster parallel operation Nyström method. Finally, the approximate kernel is determined by the ridge regression method. The matrices are combined to produce a more accurate low rank approximation than that by standard Nyström method. Experiments on UCI datasets demonstrate that the proposed algorithm achieves better clustering results.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Spectral%20Clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Spectral Clustering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nystr%C3%B6m%20Sampling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nyström Sampling;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Statistical%20Leverage%20Score%20Weighting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Statistical Leverage Score Weighting;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Ensemble%20Nystr%C3%B6m&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Ensemble Nyström;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    QIU Yunfei ( Corresponding author) , Ph. D. , professor. His research interests include data mining and intelligent data processing.;
                                </span>
                                <span>
                                    LIU Chang, master student. Her research interests include data mining and intelligent data processing.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-27</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China (No.71771111);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="56">谱聚类算法已广泛应用于各种领域, 如数据挖掘<citation id="240" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>、信号处理<citation id="237" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>和计算机视觉<citation id="238" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>等.但是, 由于谱聚类算法在计算和存储相似度矩阵以及进行拉普拉斯矩阵特征值分解上的复杂度, 谱聚类算法在大规模数据集上实用性较低<citation id="239" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="57">为了降低谱聚类算法在大规模数据集上的复杂度, Nyström方法抽取原始矩阵列的子集, 生成原始矩阵的低秩近似.Nyström方法现已成功应用于加速核机器学习<citation id="241" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和谱聚类算法<citation id="245" type="reference"><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>中.Drineas等<citation id="242" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>设计基于概率的抽样策略, 由于抽样概率是基于Gram矩阵中所有行/列的范数计算, 因此采样步骤需额外的<i>O</i> (<i>n</i><sup>2</sup>) 时间.Ouimet等<citation id="243" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出基于特征空间几何结构的贪婪采样方案, 时间复杂度为<i>O</i> (<i>m</i><sup>2</sup><i>n</i>) , <i>m</i>为采样点数.Zhang等<citation id="246" type="reference"><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>通过推导Nyström方法的低秩逼近误差, 指出量化误差的目标函数与<i>K</i>-means算法目标函数一致, 提出使用<i>K</i>-means聚类产生的中心点作为采样点, 即<i>k</i>=<i>m</i>.算法使用样本外扩展生成<i>K</i>的一组<i>m</i>个具有代表性的列.Kumar等<citation id="244" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>分析Nyström方法的误差界限, 指出集成Nyström方法比标准的Nyström方法的收敛速度更快.并行化实现可提高算法效率, 但算法采样方式仍为随机采样, 样本点间赋予同等权重.</p>
                </div>
                <div class="p1">
                    <p id="58">基于此种情况, 本文提出基于加权集成Nyström采样的谱聚类算法 (Spectral Clustering Algorithm Based on Weighted Ensemble Nyström Sampling, WENS-SC) .利用统计杠杆分数对数据进行加权, 根据权重调用加权<i>K</i>-means对数据进行采样, 将聚类的中心点作为抽样点, 并行化运用Nyström方法得到近似核矩阵, 并利用混合权重组合近似核矩阵, 产生比标准Nyström方法更准确的低秩近似.在UCI数据集上的测试实验表明, 本文算法取得较理想的聚类结果.</p>
                </div>
                <h3 id="59" name="59" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="60" name="60"><b>1.1 谱聚类</b></h4>
                <div class="p1">
                    <p id="61">谱聚类是建立在谱图理论基础上的方法.谱图理论是将数据点的聚类问题转化成对图的最优划分问题, 有效切割子图聚类数据点.设数据集包含<i>N</i>个点, 构造<i>N</i>×<i>N</i>的相似度矩阵, 谱方法通过对拉普拉斯矩阵进行特征分解以聚类.规范割 (Normalized Cut, NCut) <citation id="247" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>为常用的划分准则, 下面简要介绍谱聚类的基本原理.</p>
                </div>
                <div class="p1">
                    <p id="62">设数据点为图中的顶点<i>V</i>, 顶点间的边为<i>E</i>, 根据数据点间的相似度将<i>E</i>赋以权重值<i>W</i>, 得到一个无向加权图<i>G</i>= (<i>V</i>, <i>E</i>) , 其中<i>V</i>={<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, …, <i>v</i><sub><i>n</i></sub>}表示点集.将图<i>G</i>划分为<i>A</i>、<i>B</i>两个子图 (其中<i>A</i>∪<i>B</i>=<i>V</i>, <i>A</i>∩<i>B</i>=∅) 的代价函数为</p>
                </div>
                <div class="p1">
                    <p id="63" class="code-formula">
                        <mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><mi>u</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>A</mi><mo>, </mo><mi>B</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>i</mi><mo>∈</mo><mi>A</mi></mrow></mstyle><mrow><mspace width="0.25em" /><mi>j</mi><mo>∈</mo><mi>B</mi></mrow></munder></mrow></munder><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mspace width="0.25em" /><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="64">第<i>i</i>个节点的度定义为<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>W</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math></mathml>.集合<i>A</i>、<i>B</i>之间的规范割如下:</p>
                </div>
                <div class="p1">
                    <p id="66"><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>C</mi><mi>u</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>A</mi><mo>, </mo><mi>B</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>c</mi><mi>u</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>A</mi><mo>, </mo><mi>B</mi><mo stretchy="false">) </mo></mrow><mrow><mi>v</mi><mi>o</mi><mi>l</mi><mo stretchy="false"> (</mo><mi>A</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>c</mi><mi>u</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>A</mi><mo>, </mo><mi>B</mi><mo stretchy="false">) </mo></mrow><mrow><mi>v</mi><mi>o</mi><mi>l</mi><mo stretchy="false"> (</mo><mi>B</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="68">其中</p>
                </div>
                <div class="p1">
                    <p id="69" class="code-formula">
                        <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><mi>o</mi><mi>l</mi><mo stretchy="false"> (</mo><mi>A</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>A</mi></mrow></munder><mi>d</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mspace width="0.25em" /><mi>v</mi><mi>o</mi><mi>l</mi><mo stretchy="false"> (</mo><mi>B</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>B</mi></mrow></munder><mi>d</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="70">为集合内所有节点度的总和.</p>
                </div>
                <div class="p1">
                    <p id="71">规范割集准则即最小化NCut目标函数, 根据Rayleigh原理<citation id="248" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 优化问题转化为求解拉普拉斯矩阵<b><i>L</i></b>的第二小特征值<i>λ</i><sub>2</sub>问题.归一化的拉普拉斯矩阵定义为</p>
                </div>
                <div class="p1">
                    <p id="72"><b><i>L</i></b>=<b><i>D</i></b><sup>-1/2</sup> (<b><i>D</i></b>-<b><i>W</i></b>) <b><i>D</i></b><sup>-1/2</sup>=<b><i>I</i></b>-<b><i>D</i></b><sup>-1/2</sup><b><i>WD</i></b><sup>-1/2</sup>  , </p>
                </div>
                <div class="p1">
                    <p id="73">其中, <b><i>D</i></b>为对角矩阵, 元素<i>D</i><sub><i>ii</i></sub>=<i>d</i><sub><i>i</i></sub>, <b><i>L</i></b>为半正定矩阵.</p>
                </div>
                <div class="p1">
                    <p id="74">由于求解特征值和特征向量需花费<i>O</i> (<i>n</i><sup>3</sup>) 的时间复杂度, 因此将谱聚类算法应用于大规模数据问题仍是一个挑战.Fowlkes等<citation id="249" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出Nyström矩阵低秩逼近方法, 通过对数据点进行采样, 使用一部分数据点的相似度矩阵近似逼近全部数据点的相似度矩阵.这种方法以损失一部分精度为代价, 大幅降低计算复杂度, 在大规模实验中获得广泛应用.</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>1.2 Nyström</b><b>方法</b></h4>
                <div class="p1">
                    <p id="76">最初提出Nyström方法是为了解决积分方程的数值处理问题.考虑定义特征核函数的积分方程:</p>
                </div>
                <div class="p1">
                    <p id="77">∫<i>p</i> (<i>y</i>) <i>k</i> (<i>x</i>, <i>y</i>) ϕ<sub><i>i</i></sub> (<i>y</i>) d<i>y</i>=<i>λ</i><sub><i>i</i></sub>ϕ<sub><i>i</i></sub> (<i>x</i>) ,      (1) </p>
                </div>
                <div class="p1">
                    <p id="78">其中, <i>p</i> (·) 为概率密度函数, <i>k</i> (·, ·) 为正定核函数, <i>λ</i><sub>1</sub>≥<i>λ</i><sub>2</sub>≥…≥0为核<i>k</i>的特征值, ϕ<sub>1</sub>, ϕ<sub>2</sub>, …为核<i>k</i>的特征向量.特别地, 给定一组从<i>p</i> (·) 中产生的样本集合{<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>q</i></sub>}, 则积分方程可近似为</p>
                </div>
                <div class="p1">
                    <p id="79"><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mi>q</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>q</mi></munderover><mi>k</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mtext>ϕ</mtext><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>≃</mo><mi>λ</mi><msub><mrow></mrow><mi>i</mi></msub><mtext>ϕ</mtext><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="81">从{<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>q</i></sub>}中选择<i>x</i>作为抽样点, 并进行标准特征值分解</p>
                </div>
                <div class="p1">
                    <p id="82"><b><i>K</i></b><sup> (<i>q</i>) </sup><b><i>U</i></b><sup> (<i>q</i>) </sup>=<b><i>U</i></b><sup> (<i>q</i>) </sup><i>Λ</i><sup> (<i>q</i>) </sup>, </p>
                </div>
                <div class="p1">
                    <p id="83">其中</p>
                </div>
                <div class="p1">
                    <p id="84"><i>K</i><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>=<i>k</i> (<i>x</i><sub><i>i</i></sub>, <i>x</i><sub><i>j</i></sub>) , <i>i</i>=1, 2, …, <i>q</i>, <i>j</i>=1, 2, …, <i>q</i>, </p>
                </div>
                <div class="p1">
                    <p id="86"><b><i>U</i></b><sup> (<i>q</i>) </sup>∈<b>R</b><sup><i>q</i>×<i>q</i></sup>具有正交列, <i>Λ</i><sup> (<i>q</i>) </sup>∈<b>R</b><sup><i>q</i>×<i>q</i></sup>为一个对角矩阵.由<b><i>U</i></b><sup> (<i>q</i>) </sup>和<i>Λ</i><sup> (<i>q</i>) </sup>逼近式 (1) 中特征函数ϕ<sub><i>i</i></sub>和特征值<i>λ</i><sub><i>i</i></sub>, 即</p>
                </div>
                <div class="p1">
                    <p id="87"><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϕ</mtext><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>≃</mo><mroot><mi>q</mi><mrow></mrow></mroot><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mi>j</mi><mi>i</mi></mrow><mrow><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>, </mo><mspace width="0.25em" /><mi>λ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≃</mo><mfrac><mrow><mi>λ</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow><mi>q</mi></mfrac></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="89">上式表明, 使用不同数量的子集<i>q</i>都可在积分方程 (1) 中逼近<i>λ</i><sub><i>i</i></sub>和ϕ<sub><i>i</i></sub>.设数据集<i>Χ</i>={<i>x</i><sub><i>i</i></sub>}<mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow></math></mathml>, 对应核矩阵<b><i>K</i></b>∈<b>R</b><sup><i>n</i>×<i>n</i></sup>, 采用Nyström方法随机采样得到抽样子集<i>Z</i>={<i>z</i><sub><i>i</i></sub>}<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></mrow></math></mathml>, 样本点 (标志点) 个数为<i>m</i>, 则标志点通过</p>
                </div>
                <div class="p1">
                    <p id="92"><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>ϕ</mtext><msub><mrow></mrow><mi>Κ</mi></msub><mo>≃</mo><mroot><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow><mtext> </mtext></mroot><mi mathvariant="bold-italic">E</mi><mtext>ϕ</mtext><msub><mrow></mrow><mi>Ζ</mi></msub><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi>Ζ</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mspace width="0.25em" /><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi>Κ</mi></msub><mo>≃</mo><mfrac><mi>n</mi><mi>m</mi></mfrac><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi>Ζ</mi></msub></mrow></math></mathml>,       (2) </p>
                </div>
                <div class="p1">
                    <p id="94">近似全核矩阵的特征系统<b><i>K</i></b>ϕ<sub><i>K</i></sub>=<i>λ</i><sub><i>K</i></sub>ϕ<sub><i>K</i></sub>, 其中</p>
                </div>
                <div class="p1">
                    <p id="95"><b><i>E</i></b>∈<b>R</b><sup><i>n</i>×<i>m</i></sup>, <i>E</i><sub><i>ij</i></sub>=<i>k</i> (<i>x</i><sub><i>i</i></sub>, <i>z</i><sub><i>j</i></sub>) .</p>
                </div>
                <div class="p1">
                    <p id="96">ϕ<sub><i>Z</i></sub>∈<b>R</b><sup><i>m</i>×<i>m</i></sup>、<i>λ</i><sub><i>Z</i></sub>∈<b>R</b><sup><i>m</i>×<i>m</i></sup>分别为<b><i>A</i></b>∈<b>R</b><sup><i>m</i>×<i>m</i></sup>的特征向量、特征值, <i>A</i><sub><i>ij</i></sub>=<i>k</i> (<i>z</i><sub><i>i</i></sub>, <i>z</i><sub><i>j</i></sub>) .</p>
                </div>
                <div class="p1">
                    <p id="97">由式 (2) , 矩阵<b><i>K</i></b>近似重建为</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><mo>≃</mo><mo stretchy="false"> (</mo><mroot><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow><mrow></mrow></mroot><mi mathvariant="bold-italic">E</mi><mtext>ϕ</mtext><msub><mrow></mrow><mi>Ζ</mi></msub><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi>Ζ</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mfrac><mi>n</mi><mi>m</mi></mfrac><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi>Ζ</mi></msub><mo stretchy="false">) </mo><mrow><mo stretchy="false"> (</mo><mroot><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow><mrow></mrow></mroot><mi mathvariant="bold-italic">E</mi><mtext>ϕ</mtext><msub><mrow></mrow><mi>Ζ</mi></msub><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi>Ζ</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo></mrow><mo>´</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mi mathvariant="bold-italic">E</mi><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><msup><mi mathvariant="bold-italic">E</mi><mo>′</mo></msup><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">上式为Nyström低秩逼近方法的基础<citation id="250" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>.上述过程为公式推演过程, 下面以矩阵补全的角度解释Nyström方法的本质.</p>
                </div>
                <div class="p1">
                    <p id="100">设有<i>n</i>个数据点, 其中有<i>m</i>个随机抽样的样本点, <i>n</i>-<i>m</i>个非样本点, 则相似度矩阵</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Κ</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi></mtd><mtd><mi mathvariant="bold-italic">B</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mtd><mtd><mi mathvariant="bold-italic">C</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo>, </mo><mspace width="0.25em" /><mi mathvariant="bold-italic">E</mi><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">其中, <b><i>A</i></b>∈<b>R</b><sup><i>m</i>×<i>m</i></sup>为样本点间的相似度矩阵, <b><i>A</i></b>的特征分解形式为<b><i>A</i></b>=ϕ<i>λ</i>ϕ<sup>T</sup>, <b><i>B</i></b>∈<b>R</b><sup><i>m</i>× (<i>n</i>-<i>m</i>) </sup>为样本点与非样本点的相似度矩阵, <b><i>C</i></b>∈<b>R</b><sup> (<i>n</i>-<i>m</i>) × (<i>n</i>-<i>m</i>) </sup>为非样本点间的相似度矩阵.由于<i>m</i>≪<i>n</i>, 所以抽样后非样本点的数目通常较大.Nyström近似技术使用<b><i>A</i></b>和<b><i>E</i></b>逼近<b><i>K</i></b>, 即</p>
                </div>
                <div class="p1">
                    <p id="104" class="code-formula">
                        <mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Κ</mi><mo>≃</mo><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><mo>=</mo><mi mathvariant="bold-italic">E</mi><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">E</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">[</mo><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi></mtd><mtd><mi mathvariant="bold-italic">B</mi></mtd></mtr></mtable><mo stretchy="false">]</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi><mtext> </mtext><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd></mtr><mtr><mtd><mrow><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mtext> </mtext><mi mathvariant="bold-italic">A</mi></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mo stretchy="false">[</mo><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi></mtd><mtd><mi mathvariant="bold-italic">B</mi></mtd></mtr></mtable><mo stretchy="false">]</mo><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">A</mi></mtd><mtd><mi mathvariant="bold-italic">B</mi></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Τ</mtext></msup></mtd><mtd><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">B</mi></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mspace width="0.25em" /><mspace width="0.25em" /><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="105">由上式可知, Nyström方法使用<b><i>B</i></b><sup>T</sup><b><i>A</i></b><sup>-1</sup><b><i>B</i></b>逼近<b><i>C</i></b>.Nyström方法通过避免使用非样本点的相似度, 仅使用样本间相似度的特征向量和特征值, 大幅降低算法的空间复杂度和时间复杂度.</p>
                </div>
                <div class="p1">
                    <p id="106">设<mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover></math></mathml>特征值分解为<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><mo>=</mo><mtext>ϕ</mtext><mi mathvariant="bold-italic">λ</mi><mtext>ϕ</mtext><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>, </mo><mi mathvariant="bold-italic">λ</mi></mrow></math></mathml>为对角矩阵, 其对角线元素为<mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover></math></mathml>的特征值, 特征向量为ϕ.Nyström方法通过对样本点间相似度矩阵<b><i>A</i></b>的特征值分解产生近似的ϕ和<i>λ</i>.由<b><i>A</i></b>=ϕ<sub><i>A</i></sub><i>λ</i><sub><i>A</i></sub>ϕ<sup>T</sup><sub><i>A</i></sub>, 可得</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><mo>=</mo><mi mathvariant="bold-italic">E</mi><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">E</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>=</mo><mi mathvariant="bold-italic">E</mi><mtext>ϕ</mtext><msub><mrow></mrow><mi>A</mi></msub><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi>A</mi></msub><mtext>ϕ</mtext><msubsup><mrow></mrow><mi>A</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">E</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo stretchy="false"> (</mo><mroot><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow><mrow></mrow></mroot><mi mathvariant="bold-italic">E</mi><mtext>ϕ</mtext><msub><mrow></mrow><mi>A</mi></msub><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi>A</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mfrac><mi>n</mi><mi>m</mi></mfrac><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mroot><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow><mrow></mrow></mroot><mi mathvariant="bold-italic">E</mi><mtext>ϕ</mtext><msub><mrow></mrow><mi>A</mi></msub><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi>A</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><msup><mo stretchy="false">) </mo><mo>′</mo></msup><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">则Nyström方法生成的原核矩阵<b><i>K</i></b>的近似特征值<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover></math></mathml>和近似特征向量<mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mtext>ϕ</mtext><mo>˜</mo></mover></math></mathml>分别为</p>
                </div>
                <div class="p1">
                    <p id="114"><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>˜</mo></mover><mo>=</mo><mfrac><mi>n</mi><mi>m</mi></mfrac><mi mathvariant="bold-italic">λ</mi><msub><mrow></mrow><mi>A</mi></msub><mspace width="0.25em" /><mo>, </mo><mspace width="0.25em" /><mover accent="true"><mtext>ϕ</mtext><mo>˜</mo></mover><mo>=</mo><mroot><mrow><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow><mtext> </mtext></mroot><mi mathvariant="bold-italic">E</mi><mtext>ϕ</mtext><msub><mrow></mrow><mi>A</mi></msub><mi mathvariant="bold-italic">λ</mi><msubsup><mrow></mrow><mi>A</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>.</p>
                </div>
                <h3 id="116" name="116" class="anchor-tag">2 基于加权集成Nyström采样的谱聚类算法</h3>
                <h4 class="anchor-tag" id="117" name="117"><b>2.1 加权</b><b>Nyström</b><b>方法</b></h4>
                <div class="p1">
                    <p id="118">标准Nyström方法赋予所有选择样本同等的重要性, 导致样本代表性较弱.本文将Nyström方法扩展到加权版本, 根据权重区分不同的数据点.由此积分方程其中的积分变量改变为权值函数, 为了区分标准Nyström积分方程, 使用<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mo>·</mo><mo>^</mo></mover></mrow></math></mathml>表示相应项的加权版本.加权Nyström方法的积分方程近似为</p>
                </div>
                <div class="p1">
                    <p id="120"><mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><mrow><mo>∫</mo><mi>p</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mi>k</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mrow><mover accent="true"><mtext>ϕ</mtext><mo>^</mo></mover></mrow><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mtext>d</mtext><mi>y</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>k</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml><mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mtext>ϕ</mtext><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="123">对选取的采样点<i>X</i>={<i>x</i><sub><i>i</i></sub>}<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></mrow></math></mathml>特征值分解, 有<mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">A</mi></mstyle><mo>︿</mo></mover><mrow><mover accent="true"><mtext>ϕ</mtext><mo>^</mo></mover></mrow><msub><mrow></mrow><mi mathvariant="bold-italic">A</mi></msub></mrow><mo>=</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>A</mi></msub><mrow><mover accent="true"><mtext>ϕ</mtext><mo>^</mo></mover></mrow></mrow><msub><mrow></mrow><mi>A</mi></msub></mrow></math></mathml>, 其中<mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">A</mi></mstyle><mo>︿</mo></mover><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>m</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow></math></mathml>为数据点为<i>m</i>的加权核矩阵, <mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">A</mi></mstyle><mo>︿</mo></mover><mo>=</mo><mi>w</mi><msub><mrow></mrow><mi>j</mi></msub><mi>k</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>, </mo><mrow><mover accent="true"><mtext>ϕ</mtext><mo>^</mo></mover></mrow><msub><mrow></mrow><mi>A</mi></msub></mrow></math></mathml>和<mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">λ</mi><mo>^</mo></mover><msub><mrow></mrow><mi>A</mi></msub></mrow></math></mathml>为相应的特征向量和特征值.通过特征值分解, 在任意点<b><i>x</i></b>处的特征函数为</p>
                </div>
                <div class="p1">
                    <p id="129"><mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover accent="true"><mtext>ϕ</mtext><mo>^</mo></mover></mrow><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>λ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>k</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mtext>ϕ</mtext><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>.</p>
                </div>
                <h4 class="anchor-tag" id="131" name="131"><b>2.1.1 统计杠杆分数加权</b></h4>
                <div class="p1">
                    <p id="132">本文提出数据加权方式, 采用统计杠杆分数对数据进行加权, 在采样步骤前对数据进行一次权重的整体评估, 通过计算数据权重值, 使采样步骤选择的样本点更合理.本文算法在对大规模数据进行聚类时, 利用统计杠杆分数对数据进行加权.由于聚类结果的好坏取决于样本集的选择, 应使样本核矩阵中的采样数据之间的差异较大, 包含更多的数据信息, 更能代表大规模数据中数据的分布情况.</p>
                </div>
                <div class="p1">
                    <p id="133">设数据点个数为<i>n</i>, <b><i>K</i></b>∈<b>R</b><sup><i>n</i>×<i>n</i></sup>为对应的核矩阵, <b><i>K</i></b>为对称半正定 (Symmetric Positive Semidefinite, SPSD) 矩阵, 对<b><i>K</i></b>进行奇异值分解.由于在采集样本点时, 需要计算核矩阵的每个行向量的统计杠杆值, 通过奇异值分解方法提取核矩阵的特征, 特征值越大, 矩阵在其对应的特征向量上的方差越大, 每行包含的信息越多, 采样得到的数据点差异性越大, 更能代表数据分布情况.因此利用奇异值分解得到核矩阵中具有代表性的<i>m</i>个向量作为采样点.分解过程如下:</p>
                </div>
                <div class="p1">
                    <p id="134" class="code-formula">
                        <mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Κ</mi><mo>=</mo><mi mathvariant="bold-italic">U</mi><mi mathvariant="bold-italic">Σ</mi><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Σ</mi><mo>=</mo><mtext>d</mtext><mtext>i</mtext><mtext>a</mtext><mtext>g</mtext><mo stretchy="false"> (</mo><mi>λ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>λ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>λ</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">U</mi><mo>=</mo><mo stretchy="false"> (</mo><mtext>ϕ</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mtext>ϕ</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mtext>ϕ</mtext><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="135">其中, <i>m</i>为聚类个数 (即采样点个数) , 对<b><i>K</i></b>的特征值进行降序排列</p>
                </div>
                <div class="p1">
                    <p id="136"><i>λ</i><sub>1</sub> (<b><i>K</i></b>) ≥<i>λ</i><sub>2</sub> (<b><i>K</i></b>) ≥…≥<i>λ</i><sub><i>m</i></sub> (<b><i>K</i></b>) , </p>
                </div>
                <div class="p1">
                    <p id="137"><i>Σ</i>为<b><i>K</i></b>最大的<i>m</i>个特征值组成的对角矩阵, <b><i>U</i></b>为对应的特征向量矩阵.</p>
                </div>
                <div class="p1">
                    <p id="138"><b><i>U</i></b>可分成如下形式:<mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">U</mi><mo>=</mo><mo stretchy="false">[</mo><mtable><mtr><mtd><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mn>1</mn></msub></mtd><mtd><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mn>2</mn></msub></mtd></mtr></mtable><mo stretchy="false">]</mo></mrow></math></mathml>, 其中, <b><i>U</i></b><sub>1</sub>∈<b>R</b><sup><i>n</i>×<i>k</i></sup>, 包括生成特征空间<b><i>K</i></b>的前<i>k</i>个标准正交列, <b><i>U</i></b><sub>2</sub>∈<b>R</b><sup><i>n</i>× (<i>n</i>-<i>k</i>) </sup>为特征空间<b><i>K</i></b>中剩余的<i>n</i>-<i>k</i>个标准正交列.</p>
                </div>
                <div class="p1">
                    <p id="140">给定核矩阵<b><i>K</i></b>及其秩<i>k</i>, 定义<b><i>K</i></b>的统计杠杆分数为矩阵<b><i>U</i></b><sub>1</sub>∈<b>R</b><sup><i>n</i>×<i>k</i></sup>的行向量的2-范数的平方<citation id="251" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="141"><mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mrow><mo>|</mo><mrow><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mrow><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></msub></mrow><mo>|</mo></mrow></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="143">其中</p>
                </div>
                <div class="area_img" id="144">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="145">定义数据点权值系数如下:</p>
                </div>
                <div class="p1">
                    <p id="146"><mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>l</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>k</mi></mfrac></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="148">利用<b><i>U</i></b><sub>1</sub>计算统计杠杆分数, 提取更丰富有用的信息, 并增加筛选的准确率, 使样本具有强代表性, 提高样本矩阵的整体差异度, 降低矩阵逼近误差.由此构建权重值, 权重值越高, 表明数据点在数据集中的影响程度越高, 采集权重值较高的数据以保证样本核矩阵中数据点的差异性和有效性.</p>
                </div>
                <h4 class="anchor-tag" id="149" name="149"><b>2.1.2 采样方式</b></h4>
                <div class="p1">
                    <p id="150">Nyström方法采样方式为随机采样, 随机采样容易造成数据集中在某一区域, 导致聚类效果不稳定, 不能准确反映整个数据集的结构特性.在Nyström方法中选择界标点<i>z</i><sub><i>k</i></sub>的基本思想是选择的<i>z</i><sub><i>k</i></sub>应使得到的块状恒定核矩阵<mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover></math></mathml>接近原始核矩阵<b><i>K</i></b>, 即最小化它们之间差异的Frobenius范数.</p>
                </div>
                <div class="p1">
                    <p id="152">假设数据集<i>X</i>={<i>x</i><sub><i>i</i></sub>}<mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow></math></mathml>划分为<i>m</i>个不相交的聚类<i>S</i><sub><i>k</i></sub>, 聚类中心为<i>z</i><sub><i>k</i></sub>, <i>k</i>=1, 2, …, <i>m</i>.将每个样本<i>x</i><sub><i>i</i></sub>替换为其对应的簇中心<i>z</i><sub><i>c</i> (<i>i</i>) </sub>, 获得逼近后的核矩阵.若使用静态核</p>
                </div>
                <div class="area_img" id="154">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="155">则有</p>
                </div>
                <div class="area_img" id="156">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="157">其中, <i>R</i>为样本之间的最大成对距离, </p>
                </div>
                <div class="p1">
                    <p id="158" class="code-formula">
                        <mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ξ</mi><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mi>x</mi></munder><mrow><mo>|</mo><mrow><msup><mi>k</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="159"><mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mrow><mi>D</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msup></mrow><mo stretchy="true">¯</mo></mover></mrow></math></mathml>为由不同范数定义的量化误差:</p>
                </div>
                <div class="area_img" id="161">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_16100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="162">由上式可知, <image id="163" type="formula" href="images/MSSB201905005_16300.jpg" display="inline" placement="inline"><alt></alt></image>是由<image id="164" type="formula" href="images/MSSB201905005_16400.jpg" display="inline" placement="inline"><alt></alt></image>决定的, 即每个点到相应簇中心的量化误差.量化误差越小, <image id="165" type="formula" href="images/MSSB201905005_16500.jpg" display="inline" placement="inline"><alt></alt></image>越小.当k=2时, D<sup> (k) </sup>正好为K-<i>means</i>聚类算法的目标函数, 由此可得D<sup> (k) </sup>的局部最小值.</p>
                </div>
                <div class="p1">
                    <p id="166">本文在数据点采样环节使用加权K-<i>means</i>算法, 给定一组聚类{C<sub>1</sub>, C<sub>2</sub>, …, C<sub>m</sub>}, 则加权K-<i>means</i>的目标函数为</p>
                </div>
                <div class="area_img" id="264">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_26400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="169">其中, c<sub>i</sub>为C<sub>i</sub>的中心点, </p>
                </div>
                <div class="p1">
                    <p id="170" class="code-formula">
                        <mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>x</mi></mstyle><mi>w</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>∈</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>w</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="171">将经过加权的数据通过加权K-<i>means</i>算法划分数据集, 并使用得到的聚类中心作为界标点z<sub>k</sub>.加权K-<i>means</i>算法易于实现, 复杂性与样本大小和维度呈线性关系.因此, 基于加权K-<i>means</i>的采样策略适用于解决大规模数据采样问题.</p>
                </div>
                <h4 class="anchor-tag" id="172" name="172"><b>2.2 基于</b><b>Nyström</b><b>方法聚类的集成框架</b></h4>
                <div class="p1">
                    <p id="173">本文采用的集成框架将单个Nyström方法视为一个基聚类成员.由于初始样本点选择的不同, 每次运行Nyström都会产生差异的近似核矩阵, 因此构造有效的集成模型可以较好地利用这一特点, 保证集成的多样性和高效性<citation id="252" type="reference"><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="174">设由固定核函数<b><i>K</i></b>∶<i>X</i>×<i>X</i>→<b>R</b>生成的核矩阵<b><i>K</i></b>, 从<b><i>K</i></b>中通过加权<i>K</i>-means中心点采样得到样本集合<i>S</i>, <i>S</i>分为<i>p</i>个<i>m</i>列的子样本<i>S</i><sub>1</sub>, <i>S</i><sub>2</sub>, …, <i>S</i><sub><i>p</i></sub>.对于每个子样本<i>S</i><sub><i>r</i></sub>, <i>r</i>∈{1, 2, …, <i>p</i>}.定义秩为<i>k</i>的Nyström逼近子核矩阵</p>
                </div>
                <div class="area_img" id="265">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_26500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="177">其中, <b><i>E</i></b><sub><i>r</i></sub>、<b><i>A</i></b><sub><i>r</i></sub>为由<i>S</i><sub><i>r</i></sub>中的列形成的矩阵, <b><i>A</i></b><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>r</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>为<b><i>A</i></b><sub><i>r</i></sub>的逆矩阵.通过<i>p</i>次重复运行Nyström算法, 得到<i>p</i>个<image id="266" type="formula" href="images/MSSB201905005_26600.jpg" display="inline" placement="inline"><alt></alt></image>, 其中<image id="267" type="formula" href="images/MSSB201905005_26700.jpg" display="inline" placement="inline"><alt></alt></image>为<i>m</i>×<i>m</i>的近似子核矩阵.再对每个使用标准Nyström方法生成的<i>p</i>个近似核矩阵进行凸组合.</p>
                </div>
                <div class="p1">
                    <p id="179">由此, 集成Nyström算法生成最终的近似核矩阵<image id="268" type="formula" href="images/MSSB201905005_26800.jpg" display="inline" placement="inline"><alt></alt></image>可表示为</p>
                </div>
                <div class="p1">
                    <p id="180" class="code-formula">
                        <mathml id="180"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mtext>e</mtext><mtext>n</mtext><mtext>s</mtext></mrow></msup><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mi>μ</mi></mstyle><msub><mrow></mrow><mi>r</mi></msub><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>r</mi></msub><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">E</mi><msub><mrow></mrow><mn>1</mn></msub></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd><mo>⋱</mo></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd><mi mathvariant="bold-italic">E</mi><msub><mrow></mrow><mi>p</mi></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mrow><mi>μ</mi><msub><mrow></mrow><mn>1</mn></msub><mi mathvariant="bold-italic">A</mi></mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd><mo>⋱</mo></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd><mrow><mi>μ</mi><msub><mrow></mrow><mi>p</mi></msub><mi mathvariant="bold-italic">A</mi></mrow><msubsup><mrow></mrow><mi>p</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mrow><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mi mathvariant="bold-italic">E</mi><msub><mrow></mrow><mn>1</mn></msub></mtd><mtd></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd><mo>⋱</mo></mtd><mtd></mtd></mtr><mtr><mtd></mtd><mtd></mtd><mtd><mi mathvariant="bold-italic">E</mi><msub><mrow></mrow><mi>p</mi></msub></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="181">其中, <i>μ</i><sub><i>r</i></sub>为混合权重, 本文算法采用基于岭回归方法优化<i>μ</i><sub><i>r</i></sub>.先在<b><i>K</i></b>中取出<i>s</i>列样本集称为验证集<b><i>V</i></b>, 再利用验证样本<b><i>V</i></b>训练混合权重<i>μ</i><sub><i>r</i></sub>, 用于优化岭回归目标函数, 即<image id="182" type="formula" href="images/MSSB201905005_18200.jpg" display="inline" placement="inline"><alt></alt></image>其中, <b><i>K</i></b><sub><i>V</i></sub>为由样本集<b><i>S</i></b>和验证集<b><i>V</i></b>形成的核矩阵, <i>λ</i>&gt;0.</p>
                </div>
                <h4 class="anchor-tag" id="184" name="184"><b>2.3 算法步骤</b></h4>
                <div class="p1">
                    <p id="185">本文提出的基于加权集成Nyström采样的谱聚类算法描述如下.</p>
                </div>
                <div class="p1">
                    <p id="186"><b>算法</b> WENS-SC</p>
                </div>
                <div class="p1">
                    <p id="187"><b>输入</b> 数据集<i>X</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>}, 采样点个数<i>m</i>≪<i>n</i>, 聚类个数k</p>
                </div>
                <div class="p1">
                    <p id="189"><b>输出</b> 聚类产生的<i>k</i>个簇</p>
                </div>
                <div class="p1">
                    <p id="190">step 1 加权.计算统计杠杆分数并将权值赋给对应的数据, 得到加权后的数据集<mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi>X</mi></mstyle><mo>︿</mo></mover><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="192">step 2 采样.通过加权<i>K</i>-means算法, 取算法的中心点作为采样点, 得到样本集<i>S</i>, 并将<i>S</i>分为<i>p</i>个子样本<i>S</i><sub><i>r</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="193">step 3 集成聚类.利用集成框架并行化实现<i>p</i>个Nyström算法, 生成近似核矩阵<image id="269" type="formula" href="images/MSSB201905005_26900.jpg" display="inline" placement="inline"><alt></alt></image>, 再根据岭回归方法确定的混合权重, 组合<i>p</i>个<mathml id="194"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>r</mi></msub></mrow></math></mathml>, 生成最终的近似核矩阵<mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mtext>e</mtext><mtext>n</mtext><mtext>s</mtext></mrow></msup><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="196">step 4 对<mathml id="197"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">Κ</mi><mo>¯</mo></mover><msup><mrow></mrow><mrow><mtext>e</mtext><mtext>n</mtext><mtext>s</mtext></mrow></msup></mrow></math></mathml>运用基于<i>Nystr</i>ö<i>m</i>方法的谱算法, 最后通过K-<i>means</i>将数据点划分为k个类.</p>
                </div>
                <div class="p1">
                    <p id="198">算法整体流程框架如图1所示.</p>
                </div>
                <div class="area_img" id="199">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905005_199.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 算法整体框架图" src="Detail/GetImg?filename=images/MSSB201905005_199.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 算法整体框架图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905005_199.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><i>Fig</i>.1 <i>Overall framework of the proposed algorithm</i></p>

                </div>
                <h4 class="anchor-tag" id="200" name="200"><b>2.4 复杂性分析</b></h4>
                <div class="p1">
                    <p id="201">假设样本大小为n, 标志点数量为m.原始的<i>Nystr</i>ö<i>m</i>方法具有时间复杂度O (m<sup>3</sup>+nm) , 其中第1项用于m×m核矩阵<b><i>K</i></b>的特征值分解, 第2项用于Nyström扩展.对于加权Nyström方法, 需计算核矩阵中每行的统计杠杆分数, 时间复杂度为<i>O</i> (<i>n</i>) , 在采用奇异值分解后, 只需利用<i>k</i>个特征向量的值进行计算, <i>k</i>&lt;<i>n</i>, 时间复杂度为<i>O</i> (<i>k</i>) , 进一步降低本文算法的时间复杂度.执行加权<i>K</i>-means得到标志点需额外的<i>O</i> (<i>mnl</i>) 时间, 其中<i>l</i>为<i>K</i>-means迭代次数.由于本文将<i>l</i>设置为常数 (本文实验中均为5) , 因此加权Nyström方法的总体时间复杂度为</p>
                </div>
                <div class="p1">
                    <p id="202"><i>O</i> (<i>k</i>) +<i>O</i> (<i>mnl</i>) +<i>O</i> (<i>m</i><sup>3</sup>+<i>nm</i>) .</p>
                </div>
                <div class="p1">
                    <p id="203">加权集成Nyström算法的总体时间复杂度为</p>
                </div>
                <div class="p1">
                    <p id="204"><i>O</i> (<i>k</i>) +<i>O</i> (<i>mnl</i>) +<i>O</i> (<i>pm</i><sup>3</sup>+<i>pmkn</i>+<i>C</i> (<i>μ</i>) ) , </p>
                </div>
                <div class="p1">
                    <p id="205">其中, <i>C</i> (<i>μ</i>) 为计算混合权重<i>μ</i>的成本, 用于组合<i>p</i>个Nyström近似, 对于岭回归方法, 为<i>O</i> (<i>p</i><sup>3</sup>+<i>pms</i>) .虽然集成Nyström算法需要比标准Nyström算法多<i>p</i>倍的空间和CPU周期, 但<i>p</i>通常为<i>O</i> (1) 且<i>m</i>通常是<i>n</i>的非常小的百分比, 因此空间要求对大规模应用仍可接受.对于CPU要求, 集成Nyström算法可实现并行化, 因为所有的<i>p</i>个基聚类都可同时计算.对于有<i>p</i>个机器的集群, 算法运行时间复杂度几乎等于具有<i>m</i>个样本的标准Nyström算法的复杂度.</p>
                </div>
                <h3 id="206" name="206" class="anchor-tag">3 实验及结果分析</h3>
                <div class="p1">
                    <p id="207">为了验证本文的加权集成Nyström采样的谱聚类算法 (WENS-SC) 的有效性, 从UCI机器学习数据库中选取5个不同大小的数据集信息, 如表1所示.</p>
                </div>
                <div class="p1">
                    <p id="208">为了更全面地评价WES-SC的性能, 采用低秩逼近误差百分比 (Percent of Low-Rank Approximation Error, %error) <citation id="253" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>、聚类准确率 (Clustering Accuracy, CA) <citation id="254" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、标准化互信息 ( Normalized Mutual Informa-tion, NMI) <citation id="255" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、运行时间作为评价标准.</p>
                </div>
                <div class="area_img" id="210">
                    <p class="img_tit"><b>表1 UCI数据集信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"> Table 1 UCI datasets used in the experiments</p>
                    <p class="img_note"></p>
                    <table id="210" border="1"><tr><td><br />名称</td><td>样本数</td><td>维数</td><td>聚类数</td></tr><tr><td><br />Segment</td><td>2310</td><td>18</td><td>7</td></tr><tr><td><br />Waveform</td><td>5000</td><td>21</td><td>3</td></tr><tr><td><br />Pageblocks</td><td>5473</td><td>10</td><td>5</td></tr><tr><td><br />Pendigits</td><td>10992</td><td>16</td><td>10</td></tr><tr><td><br />Forest Cover Type</td><td>581012</td><td>54</td><td>7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="211">低秩逼近误差 (<i>Low</i>-<i>Rank Approximation Error</i>, ε) 和误差百分比计算如下:</p>
                </div>
                <div class="area_img" id="212">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_21200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="213">其中, <b><i>K</i></b>为<i>n</i>×<i>n</i>的核矩阵, <b><i>EA</i></b><sup>-1</sup><b><i>E</i></b><sup>T</sup>为通过Nyström方法低秩逼近的核矩阵.</p>
                </div>
                <div class="p1">
                    <p id="214"><i>CA</i>计算如下:</p>
                </div>
                <div class="p1">
                    <p id="215" class="code-formula">
                        <mathml id="215"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>A</mi><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>δ</mi></mstyle><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mtext>m</mtext><mtext>a</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>r</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="216">其中, <i>N</i>为样本总数, <i>δ</i> (·, ·) 为函数表示, <i>s</i><sub><i>i</i></sub>为样本数据原始类别, <i>r</i><sub><i>i</i></sub>为聚类后样本数据的类别, map (<i>r</i><sub><i>i</i></sub>) 为映射函数.</p>
                </div>
                <div class="p1">
                    <p id="217"><i>NMI</i>计算如下:</p>
                </div>
                <div class="p1">
                    <p id="218" class="code-formula">
                        <mathml id="218"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>Μ</mi><mi>Ι</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mi>n</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>ln</mi><mo stretchy="false"> (</mo><mfrac><mrow><mi>Ν</mi><mi>n</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mi>n</mi><msub><mrow></mrow><mi>i</mi></msub><mi>n</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mo stretchy="false">) </mo></mrow><mrow><mroot><mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mi>n</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>ln</mi><mo stretchy="false"> (</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mi>Ν</mi></mfrac><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mi>n</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mi>ln</mi><mo stretchy="false"> (</mo><mfrac><mrow><mi>n</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mi>Ν</mi></mfrac><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow></mrow></mroot></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="219">其中, <i>N</i>为样本总数, <i>c</i>为类簇数, <i>n</i><sub><i>i</i></sub>、<i>n</i><sub><i>j</i></sub>分别为属于类簇<i>i</i>、类簇<i>j</i>的样本数, <i>n</i><sub><i>ij</i></sub>为属于类簇<i>i</i>和类簇<i>j</i>的相同样本的个数.</p>
                </div>
                <div class="p1">
                    <p id="220">本文算法在Matlab R2016a 环境下编程实现.计算机环境包括Windows 7 操作系统、Intel Core i5 CPU、16 GB 内存.</p>
                </div>
                <div class="p1">
                    <p id="221">由Matlab提供的并行组件实现本文算法集成框架.Matlab提供并完善并行计算工具箱 (Parallel Computing Toolbox) 和Matlab分布式计算服务器 (Distributed Computing Server) , 可在Matlab中开发分布式和并行计算, 并在多核处理器和多台PC端中执行, 通过Matlab并行组件构建集成算法并行计算环境.由于PC处理器内核数为4, 所以本文实验中<i>p</i>为固定值4.</p>
                </div>
                <div class="p1">
                    <p id="222">所有算法的核函数使用高斯核</p>
                </div>
                <div class="area_img" id="223">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905005_22300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="224">其中<i>γ</i>取数据点与每个数据集均值的平均平方距离.对于岭回归变量, 取验证集<i>V</i>=20列作为训练最佳的<i>λ</i>值, 实验采样个数<i>m</i>=5%<i>n</i>, 10%<i>n</i>, 15%<i>n</i>.为了客观对比算法的各项聚类指标, 将每种算法独立运行20次, 评价指标%<i>error</i>、<i>CA</i>、<i>NMI</i>和运行时间取平均值.</p>
                </div>
                <div class="p1">
                    <p id="225">本文选取4种基于不同采样技术的Nyström谱聚类算法进行对比, 分别为:基于随机抽样的Nyström谱聚类算法 (Spectral Clustering Algorithm Based on Random Nyström Sampling, RNS-SC) <citation id="256" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、基于<i>K</i>-means中心点抽样的Nyström谱聚类算法 (Spectral Clustering Algorithm Based on <i>K</i>-means Nyström Sampling, KNS-SC) <citation id="257" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、基于方差增量抽样的Nyström谱聚类算法 (Spectral Clustering Algorithm Based on Incremental Nyström Sampling, INS-SC) <citation id="258" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>和基于概率抽样的Nyström谱聚类算法 (Spectral Clustering Algorithm Based on Probabilistic Nyström Sampling, PNS-SC) <citation id="259" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>.在5个数据集上测试5种算法, %<i>error</i>、<i>CA</i>和<i>NMI</i>的结果分别如表2～表4所示, 表中</p>
                </div>
                <div class="p1">
                    <p id="226">采样比例<mathml id="227"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mfrac><mrow><mtext>采</mtext><mtext>样</mtext><mtext>个</mtext><mtext>数</mtext></mrow><mrow><mtext>样</mtext><mtext>本</mtext><mtext>数</mtext></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi><mo>.</mo></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="228">平均运行时间如表5所示.</p>
                </div>
                <div class="p1">
                    <p id="229">由表2～表4可见, WES-SC和KNS-SC明显优于RNS-SC、INS-SC、PNS-SC.RNS-SC采用基于随机抽样的策略, 聚类效果较差, 聚类结果也不稳定.INS-SC采用基于方差的增量抽样策略, 利用特征向量的可聚性, 通过计算方差增量抽样得到各样本点, 最终生成样本集.PNS-SC设计计算各行向量范数的概率分布获得采样点.在多数情况下, 聚类准确率近似等于INS-SC.KNS-SC和WENS-SC聚类效果最好.KNS-SC通过分析Nyström的逼近误差函数与<i>K</i>-means算法目标函数一致, 并取其中心点为抽样点.而WENS-SC (<i>p</i>=4) 在大多数实验中的聚类准确率最高, 说明本文算法利用统计杠杆分数加权采样得到的采样点更具代表性, 在大数据下利用Nyström方法聚类的集成框架也更有优越性.</p>
                </div>
                <div class="p1">
                    <p id="230">由表5可知, RNS-SC的运行时间最短, 其余4种算法因采用不同的抽样策略, 导致运行时间较长.INS-SC的运行时间最长, 因为在采样过程中需要计算矩阵每列的列方差, 选择列方差大的那列作为抽样列, 直到抽取全部的抽样点, 时间复杂度较高.PNS-SC运行时间也较长, 因为使用全部核矩阵进行运算, 当数据量变大时, 需要消耗大量的存储空间和时间.仅使用部分核矩阵进行近似计算的RNS-SC、KNS-SC和WENS-SC在各个数据集上均能较快得到聚类结果.当采样比例增加时, WENS-SC在大数据集上的聚类时间显著增加, 说明算法 所 需 的计 算量较大.但WENS-SC支持并行计算, 在集成框架下的聚类效率更高, 更适合解决集成聚类框架下的大数据聚类问题.</p>
                </div>
                <div class="area_img" id="231">
                    <p class="img_tit"><b>表2 5种算法在5个数据集上的%error对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 %error comparison of 5 algorithms on 5 datasets </p>
                    <p class="img_note">%</p>
                    <table id="231" border="1"><tr><td>采样比例</td><td>数据集</td><td>RNS-SC</td><td>KNS-SC</td><td>INS-SC</td><td>PNS-SC</td><td>WENS-SC</td></tr><tr><td>5</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br /> Forest CovType</td><td>0.267 (±0.56) <br />3.621 (±0.52) <br />0.220 (±0.61) <br />5.121 (±1.05) <br />15.451 (±1.24) </td><td>0.230 (±0.23) <br />2.327 (±0.48) <br />0.187 (±0.46) <br />4.631 (±0.79) <br />12.124 (±1.07) </td><td>0.256 (±0.61) <br />3.155 (±0.52) <br />0.195 (±0.11) <br />5.562 (±0.68) <br />14.754 (±1.13) </td><td>0.242 (±0.65) <br />3.984 (±0.21) <br />0.223 (±0.53) <br />5.456 (±0.81) <br />14.390 (±1.21) </td><td>0.247 (±0.39) <br />2.315 (±0.62) <br />0.187 (±0.12) <br />5.215 (±0.83) <br />12.574 (±1.44) </td></tr><tr><td>10</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br /> Forest CovType</td><td>0.153 (±0.42) <br />1.983 (±0.33) <br />0.177 (±0.47) <br />4.235 (±0.64) <br />13.674 (±1.74) </td><td>0.145 (±0.39) <br />1.472 (±0.57) <br />0.136 (±0.32) <br />4.013 (±0.45) <br />11.061 (±1.04) </td><td>0.153 (±0.53) <br />2.051 (±0.32) <br />0.163 (±0.30) <br />4.645 (±0.46) <br />13.121 (±1.48) </td><td>0.152 (±0.45) <br />2.231 (±0.10) <br />0.176 (±0.12) <br />4.646 (±0.71) <br />12.746 (±1.03) </td><td>0.143 (±0.15) <br />1.412 (±0.39) <br />0.153 (±0.48) <br />4.561 (±1.11) <br />11.150 (±1.16) </td></tr><tr><td>15</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br /> Forest CovType</td><td>0.127 (±0.36) <br />1.352 (±0.45) <br />0.162 (±0.29) <br />3.985 (±0.83) <br />10.124 (±1.53) </td><td>0.119 (±0.52) <br />1.051 (±0.25) <br />0.149 (±0.37) <br />3.564 (±0.46) <br />9.006 (±1.24) </td><td>0.126 (±0.48) <br />1.302 (±0.34) <br />0.144 (±0.26) <br />4.262 (±0.73) <br />9.329 (±1.20) </td><td>0.129 (±0.40) <br />1.420 (±0.31) <br />0.160 (±0.35) <br />4.156 (±0.69) <br />9.257 (±1.01) </td><td>0.119 (±0.67) <br />1.013 (±0.42) <br />0.146 (±0.33) <br />4.156 (±0.82) <br />9.013 (±1.08) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="232">
                    <p class="img_tit"><b>表3 5种算法在5个数据集上的CA对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 CA comparison of 5 algorithms on 5 datasets </p>
                    <p class="img_note">%</p>
                    <table id="232" border="1"><tr><td>采样比例</td><td>数据集</td><td>RNS-SC</td><td>KNS-SC</td><td>INS-SC</td><td>PNS-SC</td><td>WENS-SC</td></tr><tr><td>5</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>63.18 (±2.63) <br />50.53 (±2.13) <br />55.13 (±1.73) <br />46.12 (±3.45) <br />26.05 (±2.09) </td><td>73.12 (±1.49) <br />56.26 (±2.24) <br />59.16 (±1.07) <br />54.15 (±1.51) <br />28.15 (±2.06) </td><td>69.64 (±1.03) <br />53.15 (±1.84) <br />55.45 (±0.98) <br />49.87 (±1.20) <br />27.62 (±1.56) </td><td>64.15 (±1.62) <br />51.34 (±1.43) <br />56.22 (±1.36) <br />48.63 (±1.41) <br />27.46 (±1.48) </td><td>73.20 (±1.54) <br />56.67 (±1.96) <br />59.71 (±1.93) <br />54.01 (±1.37) <br />28.14 (±2.52) </td></tr><tr><td>10</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>69.15 (±1.95) <br />56.44 (±2.04) <br />62.52 (±2.23) <br />55.21 (±2.53) <br />29.48 (±2.19) </td><td>80.21 (±1.83) <br />63.34 (±1.65) <br />68.39 (±1.43) <br />60.12 (±1.30) <br />34.14 (±2.67) </td><td>78.45 (±1.35) <br />58.65 (±1.80) <br />66.23 (±2.03) <br />62.47 (±1.75) <br />30.04 (±2.69) </td><td>76.17 (±1.48) <br />57.16 (±1.93) <br />63.81 (±2.68) <br />56.97 (±1.79) <br />29.85 (±2.75) </td><td>79.91 (±2.11) <br />64.11 (±1.77) <br />68.49 (±1.56) <br />59.15 (±1.45) <br />34.89 (±1.46) </td></tr><tr><td>15</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>77.13 (±1.05) <br />64.16 (±1.72) <br />70.53 (±1.23) <br />67.98 (±2.78) <br />35.08 (±3.70) </td><td>88.54 (±1.38) <br />76.13 (±1.46) <br />76.59 (±1.35) <br />75.94 (±1.19) <br />39.57 (±2.04) </td><td>81.32 (±1.92) <br />68.21 (±1.83) <br />70.26 (±1.65) <br />75.16 (±1.89) <br />37.51 (±1.17) </td><td>77.63 (±1.55) <br />66.19 (±1.97) <br />72.54 (±1.27) <br />68.47 (±1.20) <br />37.06 (±1.76) </td><td>83.65 (±1.47) <br />77.29 (±1.56) <br />77.10 (±1.42) <br />76.12 (±1.32) <br />39.78 (±1.68) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="233">
                    <p class="img_tit"><b>表4 5种算法在5个数据集上的NMI 对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 NMI comparison of 5 algorithms on 5 datasets</p>
                    <p class="img_note"></p>
                    <table id="233" border="1"><tr><td>采样比例</td><td>数据集</td><td>RNS-SC</td><td>KNS-SC</td><td>INS-SC</td><td>PNS-SC</td><td>WENS-SC</td></tr><tr><td>5</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>70.61 (±0.30) <br />36.21 (±0.25) <br />57.62 (±0.64) <br />53.16 (±0.43) <br />17.54 (±0.46) </td><td>76.22 (±0.41) <br />36.89 (±0.23) <br />60.53 (±0.21) <br />56.23 (±0.37) <br />18.15 (±0.23) </td><td>73.15 (±0.42) <br />36.54 (±0.20) <br />56.23 (±0.36) <br />54.15 (±0.26) <br />17.78 (±0.15) </td><td>72.26 (±0.37) <br />36.35 (±0.13) <br />57.51 (±0.23) <br />53.46 (±0.43) <br />17.81 (±0.30) </td><td>76.46 (±0.35) <br />36.76 (±0.41) <br />58.69 (±0.55) <br />56.13 (±0.20) <br />18.54 (±0.41) </td></tr><tr><td>10</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>71.23 (±0.20) <br />36.32 (±0.23) <br />58.07 (±0.15) <br />53.67 (±0.40) <br />18.20 (±0.46) </td><td>76.83 (±0.42) <br />37.15 (±0.30) <br />60.93 (±0.35) <br />56.82 (±0.61) <br />18.51 (±0.37) </td><td>73.63 (±0.70) <br />36.87 (±0.32) <br />56.61 (±0.30) <br />54.73 (±0.38) <br />18.03 (±0.04) </td><td>72.79 (±0.53) <br />36.51 (±0.52) <br />57.88 (±0.28) <br />53.98 (±0.49) <br />18.14 (±0.13) </td><td>76.91 (±0.34) <br />37.03 (±0.38) <br />59.30 (±0.29) <br />56.89 (±0.31) <br />18.53 (±0.19) </td></tr><tr><td>15</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>71.87 (±0.35) <br />36.59 (±0.18) <br />58.61 (±0.26) <br />54.25 (±0.13) <br />18.59 (±0.36) </td><td>77.23 (±0.41) <br />37.48 (±0.17) <br />61.23 (±0.27) <br />57.31 (±0.42) <br />18.82 (±0.26) </td><td>74.06 (±0.56) <br />37.06 (±0.02) <br />57.00 (±0.25) <br />54.97 (±0.63) <br />18.43 (±0.31) </td><td>73.40 (±0.52) <br />36.79 (±0.36) <br />58.14 (±0.10) <br />54.21 (±0.44) <br />18.67 (±0.08) </td><td>77.50 (±0.12) <br />37.56 (±0.32) <br />59.79 (±0.15) <br />57.32 (±0.23) <br />18.84 (±0.30) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="234">
                    <p class="img_tit"><b>表5 5种算法在5个数据集上的运行时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Running time comparison of 5 algorithms on 5 datasets s</p>
                    <p class="img_note"></p>
                    <table id="234" border="1"><tr><td>采样比例</td><td>数据集</td><td>RNS-SC</td><td>KNS-SC</td><td>INS-SC</td><td>PNS-SC</td><td>WENS-SC</td></tr><tr><td>5</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>0.352<br />0.869<br />2.480<br />3.458<br />52.131</td><td>1.556<br />2.335<br />2.322<br />5.912<br />214.156</td><td>1.781<br />3.514<br />3.292<br />12.793<br />271.783</td><td>1.615<br />3.152<br />2.965<br />10.468<br />254.962</td><td>1.570<br />2.885<br />3.203<br />9.514<br />251.127</td></tr><tr><td>10</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>0.545<br />1.201<br />4.352<br />6.264<br />68.481</td><td>1.879<br />1.892<br />5.079<br />9.130<br />436.217</td><td>2.626<br />4.689<br />5.562<br />19.529<br />537.843</td><td>2.253<br />4.232<br />4.156<br />16.216<br />525.675</td><td>2.156<br />3.493<br />6.211<br />14.560<br />477.149</td></tr><tr><td>15</td><td>Segment<br />Waveform<br />Pageblocks<br />Pendigits<br />Forest CovType</td><td>0.949<br />1.904<br />6.374<br />9.526<br />95.165</td><td>2.481<br />2.637<br />7.270<br />14.325<br />591.749</td><td>3.623<br />6.145<br />9.253<br />36.207<br />667.483</td><td>3.897<br />6.112<br />8.143<br />37.179<br />649.646</td><td>4.157<br />6.121<br />8.001<br />30.258<br />637.942</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="235" name="235" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="236">本文提出基于加权集成<i>Nystr</i>ö<i>m</i>采样的谱聚类算法.首先为了区别数据样本间重要程度, 利用统计杠杆分数对数据进行加权, 然后根据权重调用加权K-<i>means</i>对数据进行采样, 聚类的中心点作为抽样点, 使得样本中的点更能代表数据中点的分布特征.再引入集成框架, 并行化运用<i>Nystr</i>ö<i>m</i>方法得到近似核矩阵, 大幅降低算法的时间复杂度.最后利用混合权重组合优化近似核矩阵, 产生比标准<i>Nystr</i>ö<i>m</i>方法更准确的低秩近似.实验表明, 本文算法能有效提高基于<i>Nystr</i>ö<i>m</i>算法的谱聚类算法的聚类性能.下一步工作将重点研究如何提高算法在加权采样步骤上的运行效率.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="261" type="formula" href="images/MSSB201905005_26100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">邱云飞</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="263" type="formula" href="images/MSSB201905005_26300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">刘畅</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="5">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 MEI J P, WANG Y T, CHEN L H, <i>et al</i>.Large Scale Document Categorization with Fuzzy Clustering.IEEE Transactions on Fuzzy Systems, 2017, 25 (5) :1239-1251.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201707004&amp;v=MjAzMjNVUkxPZVplUm5GeXpnVmIzUEtEN1liTEc0SDliTXFJOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 邱云飞, 费博雯, 刘大千.基于概率模型的重叠子空间聚类算法.模式识别与人工智能, 2017, 30 (7) :609-621. (QIU Y F, FEI B W, LIU D Q.Overlapping Subspace Clustering Based on Probabilistic Model.Pattern Recognition and Artificial Intelligence, 2017, 30 (7) :609-621.) 
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201702004&amp;v=MjI3MjZPZVplUm5GeXpnVmIzUElUZlNkckc0SDliTXJZOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 叶茂, 刘文芬.基于快速地标采样的大规模谱聚类算法.电子与信息学报, 2017, 39 (2) :278-284. (YE M, LIU W F.Large Scale Spectral Clustering Based on Fast Landmark Sampling.Journal of Electronics and Information Techno-logy, 2017, 39 (2) :278-284.) 
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201208013&amp;v=MDExOTJGeXpnVmIzUEtDTGZZYkc0SDlQTXA0OUVaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 周林, 平西建, 徐森, 等.基于谱聚类的聚类集成算法.自动化学报, 2012, 38 (8) :1335-1342. (ZHOU L, PING X J, XU S, <i>et al</i>.Cluster Ensemble Based on Spectral Clustering.Acta Automatica Sinica, 2012, 38 (8) :1335-1342.) 
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201409012&amp;v=MDAwMTZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVmIzUE55ZlRiTEc0SDlYTXBvOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 丁世飞, 贾洪杰, 史忠植.基于自适应Nyström采样的大数据谱聚类算法.软件学报, 2014, 25 (9) :2037-2049. (DING S F, JIA H J, SHI Z Z.Spectral Clustering Algorithm Based on Adaptive Nyström Sampling for Big Data Analysis.Journal of Software, 2014, 25 (9) :2037-2049.) 
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 WILLIAMS C K I, SEEGER M.Using the Nyström Method to Speed up Kernel Machines // Proc of the 13th International Conference on Neural Information Processing Systems.Cambridge, USA:The MIT Press, 2000:661-667.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 FOWLKES C, BELONGIE S, CHUNG F, <i>et al</i>.Spectral Grouping Using the Nyström Method.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (2) :214-225.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 WILLIAMS C K I, SEEGER M.The Effect of the Input Density Distribution on Kernel-Based Classifiers // Proc of the 17th International Conference on Machine Learning.San Francisco, USA:Morgan Kaufmann Publishers, 2000:1159-1166.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 DRINEAS P, MAHONEY M W.On the Nyström Method for Approximating a Gram Matrix for Improved Kernel-Based Learning.Journal of Machine Learning Research, 2005, 6:2153-2175.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                 OUIMET M, BENGIO Y.Greedy Spectral Embedding[C/OL].[2018-12-12].http://www.gatsby.ucl.ac.uk/aistats/fullpapers/209.pdf.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 ZHANG K, TSANG I W, KWOK J T.Improved Nyström Low-Rank Approximation and Error Analysis // Proc of the 25th International Conference on Machine Learning.New York, USA:ACM, 2008:1232-1239.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 ZHANG K, KWOK J T.Clustered Nyström Method for Large Scale Manifold Learning and Dimension Reduction.IEEE Transactions on Neural Networks, 2010, 21 (10) :1576-1587.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 KUMAR S, MOHRI M, TALWALKAR A.Sampling Methods for the Nyström Method.Journal of Machine Learning Research, 2012, 13:981-1006.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 SHI J B, MALIK J.Normalized Cuts and Image Segmentation.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 (8) :888-905.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 BOUTSIDIS C, MAHONEY M W, DRINEAS P.An Improved Approximation Algorithm for the Column Subset Selection Problem // Proc of the 20th Annual ACM-SIAM Symposium on Discrete Algorithms.New York, USA:ACM, 2009:968-977.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200504002&amp;v=MTkyMzZxQnRHRnJDVVJMT2VaZVJuRnl6Z1ZiM1BOeWZUYkxHNEh0VE1xNDlGWm9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 唐伟, 周志华.基于Bagging的选择性聚类集成.软件学报, 2005, 16 (4) :496-502. (TANG W, ZHOU Z H.Bagging-Based Selective Cluster Ensemble.Journal of Software, 2005, 16 (4) :496-502.) 
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 FERN X Z, LIN W.Cluster Ensemble Selection.Statistical Analysis and Data Mining, 2008, 1 (3) :128-141.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201608011&amp;v=MTcwNzVxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emdWYjNQS0NMZlliRzRIOWZNcDQ5RVpZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> 刘展杰, 陈晓云.局部子空间聚类.自动化学报, 2016, 42 (8) :1238-1247. (LIU Z J, CHEN X Y.Local Subspace Clustering.Acta Automatica Sinica, 2016, 42 (8) :1238-1247.) 
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201510005&amp;v=MjQ0NjllUm5GeXpnVmIzUEtEN1liTEc0SDlUTnI0OUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 邱云飞, 杨倩, 唐晓亮.基于粒子群优化的软子空间聚类算法.模式识别与人工智能, 2015, 28 (10) :903-912. (QIU Y F, YANG Q, TANG X L.Soft Subspace Clustering Based on Particle Swarm Optimization.Pattern Recognition and Artificial Intelligence, 2015, 28 (10) :903-912.) 
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_20" >
                                    <b>[20]</b>
                                 ZHANG X C, YOU Q Z.Clusterability Analysis and Incremental Sampling for Nyström Extension Based Spectral Clustering // Proc of the 11th IEEE International Conference on Data Mining.Wa-shington, USA:IEEE, 2011:942-951.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201905005" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201905005&amp;v=MTA5NzJGeXpnVmIzUEtEN1liTEc0SDlqTXFvOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
