<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131461190655000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201910012%26RESULT%3d1%26SIGN%3dk3nkofxbr%252bwMMGXnOzNaVSzbxa4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201910012&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201910012&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201910012&amp;v=MTA1MzlHRnJDVVJMT2VaZVJuRnkva1dyM0FLRDdZYkxHNEg5ak5yNDlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#70" data-title="1 基于非局部张量火车分解的张量补全算法 ">1 基于非局部张量火车分解的张量补全算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="&lt;b&gt;1.1&lt;/b&gt; 低张量火车秩张量补全模型"><b>1.1</b> 低张量火车秩张量补全模型</a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;1.2&lt;/b&gt; 非局部张量火车分解模型"><b>1.2</b> 非局部张量火车分解模型</a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;1.3&lt;/b&gt; 算法步骤"><b>1.3</b> 算法步骤</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#135" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#183" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#81" data-title="图1 五阶张量的火车张量分解示意图">图1 五阶张量的火车张量分解示意图</a></li>
                                                <li><a href="#95" data-title="图2 非局部张量火车算法">图2 非局部张量火车算法</a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表1 彩色图像补全中5种算法的RSE值对比&lt;/b&gt;"><b>表1 彩色图像补全中5种算法的RSE值对比</b></a></li>
                                                <li><a href="#146" data-title="&lt;b&gt;表2 彩色图像补全中5种算法的PSNR值对比&lt;/b&gt;"><b>表2 彩色图像补全中5种算法的PSNR值对比</b></a></li>
                                                <li><a href="#231" data-title="图3 缺失率为0.3时5种算法的恢复效果对比">图3 缺失率为0.3时5种算法的恢复效果对比</a></li>
                                                <li><a href="#231" data-title="图3 缺失率为0.3时5种算法的恢复效果对比">图3 缺失率为0.3时5种算法的恢复效果对比</a></li>
                                                <li><a href="#232" data-title="图4 缺失率为0.5时5种算法的恢复效果对比">图4 缺失率为0.5时5种算法的恢复效果对比</a></li>
                                                <li><a href="#232" data-title="图4 缺失率为0.5时5种算法的恢复效果对比">图4 缺失率为0.5时5种算法的恢复效果对比</a></li>
                                                <li><a href="#233" data-title="图5 缺失率为0.5时3种算法部分图像局部细节恢复效果">图5 缺失率为0.5时3种算法部分图像局部细节恢复效果</a></li>
                                                <li><a href="#181" data-title="图6 不同缺失率下矩阵块大小对实验结果的影响">图6 不同缺失率下矩阵块大小对实验结果的影响</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="234">


                                    <a id="bibliography_1" title=" CAI J F,CAND&#201;S E J,SHEN Z W.A Singular Value Thresholding Algorithm for Matrix Completion.SIAM Journal on Optimization,2010,20(4):1956-1982." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A singular value thresholding algorithm for matrix completion">
                                        <b>[1]</b>
                                         CAI J F,CAND&#201;S E J,SHEN Z W.A Singular Value Thresholding Algorithm for Matrix Completion.SIAM Journal on Optimization,2010,20(4):1956-1982.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_2" title=" JAIN P,NETRAPALLI P,SANGHAVI S.Low-Rank Matrix Completion Using Alternating Minimization // Proc of the 45th Annual ACM Symposium on Theory of Computing.New York,USA:ACM,2013:665-674." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low-rank matrix completion using alternating minimization">
                                        <b>[2]</b>
                                         JAIN P,NETRAPALLI P,SANGHAVI S.Low-Rank Matrix Completion Using Alternating Minimization // Proc of the 45th Annual ACM Symposium on Theory of Computing.New York,USA:ACM,2013:665-674.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_3" title=" HU Y,ZHANG D B,YE J P,et al.Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization.IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(9):2117-2130." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast and accurate matrix completion via truncated nuclear norm regularization">
                                        <b>[3]</b>
                                         HU Y,ZHANG D B,YE J P,et al.Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization.IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(9):2117-2130.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_4" title=" DU B,ZHANG M F,ZHANG L F,et al.PLTD:Patch-Based Low-Rank Tensor Decomposition for Hyperspectral Images.IEEE Transa-ctions on Multimedia,2017,19(1):67-79." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PLTD:Patch-based low-rank tensor decomposition for hyperspectral images">
                                        <b>[4]</b>
                                         DU B,ZHANG M F,ZHANG L F,et al.PLTD:Patch-Based Low-Rank Tensor Decomposition for Hyperspectral Images.IEEE Transa-ctions on Multimedia,2017,19(1):67-79.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_5" title=" HE Z,HU J,WANG Y W.Low-Rank Tensor Learning for Classification of Hyperspectral Image with Limited Labeled Samples.Signal Processing,2018,145:12-25." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESCDE43A03A8F2F7EEF442336E98D9EF87&amp;v=MjEzNjM1RGdvK3VtTmw3anQvUzN6azJSczlEYnZoTTdLWUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaHc3bTJ3cUE9TmlmT2ZjRE1hOVhQM285R0ZlTg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         HE Z,HU J,WANG Y W.Low-Rank Tensor Learning for Classification of Hyperspectral Image with Limited Labeled Samples.Signal Processing,2018,145:12-25.
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_6" title=" GUO H W,WU X Y,FENG W.Multi-stream Deep Networks for Human Action Classification with Sequential Tensor Decomposition.Signal Processing,2017,140:198-206." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC94BC9C9E3486B3A83B039E0914BC078&amp;v=MDU5MDhCSHBMekdjYjZVMTlTM2FYckJzMGZjRG5SYjJYQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtMndxQT1OaWZPZmNDeEdxTy9wdnhNRWVnTA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         GUO H W,WU X Y,FENG W.Multi-stream Deep Networks for Human Action Classification with Sequential Tensor Decomposition.Signal Processing,2017,140:198-206.
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_7" title=" VIGNERON V,KODEWITZ A,DA COSTA M N,et al.Non-negative Sub-tensor Ensemble Factorization(NsTEF) Algorithm:A New Incremental Tensor Factorization for Large Data Sets.Signal Proce-ssing,2018,144:77-86." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES6D75FC531E6AF6064D55A89B56C90D97&amp;v=MjkxNzNkUzYzSXBHWlo0SmZRby96eEFYbmpwNE9YZnIzaGN6Q3J1VU1iT1lDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N20yd3FBPU5pZk9mYlhNRw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         VIGNERON V,KODEWITZ A,DA COSTA M N,et al.Non-negative Sub-tensor Ensemble Factorization(NsTEF) Algorithm:A New Incremental Tensor Factorization for Large Data Sets.Signal Proce-ssing,2018,144:77-86.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_8" title=" PAPALEXAKIS E E,FALOUTSOS C,SIDIROPOULOS N D.Tensors for Data Mining and Data Fusion:Models,Applications,and Scalable Algorithms.ACM Transactions on Intelligent Systems and Technology,2016,8(2).DOI:10.1145/2915921." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM91179A4903A46131E60661DC2C5CE4A4&amp;v=MjY3NDJwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtMndxQT1OaWZJWTdxNUg5YkYzb3RNWk9oK0NIbzR6QmRtN0Q5N1RuNlczeEJHZk1IaFFjdWJDT052RlNpV1dyN0pJRg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         PAPALEXAKIS E E,FALOUTSOS C,SIDIROPOULOS N D.Tensors for Data Mining and Data Fusion:Models,Applications,and Scalable Algorithms.ACM Transactions on Intelligent Systems and Technology,2016,8(2).DOI:10.1145/2915921.
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_9" title=" LIU J,MUSIALSKI P,WONKA P,et al.Tensor Completion for Estimating Missing Values in Visual Data // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2009:2114-2121." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor Completion for Estimating Missing Values in Visual Data">
                                        <b>[9]</b>
                                         LIU J,MUSIALSKI P,WONKA P,et al.Tensor Completion for Estimating Missing Values in Visual Data // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2009:2114-2121.
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_10" title=" XU Y X,HAO R R,YIN W T,et al.Parallel Matrix Factorization for Low-Rank Tensor Completion.Inverse Problems and Imaging,2015,9(2):601-624." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Parallel matrix factorization for low-rank tensor completion">
                                        <b>[10]</b>
                                         XU Y X,HAO R R,YIN W T,et al.Parallel Matrix Factorization for Low-Rank Tensor Completion.Inverse Problems and Imaging,2015,9(2):601-624.
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_11" title=" CARROLL J D,CHANG J J.Analysis of Individual Differences in Multidimensional Scaling via an N-Way Generalization of &quot;Eckart-Young&quot; Decomposition.Psychometrika,1970,35(3):283-319." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001069213&amp;v=MTc5NzF0RkNIbFZMN0JJbFk9Tmo3QmFyTzRIdEhOcjRsTVp1b01ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVk&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         CARROLL J D,CHANG J J.Analysis of Individual Differences in Multidimensional Scaling via an N-Way Generalization of &quot;Eckart-Young&quot; Decomposition.Psychometrika,1970,35(3):283-319.
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_12" title=" TUCKER L R.Some Mathematical Notes on Three-Mode Factor Analysis.Psychometrika,1966,31(3):279-311." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001068384&amp;v=MDk1MjF1ZHRGQ0hsVkw3QklsWT1OajdCYXJPNEh0SE5yNGxOWitNTFkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVi&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         TUCKER L R.Some Mathematical Notes on Three-Mode Factor Analysis.Psychometrika,1966,31(3):279-311.
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_13" title=" OSELEDETS I V.Tensor-Train Decomposition.SIAM Journal on Scientific Computing,2011,33(5):2295-2317." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor-train decomposition">
                                        <b>[13]</b>
                                         OSELEDETS I V.Tensor-Train Decomposition.SIAM Journal on Scientific Computing,2011,33(5):2295-2317.
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_14" title=" ACAR E,DUNLAVY D M,KOLDA T G,et al.Scalable Tensor Factorizations for Incomplete Data.Chemometrics and Intelligent Laboratory Systems,2011,106(1):41-56." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300184801&amp;v=MTEyMDdtVUxiSUoxOGRhQm89TmlmT2ZiSzdIdERPckk5RlplTUxCSHc0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         ACAR E,DUNLAVY D M,KOLDA T G,et al.Scalable Tensor Factorizations for Incomplete Data.Chemometrics and Intelligent Laboratory Systems,2011,106(1):41-56.
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_15" title=" KOLDA T G,BADER B W.Tensor Decompositions and Applications.SIAM Review,2009,51(3):455-500." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST15012900404745&amp;v=MTg2MjlCbz1OaWZZZXJLOUh0RE9wbzlGWU9zTEMzZzhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKMThkYQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         KOLDA T G,BADER B W.Tensor Decompositions and Applications.SIAM Review,2009,51(3):455-500.
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_16" title=" CHEN Y L,HSU C T,LIAO H Y M.Simultaneous Tensor Decomposition and Completion Using Factor Priors.IEEE Transactions on Pattern Analysis and Machine Intelligence,2014,36(3):577-591." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Simultaneous tensor decomposition and completion using factor priors">
                                        <b>[16]</b>
                                         CHEN Y L,HSU C T,LIAO H Y M.Simultaneous Tensor Decomposition and Completion Using Factor Priors.IEEE Transactions on Pattern Analysis and Machine Intelligence,2014,36(3):577-591.
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_17" title=" BENGUA J A,PHIEN H N,TUAN H D,et al.Efficient Tensor Completion for Color Image and Video Recovery:Low-Rank Tensor Train.IEEE Transactions on Image Processing,2017,26(5):2466-2479." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient tensor completion for color image and video recovery:Low-rank tensor train">
                                        <b>[17]</b>
                                         BENGUA J A,PHIEN H N,TUAN H D,et al.Efficient Tensor Completion for Color Image and Video Recovery:Low-Rank Tensor Train.IEEE Transactions on Image Processing,2017,26(5):2466-2479.
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_18" title=" BUADES A,COLL B,MOREL J M.A Non-local Algorithm for Image Denoising // Proc of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2005,II:60-65" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A non-local algorithm for image denoising">
                                        <b>[18]</b>
                                         BUADES A,COLL B,MOREL J M.A Non-local Algorithm for Image Denoising // Proc of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2005,II:60-65
                                    </a>
                                </li>
                                <li id="270">


                                    <a id="bibliography_19" title=" DABOV K,FOI A,KATKOVNIK V,et al.Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering.IEEE Transac-tions on Image Processing,2007,16(8):2080-2095." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image denoising by sparse 3-D transform-domain collaborative filtering">
                                        <b>[19]</b>
                                         DABOV K,FOI A,KATKOVNIK V,et al.Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering.IEEE Transac-tions on Image Processing,2007,16(8):2080-2095.
                                    </a>
                                </li>
                                <li id="272">


                                    <a id="bibliography_20" title=" MAIRAL J,BACH F,PONCE J,et al.Non-local Sparse Models for Image Restoration // Proc of the 12th IEEE International Conference on Computer Vision.Washington,USA:IEEE,2009:2272-2279." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Non-local sparse models for image restoration">
                                        <b>[20]</b>
                                         MAIRAL J,BACH F,PONCE J,et al.Non-local Sparse Models for Image Restoration // Proc of the 12th IEEE International Conference on Computer Vision.Washington,USA:IEEE,2009:2272-2279.
                                    </a>
                                </li>
                                <li id="274">


                                    <a id="bibliography_21" title=" WANG S L,LEI Z,YAN L.Nonlocal Spectral Prior Model for Low-Level Vision // Proc of the 11th Asian Conference on Computer Vision.Berlin,Germany:Springer,2012,III:231-244." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlocal Spectral Prior Model for Low-Level Vision">
                                        <b>[21]</b>
                                         WANG S L,LEI Z,YAN L.Nonlocal Spectral Prior Model for Low-Level Vision // Proc of the 11th Asian Conference on Computer Vision.Berlin,Germany:Springer,2012,III:231-244.
                                    </a>
                                </li>
                                <li id="276">


                                    <a id="bibliography_22" title=" MA S Q,GLODFARB D,CHEN L F.Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization.Mathematical Programming,2009,128(1/2):321-353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fixed point and Bregman iterative methods for matrix rank minimization">
                                        <b>[22]</b>
                                         MA S Q,GLODFARB D,CHEN L F.Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization.Mathematical Programming,2009,128(1/2):321-353.
                                    </a>
                                </li>
                                <li id="278">


                                    <a id="bibliography_23" title=" BACH F R.Consistency of Trace Norm Minimization.Journal of Machine Learning Research,2008,9:1019-1048." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Consistency of trace norm minimization">
                                        <b>[23]</b>
                                         BACH F R.Consistency of Trace Norm Minimization.Journal of Machine Learning Research,2008,9:1019-1048.
                                    </a>
                                </li>
                                <li id="280">


                                    <a id="bibliography_24" title=" LIU Y P,LONG Z,ZHU C.Image Completion Using Low Tensor Tree Rank and Total Variation Minimization.IEEE Transactions on Multimedia,2019,21(2):338-350." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Completion Using Low Tensor Tree Rank and Total Variation Minimization">
                                        <b>[24]</b>
                                         LIU Y P,LONG Z,ZHU C.Image Completion Using Low Tensor Tree Rank and Total Variation Minimization.IEEE Transactions on Multimedia,2019,21(2):338-350.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(10),955-963 DOI:10.16451/j.cnki.issn1003-6059.201910010            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于非局部张量火车分解的彩色图像修补</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BE%E6%85%A7%E8%BF%AA&amp;code=43237366&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贾慧迪</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%9F%A9%E5%BF%97&amp;code=34839123&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">韩志</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%99%88%E5%B8%8C%E7%88%B1&amp;code=43237368&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">陈希爱</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%94%90%E5%BB%B6%E4%B8%9C&amp;code=10356720&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">唐延东</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%B2%88%E9%98%B3%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A0%94%E7%A9%B6%E6%89%80%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0183762&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院沈阳自动化研究所机器人学国家重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%8E%E6%99%BA%E8%83%BD%E5%88%B6%E9%80%A0%E5%88%9B%E6%96%B0%E7%A0%94%E7%A9%B6%E9%99%A2&amp;code=1698842&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院机器人与智能制造创新研究院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E9%99%A2%E5%A4%A7%E5%AD%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国科学院大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>数据在采集和转换的过程中通常存在部分数据丢失的问题,丢失数据的补全直接影响后续的识别、跟踪等高层任务的结果.自然图像中经常存在许多具有重复特性的相似结构,利用该类冗余信息,文中提出基于非局部张量火车分解的张量补全方法.利用图像的非局部相似性,挖掘其中蕴含的低秩特性,并通过张量火车分解模型进行建模及升阶,将低阶张量转化为高阶以进行低秩信息的进一步挖掘利用,从而进行图像中缺失数据的修补.实验验证文中方法在图像修补上的有效性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%A0%E9%87%8F%E7%81%AB%E8%BD%A6%E5%88%86%E8%A7%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张量火车分解;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%B1%80%E9%83%A8%E7%9B%B8%E4%BC%BC%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非局部相似性;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8E%E7%A7%A9%E6%80%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">低秩性;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E4%BF%AE%E8%A1%A5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像修补;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    贾慧迪,硕士研究生,主要研究方向为计算机视觉、图像处理等．E-mail:jiahuidi@sia.cn.&lt;image id="223" type="formula" href="images/MSSB201910012_22300.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    陈希爱,博士研究生,主要研究方向为图像处理、噪声建模、图像视频恢复等．E-mail:chenxiai@sia.cn.&lt;image id="224" type="formula" href="images/MSSB201910012_22400.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    *韩志(通讯作者),博士,研究员,主要研究方向为计算机视觉、矩阵恢复、光照建模等．E-mail:hanzhi@sia.cn.&lt;image id="225" type="formula" href="images/MSSB201910012_22500.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    唐延东,博士,研究员,主要研究方向为机器人视觉、图像处理、模式识别等．E-mail:ytang@sia.cn.&lt;image id="226" type="formula" href="images/MSSB201910012_22600.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-31</p>

            </div>
                    <h1><b>Nonlocal Similarity Based Tensor Train Factorization for Color Image Completion</b></h1>
                    <h2>
                    <span>JIA Huidi</span>
                    <span>HAN Zhi</span>
                    <span>CHEN Xiai</span>
                    <span>TANG Yandong</span>
            </h2>
                    <h2>
                    <span>State Key Laboratory of Robotics,Shenyang Institute of Automation,Chinese Academy of Sciences</span>
                    <span>Institutes for Robotics and Intelligent Manufacturing,Chinese Academy of Sciences</span>
                    <span>University of Chinese Academy of Sciences</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In data acquisition and transformation, the data are more or less lost. Therefore, the results of computer vision tasks such as object recognition and tracking are affected. In a natural image, there are many similar structures and patterns with repeated features. With these similar structures and patterns, a method of nonlocal similarity based tensor train factorization for color image completion is proposed. Nonlocal similarity of images are employed to exploit the low rank feature, and modeling is conducted by tensor train factorization to further mine low rank information through transforming a low-order tensor to higher-order one. Experimental results validate the proposed method in image completion.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Tensor%20Train%20Factorization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Tensor Train Factorization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nonlocal%20Similarity&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nonlocal Similarity;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Low%20Rank&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Low Rank;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20Completion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image Completion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    JIA Huidi,master student. Her research interests include computer vision and image processing.;
                                </span>
                                <span>
                                    CHEN Xiai,Ph.D. candidate. Her research interests include image processing, noise modeling and image/video completion.;
                                </span>
                                <span>
                                    HAN Zhi(Corresponding author),Ph. D., professor. His research interests include computer vision,matrix completion and illumination modeling.;
                                </span>
                                <span>
                                    TANG Yandong,Ph.D.,professor. His research interests include robot vision,image processing and pattern recognition.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-01-31</p>
                            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="64">在数据传输或转换过程中经常会出现部分数据丢失的问题.数据补全是指根据一些先验信息从可观测到的数据中恢复丢失的数据.作为计算机视觉的底层任务,图像数据补全对目标识别与跟踪等任务具有重要的应用价值,因此是计算机视觉领域的主要研究课题之一.</p>
                </div>
                <div class="p1">
                    <p id="65">低秩矩阵补全方法<citation id="284" type="reference"><link href="234" rel="bibliography" /><link href="236" rel="bibliography" /><link href="238" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>应用于图像的修补任务,在数据补全问题中取得一定效果,但处理多维数据时,基于矩阵的方法的效果并不理想.张量作为向量和矩阵的高阶推广,提供一种表示多维数据的更普适的方法.这种张量的表达形式能更好地保持多维数据的结构性,表达更丰富的全局信息.近年来,利用张量理论分析处理多维数据的思想在众多领域引起关注,如信号处理<citation id="282" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、计算机视觉<citation id="285" type="reference"><link href="242" rel="bibliography" /><link href="244" rel="bibliography" /><link href="246" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>及数据挖掘<citation id="283" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等.低秩张量补全方法开始应用于多维数据处理中,并取得比矩阵方法更优的效果.</p>
                </div>
                <div class="p1">
                    <p id="66">张量补全的成功恢复主要依赖于低秩假设.不同于矩阵低秩分解的唯一性,张量分解方式并不唯一.针对不同的张量分解形式,出现一系列的张量补全方法.简单低秩张量补全算法(Simple Low Rank Tensor Completion, SiLRTC)<citation id="286" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>将核范数的概念推广到张量中,用于图像修补.低秩张量补全的并行矩阵分解(Parallel Matrix Factorization for Low Rank Tensor Completion, TMac)<citation id="287" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>通过对潜在张量的全模矩阵进行低秩矩阵分解以完成图像修补.</p>
                </div>
                <div class="p1">
                    <p id="67">目前广泛用于张量补全的张量分解方式主要有如下3种:CP分解<citation id="288" type="reference"><link href="254" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,Tucker分解<citation id="289" type="reference"><link href="256" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和张量火车(Tensor Train, TT)分解<citation id="290" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.基于CP分解的方法将张量分解为若干个秩一张量的和,其中秩一张量的个数为张量的CP秩.CP加权优化(CP Weighted Optimization, CPWOPT)<citation id="291" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>将CP模型表示为只对已知项进行建模的加权最小二乘问题.虽然基于CP分解的方法只需要很少的存储空间,但CP秩的计算是一个NP难题<citation id="292" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>,尤其对于缺失数据.基于Tucker分解的张量补全方法将张量表示成一个核心张量和若干个因子矩阵的乘积,对因子矩阵进行秩的最小化约束.Tucker分解方式的出现解决CP秩的计算问题,Chen等<citation id="293" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出同时进行张量分解与补全(Simultaneous Tensor Decomposition and Completion, STDC)的方法,对Tucker分解的因子采用迹范数最小化以完成图像修补的任务,但通过Tucker分解得到的因子矩阵往往不均衡,而一般认为只有在矩阵较均衡的情况下,矩阵秩的最小化才更有效.张量火车分解方式的出现解决因子矩阵不均衡的问题,近年来逐渐应用于图像处理问题<citation id="294" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>.张量火车分解下的模式矩阵比Tucker分解更均衡,能更好地利用均衡模式的信息,各模式矩阵之间具有更强的相关性.</p>
                </div>
                <div class="p1">
                    <p id="68">上述图像修补方法都是基于全局的低秩张量补全算法,但图像中常存在许多相似的区域称为非局部相似性<citation id="297" type="reference"><link href="268" rel="bibliography" /><link href="270" rel="bibliography" /><link href="272" rel="bibliography" /><link href="274" rel="bibliography" /><sup>[<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>,<a class="sup">21</a>]</sup></citation>,是一种基于块的有效先验.三维块匹配算法(Block Matching 3D, BM3D)<citation id="295" type="reference"><link href="270" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>通过将图像中的相似块进行堆叠形成一个3维数组,再对数组进行协同滤波,获得较好的去噪效果.许多算法都依赖于图像的非局部相似先验.将数据中的非局部相似块拉成向量后排列成矩阵,该矩阵具有低秩性和稀疏的奇异值.这种低秩矩阵近似方法可用于图像及视频的去噪和修补工作,这一假设在文献<citation id="296" type="reference">[<a class="sup">21</a>]</citation>中得到验证,并称为非局部谱段先验.</p>
                </div>
                <div class="p1">
                    <p id="69">为了充分利用图像的全局信息和局部信息,在具有较均衡分解模式的火车张量分解方式的基础上,引入非局部自相似性,进一步挖掘数据的低秩特性,由此提出基于非局部张量火车分解的张量补全方法.在张量火车分解模式矩阵下处理数据,由于模式矩阵具有良好的均衡性,从而使低秩约束更有效,同时有效利用张量的全局相关性.引入非局部相似性用于进一步挖掘张量火车分解下各模式矩阵的低秩特性,同时利用张量的全局信息和局部信息用于完成图像修补.最后通过实验验证本文方法的有效性.</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag">1 基于非局部张量火车分解的张量补全算法</h3>
                <h4 class="anchor-tag" id="71" name="71"><b>1.1</b> 低张量火车秩张量补全模型</h4>
                <div class="p1">
                    <p id="72">张量是矩阵的高维泛化,它的本质是一个多维数组,张量的阶或模就是它的维数.本文把标量看作零阶张量并使用小写字母(<i>x</i>,<i>y</i>,<i>z</i>,…)表示,向量和矩阵分别为一阶和二阶张量,分别使用黑体小写字母(<i><b>x</b></i>,<i><b>y</b></i>,<i><b>z</b></i>,…)和大写字母(<i><b>X</b></i>,<i><b>Y</b></i>,<i><b>Z</b></i>,…)表示.高阶(例如<i>N</i>阶)的张量可以表示为花体,如X∈<b>R</b><sup><i>I</i></sup><sub><sup>1</sup></sub><sup>×</sup><sup><i>I</i></sup><sub><sup>2</sup></sub><sup>×…×</sup><sup><i>I</i></sup><sub><sup><i>N</i></sup></sub>,它的元素表示为X<sub><i>i</i></sub><sub>1,</sub><sub><i>i</i></sub><sub>2,…,</sub><sub><i>ik</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="73">对于2个尺寸相同的张量X、Y,内积定义为</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>〈</mo><mtext>X</mtext><mo>,</mo><mtext>Y</mtext><mo>〉</mo><mo>∶</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>i</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></munder><mi>x</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>i</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></msub><mspace width="0.25em" /><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>i</mi><msub><mrow></mrow><mi>Κ</mi></msub></mrow></msub><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">相应的F-范数(Frobenius Norm)定义为</p>
                </div>
                <div class="p1">
                    <p id="76" class="code-formula">
                        <mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mtext>X</mtext><mo stretchy="false">∥</mo><msub><mrow></mrow><mtext>F</mtext></msub><mo>=</mo><msqrt><mrow><mo>〈</mo><mtext>X</mtext><mo>,</mo><mtext>X</mtext><mo>〉</mo></mrow></msqrt><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="77">张量火车分解是将一个高阶张量分解为一组三阶张量,对于一个给定的张量A,可表示为</p>
                </div>
                <div class="p1">
                    <p id="78" class="code-formula">
                        <mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mtext>A</mtext><mo stretchy="false">(</mo><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>i</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>α</mi><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mi>α</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋯</mo><mo>,</mo><mi>α</mi><msub><mrow></mrow><mi>d</mi></msub></mrow></munder><mtext>G</mtext></mstyle><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mi>α</mi><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mi>i</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>α</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mtext>G</mtext><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>α</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>i</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>α</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>⋯</mo><mtext>G</mtext><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">(</mo><mi>α</mi><msub><mrow></mrow><mrow><mi>d</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo><mi>i</mi><msub><mrow></mrow><mi>d</mi></msub><mo>,</mo><mi>α</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="79">其中边界条件<i>α</i><sub>0</sub>=<i>α</i><sub><i>d</i></sub>=1.向量<i><b>r</b></i>=(<i>α</i><sub>1</sub>,<i>α</i><sub>2</sub>,…,<i>α</i><sub><i>d</i></sub><sub>-1</sub>)为张量的TT秩,<i>α</i><sub><i>i</i></sub>为模式<i>i</i>标准展开矩阵的秩.</p>
                </div>
                <div class="p1">
                    <p id="80">由于<i>α</i><sub>0</sub>=<i>α</i><sub><i>d</i></sub>=1,这种分解可使用线性张量网络的图形化表示.以一个五阶张量为例,图1中有2种类型的节点:矩形包含空间索引<i>i</i><sub><i>k</i></sub>和一些辅助索引<i>α</i><sub><i>k</i></sub><sub>-1</sub>,<i>α</i><sub><i>k</i></sub>;圆圈只包含辅助索引<i>α</i><sub><i>k</i></sub>,表示两个张量间的连接,也就是TT秩.</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 五阶张量的火车张量分解示意图" src="Detail/GetImg?filename=images/MSSB201910012_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 五阶张量的火车张量分解示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Sketch map of tensor Train decomposition of the 5-order tensor</p>

                </div>
                <div class="p1">
                    <p id="83">设T∈<b>R</b><sup><i>I</i></sup><sub><sup>1</sup></sub><sup>×</sup><sup><i>I</i></sup><sub><sup>2</sup></sub><sup>…×</sup><sup><i>I</i></sup><sub><sup><i>N</i></sup></sub>为原始的数据张量,X∈<b>R</b><sup><i>I</i></sup><sub><sup>1</sup></sub><sup>×</sup><sup><i>I</i></sup><sub><sup>2</sup></sub><sup>…×</sup><sup><i>I</i></sup><sub><sup><i>N</i></sup></sub>中属于集合<i>Ω</i>的元素已知,其余位置的元素丢失.张量补全就是根据缺失的数据张量恢复完整的张量,使用约束张量秩的方式实现缺失数据的补全:</p>
                </div>
                <div class="area_img" id="227">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201910012_22700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="86">对于式(1),通过优化如下的张量火车秩以解决,即</p>
                </div>
                <div class="area_img" id="228">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201910012_22800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="89">其中,<i>α</i><sub><i>k</i></sub>表示每个模式矩阵的权重,<mathml id="185"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mn>1</mn><mo>.</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub></mrow></math></mathml>表示按照张量火车分解展开得到的标准模式<i>k</i>矩阵.由于(‖<i><b>X</b></i><sub>[1]</sub>‖<sub>*</sub>,‖<i><b>X</b></i><sub>[2]</sub>‖<sub>*</sub>,…,‖<i><b>X</b></i><sub>[</sub><sub><i>K</i></sub><sub>-1]</sub>‖<sub>*</sub>)包含所有模式间的相关性,因此可以得到张量的全局相关性.</p>
                </div>
                <div class="p1">
                    <p id="90">由于函数rank()是非凸的,式(2)仍然难以求解.针对这个问题,利用核范数‖·‖<sub>*</sub>近似矩阵的秩rank()<citation id="300" type="reference"><link href="234" rel="bibliography" /><link href="276" rel="bibliography" /><link href="278" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>:</p>
                </div>
                <div class="area_img" id="91">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201910012_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="93" name="93"><b>1.2</b> 非局部张量火车分解模型</h4>
                <div class="p1">
                    <p id="94">为了利用非局部相似块间的低秩特性,如图2所示,将得到的模式矩阵<i><b>X</b></i><sub>[</sub><sub><i>k</i></sub><sub>]</sub>分割成一系列矩阵块<i>Ψ</i>={<i><b>y</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>∈<b>R</b><sup><i>b</i></sup><sup>×</sup><sup><i>b</i></sup>}<mathml id="186"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>Ρ</mi></msubsup></mrow></math></mathml>,其中,<i>b</i>为矩阵块的大小,<i>P</i>为包括灰色部分(Overlap)的矩阵块数量.按照矩阵块之间的相似性大小找到与目标块<i><b>y</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>最相似的<i>N</i>-1个矩阵块.将这些矩阵向量化,并按照相似性大小与目标块向量排列,得到一个大小为<i>b</i><sup>2</sup>×<i>N</i>的新矩阵<i><b>Y</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>=[<i><b>y</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>,<i><b>Y</b></i><mathml id="187"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Ν</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>],其中,<i><b>Y</b></i><mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Ν</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>=[<i><b>y</b></i><mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mn>1</mn></msubsup></mrow></math></mathml>,<i><b>y</b></i><mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mn>2</mn></msubsup></mrow></math></mathml>,…,<i><b>y</b></i><mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Ν</mi><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>]表示与目标块最相似的前<i>N</i>-1个矩阵块向量的集合.</p>
                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 非局部张量火车算法" src="Detail/GetImg?filename=images/MSSB201910012_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 非局部张量火车算法  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Sketch map of nonlocal tensor train method</p>

                </div>
                <div class="p1">
                    <p id="96">根据非局部相似的思想,利用<i>P</i>个新矩阵核范数的加和以度量整个模式矩阵的低秩性,因此将非局部张量火车分解下的模式矩阵<i><b>X</b></i><sub>[</sub><sub><i>k</i></sub><sub>]</sub>的核范数记作‖<i><b>X</b></i><sub>[</sub><sub><i>k</i></sub><sub>]</sub>‖<sub><i>Nonlocal</i></sub><sub>-*</sub>,并得到如下定义:</p>
                </div>
                <div class="p1">
                    <p id="97"><mathml id="192"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mrow><mi>Ν</mi><mi>o</mi><mi>n</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>l</mi><mo>-</mo><mo>*</mo></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>Ρ</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub></mrow></math></mathml>.      (4)</p>
                </div>
                <div class="p1">
                    <p id="98">由式(3)、式(4),针对张量补全任务提出模型:</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mtext>X</mtext></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mrow><mi>Ν</mi><mi>o</mi><mi>n</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>l</mi><mo>-</mo><mo>*</mo></mrow></msub></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mtext>X</mtext><msub><mrow></mrow><mi>Ω</mi></msub><mo>=</mo><mtext>Τ</mtext><msub><mrow></mrow><mi>Ω</mi></msub><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">根据式(4)的定义</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mrow><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo></mrow></msub><mo stretchy="false">∥</mo></mrow><msub><mrow></mrow><mrow><mi>Ν</mi><mi>o</mi><mi>n</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>l</mi><mo>-</mo><mo>*</mo></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>Ρ</mi></munderover><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mo>*</mo></msub><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">这个模型也可以写成如下形式:</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></msub></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Κ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><mi>Ρ</mi></munderover><mrow><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">∥</mo></mrow></mstyle><msub><mrow></mrow><mo>*</mo></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">Y</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mi>Ω</mi></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>k</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mi>Ω</mi></mrow></msub><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="104">其中,<i><b>Y</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub><sub><i>Ω</i></sub>=<i><b>T</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub><sub><i>Ω</i></sub>与X<sub><i>Ω</i></sub>=T<sub><i>Ω</i></sub>等价,表示缺失张量与原始张量经过同样变换后,每个相似块上已知元素的值与原始张量对应位置上的值相等.</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>1.3</b> 算法步骤</h4>
                <div class="p1">
                    <p id="106">因为各模式矩阵都由张量X火车分解得到,各模式矩阵之间相互依赖而难以求解,于是引入辅助变量<i><b>M</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>,得</p>
                </div>
                <div class="area_img" id="107">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201910012_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="109">根据拉格朗日乘数法将式(5)写成</p>
                </div>
                <div class="area_img" id="229">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201910012_22900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="112">其中<i>λ</i>为低秩项的调优参数.对于式(5)的求解已经在文献<citation id="301" type="reference">[<a class="sup">7</a>]</citation>和文献<citation id="302" type="reference">[<a class="sup">8</a>]</citation>中证明,<i><b>Y</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>的优化如下:</p>
                </div>
                <div class="p1">
                    <p id="113"><i><b>Y</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>=D<sub><i>τ</i></sub>(<i><b>M</b></i><sub><i>k</i></sub><sub>(</sub><sub><i>p</i></sub><sub>)</sub>), <i>τ</i>=<i>λ</i>,      (7)</p>
                </div>
                <div class="p1">
                    <p id="114">其中,D<sub><i>T</i></sub>(<i>X</i>)为收缩(Shrinkage)操作<citation id="303" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>,定义为</p>
                </div>
                <div class="p1">
                    <p id="115">D<sub><i>τ</i></sub>(<i><b>X</b></i>)=<i><b>U</b></i><i>Σ</i><sub><i>τ</i></sub><i><b>V</b></i><sup>T</sup>.</p>
                </div>
                <div class="p1">
                    <p id="116"><i><b>X</b></i>的奇异值分解一般写成<i><b>X</b></i>=<i><b>UΣV</b></i><sup>T</sup>,其中</p>
                </div>
                <div class="p1">
                    <p id="117"><i>Σ</i><sub><i>τ</i></sub>=diag(max(<i>σ</i><sub><i>i</i></sub>-<i>τ</i>,0)).</p>
                </div>
                <div class="p1">
                    <p id="118">基于非局部张量火车分解的张量补全算法步骤如下所示.</p>
                </div>
                <div class="area_img" id="230">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201910012_23000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="230">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201910012_23001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="135" name="135" class="anchor-tag">2 实验及结果分析</h3>
                <div class="p1">
                    <p id="136">在彩色图像真实数据上验证本文算法性能.对比算法如下:基于张量核范数的SiLRTC<citation id="304" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,利用潜在张量的全模矩阵进行图像恢复的TMac<citation id="305" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>,同时进行张量分解与补全(Simultaneous Tensor Decom-position and Completion, STDC)<citation id="306" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>,同时利用局部平滑先验和张量树(Tensor Tree)分解的光滑低秩张量树补全(Smooth Low Rank Tensor Tree Comple-tion, STTC)<citation id="307" type="reference"><link href="280" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>.采用相对平方误差(Relative Square Error, RSE)和峰值信噪比(Peak Signal to Noise Ratio, PSNR)评价恢复后的图像.恢复的张量X与原始张量T之间的RSE定义如下:</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mtext>X</mtext><mo>-</mo><mtext>Τ</mtext><mo stretchy="false">∥</mo><msub><mrow></mrow><mtext>F</mtext></msub></mrow><mrow><mo stretchy="false">∥</mo><mtext>Τ</mtext><mo stretchy="false">∥</mo><msub><mrow></mrow><mtext>F</mtext></msub></mrow></mfrac><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="138">PSNR的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="139" class="code-formula">
                        <mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>S</mi><mi>Ν</mi><mi>R</mi><mo>=</mo><mn>1</mn><mn>0</mn><mrow><mi>lg</mi></mrow><mfrac><mrow><mrow><mn>2</mn><mn>5</mn><mn>5</mn></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mfrac><mn>1</mn><mrow><mi>w</mi><mi>h</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>w</mi><mi>h</mi></mrow></munderover><mrow><mo stretchy="false">(</mo><mtext>X</mtext><mo>-</mo><mtext>Τ</mtext><mo stretchy="false">)</mo></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="140">其中<i>w</i>、<i>h</i>分别为图像的宽度、高度.</p>
                </div>
                <div class="p1">
                    <p id="141">本文共选取Airplane、Barbara、Lena、Peppers、Sailboat这5幅常用的,大小为256×256×3的8位RGB图像验证本文算法.所有实验均在8.00 GB内存和Intel(R) Core(TM) i7-7700 处理器的计算机上进行.</p>
                </div>
                <div class="p1">
                    <p id="142">实验参数设置如下:对图像进行张量火车分解展开后的各模式矩阵相似块的大小设定为12×12,overlap的大小为4,以256×256×3的图像为例,每个模式矩阵共提取<i>P</i>=8 194个相似块.每个矩阵块对应相似块的个数<i>N</i>=30.本文算法每次迭代的时间复杂度为<i>O</i>(<i>K</i>(<i>P</i><sup>3</sup>+1)),其中,<i>K</i>为模式矩阵个数,<i>P</i>为每个模式矩阵中矩阵块的个数.</p>
                </div>
                <div class="p1">
                    <p id="143">对于5幅图像,当缺失率为0.3和0.5时进行对比实验,计算RSE和PSNR,结果如表1和表2所示.由表可知,本文算法在不同缺失率下,均优于SiLRTC、TMac、STDC及STTC.</p>
                </div>
                <div class="p1">
                    <p id="144">图3和图4分别为5种算法在5幅图像上当缺失率为0.3和0.5时的恢复效果.由图可看出,本文算法在视觉上恢复效果更好.图5为图像局部的恢复效果,显然,本文算法更有效地保留图像的细节.</p>
                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表1 彩色图像补全中5种算法的RSE值对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 RSE comparison of 5 algorithms of color image completion</p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td>图像</td><td>缺失率</td><td>SiLRTC</td><td>TMac</td><td>STDC</td><td>STTC</td><td>本文算法</td></tr><tr><td><br />Airplane</td><td>0.3<br />0.5</td><td>0.0258<br />0.0445</td><td>0.0232<br />0.0461</td><td>0.0400<br />0.0490</td><td>0.0291<br />0.0435</td><td><b>0.0196<br />0.0381</b></td></tr><tr><td><br />Barbara</td><td>0.3<br />0.5</td><td>0.0405<br />0.0680</td><td>0.0396<br />0.0728</td><td>0.0538<br />0.0657</td><td>0.0462<br />0.0638</td><td><b>0.0325<br />0.0605</b></td></tr><tr><td><br />Lena</td><td>0.3<br />0.5</td><td>0.0326<br />0.0553</td><td>0.0325<br />0.0606</td><td>0.0467<br />0.0574</td><td>0.0332<br />0.0478</td><td><b>0.0235<br />0.0443</b></td></tr><tr><td><br />Peppers</td><td>0.3<br />0.5</td><td>0.0417<br />0.0719</td><td>0.0371<br />0.0710</td><td>0.0533<br />0.0633</td><td>0.0416<br />0.0595</td><td><b>0.0341<br />0.0574</b></td></tr><tr><td><br />Sailboat</td><td>0.3<br />0.5</td><td>0.0512<br />0.0824</td><td>0.0477<br />0.0847</td><td>0.0517<br />0.0796</td><td>0.0517<br /><b>0.0701</b></td><td><b>0.0430</b><br />0.0749</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="146">
                    <p class="img_tit"><b>表2 彩色图像补全中5种算法的PSNR值对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 PSNR comparison of 5 algorithms of color image completion</p>
                    <p class="img_note"></p>
                    <table id="146" border="1"><tr><td>图像</td><td>缺失率</td><td>SiLRTC</td><td>TMac</td><td>STDC</td><td>STTC</td><td>本文算法</td></tr><tr><td><br />Airplane</td><td>0.3<br />0.5</td><td>36.7762<br />31.5337</td><td>37.2188<br />30.7246</td><td>33.1007<br />30.7747</td><td>36.0791<br />32.1424</td><td><b>38.7593<br />32.7415</b></td></tr><tr><td><br />Barbara</td><td>0.3<br />0.5</td><td>37.8507<br />32.7967</td><td>37.0913<br />31.4407</td><td>35.4185<br />32.9475</td><td>36.6303<br />33.2421</td><td><b>39.2810<br />33.4313</b></td></tr><tr><td><br />Lena</td><td>0.3<br />0.5</td><td>37.6592<br />32.5865</td><td>37.1803<br />31.2319</td><td>34.6047<br />32.2142</td><td>37.6468<br />33.9793</td><td><b>40.3175<br />34.4269</b></td></tr><tr><td><br />Peppers</td><td>0.3<br />0.5</td><td>36.4218<br />31.2948</td><td>37.4054<br />31.3529</td><td>34.6565<br />32.6923</td><td>36.1824<br />32.7845</td><td><b>38.0402<br />33.2311</b></td></tr><tr><td><br />Sailboat</td><td>0.3<br />0.5</td><td>34.1296<br />29.5110</td><td>34.4275<br />28.7769</td><td>32.2895<br />29.8189</td><td>34.0258<br /><b>30.9431</b></td><td><b>35.2901</b><br />30.0255</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="231">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_23100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 缺失率为0.3时5种算法的恢复效果对比" src="Detail/GetImg?filename=images/MSSB201910012_23100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 缺失率为0.3时5种算法的恢复效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_23100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Comparison of completion results of 5 methods with missing rate of 0.3</p>

                </div>
                <div class="area_img" id="231">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_23101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 缺失率为0.3时5种算法的恢复效果对比" src="Detail/GetImg?filename=images/MSSB201910012_23101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 缺失率为0.3时5种算法的恢复效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_23101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Comparison of completion results of 5 methods with missing rate of 0.3</p>

                </div>
                <div class="area_img" id="232">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_23200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 缺失率为0.5时5种算法的恢复效果对比" src="Detail/GetImg?filename=images/MSSB201910012_23200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 缺失率为0.5时5种算法的恢复效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_23200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Comparison of completion results of 5 methods with missing rate of 0.5</p>

                </div>
                <div class="area_img" id="232">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_23201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 缺失率为0.5时5种算法的恢复效果对比" src="Detail/GetImg?filename=images/MSSB201910012_23201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 缺失率为0.5时5种算法的恢复效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_23201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Comparison of completion results of 5 methods with missing rate of 0.5</p>

                </div>
                <div class="area_img" id="233">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_23300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 缺失率为0.5时3种算法部分图像局部细节恢复效果" src="Detail/GetImg?filename=images/MSSB201910012_23300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 缺失率为0.5时3种算法部分图像局部细节恢复效果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_23300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Completion results of local details obtained by 3 methods with missing rate of 0.5</p>

                </div>
                <div class="p1">
                    <p id="180">图6为缺失率分别为0.3和0.5时不同矩阵块大小(从4×4到14×14)对实验结果的影响.由图可看出,矩阵块大小不同时实验结果有所变化,但仍保持较高的PSNR值,表明本文算法针对不同矩阵块大小具有一定的鲁棒性.</p>
                </div>
                <div class="area_img" id="181">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910012_181.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同缺失率下矩阵块大小对实验结果的影响" src="Detail/GetImg?filename=images/MSSB201910012_181.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同缺失率下矩阵块大小对实验结果的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910012_181.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Effect of patch size on experimental results with different missing rates</p>

                </div>
                <h3 id="183" name="183" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="184">针对图像数据缺失修补问题,本文提出非局部张量火车分解方法.利用张量火车分解下模式矩阵的均衡性以提高分解算法有效性,同时利用非局部相似块进一步挖掘各模式矩阵之间的相似性结构信息,从而有效利用数据中蕴含的低秩特性,实现图像缺失数据的有效修补.本文方法在多幅RGB彩色图像的不同缺失率下均取得不错的恢复效果.针对高缺失率问题,拟在下一步工作中挖掘图像中更多的先验信息,实现数据的有效修补.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="234">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A singular value thresholding algorithm for matrix completion">

                                <b>[1]</b> CAI J F,CANDÉS E J,SHEN Z W.A Singular Value Thresholding Algorithm for Matrix Completion.SIAM Journal on Optimization,2010,20(4):1956-1982.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low-rank matrix completion using alternating minimization">

                                <b>[2]</b> JAIN P,NETRAPALLI P,SANGHAVI S.Low-Rank Matrix Completion Using Alternating Minimization // Proc of the 45th Annual ACM Symposium on Theory of Computing.New York,USA:ACM,2013:665-674.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast and accurate matrix completion via truncated nuclear norm regularization">

                                <b>[3]</b> HU Y,ZHANG D B,YE J P,et al.Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization.IEEE Transactions on Pattern Analysis and Machine Intelligence,2013,35(9):2117-2130.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PLTD:Patch-based low-rank tensor decomposition for hyperspectral images">

                                <b>[4]</b> DU B,ZHANG M F,ZHANG L F,et al.PLTD:Patch-Based Low-Rank Tensor Decomposition for Hyperspectral Images.IEEE Transa-ctions on Multimedia,2017,19(1):67-79.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESCDE43A03A8F2F7EEF442336E98D9EF87&amp;v=MTk3NzJ3N20yd3FBPU5pZk9mY0RNYTlYUDNvOUdGZU41RGdvK3VtTmw3anQvUzN6azJSczlEYnZoTTdLWUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> HE Z,HU J,WANG Y W.Low-Rank Tensor Learning for Classification of Hyperspectral Image with Limited Labeled Samples.Signal Processing,2018,145:12-25.
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC94BC9C9E3486B3A83B039E0914BC078&amp;v=MDkzMzEwZmNEblJiMlhDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N20yd3FBPU5pZk9mY0N4R3FPL3B2eE1FZWdMQkhwTHpHY2I2VTE5UzNhWHJCcw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> GUO H W,WU X Y,FENG W.Multi-stream Deep Networks for Human Action Classification with Sequential Tensor Decomposition.Signal Processing,2017,140:198-206.
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES6D75FC531E6AF6064D55A89B56C90D97&amp;v=MTk0OTZ3N20yd3FBPU5pZk9mYlhNR2RTNjNJcEdaWjRKZlFvL3p4QVhuanA0T1hmcjNoY3pDcnVVTWJPWUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> VIGNERON V,KODEWITZ A,DA COSTA M N,et al.Non-negative Sub-tensor Ensemble Factorization(NsTEF) Algorithm:A New Incremental Tensor Factorization for Large Data Sets.Signal Proce-ssing,2018,144:77-86.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM91179A4903A46131E60661DC2C5CE4A4&amp;v=MzE1OTdNSGhRY3ViQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtMndxQT1OaWZJWTdxNUg5YkYzb3RNWk9oK0NIbzR6QmRtN0Q5N1RuNlczeEJHZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> PAPALEXAKIS E E,FALOUTSOS C,SIDIROPOULOS N D.Tensors for Data Mining and Data Fusion:Models,Applications,and Scalable Algorithms.ACM Transactions on Intelligent Systems and Technology,2016,8(2).DOI:10.1145/2915921.
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor Completion for Estimating Missing Values in Visual Data">

                                <b>[9]</b> LIU J,MUSIALSKI P,WONKA P,et al.Tensor Completion for Estimating Missing Values in Visual Data // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2009:2114-2121.
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Parallel matrix factorization for low-rank tensor completion">

                                <b>[10]</b> XU Y X,HAO R R,YIN W T,et al.Parallel Matrix Factorization for Low-Rank Tensor Completion.Inverse Problems and Imaging,2015,9(2):601-624.
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001069213&amp;v=MTIwNjM5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGQ0hsVkw3QklsWT1OajdCYXJPNEh0SE5yNGxNWnVvTVkzazV6QmRoNGo5&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> CARROLL J D,CHANG J J.Analysis of Individual Differences in Multidimensional Scaling via an N-Way Generalization of "Eckart-Young" Decomposition.Psychometrika,1970,35(3):283-319.
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001068384&amp;v=MjkwNDlMN0JJbFk9Tmo3QmFyTzRIdEhOcjRsTlorTUxZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZDSGxW&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> TUCKER L R.Some Mathematical Notes on Three-Mode Factor Analysis.Psychometrika,1966,31(3):279-311.
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor-train decomposition">

                                <b>[13]</b> OSELEDETS I V.Tensor-Train Decomposition.SIAM Journal on Scientific Computing,2011,33(5):2295-2317.
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300184801&amp;v=Mjc3MjBUTW53WmVadUh5am1VTGJJSjE4ZGFCbz1OaWZPZmJLN0h0RE9ySTlGWmVNTEJIdzRvQk1UNlQ0UFFIL2lyUmRHZXJxUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> ACAR E,DUNLAVY D M,KOLDA T G,et al.Scalable Tensor Factorizations for Incomplete Data.Chemometrics and Intelligent Laboratory Systems,2011,106(1):41-56.
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJST15012900404745&amp;v=MjY1NDdUNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKMThkYUJvPU5pZlllcks5SHRET3BvOUZZT3NMQzNnOG9CTQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> KOLDA T G,BADER B W.Tensor Decompositions and Applications.SIAM Review,2009,51(3):455-500.
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Simultaneous tensor decomposition and completion using factor priors">

                                <b>[16]</b> CHEN Y L,HSU C T,LIAO H Y M.Simultaneous Tensor Decomposition and Completion Using Factor Priors.IEEE Transactions on Pattern Analysis and Machine Intelligence,2014,36(3):577-591.
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient tensor completion for color image and video recovery:Low-rank tensor train">

                                <b>[17]</b> BENGUA J A,PHIEN H N,TUAN H D,et al.Efficient Tensor Completion for Color Image and Video Recovery:Low-Rank Tensor Train.IEEE Transactions on Image Processing,2017,26(5):2466-2479.
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A non-local algorithm for image denoising">

                                <b>[18]</b> BUADES A,COLL B,MOREL J M.A Non-local Algorithm for Image Denoising // Proc of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2005,II:60-65
                            </a>
                        </p>
                        <p id="270">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image denoising by sparse 3-D transform-domain collaborative filtering">

                                <b>[19]</b> DABOV K,FOI A,KATKOVNIK V,et al.Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering.IEEE Transac-tions on Image Processing,2007,16(8):2080-2095.
                            </a>
                        </p>
                        <p id="272">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Non-local sparse models for image restoration">

                                <b>[20]</b> MAIRAL J,BACH F,PONCE J,et al.Non-local Sparse Models for Image Restoration // Proc of the 12th IEEE International Conference on Computer Vision.Washington,USA:IEEE,2009:2272-2279.
                            </a>
                        </p>
                        <p id="274">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlocal Spectral Prior Model for Low-Level Vision">

                                <b>[21]</b> WANG S L,LEI Z,YAN L.Nonlocal Spectral Prior Model for Low-Level Vision // Proc of the 11th Asian Conference on Computer Vision.Berlin,Germany:Springer,2012,III:231-244.
                            </a>
                        </p>
                        <p id="276">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fixed point and Bregman iterative methods for matrix rank minimization">

                                <b>[22]</b> MA S Q,GLODFARB D,CHEN L F.Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization.Mathematical Programming,2009,128(1/2):321-353.
                            </a>
                        </p>
                        <p id="278">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Consistency of trace norm minimization">

                                <b>[23]</b> BACH F R.Consistency of Trace Norm Minimization.Journal of Machine Learning Research,2008,9:1019-1048.
                            </a>
                        </p>
                        <p id="280">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Completion Using Low Tensor Tree Rank and Total Variation Minimization">

                                <b>[24]</b> LIU Y P,LONG Z,ZHU C.Image Completion Using Low Tensor Tree Rank and Total Variation Minimization.IEEE Transactions on Multimedia,2019,21(2):338-350.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201910012" />
        <input id="dpi" type="hidden" value="96" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201910012&amp;v=MTA1MzlHRnJDVVJMT2VaZVJuRnkva1dyM0FLRDdZYkxHNEg5ak5yNDlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
