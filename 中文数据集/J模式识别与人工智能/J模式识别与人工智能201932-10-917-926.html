<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131461071280000%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201910006%26RESULT%3d1%26SIGN%3dCmfs5jn6ChZQvrfRBkCNW3r9GXM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201910006&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201910006&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201910006&amp;v=MDAyOTJGeS9rV3J6T0tEN1liTEc0SDlqTnI0OUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#371" data-title="1 相关工作 ">1 相关工作</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#372" data-title="&lt;b&gt;1.1&lt;/b&gt; 图像块提取"><b>1.1</b> 图像块提取</a></li>
                                                <li><a href="#398" data-title="&lt;b&gt;1.2&lt;/b&gt; 图像块转置学习"><b>1.2</b> 图像块转置学习</a></li>
                                                <li><a href="#413" data-title="&lt;b&gt;1.3&lt;/b&gt; 图像去噪去模糊"><b>1.3</b> 图像去噪去模糊</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#426" data-title="2 基于图像组转置学习及非凸约束的图像去噪去模糊算法 ">2 基于图像组转置学习及非凸约束的图像去噪去模糊算法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#429" data-title="&lt;b&gt;2.1&lt;/b&gt; 图像分解与去噪去模糊过程"><b>2.1</b> 图像分解与去噪去模糊过程</a></li>
                                                <li><a href="#446" data-title="&lt;b&gt;2.2&lt;/b&gt; 系数求解过程"><b>2.2</b> 系数求解过程</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#502" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#530" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#609" data-title="图1 图像Barbara的块匹配过程与数值对比">图1 图像Barbara的块匹配过程与数值对比</a></li>
                                                <li><a href="#610" data-title="图2 σ=20时本文算法对House图像的去噪结果">图2 σ=20时本文算法对House图像的去噪结果</a></li>
                                                <li><a href="#611" data-title="图3 σ=20时本文算法对House图像的去模糊结果">图3 σ=20时本文算法对House图像的去模糊结果</a></li>
                                                <li><a href="#612" data-title="图4 σ=30时6种算法对Couple图像的去噪结果">图4 σ=30时6种算法对Couple图像的去噪结果</a></li>
                                                <li><a href="#613" data-title="图5 σ=40时6种算法对图像Lax的去噪结果">图5 σ=40时6种算法对图像Lax的去噪结果</a></li>
                                                <li><a href="#522" data-title="&lt;b&gt;表1&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;20时6种算法图像去噪结果的PSNR值&lt;/b&gt;"><b>表1</b><i>σ</i>=<b>20时6种算法图像去噪结果的PSNR值</b></a></li>
                                                <li><a href="#523" data-title="&lt;b&gt;表2&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;30时6种算法图像去噪结果的PSNR值&lt;/b&gt;"><b>表2</b><i>σ</i>=<b>30时6种算法图像去噪结果的PSNR值</b></a></li>
                                                <li><a href="#524" data-title="&lt;b&gt;表3&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;40时6种算法图像去噪结果的PSNR值&lt;/b&gt;"><b>表3</b><i>σ</i>=<b>40时6种算法图像去噪结果的PSNR值</b></a></li>
                                                <li><a href="#525" data-title="&lt;b&gt;表4&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;50时6种算法图像去噪结果的PSNR值&lt;/b&gt;"><b>表4</b><i>σ</i>=<b>50时6种算法图像去噪结果的PSNR值</b></a></li>
                                                <li><a href="#526" data-title="&lt;b&gt;表5&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;20时6种算法图像去模糊结果的PSNR值&lt;/b&gt;"><b>表5</b><i>σ</i>=<b>20时6种算法图像去模糊结果的PSNR值</b></a></li>
                                                <li><a href="#527" data-title="&lt;b&gt;表6&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;30时6种算法图像去模糊结果的PSNR值&lt;/b&gt;"><b>表6</b><i>σ</i>=<b>30时6种算法图像去模糊结果的PSNR值</b></a></li>
                                                <li><a href="#528" data-title="&lt;b&gt;表7&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;40时6种算法图像去模糊结果的PSNR值&lt;/b&gt;"><b>表7</b><i>σ</i>=<b>40时6种算法图像去模糊结果的PSNR值</b></a></li>
                                                <li><a href="#529" data-title="&lt;b&gt;表8&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;50时6种算法图像去模糊结果的PSNR值&lt;/b&gt;"><b>表8</b><i>σ</i>=<b>50时6种算法图像去模糊结果的PSNR值</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="614">


                                    <a id="bibliography_1" title=" ZHA Z Y,ZHANG X G,WANG Q,et al.Group Sparsity Residual Constraint for Image Denoising with External Nonlocal Self-similarity Prior.Neurocomputing,2018,275:2294-2306." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES47CA6F48133A6CBEBA1F6FC393A7D400&amp;v=MTIzODJpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N20ydzY0PU5pZk9mYmUvYmFESzJZdE5aZWdNZlhwS3ZXTmhtejRMVGdtUnJ4czJDTFhnUWJxZkNPTnZGUw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         ZHA Z Y,ZHANG X G,WANG Q,et al.Group Sparsity Residual Constraint for Image Denoising with External Nonlocal Self-similarity Prior.Neurocomputing,2018,275:2294-2306.
                                    </a>
                                </li>
                                <li id="616">


                                    <a id="bibliography_2" title=" REN C,HE X H,NGUYEN T Q.Adjusted Non-local Regression and Directional Smoothness for Image Restoration.IEEE Transactions on Multimedia,2018,21(3):731-745." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adjusted non-local regression and directional smoothness for image restoration">
                                        <b>[2]</b>
                                         REN C,HE X H,NGUYEN T Q.Adjusted Non-local Regression and Directional Smoothness for Image Restoration.IEEE Transactions on Multimedia,2018,21(3):731-745.
                                    </a>
                                </li>
                                <li id="618">


                                    <a id="bibliography_3" title=" LIU L N,MA J W,PLONKA G.Sparse Graph-Regularized Dictionary Learning for Suppressing Random Seismic Noise.Geophysics,2018,83(3):V215-V231." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse Graph-Regularized Dictionary Learning for Suppressing Random Seismic Noise">
                                        <b>[3]</b>
                                         LIU L N,MA J W,PLONKA G.Sparse Graph-Regularized Dictionary Learning for Suppressing Random Seismic Noise.Geophysics,2018,83(3):V215-V231.
                                    </a>
                                </li>
                                <li id="620">


                                    <a id="bibliography_4" title=" XIE N,CHEN Y,LIU H.Nonlocal Low-Rank and Total Variation Constrained PET Image Reconstruction // Proc of the 24th International Conference on Pattern Recognition.Washington,USA:IEEE,2018:3874-3879." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlocal Low-Rank and Total Variation Constrained PET Image Reconstruction">
                                        <b>[4]</b>
                                         XIE N,CHEN Y,LIU H.Nonlocal Low-Rank and Total Variation Constrained PET Image Reconstruction // Proc of the 24th International Conference on Pattern Recognition.Washington,USA:IEEE,2018:3874-3879.
                                    </a>
                                </li>
                                <li id="622">


                                    <a id="bibliography_5" title=" PANG Z F,ZHOU Y M,WU T T,et al.Image Denoising via a New Anisotropic Total-Variation-Based Model.Signal Processing(Image Communication),2019,74:140-152." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Denoising via a New Anisotropic Total-Variation-Based Model">
                                        <b>[5]</b>
                                         PANG Z F,ZHOU Y M,WU T T,et al.Image Denoising via a New Anisotropic Total-Variation-Based Model.Signal Processing(Image Communication),2019,74:140-152.
                                    </a>
                                </li>
                                <li id="624">


                                    <a id="bibliography_6" title=" BAYER F M,KOZAKEVICIUS A J,CINTRA R J.An Iterative Wavelet Threshold for Signal Denoising.Signal Processing,2019,162:10-20." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Iterative Wavelet Threshold for Signal Denoising">
                                        <b>[6]</b>
                                         BAYER F M,KOZAKEVICIUS A J,CINTRA R J.An Iterative Wavelet Threshold for Signal Denoising.Signal Processing,2019,162:10-20.
                                    </a>
                                </li>
                                <li id="626">


                                    <a id="bibliography_7" title=" YANG J,FAN J F,AI D N,et al.Local Statistics and Non-local Mean Filter for Speckle Noise Reduction in Medical Ultrasound Image.Neurocomputing,2016,195:88-95." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES035767E441303647A036D6FC575260BC&amp;v=MTc0MjFIbVUzeGN5ZkxDU1JjanNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N20ydzY0PU5pZk9mYk83RzliS3FQcEJZT29NREg4L3l4Rmk2ang3UA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         YANG J,FAN J F,AI D N,et al.Local Statistics and Non-local Mean Filter for Speckle Noise Reduction in Medical Ultrasound Image.Neurocomputing,2016,195:88-95.
                                    </a>
                                </li>
                                <li id="628">


                                    <a id="bibliography_8" title=" WU Z X,POTTER T,WU D N,et al.Denoising High Angular Resolution Diffusion Imaging Data by Combining Singular Value Decomposition and Non-local Means Filter.Journal of Neuroscience Methods,2019,312:105-113." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES785E38ABC13D2657165EDD06DDDFE298&amp;v=MTg3MTZEY1RoUjdPWENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaHc3bTJ3NjQ9TmlmT2ZiU3dHNlRQcC80M0Yrb01lSDQveWhFUzdEb0lQQXZpcW1aQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         WU Z X,POTTER T,WU D N,et al.Denoising High Angular Resolution Diffusion Imaging Data by Combining Singular Value Decomposition and Non-local Means Filter.Journal of Neuroscience Methods,2019,312:105-113.
                                    </a>
                                </li>
                                <li id="630">


                                    <a id="bibliography_9" title=" DANIELYAN A,KATKOVNIK V,EGIAZARIAN K.BM3D Frames and Variational Image Deblurring.IEEE Transactions on Image Processing,2012,21(4):1715-1728." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=BM3D Frames and Variational Image Deblurring">
                                        <b>[9]</b>
                                         DANIELYAN A,KATKOVNIK V,EGIAZARIAN K.BM3D Frames and Variational Image Deblurring.IEEE Transactions on Image Processing,2012,21(4):1715-1728.
                                    </a>
                                </li>
                                <li id="632">


                                    <a id="bibliography_10" title=" LIU X M,ZHAI D M,ZHAO D B,et al.Progressive Image Denoising through Hybrid Graph Laplacian Regularization:A Unified Framework.IEEE Transactions on Image Processing,2014,23(4):1491-1503." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Progressive image denoising through hybrid graph laplacian regularization:a unified framework">
                                        <b>[10]</b>
                                         LIU X M,ZHAI D M,ZHAO D B,et al.Progressive Image Denoising through Hybrid Graph Laplacian Regularization:A Unified Framework.IEEE Transactions on Image Processing,2014,23(4):1491-1503.
                                    </a>
                                </li>
                                <li id="634">


                                    <a id="bibliography_11" title=" SHANG L,LIU S F,ZHOU Y,et al.Modified Sparse Representation Based Image Super-Resolution Reconstruction Method.Neurocomputing,2017,228:37-52." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES29960AB92B6A6E41F13A26047E97387D&amp;v=MTk3MTh3TVNubmlxQlZBY0xXWFRiM3JDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N20ydzY0PU5pZk9mYkd4RjlmTTN2MU1acGtKZlhwTXl4ZGw2eg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         SHANG L,LIU S F,ZHOU Y,et al.Modified Sparse Representation Based Image Super-Resolution Reconstruction Method.Neurocomputing,2017,228:37-52.
                                    </a>
                                </li>
                                <li id="636">


                                    <a id="bibliography_12" title=" 李小宝,郭立君,张荣,等.混合l&lt;sub&gt;2&lt;/sub&gt;/l&lt;sub&gt;1/2&lt;/sub&gt;范数的局部组稀疏表示方法.模式识别与人工智能,2018,31(9):773-785.(LI X B,GUO L J,ZHANG R,et al.Local Group Sparse Representation Method with Mixed l&lt;sub&gt;2&lt;/sub&gt;/l&lt;sub&gt;1/2&lt;/sub&gt; Norm.Pattern Recognition and Artificial Intelligence,2018,31(9):773-785.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201809001&amp;v=MTk4OTVxcUJ0R0ZyQ1VSTE9lWmVSbkZ5L2tXcnpPS0Q3WWJMRzRIOW5NcG85RlpZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         李小宝,郭立君,张荣,等.混合l&lt;sub&gt;2&lt;/sub&gt;/l&lt;sub&gt;1/2&lt;/sub&gt;范数的局部组稀疏表示方法.模式识别与人工智能,2018,31(9):773-785.(LI X B,GUO L J,ZHANG R,et al.Local Group Sparse Representation Method with Mixed l&lt;sub&gt;2&lt;/sub&gt;/l&lt;sub&gt;1/2&lt;/sub&gt; Norm.Pattern Recognition and Artificial Intelligence,2018,31(9):773-785.)
                                    </a>
                                </li>
                                <li id="638">


                                    <a id="bibliography_13" title=" ZHANG J,ZHAO D B,GAO W.Group-Based Sparse Representation for Image Restoration.IEEE Transactions on Image Proce-ssing,2014,23(8):3336-3351." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Group-based Sparse Representation for Image Restoration">
                                        <b>[13]</b>
                                         ZHANG J,ZHAO D B,GAO W.Group-Based Sparse Representation for Image Restoration.IEEE Transactions on Image Proce-ssing,2014,23(8):3336-3351.
                                    </a>
                                </li>
                                <li id="640">


                                    <a id="bibliography_14" title=" LIU H F,XIONG R Q,ZHANG J,et al.Image Denoising via Adaptive Soft-Thresholding Based on Non-local Samples // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2015:484-492." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image denoising via adaptive soft-thresholding based on non-local samples">
                                        <b>[14]</b>
                                         LIU H F,XIONG R Q,ZHANG J,et al.Image Denoising via Adaptive Soft-Thresholding Based on Non-local Samples // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2015:484-492.
                                    </a>
                                </li>
                                <li id="642">


                                    <a id="bibliography_15" title=" 阴盼强,路东明,袁渊.基于马氏距离的改进非局部均值图像去噪算法.计算机辅助设计与图形学学报,2016,28(3):404-410.(YIN P Q,LU D M,YUAN Y.An Improved Non-local Means Image De-noising Algorithm Using Mahalanobis Distance.Journal of Computer-Aided Design and Computer Graphics,2016,28(3):404-410.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201603004&amp;v=MDU0NDdlWmVSbkZ5L2tXcnpPTHo3QmFMRzRIOWZNckk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         阴盼强,路东明,袁渊.基于马氏距离的改进非局部均值图像去噪算法.计算机辅助设计与图形学学报,2016,28(3):404-410.(YIN P Q,LU D M,YUAN Y.An Improved Non-local Means Image De-noising Algorithm Using Mahalanobis Distance.Journal of Computer-Aided Design and Computer Graphics,2016,28(3):404-410.)
                                    </a>
                                </li>
                                <li id="644">


                                    <a id="bibliography_16" title=" RUSU C,THOMPSON J.Learning Fast Sparsifying Transforms.IEEE Transactions on Signal Processing,2017,65(16):4367-4378." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning Fast Sparsifying Transforms">
                                        <b>[16]</b>
                                         RUSU C,THOMPSON J.Learning Fast Sparsifying Transforms.IEEE Transactions on Signal Processing,2017,65(16):4367-4378.
                                    </a>
                                </li>
                                <li id="646">


                                    <a id="bibliography_17" title=" WEN B H,LI Y J,BRESLER Y.When Sparsity Meets Low-Rankness:Transform Learning with Non-local Low-Rank Constraintfor Image Restoration // Proc of the IEEE International Conference on Acoustics,Speech and Signal Processing.Washington,USA:IEEE,2017:2297-2301." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=When Sparsity Meets Low-Rankness:Transform Learning with Non-local Low-Rank Constraintfor Image Restoration">
                                        <b>[17]</b>
                                         WEN B H,LI Y J,BRESLER Y.When Sparsity Meets Low-Rankness:Transform Learning with Non-local Low-Rank Constraintfor Image Restoration // Proc of the IEEE International Conference on Acoustics,Speech and Signal Processing.Washington,USA:IEEE,2017:2297-2301.
                                    </a>
                                </li>
                                <li id="648">


                                    <a id="bibliography_18" title=" WANG Q,ZHANG X G,WU Y,et al.Non-Convex Weighted l&lt;sub&gt;p&lt;/sub&gt; Minimization Based Group Sparse Representation Framework for Image Denoising[J/OL].[2019-2-26].https://arxiv.org/pdf/1704.01429.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Non-Convex Weighted lp Minimization Based Group Sparse Representation Framework for Image Denoising">
                                        <b>[18]</b>
                                         WANG Q,ZHANG X G,WU Y,et al.Non-Convex Weighted l&lt;sub&gt;p&lt;/sub&gt; Minimization Based Group Sparse Representation Framework for Image Denoising[J/OL].[2019-2-26].https://arxiv.org/pdf/1704.01429.pdf.
                                    </a>
                                </li>
                                <li id="650">


                                    <a id="bibliography_19" title=" YANG J,LUO L,QIAN J J,et al.Nuclear Norm Based Matrix Regression with Applications to Face Recognition with Occlusion and Illumination Changes.IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(1):156-171." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nuclear Norm Based Matrix Regression with Applications to Face Recognition with Occlusion and Illumination Changes">
                                        <b>[19]</b>
                                         YANG J,LUO L,QIAN J J,et al.Nuclear Norm Based Matrix Regression with Applications to Face Recognition with Occlusion and Illumination Changes.IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(1):156-171.
                                    </a>
                                </li>
                                <li id="652">


                                    <a id="bibliography_20" title=" 刘建伟,崔立鹏,刘泽宇,等.正则化稀疏模型.计算机学报,2015,38(7):1307-1325.(LIU J W,CUI L P,LIU Z Y,et al.Survey on the Regularized Sparse Models.Chinese Journal of Computers,2015,38(7):1307-1325.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201507001&amp;v=MjE3MjZHNEg5VE1xSTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnkva1dyek9MejdCZHI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         刘建伟,崔立鹏,刘泽宇,等.正则化稀疏模型.计算机学报,2015,38(7):1307-1325.(LIU J W,CUI L P,LIU Z Y,et al.Survey on the Regularized Sparse Models.Chinese Journal of Computers,2015,38(7):1307-1325.)
                                    </a>
                                </li>
                                <li id="654">


                                    <a id="bibliography_21" title=" SHAO C B,SONG X N,FENG Z H,et al.Dynamic Dictionary Optimization for Sparse Representation Based Face Classification Using Local Difference Images.Information Sciences,2017,393:1-14." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC0F3776601BE496818BD42B9FB3DAA1E&amp;v=MTQ3NzF2RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N20ydzY0PU5pZk9mY0M0YU5MTHFJbERaT3A5ZVhnd3lSNFM0azBKVEgyUXBXUkhlc2JsTkx2cUNPTg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         SHAO C B,SONG X N,FENG Z H,et al.Dynamic Dictionary Optimization for Sparse Representation Based Face Classification Using Local Difference Images.Information Sciences,2017,393:1-14.
                                    </a>
                                </li>
                                <li id="656">


                                    <a id="bibliography_22" title=" ZHENG J W,YANG P,CHEN S Y,et al.Iterative Re-constrained Group Sparse Face Recognition with Adaptive Weights Learning.IEEE Transactions on Image Processing,2017,26(5):2408-2423." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Iterative re-constrained group sparse face recognition with adaptive weights learning">
                                        <b>[22]</b>
                                         ZHENG J W,YANG P,CHEN S Y,et al.Iterative Re-constrained Group Sparse Face Recognition with Adaptive Weights Learning.IEEE Transactions on Image Processing,2017,26(5):2408-2423.
                                    </a>
                                </li>
                                <li id="658">


                                    <a id="bibliography_23" title=" GU S H,XIE Q,MENG D Y,et al.Weighted Nuclear Norm Mi-nimization and Its Applications to Low Level Vision.International Journal of Computer Vision,2017,121(2):183-208." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Weighted nuclear norm minimization and its applications to low level vision">
                                        <b>[23]</b>
                                         GU S H,XIE Q,MENG D Y,et al.Weighted Nuclear Norm Mi-nimization and Its Applications to Low Level Vision.International Journal of Computer Vision,2017,121(2):183-208.
                                    </a>
                                </li>
                                <li id="660">


                                    <a id="bibliography_24" title=" KAMIREDDY R R,PUNEM S,JANGALA S,et al.Objective Quality Assessments of Restoration Images // Proc of the International Conference on Communication and Networks.Berlin,Germany:Springer,2017:255-268." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Objective Quality Assessments of Restoration Images">
                                        <b>[24]</b>
                                         KAMIREDDY R R,PUNEM S,JANGALA S,et al.Objective Quality Assessments of Restoration Images // Proc of the International Conference on Communication and Networks.Berlin,Germany:Springer,2017:255-268.
                                    </a>
                                </li>
                                <li id="662">


                                    <a id="bibliography_25" title=" ZHANG J,ZHAO D B,XIONG R Q,et al.Image Restoration Using Joint Statistical Modeling in a Space-Transform Domain.IEEE Transactions on Circuits and Systems for Video Technology,2014,24(6):915-928." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image restoration using joint statistical modeling in a space-transform domain">
                                        <b>[25]</b>
                                         ZHANG J,ZHAO D B,XIONG R Q,et al.Image Restoration Using Joint Statistical Modeling in a Space-Transform Domain.IEEE Transactions on Circuits and Systems for Video Technology,2014,24(6):915-928.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(10),917-926 DOI:10.16451/j.cnki.issn1003-6059.201910006            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>图像组转置训练及非凸约束的去噪去模糊算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E5%B9%B3&amp;code=34952312&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E7%87%95%E4%BC%9F&amp;code=09406708&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵燕伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%91%E5%BB%BA%E7%82%9C&amp;code=15595954&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郑建炜</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%B8%87%E8%89%AF&amp;code=10288021&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王万良</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B5%99%E6%B1%9F%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0198836&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">浙江工业大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对稀疏表示模型的过完备字典集训练过程中图像块采样不充分问题,提出图像组转置训练及非凸约束的去噪去模糊算法.采用组间方差约束的图像块搜索策略,并根据自适应软阈值对筛选的字典集进行转置学习.在重构过程中采用<i>l</i><sub><i>p</i></sub>(0&lt;<i>p</i>&lt;1)范数约束以保证结果的强稀疏性.最后采用Bregman拆分迭代法求解文中非凸模型.实验表明,文中算法重构图像具有较好的视觉效果,去噪去模糊效果较优.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E5%99%AA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去噪;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E6%A8%A1%E7%B3%8A&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去模糊;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BD%AC%E7%BD%AE%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">转置学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AD%97%E5%85%B8%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">字典学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%87%B8%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非凸优化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bregman%E6%8B%86%E5%88%86%E8%BF%AD%E4%BB%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bregman拆分迭代;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    杨平,博士研究生,主要研究方向为机器学习、模式识别．E-mail:ypingpds@163.com.&lt;image id="605" type="formula" href="images/MSSB201910006_60500.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    赵燕伟,博士,教授,主要研究方向为优化调度．E-mail:zyw@zjut.edu.cn.&lt;image id="606" type="formula" href="images/MSSB201910006_60600.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    郑建炜,博士,副教授,主要研究方向为模式识别、计算机视觉．E-mail:zjw@zjut.edu.cn.&lt;image id="607" type="formula" href="images/MSSB201910006_60700.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    *王万良(通讯作者),博士,教授,主要研究方向为人工智能．E-mail:zjutwwl@zjut.edu.cn.&lt;image id="608" type="formula" href="images/MSSB201910006_60800.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-03-14</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(No.61602413,61873240);</span>
                                <span>浙江省自然科学基金面上项目(No.LY19F030016)资助;</span>
                    </p>
            </div>
                    <h1><b>Image Patch Transform Training and Non-convex Regularization for Image Denoising and Deblurring</b></h1>
                    <h2>
                    <span>YANG Ping</span>
                    <span>ZHAO Yanwei</span>
                    <span>ZHENG Jianwei</span>
                    <span>WANG Wanliang</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology,Zhejiang University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at insufficient sampling of image patches in the process of over-complete dictionary training of sparse representation model, an algorithm of image patch transform training and non-convex regularization for image denoising and deblurring is proposed. The image patch search strategy with inter-group variance constraint is adopted, and the selected dictionary set is transposed and learned according to the adaptive soft threshold. The <i>l</i><sub><i>p</i></sub>(0&lt;<i>p</i>&lt;1) norm is adopted in the reconstruction process to ensure strong sparsity of the results. Split Bregman method is employed to solve the proposed non-convex model. Experimental results show that the proposed algorithm produces better visual effect and Denoising and Deblurring effect.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Denoising&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Denoising;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deblurring&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deblurring;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Transform%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Transform Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dictionary%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dictionary Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Non-convex%20Optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Non-convex Optimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bregman%20Split%20Iteration&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bregman Split Iteration;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    YANG Ping,Ph.D. candidate. His research interests include machine learning and pattern recognition.;
                                </span>
                                <span>
                                    ZHAO Yanwei,Ph.D.,professor. Her research interests include optimized scheduling.;
                                </span>
                                <span>
                                    ZHENG Jianwei,Ph. D.,associate professor. His research interests include pattern recognition and computer vision.;
                                </span>
                                <span>
                                    WANG Wanliang(Corresponding author), Ph. D.,professor. His research interests include artificial intelligence.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-03-14</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China(No.61602413,61873240);</span>
                                <span>General Program of Natural Science Foundation of Zhejiang Province(No.LY19F030016);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="366">图像去噪去模糊是图像预处理过程的重要部分.相比单个像素的操作,在图像去噪去模糊过程中,采用图像块作为基本操作单元可有效改善图像的修复结果<citation id="666" type="reference"><link href="614" rel="bibliography" /><link href="616" rel="bibliography" /><link href="618" rel="bibliography" /><link href="620" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>.常用算法如全变差模型<citation id="664" type="reference"><link href="622" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、小波变换模型<citation id="665" type="reference"><link href="624" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等.单幅图像的去噪去模糊算法均以图像的局部平滑性(Local Smoothness)和非局部自相似性(Non-local Similarity)作为重要的先验知识<citation id="667" type="reference"><link href="626" rel="bibliography" /><link href="628" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="367">近年来,图像去噪去模糊涌现出多种算法.Danielyan等<citation id="668" type="reference"><link href="630" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出图像块匹配及三维变换域滤波(Block-Matching and 3D Filtering, BM3D),效果较优,但对每个图像块都进行一次全局搜索,计算复杂度较高.针对这一缺点,Liu等<citation id="669" type="reference"><link href="632" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出将图像进行多分辨率采样,计算不同分辨率之间图像块的关系.Shang等<citation id="670" type="reference"><link href="634" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出在匹配计算时使用低分辨率图像块,在重建过程中使用相应高分辨率图像块,降低计算量.然而在匹配过程中,低分辨率图像因缺失结构信息较多,本质上不利于提高匹配的准确性.</p>
                </div>
                <div class="p1">
                    <p id="368">此外,基于稀疏表示和正则项约束的回归模型也越来越多地应用在图像处理方面<citation id="671" type="reference"><link href="636" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.稀疏表示模型可将图像的去噪问题拆分为字典集训练和系数求解问题.Zhang等<citation id="672" type="reference"><link href="638" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>和Liu等<citation id="673" type="reference"><link href="640" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出基于组稀疏表示的图像去噪算法.在上述多种模型中,采用欧氏距离作为图像块相似度的计算方法尚有争议<citation id="674" type="reference"><link href="642" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.以<i>l</i><sub>2</sub>范数作为约束项虽能保证模型的凸性,但会弱化模型的稀疏性.</p>
                </div>
                <div class="p1">
                    <p id="369">除此之外,转置域字典训练方法也越来越多的引入到图像去噪工作中.Rusu等<citation id="675" type="reference"><link href="644" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>对图像块进行转置训练,将训练后的转置矩阵作为字典集.Wen等<citation id="676" type="reference"><link href="646" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>对训练所得字典集进行低秩约束,进一步提升图像修复效果.Wang等<citation id="677" type="reference"><link href="648" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>在相似图像块搜索的过程中采用软阈值法代替普遍使用的硬阈值法,Yang等<citation id="678" type="reference"><link href="650" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>采用核范数约束的形式,增强相似图像块匹配过程的鲁棒性.刘建伟等<citation id="679" type="reference"><link href="652" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>指出,相比<i>l</i><sub>2</sub>范数约束的模型,<i>l</i><sub>1</sub>范数约束的正则化稀疏表示模型可保证解的稀疏性.</p>
                </div>
                <div class="p1">
                    <p id="370">受现有模型<citation id="680" type="reference"><link href="638" rel="bibliography" /><link href="644" rel="bibliography" /><link href="646" rel="bibliography" /><link href="648" rel="bibliography" /><link href="654" rel="bibliography" /><link href="656" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">21</a>,<a class="sup">22</a>]</sup></citation>启发,本文提出图像组转置训练及非凸约束的图像去噪去模糊算法(Image Patch Transform Training and Non-convex Regulari-zation for Image Denoising and Deblurring, PTNR).在图像分解过程中,采用组间方差代替欧氏距离、马氏距离等作为图像块相似性的判断标准,可有效避免因阴影变化等产生的计算结果差异.在字典学习过程中,对选择的相似图像块组进行转置操作,然后对所得变换域图像进行奇异值分解(Singular Value Decomposition, SVD)计算,设立自学习软阈值系数,对变换矩阵进行迭代学习更新.在稀疏回归的计算过程中,采用<i>l</i><sub><i>p</i></sub>(0&lt;<i>p</i>&lt;1)范数进行约束,保证回归系数的强稀疏性.求解过程采用Bregman拆分迭代法,迭代更新转置矩阵与表示系数.实验表明,本文算法去噪去模糊效果较优.</p>
                </div>
                <h3 id="371" name="371" class="anchor-tag">1 相关工作</h3>
                <h4 class="anchor-tag" id="372" name="372"><b>1.1</b> 图像块提取</h4>
                <div class="p1">
                    <p id="373">图像的局部平滑性和非局部自相似性可统一定义为:在整幅图像中,任意选择一定大小的图像块<i>I</i><sub><i>b</i></sub>,存在集合<i>S</i>∈<b>R</b>,满足<citation id="681" type="reference"><link href="616" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation></p>
                </div>
                <div class="p1">
                    <p id="374"><i>dis</i><sub><i>E</i></sub>(<i>I</i><sub><i>b</i></sub>,∀<sub>1</sub>{<i>S</i><sub>1</sub>,<i>S</i><sub>2</sub>,…,<i>S</i><sub><i>i</i></sub>})&lt;<i>ε</i>.</p>
                </div>
                <div class="p1">
                    <p id="375">其中:<i>dis</i><sub><i>E</i></sub>(, )表示计算两个图像块的欧氏距离,用于表示相似度;∀<sub>1</sub>表示选出集合中的任意一个元素,集合<i>S</i>内部元素之间满足<citation id="682" type="reference"><link href="618" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation></p>
                </div>
                <div class="p1">
                    <p id="376"><i>dis</i><sub><i>E</i></sub>(∀<sub>1</sub>{<i>S</i><sub>1</sub>,<i>S</i><sub>2</sub>,…,<i>S</i><sub><i>i</i></sub>},∀<sub>1</sub>{<i>S</i><sub>1</sub>,<i>S</i><sub>2</sub>,…,<i>S</i><sub><i>i</i></sub>})&lt;<i>ε</i>;</p>
                </div>
                <div class="p1">
                    <p id="377"><i>S</i><sub><i>i</i></sub>表示自然图像中与<i>I</i><sub><i>b</i></sub>匹配的第<i>i</i>个相似图像块.集合<i>S</i>由相似性较高的图像块组成,将图像块<i>S</i><sub><i>i</i></sub>改为列向量的形式<i><b>I</b></i><sub><i>Si</i></sub>,并将<i>i</i>个列向量合并成一个矩阵,可得矩阵<i><b>I</b></i><sub><i>S</i></sub>,易知该矩阵列间相关程度较高<citation id="683" type="reference"><link href="658" rel="bibliography" /><link href="660" rel="bibliography" /><sup>[<a class="sup">23</a>,<a class="sup">24</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="378">在一幅自然图像中,任意选定一个指定大小的图像块<i><b>I</b></i><sub><i>b</i></sub>,向量形式为<i><b>I</b></i><sub><i>Ib</i></sub>,即可在局部或全局范围内得到一个与<i><b>I</b></i><sub><i>Ib</i></sub>有相同维度的向量<i><b>I</b></i><sub><i>Sj</i></sub>,满足</p>
                </div>
                <div class="p1">
                    <p id="379"><i>dis</i><sub><i>E</i></sub>(<i><b>I</b></i><sub><i>Ib</i></sub>,<i><b>I</b></i><sub><i>Sj</i></sub>)&lt;<i>ε</i>.</p>
                </div>
                <div class="p1">
                    <p id="380">将一幅图像<i><b>I</b></i>分为<i>n</i>个同样大小的图像块<i><b>I</b></i><sub><i>bi</i></sub>(<i>i</i>=1,2,…,<i>n</i>),可得集合</p>
                </div>
                <div class="p1">
                    <p id="381"><i><b>I</b></i><sub><i>b</i></sub>={<i><b>I</b></i><sub><i>b</i></sub><sub>1</sub>,<i><b>I</b></i><sub><i>b</i></sub><sub>2</sub>,…,<i><b>I</b></i><sub><i>bn</i></sub> }∈<b>R</b><sup><i>S</i></sup><sub><sup><i>pch</i></sup></sub><sup>×</sup><sup><i>n</i></sup>.</p>
                </div>
                <div class="p1">
                    <p id="382"><i>S</i><sub><i>pch</i></sub>为设定图像块尺寸的平方,即图像块的尺寸为<mathml id="532"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt><mo>×</mo><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt></mrow></math></mathml>.根据上述方式,针对每个<i><b>I</b></i><sub><i>bi</i></sub>,均存在一个与之对应的<i><b>I</b></i><sub><i>Si</i></sub>,集合为</p>
                </div>
                <div class="p1">
                    <p id="383"><i><b>I</b></i><sub><i>S</i></sub>={<i><b>I</b></i><sub><i>S</i></sub><sub>1</sub>,<i><b>I</b></i><sub><i>S</i></sub><sub>2</sub>,…,<i><b>I</b></i><sub><i>Sn</i></sub>}∈<b>R</b><sup><i>S</i></sup><sub><sup><i>pch</i></sup></sub><sup>×</sup><sup><i>n</i></sup>,</p>
                </div>
                <div class="p1">
                    <p id="384">满足</p>
                </div>
                <div class="p1">
                    <p id="385"><i><b>I</b></i><sub><i>bi</i></sub>=<i><b>I</b></i><sub><i>S</i></sub>⊙<i>θ</i><sub><i>i</i></sub>+<i>ξ</i>,</p>
                </div>
                <div class="p1">
                    <p id="386">其中,⊙表示依元素相乘,<i>θ</i><sub><i>i</i></sub>为系数<citation id="684" type="reference"><link href="638" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.将系数改写为矩阵形式,即</p>
                </div>
                <div class="p1">
                    <p id="387"><i><b>I</b></i><sub><i>b</i></sub>=<i><b>I</b></i><sub><i>S</i></sub><i>θ</i>+<i>ξ</i>.</p>
                </div>
                <div class="p1">
                    <p id="388">在理想情况下,<i>ξ</i>忽略不计,向量<i>θ</i><sub><i>i</i></sub>中只有第<i>i</i>个元素的值为1,其余均为0.但在实际情况下,考虑到重构误差的存在,设<i>θ</i><sub><i>i</i></sub>为稀疏系数,稀疏程度与集合<i><b>I</b></i><sub><i>s</i></sub>内部列向量相关性有关.进一步可得,</p>
                </div>
                <div class="p1">
                    <p id="389"><i>θ</i>={<i>θ</i><sub>1</sub>,<i>θ</i><sub>2</sub>,…,<i>θ</i><sub><i>n</i></sub>}∈<b>R</b><sup><i>n</i></sup><sup>×</sup><sup><i>n</i></sup></p>
                </div>
                <div class="p1">
                    <p id="390">为行满秩稀疏矩阵.根据文献<citation id="685" type="reference">[<a class="sup">11</a>]</citation>和文献<citation id="686" type="reference">[<a class="sup">16</a>]</citation>,将集合<i><b>I</b></i><sub><i>s</i></sub>视为字典集,对选定图像块<i><b>I</b></i><sub><i>b</i></sub>重建过程如下:</p>
                </div>
                <div class="p1">
                    <p id="391" class="code-formula">
                        <mathml id="391"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">θ</mi></munder><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>b</mi><mi>i</mi></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mi>S</mi></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>,</mo><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>≤</mo><mi>ε</mi><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="392">其中,<mathml id="533"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mo>︿</mo></mover></mrow></math></mathml>为<i>θ</i>的优化值,<mathml id="534"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub></mrow></math></mathml>表示<i>l</i><sub>0</sub>范数,即计算<i>θ</i><sub><i>i</i></sub>中0的个数.</p>
                </div>
                <div class="p1">
                    <p id="393">上述以图像块为基本操作单元的算法大多采用滑窗形式的重叠分割方法<citation id="687" type="reference"><link href="614" rel="bibliography" /><link href="616" rel="bibliography" /><link href="618" rel="bibliography" /><link href="638" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">13</a>]</sup></citation>,对于一幅自然图像<i>x</i><sub>org</sub>,选定一个图像块<i>x</i><sub><i>i</i></sub>,如图1(a)中小蓝色框,设定尺寸为<mathml id="535"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt><mo>×</mo><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt></mrow></math></mathml>.设滑窗表示为<i>W</i><sub><i>s</i></sub>,尺寸大小与图像块<i>x</i><sub><i>i</i></sub>一致,在图1(a)中大蓝色框范围内<mathml id="536"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">(</mo><msqrt><mi>l</mi></msqrt><mo>×</mo><msqrt><mi>l</mi></msqrt><mo stretchy="false">)</mo></mrow></math></mathml>,搜寻与<i>x</i><sub><i>i</i></sub>相似的图像块.通过设置固定阈值<i>τ</i>,可取出前<i>n</i>个相似的图像块.</p>
                </div>
                <div class="area_img" id="609">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910006_60900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 图像Barbara的块匹配过程与数值对比" src="Detail/GetImg?filename=images/MSSB201910006_60900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 图像Barbara的块匹配过程与数值对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910006_60900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Block matching process and numerical comparison of image Barbara</p>

                </div>
                <div class="p1">
                    <p id="395">为了改善硬阈值在相似图像块判定中的不准确性,Wang等<citation id="688" type="reference"><link href="648" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出采用软阈值方法以提取相似图像块:</p>
                </div>
                <div class="p1">
                    <p id="396"><mathml id="537"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>τ</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>2</mn><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mo>-</mo><mi>p</mi></mrow></mfrac></mrow></msup><mo>+</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>i</mi></msub><mi>p</mi><mo stretchy="false">(</mo><mn>2</mn><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mfrac><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>2</mn><mo>-</mo><mi>p</mi></mrow></mfrac></mrow></msup><mo>,</mo></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="397">其中,<i>τ</i><sub><i>p</i></sub>(<i><b>D</b></i><sub><i>i</i></sub>)为对图像组<i><b>D</b></i><sub><i>i</i></sub>进行计算所得的阈值,<i>p</i>为参数,文献<citation id="689" type="reference">[<a class="sup">18</a>]</citation>设置<i>p</i>=0.85,选出<i><b>D</b></i><sub><i>i</i></sub>中大于阈值<i>τ</i><sub><i>p</i></sub>(<i><b>D</b></i><sub><i>i</i></sub>)的列向量作为图像块<i>x</i><sub><i>i</i></sub>的字典集<i><b>D</b></i><sub><i>i</i></sub>.</p>
                </div>
                <h4 class="anchor-tag" id="398" name="398"><b>1.2</b> 图像块转置学习</h4>
                <div class="p1">
                    <p id="399">与针对图像像素的操作不同,图像的转置学习框架目标在于将图像信号通过离散余弦变换(Discrete Consine Transform, DCT)等方式转置到频域中,再对转置矩阵和转置系数进行拆分迭代学习,基础模型为<citation id="690" type="reference"><link href="644" rel="bibliography" /><link href="646" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation></p>
                </div>
                <div class="p1">
                    <p id="400"><i><b>W</b></i><sub><i>i</i></sub><i><b>I</b></i><sub><i>b</i></sub>=<i><b>U</b></i><sub><i>i</i></sub>+<i><b>e</b></i><sub><i>i</i></sub>,</p>
                </div>
                <div class="p1">
                    <p id="401">其中,<i><b>W</b></i><sub><i>i</i></sub>∈<b>R</b><sup><i>n</i></sup><sup>×</sup><sup><i>Spch</i></sup>为转置矩阵,<i><b>I</b></i><sub><i>b</i></sub>为待操作图像块,<i><b>U</b></i><sub><i>i</i></sub>为系数,<i><b>e</b></i><sub><i>i</i></sub>为模型误差.转置学习的目标在于使模型误差尽可能小,同时约束条件在于采用尽可能稀疏的系数矩阵<i><b>U</b></i><sub><i>i</i></sub>,因此求解模型为</p>
                </div>
                <div class="p1">
                    <p id="402" class="code-formula">
                        <mathml id="402"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>min</mi></mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mi>b</mi></msub><mo>-</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>,</mo><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>≤</mo><mi>s</mi><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="403">为了避免无效解,如</p>
                </div>
                <div class="p1">
                    <p id="404"><i><b>W</b></i>=<b>0</b>, <i><b>X</b></i>=<b>0</b></p>
                </div>
                <div class="p1">
                    <p id="405">等情况,对该模型添加正则项约束,进一步可以修改为</p>
                </div>
                <div class="area_img" id="406">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201910006_40600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="408">其中lg det <i><b>W</b></i>限制模型中<i><b>W</b></i>为满秩矩阵.该模型的求解可拆分为两步迭代进行,当初始转置矩阵<i><b>W</b></i>固定时,根据系数矩阵的稀疏程度求解系数矩阵:</p>
                </div>
                <div class="p1">
                    <p id="409"><mathml id="538"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">X</mi></munder><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mi>b</mi></msub><mo>-</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>,</mo><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>≤</mo><mi>s</mi></mrow></math></mathml>.      (3)</p>
                </div>
                <div class="p1">
                    <p id="410">当得到系数矩阵后,可进一步更新转置矩阵:</p>
                </div>
                <div class="p1">
                    <p id="411" class="code-formula">
                        <mathml id="411"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">W</mi></munder><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mi>b</mi></msub><mo>-</mo><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mtext>F</mtext><mn>2</mn></msubsup><mo>-</mo><mi>λ</mi><mrow><mi>lg</mi></mrow><mspace width="0.25em" /><mrow><mi>det</mi></mrow><mi mathvariant="bold-italic">W</mi><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="412">这个过程可以根据梯度下降法快速迭代求出,并且转置矩阵的求解过程可单独作为先验计算结果,进而参与到图像的修复过程中.</p>
                </div>
                <h4 class="anchor-tag" id="413" name="413"><b>1.3</b> 图像去噪去模糊</h4>
                <div class="p1">
                    <p id="414">由于图像传感器精度限制和数字图像传输过程中的干扰,图像的退化过程包括多种情况,通用模型表达如下<citation id="691" type="reference"><link href="660" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="415"><i><b>y</b></i>=<i><b>Gx</b></i><sub>org</sub>+<i><b>n</b></i>,</p>
                </div>
                <div class="p1">
                    <p id="416">其中,<i><b>x</b></i><sub>org</sub>表示初始数字图像,<i><b>y</b></i>为退化后的图像,<i><b>G</b></i>可以看成是原始图像<i><b>x</b></i><sub>org</sub>的退化过程,<i><b>n</b></i>为附加的噪声信号.图像反退化的修复过程表示如下:</p>
                </div>
                <div class="p1">
                    <p id="417" class="code-formula">
                        <mathml id="417"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover><mo>=</mo><mi mathvariant="bold-italic">G</mi><msup><mrow></mrow><mo>†</mo></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">y</mi><mo>-</mo><mi mathvariant="bold-italic">n</mi><mo stretchy="false">)</mo><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="418">其中,<mathml id="539"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml>表示处理后的图像,<i><b>G</b></i><sup>†</sup>表示<i><b>G</b></i>的伪逆矩阵.由于<i><b>G</b></i>表示图像的退化过程,故该方程并不能求出唯一解.针对该问题,文献<citation id="692" type="reference">[<a class="sup">21</a>]</citation>和文献<citation id="693" type="reference">[<a class="sup">25</a>]</citation>通过稀疏表示模型实现图像的分解与重构,实现良好的图像去噪能力.</p>
                </div>
                <div class="p1">
                    <p id="419">分解原始图像<i><b>x</b></i><sub>org</sub>,对每个图像块<i><b>x</b></i><sub><i>i</i></sub>,得到过完备的未训练字典集<i><b>D</b></i><sub><i>i</i></sub>,可得如下方程:</p>
                </div>
                <div class="p1">
                    <p id="420"><mathml id="540"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>,      (4)</p>
                </div>
                <div class="p1">
                    <p id="421">其中,<mathml id="541"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>为重建图像块,<i>θ</i>为稀疏系数.假定<i><b>D</b></i><sub><i>i</i></sub>已通过相似图像块训练得出,故只需求得系数<i>θ</i><sub><i>i</i></sub>即可得到修复后图像块<mathml id="542"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>.为了得到图像中的有效信息量,排除噪声干扰,建立优化方程<citation id="694" type="reference"><link href="638" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="422" class="code-formula">
                        <mathml id="422"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><mrow><mi>min</mi></mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mrow><mo>|</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>&lt;</mo><mi>ε</mi><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="423">也即</p>
                </div>
                <div class="p1">
                    <p id="424" class="code-formula">
                        <mathml id="424"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><mspace width="0.25em" /><mrow><mi>min</mi></mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">D</mi><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>0</mn></msub><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="425">上式中,<i>θ</i><sub><i>i</i></sub>、<i><b>D</b></i>的定义同式(4),<i>λ</i>为正则化参数.当<i>θ</i><sub><i>i</i></sub>达到优化值<mathml id="543"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>时,限制修复图像块<mathml id="544"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>质量的重要因素为过完备字典<i><b>D</b></i><sub><i>i</i></sub>的训练结果.</p>
                </div>
                <h3 id="426" name="426" class="anchor-tag">2 基于图像组转置学习及非凸约束的图像去噪去模糊算法</h3>
                <div class="p1">
                    <p id="427">单幅图像去噪去模糊算法步骤如下:1)图像分解;2)图像去噪;3)复原图像重建.根据相关工作阐述,本节针对1)和2),在图像分解过程中,采用组间方差最大的图像块搜索算法,将结构相似的图像块搜索到同一组内.然后对每组图像块进行转置训练,得到转置域训练后的原图像组.在图像去噪过程中,对转置字典集训练后所得的图像组视为过完备字典集,进行SVD分解,通过自学习软阈值参数,提取每个分组的重要成分.在重构过程中采用<i>l</i><sub><i>p</i></sub>(0&lt;<i>p</i>&lt;1)范数,保证结果的强稀疏性,采用Bregman拆分迭代法求解本文算法.</p>
                </div>
                <div class="p1">
                    <p id="428">本文算法可以充分有效地利用自然图像在转置域中的本质稀疏性,提取图形块的特征信息,采用最小方差图像匹配方法避免因光照产生的阴影造成的图像灰度值的变化,实验表明本文算法针对图像的去噪去模糊效果在峰值信噪比(Peak Signal-to-Noise Ratio, PSNR)上优于现有算法.</p>
                </div>
                <h4 class="anchor-tag" id="429" name="429"><b>2.1</b> 图像分解与去噪去模糊过程</h4>
                <div class="p1">
                    <p id="430">将一幅自然图像<i><b>x</b></i><sub>org</sub>以滑窗形式分为<i>n</i>个相互重叠、尺寸相同的正方形图像块<i><b>x</b></i><sub><i>i</i></sub>,滑窗步长为<i>s</i><sub><i>x</i></sub>,每个小图像块大小为<mathml id="545"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt><mo>×</mo><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt></mrow></math></mathml>.对每个<i><b>x</b></i><sub><i>i</i></sub>,存在<mathml id="546"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>S</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mspace width="0.25em" /><mi>τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo></mrow></math></mathml>个相似的图像块,其中<i>Sim</i>(,)表示相似度计算,<mathml id="547"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mo>⋅</mo><mo stretchy="false">|</mo></mrow></math></mathml>为取模符号,<i>τ</i><sub><i>i</i></sub>表示为相似度判定的阈值.<i>Sim</i>(,)使用两个图像块<i>l</i><sub>1</sub>范数的方差作为相似度判断标准.取出相似图像块可组成矩阵<i><b>D</b></i><sub><i>i</i></sub>∈<b>R</b><sup><i>S</i></sup><sub><sup><i>pch</i></sup></sub><sup>×</sup><sup><i>S</i></sup><sub><sup><i>i</i></sup></sub>,</p>
                </div>
                <div class="p1">
                    <p id="431" class="code-formula">
                        <mathml id="431"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mo stretchy="false">|</mo><mi>S</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mspace width="0.25em" /><mi>τ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="432">设选定图像块为<i><b>x</b></i><sub><i>i</i></sub>,向量形式为<i><b>I</b></i><sub><i>xi</i></sub>,滑窗选出新图像块<i><b>I</b></i><sub><i>xij</i></sub>与选定图像块<i><b>I</b></i><sub><i>xi</i></sub>的相似度:</p>
                </div>
                <div class="p1">
                    <p id="433" class="code-formula">
                        <mathml id="433"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>i</mi><mi>j</mi></mrow></msub><mo>,</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></munderover><mo stretchy="false">(</mo></mstyle><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mo>∶</mo><mo stretchy="false">)</mo><mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Ι</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">(</mo><mo>∶</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="bold-italic">Ι</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="434">其中,<i><b>I</b></i><sub><i>xij</i></sub>(∶)∈<b>R</b><sup><i>S</i></sup><sub><sup><i>pch</i></sup></sub><sup>×1</sup>表示向量<i><b>I</b></i><sub><i>xij</i></sub>与<i><b>I</b></i><sub><i>xi</i></sub>依元素相减所得的向量,<i>mean</i>(·)表示计算向量的平均值,结果为常数,<i><b>I</b></i>为单位向量.</p>
                </div>
                <div class="p1">
                    <p id="435">以Barbara图像为例,由图1(b)可以看出,相同颜色的框内具有相似的纹理结构,由于阴影产生的像素值变化,欧氏距离值变化较大,计算两个图像块的方差能有效避免光照等的影响.图像<i><b>x</b></i><sub>org</sub>大小为512×512,所选图像块<i><b>x</b></i><sub><i>i</i></sub>大小为32×32,第一列为随机选定图像,第二列为重叠分割图像,与第一列有很高的相似性,第三列为受阴影影响亮度变化较大的图像.每组数据上方为重叠块与初始块的欧氏距离值与方差值,下方为亮度变化较大图像块与初始图像块的欧氏距离值与方差值.计算结果显示,三组欧氏距离变化率分别为378%、112%、65%,对应三组方差值变化率分别为-14%、45%、10%.在图像具有相似纹理的情况下,欧氏距离值受亮度影响较大,方差值受亮度影响较小,鲁棒性较好.</p>
                </div>
                <div class="p1">
                    <p id="436">对每个选定的<i><b>x</b></i><sub><i>i</i></sub>在局部或全局范围内进行相似图像块匹配计算,可得到未训练字典集<i><b>D</b></i><sub><i>i</i></sub>,根据模型(2),对<i><b>D</b></i><sub><i>i</i></sub>进行转置学习,可得转置训练后的字典集<i><b>D</b></i><sub><i>Ti</i></sub>,对<i><b>D</b></i><sub><i>Ti</i></sub>进行SVD分解计算:</p>
                </div>
                <div class="p1">
                    <p id="437">(<i><b>V</b></i><sub><i>i</i></sub>,<i>Σ</i><sub><i>i</i></sub>,<i><b>U</b></i><sub><i>i</i></sub>)=<i>SVD</i>(<i><b>D</b></i><sub><i>Ti</i></sub>).</p>
                </div>
                <div class="p1">
                    <p id="438">对<i>Σ</i>分量进行软阈值计算,软阈值计算公式参照式(1),将<i><b>D</b></i><sub><i>Ti</i></sub>替换为<i>Σ</i>,具体公式如下:</p>
                </div>
                <div class="p1">
                    <p id="439" class="code-formula">
                        <mathml id="439"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>τ</mi><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mo stretchy="false">(</mo><mn>2</mn><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mo>-</mo><mi>p</mi></mrow></mfrac></mrow></msup><mo>+</mo><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mi>i</mi></msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mrow><mfrac><mrow><mi>p</mi><mo>-</mo><mn>1</mn></mrow><mrow><mn>2</mn><mo>-</mo><mi>p</mi></mrow></mfrac></mrow></msup><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="440">筛选大于阈值的项,得到<mathml id="548"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">Σ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>,按照</p>
                </div>
                <div class="p1">
                    <p id="441"><mathml id="549"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover></mrow><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">V</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">Σ</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>,      (5)</p>
                </div>
                <div class="p1">
                    <p id="442">得到训练后的字典集.</p>
                </div>
                <div class="p1">
                    <p id="443">在得到每个图像块组<mathml id="550"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover></mrow><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub></mrow></math></mathml>后,根据式(3),目标函数转化为对稀疏系数的求解,由于<i>l</i><sub><i>p</i></sub>(0&lt;<i>p</i>&lt;1)范数可较好保证所求结果的强稀疏性,在求解模型中采用<i>l</i><sub><i>p</i></sub>范数正则约束:</p>
                </div>
                <div class="p1">
                    <p id="444"><mathml id="551"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo></mstyle><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover></mrow><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msub><mrow></mrow><mi>p</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>,      (6)</p>
                </div>
                <div class="p1">
                    <p id="445">其中,‖·‖<mathml id="552"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>表示<i>l</i><sub>2</sub>范数,<i>λ</i><sub><i>i</i></sub>为正则参数,‖·‖<sub><i>p</i></sub>为非凸<i>l</i><sub><i>p</i></sub>范数惩罚项.</p>
                </div>
                <h4 class="anchor-tag" id="446" name="446"><b>2.2</b> 系数求解过程</h4>
                <div class="p1">
                    <p id="447">为了快速准确地对式(6)进行求解,采用Bregman拆分迭代法,交替计算<mathml id="553"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover></mrow><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>和<i>θ</i><sub><i>i</i></sub>的值,同时避免高复杂度的迭代计算过程.当满足给定条件时,退出循环,返回计算后<i>θ</i><sub><i>i</i></sub>、<i><b>x</b></i><sub><i>i</i></sub>的值.</p>
                </div>
                <div class="p1">
                    <p id="448">Bregman拆分迭代法描述如下:</p>
                </div>
                <div class="p1">
                    <p id="449" class="code-formula">
                        <mathml id="449"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">u</mi><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mi>Ν</mi></msup></mrow></munder></mrow></mstyle><mrow><mi mathvariant="bold-italic">v</mi><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mi>Μ</mi></msup></mrow></munder><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">)</mo><mo>+</mo><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">v</mi><mo stretchy="false">)</mo><mo>,</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">u</mi><mo>=</mo><mi mathvariant="bold-italic">G</mi><mi mathvariant="bold-italic">v</mi><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="450">Bregman拆分迭代过程如下.</p>
                </div>
                <div class="p1">
                    <p id="451"><b>算法1</b> Bregman拆分迭代法</p>
                </div>
                <div class="p1">
                    <p id="452"><b>输入</b> 迭代参数<i>b</i><sub>0</sub>=0,<i>u</i><sub>0</sub>=0,<i>v</i><sub>0</sub>=0,</p>
                </div>
                <div class="p1">
                    <p id="453">初始迭代次数<i>t</i>=0,步长参数<i>μ</i>=0.0125</p>
                </div>
                <div class="p1">
                    <p id="454"><b>输出</b> 迭代的最终结果<i>u</i><sub><i>t</i></sub>,<i>v</i><sub><i>t</i></sub></p>
                </div>
                <div class="p1">
                    <p id="455">step 1 迭代<i>u</i><sub><i>t</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="456" class="code-formula">
                        <mathml id="456"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>u</mi></munder><mspace width="0.25em" /><mi>f</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi>u</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>G</mi><mi>v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="457">step 2 迭代<i>v</i><sub><i>t</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="458" class="code-formula">
                        <mathml id="458"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>v</mi></munder><mspace width="0.25em" /><mi>g</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi>u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi>G</mi><mi>v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi>b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="459">step 3 迭代<i>b</i><sub><i>t</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="460"><i>b</i><sub><i>t</i></sub><sub>+1</sub>=<i>b</i><sub><i>t</i></sub>-(<i>u</i><sub><i>t</i></sub><sub>+1</sub>-<i>Gv</i><sub><i>t</i></sub><sub>+1</sub>).</p>
                </div>
                <div class="p1">
                    <p id="461">step 4 迭代次数<i>t</i>=<i>t</i>+1.</p>
                </div>
                <div class="p1">
                    <p id="462">step 5 若达到迭代条件,退出循环,输出<i>u</i><sub><i>t</i></sub>, <i>v</i><sub><i>t</i></sub>,否则返回step 1.</p>
                </div>
                <div class="p1">
                    <p id="463">根据上述Bregman拆分迭代法,设置<mathml id="554"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><mo>=</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>,则式(6)可以改写为</p>
                </div>
                <div class="p1">
                    <p id="464" class="code-formula">
                        <mathml id="464"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">θ</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>arg</mi><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">)</mo><mo>+</mo><mi>g</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">v</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="465">故可将算法1中的步骤改写如下.</p>
                </div>
                <div class="p1">
                    <p id="466">step 1</p>
                </div>
                <div class="p1">
                    <p id="467" class="code-formula">
                        <mathml id="467"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>u</mi><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">u</mi></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mfrac><mi>μ</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>.</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="468">step 2</p>
                </div>
                <div class="p1">
                    <p id="469" class="code-formula">
                        <mathml id="469"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>v</mi><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mrow><mi>arg</mi></mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">v</mi></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="470" class="code-formula">
                        <mathml id="470"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>s</mtext><mtext>t</mtext><mtext>e</mtext><mtext>p</mtext><mspace width="0.25em" /><mn>3</mn><mtext> </mtext><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup><mo>=</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">θ</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="471">为了进一步求解该计算过程,可将上述步骤分别求解<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>和<i><b>v</b></i><sub><i>t</i></sub><sub>+1</sub>,具体如下.</p>
                </div>
                <div class="p1">
                    <p id="472">1)求解<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>.在step 1中,由于对<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>的最小化函数是严格的凸函数,故可对<i><b>u</b></i><sub><i>t</i></sub>求导,并令导数为0,可得</p>
                </div>
                <div class="p1">
                    <p id="473" class="code-formula">
                        <mathml id="473"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mo stretchy="false">{</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">}</mo></mrow><mrow><mo>∂</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mn>0</mn><mo>,</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mo>∂</mo><mo stretchy="false">{</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><mrow><mo>∂</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>+</mo></mtd></mtr><mtr><mtd><mfrac><mrow><mi>μ</mi><mo>∂</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo>-</mo><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo>-</mo><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mn>2</mn><mo>∂</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mn>0</mn><mo>,</mo></mtd></mtr><mtr><mtd><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mn>2</mn><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mn>2</mn><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="474">解得</p>
                </div>
                <div class="p1">
                    <p id="475" class="code-formula">
                        <mathml id="475"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mi>μ</mi></mrow></mfrac><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="476">将该值赋给<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>,可得</p>
                </div>
                <div class="p1">
                    <p id="477"><mathml id="555"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mfrac><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><mi>μ</mi></mrow></mfrac></mrow></math></mathml>.      (7)</p>
                </div>
                <div class="p1">
                    <p id="478">至此,将复杂的优化问题转化为较简单的计算问题.</p>
                </div>
                <div class="p1">
                    <p id="479">2)求解<i><b>v</b></i><sub><i>t</i></sub><sub>+1</sub>.对step 2中的<i><b>v</b></i><sub><i>t</i></sub>求导并令导数为0,可得</p>
                </div>
                <div class="p1">
                    <p id="480" class="code-formula">
                        <mathml id="480"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mfrac><mrow><mo>∂</mo><mo stretchy="false">{</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">∥</mo><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mfrac><mi>μ</mi><mn>2</mn></mfrac><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">}</mo></mrow><mrow><mo>∂</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><mn>0</mn><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi>μ</mi><mo stretchy="false">(</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow><mtext>Τ</mtext></msubsup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">v</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>μ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">)</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow><mtext>Τ</mtext></msubsup><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>μ</mi><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow><mtext>Τ</mtext></msubsup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="481">在求得<i><b>v</b></i><sub><i>t</i></sub>的过程中,可看出<mathml id="556"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow><mtext>Τ</mtext></msubsup><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>μ</mi><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow><mtext>Τ</mtext></msubsup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>在每次迭代过程中为固定值,故可以在迭代前将该值算出,令</p>
                </div>
                <div class="p1">
                    <p id="482"><mathml id="557"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><msub><mrow></mrow><mi>D</mi></msub><mo>=</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow><mtext>Τ</mtext></msubsup><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><mi>μ</mi><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msubsup><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow><mtext>Τ</mtext></msubsup><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>,      (8)</p>
                </div>
                <div class="p1">
                    <p id="483">故<i><b>v</b></i><sub><i>t</i></sub>的最终结果为</p>
                </div>
                <div class="p1">
                    <p id="484"><i><b>v</b></i><sub><i>t</i></sub>=<i>μ</i>(<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>-<i><b>b</b></i><sub><i>t</i></sub>)<i>ψ</i><sub><i>D</i></sub>,</p>
                </div>
                <div class="p1">
                    <p id="485">将该值赋给<i><b>v</b></i><sub><i>t</i></sub><sub>+1</sub>,解得</p>
                </div>
                <div class="p1">
                    <p id="486"><i><b>v</b></i><sub><i>t</i></sub><sub>+1</sub>=<i>μ</i>(<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>-<i><b>b</b></i><sub><i>t</i></sub>)<i>ψ</i><sub><i>D</i></sub>.      (9)</p>
                </div>
                <div class="p1">
                    <p id="487">至此已将复杂的优化问题转化为对<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>和<i><b>v</b></i><sub><i>t</i></sub><sub>+1</sub>的求解问题.综上所述,本文算法求解的详细步骤如下.</p>
                </div>
                <div class="p1">
                    <p id="488"><b>算法2</b> 图像块字典训练的非凸去噪去模糊算法</p>
                </div>
                <div class="p1">
                    <p id="489"><b>输入</b> 原始图像<i><b>x</b></i><sub>org</sub>,图像分块大小<i>S</i><sub><i>pch</i></sub>,</p>
                </div>
                <div class="p1">
                    <p id="490">滑窗步长<i>s</i><sub><i>x</i></sub>,最大迭代次数<i>t</i><sub>max</sub>,</p>
                </div>
                <div class="p1">
                    <p id="491">初始迭代参数<i>b</i><sub>0</sub>=0,<i>u</i><sub>0</sub>=0,<i>v</i><sub>0</sub>=0,</p>
                </div>
                <div class="p1">
                    <p id="492">初始迭代次数<i>t</i>=0,步长参数<i>μ</i>=0.0125</p>
                </div>
                <div class="p1">
                    <p id="493"><b>输出</b> 去噪去模糊后图像<mathml id="558"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="494">step 1 分解<i><b>x</b></i><sub>org</sub>至<mathml id="559"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>n</mi><mo>,</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mrow><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt><mo>×</mo><msqrt><mrow><mi>S</mi><msub><mrow></mrow><mrow><mi>p</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow></msqrt></mrow></msup><mo>;</mo></mrow></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="495">step 2 对每个<i><b>x</b></i><sub><i>i</i></sub>进行相似度计算, 根据式(5)计算<mathml id="560"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub><mo>;</mo><mspace width="0.25em" /></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="496">step 3 根据式(7)计算<i><b>u</b></i><sub><i>t</i></sub><sub>+1</sub>;</p>
                </div>
                <div class="p1">
                    <p id="497">step 4 根据式(8)计算<i>ψ</i><sub><i>D</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="498">step 5 根据式(9)计算<i><b>v</b></i><sub><i>t</i></sub><sub>+1</sub>;</p>
                </div>
                <div class="p1">
                    <p id="499">step 6  <i>t</i>=<i>t</i>+1, 若<i>t</i>=<i>t</i><sub>max</sub>,退出循环,输出<mathml id="561"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub></mrow></math></mathml>和<i>θ</i><sub><i>i</i></sub>,否则转至step 3;</p>
                </div>
                <div class="p1">
                    <p id="500">step 7 对所得<mathml id="562"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">D</mi></mstyle><mo>︿</mo></mover><msub><mrow></mrow><mrow><mi>Τ</mi><mi>i</mi></mrow></msub></mrow></math></mathml>、<i>θ</i><sub><i>i</i></sub>,按照式(4)计算去噪去模糊后的图像块<mathml id="563"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover></math></mathml><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="501">step 8 重建图像块,放回原始位置,得到<mathml id="564"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>^</mo></mover><mo>.</mo></mrow></math></mathml></p>
                </div>
                <h3 id="502" name="502" class="anchor-tag">3 实验及结果分析</h3>
                <div class="p1">
                    <p id="503">为验证本文算法(PTNR)实际效果,采用如下对比算法:BM3D<citation id="695" type="reference"><link href="630" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,加权核范数最小化算法(Weighted Nuclear Norm Minimization, WNNM)<citation id="696" type="reference"><link href="658" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>,非局部样本自适应软阈值算法(Adaptive Soft-Thresholding Based on Non-Local Samples, AST-NLS)<citation id="697" type="reference"><link href="640" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>,图像组稀疏正则化算法(Group-Based Sparse Representa-tion, GSR)<citation id="698" type="reference"><link href="638" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>,基于非凸加权<i>l</i><sub><i>p</i></sub>范数最小化的组稀疏正则化算法(Non-convex Weighted <i>l</i><sub><i>p</i></sub> Minimiza-tion Based Group Sparse Representation, GST-GSR)<citation id="699" type="reference"><link href="648" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>,对比算法的Matlab代码均在作者的主页下载.采用USC图像库(http://sipi.usc.edu/database)中灰度级为256的Baboon、Barbara、Boat、Cameraman、Couple、Crowd、House、Lake、Lax、Lena、Milkdrop、Peppers等12幅图像作为实验对象,图像像素为256×256.图像质量以PSNR值为指标.通过对原始图像进行平滑卷积得到模糊图像,噪声图像由原始图像附加高斯噪声得到.</p>
                </div>
                <div class="p1">
                    <p id="504">为了保证实验一致性,实验中将对比算法所用参数统一设定,小图像块边长<i>S</i><sub><i>pch</i></sub>=8,局部框选范围设为32×32,步长<i>s</i><sub><i>x</i></sub>=4,<i>D</i><sub><i>i</i></sub>维度设为64×64.<i>σ</i>表示为不同的噪声程度,分别设为20、30、40和50,<i>σ</i>=20,30时,<i>l</i><sub><i>p</i></sub>中<i>p</i>=0.85,<i>σ</i>=40,50时,<i>p</i>=0.95.</p>
                </div>
                <div class="p1">
                    <p id="505">由于引入组间方差最大方法,本文算法在迭代运算中求解效率更快,以House图像为例,当<i>σ</i>=20时,不同迭代次数下本文算法在图像去噪方面的运算结果如图2所示.(b)为第1次迭代的结果,可以看出在轮廓勾画方面本文算法效果较佳,(c)为最终迭代的结果,可看出,在去噪运算后图像具有较好的视觉效果.</p>
                </div>
                <div class="area_img" id="610">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910006_61000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 σ=20时本文算法对House图像的去噪结果" src="Detail/GetImg?filename=images/MSSB201910006_61000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 σ=20时本文算法对House图像的去噪结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910006_61000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Denoising results of the proposed algorithm withσ=20 on image House</p>

                </div>
                <div class="p1">
                    <p id="508">不同迭代次数下本文算法在图像去模糊方面的运算结果如图3所示.(b)为第1次迭代结果,和图2(b)相似,本文算法在特征轮廓纹理处理方面具有较好的效果.</p>
                </div>
                <div class="area_img" id="611">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910006_61100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 σ=20时本文算法对House图像的去模糊结果" src="Detail/GetImg?filename=images/MSSB201910006_61100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 σ=20时本文算法对House图像的去模糊结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910006_61100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Deblurring results of the proposed algorithm withσ=20 on image House</p>

                </div>
                <div class="p1">
                    <p id="511">当<i>σ</i>=30时,6种算法对Couple图像的去噪效果如图4所示.由女性人脸及头发等部位可以明显看出,WNNM效果得到提升.GSR对女性人脸实现进一步细致的修复,电话轮廓也重建得较清晰.相比其它算法,本文算法可以重建更清晰的图像结果,虽然对比GST-GSR无肉眼可见的明显视觉效果提升,但PSNR值有所提高.</p>
                </div>
                <div class="area_img" id="612">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910006_61200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 σ=30时6种算法对Couple图像的去噪结果" src="Detail/GetImg?filename=images/MSSB201910006_61200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 σ=30时6种算法对Couple图像的去噪结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910006_61200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Denoising results of 6 algorithms on image Couple withσ=30</p>

                </div>
                <div class="p1">
                    <p id="516"><i>σ</i>=40时6种算法对Lax图像的去噪效果如图5所示.由图可以看出,本文算法对图像中白色飞机的重建效果有明显提高.</p>
                </div>
                <div class="area_img" id="613">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201910006_61300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 σ=40时6种算法对图像Lax的去噪结果" src="Detail/GetImg?filename=images/MSSB201910006_61300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 σ=40时6种算法对图像Lax的去噪结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201910006_61300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Denoising results of 6 algorithms on image Lax withσ=40</p>

                </div>
                <div class="p1">
                    <p id="521">表1～表4为6种算法对图像去噪结果的PSNR值对比,由表可见,本文算法结果最优.表5～表8为6种算法图像去模糊结果的PSNR值对比.由表可见,本文算法在各个图像的不同噪声和模糊程度影响下的去噪去模糊实验结果均较优.</p>
                </div>
                <div class="area_img" id="522">
                    <p class="img_tit"><b>表1</b><i>σ</i>=<b>20时6种算法图像去噪结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 PSNR of images denoising results of 6 algorithms with <i>σ</i>=20</p>
                    <p class="img_note"></p>
                    <table id="522" border="1"><tr><td>图像</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>28.89</td><td>28.63</td><td>28.47</td><td>28.95</td><td>29.16</td><td>29.83</td></tr><tr><td><br />Baboon</td><td>28.90</td><td>29.43</td><td>29.48</td><td>29.55</td><td>29.58</td><td>29.61</td></tr><tr><td><br />Boat</td><td>30.82</td><td>31.09</td><td>30.68</td><td>31.34</td><td>31.93</td><td>32.15</td></tr><tr><td><br />C-man</td><td>27.93</td><td>27.86</td><td>28.16</td><td>28.28</td><td>28.75</td><td>28.79</td></tr><tr><td><br />Couple</td><td>32.44</td><td>32.85</td><td>33.30</td><td>33.12</td><td>33.57</td><td>33.69</td></tr><tr><td><br />Crowd</td><td>32.96</td><td>33.89</td><td>34.02</td><td>34.11</td><td>34.3</td><td>34.32</td></tr><tr><td><br />House</td><td>33.72</td><td>34.35</td><td>34.19</td><td>34.48</td><td>34.56</td><td>34.83</td></tr><tr><td><br />Lake</td><td>30.07</td><td>30.64</td><td>30.98</td><td>31.21</td><td>31.46</td><td>31.69</td></tr><tr><td><br />Lax</td><td>28.00</td><td>28.07</td><td>28.05</td><td>28.13</td><td>28.15</td><td>28.16</td></tr><tr><td><br />Lena</td><td>30.33</td><td>30.16</td><td>30.45</td><td>30.10</td><td>30.34</td><td>31.63</td></tr><tr><td><br />Milkdrop</td><td>32.86</td><td>32.91</td><td>33.14</td><td>33.49</td><td>33.33</td><td>33.84</td></tr><tr><td><br />Peppers</td><td>29.64</td><td>30.07</td><td>29.86</td><td>29.66</td><td>30.17</td><td>30.76</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="523">
                    <p class="img_tit"><b>表2</b><i>σ</i>=<b>30时6种算法图像去噪结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 PSNR of images denoising results of 6 algorithms with <i>σ</i>=30</p>
                    <p class="img_note"></p>
                    <table id="523" border="1"><tr><td>图像</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>27.88</td><td>27.61</td><td>27.94</td><td>28.03</td><td>30.19</td><td>28.63</td></tr><tr><td><br />Baboon</td><td>27.24</td><td>27.83</td><td>27.91</td><td>27.82</td><td>27.94</td><td>28.01</td></tr><tr><td><br />Boat</td><td>29.43</td><td>29.67</td><td>29.87</td><td>30.03</td><td>30.16</td><td>30.26</td></tr><tr><td><br />C-man</td><td>26.46</td><td>26.92</td><td>26.81</td><td>26.93</td><td>27.13</td><td>27.25</td></tr><tr><td><br />Couple</td><td>23.41</td><td>24.87</td><td>24.95</td><td>25.09</td><td>25.10</td><td>25.21</td></tr><tr><td><br />Crowd</td><td>23.42</td><td>24.07</td><td>24.54</td><td>24.63</td><td>24.83</td><td>24.98</td></tr><tr><td><br />House</td><td>33.08</td><td>33.16</td><td>32.97</td><td>33.58</td><td>33.81</td><td>33.99</td></tr><tr><td><br />Lake</td><td>27.71</td><td>28.81</td><td>28.83</td><td>28.95</td><td>29.02</td><td>29.11</td></tr><tr><td><br />Lax</td><td>28.10</td><td>28.58</td><td>28.81</td><td>28.06</td><td>28.10</td><td>28.16</td></tr><tr><td><br />Lena</td><td>28.32</td><td>28.49</td><td>28.94</td><td>29.03</td><td>28.32</td><td>29.42</td></tr><tr><td><br />Milkdrop</td><td>30.08</td><td>30.29</td><td>30.2</td><td>30.48</td><td>30.53</td><td>30.56</td></tr><tr><td><br />Peppers</td><td>28.56</td><td>28.97</td><td>29.20</td><td>29.12</td><td>29.55</td><td>29.83</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="524">
                    <p class="img_tit"><b>表3</b><i>σ</i>=<b>40时6种算法图像去噪结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 PSNR of images denoising results of 6 algorithms with <i>σ</i>=40</p>
                    <p class="img_note"></p>
                    <table id="524" border="1"><tr><td>图像</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>27.48</td><td>27.37</td><td>27.13</td><td>27.81</td><td>27.87</td><td>28.17</td></tr><tr><td><br />Baboon</td><td>26.31</td><td>26.42</td><td>26.33</td><td>26.45</td><td>26.46</td><td>26.48</td></tr><tr><td><br />Boat</td><td>29.31</td><td>29.23</td><td>29.27</td><td>29.31</td><td>29.91</td><td>30.08</td></tr><tr><td><br />C-man</td><td>26.51</td><td>26.30</td><td>26.28</td><td>26.34</td><td>26.58</td><td>26.92</td></tr><tr><td><br />Couple</td><td>28.71</td><td>29.07</td><td>29.04</td><td>29.37</td><td>29.55</td><td>29.31</td></tr><tr><td><br />Crowd</td><td>26.96</td><td>27.43</td><td>27.33</td><td>27.27</td><td>27.38</td><td>27.55</td></tr><tr><td><br />House</td><td>33.08</td><td>32.76</td><td>32.16</td><td>32.65</td><td>32.88</td><td>33.04</td></tr><tr><td><br />Lake</td><td>26.17</td><td>26.83</td><td>26.84</td><td>26.92</td><td>27.11</td><td>27.22</td></tr><tr><td><br />Lax</td><td>26.08</td><td>26.59</td><td>26.56</td><td>26.67</td><td>26.73</td><td>26.78</td></tr><tr><td><br />Lena</td><td>28.42</td><td>28.65</td><td>28.37</td><td>28.48</td><td>28.81</td><td>28.93</td></tr><tr><td><br />Milkdrop</td><td>31.31</td><td>31.71</td><td>31.82</td><td>32.00</td><td>32.03</td><td>32.07</td></tr><tr><td><br />Peppers</td><td>25.56</td><td>28.19</td><td>28.42</td><td>28.67</td><td>28.73</td><td>28.94</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="525">
                    <p class="img_tit"><b>表4</b><i>σ</i>=<b>50时6种算法图像去噪结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 PSNR of images denoising results of 6 algorithms with <i>σ</i>=50</p>
                    <p class="img_note"></p>
                    <table id="525" border="1"><tr><td>算法</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>24.34</td><td>25.47</td><td>25.98</td><td>26.02</td><td>26.12</td><td>26.29</td></tr><tr><td><br />Baboon</td><td>24.71</td><td>24.80</td><td>24.89</td><td>25.03</td><td>25.05</td><td>25.08</td></tr><tr><td><br />Boat</td><td>27.02</td><td>27.24</td><td>27.16</td><td>27.24</td><td>27.54</td><td>28.02</td></tr><tr><td><br />C-man</td><td>24.32</td><td>24.51</td><td>24.49</td><td>24.77</td><td>24.98</td><td>25.11</td></tr><tr><td><br />Couple</td><td>25.63</td><td>26.05</td><td>26.60</td><td>26.39</td><td>26.86</td><td>27.12</td></tr><tr><td><br />Crowd</td><td>24.72</td><td>25.08</td><td>24.87</td><td>25.08</td><td>25.13</td><td>25.38</td></tr><tr><td><br />House</td><td>30.41</td><td>30.98</td><td>30.83</td><td>30.81</td><td>30.97</td><td>31.37</td></tr><tr><td><br />Lake</td><td>24.18</td><td>24.37</td><td>24.51</td><td>24.56</td><td>24.68</td><td>24.71</td></tr><tr><td><br />Lax</td><td>24.73</td><td>24.83</td><td>24.92</td><td>24.99</td><td>25.01</td><td>25.05</td></tr><tr><td><br />Lena</td><td>26.16</td><td>26.20</td><td>26.47</td><td>26.45</td><td>26.76</td><td>27.15</td></tr><tr><td><br />Milkdrop</td><td>30.91</td><td>31.30</td><td>31.28</td><td>31.46</td><td>31.50</td><td>31.57</td></tr><tr><td><br />Peppers</td><td>26.06</td><td>26.37</td><td>26.38</td><td>26.23</td><td>26.38</td><td>26.96</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="526">
                    <p class="img_tit"><b>表5</b><i>σ</i>=<b>20时6种算法图像去模糊结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 PSNR of images deblurring results of 6 algorithms with <i>σ</i>=20</p>
                    <p class="img_note"></p>
                    <table id="526" border="1"><tr><td>图像</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>33.98</td><td>34.12</td><td>34.17</td><td>34.48</td><td>34.65</td><td>34.85</td></tr><tr><td><br />Baboon</td><td>31.11</td><td>31.34</td><td>31.41</td><td>31.78</td><td>31.48</td><td>32.25</td></tr><tr><td><br />Boat</td><td>30.73</td><td>30.92</td><td>30.87</td><td>31.34</td><td>31.53</td><td>31.97</td></tr><tr><td><br />C-man</td><td>27.16</td><td>27.93</td><td>28.13</td><td>28.28</td><td>28.33</td><td>28.80</td></tr><tr><td><br />Couple</td><td>31.92</td><td>31.67</td><td>32.45</td><td>32.48</td><td>32.98</td><td>33.08</td></tr><tr><td><br />Crowd</td><td>30.44</td><td>31.28</td><td>30.86</td><td>31.41</td><td>31.43</td><td>31.54</td></tr><tr><td><br />House</td><td>33.98</td><td>34.12</td><td>34.17</td><td>34.48</td><td>34.49</td><td>34.92</td></tr><tr><td><br />Lake</td><td>31.15</td><td>31.28</td><td>31.97</td><td>31.65</td><td>32.11</td><td>32.52</td></tr><tr><td><br />Lax</td><td>28.73</td><td>28.71</td><td>29.03</td><td>28.98</td><td>28.83</td><td>29.11</td></tr><tr><td><br />Lena</td><td>29.34</td><td>29.87</td><td>30.06</td><td>30.10</td><td>30.25</td><td>30.85</td></tr><tr><td><br />Milkdrop</td><td>34.29</td><td>34.24</td><td>34.52</td><td>32.76</td><td>34.35</td><td>34.55</td></tr><tr><td><br />Peppers</td><td>29.64</td><td>30.07</td><td>29.86</td><td>29.66</td><td>30.12</td><td>30.76</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="527">
                    <p class="img_tit"><b>表6</b><i>σ</i>=<b>30时6种算法图像去模糊结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 6 PSNR of images deblurring results of 6 algorithms with <i>σ</i>=30</p>
                    <p class="img_note"></p>
                    <table id="527" border="1"><tr><td>图像</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>32.15</td><td>32.37</td><td>32.81</td><td>32.93</td><td>33.13</td><td>33.34</td></tr><tr><td><br />Baboon</td><td>28.19</td><td>28.37</td><td>28.36</td><td>28.47</td><td>28.52</td><td>28.65</td></tr><tr><td><br />Boat</td><td>29.06</td><td>29.23</td><td>29.48</td><td>29.67</td><td>30.06</td><td>30.14</td></tr><tr><td><br />C-man</td><td>26.89</td><td>26.91</td><td>27.19</td><td>27.34</td><td>27.46</td><td>27.67</td></tr><tr><td><br />Couple</td><td>30.27</td><td>31.57</td><td>31.58</td><td>31.59</td><td>31.55</td><td>30.46</td></tr><tr><td><br />Crowd</td><td>28.87</td><td>29.05</td><td>29.23</td><td>30.13</td><td>30.13</td><td>30.56</td></tr><tr><td><br />House</td><td>32.15</td><td>32.37</td><td>32.81</td><td>32.93</td><td>33.27</td><td>33.87</td></tr><tr><td><br />Lake</td><td>28.4</td><td>29.68</td><td>29.65</td><td>29.51</td><td>29.94</td><td>29.68</td></tr><tr><td><br />Lax</td><td>28.65</td><td>29.37</td><td>29.72</td><td>29.05</td><td>28.94</td><td>29.03</td></tr><tr><td><br />Lena</td><td>28.94</td><td>28.47</td><td>28.96</td><td>29.13</td><td>29.49</td><td>29.57</td></tr><tr><td><br />Milkdrop</td><td>29.35</td><td>31.31</td><td>31.84</td><td>32.63</td><td>30.73</td><td>32.35</td></tr><tr><td><br />Peppers</td><td>28.56</td><td>28.97</td><td>29.20</td><td>29.12</td><td>29.55</td><td>29.83</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="528">
                    <p class="img_tit"><b>表7</b><i>σ</i>=<b>40时6种算法图像去模糊结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 7 PSNR of images deblurring results of 6 algorithms with <i>σ</i>=40</p>
                    <p class="img_note"></p>
                    <table id="528" border="1"><tr><td>图像</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>26.11</td><td>26.32</td><td>26.16</td><td>26.48</td><td>29.70</td><td>26.94</td></tr><tr><td><br />Baboon</td><td>27.09</td><td>27.12</td><td>26.86</td><td>26.83</td><td>27.22</td><td>26.83</td></tr><tr><td><br />Boat</td><td>25.97</td><td>25.38</td><td>25.37</td><td>25.93</td><td>26.34</td><td>26.73</td></tr><tr><td><br />C-man</td><td>25.69</td><td>25.78</td><td>25.93</td><td>25.95</td><td>26.12</td><td>26.77</td></tr><tr><td><br />Couple</td><td>29.11</td><td>29.96</td><td>29.67</td><td>30.33</td><td>30.36</td><td>29.72</td></tr><tr><td><br />Crowd</td><td>27.93</td><td>28.05</td><td>28.27</td><td>28.22</td><td>28.38</td><td>28.52</td></tr><tr><td><br />House</td><td>31.48</td><td>31.26</td><td>31.76</td><td>31.64</td><td>31.75</td><td>32.02</td></tr><tr><td><br />Lake</td><td>26.72</td><td>27.27</td><td>27.35</td><td>27.79</td><td>27.79</td><td>27.63</td></tr><tr><td><br />Lax</td><td>27.12</td><td>27.25</td><td>27.19</td><td>27.45</td><td>27.67</td><td>27.41</td></tr><tr><td><br />Lena</td><td>27.19</td><td>27.68</td><td>27.46</td><td>27.64</td><td>27.88</td><td>28.04</td></tr><tr><td><br />Milkdrop</td><td>32.18</td><td>32.49</td><td>32.72</td><td>32.95</td><td>32.73</td><td>32.69</td></tr><tr><td><br />Peppers</td><td>25.97</td><td>27.68</td><td>27.46</td><td>27.64</td><td>27.92</td><td>28.25</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="529">
                    <p class="img_tit"><b>表8</b><i>σ</i>=<b>50时6种算法图像去模糊结果的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 8 PSNR of images deblurring results of 6 algorithms with <i>σ</i>=50</p>
                    <p class="img_note"></p>
                    <table id="529" border="1"><tr><td>图像</td><td>BM3D</td><td>WNNM</td><td>AST-NLS</td><td>GSR</td><td>GST-GSR</td><td>PTNR</td></tr><tr><td><br />Barbara</td><td>24.46</td><td>24.37</td><td>24.58</td><td>24.83</td><td>25.08</td><td>25.37</td></tr><tr><td><br />Baboon</td><td>25.40</td><td>25.41</td><td>25.72</td><td>25.67</td><td>25.95</td><td>26.00</td></tr><tr><td><br />Boat</td><td>26.43</td><td>26.84</td><td>26.71</td><td>26.82</td><td>26.98</td><td>27.19</td></tr><tr><td><br />C-man</td><td>24.19</td><td>24.16</td><td>24.59</td><td>24.46</td><td>24.73</td><td>25.32</td></tr><tr><td><br />Couple</td><td>26.23</td><td>26.44</td><td>27.58</td><td>27.16</td><td>27.86</td><td>27.81</td></tr><tr><td><br />Crowd</td><td>25.45</td><td>25.59</td><td>25.87</td><td>26.09</td><td>26.17</td><td>26.41</td></tr><tr><td><br />House</td><td>29.35</td><td>29.97</td><td>29.67</td><td>29.83</td><td>30.23</td><td>30.65</td></tr><tr><td><br />Lake</td><td>25.07</td><td>25.20</td><td>24.97</td><td>25.20</td><td>25.59</td><td>25.85</td></tr><tr><td><br />Lax</td><td>25.45</td><td>25.58</td><td>25.58</td><td>25.97</td><td>25.84</td><td>25.99</td></tr><tr><td><br />Lena</td><td>25.03</td><td>25.37</td><td>25.35</td><td>25.76</td><td>25.83</td><td>26.24</td></tr><tr><td><br />Milkdrop</td><td>31.52</td><td>32.20</td><td>32.02</td><td>32.29</td><td>32.24</td><td>32.57</td></tr><tr><td><br />Peppers</td><td>24.10</td><td>24.27</td><td>24.12</td><td>24.30</td><td>24.28</td><td>24.80</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="530" name="530" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="531">本文提出基于图像组转置训练及非凸约束的图像去噪去模糊算法,首先在相似图像块选取过程中采用差异性判定方法,选取图像块组间最小方差值代替欧氏距离、马氏距离等作为图像块相似性的判断标准,有效避免因阴影变化等产生的计算结果差异.在字典学习过程中,对选择的相似图像块组先进行转置域学习,再进行SVD分解,并设立自学习软阈值系数,提高图像块提取的准确性.最后在稀疏回归的计算过程中,采用<i>l</i><sub><i>p</i></sub>(0&lt;<i>p</i>&lt;1)范数进行约束,保证回归系数的强稀疏性.实验表明,在保持相同计算复杂度的情况下,本文算法具有较优的去噪和去模糊效果,由于训练所得字典集分布更广、组间相似度更低,本文算法在迭代过程中具有更明显的清晰化效果.本文算法虽然在附加高斯噪声的图像中具有较好效果,但并未在真实图像上实验,下一步将进一步探索无附加高斯噪声的真实图像去噪.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="614">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES47CA6F48133A6CBEBA1F6FC393A7D400&amp;v=MTE1MzhzMkNMWGdRYnFmQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtMnc2ND1OaWZPZmJlL2JhREsyWXROWmVnTWZYcEt2V05obXo0TFRnbVJyeA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> ZHA Z Y,ZHANG X G,WANG Q,et al.Group Sparsity Residual Constraint for Image Denoising with External Nonlocal Self-similarity Prior.Neurocomputing,2018,275:2294-2306.
                            </a>
                        </p>
                        <p id="616">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adjusted non-local regression and directional smoothness for image restoration">

                                <b>[2]</b> REN C,HE X H,NGUYEN T Q.Adjusted Non-local Regression and Directional Smoothness for Image Restoration.IEEE Transactions on Multimedia,2018,21(3):731-745.
                            </a>
                        </p>
                        <p id="618">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse Graph-Regularized Dictionary Learning for Suppressing Random Seismic Noise">

                                <b>[3]</b> LIU L N,MA J W,PLONKA G.Sparse Graph-Regularized Dictionary Learning for Suppressing Random Seismic Noise.Geophysics,2018,83(3):V215-V231.
                            </a>
                        </p>
                        <p id="620">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlocal Low-Rank and Total Variation Constrained PET Image Reconstruction">

                                <b>[4]</b> XIE N,CHEN Y,LIU H.Nonlocal Low-Rank and Total Variation Constrained PET Image Reconstruction // Proc of the 24th International Conference on Pattern Recognition.Washington,USA:IEEE,2018:3874-3879.
                            </a>
                        </p>
                        <p id="622">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Denoising via a New Anisotropic Total-Variation-Based Model">

                                <b>[5]</b> PANG Z F,ZHOU Y M,WU T T,et al.Image Denoising via a New Anisotropic Total-Variation-Based Model.Signal Processing(Image Communication),2019,74:140-152.
                            </a>
                        </p>
                        <p id="624">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Iterative Wavelet Threshold for Signal Denoising">

                                <b>[6]</b> BAYER F M,KOZAKEVICIUS A J,CINTRA R J.An Iterative Wavelet Threshold for Signal Denoising.Signal Processing,2019,162:10-20.
                            </a>
                        </p>
                        <p id="626">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES035767E441303647A036D6FC575260BC&amp;v=MDE4NjlqeDdQSG1VM3hjeWZMQ1NSY2pzQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtMnc2ND1OaWZPZmJPN0c5YktxUHBCWU9vTURIOC95eEZpNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> YANG J,FAN J F,AI D N,et al.Local Statistics and Non-local Mean Filter for Speckle Noise Reduction in Medical Ultrasound Image.Neurocomputing,2016,195:88-95.
                            </a>
                        </p>
                        <p id="628">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES785E38ABC13D2657165EDD06DDDFE298&amp;v=MTk5MTJEY1RoUjdPWENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkNwYlEzNU5GaHc3bTJ3NjQ9TmlmT2ZiU3dHNlRQcC80M0Yrb01lSDQveWhFUzdEb0lQQXZpcW1aQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> WU Z X,POTTER T,WU D N,et al.Denoising High Angular Resolution Diffusion Imaging Data by Combining Singular Value Decomposition and Non-local Means Filter.Journal of Neuroscience Methods,2019,312:105-113.
                            </a>
                        </p>
                        <p id="630">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=BM3D Frames and Variational Image Deblurring">

                                <b>[9]</b> DANIELYAN A,KATKOVNIK V,EGIAZARIAN K.BM3D Frames and Variational Image Deblurring.IEEE Transactions on Image Processing,2012,21(4):1715-1728.
                            </a>
                        </p>
                        <p id="632">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Progressive image denoising through hybrid graph laplacian regularization:a unified framework">

                                <b>[10]</b> LIU X M,ZHAI D M,ZHAO D B,et al.Progressive Image Denoising through Hybrid Graph Laplacian Regularization:A Unified Framework.IEEE Transactions on Image Processing,2014,23(4):1491-1503.
                            </a>
                        </p>
                        <p id="634">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES29960AB92B6A6E41F13A26047E97387D&amp;v=MjU2Njc9TmlmT2ZiR3hGOWZNM3YxTVpwa0pmWHBNeXhkbDZ6d01Tbm5pcUJWQWNMV1hUYjNyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtMnc2NA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> SHANG L,LIU S F,ZHOU Y,et al.Modified Sparse Representation Based Image Super-Resolution Reconstruction Method.Neurocomputing,2017,228:37-52.
                            </a>
                        </p>
                        <p id="636">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201809001&amp;v=MjYyOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rV3J6T0tEN1liTEc0SDluTXBvOUZaWVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 李小宝,郭立君,张荣,等.混合l<sub>2</sub>/l<sub>1/2</sub>范数的局部组稀疏表示方法.模式识别与人工智能,2018,31(9):773-785.(LI X B,GUO L J,ZHANG R,et al.Local Group Sparse Representation Method with Mixed l<sub>2</sub>/l<sub>1/2</sub> Norm.Pattern Recognition and Artificial Intelligence,2018,31(9):773-785.)
                            </a>
                        </p>
                        <p id="638">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Group-based Sparse Representation for Image Restoration">

                                <b>[13]</b> ZHANG J,ZHAO D B,GAO W.Group-Based Sparse Representation for Image Restoration.IEEE Transactions on Image Proce-ssing,2014,23(8):3336-3351.
                            </a>
                        </p>
                        <p id="640">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image denoising via adaptive soft-thresholding based on non-local samples">

                                <b>[14]</b> LIU H F,XIONG R Q,ZHANG J,et al.Image Denoising via Adaptive Soft-Thresholding Based on Non-local Samples // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2015:484-492.
                            </a>
                        </p>
                        <p id="642">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201603004&amp;v=MTcwMzVrV3J6T0x6N0JhTEc0SDlmTXJJOUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 阴盼强,路东明,袁渊.基于马氏距离的改进非局部均值图像去噪算法.计算机辅助设计与图形学学报,2016,28(3):404-410.(YIN P Q,LU D M,YUAN Y.An Improved Non-local Means Image De-noising Algorithm Using Mahalanobis Distance.Journal of Computer-Aided Design and Computer Graphics,2016,28(3):404-410.)
                            </a>
                        </p>
                        <p id="644">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning Fast Sparsifying Transforms">

                                <b>[16]</b> RUSU C,THOMPSON J.Learning Fast Sparsifying Transforms.IEEE Transactions on Signal Processing,2017,65(16):4367-4378.
                            </a>
                        </p>
                        <p id="646">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=When Sparsity Meets Low-Rankness:Transform Learning with Non-local Low-Rank Constraintfor Image Restoration">

                                <b>[17]</b> WEN B H,LI Y J,BRESLER Y.When Sparsity Meets Low-Rankness:Transform Learning with Non-local Low-Rank Constraintfor Image Restoration // Proc of the IEEE International Conference on Acoustics,Speech and Signal Processing.Washington,USA:IEEE,2017:2297-2301.
                            </a>
                        </p>
                        <p id="648">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Non-Convex Weighted lp Minimization Based Group Sparse Representation Framework for Image Denoising">

                                <b>[18]</b> WANG Q,ZHANG X G,WU Y,et al.Non-Convex Weighted l<sub>p</sub> Minimization Based Group Sparse Representation Framework for Image Denoising[J/OL].[2019-2-26].https://arxiv.org/pdf/1704.01429.pdf.
                            </a>
                        </p>
                        <p id="650">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nuclear Norm Based Matrix Regression with Applications to Face Recognition with Occlusion and Illumination Changes">

                                <b>[19]</b> YANG J,LUO L,QIAN J J,et al.Nuclear Norm Based Matrix Regression with Applications to Face Recognition with Occlusion and Illumination Changes.IEEE Transactions on Pattern Analysis and Machine Intelligence,2017,39(1):156-171.
                            </a>
                        </p>
                        <p id="652">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201507001&amp;v=MDk4OTQva1dyek9MejdCZHJHNEg5VE1xSTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 刘建伟,崔立鹏,刘泽宇,等.正则化稀疏模型.计算机学报,2015,38(7):1307-1325.(LIU J W,CUI L P,LIU Z Y,et al.Survey on the Regularized Sparse Models.Chinese Journal of Computers,2015,38(7):1307-1325.)
                            </a>
                        </p>
                        <p id="654">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC0F3776601BE496818BD42B9FB3DAA1E&amp;v=Mjg3MDM9TmlmT2ZjQzRhTkxMcUlsRFpPcDllWGd3eVI0UzRrMEpUSDJRcFdSSGVzYmxOTHZxQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtMnc2NA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> SHAO C B,SONG X N,FENG Z H,et al.Dynamic Dictionary Optimization for Sparse Representation Based Face Classification Using Local Difference Images.Information Sciences,2017,393:1-14.
                            </a>
                        </p>
                        <p id="656">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Iterative re-constrained group sparse face recognition with adaptive weights learning">

                                <b>[22]</b> ZHENG J W,YANG P,CHEN S Y,et al.Iterative Re-constrained Group Sparse Face Recognition with Adaptive Weights Learning.IEEE Transactions on Image Processing,2017,26(5):2408-2423.
                            </a>
                        </p>
                        <p id="658">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Weighted nuclear norm minimization and its applications to low level vision">

                                <b>[23]</b> GU S H,XIE Q,MENG D Y,et al.Weighted Nuclear Norm Mi-nimization and Its Applications to Low Level Vision.International Journal of Computer Vision,2017,121(2):183-208.
                            </a>
                        </p>
                        <p id="660">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Objective Quality Assessments of Restoration Images">

                                <b>[24]</b> KAMIREDDY R R,PUNEM S,JANGALA S,et al.Objective Quality Assessments of Restoration Images // Proc of the International Conference on Communication and Networks.Berlin,Germany:Springer,2017:255-268.
                            </a>
                        </p>
                        <p id="662">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image restoration using joint statistical modeling in a space-transform domain">

                                <b>[25]</b> ZHANG J,ZHAO D B,XIONG R Q,et al.Image Restoration Using Joint Statistical Modeling in a Space-Transform Domain.IEEE Transactions on Circuits and Systems for Video Technology,2014,24(6):915-928.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201910006" />
        <input id="dpi" type="hidden" value="96" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201910006&amp;v=MDAyOTJGeS9rV3J6T0tEN1liTEc0SDlqTnI0OUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
