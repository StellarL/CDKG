<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131458926592500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201909008%26RESULT%3d1%26SIGN%3dLD1xRK5Ed1q0MjsyGLTacgn%252bPus%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201909008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201909008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201909008&amp;v=MDY5MjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnkva1ZydkxLRDdZYkxHNEg5ak1wbzlGYklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#80" data-title="1 多方面情感注意力模型 ">1 多方面情感注意力模型</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="&lt;b&gt;1.1 嵌入方面的句子表示模块&lt;/b&gt;"><b>1.1 嵌入方面的句子表示模块</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;1.2 方面间依赖关系模块&lt;/b&gt;"><b>1.2 方面间依赖关系模块</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;1.3 情感资源注意力模块&lt;/b&gt;"><b>1.3 情感资源注意力模块</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;1.4 最终分类&lt;/b&gt;"><b>1.4 最终分类</b></a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;1.5 模型训练&lt;/b&gt;"><b>1.5 模型训练</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#126" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="&lt;b&gt;2.1 实验参数及数据集&lt;/b&gt;"><b>2.1 实验参数及数据集</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;2.2 基线模型&lt;/b&gt;"><b>2.2 基线模型</b></a></li>
                                                <li><a href="#150" data-title="&lt;b&gt;2.3 评估指标及实验结果&lt;/b&gt;"><b>2.3 评估指标及实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#175" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="图1 Multi-ASAM网络框图">图1 Multi-ASAM网络框图</a></li>
                                                <li><a href="#88" data-title="图2 嵌入方面的句子表示模块网络框图">图2 嵌入方面的句子表示模块网络框图</a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;表1 数据集中样本的标签极性分布&lt;/b&gt;"><b>表1 数据集中样本的标签极性分布</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;表2 各模型在Education数据集上的性能对比&lt;/b&gt;"><b>表2 各模型在Education数据集上的性能对比</b></a></li>
                                                <li><a href="#158" data-title="&lt;b&gt;表3 各模型在Courses数据集上的性能对比&lt;/b&gt;"><b>表3 各模型在Courses数据集上的性能对比</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;表4 各模型在Restaurants数据集上的性能对比&lt;/b&gt;"><b>表4 各模型在Restaurants数据集上的性能对比</b></a></li>
                                                <li><a href="#164" data-title="&lt;b&gt;表5 不同方面数目下2种模型在Restaurants数据集上的 准确率&lt;/b&gt;"><b>表5 不同方面数目下2种模型在Restaurants数据集上的 准确率</b></a></li>
                                                <li><a href="#215" data-title="图3 2种模型对于同一句子的注意力权重分布">图3 2种模型对于同一句子的注意力权重分布</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="216">


                                    <a id="bibliography_1" title=" BOUSBIA N,BELAMRI I.Which Contribution Does EDM Provide to Computer-Based Learning Environments?// PEA,ed.Educational Data Mining.Berlin,Germany:Springer,2014:3-28." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Which Contribution Does EDM Provide to Computer-Based Learning Environments">
                                        <b>[1]</b>
                                         BOUSBIA N,BELAMRI I.Which Contribution Does EDM Provide to Computer-Based Learning Environments?// PEA,ed.Educational Data Mining.Berlin,Germany:Springer,2014:3-28.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_2" title=" GRELLER W,DRACHSLER H.Translating Learning into Numbers:A Generic Framework for Learning Analytics.Educational Technology &amp;amp; Society,2012,15(3):42-57." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJSTA6CB41CC66C0955CFE988D0A2A4ED14F&amp;v=MjU4NThLK2JhUElydncyWXUxOERIVTh5bVZsbnpaMVFBdmkzUkJFZmNmZ1JMN3BDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N202eEtzPU5pZlllcw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         GRELLER W,DRACHSLER H.Translating Learning into Numbers:A Generic Framework for Learning Analytics.Educational Technology &amp;amp; Society,2012,15(3):42-57.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_3" title=" KALAKOSKI V,KANNISTO H,DRUPSTEEN L.Enhancing Lear-ning at Work.How to Combine Theoretical and Data-Driven Approaches,and Individual,Behavioural,and Organizational Levels of Data?// Proc of the 23rd European Symposium on Artificial Neural Networks.Berlin,Germany:Springer,2015:331-336." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhancing Lear-ning at Work.How to Combine Theoretical and Data-Driven Approaches,and Individual,Behavioural,and Organizational Levels of Data?">
                                        <b>[3]</b>
                                         KALAKOSKI V,KANNISTO H,DRUPSTEEN L.Enhancing Lear-ning at Work.How to Combine Theoretical and Data-Driven Approaches,and Individual,Behavioural,and Organizational Levels of Data?// Proc of the 23rd European Symposium on Artificial Neural Networks.Berlin,Germany:Springer,2015:331-336.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_4" title=" NASUKAWA T,YI J.Sentiment Analysis:Capturing Favorability Using Natural Language Processing // Proc of the 2nd International Conference on Knowledge Capture.New York,USA:ACM,2003:70-77." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sentiment analysis: Capturing favorability using natural language processing">
                                        <b>[4]</b>
                                         NASUKAWA T,YI J.Sentiment Analysis:Capturing Favorability Using Natural Language Processing // Proc of the 2nd International Conference on Knowledge Capture.New York,USA:ACM,2003:70-77.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_5" title=" LIU B.Sentiment Analysis and Opinion Mining // HIRST G,ed.Synthesis Lectures on Human Language Technologies.San Rafael,USA:Morgan &amp;amp; Claypool Publishers,2012:1-167." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sentiment analysis and opinion mining">
                                        <b>[5]</b>
                                         LIU B.Sentiment Analysis and Opinion Mining // HIRST G,ed.Synthesis Lectures on Human Language Technologies.San Rafael,USA:Morgan &amp;amp; Claypool Publishers,2012:1-167.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_6" title=" PANG B,LEE L.Opinion Mining and Sentiment Analysis.Foundations and Trends&#174; in Information Retrieval,2008,2(1/2):1-135." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Opinion mining and sentiment analysis">
                                        <b>[6]</b>
                                         PANG B,LEE L.Opinion Mining and Sentiment Analysis.Foundations and Trends&#174; in Information Retrieval,2008,2(1/2):1-135.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_7" title=" PANG B,LEE L,VAITHYANATHAN S.Thumbs up?Sentiment Classification Using Machine Learning Techniques[C/OL].[2019-07-29].https://arxiv.org/pdf/cs/0205070.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Thumbs up?Sentiment Classification Using Machine Learning Techniques[C/OL]">
                                        <b>[7]</b>
                                         PANG B,LEE L,VAITHYANATHAN S.Thumbs up?Sentiment Classification Using Machine Learning Techniques[C/OL].[2019-07-29].https://arxiv.org/pdf/cs/0205070.pdf.
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_8" title=" KIM Y.Convolutional Neural Networks for Sentence Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1408.5882.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional Neural Networks for Sentence Classification[C/OL]">
                                        <b>[8]</b>
                                         KIM Y.Convolutional Neural Networks for Sentence Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1408.5882.pdf.
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_9" title=" SHIN B,LEE T,CHOI J D.Lexicon Integrated CNN Models with Attention for Sentiment Analysis[C/OL].[2019-07-29].https://arxiv.org/pdf/1610.06272.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Lexicon Integrated CNN Models with Attention for Sentiment Analysis[C/OL]">
                                        <b>[9]</b>
                                         SHIN B,LEE T,CHOI J D.Lexicon Integrated CNN Models with Attention for Sentiment Analysis[C/OL].[2019-07-29].https://arxiv.org/pdf/1610.06272.pdf.
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_10" title=" HOCHREITER S,SCHMIDHUBER J.Long Short-Term Memory.Neural Computation,1997,9(8):1735-1780." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MTEzNjJLOUh0ak1xbzlGWk9vTERYVXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKMThSYmhFPU5pZkpaYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         HOCHREITER S,SCHMIDHUBER J.Long Short-Term Memory.Neural Computation,1997,9(8):1735-1780.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_11" title=" QIAN Q,HUANG M L,ZHU X Y.Linguistically Regularized LSTMs for Sentiment Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1611.03949v1.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Linguistically Regularized LSTMs for Sentiment Classification[C/OL]">
                                        <b>[11]</b>
                                         QIAN Q,HUANG M L,ZHU X Y.Linguistically Regularized LSTMs for Sentiment Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1611.03949v1.pdf.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_12" title=" ZHOU X J,WAN X J,XIAO J G.Attention-Based LSTM Network for Cross-Lingual Sentiment Classification // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2016:247-256." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM Network for Cross-Lingual Sentiment Classification">
                                        <b>[12]</b>
                                         ZHOU X J,WAN X J,XIAO J G.Attention-Based LSTM Network for Cross-Lingual Sentiment Classification // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2016:247-256.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_13" title=" YANG Z C,YANG D Y,DYER C,et al.Hierarchical Attention Networks for Document Classification // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg,USA:ACL,2016:1480-1489." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical Attention Networks for Document Classification">
                                        <b>[13]</b>
                                         YANG Z C,YANG D Y,DYER C,et al.Hierarchical Attention Networks for Document Classification // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg,USA:ACL,2016:1480-1489.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_14" title=" LIN Z H,FENG M W,DOS SANTOS C N,et al.A Structured Self-attentive Sentence Embedding[C/OL].[2019-7-29].https://openreview.net/pdf?id=BJC_jUqxe." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Structured Self-attentive Sentence Embedding[C/OL]">
                                        <b>[14]</b>
                                         LIN Z H,FENG M W,DOS SANTOS C N,et al.A Structured Self-attentive Sentence Embedding[C/OL].[2019-7-29].https://openreview.net/pdf?id=BJC_jUqxe.
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_15" title=" WANG Y Q,HUANG M L,ZHAO L,et al.Attention-Based LS-TM for Aspect-Level Sentiment Classification // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2016:606-615." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM for Aspect-level Sentiment Classification">
                                        <b>[15]</b>
                                         WANG Y Q,HUANG M L,ZHAO L,et al.Attention-Based LS-TM for Aspect-Level Sentiment Classification // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2016:606-615.
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_16" title=" MA D H,LI S J,ZHANG X D,et al.Interactive Attention Networks for Aspect-Level Sentiment Classification // Proc of the 26th International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:4068-4074." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive attention networks for aspect-level sentiment classification">
                                        <b>[16]</b>
                                         MA D H,LI S J,ZHANG X D,et al.Interactive Attention Networks for Aspect-Level Sentiment Classification // Proc of the 26th International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:4068-4074.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_17" title=" TAY Y,TUAN L A,HUI S C.Learning to Attend via Word-Aspect Associative Fusion for Aspect-Based Sentiment Analysis // Proc of the 32nd AAAI Conference on Artificial Intelligence.Palo Alto,USA:AAAI Press,2018:5956-5963." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning to Attend via Word-Aspect Associative Fusion for Aspect-Based Sentiment Analysis">
                                        <b>[17]</b>
                                         TAY Y,TUAN L A,HUI S C.Learning to Attend via Word-Aspect Associative Fusion for Aspect-Based Sentiment Analysis // Proc of the 32nd AAAI Conference on Artificial Intelligence.Palo Alto,USA:AAAI Press,2018:5956-5963.
                                    </a>
                                </li>
                                <li id="250">


                                    <a id="bibliography_18" title=" LI X,BING L D,LAM W,et al.Transformation Networks for Target-Oriented Sentiment Classification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,USA:ACL,2018:946-956." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Transformation Networks for Target-Oriented Sentiment Classification">
                                        <b>[18]</b>
                                         LI X,BING L D,LAM W,et al.Transformation Networks for Target-Oriented Sentiment Classification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,USA:ACL,2018:946-956.
                                    </a>
                                </li>
                                <li id="252">


                                    <a id="bibliography_19" title=" LI C,GUO X X,MEI Q Z.Deep Memory Ntworks for Attitude Identification // Proc of the 10th ACM International Conference on Web Search and Data Mining.New York,USA:ACM,2017:671-680." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Memory Ntworks for Attitude Identification">
                                        <b>[19]</b>
                                         LI C,GUO X X,MEI Q Z.Deep Memory Ntworks for Attitude Identification // Proc of the 10th ACM International Conference on Web Search and Data Mining.New York,USA:ACM,2017:671-680.
                                    </a>
                                </li>
                                <li id="254">


                                    <a id="bibliography_20" title=" CHUNG J,GULCEHRE C,CHO K H,et al.Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL].[2019-07-29].https://arxiv.org/pdf/1412.3555.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL]">
                                        <b>[20]</b>
                                         CHUNG J,GULCEHRE C,CHO K H,et al.Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL].[2019-07-29].https://arxiv.org/pdf/1412.3555.pdf.
                                    </a>
                                </li>
                                <li id="256">


                                    <a id="bibliography_21" title=" SUKHBAATAR S,SZLAM A,WESTON J,et al.End-to-End Memory Networks[C/OL].[2019-07-29].https://arxiv.org/pdf/1503.08895.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=End-to-End Memory Networks[C/OL]">
                                        <b>[21]</b>
                                         SUKHBAATAR S,SZLAM A,WESTON J,et al.End-to-End Memory Networks[C/OL].[2019-07-29].https://arxiv.org/pdf/1503.08895.pdf.
                                    </a>
                                </li>
                                <li id="258">


                                    <a id="bibliography_22" title=" WESTON J,CHOPRA S,BORDES A.Memory Networks[C/OL].[2019-07-29].https://arxiv.org/pdf/1410.3916.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Memory Networks[C/OL]">
                                        <b>[22]</b>
                                         WESTON J,CHOPRA S,BORDES A.Memory Networks[C/OL].[2019-07-29].https://arxiv.org/pdf/1410.3916.pdf.
                                    </a>
                                </li>
                                <li id="260">


                                    <a id="bibliography_23" title=" KINGMA D P,BA J L.ADAM:A Method for Stochastic Optimization[C/OL].[2019-07-29].https://arxiv.org/pdf/1412.6980.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adam:A Method for Stochastic Optimization[C/OL]">
                                        <b>[23]</b>
                                         KINGMA D P,BA J L.ADAM:A Method for Stochastic Optimization[C/OL].[2019-07-29].https://arxiv.org/pdf/1412.6980.pdf.
                                    </a>
                                </li>
                                <li id="262">


                                    <a id="bibliography_24" title=" HU M Q,LIU B.Mining and Summarizing Customer Reviews // Proc of the 10th ACM SIGKDD International Conference on Know-ledge Discovery and Data Mining.New York,USA:ACM,2004:168-177." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining and summarizing customer reviews">
                                        <b>[24]</b>
                                         HU M Q,LIU B.Mining and Summarizing Customer Reviews // Proc of the 10th ACM SIGKDD International Conference on Know-ledge Discovery and Data Mining.New York,USA:ACM,2004:168-177.
                                    </a>
                                </li>
                                <li id="264">


                                    <a id="bibliography_25" title=" PENNINGTON J,SOCHER R,MANNING C D.Glove:Global Vectors for Word Representation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2014:1532-1543." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">
                                        <b>[25]</b>
                                         PENNINGTON J,SOCHER R,MANNING C D.Glove:Global Vectors for Word Representation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2014:1532-1543.
                                    </a>
                                </li>
                                <li id="266">


                                    <a id="bibliography_26" title=" TANG D Y,QIN B,FENG X C,et al.Effective LSTMs for Target-Dependent Sentiment Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1512.01100.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Effective LSTMs for Target-Dependent Sentiment Classification[C/OL]">
                                        <b>[26]</b>
                                         TANG D Y,QIN B,FENG X C,et al.Effective LSTMs for Target-Dependent Sentiment Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1512.01100.pdf.
                                    </a>
                                </li>
                                <li id="268">


                                    <a id="bibliography_27" title=" VASWANI A,SHAZEER N,PARMAR N,et al.Attention Is All You Need[C/OL].[2019-07-29].https://arxiv.org/pdf/1706.03762.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention Is All You Need[C/OL]">
                                        <b>[27]</b>
                                         VASWANI A,SHAZEER N,PARMAR N,et al.Attention Is All You Need[C/OL].[2019-07-29].https://arxiv.org/pdf/1706.03762.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(09),828-834 DOI:10.16451/j.cnki.issn1003-6059.201909007            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>面向教育大数据情感分类的多方面情感注意力模型</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BF%9F%E5%86%A0%E9%9C%96&amp;code=42356074&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">翟冠霖</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E7%87%95&amp;code=09183035&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨燕</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%AA%E8%A1%A1&amp;code=42356073&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">汪衡</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%9C%E5%9C%A3%E4%B8%9C&amp;code=24891473&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杜圣东</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8D%97%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0218487&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西南交通大学信息科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%8D%97%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E5%9B%9B%E5%B7%9D%E7%9C%81%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E9%AB%98%E6%A0%A1%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西南交通大学四川省云计算与智能技术高校重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对高校课程评价方法效率较低、工作量较大等问题,文中提出多方面情感注意力模型(Multi-ASAM).使用神经网络将句子分别与句中的各个方面进行嵌入,加入情感资源注意力,在考虑方面间的关系对于情感极性影响的同时,考虑情感资源对于情感极性的贡献,从而取得更好的分类效果.实验表明,在教育领域和其它领域的应用中Multi-ASAM性能有部分提升.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分析;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%99%E8%82%B2%E5%A4%A7%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">教育大数据;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    翟冠霖，硕士研究生，主要研究方向为数据挖掘、深度学习、自然语言处理．E-mail:384039089@qq.com.&lt;image id="209" type="formula" href="images/MSSB201909008_20900.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    *杨燕(通讯作者)，博士，教授，主要研究方向为人工智能、大数据分析与挖掘、集成学习．E-mail:yyang@swjtu.edu.cn.&lt;image id="210" type="formula" href="images/MSSB201909008_21000.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    汪衡，硕士研究生，主要研究方向为深度学习、自然语言处理．E-mail:2483675307@qq.com.&lt;image id="211" type="formula" href="images/MSSB201909008_21100.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    杜圣东，博士，讲师，主要研究方向为数据挖掘、深度学习、大数据分析．E-mail:sddu@swjtu.edu.cn.&lt;image id="212" type="formula" href="images/MSSB201909008_21200.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-05-12</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(No.61572407);</span>
                                <span>国家科技支撑计划课题(No.2015BAH19F02);</span>
                                <span>西南交通大学重点教改项目(No.1802028)资助;</span>
                    </p>
            </div>
                    <h1><b>Multi-aspect Sentiment Attention Modeling for Sentiment Classification of Educational Big Data</b></h1>
                    <h2>
                    <span>ZHAI Guanlin</span>
                    <span>YANG Yan</span>
                    <span>WANG Heng</span>
                    <span>DU Shengdong</span>
            </h2>
                    <h2>
                    <span>School of Information Science and Technology,Southwest Jiaotong University</span>
                    <span>Key Laboratory of Cloud Computing and Intelligent Technique,Sichuan Province,Southwest Jiaotong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at inefficiency and heavy workloads of college curriculum evaluation methods, a multi-aspect sentiment attention modeling(multi-ASAM) is proposed. Multi-ASAM concatenates a sentence and various aspects of the sentence by neural networks and adds emotional resources attention. To achieve better classification results, influence of relationships between aspects on emotinal polarity and contribution of emotional resources to emotional polarity is taken into auount in multi-ASAM. Experimental results show that Multi-ASAM is improved compared with other methods in the application of education and other fields.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sentiment%20Analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sentiment Analysis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Educational%20Big%20Data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Educational Big Data;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Attention%20Mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Attention Mechanism;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Neural%20Network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Neural Network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHAI Guanlin,master student. His research interests include data mining, deep learning and natural language processing.;
                                </span>
                                <span>
                                    YANG Yan(Corresponding author),Ph. D., professor. Her research interests include artificial intelligence,big data analysis and mining,ensemble learning.;
                                </span>
                                <span>
                                    WANG Heng,master student. His research interests include deep learning and natural language processing.;
                                </span>
                                <span>
                                    DU Shengdong,Ph. D. ,lecturer. His research interests include data mining, deep learning and big data analysis.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-05-12</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China(No.61572407);</span>
                                <span>National Key Technology Research and Development Program(No.2015BAH19F02);</span>
                                <span>Southwest Jiaotong University Key Education Reform Project(No.1802028);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="69">教育数据挖掘(Educational Data Mining, EDM)是一个新兴的研究领域<citation id="270" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,就是将数据挖掘方法应用于教育数据,可以为学习者的行为和学习途径提供新的见解,并以数据驱动的方式改进学习方法<citation id="271" type="reference"><link href="218" rel="bibliography" /><link href="220" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="70">情感分析(Sentiment analysis, SA)<citation id="272" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>,又称为意见挖掘<citation id="274" type="reference"><link href="224" rel="bibliography" /><link href="226" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>,作为自然语言处理中的核心任务之一,近年来已经引起人们的广泛关注. 现 有 的 情感分析方法大多使用有监督的机器学习方法建立情绪分类器，如支持向量机(Support Vector Machine,SVM)<citation id="273" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>，卷积神经网络(Convolutional Neural Network,CNN)<citation id="275" type="reference"><link href="230" rel="bibliography" /><link href="232" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>，长短期记忆网络(Long Short-Term Memory,LST-M)<citation id="276" type="reference"><link href="234" rel="bibliography" /><link href="236" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>]</sup></citation>及基于注意力的方法<citation id="277" type="reference"><link href="238" rel="bibliography" /><link href="240" rel="bibliography" /><link href="242" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="75">人们在评论某件事物时,往往会考虑它的各方面,但以往的情感分析方法未考虑这种内在联系,只是独立考虑单个方面,具有局限性.近年来,基于方面级别的情感分析(Aspect-Level Sentiment Analysis, ABSA)研究发展迅速.ABSA分类句子中的每个方面的情感极性,是一种更细粒度的情感分析方法.</p>
                </div>
                <div class="p1">
                    <p id="76">Wang等<citation id="278" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出一种处理方面级别的情感分析任务的方法,将嵌入方面信息的句子提供给神经网络,通过神经网络进行分类.在句子中的每个单词的词嵌入后附加目标方面的嵌入,用于生成嵌入方面的句子表示,将该表示送入注意力层,再送入softmax层,以便完成最终的分类任务.</p>
                </div>
                <div class="p1">
                    <p id="77">近来,Ma等<citation id="279" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出用于方面级别情感分类的交互式注意力网络模型.在模型中,上下文注意力机制和方面表示注意力机制之间相互作用,用于产生最终的整体表示.Tay等<citation id="280" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>在Wang等<citation id="281" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>的基础上提出词语-方面关联概念,使用循环相关性达到改进原方法的目的.此外,Li等<citation id="282" type="reference"><link href="250" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>使用转换网络进行面向目标的情感分类.方面级别的情感分析在问答系统领域也得到深入研究,其中深度神经网络在问答系统中尤为重要<citation id="283" type="reference"><link href="252" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="78">大部分情感分类模型大多是对句子的整体情感极性进行分类,分类粒度较大,或者只关注句子某个方面的情感,未考虑方面之间的关系.</p>
                </div>
                <div class="p1">
                    <p id="79">为了在考虑各方面间关系的同时考虑情感资源对情感极性的贡献度,本文提出多方面情感注意力模型(Multi-Aspect Sentiment Attention Modeling, Multi-ASAM).对句子进行细粒度的方面级别的情感分类,在考虑不同方面之间的关系对于情感极性影响的同时,考虑情感资源对于情感极性的贡献,从而达到更好的分类效果.首先,使用门控循环单元(Gated Recurrent Unit, GRU)<citation id="284" type="reference"><link href="254" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>和注意力机制生成嵌入方面的句子表示,使句子每次只关注一个方面.再使用记忆网络<citation id="285" type="reference"><link href="256" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>重复地将目标方面的表示与其它方面的表示匹配,以生成更准确的目标方面表示.然后,在记忆网络输出之前,将目标方面的表示分别加上对应不同情感资源的注意力,再次经过GRU单元找出情感资源与句子的隐藏语义信息.最后,该精确表示被馈送到softmax分类器进行最终分类.实验表明,Multi-ASAM在几个不同领域中的性能优于现有方法.</p>
                </div>
                <h3 id="80" name="80" class="anchor-tag">1 多方面情感注意力模型</h3>
                <div class="p1">
                    <p id="81">Multi-ASAM主要由3部分组成:嵌入方面的句子表示模块、方面间依赖关系模块、情感资源注意力模块.Multi-ASAM模型网络整体框架如图1所示.</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909008_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Multi-ASAM网络框图" src="Detail/GetImg?filename=images/MSSB201909008_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Multi-ASAM网络框图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909008_082.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Network framework of multi-ASAM</p>

                </div>
                <div class="p1">
                    <p id="83">为了便于理解,文中所用的符号定义如下:句子<i><b>S</b></i>=[<i><b>w</b></i><sub>1</sub>,<i><b>w</b></i><sub>2</sub>,…,<i><b>w</b></i><sub><i>L</i></sub>],其中,<i><b>w</b></i><sub><i>i</i></sub>表示每个单词,使用维度为<i>D</i>的词嵌入向量表示,<i>L</i>表示句子中单词的最大数量,即句子最大长度.同时,使用<i>A</i><sub><i>i</i></sub>表示句子<i><b>S</b></i>中的第<i>i</i>个方面,0&lt;<i>i</i>&lt;<i>M</i>&lt;<i>L</i>, <i>M</i>表示句子中包含的最大方面数.</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>1.1 嵌入方面的句子表示模块</b></h4>
                <div class="p1">
                    <p id="85">在一个句子中,不是每个词都携带能表示特定方面的情感信息,有些单词是不包含情感信息的,如停用词.因此可使用一个句子表示某个特定方面的情感.Multi-ASAM首先将句子中的每个单词<i><b>w</b></i><sub><i>i</i></sub>与特定方面<i><b>a</b></i><sub><i>i</i></sub>拼接,使一个句子每次只关注一个特定方面.嵌入方面的句子表示模块网络框架图如图2所示,具体定义如下:</p>
                </div>
                <div class="area_img" id="213">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201909008_21300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="87">其中⊕表示串联.</p>
                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909008_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 嵌入方面的句子表示模块网络框图" src="Detail/GetImg?filename=images/MSSB201909008_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 嵌入方面的句子表示模块网络框图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909008_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Network framework of aspect-embedded sentence representation module</p>

                </div>
                <div class="p1">
                    <p id="90">为了将上下文信息在句子中传播,Multi-ASAM模型将<i><b>S</b></i><sub><i><b>a</b></i></sub><sub><i>i</i></sub>送入一个双向GRU,定义此单元为<i>GRU</i><sub>1</sub>,隐藏层大小为<i>D</i><sub>0</sub>.<i>GRU</i><sub>1</sub>的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="91" class="code-formula">
                        <mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">z</mi><mo>=</mo><mi mathvariant="bold-italic">σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>z</mi><msub><mrow></mrow><mo>.</mo></msub><mo>+</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>z</mi><msub><mrow></mrow><mo>.</mo></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">γ</mi><mo>=</mo><mi mathvariant="bold-italic">σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>γ</mi><msub><mrow></mrow><mo>.</mo></msub><mo>+</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>γ</mi><msub><mrow></mrow><mo>.</mo></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>tanh</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mi mathvariant="bold-italic">U</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>h</mi><msub><mrow></mrow><mo>.</mo></msub><mo>+</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mi mathvariant="bold-italic">γ</mi><mo stretchy="false">)</mo><mi>W</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>h</mi><msub><mrow></mrow><mo>.</mo></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">)</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">z</mi><mi mathvariant="bold-italic">s</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="92">其中,<i><b>h</b></i><sub><i>t</i></sub>和<i><b>s</b></i><sub><i>t</i></sub>分别为时间<i>t</i>时的隐藏输出和单元状态.由此可得<i><b>R</b></i><sub><i><b>a</b></i></sub><sub><i>i</i></sub>=<i>GRU</i><sub>1</sub>(<i><b>S</b></i><sub><i><b>a</b></i></sub><sub><i>i</i></sub>).</p>
                </div>
                <div class="p1">
                    <p id="93">为了增强方面<i><b>a</b></i><sub><i>i</i></sub>与对应情感词之间的相关性,Multi-ASAM增加一个注意力层,以便获得嵌入方面的句子表示<i><b>r</b></i><sub><i>ai</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">α</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">z</mi><mo>=</mo><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mrow><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>S</mi></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>s</mi></msub><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">α</mi><mo>=</mo><mtext>s</mtext><mtext>o</mtext><mtext>f</mtext><mtext>t</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mo stretchy="false">(</mo><mi mathvariant="bold-italic">z</mi><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">其中</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">z</mi><mo>=</mo><mo stretchy="false">[</mo><mi>z</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>z</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>z</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>L</mi><mo>×</mo><mn>1</mn></mrow></msup><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">α</mi><mo>=</mo><mo stretchy="false">[</mo><mi>α</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>α</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>α</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>L</mi><mo>×</mo><mn>1</mn></mrow></msup><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mrow><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msub><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>D</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msup><mo>,</mo><mspace width="0.25em" /><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>D</mi><msub><mrow></mrow><mn>0</mn></msub><mo>×</mo><mn>1</mn></mrow></msup><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97"><i>b</i><sub><i>s</i></sub>为一个标量.</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98"><b>1.2 方面间依赖关系模块</b></h4>
                <div class="p1">
                    <p id="99">Multi-ASAM将<i><b>R</b></i>=[<i><b>r</b></i><sub><i><b>a</b></i></sub><sub>1</sub>,<i><b>r</b></i><sub><i><b>a</b></i></sub><sub>2</sub>,…,<i><b>r</b></i><sub><i><b>a</b></i></sub><sub><i>M</i></sub>]送入另一个隐藏层大小为<i>D</i><sub>0</sub>的门控循环单元(<i>GRU</i><sub>2</sub>)中,用于传播嵌入方面的句子表示中的方面信息,得到的结果<i>Q</i>=<i>GRU</i><sub>2</sub>(<i><b>R</b></i>).</p>
                </div>
                <div class="p1">
                    <p id="100">为了进一步对方面间依赖关系建模,Multi-ASAM采用记忆网络<citation id="286" type="reference"><link href="256" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>实现建模,使用<i><b>r</b></i><sub><i>at</i></sub>表示网络中目标方面表示.通过使用一个全连接层,将<i><b>r</b></i><sub><i>at</i></sub>转化为内部查询状态<i><b>q</b></i>:</p>
                </div>
                <div class="p1">
                    <p id="101"><i><b>q</b></i>=tanh(<i><b>r</b></i><sub><i>at</i></sub><i><b>W</b></i><sub><i>T</i></sub>+<i><b>b</b></i><sub><i>T</i></sub>)∈<b>R</b><sup><i>D</i></sup><sub><sup>0</sup></sub>,<i><b>W</b></i><sub><i>T</i></sub>∈<b>R</b><sup><i>D</i></sup><sub><sup>0</sup></sub><sup>×</sup><sup><i>D</i></sup><sub><sup>0</sup></sub>,<i><b>b</b></i><sub><i>T</i></sub>∈<b>R</b><sup><i>D</i></sup><sub><sup>0</sup></sub>.</p>
                </div>
                <h4 class="anchor-tag" id="102" name="102"><b>1.3 情感资源注意力模块</b></h4>
                <div class="p1">
                    <p id="103">Multi-ASAM的情感资源注意力模块是在记忆网络中加入注意力层,增强句子中相应的情感资源,获得更好的分类结果.</p>
                </div>
                <div class="p1">
                    <p id="104">记忆网络的输入.句子中所有方面被存储在记忆单元中,每个方面由<i><b>Q</b></i>中对应的嵌入方面的句子表示所表示.网络中加入一层注意力机制,用于读取<i><b>Q</b></i>中的记忆内容<citation id="287" type="reference"><link href="258" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.Multi-ASAM使用内积计算<i><b>q</b></i>在<i><b>Q</b></i>中对应的记忆单元:</p>
                </div>
                <div class="p1">
                    <p id="105"><i><b>z</b></i>=<i><b>qQ</b></i><sup>T</sup>, <i>β</i>=<i>softmax</i>(<i><b>z</b></i>),</p>
                </div>
                <div class="p1">
                    <p id="106">其中</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">z</mi><mo>=</mo><mo stretchy="false">[</mo><mi>z</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>z</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>z</mi><msub><mrow></mrow><mi>Μ</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>Μ</mi><mo>×</mo><mn>1</mn></mrow></msup><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">β</mi><mo>=</mo><mo stretchy="false">[</mo><mi>β</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>β</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>β</mi><msub><mrow></mrow><mi>Μ</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>Μ</mi><mo>×</mo><mn>1</mn></mrow></msup><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108"><i>β</i><sub><i>i</i></sub>为目标方面和方面<i>i</i>之间的相关性度量,即注意力得分.</p>
                </div>
                <div class="p1">
                    <p id="109">记忆网络的输出.Multi-ASAM所用的情感资源包括两种:情感词和程度副词(包括强度词和否定词),各自对应的嵌入矩阵如下:</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>s</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>D</mi><mo>×</mo><mi>m</mi></mrow></msup><mo>,</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>d</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">]</mo><mo>∈</mo><mi mathvariant="bold">R</mi><msup><mrow></mrow><mrow><mi>D</mi><mo>×</mo><mi>n</mi></mrow></msup><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">其中<i>m</i>和<i>n</i>表示情感词和程度副词各自嵌入矩阵的长度.</p>
                </div>
                <div class="p1">
                    <p id="112">Multi-ASAM将<i><b>Q</b></i>与情感词嵌入矩阵进行相乘操作,得到<i><b>Q</b></i><sub><i>s</i></sub>=<i><b>QW</b></i><sub><i>s</i></sub>,增强<i><b>Q</b></i>中隐含的情感词,有利于得到更好的分类结果.同理,对程度副词嵌入矩阵也进行相同操作,得到<i><b>Q</b></i><sub><i>d</i></sub>=<i><b>QW</b></i><sub><i>d</i></sub>.再将<i><b>Q</b></i><sub><i>s</i></sub>通过门控循环单元(<i>GRU</i><sub>3</sub>)提取隐含的语义信息,得到<i><b>Q</b></i>′<sub><i>s</i></sub>=<i>GRU</i><sub>3</sub>(<i><b>Q</b></i><sub><i>s</i></sub>).类似地,将<i><b>Q</b></i><sub><i>d</i></sub>经过<i>GRU</i><sub>4</sub>,得到<i><b>Q</b></i>′<sub><i>d</i></sub>=<i>GRU</i><sub>4</sub>(<i><b>Q</b></i><sub><i>d</i></sub>).最后对<i><b>Q</b></i>′<sub><i>s</i></sub>和<i><b>Q</b></i>′<sub><i>d</i></sub>进行融合以汇总注意力,得到<i><b>Q</b></i>′=<i><b>Q</b></i>′<sub><i>s</i></sub>+<i><b>Q</b></i>′<sub><i>d</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="113">记忆网络的最终输出是通过汇总<i><b>Q</b></i>′中的输出向量得到,对应的权重为前文求得的<i>β</i>中的注意力分值<i><b>o</b></i>=<i>β</i><sup>T</sup><i><b>Q</b></i>′∈<b>R</b><sup><i>D</i></sup><sub><sup>0</sup></sub>.</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>1.4 最终分类</b></h4>
                <div class="p1">
                    <p id="115">将目标方面表示<i><b>q</b></i>和记忆网络的输出<i><b>o</b></i>相加,产生更精细的目标方面表示.将得到的更精细的目标方面的表示通过一个尺寸为<i>C</i>(<i>C</i>为类别数目)的softmax分类器,用于输出最终的情感分类结果:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">ρ</mi><mo>=</mo><mtext>s</mtext><mtext>o</mtext><mtext>f</mtext><mtext>t</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">q</mi><mo>+</mo><mi mathvariant="bold-italic">o</mi><mo stretchy="false">)</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>m</mtext><mtext>a</mtext><mtext>x</mtext></mrow></msub><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr><mtr><mtd><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mi>arg</mi><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mi>i</mi></munder><mo stretchy="false">(</mo><mi>ρ</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">其中<mathml id="177"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>y</mi><mo>^</mo></mover></math></mathml>为情感极性的预测结果.</p>
                </div>
                <h4 class="anchor-tag" id="118" name="118"><b>1.5 模型训练</b></h4>
                <div class="p1">
                    <p id="119">在训练过程中对模型进行30次迭代,使用分类交叉熵作为损失函数,同时引入<i>L</i>2正则化项:</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo>=</mo><mo>-</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>C</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>y</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mrow><mi>log</mi></mrow><msub><mrow></mrow><mn>2</mn></msub><mspace width="0.25em" /><mi>ρ</mi><mo stretchy="false">[</mo><mi>k</mi><mo stretchy="false">]</mo><mo>+</mo><mi>λ</mi><mrow><mo>|</mo><mi>θ</mi><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">其中,<i>N</i>为样本数量, <i>i</i>为样本索引, <i>k</i>为分类类别,<i>λ</i>为正则化权重.</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>,</mo></mtd><mtd columnalign="left"><mtext>样</mtext><mtext>本</mtext><mi>i</mi><mtext>的</mtext><mtext>预</mtext><mtext>测</mtext><mtext>类</mtext><mtext>别</mtext><mtext>为</mtext><mi>k</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>,</mo></mtd><mtd columnalign="left"><mtext>其</mtext><mtext>它</mtext></mtd></mtr></mtable></mrow></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123"><i>θ</i>为网络中需要被训练的参数的集合.</p>
                </div>
                <div class="p1">
                    <p id="124">由于dot product是注意力建模的一种最常用的手段,结构较简单,因此Multi-ASAM采用dot product作为注意力模型.</p>
                </div>
                <div class="p1">
                    <p id="125">由于基于随机梯度下降(Stochastic Gradient Descent, SGD)的ADAM(Adaptive Moment Estima-tion)<citation id="288" type="reference"><link href="260" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>具有参数自适应学习方案,因此Multi-ASAM选择ADAM作为优化算法.</p>
                </div>
                <h3 id="126" name="126" class="anchor-tag">2 实验及结果分析</h3>
                <h4 class="anchor-tag" id="127" name="127"><b>2.1 实验参数及数据集</b></h4>
                <div class="p1">
                    <p id="128">在实验过程中,所有词嵌入的维度<i>D</i>=300,隐藏层的大小<i>D</i><sub>0</sub>=300,初始学习率<i>l</i><sub><i>r</i></sub>=0.001,<i>L</i>2正则化的系数<i>l</i><sub>2</sub>=0.00001.</p>
                </div>
                <div class="p1">
                    <p id="129">实验数据集如下.</p>
                </div>
                <div class="p1">
                    <p id="130">Courses数据集(https://www.kaggle.com/septa</p>
                </div>
                <div class="p1">
                    <p id="131">97/100k-courseras-course-reviews-dataset),来自教育网站Coursera的评论集中的中文评论部分,包含不同课程及老师.主要关注如下两方面.</p>
                </div>
                <div class="p1">
                    <p id="132">1)课程:课程内容、优缺点等.</p>
                </div>
                <div class="p1">
                    <p id="133">2)老师:授课老师的态度、积极性、优缺点等.</p>
                </div>
                <div class="p1">
                    <p id="134">Education数据集取自某高校2014～2017学年信息学院共计3 000多名本科生的课程评价信息,涉及不同科目、年级及授课老师.主要关注如下4方面.</p>
                </div>
                <div class="p1">
                    <p id="135">1)课程难度:课程的难度对学生是否合适.</p>
                </div>
                <div class="p1">
                    <p id="136">2)课程内容:课程内容是否合理,是否老旧过时.</p>
                </div>
                <div class="p1">
                    <p id="137">3)课程实用性:课程对就业或将来的发展是否有帮助.</p>
                </div>
                <div class="p1">
                    <p id="138">4)授课老师:老师在授课过程中的优点和不足.</p>
                </div>
                <div class="p1">
                    <p id="139">Courses数据集和Education数据集对应的情感词汇表来自台湾大学NTUSD简体中文情感词典,强度词和否定词由人工收集.采用Mixed-large综合语料库预训练得到的中文词向量表示词级嵌入.</p>
                </div>
                <div class="p1">
                    <p id="140">SemEval-2014 ABSA中的Restaurants数据集(http://alt.qcri.org/semeval2014/)包含用户的评论信息,每条评论包含一组方面及其对应的情感极性,每个句子包含的方面在数据集中已给出或由人工标注.本文目标是正确识别方面对应的情感极性.Restaurants数据集对应的情感词汇表来自Qian 等<citation id="289" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和Hu等<citation id="290" type="reference"><link href="262" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>的汇总,由于强度词和否定词的数目较少,故采用人工收集.对于Restaurants数据集采用的词级嵌入,采用GloVe(Gloal Vectors for Word Representation, GloVe)模型<citation id="291" type="reference"><link href="264" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>获得.</p>
                </div>
                <div class="p1">
                    <p id="141">3个数据集中样本的标签极性分布如表1所示.</p>
                </div>
                <div class="area_img" id="142">
                    <p class="img_tit"><b>表1 数据集中样本的标签极性分布</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Polarity distribution of labels in dataset</p>
                    <p class="img_note"></p>
                    <table id="142" border="1"><tr><td rowspan="2"><br />数据集</td><td colspan="2"><br />正向情感</td><td colspan="2"><br />中性情感</td><td colspan="2"><br />负向情感</td></tr><tr><td><br />训练</td><td>测试</td><td><br />训练</td><td>测试</td><td><br />训练</td><td>测试</td></tr><tr><td>Education</td><td>2470</td><td>821</td><td>5468</td><td>1829</td><td>1062</td><td>350</td></tr><tr><td>Courses</td><td>444</td><td>84</td><td>96</td><td>13</td><td>46</td><td>22</td></tr><tr><td><br />Restaurants</td><td>2164</td><td>728</td><td>633</td><td>196</td><td>805</td><td>196</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="143" name="143"><b>2.2 基线模型</b></h4>
                <div class="p1">
                    <p id="144">为了全方位评估Multi-ASAM,本文使用如下四种对比模型.</p>
                </div>
                <div class="p1">
                    <p id="145">1)依赖于目标的长短期记忆网络(Target-Dependent LSTM, TD-LSTM)<citation id="292" type="reference"><link href="266" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>.采用两个LSTM网络,使用目标分别和左上下文及右上下文建模.将左目标依赖和右目标依赖连接以预测目标的情感极性.</p>
                </div>
                <div class="p1">
                    <p id="146">2)方面嵌入的长短期记忆网络(LSTM with Aspect Embedding, AE-LSTM)<citation id="293" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.让句子通过LSTM网络进行上下文传播,将单词隐藏状态与方面嵌入联接,生成注意力向量.注意力向量用于生成方面级情感分类的最终表示,最终送到softmax分类器中.</p>
                </div>
                <div class="p1">
                    <p id="147">3)基于注意力方面嵌入的长短期记忆网络(Attention-Based LSTM with Aspect Embedding, ATAE-LSTM)<citation id="294" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.基于AE-LSTM开发,进一步增强方面嵌入的效果,并将方面嵌入与每个单词嵌入向量相加以表示上下文.</p>
                </div>
                <div class="p1">
                    <p id="148">4)交互式注意力网络(Interactive Attention Networks, IAN)<citation id="295" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>.将目标方面及其上下文输入到两个不同的LSTM,隐藏层的输出分别为中间方面表示和上下文表示.从两个LSTM的隐藏输出中生成注意力分数,用于生成最终方面和上下文表示.连接这两个向量输入到softmax分类器进行最终分类.</p>
                </div>
                <div class="p1">
                    <p id="149">上述模型在进行方面级别的情感分类时,只关注句子中的某个方面,并未关注不同方面之间的关系.</p>
                </div>
                <h4 class="anchor-tag" id="150" name="150"><b>2.3 评估指标及实验结果</b></h4>
                <div class="p1">
                    <p id="151">实验中所用的各评估指标如下.</p>
                </div>
                <div class="p1">
                    <p id="152">1)准确率.所有样本中被正确分类的样本比例.</p>
                </div>
                <div class="p1">
                    <p id="153">2)精度.被预测为正例的样本中实际为正例的比例.</p>
                </div>
                <div class="p1">
                    <p id="154">3)召回率.实际为正例的样本中预测为正例的比例.</p>
                </div>
                <div class="p1">
                    <p id="155">4)F1值.精度和召回率的加权调和平均.</p>
                </div>
                <div class="p1">
                    <p id="156">表2～表4为5种模型在3个数据集上的性能对比.表中各项指标值取多次实验中各指标的最高值.同时,为了验证情感资源模块对模型分类能力有提升,在Multi-ASAM中去除情感资源模块,并在Education数据集上进行对比实验,得到的准确率为94.6%,可以证明情感资源模块对模型性能有较大提升.</p>
                </div>
                <div class="area_img" id="157">
                    <p class="img_tit"><b>表2 各模型在Education数据集上的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Performance comparison of models on Education dataset </p>
                    <p class="img_note"></p>
                    <table id="157" border="1"><tr><td><br />模型</td><td>准确率</td><td>精度</td><td>召回率</td><td>F1值</td></tr><tr><td><br />TD-LSTM</td><td>92.8</td><td>86.3</td><td>87.5</td><td>86.9</td></tr><tr><td><br />AE-LSTM</td><td>88.9</td><td>86.9</td><td>85.9</td><td>86.4</td></tr><tr><td><br />ATAE-LSTM</td><td>90.7</td><td>87.9</td><td>88.1</td><td>88.0</td></tr><tr><td><br />IAN</td><td>71.7</td><td>62.6</td><td>60.8</td><td>61.7</td></tr><tr><td><br />Multi-ASAM</td><td>95.4</td><td>93.6</td><td>93.4</td><td>93.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="158">
                    <p class="img_tit"><b>表3 各模型在Courses数据集上的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Performance comparison of modesl on Courses dataset</p>
                    <p class="img_note"></p>
                    <table id="158" border="1"><tr><td><br />模型</td><td>准确率</td><td>精度</td><td>召回率</td><td>F1值</td></tr><tr><td><br />TD-LSTM</td><td>79.83</td><td>78.12</td><td>67.66</td><td>70.1</td></tr><tr><td><br />AE-LSTM</td><td>79.00</td><td>73.88</td><td>64.16</td><td>66.99</td></tr><tr><td><br />ATAE-LSTM</td><td>81.51</td><td>79.62</td><td>70.48</td><td>68.08</td></tr><tr><td><br />IAN</td><td>78.00</td><td>75.69</td><td>52.55</td><td>61.46</td></tr><tr><td><br />Multi-ASAM</td><td>86.47</td><td>92.40</td><td>79.76</td><td>79.21</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="159">
                    <p class="img_tit"><b>表4 各模型在Restaurants数据集上的性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 Performance comparison of models on Restaurants dataset</p>
                    <p class="img_note"></p>
                    <table id="159" border="1"><tr><td><br />模型</td><td>准确率</td><td>精度</td><td>召回率</td><td>F1值</td></tr><tr><td><br />TD-LSTM</td><td>75.6</td><td>71.0</td><td>65.4</td><td>67.8</td></tr><tr><td><br />AE-LSTM</td><td>76.2</td><td>70.0</td><td>61.0</td><td>63.4</td></tr><tr><td><br />ATAE-LSTM</td><td>77.2</td><td>63.7</td><td>59.1</td><td>60.1</td></tr><tr><td><br />IAN</td><td>78.6</td><td>69.0</td><td>68.8</td><td>68.9</td></tr><tr><td><br />Multi-ASAM</td><td>79.8</td><td>75.9</td><td>69.3</td><td>69.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="160">由表2～表4可知,相比基线模型,Multi-ASAM优势较明显.首先,相比未利用两个数据集上的情感语言知识的方法(TD-LSTM,AE-LSTM,ATAE-LSTM和IAN),Multi-ASAM有实质性的改进,验证深度学习算法利用情感语言资源的有效性.同时,Multi-ASAM关注一个句子中不同方面之间隐含的内在联系,因此相比基线模型,Multi-ASAM性能具有较大提升.</p>
                </div>
                <div class="p1">
                    <p id="161">数据集上已经给出每条句子包含的方面,不同句子包含的方面可能不同.如Courses中示例“是很好学的一门课程,对于初学者也很好掌握,很多的细节老师都讲得很详细”,其中包含“课程”和“老师”两个方面,对应的情感极性都为正向.Multi-ASAM模型主要关注每个句子中不同方面间的内在关系,因此对于只含一个方面的句子的提升不大.</p>
                </div>
                <div class="p1">
                    <p id="162">由于在Education、Courses数据集中主要是多方面的句子,因此本文只使用Restaurants数据集进行单方面和多方面分类效果的对比实验,如表5所示.数据集中已经给出该条评论对应的方面.</p>
                </div>
                <div class="p1">
                    <p id="163">由表5的结果可知,Multi-ASAM对只包含单方面的句子的分类效果的提升只有0.4%,对于包含多方面的句子的准确率的提升则达到3.5%.这也是在Education、Courses数据集中IAN与Multi-ASAM相比性能相差较大的原因.</p>
                </div>
                <div class="area_img" id="164">
                    <p class="img_tit"><b>表5 不同方面数目下2种模型在Restaurants数据集上的 准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 Accuracies of 2 models with different numbers of aspects on Restaurants dataset</p>
                    <p class="img_note"></p>
                    <table id="164" border="1"><tr><td><br />模型</td><td>单方面</td><td>多方面</td></tr><tr><td><br />IAN</td><td>75.4</td><td>77.7</td></tr><tr><td><br />Multi-ASAM</td><td>75.8</td><td>81.2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="165">当句子中存在多个方面时,IAN在正确匹配方面和方面相应的情感词时出现困难.例如,在Education数据集中,对于句子“相比于枯燥的内容,我很喜欢老师的教学方式.”,其中包含两个方面:内容和老师.在真实情况下,“枯燥”与“内容”匹配,“喜欢”和“老师”匹配.然而,由图3(a)可以看出,IAN在预测“内容”方面时,将注意力权重过多地集中在“喜欢”一词上,导致生成有偏差的嵌入方面的句子表示,以至于对“内容”方面的情感类别做出错误划分.</p>
                </div>
                <div class="p1">
                    <p id="214">但是，Multi-ASAM通过词语级的嵌入方面注意力和记忆网络的组合解决这个问题．记忆网络重复地对比目标方面句子表示与其它方面的句子表示，最终从记忆网络中输出目标方面的正确表示．同时，Multi-ASAM关注方面间的关系，使网络更好地区分特定方面对应的情感词．这些点反映在“内容”和“老师”方面各自的注意力权重中，分别如图3(b)、(c)所示．</p>
                </div>
                <div class="area_img" id="215">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909008_21500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 2种模型对于同一句子的注意力权重分布" src="Detail/GetImg?filename=images/MSSB201909008_21500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 2种模型对于同一句子的注意力权重分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909008_21500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Weight distribution of attention of 2 models for the same sentence</p>

                </div>
                <h3 id="175" name="175" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="176">本文提出基于方面级别的情感分类方法(Multi-ASAM),在考虑方面间的关系对于情感极性影响的同时,考虑情感资源对于情感极性的贡献,从而达到更好的分类效果.为了验证Multi-ASAM的性能,分别使用不同方法在3个数据集上进行对比实验.结果表明,Multi-ASAM在性能上有部分提升,Multi-ASAM的提出为教育领域中的教学评价工作提供一种新的处理方法.Vaswani等<citation id="296" type="reference"><link href="268" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>提出transformer特征提取器,在很多任务中表现优异.然而,对于长输入的任务,transformer存在巨大的计算复杂度,导致速度变慢,同时相比GRU,transformer整体结构更复杂,本文使用的GRU在经过调试后整体性能表现良好.今后将尝试引入transformer的相关内容,同时关注无明显情感词的句子的情感分类,并尝试通过增加某些外部语料信息更好地解决方面水平的情感分类问题.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="216">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Which Contribution Does EDM Provide to Computer-Based Learning Environments">

                                <b>[1]</b> BOUSBIA N,BELAMRI I.Which Contribution Does EDM Provide to Computer-Based Learning Environments?// PEA,ed.Educational Data Mining.Berlin,Germany:Springer,2014:3-28.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJST&amp;filename=SJSTA6CB41CC66C0955CFE988D0A2A4ED14F&amp;v=MDUzODNwQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtNnhLcz1OaWZZZXNLK2JhUElydncyWXUxOERIVTh5bVZsbnpaMVFBdmkzUkJFZmNmZ1JMNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> GRELLER W,DRACHSLER H.Translating Learning into Numbers:A Generic Framework for Learning Analytics.Educational Technology &amp; Society,2012,15(3):42-57.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhancing Lear-ning at Work.How to Combine Theoretical and Data-Driven Approaches,and Individual,Behavioural,and Organizational Levels of Data?">

                                <b>[3]</b> KALAKOSKI V,KANNISTO H,DRUPSTEEN L.Enhancing Lear-ning at Work.How to Combine Theoretical and Data-Driven Approaches,and Individual,Behavioural,and Organizational Levels of Data?// Proc of the 23rd European Symposium on Artificial Neural Networks.Berlin,Germany:Springer,2015:331-336.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sentiment analysis: Capturing favorability using natural language processing">

                                <b>[4]</b> NASUKAWA T,YI J.Sentiment Analysis:Capturing Favorability Using Natural Language Processing // Proc of the 2nd International Conference on Knowledge Capture.New York,USA:ACM,2003:70-77.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sentiment analysis and opinion mining">

                                <b>[5]</b> LIU B.Sentiment Analysis and Opinion Mining // HIRST G,ed.Synthesis Lectures on Human Language Technologies.San Rafael,USA:Morgan &amp; Claypool Publishers,2012:1-167.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Opinion mining and sentiment analysis">

                                <b>[6]</b> PANG B,LEE L.Opinion Mining and Sentiment Analysis.Foundations and Trends® in Information Retrieval,2008,2(1/2):1-135.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Thumbs up?Sentiment Classification Using Machine Learning Techniques[C/OL]">

                                <b>[7]</b> PANG B,LEE L,VAITHYANATHAN S.Thumbs up?Sentiment Classification Using Machine Learning Techniques[C/OL].[2019-07-29].https://arxiv.org/pdf/cs/0205070.pdf.
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional Neural Networks for Sentence Classification[C/OL]">

                                <b>[8]</b> KIM Y.Convolutional Neural Networks for Sentence Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1408.5882.pdf.
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Lexicon Integrated CNN Models with Attention for Sentiment Analysis[C/OL]">

                                <b>[9]</b> SHIN B,LEE T,CHOI J D.Lexicon Integrated CNN Models with Attention for Sentiment Analysis[C/OL].[2019-07-29].https://arxiv.org/pdf/1610.06272.pdf.
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MjEzNjlPb0xEWFV4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSjE4UmJoRT1OaWZKWmJLOUh0ak1xbzlGWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> HOCHREITER S,SCHMIDHUBER J.Long Short-Term Memory.Neural Computation,1997,9(8):1735-1780.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Linguistically Regularized LSTMs for Sentiment Classification[C/OL]">

                                <b>[11]</b> QIAN Q,HUANG M L,ZHU X Y.Linguistically Regularized LSTMs for Sentiment Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1611.03949v1.pdf.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM Network for Cross-Lingual Sentiment Classification">

                                <b>[12]</b> ZHOU X J,WAN X J,XIAO J G.Attention-Based LSTM Network for Cross-Lingual Sentiment Classification // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2016:247-256.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical Attention Networks for Document Classification">

                                <b>[13]</b> YANG Z C,YANG D Y,DYER C,et al.Hierarchical Attention Networks for Document Classification // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies.Stroudsburg,USA:ACL,2016:1480-1489.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Structured Self-attentive Sentence Embedding[C/OL]">

                                <b>[14]</b> LIN Z H,FENG M W,DOS SANTOS C N,et al.A Structured Self-attentive Sentence Embedding[C/OL].[2019-7-29].https://openreview.net/pdf?id=BJC_jUqxe.
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention-based LSTM for Aspect-level Sentiment Classification">

                                <b>[15]</b> WANG Y Q,HUANG M L,ZHAO L,et al.Attention-Based LS-TM for Aspect-Level Sentiment Classification // Proc of the Confe-rence on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2016:606-615.
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive attention networks for aspect-level sentiment classification">

                                <b>[16]</b> MA D H,LI S J,ZHANG X D,et al.Interactive Attention Networks for Aspect-Level Sentiment Classification // Proc of the 26th International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:4068-4074.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning to Attend via Word-Aspect Associative Fusion for Aspect-Based Sentiment Analysis">

                                <b>[17]</b> TAY Y,TUAN L A,HUI S C.Learning to Attend via Word-Aspect Associative Fusion for Aspect-Based Sentiment Analysis // Proc of the 32nd AAAI Conference on Artificial Intelligence.Palo Alto,USA:AAAI Press,2018:5956-5963.
                            </a>
                        </p>
                        <p id="250">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Transformation Networks for Target-Oriented Sentiment Classification">

                                <b>[18]</b> LI X,BING L D,LAM W,et al.Transformation Networks for Target-Oriented Sentiment Classification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg,USA:ACL,2018:946-956.
                            </a>
                        </p>
                        <p id="252">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Memory Ntworks for Attitude Identification">

                                <b>[19]</b> LI C,GUO X X,MEI Q Z.Deep Memory Ntworks for Attitude Identification // Proc of the 10th ACM International Conference on Web Search and Data Mining.New York,USA:ACM,2017:671-680.
                            </a>
                        </p>
                        <p id="254">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL]">

                                <b>[20]</b> CHUNG J,GULCEHRE C,CHO K H,et al.Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[C/OL].[2019-07-29].https://arxiv.org/pdf/1412.3555.pdf.
                            </a>
                        </p>
                        <p id="256">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=End-to-End Memory Networks[C/OL]">

                                <b>[21]</b> SUKHBAATAR S,SZLAM A,WESTON J,et al.End-to-End Memory Networks[C/OL].[2019-07-29].https://arxiv.org/pdf/1503.08895.pdf.
                            </a>
                        </p>
                        <p id="258">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Memory Networks[C/OL]">

                                <b>[22]</b> WESTON J,CHOPRA S,BORDES A.Memory Networks[C/OL].[2019-07-29].https://arxiv.org/pdf/1410.3916.pdf.
                            </a>
                        </p>
                        <p id="260">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adam:A Method for Stochastic Optimization[C/OL]">

                                <b>[23]</b> KINGMA D P,BA J L.ADAM:A Method for Stochastic Optimization[C/OL].[2019-07-29].https://arxiv.org/pdf/1412.6980.pdf.
                            </a>
                        </p>
                        <p id="262">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining and summarizing customer reviews">

                                <b>[24]</b> HU M Q,LIU B.Mining and Summarizing Customer Reviews // Proc of the 10th ACM SIGKDD International Conference on Know-ledge Discovery and Data Mining.New York,USA:ACM,2004:168-177.
                            </a>
                        </p>
                        <p id="264">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">

                                <b>[25]</b> PENNINGTON J,SOCHER R,MANNING C D.Glove:Global Vectors for Word Representation // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg,USA:ACL,2014:1532-1543.
                            </a>
                        </p>
                        <p id="266">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Effective LSTMs for Target-Dependent Sentiment Classification[C/OL]">

                                <b>[26]</b> TANG D Y,QIN B,FENG X C,et al.Effective LSTMs for Target-Dependent Sentiment Classification[C/OL].[2019-07-29].https://arxiv.org/pdf/1512.01100.pdf.
                            </a>
                        </p>
                        <p id="268">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention Is All You Need[C/OL]">

                                <b>[27]</b> VASWANI A,SHAZEER N,PARMAR N,et al.Attention Is All You Need[C/OL].[2019-07-29].https://arxiv.org/pdf/1706.03762.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201909008" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201909008&amp;v=MDY5MjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnkva1ZydkxLRDdZYkxHNEg5ak1wbzlGYklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
