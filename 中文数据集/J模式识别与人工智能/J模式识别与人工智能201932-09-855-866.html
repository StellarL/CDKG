<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131459004248750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201909011%26RESULT%3d1%26SIGN%3dCc4p2dpq2dBBo6FSq0s%252bqQI4lag%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201909011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201909011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201909011&amp;v=MTc4OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnkva1Y3N0pLRDdZYkxHNEg5ak1wbzlFWlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#78" data-title="1 基于深度概率图模型的鲁棒人脸画像合成 ">1 基于深度概率图模型的鲁棒人脸画像合成</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="&lt;b&gt;1.1 预处理&lt;/b&gt;"><b>1.1 预处理</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;1.2 深度特征提取&lt;/b&gt;"><b>1.2 深度特征提取</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;1.3 快速近邻搜索&lt;/b&gt;"><b>1.3 快速近邻搜索</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;1.4 深度概率图模型的人脸画像合成&lt;/b&gt;"><b>1.4 深度概率图模型的人脸画像合成</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#121" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="&lt;b&gt;2.1 CUFS数据集的画像合成实验&lt;/b&gt;"><b>2.1 CUFS数据集的画像合成实验</b></a></li>
                                                <li><a href="#165" data-title="&lt;b&gt;2.2 侧面光照数据集的画像合成实验&lt;/b&gt;"><b>2.2 侧面光照数据集的画像合成实验</b></a></li>
                                                <li><a href="#187" data-title="&lt;b&gt;2.3 姿态变换数据集的画像合成实验&lt;/b&gt;"><b>2.3 姿态变换数据集的画像合成实验</b></a></li>
                                                <li><a href="#210" data-title="&lt;b&gt;2.4 复杂背景数据集的画像合成实验&lt;/b&gt;"><b>2.4 复杂背景数据集的画像合成实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#232" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#81" data-title="图1 本文算法框架">图1 本文算法框架</a></li>
                                                <li><a href="#90" data-title="图2 VGG19bn网络relu2_2层提取的人脸照片深度特征图">图2 VGG19bn网络relu2_2层提取的人脸照片深度特征图</a></li>
                                                <li><a href="#91" data-title="图3 块划分和块重叠方式">图3 块划分和块重叠方式</a></li>
                                                <li><a href="#281" data-title="图4 不同算法在CUFS数据集上的人脸画像合成结果">图4 不同算法在CUFS数据集上的人脸画像合成结果</a></li>
                                                <li><a href="#281" data-title="图4 不同算法在CUFS数据集上的人脸画像合成结果">图4 不同算法在CUFS数据集上的人脸画像合成结果</a></li>
                                                <li><a href="#282" data-title="图5 各算法合成画像的质量评价">图5 各算法合成画像的质量评价</a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;表1 不同算法在CUFS数据库上的平均质量评价分数值&lt;/b&gt;"><b>表1 不同算法在CUFS数据库上的平均质量评价分数值</b></a></li>
                                                <li><a href="#164" data-title="&lt;b&gt;表2 2种算法的运行时间对比&lt;/b&gt;"><b>表2 2种算法的运行时间对比</b></a></li>
                                                <li><a href="#283" data-title="图6 不同算法在CUHK侧面光照数据集上的画像合成结果">图6 不同算法在CUHK侧面光照数据集上的画像合成结果</a></li>
                                                <li><a href="#283" data-title="图6 不同算法在CUHK侧面光照数据集上的画像合成结果">图6 不同算法在CUHK侧面光照数据集上的画像合成结果</a></li>
                                                <li><a href="#284" data-title="图7 不同算法在CUHK姿态变换数据集上的画像合成结果">图7 不同算法在CUHK姿态变换数据集上的画像合成结果</a></li>
                                                <li><a href="#284" data-title="图7 不同算法在CUHK姿态变换数据集上的画像合成结果">图7 不同算法在CUHK姿态变换数据集上的画像合成结果</a></li>
                                                <li><a href="#285" data-title="图8 不同算法在CUHK复杂背景数据集上的画像合成结果">图8 不同算法在CUHK复杂背景数据集上的画像合成结果</a></li>
                                                <li><a href="#285" data-title="图8 不同算法在CUHK复杂背景数据集上的画像合成结果">图8 不同算法在CUHK复杂背景数据集上的画像合成结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="286">


                                    <a id="bibliography_1" title=" 王楠楠,李洁,高新波.人脸画像合成研究的综述与对比分析.模式识别与人工智能,2018,31(1):37-48.(WANG N N,LI J,GAO X B.A Review and Comparison Study on Face Sketch Synthesis.Pattern Recognition and Artificial Intelligence,2018,31(1):37-48.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201801006&amp;v=MDUzNzA1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnkva1Y3N0pLRDdZYkxHNEg5bk1ybzlGWW9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         王楠楠,李洁,高新波.人脸画像合成研究的综述与对比分析.模式识别与人工智能,2018,31(1):37-48.(WANG N N,LI J,GAO X B.A Review and Comparison Study on Face Sketch Synthesis.Pattern Recognition and Artificial Intelligence,2018,31(1):37-48.)
                                    </a>
                                </li>
                                <li id="288">


                                    <a id="bibliography_2" title=" 高新波,王楠楠,彭春蕾,等.基于三元空间融合的人脸图像模式识别.模式识别与人工智能,2015,28(9):811-821.(GAO X B,WANG N N,PENG C L,et al.Facial Image Pattern Recognition Based on Triple Space Fusion.Pattern Recognition and Artificial Intelligence,2015,28(9):811-821.)." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201509006&amp;v=MTQzMjRSTE9lWmVSbkZ5L2tWNzdKS0Q3WWJMRzRIOVRNcG85RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         高新波,王楠楠,彭春蕾,等.基于三元空间融合的人脸图像模式识别.模式识别与人工智能,2015,28(9):811-821.(GAO X B,WANG N N,PENG C L,et al.Facial Image Pattern Recognition Based on Triple Space Fusion.Pattern Recognition and Artificial Intelligence,2015,28(9):811-821.).
                                    </a>
                                </li>
                                <li id="290">


                                    <a id="bibliography_3" title=" WANG N N,TAO D C,GAO X B,et al.A Comprehensive Survey to Face Hallucination.International Journal of Computer Vision,2014,106(1):9-30." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300028332&amp;v=MjI3MTQ3QmFySzhIdExNckk5RlpPa0hEMzg3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSjE4UWF4TT1Oag==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         WANG N N,TAO D C,GAO X B,et al.A Comprehensive Survey to Face Hallucination.International Journal of Computer Vision,2014,106(1):9-30.
                                    </a>
                                </li>
                                <li id="292">


                                    <a id="bibliography_4" title=" TANG X O,WANG X G.Face Photo Recognition Using Sketches // Proc of the International Conference on Image Processing.Washing-ton,USA:IEEE,2002:257-260." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face photo recognition using sketches">
                                        <b>[4]</b>
                                         TANG X O,WANG X G.Face Photo Recognition Using Sketches // Proc of the International Conference on Image Processing.Washing-ton,USA:IEEE,2002:257-260.
                                    </a>
                                </li>
                                <li id="294">


                                    <a id="bibliography_5" title=" LIU Q S,TANG X O,JIN H L,et al.A Nonlinear Approach for Face Sketch Synthesis and Recognition // Proc of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2005,I:1005-1010." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Nonlinear Approach for Face Sketch Synthesis and Recognition">
                                        <b>[5]</b>
                                         LIU Q S,TANG X O,JIN H L,et al.A Nonlinear Approach for Face Sketch Synthesis and Recognition // Proc of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2005,I:1005-1010.
                                    </a>
                                </li>
                                <li id="296">


                                    <a id="bibliography_6" title=" SONG Y B,BAO L C,YANG Q X,et al.Real-Time Exemplar-Based Face Sketch Synthesis // Proc of the European Conference on Computer Vision.Berlin,Germany:Springer,2014:800-813." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time exemplar-based face sketch synthesis">
                                        <b>[6]</b>
                                         SONG Y B,BAO L C,YANG Q X,et al.Real-Time Exemplar-Based Face Sketch Synthesis // Proc of the European Conference on Computer Vision.Berlin,Germany:Springer,2014:800-813.
                                    </a>
                                </li>
                                <li id="298">


                                    <a id="bibliography_7" title=" CHANG L,ZHOU M Q,HAN Y J,et al.Face Sketch Synthesis via Sparse Representation // Proc of the 20th International Conference on Pattern Recognition.Washington,USA:IEEE,2010:2146-2149." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face Sketch Synthesis via Sparse Representa-tion">
                                        <b>[7]</b>
                                         CHANG L,ZHOU M Q,HAN Y J,et al.Face Sketch Synthesis via Sparse Representation // Proc of the 20th International Conference on Pattern Recognition.Washington,USA:IEEE,2010:2146-2149.
                                    </a>
                                </li>
                                <li id="300">


                                    <a id="bibliography_8" title=" GAO X B,WANG N N,TAO D C,et al.Face Sketch-Photo Synthesis and Retrieval Using Sparse Representation.IEEE Transactions on Circuits Systems for Video Technology,2012,22(8):1213-1226." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face sketch-photo synthesis and retrieval using sparse representation">
                                        <b>[8]</b>
                                         GAO X B,WANG N N,TAO D C,et al.Face Sketch-Photo Synthesis and Retrieval Using Sparse Representation.IEEE Transactions on Circuits Systems for Video Technology,2012,22(8):1213-1226.
                                    </a>
                                </li>
                                <li id="302">


                                    <a id="bibliography_9" title=" WANG N N,GAO X B,LI J.Random Sampling for Fast Face Sketch Synthesis.Pattern Recognition,2017,76:215-227." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC8063880428F3C148AB4A2467203B3E2&amp;v=MjczMThtN3dhaz1OaWZPZmNDd0h0ZlBwNGRGWU9rSGVuOUt6aElibTAxNU9YM21xaFUzZWJIbVJzK2RDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3Nw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         WANG N N,GAO X B,LI J.Random Sampling for Fast Face Sketch Synthesis.Pattern Recognition,2017,76:215-227.
                                    </a>
                                </li>
                                <li id="304">


                                    <a id="bibliography_10" title=" GAO X B,ZHONG J J,LI J,et al.Face Sketch Synthesis Algorithm Based on E-HMM and Selective Ensemble.IEEE Transac-tions on Circuit Systems for Video Technology,2008,18(4):487-496." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face sketch synthesis algorithm based on E-HMM and selective ensemble">
                                        <b>[10]</b>
                                         GAO X B,ZHONG J J,LI J,et al.Face Sketch Synthesis Algorithm Based on E-HMM and Selective Ensemble.IEEE Transac-tions on Circuit Systems for Video Technology,2008,18(4):487-496.
                                    </a>
                                </li>
                                <li id="306">


                                    <a id="bibliography_11" title=" WANG X G,TANG X O.Face Photo-Sketch Synthesis and Recognition.IEEE Transactions on Pattern Analysis and Machine Intelligence,2009,31(11):1955-1967." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face photo-sketch synthesis and recognition">
                                        <b>[11]</b>
                                         WANG X G,TANG X O.Face Photo-Sketch Synthesis and Recognition.IEEE Transactions on Pattern Analysis and Machine Intelligence,2009,31(11):1955-1967.
                                    </a>
                                </li>
                                <li id="308">


                                    <a id="bibliography_12" title=" ZHOU H,KUANG Z H,WONG K K.Markov Weight Fields for Face Sketch Synthesis // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2012:1091-1097." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Markov weight fields for face sketch synthesis">
                                        <b>[12]</b>
                                         ZHOU H,KUANG Z H,WONG K K.Markov Weight Fields for Face Sketch Synthesis // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2012:1091-1097.
                                    </a>
                                </li>
                                <li id="310">


                                    <a id="bibliography_13" title=" WANG N N,GAO X B,SUN L Y,et al.Bayesian Face Sketch Synthesis.IEEE Transactions on Image Processing,2017,26(3):1264-1274." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bayesian Face Sketch Synthesis">
                                        <b>[13]</b>
                                         WANG N N,GAO X B,SUN L Y,et al.Bayesian Face Sketch Synthesis.IEEE Transactions on Image Processing,2017,26(3):1264-1274.
                                    </a>
                                </li>
                                <li id="312">


                                    <a id="bibliography_14" title=" ZHU M R,WANG N N.A Simple and Fast Method for Face Sketch Synthesis // Proc of the International Conference on Internet Multimedia Computing and Service.New York,USA:ACM,2016:168-171." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A simple and fast method for face sketch synthesis">
                                        <b>[14]</b>
                                         ZHU M R,WANG N N.A Simple and Fast Method for Face Sketch Synthesis // Proc of the International Conference on Internet Multimedia Computing and Service.New York,USA:ACM,2016:168-171.
                                    </a>
                                </li>
                                <li id="314">


                                    <a id="bibliography_15" title=" ZHANG L L,LIN L,WU X,et al.End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning // Proc of the 5th ACM International Conference on Multimedia Retrieval.New York,USA:ACM,2015:627-634." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning">
                                        <b>[15]</b>
                                         ZHANG L L,LIN L,WU X,et al.End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning // Proc of the 5th ACM International Conference on Multimedia Retrieval.New York,USA:ACM,2015:627-634.
                                    </a>
                                </li>
                                <li id="316">


                                    <a id="bibliography_16" title=" WANG N N,ZHA W J,LI J,et al.Back Projection:An Effective Postprocessing Method for GAN-Based Face Sketch Synthesis.Pa-ttern Recognition Letters,2018,107:59-65." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES71CC88B791D41F23641078803BE1BED0&amp;v=MjU0NzhtN3dhaz1OaWZPZmJTNWJhTEVwLzFDYmVwN0NIMVB6UlVWN2o1OVQzZnFyQkZIRExQbU1NNmZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3Nw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         WANG N N,ZHA W J,LI J,et al.Back Projection:An Effective Postprocessing Method for GAN-Based Face Sketch Synthesis.Pa-ttern Recognition Letters,2018,107:59-65.
                                    </a>
                                </li>
                                <li id="318">


                                    <a id="bibliography_17" title=" ISOLA P,ZHU J Y,ZHOU T H,et al.Image-to-Image Translation with Conditional Adversarial Networks // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2017:1125-1134." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image-to-image translation with conditional adversarial networks">
                                        <b>[17]</b>
                                         ISOLA P,ZHU J Y,ZHOU T H,et al.Image-to-Image Translation with Conditional Adversarial Networks // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2017:1125-1134.
                                    </a>
                                </li>
                                <li id="320">


                                    <a id="bibliography_18" title=" ZHU J Y,PARK T,ISOLA P,et al.Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2017:2242-2251." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unpaired image-to-image translation using cycle-consistent adversarial networks">
                                        <b>[18]</b>
                                         ZHU J Y,PARK T,ISOLA P,et al.Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2017:2242-2251.
                                    </a>
                                </li>
                                <li id="322">


                                    <a id="bibliography_19" title=" ZHU M R,WANG N N,GAO X B,et al.Deep Graphical Feature Learning for Face Sketch Synthesis // Proc of the 26th International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:3574-3580." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Graphical Feature Learning for Face Sketch Synthesis">
                                        <b>[19]</b>
                                         ZHU M R,WANG N N,GAO X B,et al.Deep Graphical Feature Learning for Face Sketch Synthesis // Proc of the 26th International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:3574-3580.
                                    </a>
                                </li>
                                <li id="324">


                                    <a id="bibliography_20" title=" SIMONYAN K,ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2019-04-25].https://arxiv.org/pdf/1409.1556.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">
                                        <b>[20]</b>
                                         SIMONYAN K,ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2019-04-25].https://arxiv.org/pdf/1409.1556.pdf.
                                    </a>
                                </li>
                                <li id="326">


                                    <a id="bibliography_21" title=" ZHANG Y Q,WANG N N,ZHANG S C,et al.Fast Face Sketch Synthesis via KD-Tree Search // Proc of the European Conference on Computer Vision.Berlin,Germany:Springer,2016:64-77." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast Face Sketch Synthesis via KD-Tree Search">
                                        <b>[21]</b>
                                         ZHANG Y Q,WANG N N,ZHANG S C,et al.Fast Face Sketch Synthesis via KD-Tree Search // Proc of the European Conference on Computer Vision.Berlin,Germany:Springer,2016:64-77.
                                    </a>
                                </li>
                                <li id="328">


                                    <a id="bibliography_22" title=" SONG Y B,ZHANG J W,BAO L C,et al.Fast Preprocessing for Robust Face Sketch Synthesis // Proc of the International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:4530-4536." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast Preprocessing for Robust Face Sketch Synthesis">
                                        <b>[22]</b>
                                         SONG Y B,ZHANG J W,BAO L C,et al.Fast Preprocessing for Robust Face Sketch Synthesis // Proc of the International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:4530-4536.
                                    </a>
                                </li>
                                <li id="330">


                                    <a id="bibliography_23" title=" PIZER S M,AMBURN E P,AUSTIN J D,et al.Adaptive Histogram Equalization and Its Variations.Computer Vision,Graphics,and Image Processing,1987,39(3):355-368." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive histogram equalization and its variations">
                                        <b>[23]</b>
                                         PIZER S M,AMBURN E P,AUSTIN J D,et al.Adaptive Histogram Equalization and Its Variations.Computer Vision,Graphics,and Image Processing,1987,39(3):355-368.
                                    </a>
                                </li>
                                <li id="332">


                                    <a id="bibliography_24" title=" KAZEMI V,SULLIVAN J.One Millisecond Face Alignment with an Ensemble of Regression Trees // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2014:1867-1874." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=One millisecond face alignment with an ensemble of regression trees">
                                        <b>[24]</b>
                                         KAZEMI V,SULLIVAN J.One Millisecond Face Alignment with an Ensemble of Regression Trees // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2014:1867-1874.
                                    </a>
                                </li>
                                <li id="334">


                                    <a id="bibliography_25" title=" MARTINEZ A,BENAVENTE R.The AR Face Database.Technical Report,24.Columbus,USA:The Ohio State University,1998." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The AR face database">
                                        <b>[25]</b>
                                         MARTINEZ A,BENAVENTE R.The AR Face Database.Technical Report,24.Columbus,USA:The Ohio State University,1998.
                                    </a>
                                </li>
                                <li id="336">


                                    <a id="bibliography_26" title=" MESSER K,MATAS J,KITTLER J,et al.XM2VTS:The Extended M2VTS Database // Proc of the 2nd International Confe-rence on Audio and Video-Based Biometric Person Authentication.Berlin,Germany:Springer,1999:72-77." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=XM2VTSDB: The extended M2VTS database">
                                        <b>[26]</b>
                                         MESSER K,MATAS J,KITTLER J,et al.XM2VTS:The Extended M2VTS Database // Proc of the 2nd International Confe-rence on Audio and Video-Based Biometric Person Authentication.Berlin,Germany:Springer,1999:72-77.
                                    </a>
                                </li>
                                <li id="338">


                                    <a id="bibliography_27" >
                                        <b>[27]</b>
                                     WANG Z,BOVIK A C,SHEIKH H R,et al.Image Quality Assessment:From Error Visibility to Structural Similarity.IEEE Transactions on Image Processing,2004,13(4):600-612.</a>
                                </li>
                                <li id="340">


                                    <a id="bibliography_28" title=" SHEIKH H R,BOVIK A C.Image Information and Visual Quality.IEEE Transactions on Image Processing,2006,15(2):430-444." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image information and visual quality">
                                        <b>[28]</b>
                                         SHEIKH H R,BOVIK A C.Image Information and Visual Quality.IEEE Transactions on Image Processing,2006,15(2):430-444.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(09),855-866 DOI:10.16451/j.cnki.issn1003-6059.201909010            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度概率图模型的鲁棒人脸画像合成</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E7%8E%89%E5%80%A9&amp;code=38383114&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张玉倩</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%AB%98%E6%96%B9%E8%BF%9C&amp;code=42910507&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">高方远</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%A5%A0%E6%A5%A0&amp;code=26593382&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王楠楠</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%BB%BC%E5%90%88%E4%B8%9A%E5%8A%A1%E7%BD%91%E7%90%86%E8%AE%BA%E5%8F%8A%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0008505&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安电子科技大学综合业务网理论及关键技术国家重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%A4%A7%E5%AD%A6%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%B3%BB%E7%BB%9F%E7%A7%91%E5%AD%A6%E5%AD%A6%E9%99%A2&amp;code=0207028&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京航空航天大学数学与系统科学学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对基于数据驱动的人脸画像合成算法像素特征缺乏对光照变化和复杂背景的鲁棒性,常合成低质量的画像的问题,文中提出基于深度概率图模型的鲁棒人脸画像合成算法.采用预处理方法调整测试照片的光照亮度和人脸姿态,使之与训练照片一致.采用深度特征代替像素特征进行近邻匹配,采用深度概率图模型对画像重建权重和深度特征权重联合建模,得到合成画像的最佳重构表示.为了提高画像合成速度,提出快速近邻搜索方法.实验验证文中算法的鲁棒性和快速性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BA%BA%E8%84%B8%E7%94%BB%E5%83%8F%E5%90%88%E6%88%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">人脸画像合成;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%B2%81%E6%A3%92%E5%8C%96%E9%A2%84%E5%A4%84%E7%90%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">鲁棒化预处理;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度概率图模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BF%AB%E9%80%9F%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">快速近邻搜索;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张玉倩，硕士研究生，主要研究方向为计算机视觉、模式识别、机器学习．E-mail:yuqianz@foxmail.com.&lt;image id="278" type="formula" href="images/MSSB201909011_27800.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    高方远，本科生．E-mail:fygao.buaa@gmail.com.&lt;image id="279" type="formula" href="images/MSSB201909011_27900.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    *王楠楠(通讯作者)，博士，教授，主要研究方向为计算机视觉、模式识别、机器学习．E-mail:nnwang@xidian.edu.cn.&lt;image id="280" type="formula" href="images/MSSB201909011_28000.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-05-15</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(No.61876142)资助;</span>
                    </p>
            </div>
                    <h1><b>Robust Face Sketch Synthesis Based on Deep Probabilistic Graphical Models</b></h1>
                    <h2>
                    <span>ZHANG Yuqian</span>
                    <span>GAO Fangyuan</span>
                    <span>WANG Nannan</span>
            </h2>
                    <h2>
                    <span>State Key Laboratory of Integrated Services Networks,Xidian University</span>
                    <span>Institute of Mathematics and Systems Science,Beihang University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Since pixel level features in the data-driven face sketch synthesis algorithms lack robustness to illumination variation and complex background, the quality of synthesized face sketches is poor. In this paper, a robust face sketch synthesis algorithm based on deep probabilistic graphical models is proposed. A preprocessing method is adopted to adjust illumination brightness and face pose of an input photo to make them consistent with the training photos. Instead of pixel feature, deep feature representation is utilized for neighbor selecting. A deep probabilistic graphical model is employed to jointly model the weight of sketch reconstruction and the weight of deep feature, and therefore the best reconstruction representation of the synthetic image is obtained. A fast nearest neighbor search method is proposed to speed up sketch synthesis. Experimental results verify robustness and rapidity of the proposed algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Face%20Sketch%20Synthesis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Face Sketch Synthesis;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Robust%20Preprocessing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Robust Preprocessing;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20Probabilistic%20Graphical%20Model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep Probabilistic Graphical Model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fast%20Neighbor%20Search&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Fast Neighbor Search;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    ZHANG Yuqian,master student. Her research interests include computer vision,pattern recognition and machine learning.;
                                </span>
                                <span>
                                    GAO Fangyuan,undergraduate student.;
                                </span>
                                <span>
                                    WANG Nannan ( Corresponding author) , Ph. D. ,professor. His research interests include computer vision,pattern recognition and machine learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-05-15</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China(No.61876142);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="70">人脸画像合成技术<citation id="342" type="reference"><link href="286" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>是指将人脸照片通过特定方法转换成人脸画像的技术.随着科技的不断发展与进步,人脸画像合成技术在刑侦判案<citation id="343" type="reference"><link href="288" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、数字娱乐及移动互联网等领域的应用愈加广泛,成为计算机视觉<citation id="344" type="reference"><link href="290" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、人脸识别领域研究的热点及关键.在通常情况下, 用 于 画 像合成的训练库照片由专业设备在自然光照、背景单一的环境中采集得到，画像合成技术需要学习照片域与画像域之间的映射关系．采集到的人脸图像一般为正面姿态，而在现实场景中，由于光照条件多变，背景环境复杂，采集到的测试照片中往往存在曝光、暗光、光照不均，侧面人脸姿态等问题．测试照片的光照亮度和人脸姿态与训练集照片之间的差异，容易导致以像素亮度信息进行近邻搜索的画像合成算法的误匹配，使合成的画像结果中包含大量噪声、伪影和变形，极大影响合成画像的质量．</p>
                </div>
                <div class="p1">
                    <p id="74">人脸画像合成技术需要学习照片域与画像域之间的映射关系.现有的人脸画像合成算法主要分为两类:1)基于数据驱动的人脸画像合成算法;2)基于模型驱动的人脸画像合成算法.</p>
                </div>
                <div class="p1">
                    <p id="75">基于数据驱动的方法又称为基于样例的人脸画像合成方法,可分为:1)基于子空间学习的方法<citation id="348" type="reference"><link href="292" rel="bibliography" /><link href="294" rel="bibliography" /><link href="296" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>,如局部线性嵌入方法(Local Linear Embe-dding, LLE)<citation id="345" type="reference"><link href="294" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>和基于稀疏表示的方法<citation id="349" type="reference"><link href="298" rel="bibliography" /><link href="300" rel="bibliography" /><link href="302" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>.2)基于概率图模型的方法<citation id="350" type="reference"><link href="304" rel="bibliography" /><link href="306" rel="bibliography" /><link href="308" rel="bibliography" /><link href="310" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>,如基于马尔科夫随机场(Markov Random Fields, MRF)的方法<citation id="346" type="reference"><link href="306" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和基于马尔科夫权重场(Markov Weight Fields, MWF)的方法<citation id="347" type="reference"><link href="308" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>.基于数据驱动的人脸画像合成算法大多以像素亮度为特征进行测试照片块与训练照片块之间的近邻匹配,忽略人脸的结构信息,对测试照片的姿态变换和光照变化并不鲁棒,使合成的画像结果中出现噪声、模糊、伪影、变形和局部残缺等问题.</p>
                </div>
                <div class="p1">
                    <p id="76">基于模型驱动的人脸画像合成方法可以分为基于线性模型驱动的方法和基于非线性模型驱动的方法,包括:基于线性回归(Linear Regression, LR)的方法<citation id="351" type="reference"><link href="312" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>,基于全卷积网络(Fully Convolutional Network,FCN)的方法<citation id="352" type="reference"><link href="314" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>,基于生成对抗网络(Generative Adversarial Networks, GAN)的画像生成方法<citation id="355" type="reference"><link href="316" rel="bibliography" /><link href="318" rel="bibliography" /><link href="320" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>,如Pix2Pix(Pixel to Pixel)<citation id="353" type="reference"><link href="318" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和CycleGAN(Cycle Generative Adversarial Networks)<citation id="354" type="reference"><link href="320" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>.上述算法需要大量的训练数据才能训练得到一个表示能力较强的模型,当训练数据量不足时,合成的画像结果会包含较多的噪声和人工痕迹(Artifacts).</p>
                </div>
                <div class="p1">
                    <p id="77">深度学习判别模型在图像分类和目标识别领域取得不错的成绩.实验表明,深度卷积神经网络能提取图像的高级特征,这些特征具有对物体结构的表征能力.Zhu等<citation id="356" type="reference"><link href="322" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>提出基于深度图特征学习 的 人 脸画像合成方法(Deep Graphical Feature Learning, DGFL),相比以像素亮度特征进行近邻匹配的画像合成方法,能够生成更清晰、更少噪声的画像结果<citation id="357" type="reference"><link href="324" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>.但是,当输入照片存在光照不均、非正面姿态人脸或复杂背景时,同样不能合成高质量的人脸画像.另外,由于深度特征具有很高的维度,使用深度特征进行近邻块匹配需要大量复杂的距离计算,Zhu等<citation id="358" type="reference"><link href="322" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>在算法实现中使用<i>K</i>维树(<i>K</i> Dimensional Tree, KDTree)构建深度特征索引结构的方式,加快近邻搜索的进程,但需要很长时间合成一张人脸画像.鉴于此种情况,本文提出基于深度概率图模型的鲁棒人脸画像合成算法,可以有效提高画像合成算法的鲁棒性和快速性.</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag">1 基于深度概率图模型的鲁棒人脸画像合成</h3>
                <div class="p1">
                    <p id="79">本文提出基于深度概率图模型的鲁棒人脸画像合成算法,在预处理阶段,通过调整输入照片的亮度和人脸姿态与训练照片一致,用于加强合成画像的鲁棒性.采用从预训练的深度学习网络中提取的深度特征代替像素亮度特征,表示训练照片块和测试照片块.在近邻搜索阶段,为了提高特征块的匹配速度,提出快速近邻搜索方法,进行更高效的块匹配.在重建权重与深度表示权重的优化计算阶段,采用深度概率图模型对两者进行联合建模求解.</p>
                </div>
                <div class="p1">
                    <p id="80">本文算法的整体框架如图1所示.在训练阶段,将所有训练照片输入到预训练的极深卷积网络(Very Deep Convolutional Networks, VGG)<citation id="359" type="reference"><link href="326" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>中,提取relu2_2层的输出作为训练照片的深度特征.在测试阶段,采用VGG网络提取测试照片的深度特征,将训练照片与测试照片的深度特征及训练画像以相同方法划分为互相重叠的小块.对于每个测试照片特征块,采用提出的快速近邻搜索算法在训练照片特征块中寻找它的<i>K</i>个最近邻,再将所有的测试照片特征块、近邻照片特征块、近邻画像块输入到深度概率图模型中,学习深度特征权重和画像重建权重的最优表示.最后通过重建权重与近邻画像块的线性组合重建画像块,采用平均相邻块重叠区域像素值的方式将合成的所有画像块融合成与原输入照片同等大小的人脸画像.</p>
                </div>
                <div class="area_img" id="81">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法框架" src="Detail/GetImg?filename=images/MSSB201909011_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_081.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Framework of the proposed algorithm</p>

                </div>
                <h4 class="anchor-tag" id="82" name="82"><b>1.1 预处理</b></h4>
                <div class="p1">
                    <p id="83">针对人脸画像合成中输入照片与训练照片在人脸姿态、光照条件上的差异,本文采用预处理方法<citation id="360" type="reference"><link href="328" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>,将输入照片调整为与训练集照片相同的光照和人脸姿态,从而使画像合成算法对任意的输入照片鲁棒.对于输入的人脸照片,首先通过局部仿射变换将人脸图像校正为正面姿态,再判断输入照片是否存在侧面光照不均的情况,如果存在,采用限制对比度自适应直方图均衡化(Contrast Limited Adaptive Histogram Equalization)方法<citation id="361" type="reference"><link href="330" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>降低输入照片的对比度,通过人脸关键点<citation id="362" type="reference"><link href="332" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>将输入照片划分为对称的两部分,暗光一侧的照片块根据正常光照一侧的最近邻块的亮度进行伽玛校正调整.之后采用双向亮度重映射算法<citation id="363" type="reference"><link href="328" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>进行全局光照的调整:采用抠图算法将测试照片和训练照片划分为前景、背景和二值图像,调整测试照片的前景亮度,使其与所有训练照片的前景亮度均值一致,然后调整训练照片背景区域的亮度,使其与测试照片整体的统计亮度值一致.通过交互式地对训练库图像和测试图像进行亮度重映射,实现测试照片与训练库照片的统计亮度值一致,完成整个预处理步骤.</p>
                </div>
                <div class="p1">
                    <p id="84">合成画像后可再次通过局部仿射变换将合成画像恢复成测试照片输入时的姿态.对于存在复杂背景的测试照片,在合成画像后,使用抠图算法得到的二值图像提取合成画像的前景区域,有效减少因测试照片背景复杂而在合成画像中引入的噪声.</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>1.2 深度特征提取</b></h4>
                <div class="p1">
                    <p id="86">目前学者们提出很多深度网络,如VGG、深度残差网络(Deep Residual Networks, ResNet)、稠密连接卷积网络(Densely Connected Convolutional Networks, DenseNet).这些网络因为其较深的网络层数,具有优良的性能,均可以作为图像深度特征的特征提取器.在实现本文算法的过程中,通过实验发现,使用VGG、ResNet或DenseNet网络提取图像的深度特征进行人脸画像合成,均能得到高质量的人脸画像.本文以VGG网络为例说明深度特征的提取步骤,以及如何采用深度特征进行人脸画像合成.在实际应用中,可根据需要选择不同的深度特征提取网络.</p>
                </div>
                <div class="p1">
                    <p id="87">在ImageNet分类任务上预训练地加入批量归一化的19层VGG网络(VGG19bn Network),使用该网络提取人脸图像的深度特征,采用relu2_2层的128维输出作为输入照片的深度特征图.如图2所示,relu2_2层提取的深度特征图中包含人脸的结构信息,对光照变化更鲁棒.由于VGG19bn的网络中使用最大池化层(Max Pooling Layer),所以relu2_2层输出的深度特征图尺寸小于输入图像.本文采用插值的方法将深度特征图变换成输入图像的大小.提取深度特征图后,将测试照片和训练照片的深度特征图与训练画像以图3的方式划分为互相重叠的小块.令<i>x</i><sub><i>i</i></sub>(<i>i</i>=1,2,…,<i>N</i>)表示第<i>i</i>个测试照片块,则测试照片块<i>x</i><sub><i>i</i></sub>的深度特征表示<i>D</i>(<i>x</i><sub><i>i</i></sub>)可以通过128维特征图的加权线性组合得到,权重系数<i><b>u</b></i><sub><i>i</i></sub>是一个128维的向量:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>l</mi></mrow></msub><mi>d</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">其中,<i>d</i><sub><i>l</i></sub>(<i>x</i><sub><i>i</i></sub>)表示块<i>x</i><sub><i>i</i></sub>第<i>l</i>个特征图,<i>u</i><sub><i>il</i></sub>表示第<i>l</i>个特征图对应的权重系数,<mathml id="234"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>L</mi><mo>,</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>l</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>,在本文中<i>L</i>=128.</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 VGG19bn网络relu2_2层提取的人脸照片深度特征图" src="Detail/GetImg?filename=images/MSSB201909011_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 VGG19bn网络relu2_2层提取的人脸照片深度特征图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Deep feature maps extracted from VGG19bn network relu2_2 layer</p>

                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 块划分和块重叠方式" src="Detail/GetImg?filename=images/MSSB201909011_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 块划分和块重叠方式  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_09100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Patch partition and patch overlapping mode</p>

                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>1.3 快速近邻搜索</b></h4>
                <div class="p1">
                    <p id="93">对于测试照片特征图中的每个特征块,需要通过近邻搜索算法在训练照片特征块中找到与之最相似的<i>K</i>个近邻块.本节提出快速近邻搜索方法,基于<i>L</i>1距离度量,为了避免大量的循环计算,采用计算差分图的方法代替循环计算每个特征块之间欧氏距离的方法.具体实现如下:首先将每张训练照片的特征图以复制边界像素值的方式进行边界填充,然后将训练照片特征图在搜索区域内偏移后的特征图与测试照片的特征图相比,计算差的绝对值,从而得到一张差分图,将该差分图以图3的方式划分为互相重叠的小块,对差分图中每个小块的值求和,结果即为该索引位置的训练特征块与测试特征块的匹配代价.对所有的训练照片特征图进行同样的操作,最后求得的每个位置匹配代价最小的<i>K</i>个训练特征块即为该位置测试照片特征块的<i>K</i>近邻.通过<i>K</i>近邻训练特征块的索引位置,可以找到测试照片块对应的<i>K</i>近邻照片块和<i>K</i>近邻画像块.</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>1.4 深度概率图模型的人脸画像合成</b></h4>
                <div class="p1">
                    <p id="95">对于给定的一张测试照片块<i>x</i><sub><i>i</i></sub>和它的深度表示<i>D</i>(<i>x</i><sub><i>i</i></sub>),目标是合成<i>x</i><sub><i>i</i></sub>对应的画像块<i>y</i><sub><i>i</i></sub>.首先在训练照片块局部搜索范围内找到与测试照片块<i>x</i><sub><i>i</i></sub>最相似的<i>K</i>个候选照片块{<i>x</i><sub><i>i</i></sub><sub>1</sub>,<i>x</i><sub><i>i</i></sub><sub>2</sub>,…,<i>x</i><sub><i>iK</i></sub>},以及候选照片块对应的训练画像块{<i>y</i><sub><i>i</i></sub><sub>1</sub>,<i>y</i><sub><i>i</i></sub><sub>2</sub>,…,<i>y</i><sub><i>iK</i></sub>}.假设候选照片块线性组合的系数与候选画像块线性组合的系数相同,待合成画像块<i>y</i><sub><i>i</i></sub>可由<i>K</i>个候选画像块的线性组合得到,重建系数<i><b>w</b></i><sub><i>i</i></sub>是一个<i>K</i>维的向量:</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="235"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mi>y</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>,</mo><mspace width="0.25em" /><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></math></mathml>,      (1)</p>
                </div>
                <div class="p1">
                    <p id="97">其中<i>w</i><sub><i>ik</i></sub>表示第<i>k</i>个候选画像块对应的权重系数.</p>
                </div>
                <div class="p1">
                    <p id="98">优化两个权重向量:深度表示的权重向量<i><b>u</b></i><sub><i>i</i></sub>和画像块重建的权重向量<i><b>w</b></i><sub><i>i</i></sub>.<i><b>w</b></i><sub><i>i</i></sub>决定合成画像块的质量,而<i><b>u</b></i><sub><i>i</i></sub>决定深度特征的表示能力,并间接影响重建权重.对深度表示和画像重建的权重向量进行联合建模,得到<i><b>u</b></i><sub><i>i</i></sub>和<i><b>w</b></i><sub><i>i</i></sub>的最优表示.<i><b>u</b></i><sub><i>i</i></sub>和<i><b>w</b></i><sub><i>i</i></sub>的联合概率可表示为</p>
                </div>
                <div class="area_img" id="99">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201909011_09900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="101">其中:<i>Φ</i>(<i><b>u</b></i><sub><i>i</i></sub>,<i><b>w</b></i><sub><i>i</i></sub>)为局部验证函数(Local Evidence Function),用于保证加权线性组合后的训练照片特征块与测试照片特征块尽可能的相似,</p>
                </div>
                <div class="area_img" id="103">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201909011_10300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="104"><i>Ψ</i>(<i><b>w</b></i><sub><i>i</i></sub>,<i><b>w</b></i><sub><i>j</i></sub>)为邻域兼容函数(Neighboring CompatibilityFunction),约束相邻的两个重建画像块的重叠区域尽可能的相似,从而保证合成的画像结果纹理平滑,</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ψ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">{</mo><mo>-</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>δ</mi><msubsup><mrow></mrow><mi>S</mi><mn>2</mn></msubsup></mrow></mfrac><mrow><mo>|</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mi>o</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow><mi>j</mi></msubsup><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow></msub><mi>o</mi><msubsup><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow><mi>i</mi></msubsup></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mo>;</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107"><i>Υ</i>(<i><b>u</b></i><sub><i>i</i></sub>)为正则化函数(Regularization Function),</p>
                </div>
                <div class="p1">
                    <p id="108"><mathml id="236"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ϒ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>exp</mi></mrow><mo stretchy="false">(</mo><mo>-</mo><mi>λ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="109"><i>d</i><sub><i>l</i></sub>(<i>x</i><sub><i>i</i></sub>)为块<i>x</i><sub><i>i</i></sub>的第<i>l</i>张特征图,<i>d</i><sub><i>l</i></sub>(<i>x</i><sub><i>ik</i></sub>)为第<i>k</i>个候选近邻块的第<i>l</i>张特征图,(<i>i</i>,<i>j</i>)∈<i>Ξ</i>表示第<i>i</i>个块和第<i>j</i>个块是相邻块;<i>o</i><mathml id="237"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow><mi>j</mi></msubsup></mrow></math></mathml>为候选画像块<i>y</i><sub><i>ik</i></sub>和相邻的第<i>j</i>个候选块的重叠区域;<i>δ</i><sub><i>D</i></sub>和<i>δ</i><sub><i>S</i></sub>为比例系数,<i>λ</i>为平衡正则函数、局部验证函数和邻域兼容函数的影响比例.</p>
                </div>
                <div class="p1">
                    <p id="110">最大化公式(2)中的联合概率以获得<i><b>u</b></i><sub><i>i</i></sub>和<i><b>w</b></i><sub><i>i</i></sub>最优的权重表示.最大化后验概率的问题可以转换成如下最小化问题:</p>
                </div>
                <div class="area_img" id="112">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201909011_11200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="113">采用如下交互式的优化策略解决该最小化问题.</p>
                </div>
                <div class="p1">
                    <p id="114">1)固定<i>u</i>.式(3)可简化为</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">w</mi></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">|</mo></mstyle><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mi>D</mi><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mi>α</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>Ξ</mi></mrow></munder><mo stretchy="false">|</mo></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mi>o</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mi>j</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow></msub><mi>o</mi><msubsup><mrow></mrow><mrow><mi>j</mi><mi>k</mi></mrow><mi>i</mi></msubsup><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup><mo>,</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">其中<i>α</i>=<i>δ</i><mathml id="238"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>D</mi><mn>2</mn></msubsup></mrow></math></mathml>/<i>δ</i><mathml id="239"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>S</mi><mn>2</mn></msubsup></mrow></math></mathml>.该最小化问题可以通过Zhou等<citation id="364" type="reference"><link href="308" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出的级联分解方法解决.</p>
                </div>
                <div class="p1">
                    <p id="117">2)固定<i>w</i>.式(3)可简化为</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">u</mi></munder><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mi>u</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>l</mi></mrow></msub><mi>p</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>l</mi></mrow></msub><mo>+</mo><mi>λ</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup><mo>⇒</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mspace width="0.25em" /><mi>λ</mi><mi mathvariant="bold-italic">u</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi mathvariant="bold-italic">p</mi><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo></mtd></mtr><mtr><mtd><mi>p</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>l</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mi>δ</mi><msubsup><mrow></mrow><mi>S</mi><mn>2</mn></msubsup></mrow></mfrac><mo stretchy="false">|</mo><mi>d</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mi>d</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">|</mo><msup><mrow></mrow><mn>2</mn></msup><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="119">上式是一个标准的凸二次规划问题,可以使用二次规划工具箱有效求解.</p>
                </div>
                <div class="p1">
                    <p id="120">将<i>u</i><sub><i>il</i></sub>初始化为1/<i>L</i>,<i>w</i><sub><i>ik</i></sub>初始化为1/<i>K</i>,迭代执行1)和2)直到模型收敛.当得到最优的画像块重建权重<i><b>w</b></i><sub><i>i</i></sub>后,由式(1)可以得到重建画像块{<i>y</i><sub>1</sub>,<i>y</i><sub>2</sub>,…,<i>y</i><sub><i>N</i></sub>}.通过平均这些画像块的重叠区域得到与输入照片同样大小的合成画像.</p>
                </div>
                <h3 id="121" name="121" class="anchor-tag">2 实验及结果分析</h3>
                <div class="p1">
                    <p id="122">为了验证本文算法的有效性和快速性,在香港中文大学的人脸素描画像数据库(CUHK Face Sketch Dataset, CUFS)上进行对比实验.CUFS数据库包含CUHK Student<citation id="365" type="reference"><link href="292" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、AR<citation id="366" type="reference"><link href="334" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>和XM2VTS<citation id="367" type="reference"><link href="336" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>数据集.CUHK Student数据集包含188幅人脸照片-画像对,选择其中的88对作为训练数据,剩余的100对作为测试数据.AR数据集包括123幅照片-画像对,选择其中的80对作为训练数据,剩余的43对作为测试数据.XM2VTS数据集包含295幅不同人的人脸照片-画像对,选择其中的100对作为训练数据,剩余的195对作为测试数据.CUFS数据库中照片和画像均为正常光照、自然表情、无遮挡情况下的正面人脸图像,所有画像都为写实风格,所有图像大小均为250×200,并均已经过画像几何位置配准,使得左、右瞳孔位于图像的固定位置,分别为(75,125)和(125,125).</p>
                </div>
                <div class="p1">
                    <p id="123">对比算法包括LLE<citation id="368" type="reference"><link href="294" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>,MRF<citation id="369" type="reference"><link href="306" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,MWF<citation id="370" type="reference"><link href="308" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>,Bayesian<citation id="371" type="reference"><link href="310" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>,Pix2Pix<citation id="372" type="reference"><link href="318" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>,CycleGAN<citation id="373" type="reference"><link href="320" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>,DGFL<citation id="374" type="reference"><link href="322" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>.LLE、MRF、MWF、Bayesian、DGFL及本文算法是基于数据驱动的画像合成算法,Pix2Pix和CycleGAN是基于模型驱动的画像合成算法.</p>
                </div>
                <div class="p1">
                    <p id="124">为了验证本文算法对光照、姿态变化、复杂背景的鲁棒性,在CUHK侧面光照数据集、CUHK姿态变换数据集和CUHK复杂背景数据集上进行画像合成的对比实验.因为Pix2Pix在训练和测试阶段均需要严格对齐的成对数据,而CUHK侧面光照、姿态变化、复杂背景数据集中只包含测试照片,不包含测试画像,因此在这些对比实验中采取的对比算法为LLE、MRF、MWF、CycleGAN及DGFL,不包含Pix2Pix.</p>
                </div>
                <div class="p1">
                    <p id="125">本文算法采用的参数设置如下:图像块大小为10×10,相邻块的重叠区域为5个像素,近邻搜索半径为5,搜索到的近邻块的数量<i>K</i>=10,<i>α</i>=0.25,<i>λ</i>=2,训练照片深度特征以复制边界像素的方式扩充20个像素.</p>
                </div>
                <div class="p1">
                    <p id="126">所有实验在系统为Ubuntu 16.04,CPU为i7-8700K 3.70 GHz,GPU为TITAN XP的计算机设备上进行.LLE、MRF、MWF和Bayesian的运行代码基于Matlab语言.Pix2Pix、CycleGAN、DGFL和本文算法的执行基于Python语言.CycleGAN和Pix2Pix采用Pytorch深度学习框架.</p>
                </div>
                <h4 class="anchor-tag" id="127" name="127"><b>2.1 CUFS数据集的画像合成实验</b></h4>
                <div class="p1">
                    <p id="128">图4为不同算法在CUFS数据集上的画像合成结果.由图可以看出,LLE、MRF和MWF合成的画像结果中包含非常明显的模糊和噪声,有些合成画像的头发区域存在画像块缺失的问题.Pix2Pix合成画像中的头发纹理较不自然,Pix2Pix和CycleGAN合成结果中包含较多的噪声和人工痕迹(Aritifacts),这是因为基于模型驱动的画像合成算法需要大量的训练数据才能完全拟合训练数据的数据分布.在画像合成的实验中,训练照片-画像对数据太少,Pix2Pix和CycleGAN无法训练得到表示能力较强的模型.另外,Pix2Pix和CycleGAN合成的人脸画像更像测试照片,而不是画家绘制的画像.相比其它算法,DGFL和本文算法能够合成纹理清晰的五官和头发区域,画像结果整体平滑,几乎不包含噪声.在第4幅～第6幅的画像合成结果中,相比DGFL,本文算法能够合成更浓密黑亮的头发,更好的嘴巴区域,说明本文算法具有更优的性能.</p>
                </div>
                <div class="area_img" id="281">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同算法在CUFS数据集上的人脸画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同算法在CUFS数据集上的人脸画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Face sketch synthesis results of different algorithms on CUFS dataset</p>

                </div>
                <div class="area_img" id="281">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同算法在CUFS数据集上的人脸画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同算法在CUFS数据集上的人脸画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28101.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Face sketch synthesis results of different algorithms on CUFS dataset</p>

                </div>
                <div class="p1">
                    <p id="154">为了定量阐述本文算法的有效性,使用结构相似性准则(Structural Similarity Image Measurement, SSIM)<citation id="375" type="reference"><link href="338" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>和信息保真度准则(Visual Information Fidelity, VIF)<citation id="376" type="reference"><link href="340" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>评估不同算法在CUFS数据库上合成画像的质量.SSIM和VIF属于客观质量评价方法,在生成的画像质量评价结果图中,横轴坐标表示客观质量评价的分数,纵轴坐标表示合成画像的质量分数不小于横轴坐标分数的样本百分比.在相同的横轴质量分数值下,曲线对应的纵轴值越大,说明算法合成的画像质量越好.图5给出不同算法在CUFS数据集上合成画像的SSIM和VIF质量评价图.由图可看出,本文算法在CUFS数据库上具有和DGFL基本相当的质量评价值,质量均优于LLE、MRF、MWF、Bayesian、Pix2Pix及CycleGAN.</p>
                </div>
                <div class="area_img" id="282">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 各算法合成画像的质量评价" src="Detail/GetImg?filename=images/MSSB201909011_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 各算法合成画像的质量评价  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Quality evaluation of synthsis sketches</p>

                </div>
                <div class="p1">
                    <p id="158">同时计算不同画像合成算法在CUFS数据库上质量评价分数的均值,质量评价分数越高,说明算法合成画像的质量越好.平均质量评价分数值如表1所示,本文算法在CUFS数据库上具有最高的SSIM评价分数值,有和DGFL相当的VIF评价分数值,并且优于其它的画像合成算法.</p>
                </div>
                <div class="area_img" id="159">
                    <p class="img_tit"><b>表1 不同算法在CUFS数据库上的平均质量评价分数值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Mean quality evaluation score of different algorithms on CUFS dataset</p>
                    <p class="img_note"></p>
                    <table id="159" border="1"><tr><td></td><td>LLE</td><td>MRF</td><td>MWF</td><td>Pix2Pix</td><td>CycleGAN</td><td>DGFL</td><td>本文<br />算法</td></tr><tr><td>SSIM</td><td>0.526</td><td>0.513</td><td>0.539</td><td>0.482</td><td>0.500</td><td>0.564</td><td><b>0.565</b></td></tr><tr><td>VIF</td><td>0.075</td><td>0.068</td><td>0.076</td><td>0.071</td><td>0.075</td><td><b>0.082</b></td><td><b>0.082</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="160">本文提出应用于深度概率图画像合成算法的快速近邻匹配方法.为了验证本文方法的快速性,对比本文算法和DGFL的运行时间.</p>
                </div>
                <div class="p1">
                    <p id="161">基于深度概率图的画像合成算法最耗时的步骤包括近邻搜索阶段和权重优化阶段.近邻搜索的时间消耗取决于训练照片的数量、搜索区域的范围、划分块的数量;权重优化的时间消耗取决于优化步骤迭代的次数和设置的近邻块数量.</p>
                </div>
                <div class="p1">
                    <p id="162">将两种算法在相同的CUFS数据集上进行实验,近邻匹配阶段搜索半径的大小均设为5个像素,划分块的大小为10×10,块之间的重叠区域为5个像素,权重优化的迭代次数设为8,近邻块的数量设为10.</p>
                </div>
                <div class="p1">
                    <p id="163">表2为2种算法在CUFS数据集上合成一幅人脸画像的平均时间,以及合成每幅画像近邻搜索所需的时间.实验数据表明,本文算法在近邻搜索阶段能进行更高效的块匹配,因此具有更快的画像合成速度.而DGFL因为构建的KDTree维数过高导致合成一幅人脸画像需要较长的时间.</p>
                </div>
                <div class="area_img" id="164">
                    <p class="img_tit"><b>表2 2种算法的运行时间对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Running time comparison of 2 algorithms </p>
                    <p class="img_note"></p>
                    <table id="164" border="1"><tr><td><br /></td><td>DGFL</td><td>本文算法</td></tr><tr><td><br />每幅画像近邻搜索时间</td><td>24.5</td><td>3.5</td></tr><tr><td><br />每幅画像合成时间</td><td>27.0</td><td>6.0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="165" name="165"><b>2.2 侧面光照数据集的画像合成实验</b></h4>
                <div class="p1">
                    <p id="166">为了验证本文算法对侧面光照测试照片的鲁棒性,在CUHK侧面光照的数据集上进行画像合成的实验.图6为不同算法合成的画像结果,可以发现,当输入测试照片的光照不均时,LLE、MRF、MWF均不能生成正确的人脸画像,合成的画像结果中包含大量的黑影、噪声和五官形变.CycleGAN生成的画像在人脸区域包含较多的噪声和人工痕迹(Artifacts),并且受测试照片中侧面光照的影响,画像结果中包含明显的阴影.DGFL合成画像的头发、人脸轮廓区域出现白色的画像块缺失区域.相比之下,本文算法能够有效处理测试照片中的阴影区域,生成纹理清晰、保真度较高的人脸画像,说明本文算法对复杂光照具有更高的鲁棒性.</p>
                </div>
                <div class="area_img" id="283">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法在CUHK侧面光照数据集上的画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法在CUHK侧面光照数据集上的画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Sketch synthesis results of different algorithms on CUHKside lighting dataset</p>

                </div>
                <div class="area_img" id="283">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法在CUHK侧面光照数据集上的画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法在CUHK侧面光照数据集上的画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.6 Sketch synthesis results of different algorithms on CUHKside lighting dataset</p>

                </div>
                <h4 class="anchor-tag" id="187" name="187"><b>2.3 姿态变换数据集的画像合成实验</b></h4>
                <div class="p1">
                    <p id="188">为了验证本文算法对非正面姿态测试照片的鲁棒性,在CUHK姿态变换数据集上进行画像合成的实验.图7为不同算法的画像合成结果.</p>
                </div>
                <div class="area_img" id="284">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法在CUHK姿态变换数据集上的画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同算法在CUHK姿态变换数据集上的画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Sketch synthesis results of different algorithms on CUHKpose variation dataset</p>

                </div>
                <div class="area_img" id="284">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法在CUHK姿态变换数据集上的画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同算法在CUHK姿态变换数据集上的画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.7 Sketch synthesis results of different algorithms on CUHKpose variation dataset</p>

                </div>
                <div class="p1">
                    <p id="209">由图7可看出,LLE、MRF及MWF合成的画像在人脸头发、下巴和脸颊区域包含较多的噪声和伪影,并且在人脸轮廓区域出现画像块缺失的问题.CycleGAN合成的画像在人脸的五官区域,如眼睛、鼻子、嘴巴等地方包含较多的噪声,头发区域包含很多的人工痕迹(Artifacts).DGFL合成的人脸画像在人脸轮廓区域同样出现画像块缺失的问题.相比之下,本文算法能够生成更完整、更高保真度的人脸画像,合成的画像结果纹理更平滑,不包含噪声,这说明本文算法对非正面姿态的测试照片具有更高的鲁棒性.</p>
                </div>
                <h4 class="anchor-tag" id="210" name="210"><b>2.4 复杂背景数据集的画像合成实验</b></h4>
                <div class="p1">
                    <p id="211">为了验证本文算法对复杂背景下测试照片的鲁棒性,将CUHK Student数据集中测试照片的蓝色单色背景替换成复杂背景,构建CUHK复杂背景测试集.图8为不同算法在CUHK复杂背景数据集中的画像合成结果.由图可看出,当测试照片背景区域中的物体颜色较浅时,如背景区域是蓝天白云(图8(a)中的第1幅测试照片)时,不同算法均能得到质量较好的画像合成结果,本文算法合成画像的背景区域不包含噪声.当测试照片的背景区域存在颜色较深的物体或背景的整体色调较深(图8(a)第2幅、第3幅测试照片)时,以像素亮度特征作为近邻匹配特征的LLE、MRF和MWF合成画像的背景区域会包含较多黑影,而将整幅照片进行画像转换的CycleGAN合成的画像中会包含完整的背景元素,本文算法无论在何种条件下均能生成背景干净的人脸画像.实验说明本文算法对复杂背景具有更高的鲁棒性.</p>
                </div>
                <div class="area_img" id="285">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同算法在CUHK复杂背景数据集上的画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同算法在CUHK复杂背景数据集上的画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Sketch synthesis results of different algorithms on CUHKcomplex background dataset</p>

                </div>
                <div class="area_img" id="285">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909011_28501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同算法在CUHK复杂背景数据集上的画像合成结果" src="Detail/GetImg?filename=images/MSSB201909011_28501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同算法在CUHK复杂背景数据集上的画像合成结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909011_28501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.8 Sketch synthesis results of different algorithms on CUHKcomplex background dataset</p>

                </div>
                <h3 id="232" name="232" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="233">本文提出基于深度概率图模型的鲁棒人脸画像合成算法,采用从预训练的VGG19bn网络提取的深度特征代替像素亮度特征进行照片块之间的近邻匹配,采用深度概率图模型对深度特征权重和画像块组合权重进行联合建模以得到重建画像的最佳表示.为了使算法对测试照片的光照变化、姿态变换更鲁棒,采用预处理方法调整输入照片的光照亮度和人脸姿态,与训练集照片一致.当测试照片中存在复杂背景时,采用提取合成画像前景区域的方式去除背景中的噪声.为了使算法更高效,本文提出快速近邻搜索算法,有效提高画像合成的速度.定性和定量的实验验证本文算法的有效性.相比已有的人脸画像合成算法,本文算法在侧面光照、姿态变换及复杂背景的数据集上均能生成纹理清晰、保真度较高的人脸画像,相比使用KDTree加速的深度概率图画像合成算法,本文算法具有更快的画像合成速度.今后将探索更鲁棒的深度特征,进行更精准的近邻块匹配,进一步提升画像合成质量.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="286">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201801006&amp;v=MDI0OTR6cXFCdEdGckNVUkxPZVplUm5GeS9rVjc3SktEN1liTEc0SDluTXJvOUZZb1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 王楠楠,李洁,高新波.人脸画像合成研究的综述与对比分析.模式识别与人工智能,2018,31(1):37-48.(WANG N N,LI J,GAO X B.A Review and Comparison Study on Face Sketch Synthesis.Pattern Recognition and Artificial Intelligence,2018,31(1):37-48.)
                            </a>
                        </p>
                        <p id="288">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201509006&amp;v=MjAwNDRiTEc0SDlUTXBvOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rVjc3SktEN1k=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 高新波,王楠楠,彭春蕾,等.基于三元空间融合的人脸图像模式识别.模式识别与人工智能,2015,28(9):811-821.(GAO X B,WANG N N,PENG C L,et al.Facial Image Pattern Recognition Based on Triple Space Fusion.Pattern Recognition and Artificial Intelligence,2015,28(9):811-821.).
                            </a>
                        </p>
                        <p id="290">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300028332&amp;v=MjQ0MzJEMzg3b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSjE4UWF4TT1OajdCYXJLOEh0TE1ySTlGWk9rSA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> WANG N N,TAO D C,GAO X B,et al.A Comprehensive Survey to Face Hallucination.International Journal of Computer Vision,2014,106(1):9-30.
                            </a>
                        </p>
                        <p id="292">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face photo recognition using sketches">

                                <b>[4]</b> TANG X O,WANG X G.Face Photo Recognition Using Sketches // Proc of the International Conference on Image Processing.Washing-ton,USA:IEEE,2002:257-260.
                            </a>
                        </p>
                        <p id="294">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Nonlinear Approach for Face Sketch Synthesis and Recognition">

                                <b>[5]</b> LIU Q S,TANG X O,JIN H L,et al.A Nonlinear Approach for Face Sketch Synthesis and Recognition // Proc of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2005,I:1005-1010.
                            </a>
                        </p>
                        <p id="296">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time exemplar-based face sketch synthesis">

                                <b>[6]</b> SONG Y B,BAO L C,YANG Q X,et al.Real-Time Exemplar-Based Face Sketch Synthesis // Proc of the European Conference on Computer Vision.Berlin,Germany:Springer,2014:800-813.
                            </a>
                        </p>
                        <p id="298">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face Sketch Synthesis via Sparse Representa-tion">

                                <b>[7]</b> CHANG L,ZHOU M Q,HAN Y J,et al.Face Sketch Synthesis via Sparse Representation // Proc of the 20th International Conference on Pattern Recognition.Washington,USA:IEEE,2010:2146-2149.
                            </a>
                        </p>
                        <p id="300">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face sketch-photo synthesis and retrieval using sparse representation">

                                <b>[8]</b> GAO X B,WANG N N,TAO D C,et al.Face Sketch-Photo Synthesis and Retrieval Using Sparse Representation.IEEE Transactions on Circuits Systems for Video Technology,2012,22(8):1213-1226.
                            </a>
                        </p>
                        <p id="302">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESC8063880428F3C148AB4A2467203B3E2&amp;v=MTY5NzNzK2RDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N203d2FrPU5pZk9mY0N3SHRmUHA0ZEZZT2tIZW45S3poSWJtMDE1T1gzbXFoVTNlYkhtUg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> WANG N N,GAO X B,LI J.Random Sampling for Fast Face Sketch Synthesis.Pattern Recognition,2017,76:215-227.
                            </a>
                        </p>
                        <p id="304">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face sketch synthesis algorithm based on E-HMM and selective ensemble">

                                <b>[10]</b> GAO X B,ZHONG J J,LI J,et al.Face Sketch Synthesis Algorithm Based on E-HMM and Selective Ensemble.IEEE Transac-tions on Circuit Systems for Video Technology,2008,18(4):487-496.
                            </a>
                        </p>
                        <p id="306">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face photo-sketch synthesis and recognition">

                                <b>[11]</b> WANG X G,TANG X O.Face Photo-Sketch Synthesis and Recognition.IEEE Transactions on Pattern Analysis and Machine Intelligence,2009,31(11):1955-1967.
                            </a>
                        </p>
                        <p id="308">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Markov weight fields for face sketch synthesis">

                                <b>[12]</b> ZHOU H,KUANG Z H,WONG K K.Markov Weight Fields for Face Sketch Synthesis // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2012:1091-1097.
                            </a>
                        </p>
                        <p id="310">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bayesian Face Sketch Synthesis">

                                <b>[13]</b> WANG N N,GAO X B,SUN L Y,et al.Bayesian Face Sketch Synthesis.IEEE Transactions on Image Processing,2017,26(3):1264-1274.
                            </a>
                        </p>
                        <p id="312">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A simple and fast method for face sketch synthesis">

                                <b>[14]</b> ZHU M R,WANG N N.A Simple and Fast Method for Face Sketch Synthesis // Proc of the International Conference on Internet Multimedia Computing and Service.New York,USA:ACM,2016:168-171.
                            </a>
                        </p>
                        <p id="314">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning">

                                <b>[15]</b> ZHANG L L,LIN L,WU X,et al.End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning // Proc of the 5th ACM International Conference on Multimedia Retrieval.New York,USA:ACM,2015:627-634.
                            </a>
                        </p>
                        <p id="316">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES71CC88B791D41F23641078803BE1BED0&amp;v=MzI0NTlDcGJRMzVORmh3N203d2FrPU5pZk9mYlM1YmFMRXAvMUNiZXA3Q0gxUHpSVVY3ajU5VDNmcXJCRkhETFBtTU02ZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> WANG N N,ZHA W J,LI J,et al.Back Projection:An Effective Postprocessing Method for GAN-Based Face Sketch Synthesis.Pa-ttern Recognition Letters,2018,107:59-65.
                            </a>
                        </p>
                        <p id="318">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image-to-image translation with conditional adversarial networks">

                                <b>[17]</b> ISOLA P,ZHU J Y,ZHOU T H,et al.Image-to-Image Translation with Conditional Adversarial Networks // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2017:1125-1134.
                            </a>
                        </p>
                        <p id="320">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unpaired image-to-image translation using cycle-consistent adversarial networks">

                                <b>[18]</b> ZHU J Y,PARK T,ISOLA P,et al.Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks // Proc of the IEEE International Conference on Computer Vision.Washington,USA:IEEE,2017:2242-2251.
                            </a>
                        </p>
                        <p id="322">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Graphical Feature Learning for Face Sketch Synthesis">

                                <b>[19]</b> ZHU M R,WANG N N,GAO X B,et al.Deep Graphical Feature Learning for Face Sketch Synthesis // Proc of the 26th International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:3574-3580.
                            </a>
                        </p>
                        <p id="324">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition">

                                <b>[20]</b> SIMONYAN K,ZISSERMAN A.Very Deep Convolutional Networks for Large-Scale Image Recognition[C/OL].[2019-04-25].https://arxiv.org/pdf/1409.1556.pdf.
                            </a>
                        </p>
                        <p id="326">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast Face Sketch Synthesis via KD-Tree Search">

                                <b>[21]</b> ZHANG Y Q,WANG N N,ZHANG S C,et al.Fast Face Sketch Synthesis via KD-Tree Search // Proc of the European Conference on Computer Vision.Berlin,Germany:Springer,2016:64-77.
                            </a>
                        </p>
                        <p id="328">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast Preprocessing for Robust Face Sketch Synthesis">

                                <b>[22]</b> SONG Y B,ZHANG J W,BAO L C,et al.Fast Preprocessing for Robust Face Sketch Synthesis // Proc of the International Joint Conference on Artificial Intelligence.New York,USA:ACM,2017:4530-4536.
                            </a>
                        </p>
                        <p id="330">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive histogram equalization and its variations">

                                <b>[23]</b> PIZER S M,AMBURN E P,AUSTIN J D,et al.Adaptive Histogram Equalization and Its Variations.Computer Vision,Graphics,and Image Processing,1987,39(3):355-368.
                            </a>
                        </p>
                        <p id="332">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=One millisecond face alignment with an ensemble of regression trees">

                                <b>[24]</b> KAZEMI V,SULLIVAN J.One Millisecond Face Alignment with an Ensemble of Regression Trees // Proc of the IEEE Conference on Computer Vision and Pattern Recognition.Washington,USA:IEEE,2014:1867-1874.
                            </a>
                        </p>
                        <p id="334">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The AR face database">

                                <b>[25]</b> MARTINEZ A,BENAVENTE R.The AR Face Database.Technical Report,24.Columbus,USA:The Ohio State University,1998.
                            </a>
                        </p>
                        <p id="336">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=XM2VTSDB: The extended M2VTS database">

                                <b>[26]</b> MESSER K,MATAS J,KITTLER J,et al.XM2VTS:The Extended M2VTS Database // Proc of the 2nd International Confe-rence on Audio and Video-Based Biometric Person Authentication.Berlin,Germany:Springer,1999:72-77.
                            </a>
                        </p>
                        <p id="338">
                            <a id="bibliography_27" >
                                    <b>[27]</b>
                                 WANG Z,BOVIK A C,SHEIKH H R,et al.Image Quality Assessment:From Error Visibility to Structural Similarity.IEEE Transactions on Image Processing,2004,13(4):600-612.
                            </a>
                        </p>
                        <p id="340">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image information and visual quality">

                                <b>[28]</b> SHEIKH H R,BOVIK A C.Image Information and Visual Quality.IEEE Transactions on Image Processing,2006,15(2):430-444.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201909011" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201909011&amp;v=MTc4OThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnkva1Y3N0pLRDdZYkxHNEg5ak1wbzlFWlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
