<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131439535030000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201902011%26RESULT%3d1%26SIGN%3dGxT%252fqWJNHH1kIu6FT0%252fNquSXYF0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201902011&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201902011&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201902011&amp;v=MDAzNTdMM0tLRDdZYkxHNEg5ak1yWTlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6blU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#98" data-title="1 面向属性抽取的门控动态的注意力机制 ">1 面向属性抽取的门控动态的注意力机制</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="&lt;b&gt;1.1&lt;/b&gt; 总体结构"><b>1.1</b> 总体结构</a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;1.2&lt;/b&gt; 双向长短时记忆网络层"><b>1.2</b> 双向长短时记忆网络层</a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;1.3&lt;/b&gt; 静态注意力模型"><b>1.3</b> 静态注意力模型</a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;1.4&lt;/b&gt; 门控动态注意力层"><b>1.4</b> 门控动态注意力层</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#173" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#174" data-title="&lt;b&gt;2.1&lt;/b&gt; 实验数据及评价方法"><b>2.1</b> 实验数据及评价方法</a></li>
                                                <li><a href="#180" data-title="&lt;b&gt;2.2&lt;/b&gt; 对比方法及参数设置"><b>2.2</b> 对比方法及参数设置</a></li>
                                                <li><a href="#196" data-title="&lt;b&gt;2.3&lt;/b&gt; 实验结果"><b>2.3</b> 实验结果</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#222" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#115" data-title="图1 本文方法总体结构">图1 本文方法总体结构</a></li>
                                                <li><a href="#146" data-title="图2 动态注意力机制图">图2 动态注意力机制图</a></li>
                                                <li><a href="#178" data-title="&lt;b&gt;表1&lt;/b&gt;&lt;b&gt;实验语料统计&lt;/b&gt;"><b>表1</b><b>实验语料统计</b></a></li>
                                                <li><a href="#198" data-title="&lt;b&gt;表2&lt;/b&gt;&lt;b&gt;各方法特征使用情况&lt;/b&gt;"><b>表2</b><b>各方法特征使用情况</b></a></li>
                                                <li><a href="#199" data-title="&lt;b&gt;表3&lt;/b&gt;&lt;b&gt;各方法框架使用情况&lt;/b&gt;"><b>表3</b><b>各方法框架使用情况</b></a></li>
                                                <li><a href="#200" data-title="&lt;b&gt;表4&lt;/b&gt;&lt;b&gt;各方法在4个数据集上&lt;i&gt;F&lt;/i&gt;1值对比&lt;/b&gt;"><b>表4</b><b>各方法在4个数据集上<i>F</i>1值对比</b></a></li>
                                                <li><a href="#208" data-title="图3 动态注意力机制形成的注意力分配样例">图3 动态注意力机制形成的注意力分配样例</a></li>
                                                <li><a href="#213" data-title="图4 静态注意力机制形成的注意力分配样例">图4 静态注意力机制形成的注意力分配样例</a></li>
                                                <li><a href="#219" data-title="&lt;b&gt;表5&lt;/b&gt;&lt;b&gt;在4个数据集上有无门控的&lt;i&gt;F&lt;/i&gt;1值对比&lt;/b&gt;"><b>表5</b><b>在4个数据集上有无门控的<i>F</i>1值对比</b></a></li>
                                                <li><a href="#221" data-title="&lt;b&gt;表6&lt;/b&gt;&lt;b&gt;注意力更新网络性能对比&lt;/b&gt;"><b>表6</b><b>注意力更新网络性能对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="15">


                                    <a id="bibliography_1" title=" PONTIKI M, GALANIS D, PAVLOPOULOS J, &lt;i&gt;et al&lt;/i&gt;. SemEval-2014 Task 4: Aspect Based Sentiment Analysis // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 27-35." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sem Eval-2014 Task 4:Aspect Based Sentiment Analysis">
                                        <b>[1]</b>
                                         PONTIKI M, GALANIS D, PAVLOPOULOS J, &lt;i&gt;et al&lt;/i&gt;. SemEval-2014 Task 4: Aspect Based Sentiment Analysis // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 27-35.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_2" title=" HU M Q, LIU B. Mining and Summarizing Customer Reviews // Proc of the 10th ACM SIGKDD International Conference on Know-ledge Discovery and Data Mining. New York, USA: ACM, 2004: 168-177." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mining and Summarizing Customer Reviews">
                                        <b>[2]</b>
                                         HU M Q, LIU B. Mining and Summarizing Customer Reviews // Proc of the 10th ACM SIGKDD International Conference on Know-ledge Discovery and Data Mining. New York, USA: ACM, 2004: 168-177.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_3" title=" ZHUANG L, JING F, ZHU X Y. Movie Review Mining and Su-mmarization // Proc of the 15th ACM International Conference on Information and Knowledge Management. New York, USA: ACM, 2006: 43-50." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Movie review mining and summarization">
                                        <b>[3]</b>
                                         ZHUANG L, JING F, ZHU X Y. Movie Review Mining and Su-mmarization // Proc of the 15th ACM International Conference on Information and Knowledge Management. New York, USA: ACM, 2006: 43-50.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_4" title=" BLAIR-GOLDENSOHN S, HANNAN K, MCDONALD R, &lt;i&gt;et al&lt;/i&gt;. Building a Sentiment Summarizer for Local Service Reviews // Proc of the Workshop on NLP in the Information Explosion Era. Stroudsburg, USA: ACL, 2008, XIV: 339-348." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Building a sentiment summarizer for local service reviews">
                                        <b>[4]</b>
                                         BLAIR-GOLDENSOHN S, HANNAN K, MCDONALD R, &lt;i&gt;et al&lt;/i&gt;. Building a Sentiment Summarizer for Local Service Reviews // Proc of the Workshop on NLP in the Information Explosion Era. Stroudsburg, USA: ACL, 2008, XIV: 339-348.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_5" title=" WANG B, WANG H F. Bootstrapping Both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing[C/OL]. [2018-05-30]. http://www.aclweb.org/anthology/I/I08/I08-1038.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bootstrapping Both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing[C/OL]">
                                        <b>[5]</b>
                                         WANG B, WANG H F. Bootstrapping Both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing[C/OL]. [2018-05-30]. http://www.aclweb.org/anthology/I/I08/I08-1038.pdf.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_6" title=" MEI Q Z, LING X, WONDRA M, &lt;i&gt;et al&lt;/i&gt;. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs // Proc of the 16th International Conference on World Wide Web. New York, USA: ACM, 2007: 171-180." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Topic sentiment mixture:modeling facets and opinions in weblogs">
                                        <b>[6]</b>
                                         MEI Q Z, LING X, WONDRA M, &lt;i&gt;et al&lt;/i&gt;. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs // Proc of the 16th International Conference on World Wide Web. New York, USA: ACM, 2007: 171-180.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_7" title=" TITOV I, Mcdonald R. Modeling Online Reviews with Multi-grain Topic Models // Proc of the 17th International Conference on World Wide Web. New York, USA: ACM, 2008: 111-120." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modeling online reviews with multi-grain topic models">
                                        <b>[7]</b>
                                         TITOV I, Mcdonald R. Modeling Online Reviews with Multi-grain Topic Models // Proc of the 17th International Conference on World Wide Web. New York, USA: ACM, 2008: 111-120.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_8" title=" LIN C H, HE Y L. Joint Sentiment/Topic Model for Sentiment Analysis // Proc of the 18th ACM Conference on Information and Knowledge Management. New York, USA: ACM, 2009: 375-384." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint Sentiment/Topic Model for Sentiment Analysis">
                                        <b>[8]</b>
                                         LIN C H, HE Y L. Joint Sentiment/Topic Model for Sentiment Analysis // Proc of the 18th ACM Conference on Information and Knowledge Management. New York, USA: ACM, 2009: 375-384.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_9" title=" MUKHERJEE A, LIU B. Aspect Extraction through Semi-supervised Modeling // Proc of the 50th Annual Meeting of the Association for Computational Linguistics. Stroudsburg, USA: ACL, 2012: 339-348." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aspect extraction through semi-supervised modeling">
                                        <b>[9]</b>
                                         MUKHERJEE A, LIU B. Aspect Extraction through Semi-supervised Modeling // Proc of the 50th Annual Meeting of the Association for Computational Linguistics. Stroudsburg, USA: ACL, 2012: 339-348.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_10" title=" JIN W, HO H H, SRIHARI R K. OpinionMiner: A Novel Machine Learning System for Web Opinion Mining and Extraction // Proc of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. New York, USA: ACM, 2009: 1195-1204." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OpinionMiner:A novel machine learning system for web opinion mining and extraction">
                                        <b>[10]</b>
                                         JIN W, HO H H, SRIHARI R K. OpinionMiner: A Novel Machine Learning System for Web Opinion Mining and Extraction // Proc of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. New York, USA: ACM, 2009: 1195-1204.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_11" title=" JAKOB N, GUREVYCH I. Extracting Opinion Targets in a Single-and Cross-Domain Setting with Conditional Random Fields // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2010: 1035-1045." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Extracting opinion targets in a single and cross-domain setting with conditional random fields">
                                        <b>[11]</b>
                                         JAKOB N, GUREVYCH I. Extracting Opinion Targets in a Single-and Cross-Domain Setting with Conditional Random Fields // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2010: 1035-1045.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_12" title=" LI F T, HAN C, HUANG M L, &lt;i&gt;et al&lt;/i&gt;. Structure-Aware Review Mining and Summarization // Proc of the 23rd International Conference on Computational Linguistics. Stroudsburg, USA: ACL, 2010: 653-661." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Structure-aware review mining and summarization">
                                        <b>[12]</b>
                                         LI F T, HAN C, HUANG M L, &lt;i&gt;et al&lt;/i&gt;. Structure-Aware Review Mining and Summarization // Proc of the 23rd International Conference on Computational Linguistics. Stroudsburg, USA: ACL, 2010: 653-661.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_13" title=" XU L H, LIU K, ZHAO J. Joint Opinion Relation Detection Using One-Class Deep Neural Network // Proc of the 25th International Conference on Computational Linguistics. Stroudsburg, USA: ACL, 2014: 677-687." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint Opinion Relation Detection Using One-Class Deep Neural Network">
                                        <b>[13]</b>
                                         XU L H, LIU K, ZHAO J. Joint Opinion Relation Detection Using One-Class Deep Neural Network // Proc of the 25th International Conference on Computational Linguistics. Stroudsburg, USA: ACL, 2014: 677-687.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_14" title=" LIU P F, JOTY S, MENG H L. Fine-Grained Opinion Mining with Recurrent Neural Networks and Word Embeddings // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2015: 1433-1443." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fine-grained opinion mining with recurrent neural networks and word embeddings">
                                        <b>[14]</b>
                                         LIU P F, JOTY S, MENG H L. Fine-Grained Opinion Mining with Recurrent Neural Networks and Word Embeddings // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2015: 1433-1443.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_15" title=" LI X, LAM W. Deep Multi-task Learning for Aspect Term Extraction with Memory Interaction // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2017: 2886-2892." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Multi-task Learning for Aspect Term Extraction with Memory Interaction">
                                        <b>[15]</b>
                                         LI X, LAM W. Deep Multi-task Learning for Aspect Term Extraction with Memory Interaction // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2017: 2886-2892.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_16" title=" TOH Z Q, SU J. NLANGP at SemEval-2016 Task 5: Improving Aspect Based Sentiment Analysis Using Neural Network Features // Proc of the 10th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2016: 282-288." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=NLANGP at SemEval-2016 Task 5:Improving Aspect Based Sentiment Analysis using Neural Network Features">
                                        <b>[16]</b>
                                         TOH Z Q, SU J. NLANGP at SemEval-2016 Task 5: Improving Aspect Based Sentiment Analysis Using Neural Network Features // Proc of the 10th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2016: 282-288.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_17" title=" BAHDANAU D, CHO K, BENGIO Y. Neural Machine Translation by Jointly Learning to Align and Translate[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1409.0473v7.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">
                                        <b>[17]</b>
                                         BAHDANAU D, CHO K, BENGIO Y. Neural Machine Translation by Jointly Learning to Align and Translate[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1409.0473v7.pdf.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_18" title=" WANG W Y, PAN S J, DAHLMEIER D, &lt;i&gt;et al&lt;/i&gt;. Coupled Multi-layer Attentions for Co-extraction of Aspect and Opinion Terms // Proc of the 31st AAAI Conference on Artificial Intelligence. Palo Alto, USA: AAAI Press, 2017: 3316-3322." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Coupled Multi-layer Attentions for Co-extraction of Aspect and Opinion Terms">
                                        <b>[18]</b>
                                         WANG W Y, PAN S J, DAHLMEIER D, &lt;i&gt;et al&lt;/i&gt;. Coupled Multi-layer Attentions for Co-extraction of Aspect and Opinion Terms // Proc of the 31st AAAI Conference on Artificial Intelligence. Palo Alto, USA: AAAI Press, 2017: 3316-3322.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_19" title=" YANG Z C, YANG D Y, DYER C, &lt;i&gt;et al&lt;/i&gt;. Hierarchical Attention Networks for Document Classification // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Stroudsburg, USA: ACL, 2016: 1480-1489." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hierarchical Attention Networks for Document Classification">
                                        <b>[19]</b>
                                         YANG Z C, YANG D Y, DYER C, &lt;i&gt;et al&lt;/i&gt;. Hierarchical Attention Networks for Document Classification // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Stroudsburg, USA: ACL, 2016: 1480-1489.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_20" title=" SCHUSTER M, PALIWAL K K. Bidirectional Recurrent Neural Networks. IEEE Transactions on Signal Processing, 1997, 45 (11) : 2673-2681." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bidirectional recurrent neural networks">
                                        <b>[20]</b>
                                         SCHUSTER M, PALIWAL K K. Bidirectional Recurrent Neural Networks. IEEE Transactions on Signal Processing, 1997, 45 (11) : 2673-2681.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_21" title=" COLLINS M. The Forward-Backward Algorithm[C/OL]. [2018-05-30]. http://www.cs.columbia.edu/～mcollins/fb.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Forward-Backward Algorithm[C/OL]">
                                        <b>[21]</b>
                                         COLLINS M. The Forward-Backward Algorithm[C/OL]. [2018-05-30]. http://www.cs.columbia.edu/～mcollins/fb.pdf.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_22" title=" HUANG Z H, XU W, YU K. Bidirectional LSTM-CRF Models for Sequence Tagging[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1508.01991.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF Models for Sequence Tagging[C/OL]">
                                        <b>[22]</b>
                                         HUANG Z H, XU W, YU K. Bidirectional LSTM-CRF Models for Sequence Tagging[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1508.01991.pdf.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_23" title=" PONTIKI M, GALANIS D, PAPAGEORGIOU H, &lt;i&gt;et al&lt;/i&gt;. Semeval-2015 Task 12: Aspect Based Sentiment Analysis // Proc of the 9th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2015: 486-495." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semeval-2015 Task 12: Aspect Based Sentiment Analysis">
                                        <b>[23]</b>
                                         PONTIKI M, GALANIS D, PAPAGEORGIOU H, &lt;i&gt;et al&lt;/i&gt;. Semeval-2015 Task 12: Aspect Based Sentiment Analysis // Proc of the 9th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2015: 486-495.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_24" title=" PONTIKI M, GALANIS D, PAPAGEORGIOU H, &lt;i&gt;et al&lt;/i&gt;. SemEval-2016 Task 5: Aspect Based Sentiment Analysis // Proc of the 10th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2016: 19-30." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sem Eval-2016 Task 5:Aspect Based Sentiment Analysis">
                                        <b>[24]</b>
                                         PONTIKI M, GALANIS D, PAPAGEORGIOU H, &lt;i&gt;et al&lt;/i&gt;. SemEval-2016 Task 5: Aspect Based Sentiment Analysis // Proc of the 10th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2016: 19-30.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_25" title=" GREFF K, SRIVASTAVA R K, KOUTN&#205;k J, &lt;i&gt;et al&lt;/i&gt;. LSTM: A Search Space ODYSSEY. IEEE Transactions on Neural Networks and Learning Systems, 2017, 28 (10) : 2222-2232." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LSTM:A search space odyssey">
                                        <b>[25]</b>
                                         GREFF K, SRIVASTAVA R K, KOUTN&#205;k J, &lt;i&gt;et al&lt;/i&gt;. LSTM: A Search Space ODYSSEY. IEEE Transactions on Neural Networks and Learning Systems, 2017, 28 (10) : 2222-2232.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_26" title=" CHERNYSHEVICH M. IHS R&amp;amp;D Belarus: Cross-Domain Extraction of Product Features Using Conditional Random Fields // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 309-313." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=IHS R.&amp;amp;.D Belarus:Cross-domain extraction of product features using CRF">
                                        <b>[26]</b>
                                         CHERNYSHEVICH M. IHS R&amp;amp;D Belarus: Cross-Domain Extraction of Product Features Using Conditional Random Fields // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 309-313.
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_27" title=" TOH Z Q, WANG W T. DLIREC: Aspect Term Extraction and Term Polarity Classification System // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 235-240." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DLIREC:aspect term extraction and term polarity classification system">
                                        <b>[27]</b>
                                         TOH Z Q, WANG W T. DLIREC: Aspect Term Extraction and Term Polarity Classification System // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 235-240.
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_28" title=" YIN Y C, WEI F R, DONG L, &lt;i&gt;et al&lt;/i&gt;. Unsupervised Word and Dependency Path Embeddings for Aspect Term Extraction // Proc of the 25th International Joint Conference on Artificial Intelligence. Palo Alto, USA: AAAI Press, 2016: 2979-2985." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unsupervised word and dependency path embeddings for aspect term extraction">
                                        <b>[28]</b>
                                         YIN Y C, WEI F R, DONG L, &lt;i&gt;et al&lt;/i&gt;. Unsupervised Word and Dependency Path Embeddings for Aspect Term Extraction // Proc of the 25th International Joint Conference on Artificial Intelligence. Palo Alto, USA: AAAI Press, 2016: 2979-2985.
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_29" title=" VICENTE I S, SARALEGI X, AGERRI R. EliXa: A Modular and Flexible ABSA Platform // Proc of the 9th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2015: 748-752." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=EliXa:A modular and flexible ABSA platform">
                                        <b>[29]</b>
                                         VICENTE I S, SARALEGI X, AGERRI R. EliXa: A Modular and Flexible ABSA Platform // Proc of the 9th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2015: 748-752.
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_30" title=" ZAREMBA W, SUTSKEVER I, VINYALS O. Recurrent Neural Network Regularization[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1409.2329.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recurrent neural network regularization">
                                        <b>[30]</b>
                                         ZAREMBA W, SUTSKEVER I, VINYALS O. Recurrent Neural Network Regularization[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1409.2329.pdf.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(02),184-192 DOI:10.16451/j.cnki.issn1003-6059.201902011            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">面向属性抽取的门控动态注意力机制</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A8%8B%E6%A2%A6&amp;code=41251072&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">程梦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B4%AA%E5%AE%87&amp;code=25038035&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">洪宇</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%94%90%E5%BB%BA&amp;code=37885116&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">唐建</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%AE%B6%E7%A1%95&amp;code=37736060&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张家硕</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B9%E5%8D%9A%E4%BC%9F&amp;code=33805768&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邹博伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A7%9A%E5%BB%BA%E6%B0%91&amp;code=13898051&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">姚建民</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%8B%8F%E5%B7%9E%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0240077&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏州大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在现阶段属性抽取研究中, 现有注意力建模及训练较刚性 (单句一次成型) , 而单句中不同词汇的上下文存在语境语义的差异, 一致的注意力分布缺少动态的适应性.因此, 文中提出面向属性抽取的门控动态注意力机制, 利用双向长短时记忆网络捕获目标句中每个单词的隐层表示.在注意力模型处理词一级属性预测时, 根据目标词及其上下文, 计算适应该目标词的注意力分布向量, 可以根据上下文的变化自动调整注意力权重的分配.借助门控调整注意力向量流向下一层神经元的信息量, 最终使用条件随机场进行属性标记.应用2014-2016语义评估官方数据集验证文中方法的有效性, F1值均有所提高.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%9E%E6%80%A7%E6%8A%BD%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">属性抽取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">条件随机场;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">情感分析;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    程梦, 硕士研究生, 主要研究方向为属性级情感分析、属性抽取.E-mail:dcdream@outlook.com.
;
                                </span>
                                <span>
                                    *洪宇, 博士, 副教授, 主要研究方向为信息检索、信息抽取.E-mail:tianxian er@gmail.com.
;
                                </span>
                                <span>
                                    唐建, 硕士研究生, 主要研究方向为机器翻译.E-mail:Johnnytang@gmail.com.
;
                                </span>
                                <span>
                                    张家硕, 硕士研究生, 主要研究方向为图像描述生成.E-mail:jiasurezhang@gmail.com.
;
                                </span>
                                <span>
                                    邹博伟, 博士, 主要研究方向为信息抽取、篇章分析.E-mail:zoubowei@suda.edu.cn.
;
                                </span>
                                <span>
                                    姚建民, 博士, 副教授, 主要研究方向为机器翻译.E-mail:jyao@suda.edu.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-21</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (No.2017YFB1002104);</span>
                                <span>国家自然科学基金项目 (No.61672367, 61672368) 资助;</span>
                    </p>
            </div>
                    <h1>Gated Dynamic Attention Mechanism towards Aspect Extraction</h1>
                    <h2>
                    <span>CHENG Meng</span>
                    <span>HONG Yu</span>
                    <span>TANG Jian</span>
                    <span>ZHANG Jiashuo</span>
                    <span>ZOU Bowei</span>
                    <span>YAO Jianmin</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Technology, Soochow University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In the current aspect extraction researches, the attention modeling and training are fixed, and the sentence is modeled in one time step. However, the semantics of the words vary in contexts, and a fixed attention distribution lacks dynamic adaptability. Therefore, a gated dynamic attention mechanism towards aspect extraction is proposed in this paper. A bidirectional long short term memory network is exploited to obtain hidden representations of words in a target sentence. Then, a specific attention distribution is computed according to the target word and its context while the attention model labelling words. Thus, the attention-weight distribution can be automatically adjusted according to the changes of contexts. Next, a gate is adopted to adjust the quantities of information flowing to the next units. Finally, conditional random field is utilized to label the aspect. The official datasets of 2014-2016 semantic evaluation are employed to verify the effectiveness of the proposed method, and F1 scores are increased.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Attention%20Mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Attention Mechanism;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Aspect%20Extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Aspect Extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Conditional%20Random%20Field&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Conditional Random Field;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sentiment%20Analysis&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sentiment Analysis;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    CHENG Meng, master student. His research interests include aspect based sentiment analysis and aspect extraction.
;
                                </span>
                                <span>
                                    HONG Yu , Ph.D., associate professor. His research interests include information retrieval and information extraction.
;
                                </span>
                                <span>
                                    TANG Jian, master student. His research interests include machine translation.
;
                                </span>
                                <span>
                                    ZHANG Jiashuo, master student. His research interests include image captioning.
;
                                </span>
                                <span>
                                    ZOU Bowei, Ph. D. His research interests include information extraction and discourse analysis.
;
                                </span>
                                <span>
                                    YAO Jianmin, Ph.D., associate profe-ssor. His research interests include machine translation.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-10-21</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Key R&amp;D Program of China (No.2017YF B1002104);</span>
                                <span>National Natural Science Foundation of China (No.61672367, 61672368);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="86">属性抽取 (Aspect Extraction) , 也称为评价对象的抽取 (Opinion Target Extraction) , 是属性级情感分析的一个重要子任务<citation id="286" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.属性抽取主要目标如下:对于用户提供的评论文本, 抽取该用户评价的实体或属性, 即其任务是抽取用户评价的对象.评价对象通常由一个单词、短语或多词表达组成.</p>
                </div>
                <div class="p1">
                    <p id="87">早期研究通过制定一系列规则实现抽取.Hu等<citation id="288" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>提出使用关联规则进行属性抽取.Zhuang等<citation id="287" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>使用依存关系从影评中抽取评价对象-评价意见单元对.Blair-Goldensohn等<citation id="290" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>着重考虑频繁出现在主观句中的名词和名词短语, 指定权重较高的名词和名词短语作为属性.Wang等<citation id="289" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>通过种子评价对象和评价意见, 使用Bootstrapping方法交替识别评价对象和评价意见.该类方法依赖大量的规则, 无法捕获规则之外的属性.</p>
                </div>
                <div class="p1">
                    <p id="90">此外, 主题模型也广泛应用于评价对象的抽取, Mei等<citation id="291" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>通过概率潜在语义模型 (Probabilistic La-tent Semantic Analysis, PLSA) 研究评价对象的抽取.Titov等<citation id="292" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>发现直接将潜在狄利克雷分配 (Latent Dirichlet Allocation, LDA) 模型应用到全局数据并不适用于抽取评价对象, 因此提出多粒度主题模型.Lin等<citation id="293" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>扩展LAD模型, 提出主题和情感词的联合模型.Mukherjee等<citation id="294" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>从用户提供的评价对象种子集开始, 利用半监督联合模型, 抽取用户需要的评价对象.该类方法依赖于特定主题, 无法捕获主题之外的属性词.</p>
                </div>
                <div class="p1">
                    <p id="91">在监督学习的应用方面, 学者们将属性抽取指定为一种序列标记任务.Jin等<citation id="297" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>使用词汇化的隐马尔科夫模型 (Hidden Markov Model, HMM) 学习并标记评价对象.Jakob等<citation id="295" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>将条件随机场模型 (Conditional Random Field, CRF) 单独用于评价对象的抽取, 通过CRF融合不同特征, 在属性抽取的任务上取得较好效果.Li等<citation id="296" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>使用加入链式结构特征、连接结构特征和句法结构特征的CRF模型, 发现评价对象和评价意见.然而, 该类模型的有效性依赖于大量的手工特征, 在特征缺失时, 性能将会大幅下降.</p>
                </div>
                <div class="p1">
                    <p id="92">近期, 学者们尝试将神经网络模型应用到属性抽取任务.Xu等<citation id="300" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>利用递归自动编码器的方法, 从评论文本中抽取评价对象.Liu等<citation id="301" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>进一步使用基于长短时记忆单元 (Long-Short Term Memory, LSTM) 的循环神经网络 (Recurrent Neural Network, RNN) 抽取属性词.Li等<citation id="298" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>将双通道LSTM通过记忆力机制进行交互, 实现学习情感和属性过程中的特征共享.这类方法使用网络提取单词特征, 减少手工特征的使用, 性能得到显著提升, 但在实际使用中容易将属性短语预测为多个单词.在此基础上, Toh等<citation id="299" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>结合双向循环神经网络 (Bi-directional RNN, Bi-RNN) 与CRF, 同时加入多种特征, 进一步优化属性抽取的性能.本文将Toh等<citation id="302" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的系统作为基线系统.</p>
                </div>
                <div class="p1">
                    <p id="93">目前, 注意力机制 (Attention Mechanism) <citation id="304" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>已被证明可优化多种基础神经网络的自然语言处理模型.在属性抽取方面也表现出显著优势.Wang等<citation id="303" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>将一种成对多层注意力机制应用到属性与情感词联合抽取任务上, 获得较优的效果.</p>
                </div>
                <div class="p1">
                    <p id="94">然而, 现有的注意力机制往往忽略上下文的变化, 以及由此引起的实际注意力的分布差异<citation id="305" type="reference"><link href="51" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>, 对单句中的不同词汇而言, 注意力在其上下文的权值分配上始终保持一致.由此, 现有的注意力机制略显刚性, 在大量样本的神经网络学习过程中, 出现注意力分配适应性较差、无法实时变化的问题.</p>
                </div>
                <div class="p1">
                    <p id="95">本文提出一种门控动态注意力机制, 应用到基于双向LSTM (Bi-directional LSTM, Bi-LSTM) <citation id="307" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>的CRF模型<citation id="306" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>中.该注意力机制在每个时刻 (处理每个目标词项时) 都对相应的上下文产生一套分布不同的注意力向量.在此基础上, 通过门控调整流向下一层神经元的信息量, 以此获得CRF对单句全局动态的注意力分布.</p>
                </div>
                <div class="p1">
                    <p id="96">由于CRF模型往往维持一个状态转移矩阵作为参数, 借以有效使用上下文标记预测当前的标记类别<citation id="308" type="reference"><link href="57" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>.鉴于此种情况, 本文在模型架构层面继承序列标记和语义特征的应用策略, 并着重利用上述门控动态注意力机制, 在这一框架下实现优化.</p>
                </div>
                <div class="p1">
                    <p id="97">最后, 对集成上述注意力机制的属性标注系统进行测试, 在国际属性级情感分析公开数据集SemEval 2014<citation id="309" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、2015<citation id="311" type="reference"><link href="59" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>和2016<citation id="310" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>上均获得性能提升.</p>
                </div>
                <h3 id="98" name="98" class="anchor-tag">1 面向属性抽取的门控动态的注意力机制</h3>
                <h4 class="anchor-tag" id="99" name="99"><b>1.1</b> 总体结构</h4>
                <div class="p1">
                    <p id="100">与Wang等<citation id="312" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>方法类似, 本文将属性抽取任务转化为序列标记任务, 使用的标签模式为BMESO标签.评价对象包含多个单词时, B表示一个评价对象的开始, M表示一个评价对象的中间, E表示评价对象的结尾.对于评价对象只有一个单词时, 单一使用S表示;O表示非评价对象.</p>
                </div>
                <div class="p1">
                    <p id="101">本文针对属性抽取任务, 提出面向属性抽取的门控动态注意力机制方法, 目的在于解决现有的注意力机制在建模时单句全局注意力静态不变的问题, 即对于单句中的所有不同词汇而言, 注意力分布在其上下文的权值分配上始终保持一致.本文方法能随着目标词项的变化, 对上下文重新分配注意力权重.</p>
                </div>
                <div class="p1">
                    <p id="102">本文方法的总体结构如图1所示.首先, 对于一个待判别句子</p>
                </div>
                <div class="p1">
                    <p id="103"><b><i>S</i></b>=[<i>s</i><sub>1</sub>, <i>s</i><sub>2</sub>, …, <i>s</i><sub><i>n</i></sub>], </p>
                </div>
                <div class="p1">
                    <p id="104">初始化环节获取每个词的分布式表示, 本文采用预训练的词向量</p>
                </div>
                <div class="p1">
                    <p id="105"><b><i>W</i></b>=[<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>n</i></sub>]</p>
                </div>
                <div class="p1">
                    <p id="106">作为词义的分布式表示.在此基础上执行如下特征信息的学习过程.</p>
                </div>
                <div class="p1">
                    <p id="107">将</p>
                </div>
                <div class="p1">
                    <p id="108"><b><i>W</i></b>=[<b><i>w</i></b><sub>1</sub>, <b><i>w</i></b><sub>2</sub>, …, <b><i>w</i></b><sub><i>n</i></sub>]</p>
                </div>
                <div class="p1">
                    <p id="109">输入Bi-LSTM层, 通过Bi-LSTM层的编码, 获得各个单词包含上下文信息的隐藏层</p>
                </div>
                <div class="p1">
                    <p id="110"><b><i>H</i></b>=[<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="111">在此基础上, 通过门控动态注意力机制, 按序 (自句首至句尾) 逐词动态地对各个单词 (也称为信道处理的各个时刻) 的上下文分配不同的注意力权重, 通过注意力权重与上下文词向量<b><i>H</i></b>, 计算上下文注意力分布向量</p>
                </div>
                <div class="p1">
                    <p id="112"><b><i>U</i></b>=[<b><i>u</i></b><sub>1</sub>, <b><i>u</i></b><sub>2</sub>, …, <b><i>u</i></b><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="113">经过这一环节的注意力模型尚无法直接应用于CRF进行序列标注, 原因在于注意力向量的维度无法满足CRF的特征输入要求, 必须预先进行降维处理.为此, 本文采用Toh等<citation id="313" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的方法, 将该注意力向量通过全连接层进行降维, 获得各个单词满足CRF输入要求的特征表示.将该特征表示输入CRF层进行属性词的判别, 获取各个单词对应的预测标签</p>
                </div>
                <div class="p1">
                    <p id="114"><b><i>L</i></b>=[<i>l</i><sub>1</sub>, <i>l</i><sub>2</sub>, …, <i>l</i><sub><i>n</i></sub>], <i>l</i><sub><i>i</i></sub>∈{<i>B</i>, <i>M</i>, <i>E</i>, <i>S</i>, <i>O</i>}.</p>
                </div>
                <div class="area_img" id="115">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902011_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文方法总体结构" src="Detail/GetImg?filename=images/MSSB201902011_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文方法总体结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902011_115.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 1 General structure of the proposed method</p>

                </div>
                <h4 class="anchor-tag" id="116" name="116"><b>1.2</b> 双向长短时记忆网络层</h4>
                <div class="p1">
                    <p id="117">本节介绍利用Bi-LSTM<citation id="314" type="reference"><link href="53" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>获取句子中每个单词的隐藏层, 其表示为</p>
                </div>
                <div class="p1">
                    <p id="118"><b><i>H</i></b>=[<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="119">本文使用的神经网络架构继承Greff等<citation id="315" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>的工作, 在隐藏层, 同时拥有一个正向的LSTM网络和一个反向LSTM网络, 正向LSTM的作用是捕获当前单词的上文信息, 反向LSTM的作用是捕获当前单词的下文信息.如此, 当一个单词<b><i>w</i></b><sub><i>i</i></sub>经过正向LSTM时, 获得包含上文信息的隐藏层表示<mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>→</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>, 经过反向LSTM时, 获得包含下文信息的隐藏层表示<mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>←</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>.在此基础上, 将两套表示学习结果进行拼接, 形成联合表示</p>
                </div>
                <div class="p1">
                    <p id="122"><b><i>h</i></b><sub><i>i</i></sub>=<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>→</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>;<mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>←</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="125">其中</p>
                </div>
                <div class="p1">
                    <p id="126" class="code-formula">
                        <mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>→</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>L</mi><mi>S</mi><mi>Τ</mi><mi>Μ</mi><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>→</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi>θ</mi><mo>→</mo></mover><mo stretchy="false">) </mo><mo>, </mo><mspace width="0.25em" /><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>←</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>L</mi><mi>S</mi><mi>Τ</mi><mi>Μ</mi><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">h</mi><mo>←</mo></mover><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mover accent="true"><mi>θ</mi><mo>←</mo></mover><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="127"><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>θ</mi><mo>→</mo></mover></math></mathml>表示正向LSTM神经元中的参数, <mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>θ</mi><mo>←</mo></mover></math></mathml>表示反向LSTM神经元中的参数.</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>1.3</b> 静态注意力模型</h4>
                <div class="p1">
                    <p id="131">本文继承Wang等<sup><a class="sup">[18]</a></sup>及Yang等<sup><a class="sup">[19]</a></sup>的工作, 对于每个单词的隐藏层表示</p>
                </div>
                <div class="p1">
                    <p id="132"><b><i>H</i></b>=[<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>], </p>
                </div>
                <div class="p1">
                    <p id="133">由当前隐藏层向量<b><i>h</i></b><sub><i>j</i></sub>, 经权值矩阵, 计算该向量的注意力权重<i>s</i><sub><i>j</i></sub>, 并由此计算方法获得整句注意力权重</p>
                </div>
                <div class="p1">
                    <p id="134"><b><i>S</i></b>=[<i>s</i><sub>1</sub>, <i>s</i><sub>2</sub>, …, <i>s</i><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="135">在此之后将该注意力权重归一化, 获得统一标准下的注意力得分</p>
                </div>
                <div class="p1">
                    <p id="136"><b><i>A</i></b>=[<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>, …, <i>a</i><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="137">与Yang等<sup><a class="sup">[19]</a></sup>不同, 为了获得每个单词带注意力权重的向量表示, 本文将各个单词的注意力得分与其隐藏层表示作点积, 获取每个单词的注意力向量</p>
                </div>
                <div class="p1">
                    <p id="138"><b><i>C</i></b>=[<b><i>c</i></b><sub>1</sub>, <b><i>c</i></b><sub>2</sub>, …, <b><i>c</i></b><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="139">获得每个单词的注意力向量之后, 参考Wang等<sup><a class="sup">[18]</a></sup>的工作, 将该注意力向量输入门控循环单元 (Gated Recurrent Unit, GRU) 网络中进行更新操作, 以此获取更新后的注意力向量</p>
                </div>
                <div class="p1">
                    <p id="140"><b><i>U</i></b>=[<b><i>u</i></b><sub>1</sub>, <b><i>u</i></b><sub>2</sub>, …, <b><i>u</i></b><sub><i>n</i></sub>], </p>
                </div>
                <div class="p1">
                    <p id="141">静态注意力模型具体计算如下:</p>
                </div>
                <div class="p1">
                    <p id="142" class="code-formula">
                        <mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mi mathvariant="bold-italic">V</mi><mspace width="0.25em" /><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mi>h</mi><mo>-</mo></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>s</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>a</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>G</mi><mi>R</mi><mi>U</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>θ</mi><mo>-</mo><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="143">其中, <b><i>W</i></b><sub><i>h</i>-</sub>为关联于当前词的参数矩阵, <b><i>V</i></b>为调节非归一化注意力得分的参数矩阵, <i>θ</i>-为GRU神经元的参数.</p>
                </div>
                <h4 class="anchor-tag" id="144" name="144"><b>1.4</b> 门控动态注意力层</h4>
                <div class="p1">
                    <p id="145">动态注意力机制如图2所示.</p>
                </div>
                <div class="area_img" id="146">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902011_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 动态注意力机制图" src="Detail/GetImg?filename=images/MSSB201902011_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 动态注意力机制图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902011_146.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Illustration of dynamic attention mechanism diagram</p>

                </div>
                <div class="p1">
                    <p id="147">由1.2节可以得到每个单词的隐藏层表示</p>
                </div>
                <div class="p1">
                    <p id="148"><b><i>H</i></b>=[<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="149">门控层根据每个时刻 (即每个词汇) 的隐状态进行上下文注意力计算.给定<i>t</i>时刻 (即第<i>t</i>个词) , 通过当前向量表示<b><i>h</i></b><sub><i>t</i></sub>和其上下文向量表示<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>, 计算获得上下文<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>非归一化注意力得分:</p>
                </div>
                <div class="p1">
                    <p id="150" class="code-formula">
                        <mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">S</mi><msup><mrow></mrow><mi>t</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mi>s</mi><msubsup><mrow></mrow><mn>1</mn><mi>t</mi></msubsup><mo>, </mo><mi>s</mi><msubsup><mrow></mrow><mn>2</mn><mi>t</mi></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>s</mi><msubsup><mrow></mrow><mi>n</mi><mi>t</mi></msubsup><mo stretchy="false">]</mo><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi>s</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup><mo>=</mo><mi mathvariant="bold-italic">V</mi><mtext> </mtext><mi>tanh</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>h</mi></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>j</mi></msub><mo>+</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><msup><mi>h</mi><mo>′</mo></msup></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="151">该得分表示上下文注意权重的分配, <b><i>W</i></b><sub><i>h</i></sub>和<b><i>W</i></b><sub><i>h</i>′</sub>为上下文向量及当前向量的参数矩阵, <b><i>V</i></b>为调节非归一化注意力权重的参数矩阵.</p>
                </div>
                <div class="p1">
                    <p id="152">为了使权重在统一的标准中进行公平计算, 本文对</p>
                </div>
                <div class="p1">
                    <p id="153"><b><i>S</i></b><sup><i>t</i></sup>=[<i>s</i><mathml id="154"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mi>t</mi></msubsup></mrow></math></mathml>, <i>s</i><mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mi>t</mi></msubsup></mrow></math></mathml>, …, <i>s</i><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mi>t</mi></msubsup></mrow></math></mathml>]</p>
                </div>
                <div class="p1">
                    <p id="157">进行归一化处理, 以此获得可在统一标准下衡量的注意力得分:</p>
                </div>
                <div class="p1">
                    <p id="158" class="code-formula">
                        <mathml id="158"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">A</mi><msup><mrow></mrow><mi>t</mi></msup><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><msubsup><mrow></mrow><mn>1</mn><mi>t</mi></msubsup><mo>, </mo><mi>a</mi><msubsup><mrow></mrow><mn>2</mn><mi>t</mi></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>a</mi><msubsup><mrow></mrow><mi>n</mi><mi>t</mi></msubsup><mo stretchy="false">]</mo><mo>, </mo><mspace width="0.25em" /><mi>a</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi>s</mi><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>s</mi><msubsup><mrow></mrow><mi>j</mi><mi>t</mi></msubsup><mo stretchy="false">) </mo></mrow></mfrac><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="159">为了获得注意力分布不同的注意力向量, 本文将注意力权重乘以对应的上下文向量<b><i>h</i></b><sub>1</sub>, <b><i>h</i></b><sub>2</sub>, …, <b><i>h</i></b><sub><i>n</i></sub>, 并进行累加:</p>
                </div>
                <div class="p1">
                    <p id="160" class="code-formula">
                        <mathml id="160"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>a</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mi>t</mi></msubsup><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>i</mi></msub><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="161">通过上述计算得到各个时刻 (对应待测句子中的每个目标词项) 的注意力向量</p>
                </div>
                <div class="p1">
                    <p id="162"><b><i>C</i></b>=[<b><i>c</i></b><sub>1</sub>, <b><i>c</i></b><sub>2</sub>, …, <b><i>c</i></b><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="163">在此基础上, 本文继承Wang等<sup><a class="sup">[18]</a></sup>的工作, 将注意力向量输入到GRU网络中, 获取更新后的各个单词注意力向量表示.与Wang等<sup><a class="sup">[18]</a></sup>方法不同的是, 本文将<b><i>h</i></b><sub><i>t</i></sub>也作为GRU网络的输入, 用于获取更新后的各个单词注意力向量表示, 即本文将[<b><i>h</i></b><sub><i>t</i></sub>;<b><i>c</i></b><sub><i>t</i></sub>]作为GRU网络的输入.</p>
                </div>
                <div class="p1">
                    <p id="164">进一步地, 为了模拟某一词汇上下文对该词汇独立的重要性分布, 本文在[<b><i>h</i></b><sub><i>t</i></sub>;<b><i>c</i></b><sub><i>t</i></sub>]输入GRU网络前加入一个门控进行滤波, 借以控制流向GRU的信息量, 剔除一些不重要的上下文信息和错误的注意力分配.具体地, 本文将[<b><i>h</i></b><sub><i>t</i></sub>;<b><i>c</i></b><sub><i>t</i></sub>]乘以一个参数矩阵, 并经过Sigmoid函数 (由于经过Sigmoid函数后, 可将其约束在0～1之间, 起到门控作用) 进行滤波操作.</p>
                </div>
                <div class="p1">
                    <p id="165">获取门控<b><i>g</i></b><sub><i>t</i></sub>之后, 将<b><i>g</i></b><sub><i>t</i></sub>·[<b><i>h</i></b><sub><i>t</i></sub>;<b><i>c</i></b><sub><i>t</i></sub>]作为GRD的输入, 其中“·”表示对应位置相乘, [<b><i>h</i></b><sub><i>t</i></sub>;<b><i>c</i></b><sub><i>t</i></sub>]表示<b><i>h</i></b><sub><i>t</i></sub>和<b><i>c</i></b><sub><i>t</i></sub>的拼接.得到最终的各个目标词项的高级注意力向量表示:</p>
                </div>
                <div class="p1">
                    <p id="166" class="code-formula">
                        <mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mi>g</mi></msub><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>;</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⋅</mo><mo stretchy="false">[</mo><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mi>t</mi></msub><mo>;</mo><mi mathvariant="bold-italic">c</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">]</mo><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi>G</mi><mi>R</mi><mi>U</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>, </mo><mi mathvariant="bold-italic">m</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi mathvariant="bold-italic">θ</mi><mo stretchy="false">) </mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="167">其中, <b><i>W</i></b><sub><i>g</i></sub>为门控参数矩阵, <i>θ</i>为GRU的参数矩阵.模型中的GRU网络可根据实际需求替换为结构不同的循环神经网络.</p>
                </div>
                <div class="p1">
                    <p id="168">通过上述Bi-LSTM层及动态注意力层的表示学习, 得到各个目标单词的上下文注意力分布不同的向量</p>
                </div>
                <div class="p1">
                    <p id="169"><b><i>U</i></b>=[<b><i>u</i></b><sub>1</sub>, <b><i>u</i></b><sub>2</sub>, …, <b><i>u</i></b><sub><i>n</i></sub>].</p>
                </div>
                <div class="p1">
                    <p id="170">在此基础上, 输入到CRF<citation id="316" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>层进行序列标注, 最终获得各个目标单词的预测标签</p>
                </div>
                <div class="p1">
                    <p id="171" class="code-formula">
                        <mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">L</mi><mo>=</mo><mo stretchy="false">[</mo><mi>l</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>l</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>l</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">]</mo><mo>‚</mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mo stretchy="false">{</mo><mi>B</mi><mo>, </mo><mi>Μ</mi><mo>, </mo><mi>E</mi><mo>, </mo><mi>S</mi><mo>, </mo><mi>Ο</mi><mo stretchy="false">}</mo><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="172">需要注意的是, 当<b><i>U</i></b>输入CRF层进属性词的判别时, 继承Collins<citation id="317" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>的工作, 利用条件随机场概率计算的前向-后向算法预测标签的概率分布及其数学期望, 最终获得待判别句子中各个目标单词的预测标签.</p>
                </div>
                <h3 id="173" name="173" class="anchor-tag">2 实验及结果分析</h3>
                <h4 class="anchor-tag" id="174" name="174"><b>2.1</b> 实验数据及评价方法</h4>
                <div class="p1">
                    <p id="175">为了验证本文方法的有效性, 在SemEval 2014-2016属性级情感分析的4个基准数据集上进行实验.数据集分为2个领域:电脑 (Laptop) 领域和餐馆 (Restaurant) 领域.数据集的来源分别为2014年语义评测任务四 (http://alt.qcri.org/semeval2014/task4) 电脑领域 (SemEval 2014 Task 4 Laptop, 简写为LAPT 14) , 2014年语义评测任务四餐馆领域 (SemEval 2014 Task 4 Restaurant, 简写为REST 14) , 2015年语义评测任务十二 (http://alt.qcri.org/semeval2015/task12) 餐馆领域 (SemEval 2015 Task 12 Restaurant, 简写为REST 15) , 2016年语义评测任务五 (http://alt.qcri.org/semeval2016/task5) 餐馆领域 (SemEval 2016 Task 5 Restaurant, 简写为REST 16) .</p>
                </div>
                <div class="p1">
                    <p id="177">在4个数据集中, 训练样本 (句子) 数量分别为3 045, 3 041, 1 315和2 000.在实验过程中, 随机从训练数据中选取20%的样本作为开发集.经过开发集的划分后, 各个数据集的训练集、开发集及测试集样本数量如表1所示.</p>
                </div>
                <div class="area_img" id="178">
                    <p class="img_tit"><b>表1</b><b>实验语料统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Experimental statistics of datasets</p>
                    <p class="img_note"></p>
                    <table id="178" border="1"><tr><td><br />数据集</td><td>来源</td><td>训练集</td><td>开发集</td><td>测试集</td></tr><tr><td><br />S1</td><td>LAPT 14</td><td>2436</td><td>609</td><td>800</td></tr><tr><td><br />S2</td><td>REST 14</td><td>2433</td><td>608</td><td>800</td></tr><tr><td><br />S3</td><td>REST 15</td><td>1052</td><td>263</td><td>685</td></tr><tr><td><br />S4</td><td>REST 16</td><td>1600</td><td>400</td><td>676</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="179">与Wang等<citation id="318" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>方法相同, 本文采用的评价指标为<i>F</i>1值.评价过程采用精确匹配方式, 只有当模型预测结果满足精确匹配条件时, 才将该预测结果看作正确预测答案.</p>
                </div>
                <h4 class="anchor-tag" id="180" name="180"><b>2.2</b> 对比方法及参数设置</h4>
                <div class="p1">
                    <p id="181">为了验证方法的有效性, 选择如下方法与本文的门控动态注意力机制 (Dynamic Attention-CRF, DA-CRF) 进行对比.</p>
                </div>
                <div class="p1">
                    <p id="182">1) IHS-RD<citation id="319" type="reference"><link href="65" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>.LAPT 14属性抽取第一名评测系统, 融入多种手工特征的CRF方法.</p>
                </div>
                <div class="p1">
                    <p id="183">2) DLIREC<citation id="320" type="reference"><link href="67" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>.REST 14属性抽取第一名评测系统, 融入多种手工特征的CRF方法.</p>
                </div>
                <div class="p1">
                    <p id="184">3) 词和依存路径向量 (Word and Dependency Path Embedding, WDEmb) <citation id="321" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">28</a>]</sup></citation>.将词向量, 线性上下文向量及依存句法向量作为特征输入CRF, 优化属性抽取的性能.</p>
                </div>
                <div class="p1">
                    <p id="185">4) EliXa<citation id="322" type="reference"><link href="71" rel="bibliography" /><sup>[<a class="sup">29</a>]</sup></citation>.REST 15属性抽取第一名评测系统, 使用多种手工特征, 并利用开源工具 (https://github.com/ixa-ehu/ixa-pipe-nerc) 训练属性抽取模型的HMM方法.</p>
                </div>
                <div class="p1">
                    <p id="186">5) LSTM<citation id="323" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>.将预训练的词向量输入LSTM, 并通过全连接层得到各个单词标签的概率分布.</p>
                </div>
                <div class="p1">
                    <p id="187">6) NLANGP<citation id="325" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>.REST 16第一名评测系统, 基于CRF的方法, 并加入大量手工特征和双向埃尔曼型 (Elman-Type) RNN<citation id="324" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>的隐藏层特征.</p>
                </div>
                <div class="p1">
                    <p id="188">7) 记忆交互网络 (Memory Interaction Network, MIN) <citation id="326" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.将Bi-LSTM通过记忆力机制行进交互, 实现学习情感和属性过程中的特征共享, 进而实现属性抽取和情感词抽取的相互促进, 属性与情感词联合抽取的模型.</p>
                </div>
                <div class="p1">
                    <p id="189">8) 成对多层注意力 (Coupled Multi-layer Atten-tions, CMLA) <citation id="327" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>.成对多层注意力机制, 同时实现属性抽取注意力 (为一种静态注意力机制S-Att) 和情感抽取注意力 (成对) .该模型是属性与情感词联合抽取模型.</p>
                </div>
                <div class="p1">
                    <p id="190">9) Bi-LSTM+CRF.在基线系统NLANGP的基础上, 将双向埃尔曼型RNN结构替换为Bi-LSTM结构.以Greff等<citation id="328" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>提出的LSTM单元为基础, 将基于Bi-LSTM的CRF结构作为基线系统.</p>
                </div>
                <div class="p1">
                    <p id="191">10) 融合静态注意力的CRF模型 (Static Atten-tion-CRF, SA-CRF) .在Bi-LSTM+CRF系统的基础上, 以一种静态注意力 (S-Att) 的计算方式, 在Bi-LSTM层后加静态的注意力机制方法.</p>
                </div>
                <div class="p1">
                    <p id="192">预训练词向量维度为100维, 词向量来源为Glove (https://nlp.stanford.edu/projects/glove) .学习率 (Learning Rate) 设为0.001.批量 (Batch Size) 输入的大小设为20.Bi-LSTM+CRF中LSTM隐藏层单元数设为100.SA-CRF和DA-CRF中LSTM隐藏层单元数也设为100, 注意力向量维度为200, 用于更新注意力向量的GRU网络隐藏层单元维度设置为200.在SA-CRF中, 经过实验对比, 静态注意力层数设为3时性能最优, DA-CRF中动态注意力 (D-Att) 层数设为1.</p>
                </div>
                <div class="p1">
                    <p id="193">为了避免过拟合, 在各层之间加入dropout, 遵循Zaremba等<citation id="329" type="reference"><link href="73" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>的方法, 在各层之间加入部分drop-out (Partial Dropout) , 其中dropout比率 (Dropout Rate) 设置为0.5.</p>
                </div>
                <div class="p1">
                    <p id="195">为了避免神经网络的不确定性引起的实验性能波动, 在每组实验中以相同的超参数 (Hyper-Para-meters) 训练5个模型进行测试, 最终结果为选取这5个模型测试结果的平均值.</p>
                </div>
                <h4 class="anchor-tag" id="196" name="196"><b>2.3</b> 实验结果</h4>
                <div class="p1">
                    <p id="197">为了方便观察对比, 本文将上述系统使用的特征 (见表2) 及基础模型框架 (见表3) 形成表格.表4为详细的实验结果.从表中可以发现, DA-CRF在S1和S4数据集上取得了最优的<i>F</i>1值.</p>
                </div>
                <div class="area_img" id="198">
                    <p class="img_tit"><b>表2</b><b>各方法特征使用情况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Feature usage of different methods</p>
                    <p class="img_note"></p>
                    <table id="198" border="1"><tr><td><br />方法</td><td>特征使用情况</td></tr><tr><td><br />IHS-RD</td><td>分词, 词性, 命名实体, 语义类别, 语义导向, 词频, 评价对象, 头节点词, 语义角色, 名词短语, 符号列表, “of”短语</td></tr><tr><td><br />DLIREC</td><td>分词, 词性, 头节点词, 头节点词性, 依存句法, 属性词表, 句法类别, 词簇</td></tr><tr><td><br />WDEmb</td><td>分词, 词性, 词前缀和后缀, 词干, 首字母大小写, 一元模型, 二元模型, 依存句法, 线性上下文, 词向量</td></tr><tr><td><br />EliXa</td><td>分词, 词形状, 前一个预测标签, 句子开始词, 词前缀和后缀, 词簇, 词向量</td></tr><tr><td><br />LSTM</td><td>词性, 分块, 词向量</td></tr><tr><td><br />NLANGP</td><td>分词, 属性词表, 词簇, 依存句法, 词向量</td></tr><tr><td><br />MIN</td><td>词向量, 情感标签, 情感句</td></tr><tr><td><br />CMLA</td><td>词向量, 情感标签</td></tr><tr><td><br />Bi-LSTM+<br />CRF</td><td>词向量</td></tr><tr><td><br />SA-CRF</td><td>词向量</td></tr><tr><td><br />DA-CRF</td><td>词向量</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="199">
                    <p class="img_tit"><b>表3</b><b>各方法框架使用情况</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Framework usage of different methods</p>
                    <p class="img_note"></p>
                    <table id="199" border="1"><tr><td>方法</td><td>HMM</td><td>CRF</td><td>RNN</td><td>LSTM</td><td>S-Att</td><td>D-Att</td></tr><tr><td><br />IHS-RD</td><td></td><td>√</td><td></td><td></td><td></td><td></td></tr><tr><td><br />DLIREC</td><td></td><td>√</td><td></td><td></td><td></td><td></td></tr><tr><td><br />WDEmb</td><td></td><td>√</td><td></td><td></td><td></td><td></td></tr><tr><td><br />EliXa</td><td>√</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td><br />SLSTM</td><td></td><td></td><td></td><td>√</td><td></td><td></td></tr><tr><td><br />NLANGP</td><td></td><td>√</td><td>√</td><td></td><td></td><td></td></tr><tr><td><br />MIN</td><td></td><td></td><td></td><td>√</td><td></td><td></td></tr><tr><td><br />CMLA</td><td></td><td></td><td>√</td><td></td><td>√</td><td></td></tr><tr><td><br />Bi-LSTM+CRF</td><td></td><td>√</td><td></td><td>√</td><td></td><td></td></tr><tr><td><br />SA-CRF</td><td></td><td>√</td><td></td><td>√</td><td>√</td><td></td></tr><tr><td><br />DA-CRF</td><td></td><td>√</td><td></td><td>√</td><td></td><td>√</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="200">
                    <p class="img_tit"><b>表4</b><b>各方法在4个数据集上<i>F</i>1值对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 4 <i>F</i>1 values comparison of different methods on 4 datasets %</p>
                    <p class="img_note"></p>
                    <table id="200" border="1"><tr><td><br />方法</td><td>S1</td><td>S2</td><td>S3</td><td>S4</td></tr><tr><td><br />IHS-RD</td><td>74.55</td><td>79.62</td><td>-</td><td>-</td></tr><tr><td><br />DLIREC</td><td>73.78</td><td>84.01</td><td>-</td><td>-</td></tr><tr><td><br />WDEmb</td><td>75.16</td><td>84.97</td><td>69.73</td><td>-</td></tr><tr><td><br />EliXa</td><td>-</td><td>-</td><td>70.05</td><td>-</td></tr><tr><td><br />LSTM</td><td>75.00</td><td>82.06</td><td>64.30</td><td>71.26</td></tr><tr><td><br />NLANGP</td><td>-</td><td>-</td><td>-</td><td>72.34</td></tr><tr><td><br />MIN</td><td>77.58</td><td>-</td><td>-</td><td>73.44</td></tr><tr><td><br />CMLA</td><td>77.80</td><td>85.29</td><td>70.73</td><td>-</td></tr><tr><td><br />Bi-LSTM+CRF</td><td>76.91</td><td>83.56</td><td>68.29</td><td>71.41</td></tr><tr><td><br />SA-CRF</td><td>75.55</td><td>83.36</td><td>67.68</td><td>71.74</td></tr><tr><td><br />DA-CRF</td><td>77.86</td><td>84.57</td><td>69.48</td><td>73.55</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="201" name="201"><b>2.3.1</b> 与传统模型的对比</h4>
                <div class="p1">
                    <p id="202">相比加入大量手工特征的CRF系统 (IHS-RD、DLIREC和WDEmb) 和HMM系统 (EliXa) , DA-CRF在S1数据集上取得最优性能, 相比WDEmb提升2.7%.在S2、S3数据集上, 相比WDEmb和EliXa, DA-CRF取得可比的性能.</p>
                </div>
                <div class="p1">
                    <p id="203">由表2可发现, DA-CRF只使用词向量作为输入特征, 而基于CRF及HMM的系统使用大量的手工特征 (每个系统都将近使用10种不同的手工特征) .结合表2和表3可以发现, 在以词向量作为输入特征时, 结合LSTM和动态注意力机制的表示学习获得的单词向量表示可以取得比大量手工特征更好的效果 (见表4中S1) 或可比的效果 (见表4中S2) .</p>
                </div>
                <h4 class="anchor-tag" id="204" name="204"><b>2.3.2</b> 与神经网络模型的对比</h4>
                <div class="p1">
                    <p id="205">相比LSTM, DA-CRF性能也都得到大幅提升, 特别是在S3数据集上, DA-CRF提升5.18%.原因在于单独的LSTM将属性抽取任务转化为分类任务, 然而逐个对目标词项进行分类的处理方式并不能总是有效捕获包含多个单词的属性短语.</p>
                </div>
                <div class="p1">
                    <p id="206">相比REST 16第一名评测系统NLANGP, DA-CRF在无任何手工特征的情况下性能提升1.21%.相比Bi-LSTM+CRF, DA-CRF的<i>F</i>1值在4个测试集上分别提升0.95%, 1.01%, 1.19%和2.14%.这一现象说明本文的门控动态注意力机制对属性抽取具有一定的性能优越性.原因在于该注意力机制可以随着目标词项的变化, 自动调整上下文注意力权重的分配.</p>
                </div>
                <div class="p1">
                    <p id="207">图3给出一个样例, 由图可发现, 对于每个<i>t</i><sub><i>i</i></sub>时刻 (对应于每个目标词项) , 注意力会为上下文中的每个单词分配一套当前时刻的注意力权重, 并且在不同时刻, 上下文中每个单词注意力权重的分配也会进行自动调整.</p>
                </div>
                <div class="area_img" id="208">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902011_208.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 动态注意力机制形成的注意力分配样例" src="Detail/GetImg?filename=images/MSSB201902011_208.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 动态注意力机制形成的注意力分配样例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902011_208.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 3 Example of attention distribution by dynamic attention mechanism</p>

                </div>
                <div class="p1">
                    <p id="210">相比MIN和CMLA, DA-CRF在S1、S4数据集上取得最优性能, 在S2数据集上取得与CMLA系统可比的性能.由此说明, 在没有情感词抽取与属性词抽取相互促进的情况下, 本文方法也能较好地处理属性抽取任务, 无需任何情感词的帮助.相比CMLA, DA-CRF在S3数据集上出现较大性能差距.经统计分析发现, S3数据集数据量较少, 属性分布较稀疏, 在此情况下, CMLA利用情感词的抽取促进属性词的抽取, 同时利用属性词的抽取促进情感词的抽取, 这种相互促进的关系可使CMLA在更好地捕获属性词的同时也能更好捕获情感词.</p>
                </div>
                <h4 class="anchor-tag" id="211" name="211"><b>2.3.3</b> 与静态注意力模型的对比</h4>
                <div class="p1">
                    <p id="212">相比SA-CRF, DA-CRF在4个数据集上<i>F</i>1值均得到提升, 证明动态注意力机制性能优于静态注意力机制.在此, 本文将动态注意力机制形成的注意力权重分配样例 (见图3) 与静态注意力机制形成的注意力权重分配样例 (见图4) 相比, 发现静态注意力机制在每层分别一次建模所有的注意力权重.</p>
                </div>
                <div class="area_img" id="213">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902011_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 静态注意力机制形成的注意力分配样例" src="Detail/GetImg?filename=images/MSSB201902011_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 静态注意力机制形成的注意力分配样例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902011_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig. 4 Example of attention distribution by static attention mechanism</p>

                </div>
                <div class="p1">
                    <p id="215">例如, 在图4第一层, 该样例中静态注意力机制直接为所有的单词分配一组固定的注意力权重, 之后该组注意力权重不再随着目标词项的变化对注意力进行调整.这种刚性的注意力分配方式会导致大量注意力分配错误.这种偏差造成加入静态注意力机制的Bi-LSTM+CRF性能下降, 略低于基准系统 (见表4的S1、S3数据集) .</p>
                </div>
                <h4 class="anchor-tag" id="216" name="216"><b>2.3.4</b> 门控及注意力更新网络的对比</h4>
                <div class="p1">
                    <p id="217">为了进一步验证在动态注意力机制中加入门控对实验结果的影响, 本文进行如下对比实验.在实验中去掉动态注意力机制中的门控 (DA-CRF-NOG) , 与加入门控的动态注意力机制结果进行对比, 结果如表5所示.</p>
                </div>
                <div class="p1">
                    <p id="218">由表5可发现, 在动态注意力机制中加入门控之后, 在所有的数据集上的性能都优于不加入门控的注意力机制.原因在于, 虽然DA-CRF能在每个时刻计算上下文注意力分配不同的注意力向量, 但不能保证该注意力向量中所有信息都是有效的.因此, 本文在动态注意力机制中加入门控, 控制注意力向量流向下一层神经元的信息.该门控在处理每个目标词项的注意力向量时, 使该注意力向量中关注正确的信息以较高百分比通过门控, 并控制注意力向量中关注错误的信息以较低百分比通过门控, 实现对目标词项的注意力向量进行滤波的作用.</p>
                </div>
                <div class="area_img" id="219">
                    <p class="img_tit"><b>表5</b><b>在4个数据集上有无门控的<i>F</i>1值对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 5 <i>F</i>1 values of gated systems on 4 datasets %</p>
                    <p class="img_note"></p>
                    <table id="219" border="1"><tr><td><br />方法</td><td>S1</td><td>S2</td><td>S3</td><td>S4</td></tr><tr><td><br />DA-CRF</td><td>77.86</td><td>84.57</td><td>69.48</td><td>73.55</td></tr><tr><td><br />DA-CRF-NOC</td><td>77.40</td><td>83.74</td><td>69.00</td><td>72.20</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="220">最后, 本文通过实验验证2.4节注意力更新网络的选择, 各网络对属性抽取性能的影响如表6所示.可以发现, 在S1、S2数据集使用双向门控循环单元 (Bi-directional GRU, Bi-GRU) 效果最好, 在S3数据集上GRU表现出最优效果, 在S4数据集上Bi-LSTM表现最优.结合表1语料统计情况可发现, S1、S2、S4数据集训练数据较多, 而S3数据集训练数据较少, 因此可推测当训练语料较多时, 可根据需求选择Bi-LSTM或Bi-GRU网络, 当训练语料较少时, 可选择GRU或LSTM网络.由于最终结果相差不是很明显, 所以本文选择GRU网络进行各个系统实验性能对比.</p>
                </div>
                <div class="area_img" id="221">
                    <p class="img_tit"><b>表6</b><b>注意力更新网络性能对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 6 Performance comparison of attention updated network %</p>
                    <p class="img_note"></p>
                    <table id="221" border="1"><tr><td><br />网络</td><td>S1</td><td>S2</td><td>S3</td><td>S4</td></tr><tr><td><br />LSTM</td><td>77.50</td><td>84.77</td><td>69.12</td><td>73.70</td></tr><tr><td><br />Bi-LSTM</td><td>78.16</td><td>84.34</td><td>69.20</td><td>73.87</td></tr><tr><td><br />Bi-GRU</td><td>78.66</td><td>85.16</td><td>69.09</td><td>73.12</td></tr><tr><td><br />GRU</td><td>77.86</td><td>84.57</td><td>69.48</td><td>73.55</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="222" name="222" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="223">本文提出面向属性抽取的门控动态注意力机制, 可以随目标词项的变化, 自动调整上下文注意力权重的分配, 并产生一套分布不同的注意力向量, 从而使注意力动态适应待测句子中的每个目标词项.并且借助门控调整注意力向量流向下一层神经元的信息量, 对注意力施加于条件随机场的影响实施自动管理.实验表明, 本文方法在4个基准数据集上性能较优, 在不同程度上提高属性抽取的性能.此外, 相比静态注意力机制, 本文动态调整目标词项的上下文注意力权重, 可得到更精确的语义信息, 实验性能得到提升.在今后的研究工作中, 考虑使用依存关系监督注意力的建模, 进一步提高属性抽取的性能.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="15">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sem Eval-2014 Task 4:Aspect Based Sentiment Analysis">

                                <b>[1]</b> PONTIKI M, GALANIS D, PAVLOPOULOS J, <i>et al</i>. SemEval-2014 Task 4: Aspect Based Sentiment Analysis // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 27-35.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mining and Summarizing Customer Reviews">

                                <b>[2]</b> HU M Q, LIU B. Mining and Summarizing Customer Reviews // Proc of the 10th ACM SIGKDD International Conference on Know-ledge Discovery and Data Mining. New York, USA: ACM, 2004: 168-177.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Movie review mining and summarization">

                                <b>[3]</b> ZHUANG L, JING F, ZHU X Y. Movie Review Mining and Su-mmarization // Proc of the 15th ACM International Conference on Information and Knowledge Management. New York, USA: ACM, 2006: 43-50.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Building a sentiment summarizer for local service reviews">

                                <b>[4]</b> BLAIR-GOLDENSOHN S, HANNAN K, MCDONALD R, <i>et al</i>. Building a Sentiment Summarizer for Local Service Reviews // Proc of the Workshop on NLP in the Information Explosion Era. Stroudsburg, USA: ACL, 2008, XIV: 339-348.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bootstrapping Both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing[C/OL]">

                                <b>[5]</b> WANG B, WANG H F. Bootstrapping Both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing[C/OL]. [2018-05-30]. http://www.aclweb.org/anthology/I/I08/I08-1038.pdf.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Topic sentiment mixture:modeling facets and opinions in weblogs">

                                <b>[6]</b> MEI Q Z, LING X, WONDRA M, <i>et al</i>. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs // Proc of the 16th International Conference on World Wide Web. New York, USA: ACM, 2007: 171-180.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modeling online reviews with multi-grain topic models">

                                <b>[7]</b> TITOV I, Mcdonald R. Modeling Online Reviews with Multi-grain Topic Models // Proc of the 17th International Conference on World Wide Web. New York, USA: ACM, 2008: 111-120.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint Sentiment/Topic Model for Sentiment Analysis">

                                <b>[8]</b> LIN C H, HE Y L. Joint Sentiment/Topic Model for Sentiment Analysis // Proc of the 18th ACM Conference on Information and Knowledge Management. New York, USA: ACM, 2009: 375-384.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aspect extraction through semi-supervised modeling">

                                <b>[9]</b> MUKHERJEE A, LIU B. Aspect Extraction through Semi-supervised Modeling // Proc of the 50th Annual Meeting of the Association for Computational Linguistics. Stroudsburg, USA: ACL, 2012: 339-348.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OpinionMiner:A novel machine learning system for web opinion mining and extraction">

                                <b>[10]</b> JIN W, HO H H, SRIHARI R K. OpinionMiner: A Novel Machine Learning System for Web Opinion Mining and Extraction // Proc of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. New York, USA: ACM, 2009: 1195-1204.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Extracting opinion targets in a single and cross-domain setting with conditional random fields">

                                <b>[11]</b> JAKOB N, GUREVYCH I. Extracting Opinion Targets in a Single-and Cross-Domain Setting with Conditional Random Fields // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2010: 1035-1045.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Structure-aware review mining and summarization">

                                <b>[12]</b> LI F T, HAN C, HUANG M L, <i>et al</i>. Structure-Aware Review Mining and Summarization // Proc of the 23rd International Conference on Computational Linguistics. Stroudsburg, USA: ACL, 2010: 653-661.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint Opinion Relation Detection Using One-Class Deep Neural Network">

                                <b>[13]</b> XU L H, LIU K, ZHAO J. Joint Opinion Relation Detection Using One-Class Deep Neural Network // Proc of the 25th International Conference on Computational Linguistics. Stroudsburg, USA: ACL, 2014: 677-687.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fine-grained opinion mining with recurrent neural networks and word embeddings">

                                <b>[14]</b> LIU P F, JOTY S, MENG H L. Fine-Grained Opinion Mining with Recurrent Neural Networks and Word Embeddings // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2015: 1433-1443.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Multi-task Learning for Aspect Term Extraction with Memory Interaction">

                                <b>[15]</b> LI X, LAM W. Deep Multi-task Learning for Aspect Term Extraction with Memory Interaction // Proc of the Conference on Empirical Methods in Natural Language Processing. Stroudsburg, USA: ACL, 2017: 2886-2892.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=NLANGP at SemEval-2016 Task 5:Improving Aspect Based Sentiment Analysis using Neural Network Features">

                                <b>[16]</b> TOH Z Q, SU J. NLANGP at SemEval-2016 Task 5: Improving Aspect Based Sentiment Analysis Using Neural Network Features // Proc of the 10th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2016: 282-288.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural machine translation by jointly learning to align and translate">

                                <b>[17]</b> BAHDANAU D, CHO K, BENGIO Y. Neural Machine Translation by Jointly Learning to Align and Translate[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1409.0473v7.pdf.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Coupled Multi-layer Attentions for Co-extraction of Aspect and Opinion Terms">

                                <b>[18]</b> WANG W Y, PAN S J, DAHLMEIER D, <i>et al</i>. Coupled Multi-layer Attentions for Co-extraction of Aspect and Opinion Terms // Proc of the 31st AAAI Conference on Artificial Intelligence. Palo Alto, USA: AAAI Press, 2017: 3316-3322.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hierarchical Attention Networks for Document Classification">

                                <b>[19]</b> YANG Z C, YANG D Y, DYER C, <i>et al</i>. Hierarchical Attention Networks for Document Classification // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Stroudsburg, USA: ACL, 2016: 1480-1489.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bidirectional recurrent neural networks">

                                <b>[20]</b> SCHUSTER M, PALIWAL K K. Bidirectional Recurrent Neural Networks. IEEE Transactions on Signal Processing, 1997, 45 (11) : 2673-2681.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Forward-Backward Algorithm[C/OL]">

                                <b>[21]</b> COLLINS M. The Forward-Backward Algorithm[C/OL]. [2018-05-30]. http://www.cs.columbia.edu/～mcollins/fb.pdf.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bidirectional LSTM-CRF Models for Sequence Tagging[C/OL]">

                                <b>[22]</b> HUANG Z H, XU W, YU K. Bidirectional LSTM-CRF Models for Sequence Tagging[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1508.01991.pdf.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semeval-2015 Task 12: Aspect Based Sentiment Analysis">

                                <b>[23]</b> PONTIKI M, GALANIS D, PAPAGEORGIOU H, <i>et al</i>. Semeval-2015 Task 12: Aspect Based Sentiment Analysis // Proc of the 9th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2015: 486-495.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sem Eval-2016 Task 5:Aspect Based Sentiment Analysis">

                                <b>[24]</b> PONTIKI M, GALANIS D, PAPAGEORGIOU H, <i>et al</i>. SemEval-2016 Task 5: Aspect Based Sentiment Analysis // Proc of the 10th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2016: 19-30.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LSTM:A search space odyssey">

                                <b>[25]</b> GREFF K, SRIVASTAVA R K, KOUTNÍk J, <i>et al</i>. LSTM: A Search Space ODYSSEY. IEEE Transactions on Neural Networks and Learning Systems, 2017, 28 (10) : 2222-2232.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=IHS R.&amp;amp;.D Belarus:Cross-domain extraction of product features using CRF">

                                <b>[26]</b> CHERNYSHEVICH M. IHS R&amp;D Belarus: Cross-Domain Extraction of Product Features Using Conditional Random Fields // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 309-313.
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DLIREC:aspect term extraction and term polarity classification system">

                                <b>[27]</b> TOH Z Q, WANG W T. DLIREC: Aspect Term Extraction and Term Polarity Classification System // Proc of the 8th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2014: 235-240.
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unsupervised word and dependency path embeddings for aspect term extraction">

                                <b>[28]</b> YIN Y C, WEI F R, DONG L, <i>et al</i>. Unsupervised Word and Dependency Path Embeddings for Aspect Term Extraction // Proc of the 25th International Joint Conference on Artificial Intelligence. Palo Alto, USA: AAAI Press, 2016: 2979-2985.
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_29" target="_blank" href="http://scholar.cnki.net/result.aspx?q=EliXa:A modular and flexible ABSA platform">

                                <b>[29]</b> VICENTE I S, SARALEGI X, AGERRI R. EliXa: A Modular and Flexible ABSA Platform // Proc of the 9th International Workshop on Semantic Evaluation. Stroudsburg, USA: ACL, 2015: 748-752.
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_30" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recurrent neural network regularization">

                                <b>[30]</b> ZAREMBA W, SUTSKEVER I, VINYALS O. Recurrent Neural Network Regularization[C/OL]. [2018-05-30]. https://arxiv.org/pdf/1409.2329.pdf.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201902011" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201902011&amp;v=MDAzNTdMM0tLRDdZYkxHNEg5ak1yWTlFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6blU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
