<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131456010967500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201908002%26RESULT%3d1%26SIGN%3d2mAA3n9gjUlD9sQ0qdi%252byVnsEdE%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201908002&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201908002&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201908002&amp;v=MDM3NzBSbkZ5L2tVcjdJS0Q3WWJMRzRIOWpNcDQ5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#53" data-title="1 多粒度的用户画像模型设计 ">1 多粒度的用户画像模型设计</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#55" data-title="&lt;b&gt;1.1&lt;/b&gt; 概念定义"><b>1.1</b> 概念定义</a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;1.2&lt;/b&gt; 多粒度的用户画像模型设计"><b>1.2</b> 多粒度的用户画像模型设计</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#78" data-title="2 系统模型设计 ">2 系统模型设计</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#81" data-title="&lt;b&gt;2.1&lt;/b&gt; 特征表示"><b>2.1</b> 特征表示</a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;2.2&lt;/b&gt; 子模型设计"><b>2.2</b> 子模型设计</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="3 实验及结果分析 ">3 实验及结果分析</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#91" data-title="&lt;b&gt;3.1&lt;/b&gt; 实验数据"><b>3.1</b> 实验数据</a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;3.2&lt;/b&gt; 模型训练结果"><b>3.2</b> 模型训练结果</a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;3.3&lt;/b&gt; 聚类及可视化"><b>3.3</b> 聚类及可视化</a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;3.4&lt;/b&gt; 可视化结果分析"><b>3.4</b> 可视化结果分析</a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#149" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="图1 Stacking模型融合示意图">图1 Stacking模型融合示意图</a></li>
                                                <li><a href="#80" data-title="图2 系统流程图">图2 系统流程图</a></li>
                                                <li><a href="#87" data-title="图3 BPNN结构">图3 BPNN结构</a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;表1 数据字段说明&lt;/b&gt;"><b>表1 数据字段说明</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;表2 各模型在3个任务上的准确率&lt;/b&gt;"><b>表2 各模型在3个任务上的准确率</b></a></li>
                                                <li><a href="#129" data-title="图4 性别不参与时聚类结果及高频词词云">图4 性别不参与时聚类结果及高频词词云</a></li>
                                                <li><a href="#129" data-title="图4 性别不参与时聚类结果及高频词词云">图4 性别不参与时聚类结果及高频词词云</a></li>
                                                <li><a href="#145" data-title="图5 性别参与时聚类结果及高频词词云">图5 性别参与时聚类结果及高频词词云</a></li>
                                                <li><a href="#145" data-title="图5 性别参与时聚类结果及高频词词云">图5 性别参与时聚类结果及高频词词云</a></li>
                                                <li><a href="#145" data-title="图5 性别参与时聚类结果及高频词词云">图5 性别参与时聚类结果及高频词词云</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" GU H Q, WANG J, WANG Z W, &lt;i&gt;et al&lt;/i&gt;.Modeling of User Portrait through Social Media // Proc of the IEEE International Conference on Multimedia and Expo.Washington, USA:IEEE, 2018.DOI:10.1109/ICME.2018.8486595." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Modeling of user portrait through social media">
                                        <b>[1]</b>
                                         GU H Q, WANG J, WANG Z W, &lt;i&gt;et al&lt;/i&gt;.Modeling of User Portrait through Social Media // Proc of the IEEE International Conference on Multimedia and Expo.Washington, USA:IEEE, 2018.DOI:10.1109/ICME.2018.8486595.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 陈慧香, 邵波.国外图书馆领域用户画像的研究现状及启示.图书馆学研究, 2017 (20) :16-20. (CHEN H X, SHAO B.The Research Status and Enlightenment of the User Profile in the Library Fields at Abroad.Research on Library Science, 2017 (20) :16-20.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TSSS201720003&amp;v=MjU2ODc0SDliT3I0OUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rVXI3SU1UN1lmYkc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         陈慧香, 邵波.国外图书馆领域用户画像的研究现状及启示.图书馆学研究, 2017 (20) :16-20. (CHEN H X, SHAO B.The Research Status and Enlightenment of the User Profile in the Library Fields at Abroad.Research on Library Science, 2017 (20) :16-20.) 
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" GAUCH S, SPERETTA M, CHANDRAMOULI A, &lt;i&gt;et al&lt;/i&gt;.User Profiles for Personalized Information Access // BRUSILOVSKY D, KOBSA A, NEJDL W, eds.The Adaptive Web, Methods and Stra-tegies of Web Personalization.Berlin, Germany:Springer, 2007:54-89." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=User Profiles for Personalized Information Access">
                                        <b>[3]</b>
                                         GAUCH S, SPERETTA M, CHANDRAMOULI A, &lt;i&gt;et al&lt;/i&gt;.User Profiles for Personalized Information Access // BRUSILOVSKY D, KOBSA A, NEJDL W, eds.The Adaptive Web, Methods and Stra-tegies of Web Personalization.Berlin, Germany:Springer, 2007:54-89.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" TEIXEIRA C, PINTO J S, MARTINS J A.User Profiles in Organizational Environments.Campus-Wide Information Systems, 2008, 25 (3) :128-144." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00000622205&amp;v=Mjg1MjFNSDdSN3FlYnVkdEZDSGxWTDdKSVY0PU5qM2Fhck80SHRITXFZMUhadXNLWTNrNXpCZGg0ajk5U1hxUnJ4b3hj&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         TEIXEIRA C, PINTO J S, MARTINS J A.User Profiles in Organizational Environments.Campus-Wide Information Systems, 2008, 25 (3) :128-144.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" BILLSUS D, PAZZANO M J.A Hybrid User Model for News Story Classification // Proc of the 7th International Conference on User Modeling.Berlin, Germany:Springer, 1999:99-108." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Hybrid User Model for News Story Classification">
                                        <b>[5]</b>
                                         BILLSUS D, PAZZANO M J.A Hybrid User Model for News Story Classification // Proc of the 7th International Conference on User Modeling.Berlin, Germany:Springer, 1999:99-108.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" LAIN&#201;-CRUZEL S, LAFOUGE T, LARDY J P, &lt;i&gt;et al&lt;/i&gt;.Improving Information Retrieval by Combining User Profile and Document Segmentation.Information Processing and Management, 1996, 32 (3) :305-315." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100870863&amp;v=MDYzNzV1SHlqbVVMYklKMThWYXhJPU5pZk9mYks3SHRET3JvOUZiT3dQQkhvNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         LAIN&#201;-CRUZEL S, LAFOUGE T, LARDY J P, &lt;i&gt;et al&lt;/i&gt;.Improving Information Retrieval by Combining User Profile and Document Segmentation.Information Processing and Management, 1996, 32 (3) :305-315.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 李映坤.大数据背景下用户画像的统计方法实践研究.硕士学位论文.北京:首都经济贸易大学, 2016. (LI Y K.Practical Research on Statistical Methods of User Portraits in the Background of Big Data.Master Dissertation.Beijing, China:Capital University of Economics and Business, 2016.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016097276.nh&amp;v=MTI1NDFGMjZHTE94R2RQTHFaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rVXI3SVY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         李映坤.大数据背景下用户画像的统计方法实践研究.硕士学位论文.北京:首都经济贸易大学, 2016. (LI Y K.Practical Research on Statistical Methods of User Portraits in the Background of Big Data.Master Dissertation.Beijing, China:Capital University of Economics and Business, 2016.) 
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 张小可, 沈文明, 杜翠凤.贝叶斯网络在用户画像构建中的研究.移动通信, 2016, 40 (22) :22-26. (ZHANG X K, SHEN W M, DU C F.Research on Bayesian Network in User Portrait Construction.Mobile Communications, 2016, 40 (22) :22-26.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YDTX201622008&amp;v=MDMzMjVSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rVXI3SVBDbmZkckc0SDlmT3JZOUZiSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         张小可, 沈文明, 杜翠凤.贝叶斯网络在用户画像构建中的研究.移动通信, 2016, 40 (22) :22-26. (ZHANG X K, SHEN W M, DU C F.Research on Bayesian Network in User Portrait Construction.Mobile Communications, 2016, 40 (22) :22-26.) 
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 张哲.基于微博数据的用户画像系统的设计与实现.硕士学位论文.武汉:华中科技大学, 2015. (ZHANG Z.Design and Implementation of User Portrait System Based on Microblog Data.Master Dissertation.Wuhan, China:Huazhong University of Science and Technology, 2015.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015908693.nh&amp;v=MDk4MzQva1VyN0lWRjI2RzdxNEZ0ZkZySkViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         张哲.基于微博数据的用户画像系统的设计与实现.硕士学位论文.武汉:华中科技大学, 2015. (ZHANG Z.Design and Implementation of User Portrait System Based on Microblog Data.Master Dissertation.Wuhan, China:Huazhong University of Science and Technology, 2015.) 
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 刘速.浅议数字图书馆知识发现系统中的用户画像——以天津图书馆为例.图书馆理论与实践, 2017 (6) :103-106. (LIU S.The Persona in Digital Library Knowledge Discovery System-Taking Tianjin Library as an Example.Library Theory and Practice, 2017 (6) :103-106.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=LSGL201706023&amp;v=MTcyMjRZckc0SDliTXFZOUhaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rVXI3SUtUN00=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         刘速.浅议数字图书馆知识发现系统中的用户画像——以天津图书馆为例.图书馆理论与实践, 2017 (6) :103-106. (LIU S.The Persona in Digital Library Knowledge Discovery System-Taking Tianjin Library as an Example.Library Theory and Practice, 2017 (6) :103-106.) 
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     高玉龙.基于文本挖掘的用户画像研究.硕士学位论文.汕头:汕头大学, 2014. (GAO Y L.Users Portrait Research Based on Text Mining.Master Dissertation.Shantou, China:Shantou University, 2014.) </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 李冰, 王悦, 刘永祥.大数据环境下基于&lt;i&gt;K&lt;/i&gt;-means的用户画像与智能推荐的应用.现代计算机, 2016 (24) :11-15. (LI B, WANG Y, LIU Y X.Application of User Portrait and Intelligent Recommendation Based on Big Data Technology and &lt;i&gt;K&lt;/i&gt;-means.Modern Computer, 2016 (24) :11-15.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201624004&amp;v=MDc0MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rVXI3SVBTbkJmYkc0SDlmT3E0OUZZSVFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         李冰, 王悦, 刘永祥.大数据环境下基于&lt;i&gt;K&lt;/i&gt;-means的用户画像与智能推荐的应用.现代计算机, 2016 (24) :11-15. (LI B, WANG Y, LIU Y X.Application of User Portrait and Intelligent Recommendation Based on Big Data Technology and &lt;i&gt;K&lt;/i&gt;-means.Modern Computer, 2016 (24) :11-15.) 
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" SUGIYAMA K, HATANO K, YOSHIKAWA M.Adaptive Web Search Based on User Profile Constructed without any Effort from Users[C/OL].[2019-05-25].https://www.iw3c2.org/WWW2004/docs/1p675.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adaptive Web Search Based on User Profile Constructed without Any Effort from Users">
                                        <b>[13]</b>
                                         SUGIYAMA K, HATANO K, YOSHIKAWA M.Adaptive Web Search Based on User Profile Constructed without any Effort from Users[C/OL].[2019-05-25].https://www.iw3c2.org/WWW2004/docs/1p675.pdf.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" ZHAO C R, WANG X K, MIAO D Q, &lt;i&gt;et al&lt;/i&gt;.Maximal Granularity Structure and Generalized Multi-view Discriminant Analysis for Person Re-identification.Pattern Recognition, 2018, 79:79-96." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES0D74FD250B0A46ACFE8F228CBF7B2096&amp;v=MzE4MTJRbGZDcGJRMzVORmh3N20rd2FnPU5pZk9mYlBNR2RXNjI0MUFaSmtQZlhnL3ZtVmxuemNMU24zcTMyQkRmc0NXUmJPWkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPRw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         ZHAO C R, WANG X K, MIAO D Q, &lt;i&gt;et al&lt;/i&gt;.Maximal Granularity Structure and Generalized Multi-view Discriminant Analysis for Person Re-identification.Pattern Recognition, 2018, 79:79-96.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" YAO Y Y.Interpreting Concept Learning in Cognitive Informatics and Granular Computing.IEEE Transactions on Systems, Man, and Cybernetics (Cybernetics) , 2009, 39 (4) :855-866." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interpreting concept learning in cognitive informatics and granular computing">
                                        <b>[15]</b>
                                         YAO Y Y.Interpreting Concept Learning in Cognitive Informatics and Granular Computing.IEEE Transactions on Systems, Man, and Cybernetics (Cybernetics) , 2009, 39 (4) :855-866.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" LAU J H, BALDWIN T.An Empirical Evaluation of Doc2Vec with Practical Insights into Document Embedding Generation // Proc of the 1st Workshop on Representation Learning for NLP.Stroudsburg, USA:ACL, 2016:78-86." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Empirical Evaluation of Doc2Vec with Practical Insights into Document Embedding Generation">
                                        <b>[16]</b>
                                         LAU J H, BALDWIN T.An Empirical Evaluation of Doc2Vec with Practical Insights into Document Embedding Generation // Proc of the 1st Workshop on Representation Learning for NLP.Stroudsburg, USA:ACL, 2016:78-86.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" RAMOS J.Using TF-IDF to Determine Word Relevance in Document Queries // Proc of the 1st Instructional Conference on Machine Learning.Berlin, Germany:Springer, 2003.DOI:10.15804/tner.2015.42.4.03." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using TF-IDF to determine Word relevance in document queries">
                                        <b>[17]</b>
                                         RAMOS J.Using TF-IDF to Determine Word Relevance in Document Queries // Proc of the 1st Instructional Conference on Machine Learning.Berlin, Germany:Springer, 2003.DOI:10.15804/tner.2015.42.4.03.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(08),691-698 DOI:10.16451/j.cnki.issn1003-6059.201908002            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于粒计算的多粒度用户画像</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%92%8B%E6%98%8E%E4%BC%9A&amp;code=42707026&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蒋明会</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%97%E5%A4%BA%E8%B0%A6&amp;code=08963093&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苗夺谦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%BD%97%E6%99%9F&amp;code=10867310&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">罗晟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%89%8D%E8%8D%A3&amp;code=30925470&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵才荣</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E7%B3%BB&amp;code=0118734&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同济大学计算机科学与技术系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%8C%E6%B5%8E%E5%A4%A7%E5%AD%A6%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%B8%8E%E6%9C%8D%E5%8A%A1%E8%AE%A1%E7%AE%97%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同济大学嵌入式系统与服务计算教育部重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>现有的用户画像分析模型使用单一模型单一粒度的学习方式处理异构多源的原始数据, 限制分析模型的性能, 无法完整展示多层次、多角度的用户画像特征.针对该问题, 基于粒计算思想, 文中提出多粒度用户画像分析模型.首先, 构建数据的多粒度表示结构, 粒化原始数据.再根据数据粒度结构, 提出基于集成学习的粒度提升算法, 用于融合低粒层的数据信息以得到高粒层的数据表示.最后, 在多个粒层数据表示上进行用户画像分析, 展示一个较全面的用户画像.实验表明, 相比单一粒度的用户画像, 多粒度的用户画像更全面、立体和丰富.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">用户画像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E7%B2%92%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多粒度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">集成学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%B2%92%E5%BA%A6%E6%8F%90%E5%8D%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">粒度提升;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    蒋明会, 硕士研究生, 主要研究方向为计算机视觉、深度学习、粒计算.E-mail:jiangminghui@tongji.edu.cn.;
                                </span>
                                <span>
                                    *苗夺谦, 博士, 教授, 主要研究方向为人工智能、机器学习、大数据分析、粒计算等.E-mail:dqmiao@tongji.edu.cn.;
                                </span>
                                <span>
                                    罗晟, 博士, 讲师, 主要研究方向为粒计算、机器学习.E-mail:9527atct@tongji.edu.cn.;
                                </span>
                                <span>
                                    赵才荣, 博士, 副研究员, 主要研究方向为人脸识别、计算机视觉.E-mail:zhaocairong@tongji.edu.cn.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-06-26</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (No.213);</span>
                                <span>国家自然科学基金项目 (No.61673301, 61563016);</span>
                                <span>公安部重大专项项目 (No.20170004) 资助;</span>
                    </p>
            </div>
                    <h1><b>Multi-granularity User Portrait Based on Granular Computing</b></h1>
                    <h2>
                    <span>JIANG Minghui</span>
                    <span>MIAO Duoqian</span>
                    <span>LUO Sheng</span>
                    <span>ZHAO Cairong</span>
            </h2>
                    <h2>
                    <span>Department of Computer Science and Technology, Tongji University</span>
                    <span>Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Single model with single granularity is employed to process multi-sources heterogeneous raw data in the existing user portrait models. The performance of the analytic model is limited and the multi-level and multi-angle user portrait features cannot be fully displayed. Aiming at this problem, based on the idea of granular computing, a multi-granularity user portrait model is proposed. Firstly, a multi-granular representation structure of the data is constructed to granulate the raw data. Then, according to the data granularity structure, a granularity upgrade algorithm based on ensemble learning is proposed. Low-level data information is fused to obtain high-level data representation. Finally, user portrait analysis is carried out at multi-level data representation to show a more comprehensive portrait. Experiments show that the user portrait with multiple granularities is more comprehensive, stereoscopic and richer than the single granularity user portrait.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=User%20Portrait&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">User Portrait;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multiple%20Granularities&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multiple Granularities;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Ensemble%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Ensemble Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Granular%20Upgrade&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Granular Upgrade;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    JIANG Minghui, master student.His research interests include computer vision, deep learning and granular computing.;
                                </span>
                                <span>
                                    MIAO Duoqian, Ph.D., professor.His research interests include artificial intelligence, machine learning, big data analysis and granular computing.;
                                </span>
                                <span>
                                    LUO Sheng, Ph.D., lecturer.His research interests include granular computing and machine learning.;
                                </span>
                                <span>
                                    ZHAO Cairong, Ph.D., associate professor.His research interests include face recognition and computer vision.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-06-26</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Key Research and Development Program of China (No.213);</span>
                                <span>National Natural Science Foundation of China (No.61673301, 61563016);</span>
                                <span>Major Project of Ministry of Public Security (No.20170004);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="48">近年来, 随着大数据的发展和文本挖掘、深度学习等技术的不断进步, 寻找用户数据, 构建用户画像模型成为可能.用户画像已得到学界、工业界等的大量关注, 在各个领域具有广泛的应用前景<citation id="152" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>.由于研究者的研究背景、方向的不同, 用户画像目前还缺乏统一的严格定义.Gauch等<citation id="153" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>将用户画像描述为一组加权关键词、语义网或概念层次结构的集合.Teixeria等<citation id="154" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>认为用户画像是一个独立的描述用户需求、偏好和兴趣的用户模型, 是从海量的系统数据中提取的个人数据信息的集合.</p>
                </div>
                <div class="p1">
                    <p id="50">在用户画像的模型构造算法方面, Billsus等<citation id="155" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>针对短期偏好可以采用最近邻分类算法, 针对长期偏好可以采用朴素贝叶斯分类法.Lainé-cruzel等<citation id="156" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>指出信息检索系统中的用户特征信息主要包含两方面:1) 与用户相关的稳定因素, 如用户的个人信息和行为习惯;2) 检索环境下的可变信息, 如搜索目标.文献<citation id="157" type="reference">[<a class="sup">5</a>]</citation>围绕这两个方面描述用户画像模型.</p>
                </div>
                <div class="p1">
                    <p id="51">用户画像也在广泛领域中有所应用.李映坤<citation id="158" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>研究固定时段内手机APP的使用数据, 分析实践用户画像、用户流失模型预测和用户行为聚类三个主要问题.张小可等<citation id="159" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>使用贝叶斯网络构造手机APP用户画像, 使用多元线性回归模型, 根据用户的上网数据更新网络各节点值, 用于追踪用户不断变化的兴趣.张哲<citation id="160" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>使用LAMP (Linux-Apache-MySQL-PHP) 和MVC (Model-View-Controller) 模型构建微博用户画像系统, 可通过ID查询微博用户的画像相关信息.刘速<citation id="161" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出基于画像的多维度交叉分析和基于画像的用户关系图谱等分析方法.高玉龙<citation id="162" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>采用文本挖掘技术获取用于构建用户画像的属性, 再利用文本聚类和文本分类对用户进行标签描述, 构建用户画像.李冰等<citation id="163" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>使用<i>K</i>-means聚类构建用户画像, 探究特征客户群对于卷烟的倾向性.Sugiyama等<citation id="164" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>分析用户上网历史数据, 改进协同过滤算法, 使搜索引擎的返回结果更符合当前用户希望得到的内容和兴趣.</p>
                </div>
                <div class="p1">
                    <p id="52">虽然用户画像的建模方法和应用领域具有很多成果, 但这些研究只从单一粒度上的单一模型分析用户画像, 在数据为多维度时难以全方位地展示用户画像特征.针对现有画像系统的不足, 基于粒计算思想, 本文以用户在搜索引擎的历史搜索记录和用户属性 (年龄、性别、学历) 为原始数据, 使用Stac-king模型融合技术对多种模型进行融合以改进单一模型、单一粒度学习的限制, 实现多粒度的用户画像分析模型.为了易于理解用户画像结果, 设计一个分析结果的可视化展示.</p>
                </div>
                <h3 id="53" name="53" class="anchor-tag">1 多粒度的用户画像模型设计</h3>
                <div class="p1">
                    <p id="54">粒计算是一种看待客观世界的世界观, 也是人们在处理日常事务时的一般性思维模式.人们在解决实际问题时, 往往是从多层次、多角度去看待问题, 这也就产生粒计算中的最基本概念之一——信息粒<citation id="165" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>.通过将不同层次、不同角度作为不同的粒度, 对数据进行粒化, 这种方法论就是粒计算<citation id="166" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>.</p>
                </div>
                <h4 class="anchor-tag" id="55" name="55"><b>1.1</b> 概念定义</h4>
                <div class="p1">
                    <p id="56"><b>定义1</b> 低层信息粒、高层信息粒 一般地, 对于采集的数据集进行简单的清洗和未知值预测填充等操作之后的数据称为低层信息, 属于低层信息粒, 记为<i>INF</i><sup><i>L</i></sup>.低层信息粒经过多个模型融合后形成的新的数据称为高层信息, 属于高层信息粒, 记为<i>INF</i><sup><i>H</i></sup>.</p>
                </div>
                <div class="p1">
                    <p id="57"><b>定义2</b> 训练信息粒、测试信息粒 在不同粒度 (低层、高层) 的信息粒上:用于训练的数据称为训练信息粒, 记为<i>INF</i><sup><i>L</i>_<i>Train</i></sup> (低层训练信息粒) 、<i>INF</i><sup><i>H</i>_<i>Train</i></sup> (高层训练信息粒) ;用于测试的数据称为测试信息粒, 记为<i>INF</i><sup><i>L</i>_<i>Test</i></sup> (低层测试信息粒) 、<i>INF</i><sup><i>H</i>_<i>Test</i></sup> (高层测试信息粒) .</p>
                </div>
                <div class="p1">
                    <p id="58"><b>定义3</b> 粒度提升 由多个低层信息粒融合成高层信息粒这一过程称为粒度提升.</p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>1.2</b> 多粒度的用户画像模型设计</h4>
                <div class="p1">
                    <p id="60">本文提出的多粒度模型是指数据在多个不同层次的粒度下进行表示, 并使用不同粒度下的数据进行实验, 形成对比实验.首先将原始数据在低层信息粒下进行表示, 并通过粒度提升融合成高层信息粒, 得到高层粒度下的数据表示, 最后在多层表示下进行后续模型训练工作.</p>
                </div>
                <div class="p1">
                    <p id="61">本文使用Stacking集成学习实现粒度提升.Stacking集成是一种灵活的集成学习方法.本文使用的Stacking框架包含如下两层:</p>
                </div>
                <div class="p1">
                    <p id="62">第一层在低层信息粒上融合多模型形成高层信息粒, 实现粒度提升, 具体过程见算法1.</p>
                </div>
                <div class="p1">
                    <p id="63">第二层使用XGBoost在高层信息粒基础上预测结果.它是一个专注于梯度提升算法的机器学习函数库, 主要过程是建立回归树.回归树与分类树相似, 只不过分类树的输出为一个个离散的类别, 而回归树为数值的形式.在更高粒度层次的<i>INF</i><sup><i>H</i>_<i>Train</i></sup>和<i>INF</i><sup><i>H</i>_<i>Test</i></sup>数据上训练XGBoost, 可以获得更好的模型效果.</p>
                </div>
                <div class="p1">
                    <p id="64">Stacking架构如图1所示.</p>
                </div>
                <div class="p1">
                    <p id="65"><b>算法1</b> 粒度提升算法</p>
                </div>
                <div class="p1">
                    <p id="66"><b>输入</b> 低层训练信息粒<i>INF</i><sup><i>L</i>_<i>Train</i></sup>, </p>
                </div>
                <div class="p1">
                    <p id="67">低层测试信息粒<i>INF</i><sup><i>L</i>_<i>Test</i></sup></p>
                </div>
                <div class="p1">
                    <p id="68"><b>输出</b> 高层训练信息粒<i>INF</i><sup><i>H</i>_<i>Train</i></sup>, </p>
                </div>
                <div class="p1">
                    <p id="69">高层测试信息粒<i>INF</i><sup><i>H</i>_<i>Test</i></sup></p>
                </div>
                <div class="p1">
                    <p id="70">step 1 对于每个子模型<i>SubModel</i>_<i>i</i>, 第<i>i</i>个子模型记为<i>SubModel</i>_<i>i</i>, 共<i>M</i>个子模型, 循环step 2～</p>
                </div>
                <div class="p1">
                    <p id="71">step 4.</p>
                </div>
                <div class="p1">
                    <p id="72">step 2 将<i>INF</i><sup><i>L</i>_<i>Train</i></sup>随机均分成<i>N</i>份, 第<i>i</i>份记为<i>INF</i><sup><i>L</i>_<i>Train</i>_<i>i</i></sup>, 每份循环step 3.</p>
                </div>
                <div class="p1">
                    <p id="73">step 3 用<i>INF</i><sup><i>L</i>_<i>Train</i></sup>减去<i>INF</i><sup><i>L</i>_<i>Train</i>_<i>i</i></sup>剩余的数据, 训练子模型<i>SubModel</i>_<i>i</i>, 使用训练的子模型预测<i>INF</i><sup><i>L</i>_<i>Train</i>_<i>i</i></sup>, 预测结果记为<i>INF</i><sup><i>L</i>_<i>Train</i>_<i>Pre</i>_<i>i</i></sup>, 同时预测<i>INF</i><sup><i>L</i>_<i>Test</i></sup>, 预测结果记为<i>INF</i><sup><i>L</i>_<i>Test</i>_<i>Pre</i>_<i>i</i></sup>.</p>
                </div>
                <div class="p1">
                    <p id="74">step 4 将step 3中产生的<i>INF</i><sup><i>L</i>_<i>Train</i>_<i>Pre</i>_1</sup>, <i>INF</i><sup><i>L</i>_<i>Train</i>_<i>Pre</i>_2</sup>, …, <i>INF</i><sup><i>L</i>_<i>Train</i>_<i>Pre</i>_<i>N</i></sup>进行样本维度拼接, 即拼接后的总样本数目等于各个拼接的样本数目总和, 得到<i>SubModel</i>_<i>i</i>的高层训练粒度表示<i>INF</i><sup><i>H</i>_<i>Train</i>_<i>SubModel</i>_<i>i</i></sup>;将产生的<i>INF</i><sup><i>L</i>_<i>Test</i>_<i>Pre</i>_1</sup>, <i>INF</i><sup><i>L</i>_<i>Test</i>_<i>Pre</i>_2</sup>, …, <i>INF</i><sup><i>L</i>_<i>Test</i>_<i>Pre</i>_<i>N</i></sup>进行样本维度求均值 (即拼接后样本数目和特征维度都不变, 每个数据点都是参与拼接的各数据点对应位置的均值) , 得到<i>SubModel</i>_<i>i</i>的高层测试粒度表示<i>INF</i><sup><i>H</i>_<i>Test</i>_<i>SubModel</i>_<i>i</i></sup>.</p>
                </div>
                <div class="p1">
                    <p id="75">step 5 将step 4中产生的<i>INF</i><sup><i>H</i>_<i>Train</i>_<i>SubModel</i>_1</sup>, <i>INF</i><sup><i>H</i>_<i>Train</i>_<i>SubModel</i>_2</sup>, …, <i>INF</i><sup><i>H</i>_<i>Train</i>_<i>SubModel</i>_<i>M</i></sup> 进行特征维度拼接, 即拼接后总样本数目等于每个拼接的样本数目, 但拼接后每个样本的特征维度是参与拼接的各样本特征维度总和, 得到高层训练信息粒<i>INF</i><sup><i>H</i>_<i>Train</i></sup>;同理产生的<i>INF</i><sup><i>H</i>_<i>Test</i>_<i>SubModel</i>_1</sup>, <i>INF</i><sup><i>H</i>_<i>Test</i>_<i>SubModel</i>_2</sup>, …, <i>INF</i><sup><i>H</i>_<i>Test</i>_<i>SubModel</i>_<i>M</i></sup>进行特征维度拼接, 得到高层测试信息粒<i>INF</i><sup><i>H</i>_<i>Test</i></sup>.</p>
                </div>
                <div class="p1">
                    <p id="76">Stacking第1层输出的高层训练信息粒<i>INF</i><sup><i>H</i>_<i>Train</i></sup>和高层测试信息粒<i>INF</i><sup><i>H</i>_<i>Test</i></sup>, 作为第2层XGBoost的输入, 之后预测<i>INF</i><sup><i>H</i>_<i>Test</i></sup>.</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Stacking模型融合示意图" src="Detail/GetImg?filename=images/MSSB201908002_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Stacking模型融合示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Diagram of stacking model fusion</p>

                </div>
                <h3 id="78" name="78" class="anchor-tag">2 系统模型设计</h3>
                <div class="p1">
                    <p id="79">系统首先对输入数据进行多种特征表示, 在每种特征表示下分别训练模型, 得到多个不同的子模型的输出, 即低层信息粒度上的数据.再对这些数据按照算法1进行粒度提升, 得到高粒度层次上的信息粒.最后, 使用XGBoost预测年龄、性别和学历三个任务上的输出.根据预测信息, 进一步分析、构建用户画像.</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 系统流程图" src="Detail/GetImg?filename=images/MSSB201908002_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 系统流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_080.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Flow chart of system</p>

                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>2.1</b> 特征表示</h4>
                <div class="p1">
                    <p id="82">为了构造段落向量, 需要将用户的搜索词列表构造成一个个段落并加上段落ID, 同时使用文档转换成向量 (Doc2Vec) 模型<citation id="167" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>中分布式记忆 (Distri-buted Memory, DM) 和分布式词袋 (Distributed Bag of Words, DBOW) 两种不同子类型模型进行训练, 保证构建特征中信息的完整性.而训练过程中需要段落列表, 为此建立一个读取并逐条返回段落的类Doc_list.类Doc_list初始化接收一个文档描述符<i>f</i>, 每当被调用时按照段落文本内容的格式, 提取段落ID和段落内容并返回.本文使用gensim.models中的Doc2Vec模块获取段落模型, 将构造的Doc_list类使用保存的段落文本实例化并当作参数传入Doc2Vec, 保存训练好的模型, 以便在后续的模型训练中直接提取段落向量.</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>2.2</b> 子模型设计</h4>
                <div class="p1">
                    <p id="84">本文在Stacking第一层应用3种子模型, 分别是TFIDF-LR、DM-BPNN和DBOW-BPNN, 避免只使用一种模型带来的学习效果不佳的问题, 第二层采用XGBoost预测最终结果.</p>
                </div>
                <div class="p1">
                    <p id="85">TFIDF-LR.此子模型以用户搜索记录分词结果的TF-IDF值为输入<citation id="168" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>, LR为训练模型进行数据的学习.该子模型在3个任务上分别进行训练.</p>
                </div>
                <div class="p1">
                    <p id="86">DM-BPNN.此子模型首先提取在DM模式下训练完成的Doc2Vec模型, 可以直接获取用户搜索记录对应的向量表示, 并作为输入送入一个反向传播神经网络 (Back Propagation Neural Network, BPNN) .BPNN共有4层, 分别为Dropout层、Tanh层、全连接层 (输出层) 和Softmax层.Softmax层将每个任务的预测结果在每一类别上以概率形式输出, 这样在最后选取结果时只需寻找概率值最大的类别.BPNN的结构如图3所示.</p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 BPNN结构" src="Detail/GetImg?filename=images/MSSB201908002_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 BPNN结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Structure of BPNN</p>

                </div>
                <div class="p1">
                    <p id="88">在BPNN中, 输入是从Doc2Vec模型中直接提取向量维度为300的向量组, 为了防止网络在训练集上过拟合, Dropout层设定一个值, 对网络中的参数按一定的概率将其暂时从网络中丢弃.对于随机梯度下降, 由于是随机丢弃, 所以每个批次 (Batch) 都是在训练不同的网络.激活函数选择Tanh, 后面一层是一个全连接层, 输出个数是类别数目.为了便于预测结果, 使用Softmax将每个数据属于某一类别的概率进行输出.</p>
                </div>
                <div class="p1">
                    <p id="89">DBOW-BPNN.此子模型与DM-BPNN相似, 只是输入改为DBOW模式下训练完成的Doc2Vec模型对应的向量表示.BPNN的结构如图3所示, 由于输入的向量来自不同的模型, 因此BPNN的参数与DM模式下的BPNN中的网络参数存在一定差异.</p>
                </div>
                <h3 id="90" name="90" class="anchor-tag">3 实验及结果分析</h3>
                <h4 class="anchor-tag" id="91" name="91"><b>3.1</b> 实验数据</h4>
                <div class="p1">
                    <p id="92">实验数据来源于2016CCF (China Computer Federation) 大数据精准营销中搜狗用户画像挖掘竞赛的实验数据, 数据内容是用户一个月内在搜狗搜索引擎上的查询词与用户的人口属性标签, 包括性别、年龄和学历.数据描述如表1所示.</p>
                </div>
                <div class="p1">
                    <p id="93">数据中存在未知数据, 本文使用已有的完整数据, 通过逻辑回归 (Logistic Regression, LR) , 对含有未知值的属性进行预测并填充.</p>
                </div>
                <div class="p1">
                    <p id="94">本文所有实验在Ubuntu 14.04.5系统下使用Python (3.4.3) 完成, PC电脑配置为64 GB的RAM, CPU为Intel (R) Core (TM) i7-6800K CPU @ 3.40 GHz.</p>
                </div>
                <div class="area_img" id="95">
                    <p class="img_tit"><b>表1 数据字段说明</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Description of data</p>
                    <p class="img_note"></p>
                    <table id="95" border="1"><tr><td><br />字段</td><td>说明</td></tr><tr><td><br />ID</td><td>加密后的ID</td></tr><tr><td><br />年龄</td><td>0:未知年龄; 1:0～18岁; 2:19～23岁; <br />3:24～30岁; 4:31～40岁; 5:41～50岁; <br />6:51～</td></tr><tr><td><br />性别</td><td>0:未知; 1:男性; 2:女性</td></tr><tr><td><br />学历</td><td>0:未知学历; 1:博士; 2:硕士; 3:大学生; <br />4:高中; 5:初中; 6:小学</td></tr><tr><td><br />QueryList</td><td>搜索词列表</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>3.2</b> 模型训练结果</h4>
                <div class="p1">
                    <p id="97">3个子模型TFIDF-LR、DM-BPNN、DBOW-BPNN及多粒度融合模型在学历、年龄和性别预测任务上的准确率如表2所示.在2016大数据精准营销的搜狗用户画像挖掘竞赛中, 评测标准是3个任务准确率的平均值.在复赛A榜的前三名得分分别为0.728 00、0.725 53、0.718 48;B榜的前三名得分分别为0.727 65、0.724 96、0.718 79.由此可知, 本文的多粒度融合模型在两个榜单均排名第三.</p>
                </div>
                <div class="area_img" id="98">
                    <p class="img_tit"><b>表2 各模型在3个任务上的准确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Accuracy of models on 3 tasks</p>
                    <p class="img_note"></p>
                    <table id="98" border="1"><tr><td>模型</td><td>学历</td><td>年龄</td><td>性别</td><td>平均值</td></tr><tr><td><br />子模型<br />TFIDF-LR</td><td>0.67024</td><td>0.60242</td><td>0.83605</td><td>0.70290</td></tr><tr><td><br />子模型<br />DM-BPNN</td><td>0.63484</td><td>0.59544</td><td>0.82860</td><td>0.68629</td></tr><tr><td><br />子模型<br />DBOW-BPNN</td><td>0.65429</td><td>0.62570</td><td>0.83830</td><td>0.70600</td></tr><tr><td><br />多粒度融合</td><td><b>0.67867</b></td><td><b>0.63060</b></td><td><b>0.85240</b></td><td><b>0.72056</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="99">若只考虑单个模型的表现, TFIDF-LR在学历任务上的表现最优, DBOW-BPNN在年龄和性别任务上表现优于TFIDF-LR.</p>
                </div>
                <div class="p1">
                    <p id="100">而多粒度的融合模型在3个任务上效果都优于子模型, 这正是本文使用多粒度Stacking融合模型的原因, 可以融合各个模型表现最优的方面, 大幅提升模型效果.</p>
                </div>
                <div class="p1">
                    <p id="101">在任务方面, 学历的预测准确率 (各个模型最优准确率) 普遍在0.63～0.67, 年龄的准确率在0.59～0.63, 而性别的准确率达到0.82～0.85, 这是因为性别预测是一个二分类问题, 而学历和年龄都含有六类, 所以性别的预测准确率高于另外两项任务.</p>
                </div>
                <h4 class="anchor-tag" id="102" name="102"><b>3.3</b> 聚类及可视化</h4>
                <div class="p1">
                    <p id="103">通过XGBoost对无标记的测试集进行预测, 预测结果保留用户ID, 便于查找对应用户, 3个任务的预测结果按年龄、性别、学历放在同行的用户ID之后, 即一行表示一个用户的预测结果.</p>
                </div>
                <div class="p1">
                    <p id="104">为了便于分析用户的类别 (社会属性) , 对预测结果进行聚类.聚类方法采用简单实用的<i>K</i>-means, 聚类数目<i>K</i>在多次实验后确定为4.</p>
                </div>
                <div class="p1">
                    <p id="105">在实验中, 性别对于聚类结果影响尤为特别, 若将性别信息参与聚类, 会出现另外两个属性几乎完全一致, 只是性别不同的情况, 因此, 文本刚开始聚类时放弃使用性别参与聚类.但是, 在后续提取类别搜索关键词时发现, 女性和男性即使社会属性一样, 在搜索关键词的方面也有一定的差别, 因此后续分析时将分析两种聚类情况, 即有无性别信息参与聚类的聚类结果.</p>
                </div>
                <div class="p1">
                    <p id="106">为了进一步展现不同类别人的搜索兴趣的不同, 本文制作搜索高频词词云, 并对词云中词汇结果去除停用词、标点等无意义词汇.</p>
                </div>
                <h4 class="anchor-tag" id="107" name="107"><b>3.4</b> 可视化结果分析</h4>
                <div class="p1">
                    <p id="108">首先规定表示范围的词汇的包含百分比.</p>
                </div>
                <div class="p1">
                    <p id="109">1) &gt;95%:几乎全部;</p>
                </div>
                <div class="p1">
                    <p id="111">2) 75%～95%:绝大部分;</p>
                </div>
                <div class="p1">
                    <p id="113">3) 55%～75%:大部分.</p>
                </div>
                <div class="p1">
                    <p id="115">当性别不参与聚类时, 结果将用户分成4类, 具体如图4所示.</p>
                </div>
                <div class="p1">
                    <p id="116">由图4 (a) 可知, 本科学历和高中学历几乎占了全部比重, 大学学历稍多, 年龄几乎全部介于24～30岁之间, 可以推断是毕业有一定时间的具有较高学历的工作人员.从高频词来看, “怀孕”、“孕妇”、“宝宝”等关键词占据榜首, 说明这类用户中含有许多准父母或刚成为父母的人.</p>
                </div>
                <div class="p1">
                    <p id="117">由 (b) 可知, 此类用户绝大部分为初中学历, 且年龄在18岁以下.从高频词来看, 多为游戏和娱乐社交等词汇, 因此可以判定为在校学生, 此类用户多喜爱网络社交和游戏.</p>
                </div>
                <div class="p1">
                    <p id="118"> (c) 表示的类别3中用户绝大部分是高中学历, 年龄绝大部分在19～23之间.高频词展示这类人群喜好电视剧、电影等娱乐活动, 同时也对招聘等有兴趣, 说明这是一群高中毕业后选择直接工作的青年人.</p>
                </div>
                <div class="p1">
                    <p id="119"> (d) 表示的类别4中用户绝大部分具有本科学历, 且年龄大都在31～40岁之间, 说明这是具有高学历的工龄较长的一类人.从高频词汇“做法”、“功效”、“价格”、“症状”等来看, 这群人更关注的是生活日常, 不难推测这是一群非常注重现实且受到过良好教育的中青年工作人群.</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 性别不参与时聚类结果及高频词词云" src="Detail/GetImg?filename=images/MSSB201908002_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 性别不参与时聚类结果及高频词词云  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_12900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Clustering result with gender excluded and word cloud of frequent words</p>
                                <p class="img_note"> (d) 类别4 (d) Category 4</p>

                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_12901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 性别不参与时聚类结果及高频词词云" src="Detail/GetImg?filename=images/MSSB201908002_12901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 性别不参与时聚类结果及高频词词云  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_12901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Clustering result with gender excluded and word cloud of frequent words</p>
                                <p class="img_note"> (d) 类别4 (d) Category 4</p>

                </div>
                <div class="p1">
                    <p id="131">性别参与聚类时主要分析性别对于高频词的影响.此时设定聚类数目<i>k</i>=5, 具体结果如图5所示.</p>
                </div>
                <div class="p1">
                    <p id="132">由图5 (a) 、 (b) 可知, 这两类用户预测都为女性.从高频词来看, 主要是在电视剧、小说等方面.从学历和年龄来看, 低年龄和低学历的一类 ( (b) 可以判定为学生) 有属于本类特色的搜索词, 如“作文”、“英语”等.</p>
                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 性别参与时聚类结果及高频词词云" src="Detail/GetImg?filename=images/MSSB201908002_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 性别参与时聚类结果及高频词词云  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_14500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Clustering result with gender included and word cloud of frequent words</p>
                                <p class="img_note"> (e) 类别5 (e) Category 5</p>

                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_14501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 性别参与时聚类结果及高频词词云" src="Detail/GetImg?filename=images/MSSB201908002_14501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 性别参与时聚类结果及高频词词云  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_14501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Clustering result with gender included and word cloud of frequent words</p>
                                <p class="img_note"> (e) 类别5 (e) Category 5</p>

                </div>
                <div class="area_img" id="145">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201908002_14502.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 性别参与时聚类结果及高频词词云" src="Detail/GetImg?filename=images/MSSB201908002_14502.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 性别参与时聚类结果及高频词词云  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201908002_14502.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Clustering result with gender included and word cloud of frequent words</p>
                                <p class="img_note"> (e) 类别5 (e) Category 5</p>

                </div>
                <div class="p1">
                    <p id="147">另一方面, 如图5 (c) 、 (d) 所示, 这两类用户预测都为男性.在年龄和学历的分类上, 类别1和类别4较相似, 而类别2和类别3较相似, 可知这两对除了性别完全不同以外, 其余属性分布范围都十分接近.从高频词汇来看, 图5 (c) 、 (d) 所示的男生的搜索高频词多为各类游戏、社交软件、手机、汽车等, 与女性的高频词汇类型差距明显.</p>
                </div>
                <div class="p1">
                    <p id="148"> (e) 中男性与女性用户的比例几乎相同, 搜索高频词未呈现明显的男性或女性倾向.92.96%的本科学历说明这一类人受教育程度普遍较高.再从年龄分析可以看出几乎全部是24～40岁的中青年.</p>
                </div>
                <h3 id="149" name="149" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="150">本文提出基于粒计算的多粒度用户画像分析模型.实验以用户在搜索引擎的搜索记录和用户人口属性 (年龄、性别和学历) 作为数据, 采用多种特征表示技术建立多个子模型, 并使用Stacking融合多种子模型, 在多粒度层次上对数据进行进一步处理, 使模型可以学习更全面、完整的用户画像特征.最后将预测结果聚类, 提取类别高频关键词制作词云, 便于观察和分析.实验表明, 相比单一粒度的用户画像, 多粒度的用户画像更全面、立体、丰富.</p>
                </div>
                <div class="p1">
                    <p id="151">未来一方面考虑更多的用户属性, 不仅仅局限于本文的静态属性 (年龄、性别、学历) , 动态属性, 如用户点击某网站频率等动态行为特征, 更能反映用户真实的画像.另一方面, 使用深度更大、结构更复杂的神经网络代替普通的反向传播神经网络也是进一步研究方向.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="173" type="formula" href="images/MSSB201908002_17300.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">蒋明会</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="174" type="formula" href="images/MSSB201908002_17400.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">苗夺谦</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="175" type="formula" href="images/MSSB201908002_17500.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">罗晟</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="176" type="formula" href="images/MSSB201908002_17600.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">赵才荣</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Modeling of user portrait through social media">

                                <b>[1]</b> GU H Q, WANG J, WANG Z W, <i>et al</i>.Modeling of User Portrait through Social Media // Proc of the IEEE International Conference on Multimedia and Expo.Washington, USA:IEEE, 2018.DOI:10.1109/ICME.2018.8486595.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TSSS201720003&amp;v=MjUyNTJGeS9rVXI3SU1UN1lmYkc0SDliT3I0OUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 陈慧香, 邵波.国外图书馆领域用户画像的研究现状及启示.图书馆学研究, 2017 (20) :16-20. (CHEN H X, SHAO B.The Research Status and Enlightenment of the User Profile in the Library Fields at Abroad.Research on Library Science, 2017 (20) :16-20.) 
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=User Profiles for Personalized Information Access">

                                <b>[3]</b> GAUCH S, SPERETTA M, CHANDRAMOULI A, <i>et al</i>.User Profiles for Personalized Information Access // BRUSILOVSKY D, KOBSA A, NEJDL W, eds.The Adaptive Web, Methods and Stra-tegies of Web Personalization.Berlin, Germany:Springer, 2007:54-89.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SPQD&amp;filename=SPQD00000622205&amp;v=MDE3MDZIN1I3cWVidWR0RkNIbFZMN0pJVjQ9TmozYWFyTzRIdEhNcVkxSFp1c0tZM2s1ekJkaDRqOTlTWHFScnhveGNN&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> TEIXEIRA C, PINTO J S, MARTINS J A.User Profiles in Organizational Environments.Campus-Wide Information Systems, 2008, 25 (3) :128-144.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Hybrid User Model for News Story Classification">

                                <b>[5]</b> BILLSUS D, PAZZANO M J.A Hybrid User Model for News Story Classification // Proc of the 7th International Conference on User Modeling.Berlin, Germany:Springer, 1999:99-108.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012100870863&amp;v=MTAyMDJmT2ZiSzdIdERPcm85RmJPd1BCSG82b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSjE4VmF4ST1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> LAINÉ-CRUZEL S, LAFOUGE T, LARDY J P, <i>et al</i>.Improving Information Retrieval by Combining User Profile and Document Segmentation.Information Processing and Management, 1996, 32 (3) :305-315.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016097276.nh&amp;v=MDkzMzMzenFxQnRHRnJDVVJMT2VaZVJuRnkva1VyN0lWRjI2R0xPeEdkUExxWkViUElRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 李映坤.大数据背景下用户画像的统计方法实践研究.硕士学位论文.北京:首都经济贸易大学, 2016. (LI Y K.Practical Research on Statistical Methods of User Portraits in the Background of Big Data.Master Dissertation.Beijing, China:Capital University of Economics and Business, 2016.) 
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YDTX201622008&amp;v=MTM5MDVMT2VaZVJuRnkva1VyN0lQQ25mZHJHNEg5Zk9yWTlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 张小可, 沈文明, 杜翠凤.贝叶斯网络在用户画像构建中的研究.移动通信, 2016, 40 (22) :22-26. (ZHANG X K, SHEN W M, DU C F.Research on Bayesian Network in User Portrait Construction.Mobile Communications, 2016, 40 (22) :22-26.) 
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015908693.nh&amp;v=MTI1ODdlWmVSbkZ5L2tVcjdJVkYyNkc3cTRGdGZGckpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 张哲.基于微博数据的用户画像系统的设计与实现.硕士学位论文.武汉:华中科技大学, 2015. (ZHANG Z.Design and Implementation of User Portrait System Based on Microblog Data.Master Dissertation.Wuhan, China:Huazhong University of Science and Technology, 2015.) 
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=LSGL201706023&amp;v=MDY0MDBGckNVUkxPZVplUm5GeS9rVXI3SUtUN01Zckc0SDliTXFZOUhaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 刘速.浅议数字图书馆知识发现系统中的用户画像——以天津图书馆为例.图书馆理论与实践, 2017 (6) :103-106. (LIU S.The Persona in Digital Library Knowledge Discovery System-Taking Tianjin Library as an Example.Library Theory and Practice, 2017 (6) :103-106.) 
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 高玉龙.基于文本挖掘的用户画像研究.硕士学位论文.汕头:汕头大学, 2014. (GAO Y L.Users Portrait Research Based on Text Mining.Master Dissertation.Shantou, China:Shantou University, 2014.) 
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XDJS201624004&amp;v=MjMzNjY0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5L2tVcjdJUFNuQmZiRzRIOWZPcTQ5RllJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 李冰, 王悦, 刘永祥.大数据环境下基于<i>K</i>-means的用户画像与智能推荐的应用.现代计算机, 2016 (24) :11-15. (LI B, WANG Y, LIU Y X.Application of User Portrait and Intelligent Recommendation Based on Big Data Technology and <i>K</i>-means.Modern Computer, 2016 (24) :11-15.) 
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adaptive Web Search Based on User Profile Constructed without Any Effort from Users">

                                <b>[13]</b> SUGIYAMA K, HATANO K, YOSHIKAWA M.Adaptive Web Search Based on User Profile Constructed without any Effort from Users[C/OL].[2019-05-25].https://www.iw3c2.org/WWW2004/docs/1p675.pdf.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES0D74FD250B0A46ACFE8F228CBF7B2096&amp;v=MjQxNTFaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtK3dhZz1OaWZPZmJQTUdkVzYyNDFBWkprUGZYZy92bVZsbnpjTFNuM3EzMkJEZnNDV1JiTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> ZHAO C R, WANG X K, MIAO D Q, <i>et al</i>.Maximal Granularity Structure and Generalized Multi-view Discriminant Analysis for Person Re-identification.Pattern Recognition, 2018, 79:79-96.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interpreting concept learning in cognitive informatics and granular computing">

                                <b>[15]</b> YAO Y Y.Interpreting Concept Learning in Cognitive Informatics and Granular Computing.IEEE Transactions on Systems, Man, and Cybernetics (Cybernetics) , 2009, 39 (4) :855-866.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Empirical Evaluation of Doc2Vec with Practical Insights into Document Embedding Generation">

                                <b>[16]</b> LAU J H, BALDWIN T.An Empirical Evaluation of Doc2Vec with Practical Insights into Document Embedding Generation // Proc of the 1st Workshop on Representation Learning for NLP.Stroudsburg, USA:ACL, 2016:78-86.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using TF-IDF to determine Word relevance in document queries">

                                <b>[17]</b> RAMOS J.Using TF-IDF to Determine Word Relevance in Document Queries // Proc of the 1st Instructional Conference on Machine Learning.Berlin, Germany:Springer, 2003.DOI:10.15804/tner.2015.42.4.03.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201908002" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201908002&amp;v=MDM3NzBSbkZ5L2tVcjdJS0Q3WWJMRzRIOWpNcDQ5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
