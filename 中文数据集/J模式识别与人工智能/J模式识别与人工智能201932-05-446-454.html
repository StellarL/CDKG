<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131448612373750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201905008%26RESULT%3d1%26SIGN%3dn1ldhznurw0VAlMPfCfmrd7PouI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201905008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201905008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201905008&amp;v=MDU5NjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1ZicklLRDdZYkxHNEg5ak1xbzlGYklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#64" data-title="1 基于Wasserstein距离的分层注意力跨域情感分类模型 ">1 基于Wasserstein距离的分层注意力跨域情感分类模型</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#81" data-title="2 分层注意力网络提取领域共享特征 ">2 分层注意力网络提取领域共享特征</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#84" data-title="&lt;b&gt;2.1 分层结构提取特征&lt;/b&gt;"><b>2.1 分层结构提取特征</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;2.2 不同层级的注意力机制&lt;/b&gt;"><b>2.2 不同层级的注意力机制</b></a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;2.3 基于&lt;/b&gt;&lt;b&gt;Wasserstein&lt;/b&gt;&lt;b&gt;距离减少域差异&lt;/b&gt;"><b>2.3 基于</b><b>Wasserstein</b><b>距离减少域差异</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#130" data-title="3 领域独有特征提取与跨域情感分类 ">3 领域独有特征提取与跨域情感分类</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#131" data-title="&lt;b&gt;3.1 辅助任务获取领域独有特征&lt;/b&gt;"><b>3.1 辅助任务获取领域独有特征</b></a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;3.2 结合领域独有特征实现情感分类&lt;/b&gt;"><b>3.2 结合领域独有特征实现情感分类</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#197" data-title="4 实验及结果分析 ">4 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#229" data-title="5 结 束 语 ">5 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#77" data-title="图1 基于Wasserstein距离的分层注意力情感分类模型">图1 基于Wasserstein距离的分层注意力情感分类模型</a></li>
                                                <li><a href="#83" data-title="图2 基于Wasserstein距离提取领域共享特征模型">图2 基于Wasserstein距离提取领域共享特征模型</a></li>
                                                <li><a href="#211" data-title="&lt;b&gt;表1 不同方法在Amazon数据集上的跨域情感分类正确率&lt;/b&gt;"><b>表1 不同方法在Amazon数据集上的跨域情感分类正确率</b></a></li>
                                                <li><a href="#212" data-title="&lt;b&gt;表2 不同方法在Amazon与UMICH数据集上的跨域情 感分类正确率&lt;/b&gt;"><b>表2 不同方法在Amazon与UMICH数据集上的跨域情 感分类正确率</b></a></li>
                                                <li><a href="#225" data-title="图3 5种方法在Amazon数据集上正确率对比">图3 5种方法在Amazon数据集上正确率对比</a></li>
                                                <li><a href="#227" data-title="图4 子句级Attention变化样例">图4 子句级Attention变化样例</a></li>
                                                <li><a href="#228" data-title="图5 单词级Attention变化样例">图5 单词级Attention变化样例</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 赵传君, 王素格, 李德玉, 等.基于分组提升集成的跨领域文本情感分类.计算机研究与发展, 2015, 52 (3) :629-638. (ZHAO C J, WANG S G, LI D Y, &lt;i&gt;et al&lt;/i&gt;.Cross-Domain Text Sentiment Classification Based on Grouping-AdaBoost Ensemble.Journal of Computer Research and Development, 2015, 52 (3) :629-638.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201503011&amp;v=MzAzMzh0R0ZyQ1VSTE9lWmVSbkZ5emdWYnJJTHl2U2RMRzRIOVRNckk5RVpZUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         赵传君, 王素格, 李德玉, 等.基于分组提升集成的跨领域文本情感分类.计算机研究与发展, 2015, 52 (3) :629-638. (ZHAO C J, WANG S G, LI D Y, &lt;i&gt;et al&lt;/i&gt;.Cross-Domain Text Sentiment Classification Based on Grouping-AdaBoost Ensemble.Journal of Computer Research and Development, 2015, 52 (3) :629-638.) 
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 庄福振, 罗平, 何清, 等.迁移学习研究进展.软件学报, 2015, 26 (1) :26-39. (ZHUANG F Z, LUO P, HE Q, &lt;i&gt;et al&lt;/i&gt;.Survey on Transfer Learning Research.Journal of Software, 2015, 26 (1) :26-39.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201501003&amp;v=MjY1NjFyQ1VSTE9lWmVSbkZ5emdWYnJJTnlmVGJMRzRIOVRNcm85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         庄福振, 罗平, 何清, 等.迁移学习研究进展.软件学报, 2015, 26 (1) :26-39. (ZHUANG F Z, LUO P, HE Q, &lt;i&gt;et al&lt;/i&gt;.Survey on Transfer Learning Research.Journal of Software, 2015, 26 (1) :26-39.) 
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" >
                                        <b>[3]</b>
                                     PAN S J, YANG Q.A Survey on Transfer Learning.IEEE Transactions on Knowledge and Data Engineering, 2010, 22 (10) :1345-1359.</a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 顾鑫, 王士同, 许敏.基于多源的跨领域数据分类快速新算法.自动化学报, 2014, 40 (3) :531-547. (GU X, WANG S T, XU M.A New Cross-multidomain Classification Algorithm and Its Fast Version for Large Datasets.Acta Automatica Sinica, 2014, 40 (3) :531-547.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201403017&amp;v=MDI5MjNVUkxPZVplUm5GeXpnVmJySUtDTGZZYkc0SDlYTXJJOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         顾鑫, 王士同, 许敏.基于多源的跨领域数据分类快速新算法.自动化学报, 2014, 40 (3) :531-547. (GU X, WANG S T, XU M.A New Cross-multidomain Classification Algorithm and Its Fast Version for Large Datasets.Acta Automatica Sinica, 2014, 40 (3) :531-547.) 
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" >
                                        <b>[5]</b>
                                     BLITZER J, DREDZE M, PEREIA F.Biographies, Bollywood, Boom-Boxes and Blenders:Domain Adaption for Sentiment Classification // Proc of the 45th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2007:440-447.</a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" >
                                        <b>[6]</b>
                                     PAN S J, NI X C, SUN J T, &lt;i&gt;et al&lt;/i&gt;.Cross-Domain Sentiment Classification via Spectral Feature Alignment // Proc of the 19th International Conference on World Wide Web.New York, USA:ACM, 2010:751-760.</a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" >
                                        <b>[7]</b>
                                     SHARMA R, BHATTACHARYYA P, DANDAPAT S, &lt;i&gt;et al&lt;/i&gt;.Identifying Transferable Information across Domains for Cross-Domain Sentiment Classification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:968-978.</a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" >
                                        <b>[8]</b>
                                     WU F Z, HUANG Y F, YAN J.Active Sentiment Domain Adaptation // Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017:1701-1711.</a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     GLOROT X, BORDES A, BENGIO Y.Domain Adaptation for Large-Scale Sentiment Classification:A Deep Learning Approach // Proc of the 28th International Conference on Machine Learning.Madison, USA:Omnipress, 2011:513-520.</a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" >
                                        <b>[10]</b>
                                     CHEN M M, XU Z X, WEINBERGER K, &lt;i&gt;et al&lt;/i&gt;.Marginalized Denoising Autoencoders for Domain Adaptation // Proc of the 29th International Conference on Machine Learning.Berlin, Germany:Springer, 2012:767-774.</a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" >
                                        <b>[11]</b>
                                     ZISER Y, REICHART R.Neural Structural Correspondence Lear-ning for Domain Adaptation // Proc of the 21st Conference on Computational Natural Language Learning.Stroudsburg, USA:ACL, 2017:400-410.</a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" >
                                        <b>[12]</b>
                                     ZISER Y, REICHART R.Pivot Based Language Modeling for Improved Neural Domain Adaption // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technologies.Stroudsburg, USA:ACL, 2018:1241-1251.</a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                     CUI X, AL-BAZZAZ N, BOLLEGALA D, &lt;i&gt;et al&lt;/i&gt;.A Comparative Study of Pivot Selection Strategies for Unsupervised Cross-Domain Sentiment Classification.The Knowledge Engineering Review, 2018, 33.DOI:10.1017/S0269888918000085.</a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" >
                                        <b>[14]</b>
                                     GANIN Y, USTINOVA E, AJAKAN H, &lt;i&gt;et al&lt;/i&gt;.Domain-Adversarial Training of Neural Networks.Journal of Machine Learning Research, 2015, 17:2096-2030.</a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" >
                                        <b>[15]</b>
                                     YU J F, JIANG J.Leveraging Auxiliary Tasks for Document-Level Cross-Domain Sentiment Classification // Proc of the 8th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL, 2017:654-663.</a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" >
                                        <b>[16]</b>
                                     LI Z, ZHANG Y, WEI Y, &lt;i&gt;et al&lt;/i&gt;.End-to-End Adversarial Memory Network for Cross-Domain Sentiment Classification // Proc of the 26th International Joint Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2017:2237-2243.</a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     LI Z, WEI Y, ZHANG Y, &lt;i&gt;et al&lt;/i&gt;.Hierarchical Attention Transfer Network for Cross-Domain Sentiment Classification[C/OL].[2018-11-15].https://www.cse.ust.hk/～yuzhangcse/papers/Li_Wei_Zhang_Yang_AAAI18.pdf.</a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" >
                                        <b>[18]</b>
                                     TANG D Y, QIN B, LIU T.Document Modeling with Gated Recurrent Neural Network for Sentiment Classification // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2015:1422-1432.</a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" >
                                        <b>[19]</b>
                                     ZHOU P, SHI W, TIAN J, &lt;i&gt;et al&lt;/i&gt;.Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification // Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2016:207-212.</a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" >
                                        <b>[20]</b>
                                     VASWANI A, SHAZEER N, PARMAR N, &lt;i&gt;et al&lt;/i&gt;.Attention Is All You Need[C/OL].[2018-11-15].https://arxiv.org/pdf/1706.03762.pdf.</a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" >
                                        <b>[21]</b>
                                     MARTIN A, CHINTALA S, BOTTOU L.Wasserstein Gan[C/OL].[2018-11-15].https://arxiv.org/pdf/ 1701.07875.pdf.</a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" >
                                        <b>[22]</b>
                                     GULRAJANI I, AHMED F, ARJOVSKY M, &lt;i&gt;et al&lt;/i&gt;.Improved Training of Wasserstein GANs[C/OL].[2018-11-15].https://arxiv.org/pdf/1704.00028.pdf.</a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" >
                                        <b>[23]</b>
                                     YU J F, JIANG J.Learning Sentence Embeddings with Auxiliary Tasks for Cross-Domain Sentiment Classification // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2016:236-246.</a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(05),446-454 DOI:10.16451/j.cnki.issn1003-6059.201905007            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于Wasserstein距离分层注意力模型的跨域情感分类</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%9C%E6%B0%B8%E8%90%8D&amp;code=14336680&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杜永萍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BA%E8%90%8C&amp;code=39376582&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贺萌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E6%99%93%E9%93%AE&amp;code=37906620&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵晓铮</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%83%A8&amp;code=0034856&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京工业大学信息学部</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>跨领域情感分类任务旨在利用已知情感标签的源域数据对缺乏标记数据的目标域进行情感倾向性分析.文中提出基于Wasserstein距离的分层注意力模型, 结合Attention机制, 采用分层模型进行特征提取, 将Wasserstein距离作为域差异度量方式, 通过对抗式训练自动捕获领域共享特征.进一步构造辅助任务捕获与共享特征共现的领域独有特征, 结合两种特征表示完成跨域情感分类任务.在亚马逊评论等数据集上的实验表明, 文中模型仅利用领域共享特征就达到较高的正确率, 在不同的跨领域对之间具有较好的稳定性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B7%A8%E9%A2%86%E5%9F%9F%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">跨领域情感分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Wasserstein%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Wasserstein距离;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E5%B1%82%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分层模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">注意力机制;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E5%90%91%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双向门控循环单元;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    *杜永萍 (通讯作者) , 博士, 副教授, 主要研究方向为信息检索、信息提取、自然语言处理.E-mail:ypdu@bjut.edu.cn.;
                                </span>
                                <span>
                                    贺萌, 硕士研究生, 主要研究方向为自然语言处理、情感分析.E-mail:hemeng199412@163.com.;
                                </span>
                                <span>
                                    赵晓铮, 硕士研究生, 主要研究方向为自然语言处理、情感分析.E-mail:zxz53000@163.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-03</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (No.2018YFC1900800);</span>
                                <span>国家语委信息化项目 (No.YB135-89) 资助;</span>
                    </p>
            </div>
                    <h1><b>Wasserstein Distance Based Hierarchical Attention Model for Cross-Domain Sentiment Classification</b></h1>
                    <h2>
                    <span>DU Yongping</span>
                    <span>HE Meng</span>
                    <span>ZHAO Xiaozheng</span>
            </h2>
                    <h2>
                    <span>Faculty of Information, Beijing University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The task of cross-domain sentiment classification is to analyze the sentiment orientation of the target domain lacking labeled data using the source-domain data with sentiment labels. A hierarchical attention model based on Wasserstein distance is proposed in this paper. The hierarchical model is used for feature extraction by combining attention mechanism, and Wasserstein distance is used as the domain difference metric to automatically capture the domain-sharing features through adversarial training. Further auxiliary task is constructed to capture the domain-special features cooccurring with domain-sharing features. These two kinds of features are united to complete the cross-domain sentiment classification task. The experimental results on Amazon datasets demonstrate that the proposed model achieves a higher accuracy and a better stability on different cross-domain pairs.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Cross-Domain%20Sentiment%20Classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Cross-Domain Sentiment Classification;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Wasserstein%20Distance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Wasserstein Distance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Hierarchical%20Model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Hierarchical Model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Attention%20Mechanism&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Attention Mechanism;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bidirectional%20Gated%20Recurrent%20Unit&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bidirectional Gated Recurrent Unit;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    DU Yongping ( Corresponding author ) , Ph.D. , associate professor. Her research interests include information retrieval, information extraction and natural language processing.;
                                </span>
                                <span>
                                    HE Meng, master student. Her research interests include natural language processing and sentiment analysis.;
                                </span>
                                <span>
                                    ZHAO Xiaozheng, master student. Her research interests include natural language processing and sentiment analysis.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-12-03</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Key R&amp;D Program of China (No.2018YF C1900800);</span>
                                <span>Research Program of State Language Commission (No.YB135-89);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="59">情感分类是自然语言处理中的一项重要任务, 其目的是对网络上的文本意见及评论进行情感极性的划分.由于不同的领域有不同的情感表达方式, 情感分类也是一项领域相关的任务.传统的情感分类方法需要充分的带标签的训练数据, 要求训练集和测试集同分布<citation id="231" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.在实际应用中, 新出现的领域通常会出现标注数据稀少的问题, 跨 领 域 情 感分类任务通过充分利用已有领域标注好的大量数据, 使用算法将其迁移到标注数据稀少的新领域<citation id="232" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>, 完成对新领域的情感分类.</p>
                </div>
                <div class="p1">
                    <p id="61">目前, 跨领域情感分类已成为研究热点.Blitzer等<citation id="233" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出结构对应学习方法 (Structural Correspon-dence Learning, SCL) , 通过选择在源域和目标域频繁共现的领域共享特征 (Pivots) 集合, 由共现关系计算权重矩阵, 利用奇异值分解构造低维特征空间训练分类器.Pan等<citation id="234" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出谱特征对齐方法 (Spectral Feature Alignment, SFA) , 对齐pivots与领域独有特征 (Non-pivots) , 在源域和目标域之间建立关联.Sharma等<citation id="235" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出基于卡方检验和词上下文向量间的余弦相似度, 用于识别领域间的重要的一致性极性词 (Significant Consistent Polarity, SCP) , 在对SCP训练的分类器的基础上得到目标域的分类器.Wu等<citation id="236" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>在主动学习模式中选择和标注少量样本, 并从未标记的目标域样本中挖掘单词之间的特定领域情感相似性, 训练目标域的情感分类器.虽然上述方法效果较好, 但都需要大量的人工干预.</p>
                </div>
                <div class="p1">
                    <p id="62">最近, 深度神经网络模型广泛应用于跨域情感分类的特征表示.Glorot等<citation id="237" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出堆叠去噪自动编码器 (Stacked Denoising Autoencoders, SDA) , 可自动学习源域和目标域数据的统一特征表示.与此相似, Chen等<citation id="238" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出边缘化堆叠去噪自动编码器, 在处理数据的速度和可扩展性方面改进SDA.Ziser等<citation id="239" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>结合SCL和自动编码神经网络, 提出具有相似正则化的自编码结构对应学习 (Autoencoder SCL with Similarity Regularization, AE-SCL-SR) , 大幅提高模型性能.为了充分利用输入文本的结构, Ziser等<citation id="240" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出基于pivots的语言模型 (Pivot Based Language Model, PBLM) , 以结构感知的方式, 结合pivot和神经网络建模进行表示学习, 基于互信息和频率选择pivot的策略, 获得较优性能<citation id="241" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>.随着域适应技术的发展, Ganin等<citation id="242" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出神经网络的领域对抗训练 (Domain Adversarial Training of Neural Networks, DANN) , 通过反转梯度方向生成特征表示, 使域分类器不能区分所属域, 在得到的域共享表示上构建情感分类器.Yu等<citation id="243" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出基于pivots的辅助任务, 合并到分层神经网络模型中学习句子嵌入.为了提高深层模型的可解释性, Li等<citation id="244" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出对抗记忆网络 (Adversarial Memory Network, AMN) , 使用注意力机制和对抗训练自动识别pivots.但AMN只关注词级注意力, 忽略文档的层次结构, 可能无法准确捕获长文档中的pivots.在此基础上, Li等<citation id="245" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>提出分层注意转移网络, 自动捕获pivots和non-pivots, 转移跨域的情感注意力, 但存在梯度消失的潜在问题.</p>
                </div>
                <div class="p1">
                    <p id="63">已有研究方法在跨领域情感分类中取得较好性能, 但仍存在问题, 例如:pivots词的选取需要大量人工干预;使用对抗域适应的方式构建领域分类器以减少领域间的差异, 当领域分类器可以完美区分两个领域的表示时, 将存在梯度消失问题;研究核心仅放在领域共享特征上, 如果两个领域的pivots较少时性能可能下降.为了解决上述问题, 本文提出基于Wasserstein距离的分层注意力网络模型, 实现跨域情感分类.首先通过分层注意力网络对源域和目标域数据进行特征的自动提取, 得到文档级的特征表示.进一步通过估计两个领域特征表示的Wasserstein距离, 以对抗方式最小化Wasserstein距离, 提供更稳定的梯度, 提取更有效的领域共享特征.最后, 构造辅助标签预测任务, 提取领域独有特征, 联合领域共享特征进行训练, 完成跨域情感分类.</p>
                </div>
                <h3 id="64" name="64" class="anchor-tag">1 基于Wasserstein距离的分层注意力跨域情感分类模型</h3>
                <div class="p1">
                    <p id="65">在跨域情感分类中, 假设<i>D</i><sub><i>s</i></sub>表示源域, <i>D</i><sub><i>t</i></sub>表示目标域.在<i>D</i><sub><i>s</i></sub>中包含一组标记数据<i>X</i><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>l</mi></msubsup></mrow></math></mathml>={<i>x</i><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>i</mi></msubsup></mrow></math></mathml>}<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msubsup><mrow></mrow><mi>s</mi><mi>l</mi></msubsup></mrow></msubsup></mrow></math></mathml>和{<i>y</i><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>i</mi></msubsup></mrow></math></mathml>}<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msubsup><mrow></mrow><mi>s</mi><mi>l</mi></msubsup></mrow></msubsup></mrow></math></mathml>, <i>N</i><mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>l</mi></msubsup></mrow></math></mathml>表示源域中标记数据的数量, <i>y</i><sub><i>s</i></sub>表示源域情感类别标签.在<i>D</i><sub><i>t</i></sub>中包含一组未标记的数据<i>X</i><sub><i>t</i></sub>={<i>x</i><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>j</mi></msubsup></mrow></math></mathml>}<mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msubsup></mrow></math></mathml>, <i>N</i><sub><i>t</i></sub>表示目标域中未标记数据的数量.跨领域情感分类的目标是使用源域的标记样本<i>X</i><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>l</mi></msubsup></mrow></math></mathml>训练分类器, 使分类器适应预测目标域中未标记样本<i>X</i><sub><i>t</i></sub>的类别.</p>
                </div>
                <div class="p1">
                    <p id="75">本文提出基于Wasserstein距离的分层注意力跨域情感分类模型, 对于给定的源域和目标域数据, 本文模型能自动捕获领域共享特征和领域独有特征, 实现在仅有源域情感标签时, 使目标域数据的情感分类结果达到最优.</p>
                </div>
                <div class="p1">
                    <p id="76">图1为本文模型框图.图左边用于提取领域共享特征, 即源域和目标域共有的情感特征.将源域标记数据和目标域未标记数据共同作为输入进行特征提取, 采用Wasserstein距离表示层 (Wasserstein Distance Representation Layer, WDRL) 估计两个领域特征表示的Wasserstein距离, 通过最小化Wasserstein距离差异使领域不可分, 提取领域共享特征.</p>
                </div>
                <div class="area_img" id="77">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905008_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于Wasserstein距离的分层注意力情感分类模型" src="Detail/GetImg?filename=images/MSSB201905008_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于Wasserstein距离的分层注意力情感分类模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905008_077.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Wasserstein distance based hierarchical attention model for sentiment classification</p>

                </div>
                <div class="p1">
                    <p id="79">图1右边用于提取领域独有的情感分类特征.隐藏图1左边部分识别的领域共享特征词pivots, 得到新的源域和目标域数据.利用同样结构的特征提取器获取两个域的特征表示, 进行辅助标签预测, 使特征提取器提取到与pivots共现的领域独有特征.</p>
                </div>
                <div class="p1">
                    <p id="80">在整个训练过程中, 首先单独训练图1左边, 模型达到最优后可自动获取领域共享词.由此产生图1右边的输入和辅助标签, 通过联合训练整个网络, 可结合领域共享特征和领域独有特征完成跨域情感分类.</p>
                </div>
                <h3 id="81" name="81" class="anchor-tag">2 分层注意力网络提取领域共享特征</h3>
                <div class="p1">
                    <p id="82">本文采用基于Wasserstein距离的分层注意力模型实现领域共享特征的提取, 模型结构见图2.</p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905008_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于Wasserstein距离提取领域共享特征模型" src="Detail/GetImg?filename=images/MSSB201905008_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于Wasserstein距离提取领域共享特征模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905008_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Pivots extraction model based on Wasserstein distance</p>

                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>2.1 分层结构提取特征</b></h4>
                <div class="p1">
                    <p id="85">本文采用分层结构<citation id="246" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>构建特征提取层, 优于简单的非分层结构.输入文档由子句组成, 每个子句由单词组成, 因此将文档表示分为两个阶段:先由子句的单词表示生成连续子句向量;再输入子句向量组合, 获得文档表示.最后实现文档级别的情感分类.</p>
                </div>
                <div class="p1">
                    <p id="86">假设<i>w</i><sub><i>i</i>, <i>j</i></sub>∈<i>V</i>表示输入文档中第<i>i</i>个子句的第<i>j</i>个单词, <i>V</i>为词汇表.使用<b><i>x</i></b><sub><i>i</i>, <i>j</i></sub>∈<b>R</b><sup><i>l</i></sup>表示单词<i>w</i><sub><i>i</i>, <i>j</i></sub>的<i>l</i>维词嵌入向量.首先通过使用一层的双向门控循环单元 (Bidirectional Gated Recurrent Unit, BiGRU) 获得第<i>i</i>个子句的嵌入向量</p>
                </div>
                <div class="p1">
                    <p id="87"><b><i>z</i></b><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>=<i>BiGRU</i><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>θ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mi>s</mi></msubsup></mrow></math></mathml> (<b><i>h</i></b><sub><i>i</i>-1</sub>, <b><i>x</i></b><sub><i>i</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="90">其中, <b><i>h</i></b><sub><i>i</i>-1</sub>∈<b>R</b><sup><i>q</i></sup>表示第<i>i</i>-1个隐藏层状态, <i>q</i>为隐藏层大小, <i>θ</i><sub>1</sub>表示捕获子句向量的<i>BiGRU</i><sup><i>s</i></sup>中所有参数.</p>
                </div>
                <div class="p1">
                    <p id="91">在得到文档中所有子句的嵌入表示后, 应用单词级的Attention关注子句中的重点单词, 得到最终的子句级表示<b><i>s</i></b>.在此基础上应用一层BiGRU组合句子顺序, 得到文档级表示</p>
                </div>
                <div class="p1">
                    <p id="92"><b><i>z</i></b><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>d</mi></msubsup></mrow></math></mathml>=<i>BiGRU</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>θ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mi>d</mi></msubsup></mrow></math></mathml> (<b><i>h</i></b><sub><i>i</i>-1</sub>, <b><i>s</i></b><sub><i>i</i></sub>) , </p>
                </div>
                <div class="p1">
                    <p id="95">其中<i>θ</i><sub>2</sub>表示捕获文档向量的<i>BiGRU</i><sup><i>d</i></sup>中所有参数.</p>
                </div>
                <div class="p1">
                    <p id="96">对得到的文档级表示向量应用句子级的Attention以关注文档中的重要子句, 得到最终的文档级表示<b><i>d</i></b>.</p>
                </div>
                <h4 class="anchor-tag" id="97" name="97"><b>2.2 不同层级的注意力机制</b></h4>
                <div class="p1">
                    <p id="98">为了更准确地捕获情感分类中的重要特征, 本文对子句级表示应用单词级Attention关注子句中重要单词, 对文档级表示应用子句级Attention关注文档中重要的子句.</p>
                </div>
                <div class="p1">
                    <p id="99">句子中不同单词对语义信息的表达并不相同<citation id="247" type="reference"><link href="39" rel="bibliography" /><link href="41" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>, 本文采用单词级Attention机制, 获取长距离相互依赖的特征, 关注子句中包含重要语义信息的单词.</p>
                </div>
                <div class="p1">
                    <p id="100">为了计算每个单词的自注意力权重, 对经过BiGRU模型得到的子句嵌入向量<b><i>z</i></b><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>, 计算注意力分数</p>
                </div>
                <div class="p1">
                    <p id="102"><b><i>g</i></b><sub><i>i</i></sub>=tanh (<b><i>W</i></b>*<b><i>z</i></b><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>+<b><i>b</i></b>) , </p>
                </div>
                <div class="p1">
                    <p id="104">其中<b><i>W</i>、<i>b</i></b>分别为网络自动学习的权重矩阵、偏移量.</p>
                </div>
                <div class="p1">
                    <p id="105">通过softmax激励函数对注意力分数<b><i>g</i></b><sub><i>i</i></sub>进行归一化, 得</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">a</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">g</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">突出当前子句的<i>n</i>个单词中重要单词的权重.将每个单词的归一化注意力分数<b><i>a</i></b><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>一一作用在对应的BiGRU输出<b><i>z</i></b><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup></mrow></math></mathml>上, 得到子句级表示</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">s</mi><mo>=</mo><mo stretchy="false">{</mo><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mn>1</mn><mi>s</mi></msubsup><mo>, </mo><mo>⋯</mo><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mi>n</mi><mi>s</mi></msubsup><mo stretchy="false">}</mo><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>=</mo><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>*</mo><mi mathvariant="bold-italic">a</mi><msubsup><mrow></mrow><mi>i</mi><mi>s</mi></msubsup><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">采用同样的方法可关注文档中的重点子句.将每个子句的归一化注意力分数<b><i>a</i></b><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>d</mi></msubsup></mrow></math></mathml>作用在对应的BiGRU输出<b><i>z</i></b><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>d</mi></msubsup></mrow></math></mathml>上, 进一步得到最终的文档级表示</p>
                </div>
                <div class="p1">
                    <p id="114" class="code-formula">
                        <mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">d</mi><mo>=</mo><mo stretchy="false">{</mo><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mn>1</mn><mi>d</mi></msubsup><mo>, </mo><mo>⋯</mo><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mi>i</mi><mi>d</mi></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mi>n</mi><mi>d</mi></msubsup><mo stretchy="false">}</mo><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mrow><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">t</mi></mrow><msubsup><mrow></mrow><mi>i</mi><mi>d</mi></msubsup><mo>=</mo><mi mathvariant="bold-italic">z</mi><msubsup><mrow></mrow><mi>i</mi><mi>d</mi></msubsup><mo>*</mo><mi mathvariant="bold-italic">a</mi><msubsup><mrow></mrow><mi>i</mi><mi>d</mi></msubsup><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>2.3 基于</b><b>Wasserstein</b><b>距离减少域差异</b></h4>
                <div class="p1">
                    <p id="116">为了使特征提取器更好地学习到领域共享特征, 采用WDRL估计源域和目标域表示分布的Wasserstein距离, 由距离最小化减少域差异.对于经过特征提取器得到的源域 (或目标域) 文档级表示<b><i>d</i></b><sub><i>s</i></sub> (或<b><i>d</i></b><sub><i>t</i></sub>) , 通过学习函数<i>f</i><sub><i>w</i></sub>将特征表示映射为具有参数<i>θ</i><sub><i>w</i></sub>的实值.源域和目标域表示分布之间的Wasserstein距离计算如下:</p>
                </div>
                <div class="p1">
                    <p id="117" class="code-formula">
                        <mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>d</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub><mo>, </mo><mi>D</mi><msub><mrow></mrow><mrow><mi>d</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>sup</mi></mrow></mstyle><mrow><mrow><mrow><mo>|</mo><mrow><mi>f</mi><msub><mrow></mrow><mi>w</mi></msub></mrow><mo>|</mo></mrow></mrow><msub><mrow></mrow><mspace width="0.25em" /></msub><mi>L</mi><mo>≤</mo><mn>1</mn></mrow></munder><mi>E</mi><msub><mrow></mrow><mrow><mi>D</mi><msub><mrow></mrow><mrow><mi>d</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></msub></mrow></msub><mo stretchy="false">[</mo><mi>f</mi><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>-</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>D</mi><msub><mrow></mrow><mrow><mi>d</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub></mrow></msub><mo stretchy="false">[</mo><mi>f</mi><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="118">如果函数<i>f</i><sub><i>w</i></sub>满足1-Lipschitz条件, 直接通过最大化关于参数<i>θ</i><sub><i>w</i></sub>的损失<i>L</i><sub>wd</sub>近似Wasserstein距离, 损失<i>L</i><sub><i>wd</i></sub>为</p>
                </div>
                <div class="p1">
                    <p id="119" class="code-formula">
                        <mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>w</mtext><mtext>d</mtext></mrow></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>s</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>s</mi></msub><mo>∈</mo><mi>X</mi><msub><mrow></mrow><mi>s</mi></msub></mrow></munder><mi>f</mi></mstyle><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false">) </mo><mo>-</mo><mfrac><mn>1</mn><mrow><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>∈</mo><mi>X</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></munder><mi>f</mi></mstyle><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">d</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="120">执行Lipschitz约束需要每次梯度更新后在[-<i>c</i>, <i>c</i>]范围内裁剪权重<citation id="248" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>, 这可能会导致容量不足和梯度消失或爆炸, 因此对<i>θ</i><sub><i>w</i></sub>强制执行梯度惩罚<i>L</i><sub>grad</sub><citation id="249" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>r</mtext><mtext>a</mtext><mtext>d</mtext></mrow></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">d</mi><mo>^</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false"> (</mo><mrow><mo>|</mo><mrow><mo>∇</mo><msub><mrow></mrow><mover accent="true"><mi>d</mi><mo>^</mo></mover></msub><mspace width="0.25em" /><mi>f</mi><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi mathvariant="bold-italic">d</mi><mo>^</mo></mover><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msub><mrow></mrow><mn>2</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mspace width="0.25em" /><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">其中, 梯度惩罚的特征表示<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold-italic">d</mi><mo>^</mo></mover></math></mathml>为<b><i>d</i></b><sub><i>s</i></sub>、<b><i>d</i></b><sub><i>t</i></sub>及两者之间的随机点<b><i>d</i></b><sub><i>r</i></sub>三者的拼接.</p>
                </div>
                <div class="p1">
                    <p id="124">由于Wasserstein距离几乎都是连续可微, 首先训练WDRL并在达到最优后固定WDRL最优参数, 最小化Wasserstein距离的估计, 使特征提取器网络可以学习具有域共享的特征表示, 即通过解决极大极小问题实现表示的学习:</p>
                </div>
                <div class="p1">
                    <p id="125" class="code-formula">
                        <mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mi>e</mi></msub></mrow></munder><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mo stretchy="false">{</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>w</mtext><mtext>d</mtext></mrow></msub><mo>-</mo><mi>λ</mi><mi>L</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>r</mtext><mtext>a</mtext><mtext>d</mtext></mrow></msub><mo stretchy="false">}</mo><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="126">其中, <i>θ</i><sub><i>e</i></sub>表示特征提取层的参数, <i>λ</i>表示惩罚系数, 在进行最小化操作时应将<i>λ</i>设为0, 此时梯度惩罚不应指导表示的学习过程.</p>
                </div>
                <div class="p1">
                    <p id="127">基于Wasserstein距离减少域差异部分训练结束后, 通过softmax分类器将文档表示<i>d</i>映射到标签<i>y</i>, 实现对情感类别的预测, 情感分类器的损失<i>L</i><sub>sen</sub>采用交叉熵损失函数.结合分类器的损失, 得到最终的目标函数:</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mi>e</mi></msub><mo>, </mo><mi>θ</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub></mrow></munder><mo stretchy="false">{</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>s</mtext><mtext>e</mtext><mtext>n</mtext></mrow></msub><mo>+</mo><mi>β</mi><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mi>w</mi></msub></mrow></munder><mo stretchy="false">[</mo><mi>L</mi><msub><mrow></mrow><mrow><mtext>w</mtext><mtext>d</mtext></mrow></msub><mo>-</mo><mi>γ</mi><mi>L</mi><msub><mrow></mrow><mrow><mtext>g</mtext><mtext>r</mtext><mtext>a</mtext><mtext>d</mtext></mrow></msub><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mspace width="0.25em" /><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="129">其中<i>β</i>表示控制进行情感分类和学习领域共享特征之间平衡的系数.</p>
                </div>
                <h3 id="130" name="130" class="anchor-tag">3 领域独有特征提取与跨域情感分类</h3>
                <h4 class="anchor-tag" id="131" name="131"><b>3.1 辅助任务获取领域独有特征</b></h4>
                <div class="p1">
                    <p id="132">当源域与目标域的共享特征较少时, 跨域情感分类性能下降, 可有效利用领域独有特征提升分类性能.通常, 数据集中领域独有特征词与具有相同情感倾向的领域共享特征词共现.为了提取领域独有特征, 需要构造与原始任务密切相关的辅助任务<citation id="250" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="133">首先, 选取领域共享特征词pivots.与传统的手动选择pivots不同, 本文模型具有自动获取pivots的能力.在领域共享特征提取网络中, 对源域的每条正向 (或负向) 文档选择具有最高句子注意力的子句, 从中选择满足词性为形容词、副词、动词并且注意力权重值较高的单词作为正向 (或负向) pivots.</p>
                </div>
                <div class="p1">
                    <p id="134">然后, 隐藏原始数据中的pivots, 同时引入是否存在正负向pivots的辅助标签.使用特殊标记UNK替换原始数据的所有pivots, <i>w</i>′<sub><i>i</i>, <i>j</i></sub>表示修改后第<i>i</i>个子句的第<i>j</i>个词, <b><i>x</i></b>′<sub><i>i</i>, <i>j</i></sub>为<i>w</i>′<sub><i>i</i>, <i>j</i></sub>的嵌入向量.对每条变换后的数据引入辅助标签<i>y</i><sub><i>p</i></sub>和<i>y</i><sub><i>n</i></sub>, 如果原始数据文档含有至少一个正向 (或负向) pivots, <i>y</i><sub><i>p</i></sub> (或<i>y</i><sub><i>n</i></sub>) 标签标记为1, 否则标记为0.转换后的数据作为特征提取层的输入生成特征表示, 预测辅助标签<i>y</i><sub><i>p</i></sub>和<i>y</i><sub><i>n</i></sub>, 损失函数分别为<i>L</i><sub>pos</sub>和<i>L</i><sub>neg</sub>.通过训练对辅助标签的预测任务, 可使特征提取层提取到与领域共享特征共现的领域独有特征.</p>
                </div>
                <h4 class="anchor-tag" id="135" name="135"><b>3.2 结合领域独有特征实现情感分类</b></h4>
                <div class="p1">
                    <p id="136">为了更好地利用领域共享特征和领域独有特征, 对图1左右两部分进行联合训练.源域数据<i>X</i><mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><mi>l</mi></msubsup></mrow></math></mathml>和转换后的数据<i>X</i><mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>s</mi><msup><mi>l</mi><mo>′</mo></msup></msubsup></mrow></math></mathml>作为特征提取层的输入, 得到文档级特征表示<b><i>d</i></b><sub><i>s</i></sub>和 <b><i>d</i></b>′<sub><i>s</i></sub>, 二者进行拼接, 用于情感分类训练, 损失函数为<i>L</i><sub>joint</sub>.结合左右两部分的损失项与正则化项构成整体目标损失函数:</p>
                </div>
                <div class="area_img" id="263">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201905008_26300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="140">其中:<i>L</i><sub>reg</sub>表示对情感分类器、WDRL及辅助标签预测的参数进行的<i>l</i><sub>2</sub>正则化项, 以避免过拟合;<i>ρ</i>表示用于平衡正则化项和其它项的参数.</p>
                </div>
                <div class="p1">
                    <p id="141">基于Wasserstein距离分层注意力模型的跨域情感分类算法描述如下.</p>
                </div>
                <div class="p1">
                    <p id="142"><b>算法</b> 基于Wasserstein距离的分层注意力模型的跨域情感分类</p>
                </div>
                <div class="area_img" id="262">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201905008_26200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="262">
                                <img alt="" src="Detail/GetImg?filename=images/MSSB201905008_26201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <h3 id="197" name="197" class="anchor-tag">4 实验及结果分析</h3>
                <div class="p1">
                    <p id="198">本次实验主要使用如下2个数据集.1) Amazon产品评论数据集 (https://www.cs.jhu.edu/～mdredze/datasets/sentiment/) , 包括4个领域:书籍 (B) 、DVD (D) 、电子产品 (E) 和厨房用品 (K) .每个领域平均包含1 000条正向评论和1 000条负向评论, 以及17 668条未标记的评论.构建12个跨域对, 对每个跨域对, 取源域的正负向标记数据各800条作为训练集, 剩余的源域标记数据作为验证集.测试集从目标域随机选择正负向数据各200条, 剩余的目标域未标记数据随机选择与源域训练数据相同大小作为领域训练数据.2) UMICH SI650数据集 (https://inclass.kaggle.com/c/si650winter11/data) , 密歇根大学的句子级情感数据集, 由博客中的句子组成, 使用Blog表示, 包括3 995条正向句子和3 091条负向句子的训练数据, 以及33 052条未标记的测试数据.</p>
                </div>
                <div class="p1">
                    <p id="200">与文献<citation id="251" type="reference">[<a class="sup">11</a>]</citation>设置相同, 以Amazon数据集的4个领域作为源域, 增加B→Blog、D→Blog、E→Blog、K→Blog这4个领域对.将UMICH数据集原始测试集作为目标域的未标记数据集, 原始训练集作为目标域的测试集.</p>
                </div>
                <div class="p1">
                    <p id="201">在实验过程中, 将子句最大的单词数设为40, 文档最大子句数设为10.对于源域和目标域的数据, 使用300维的word2vec初始化词嵌入, 在训练过程中进行微调.BiGRU的隐藏层大小设为100, 单词级注意力层和子句级注意力层的隐藏维度为200.网络中的权重是从均匀分布<i>U</i>[-0.01, 0.01]随机初始化.在训练过程中, 模型使用Adam算法进行优化, 默认为1e-3的初始学习率.</p>
                </div>
                <div class="p1">
                    <p id="202">选择以不同的方式提取pivots进行跨领域情感分类的代表性方法, 进一步对比本文模型性能, 包括使用传统方法提取pivots及使用不同的深度神经网络结构进行对抗式训练自动提取pivots的方法.基线方法如下.</p>
                </div>
                <div class="p1">
                    <p id="203">1) SCL.Blitzer等<citation id="252" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出的结构对应学习方法, 使用互信息选取pivots, 学习源域和目标域的低维特征表示.</p>
                </div>
                <div class="p1">
                    <p id="204">2) DANN.Ganin等<citation id="253" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出的对抗性表示学习方法, 通过在领域分类器应用梯度反转层实现领域不可分并自动提取领域共享特征.</p>
                </div>
                <div class="p1">
                    <p id="205">3) AMN.Li等<citation id="254" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出的基于记忆网络和应用梯度反转层对抗性训练的方法.</p>
                </div>
                <div class="p1">
                    <p id="206">4) AE-SCL-SR.Ziser等<citation id="255" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出的将SCL与自动编码神经网络结合的方法, 解码矩阵中包含对pivot的预训练嵌入.</p>
                </div>
                <div class="p1">
                    <p id="207">5) Source-only.使用本文提出的分层注意力结构作为特征提取网络, 不进行域适应, 经过源域数据训练后直接用于目标域数据的情感分类.</p>
                </div>
                <div class="p1">
                    <p id="208">6) HAW.本文提出的基于Wasserstein距离的分层注意力跨域模型, 用于提取领域共享特征以实现跨越情感分类.</p>
                </div>
                <div class="p1">
                    <p id="209">7) HAW+.在HAW的基础上, 通过辅助任务提取领域独有特征, 结合领域共享特征和领域独有特征, 实现跨域情感分类.</p>
                </div>
                <div class="p1">
                    <p id="210">在2个数据集上对比不同方法的分类性能, 结果分别如表1、表2所示.</p>
                </div>
                <div class="area_img" id="211">
                    <p class="img_tit"><b>表1 不同方法在Amazon数据集上的跨域情感分类正确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"> Table 1 Cross-domain sentiment classification accuracy by different methods on Amazon datasets</p>
                    <p class="img_note"></p>
                    <table id="211" border="1"><tr><td></td><td>SCL</td><td>DANN</td><td>AMN</td><td>Source-<br />only</td><td>HAW</td><td>HAW+</td></tr><tr><td>B→D</td><td>0.675</td><td>0.733</td><td>0.820</td><td>0.780</td><td><b>0.858</b></td><td>0.855</td></tr><tr><td>B→E</td><td>0.665</td><td>0.690</td><td>0.798</td><td>0.710</td><td>0.833</td><td><b>0.843</b></td></tr><tr><td><br />B→K</td><td>0.685</td><td>0.779</td><td>0.813</td><td>0.698</td><td><b>0.840</b></td><td>0.833</td></tr><tr><td><br />D→B</td><td>0.645</td><td>0.723</td><td>0.825</td><td>0.743</td><td>0.830</td><td><b>0.838</b></td></tr><tr><td><br />D→E</td><td>0.648</td><td>0.754</td><td>0.795</td><td>0.700</td><td><b>0.838</b></td><td>0.833</td></tr><tr><td><br />D→K</td><td>0.660</td><td>0.783</td><td>0.823</td><td>0.725</td><td><b>0.833</b></td><td>0.828</td></tr><tr><td><br />E→B</td><td>0.615</td><td>0. 668</td><td>0.770</td><td>0.668</td><td>0.788</td><td><b>0.803</b></td></tr><tr><td><br />E→D</td><td>0.618</td><td>0.738</td><td>0.768</td><td>0.743</td><td><b>0.815</b></td><td>0.813</td></tr><tr><td><br />E→K</td><td>0.750</td><td>0.854</td><td><b>0.880</b></td><td>0.808</td><td>0.855</td><td>0.865</td></tr><tr><td><br />K→B</td><td>0.668</td><td>0.645</td><td>0.795</td><td>0.678</td><td>0.803</td><td><b>0.805</b></td></tr><tr><td><br />K→D</td><td>0.653</td><td>0.740</td><td>0.800</td><td>0.720</td><td>0.818</td><td><b>0.823</b></td></tr><tr><td><br />K→E</td><td>0.713</td><td>0.795</td><td>0.810</td><td>0.818</td><td><b>0.855</b></td><td>0.843</td></tr><tr><td><br />平均值</td><td>0.666</td><td>0.742</td><td>0.808</td><td>0.733</td><td>0.831</td><td><b>0.832</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="212">
                    <p class="img_tit"><b>表2 不同方法在Amazon与UMICH数据集上的跨域情 感分类正确率</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"> Table 2 Cross-domain sentiment classification accuracy by different methods on Amazon and UMICH datasets</p>
                    <p class="img_note"></p>
                    <table id="212" border="1"><tr><td></td><td>SCL</td><td>AE-<br />SCL-SR</td><td>Source-<br />only</td><td>HAW</td><td>HAW+</td></tr><tr><td><br />B→Blog</td><td>0.687</td><td>0.705</td><td>0.815</td><td>0.910</td><td>0.874</td></tr><tr><td>D→Blog</td><td>0.767</td><td>0.793</td><td>0.839</td><td>0.909</td><td>0.863</td></tr><tr><td><br />E→Blog</td><td>0.662</td><td>0.703</td><td>0.764</td><td>0.875</td><td>0.824</td></tr><tr><td><br />K→Blog</td><td>0.704</td><td>0.841</td><td>0.779</td><td>0.872</td><td>0.831</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="213">从表1可看出, 本文的HAW和HAW+在11个跨领域对都达到最优性能.HAW+平均正确率达到最优 (0.832) .相比其它方法, SCL表现不佳, 因为SCL依赖于对pivots的选择方法, 可能无法准确捕获pivots.本文方法可自动高效地捕获pivots与non-pivots, 泛化能力更强.相比DANN、AMN, HAW平均正确率分别提高8.9%、2.3%.主要原因在于本文的分级注意力机制可提取更有效的特征, 同时使用Wasserstein距离估计两个领域的表示可以更好地实现领域不可分的效果.Source-only的正确率仅比DANN低0.9%, 说明即使没有域适应方法减少领域间差异, 仅基于本文的特征提取网络结构也可达到较好效果.HAW+在全部12个跨领域对上的正确率都超过0.8, AMN虽然在E→K领域对的正确率达到最高的0.88, 但在其它领域正确率较低.由此证明HAW+模型更稳定.</p>
                </div>
                <div class="p1">
                    <p id="214">同时, 在HAW已达到较高正确率的情况下, HAW+的正确率反而稍有下降, 如果提取的领域共享特征效果不佳, HAW+中的辅助任务提取的领域独有特征效果同样质量不佳, 干扰情感分类.</p>
                </div>
                <div class="p1">
                    <p id="215">从表2可看出, 本文模型在4个跨领域对都达到最优性能.Source-only在3个领域对上的实验结果都超过AE-SCL-SR, 表明使用分层注意力结构作为特征提取网络的有效性.对比HAW, HAW+性能有所下降, 可能的原因是Blog领域独有特征词较少, 提取的领域特征不具有代表性, 反而造成分类性能的下降.</p>
                </div>
                <div class="p1">
                    <p id="216">为了进一步评价本文模型中每个不同组成模块的有效性, 进行如下的对比实验.</p>
                </div>
                <div class="p1">
                    <p id="217">1) 结合梯度反转后的非分层模型 (Non-hierar-chical Model with Gradient Reversal Layer, GRL) .特征提取层采用单层BiGRU+注意力机制结构, 领域分类器通过梯度反转层减少域差异.</p>
                </div>
                <div class="p1">
                    <p id="219">2) 结合梯度反转层的分层注意力模型 (Hierarchi-cal Attention Model with Gradient Reversal Layer, HAGRL) .在GRL的基础上使用分层结构替换特征提取层.单层BiGRU+单词级注意力得到子句级表示, 单层BiGRU+子句级注意力得到文档级表示.</p>
                </div>
                <div class="p1">
                    <p id="221">3) 基于Wasserstein距离的注意力模型 (Atten-tion Model Based on Wasserstein Distance, AW) .对于文本的HAW模型不使用分层结构提取特征, 而是采用单层BiGRU+注意力机制.</p>
                </div>
                <div class="p1">
                    <p id="223">5种方法在Amazon的12个跨领域对数据集上的正确率结果如图3所示.</p>
                </div>
                <div class="p1">
                    <p id="224">由图3可知, AW在11个跨域对数据上的正确率都优于GRL, 说明基于Wasserstein距离减少域差异的方法比基于梯度反转层的方法更有效.同时, HAW在全部12个跨域数据对上的性能均优于AW, 进一步验证分层结构获取特征的有效性.</p>
                </div>
                <div class="area_img" id="225">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905008_225.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 5种方法在Amazon数据集上正确率对比" src="Detail/GetImg?filename=images/MSSB201905008_225.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 5种方法在Amazon数据集上正确率对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905008_225.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.3 Accuracy comparison of 5 methods on Amazon datasets</p>

                </div>
                <div class="p1">
                    <p id="226">选取Books领域的一条正向评论, 对子句级和单词级的Attention权重进行可视化展示, 分别如图4和图5所示, 颜色深度体现Attention权重的大小变化.如图4所示, 子句级注意力重点关注子句2, 认为其情感倾向性更强.如图5所示, 单词级注意力重点关注在子句1中的词“borrowed”, 在子句2中的词“excellent”、“highly”, 在子句3中的词“realistic”、“helps”等, 由图可看出, 注意力机制捕获重要的信息.</p>
                </div>
                <div class="area_img" id="227">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905008_227.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 子句级Attention变化样例" src="Detail/GetImg?filename=images/MSSB201905008_227.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 子句级Attention变化样例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905008_227.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.4 Example of sentence-level attention variation</p>

                </div>
                <div class="area_img" id="228">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201905008_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 单词级Attention变化样例" src="Detail/GetImg?filename=images/MSSB201905008_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 单词级Attention变化样例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201905008_228.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.5 Example of word-level attention variation</p>

                </div>
                <h3 id="229" name="229" class="anchor-tag">5 结 束 语</h3>
                <div class="p1">
                    <p id="230">针对现有方法在跨领域情感分类任务中特征提取能力不足的问题, 本文提出基于Wasserstein距离的分层注意力模型, 实现跨领域情感分类, 有效获取具有较强情感区分力的特征.采用分层模型结合Attention机制进行特征提取, 通过估计两个领域特征表示的Wasserstein距离, 以对抗方式最小化Wasserstein距离优化特征提取器, 获取有效的 领 域共享特征.在此基础上构造辅助标签预测任务提取领域独有特征, 联合两种特征表示完成训练, 实现跨域情感分类.在Amazon数据集上的结果表明, 本文模型性能优于已有方法, 泛化能力更强, 在不同跨领域对具有更好的稳定性.今后工作重点是如何更好地提取领域独有特征, 使其不依赖于提取的领域共享特征, 从而进一步提高模型的分类性能.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
                        <h3 class="anchor-tag">作者图片</h3>
                <div class="anchor-wrap">
                        <p>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="257" type="formula" href="images/MSSB201905008_25700.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">杜永萍</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="259" type="formula" href="images/MSSB201905008_25900.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">贺萌</span>
                                    </div>
                                    <div class="anchor-box">
                                        <span class="anchor-a"><image id="261" type="formula" href="images/MSSB201905008_26100.jpg" display="inline" placement="inline"><alt></alt></image></span>
                                        <span class="anchor-a">赵晓铮</span>
                                    </div>
                        </p>
                </div>


        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201503011&amp;v=MDM2ODg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVmJySUx5dlNkTEc0SDlUTXJJOUVaWVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 赵传君, 王素格, 李德玉, 等.基于分组提升集成的跨领域文本情感分类.计算机研究与发展, 2015, 52 (3) :629-638. (ZHAO C J, WANG S G, LI D Y, <i>et al</i>.Cross-Domain Text Sentiment Classification Based on Grouping-AdaBoost Ensemble.Journal of Computer Research and Development, 2015, 52 (3) :629-638.) 
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201501003&amp;v=MzI0OTh0R0ZyQ1VSTE9lWmVSbkZ5emdWYnJJTnlmVGJMRzRIOVRNcm85Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 庄福振, 罗平, 何清, 等.迁移学习研究进展.软件学报, 2015, 26 (1) :26-39. (ZHUANG F Z, LUO P, HE Q, <i>et al</i>.Survey on Transfer Learning Research.Journal of Software, 2015, 26 (1) :26-39.) 
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" >
                                    <b>[3]</b>
                                 PAN S J, YANG Q.A Survey on Transfer Learning.IEEE Transactions on Knowledge and Data Engineering, 2010, 22 (10) :1345-1359.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201403017&amp;v=MTM5NTE0TzN6cXFCdEdGckNVUkxPZVplUm5GeXpnVmJySUtDTGZZYkc0SDlYTXJJOUVZNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 顾鑫, 王士同, 许敏.基于多源的跨领域数据分类快速新算法.自动化学报, 2014, 40 (3) :531-547. (GU X, WANG S T, XU M.A New Cross-multidomain Classification Algorithm and Its Fast Version for Large Datasets.Acta Automatica Sinica, 2014, 40 (3) :531-547.) 
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" >
                                    <b>[5]</b>
                                 BLITZER J, DREDZE M, PEREIA F.Biographies, Bollywood, Boom-Boxes and Blenders:Domain Adaption for Sentiment Classification // Proc of the 45th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2007:440-447.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" >
                                    <b>[6]</b>
                                 PAN S J, NI X C, SUN J T, <i>et al</i>.Cross-Domain Sentiment Classification via Spectral Feature Alignment // Proc of the 19th International Conference on World Wide Web.New York, USA:ACM, 2010:751-760.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" >
                                    <b>[7]</b>
                                 SHARMA R, BHATTACHARYYA P, DANDAPAT S, <i>et al</i>.Identifying Transferable Information across Domains for Cross-Domain Sentiment Classification // Proc of the 56th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2018:968-978.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" >
                                    <b>[8]</b>
                                 WU F Z, HUANG Y F, YAN J.Active Sentiment Domain Adaptation // Proc of the 55th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2017:1701-1711.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 GLOROT X, BORDES A, BENGIO Y.Domain Adaptation for Large-Scale Sentiment Classification:A Deep Learning Approach // Proc of the 28th International Conference on Machine Learning.Madison, USA:Omnipress, 2011:513-520.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" >
                                    <b>[10]</b>
                                 CHEN M M, XU Z X, WEINBERGER K, <i>et al</i>.Marginalized Denoising Autoencoders for Domain Adaptation // Proc of the 29th International Conference on Machine Learning.Berlin, Germany:Springer, 2012:767-774.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" >
                                    <b>[11]</b>
                                 ZISER Y, REICHART R.Neural Structural Correspondence Lear-ning for Domain Adaptation // Proc of the 21st Conference on Computational Natural Language Learning.Stroudsburg, USA:ACL, 2017:400-410.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" >
                                    <b>[12]</b>
                                 ZISER Y, REICHART R.Pivot Based Language Modeling for Improved Neural Domain Adaption // Proc of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technologies.Stroudsburg, USA:ACL, 2018:1241-1251.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                 CUI X, AL-BAZZAZ N, BOLLEGALA D, <i>et al</i>.A Comparative Study of Pivot Selection Strategies for Unsupervised Cross-Domain Sentiment Classification.The Knowledge Engineering Review, 2018, 33.DOI:10.1017/S0269888918000085.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" >
                                    <b>[14]</b>
                                 GANIN Y, USTINOVA E, AJAKAN H, <i>et al</i>.Domain-Adversarial Training of Neural Networks.Journal of Machine Learning Research, 2015, 17:2096-2030.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" >
                                    <b>[15]</b>
                                 YU J F, JIANG J.Leveraging Auxiliary Tasks for Document-Level Cross-Domain Sentiment Classification // Proc of the 8th International Joint Conference on Natural Language Processing.Stroudsburg, USA:ACL, 2017:654-663.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" >
                                    <b>[16]</b>
                                 LI Z, ZHANG Y, WEI Y, <i>et al</i>.End-to-End Adversarial Memory Network for Cross-Domain Sentiment Classification // Proc of the 26th International Joint Conference on Artificial Intelligence.Palo Alto, USA:AAAI Press, 2017:2237-2243.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 LI Z, WEI Y, ZHANG Y, <i>et al</i>.Hierarchical Attention Transfer Network for Cross-Domain Sentiment Classification[C/OL].[2018-11-15].https://www.cse.ust.hk/～yuzhangcse/papers/Li_Wei_Zhang_Yang_AAAI18.pdf.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" >
                                    <b>[18]</b>
                                 TANG D Y, QIN B, LIU T.Document Modeling with Gated Recurrent Neural Network for Sentiment Classification // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2015:1422-1432.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" >
                                    <b>[19]</b>
                                 ZHOU P, SHI W, TIAN J, <i>et al</i>.Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification // Proc of the 54th Annual Meeting of the Association for Computational Linguistics.Stroudsburg, USA:ACL, 2016:207-212.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" >
                                    <b>[20]</b>
                                 VASWANI A, SHAZEER N, PARMAR N, <i>et al</i>.Attention Is All You Need[C/OL].[2018-11-15].https://arxiv.org/pdf/1706.03762.pdf.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" >
                                    <b>[21]</b>
                                 MARTIN A, CHINTALA S, BOTTOU L.Wasserstein Gan[C/OL].[2018-11-15].https://arxiv.org/pdf/ 1701.07875.pdf.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" >
                                    <b>[22]</b>
                                 GULRAJANI I, AHMED F, ARJOVSKY M, <i>et al</i>.Improved Training of Wasserstein GANs[C/OL].[2018-11-15].https://arxiv.org/pdf/1704.00028.pdf.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" >
                                    <b>[23]</b>
                                 YU J F, JIANG J.Learning Sentence Embeddings with Auxiliary Tasks for Cross-Domain Sentiment Classification // Proc of the Conference on Empirical Methods in Natural Language Processing.Stroudsburg, USA:ACL, 2016:236-246.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201905008" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201905008&amp;v=MDU5NjdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6Z1ZicklLRDdZYkxHNEg5ak1xbzlGYklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
