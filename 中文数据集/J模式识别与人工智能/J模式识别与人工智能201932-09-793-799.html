<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131458841436250%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dMSSB201909004%26RESULT%3d1%26SIGN%3dDr53hSCnKG1q1MjtlNT%252fiAER8Y4%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201909004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201909004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201909004&amp;v=MTg1MTR6cXFCdEdGckNVUkxPZVplUm5GeS9rVnJyTktEN1liTEc0SDlqTXBvOUZZSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#70" data-title="1 基于PU学习的链接预测方法 ">1 基于PU学习的链接预测方法</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="&lt;b&gt;1.1 样本集构造&lt;/b&gt;"><b>1.1 样本集构造</b></a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;1.2 基于社区结构与集成的可靠负例选择&lt;/b&gt;"><b>1.2 基于社区结构与集成的可靠负例选择</b></a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;1.3 本文方法步骤&lt;/b&gt;"><b>1.3 本文方法步骤</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#118" data-title="2 实验及结果分析 ">2 实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#142" data-title="3 结 束 语 ">3 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="&lt;b&gt;表1 特征计算中使用的基本符号&lt;/b&gt;"><b>表1 特征计算中使用的基本符号</b></a></li>
                                                <li><a href="#79" data-title="&lt;b&gt;表2 样本特征&lt;/b&gt;"><b>表2 样本特征</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;表3 实验数据集&lt;/b&gt;"><b>表3 实验数据集</b></a></li>
                                                <li><a href="#137" data-title="&lt;b&gt;表4 不同方法在4个数据集上的AUC值对比&lt;/b&gt;"><b>表4 不同方法在4个数据集上的AUC值对比</b></a></li>
                                                <li><a href="#138" data-title="&lt;b&gt;表5 不同算法在4个数据集上的Precision值&lt;/b&gt;"><b>表5 不同算法在4个数据集上的Precision值</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="184">


                                    <a id="bibliography_1" title=" 吕琳媛.复杂网络链路预测.电子科技大学学报,2010,39(5):651-661.(L&#220; L Y.Link Prediction on Complex Networks.Journal of University of Electronic Science and Technology of China,2010,39(5):651-661.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201005006&amp;v=MzEyODg2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeS9rVnJyTklTYlBkckc0SDlITXFvOUZZb1FLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         吕琳媛.复杂网络链路预测.电子科技大学学报,2010,39(5):651-661.(L&#220; L Y.Link Prediction on Complex Networks.Journal of University of Electronic Science and Technology of China,2010,39(5):651-661.)
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_2" title=" 王智强,梁吉业,李茹.基于信息融合的概率矩阵分解链路预测方法.计算机研究与发展,2019,56(2):306-318.(WANG Z Q,LIANG J Y,LI R.Probability Matrix Factorization for Link Prediction Based on Information Fusion.Journal of Computer Research and Development,2019,56(2):306-318.)" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201902007&amp;v=MzIyNjZPZVplUm5GeS9rVnJyTkx5dlNkTEc0SDlqTXJZOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         王智强,梁吉业,李茹.基于信息融合的概率矩阵分解链路预测方法.计算机研究与发展,2019,56(2):306-318.(WANG Z Q,LIANG J Y,LI R.Probability Matrix Factorization for Link Prediction Based on Information Fusion.Journal of Computer Research and Development,2019,56(2):306-318.)
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_3" title=" WANG Z Q,LIANG J Y,LI R.A Fusion Probability Matrix Factorization Framework for Link Prediction.Knowledge-Based Systems,2018,159:72-85." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDC9459C7486DA8C865BE6E12142D9FC3&amp;v=MTMxNzNPTUplQTB4dkI0VjcwMElUZ3JqcmhNeGU4YWRNOG1jQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtNnhhMD1OaWZPZmNmTEY5WEpwdnhDWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         WANG Z Q,LIANG J Y,LI R.A Fusion Probability Matrix Factorization Framework for Link Prediction.Knowledge-Based Systems,2018,159:72-85.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_4" title=" WANG P,XU B W,WU Y R,et al.Link Prediction in Social Networks:the State-of-the-Art.Science China(Information Sciences),2015,58(1).DOI:10.1007/s11432-014-5237-y." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFXG201501001&amp;v=MjY2ODdlWmVSbkZ5L2tWcnJOTHl2VGFiRzRIOVRNcm85RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         WANG P,XU B W,WU Y R,et al.Link Prediction in Social Networks:the State-of-the-Art.Science China(Information Sciences),2015,58(1).DOI:10.1007/s11432-014-5237-y.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_5" title=" LICHTENWALTER R N,CHAWIA N V.Vertex Collocation Profiles:Subgraph Counting for Link Analysis and Prediction // Proc of the 21th International Conference on World Wide Web.New York,USA:ACM,2012:1019-1028." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Vertex collocation profiles:subgraph counting for link analysis and prediction">
                                        <b>[5]</b>
                                         LICHTENWALTER R N,CHAWIA N V.Vertex Collocation Profiles:Subgraph Counting for Link Analysis and Prediction // Proc of the 21th International Conference on World Wide Web.New York,USA:ACM,2012:1019-1028.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_6" title=" LESKOVEC J,HUTTENLOCHER D,KLEINBERG J.Predicting Positive and Negative Links in Online Social Networks // Proc of the 19th International Conference on World Wide Web.New York,USA:ACM,2010:641-650." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting positive and negative links in online social networks">
                                        <b>[6]</b>
                                         LESKOVEC J,HUTTENLOCHER D,KLEINBERG J.Predicting Positive and Negative Links in Online Social Networks // Proc of the 19th International Conference on World Wide Web.New York,USA:ACM,2010:641-650.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_7" title=" CHIANG K Y,NATARAJAN N,TEWARI A,et al.Exploiting Longer Cycles for Link Prediction in Signed Networks // Proc of the 20th ACM International Conference on Information and Knowledge Management.New York,USA:ACM,2011:1157-1162." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exploiting longer cycles for link prediction in signed networks">
                                        <b>[7]</b>
                                         CHIANG K Y,NATARAJAN N,TEWARI A,et al.Exploiting Longer Cycles for Link Prediction in Signed Networks // Proc of the 20th ACM International Conference on Information and Knowledge Management.New York,USA:ACM,2011:1157-1162.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_8" title=" DE S&#193;HIALLY R,PRUD&#201;NCIO R B C.Supervised Link Prediction in Weighted Networks // Proc of the 21th International Joint Conference on Neural Networks.Washington,USA:IEEE,2011:2281-2288." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supervised link prediction in weighted networks">
                                        <b>[8]</b>
                                         DE S&#193;HIALLY R,PRUD&#201;NCIO R B C.Supervised Link Prediction in Weighted Networks // Proc of the 21th International Joint Conference on Neural Networks.Washington,USA:IEEE,2011:2281-2288.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_9" title=" CHUAN P M,GIAP C N,LE SON H,et al.Enhance Link Prediction in Online Social Networks Using Similarity Metrics,Sampling,and Classification // BHATEJA V,LE NGUYEN N,NGUYEN N G,et al.,eds.Information Systems Design and Intelligent Applications.Berlin,Germany:Springer,2018:823-833." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhance Link Prediction in Online Social Networks Using Similarity Metrics,Sampling,and Classification">
                                        <b>[9]</b>
                                         CHUAN P M,GIAP C N,LE SON H,et al.Enhance Link Prediction in Online Social Networks Using Similarity Metrics,Sampling,and Classification // BHATEJA V,LE NGUYEN N,NGUYEN N G,et al.,eds.Information Systems Design and Intelligent Applications.Berlin,Germany:Springer,2018:823-833.
                                    </a>
                                </li>
                                <li id="202">


                                    <a id="bibliography_10" title=" BROUARD C,D′ALCH&#201;-BUC F,SZAFRANSKI M.Semi-supervised Penalized Output Kernel Regression for Link Prediction // Proc of the 28th International Conference on Machine Learning.New York,USA:ACM,2011:593-600." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Semi-supervised Penalized Output Kernel Regression for Link Prediction">
                                        <b>[10]</b>
                                         BROUARD C,D′ALCH&#201;-BUC F,SZAFRANSKI M.Semi-supervised Penalized Output Kernel Regression for Link Prediction // Proc of the 28th International Conference on Machine Learning.New York,USA:ACM,2011:593-600.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_11" title=" KASHIMA H,KATO T,YAMANISHI Y,et al.Link Propagation:A Fast Semi-supervised Learning Algorithm for Link Prediction // Proc of the 9th SIAM International Conference on Data Mining.Philadelphia,USA:SIAM,2009:1100-1111." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Link Propagation:A Fast Semi-Supervised Learning Algorithm for Link Prediction">
                                        <b>[11]</b>
                                         KASHIMA H,KATO T,YAMANISHI Y,et al.Link Propagation:A Fast Semi-supervised Learning Algorithm for Link Prediction // Proc of the 9th SIAM International Conference on Data Mining.Philadelphia,USA:SIAM,2009:1100-1111.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_12" title=" HU H,ZHU C Y,AI H X,et al.LPI-ETSLP:IncRNA-Protein Interaction Prediction Using Eigenvalue Transformation-Based Semi-supervised Link Prediction.Molecular BioSystems,2017,13(9):1781-1787." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=LPI-ETSLP:IncRNA-Protein Interaction Prediction Using Eigenvalue Transformation-Based Semi-supervised Link Prediction">
                                        <b>[12]</b>
                                         HU H,ZHU C Y,AI H X,et al.LPI-ETSLP:IncRNA-Protein Interaction Prediction Using Eigenvalue Transformation-Based Semi-supervised Link Prediction.Molecular BioSystems,2017,13(9):1781-1787.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_13" title=" DENIS F.PAC Learning from Positive Statistical Queries // Proc of the 9th International Conference on Algorithmic Learning Theory.Berlin,Germany:Springer,1998:112-126." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PAC learning from positive statistical queries">
                                        <b>[13]</b>
                                         DENIS F.PAC Learning from Positive Statistical Queries // Proc of the 9th International Conference on Algorithmic Learning Theory.Berlin,Germany:Springer,1998:112-126.
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_14" title=" LIU B,LEE W S,YU P S,et al.Partially Supervised Classification of Text Documents // Proc of the 19th International Conference on Machine Learning.San Francisco,USA:Morgan Kaufmann,2002:387-394." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Partially supervised classification of text documents">
                                        <b>[14]</b>
                                         LIU B,LEE W S,YU P S,et al.Partially Supervised Classification of Text Documents // Proc of the 19th International Conference on Machine Learning.San Francisco,USA:Morgan Kaufmann,2002:387-394.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_15" title=" LU L,TAO P.Clustering-Based Method for Positive and Unlabeled Text Categorization Enhanced by Improved TFIDF.Journal of Information Science and Engineering,2014,30(5):1463-1481." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering-Based Method for Positive and Unlabeled Text Categorization Enhanced by Improved TFIDF">
                                        <b>[15]</b>
                                         LU L,TAO P.Clustering-Based Method for Positive and Unlabeled Text Categorization Enhanced by Improved TFIDF.Journal of Information Science and Engineering,2014,30(5):1463-1481.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_16" title=" YU H,HAN J W,CHANG K C C.PEBL:Positive Example Ba-sed Learning for Web Page Classification Using SVM // Proc of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York,USA:ACM,2002:239-248." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=PEBL:Positive example based learning for web page classification using SVM">
                                        <b>[16]</b>
                                         YU H,HAN J W,CHANG K C C.PEBL:Positive Example Ba-sed Learning for Web Page Classification Using SVM // Proc of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York,USA:ACM,2002:239-248.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_17" title=" ZENG Z Z,CHEN K J,ZHANG S B,et al.A Link Prediction Approach Using Semi-supervised Learning in Dynamic Networks // Proc of the 6th International Conference on Advanced Computational Intelligence.Washington,USA:IEEE,2013:276-280." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A link prediction approach using semi-supervised learning in dynamic networks">
                                        <b>[17]</b>
                                         ZENG Z Z,CHEN K J,ZHANG S B,et al.A Link Prediction Approach Using Semi-supervised Learning in Dynamic Networks // Proc of the 6th International Conference on Advanced Computational Intelligence.Washington,USA:IEEE,2013:276-280.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_18" title=" PENG G J,CHEN K J,XUE S J,et al.A Relation Prediction Method Based on PU Learning // Proc of the 12th International Conference on Intelligent Systems and Knowledge Engineering.Washington,USA:IEEE,2017.DOI:10.1109/ISKE.2017.8258752." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Relation Prediction Method Based on PU Learning">
                                        <b>[18]</b>
                                         PENG G J,CHEN K J,XUE S J,et al.A Relation Prediction Method Based on PU Learning // Proc of the 12th International Conference on Intelligent Systems and Knowledge Engineering.Washington,USA:IEEE,2017.DOI:10.1109/ISKE.2017.8258752.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_19" title=" GUO H X,LI Y J,SHANG J,et al.Learning from Class-Imbalanced Data:Review of Methods and Applications.Expert Systems with Applications,2017,73:220-239." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFDEC6FD6ECC485AE16402459199FD5F1&amp;v=MTczMzFucFJNOGNNVGdRTXllQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1TkZodzdtNnhhMD1OaWZPZmNYTWE2TEsyZnRERVpoOENIUTh2bU1TN0R0OVNudg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         GUO H X,LI Y J,SHANG J,et al.Learning from Class-Imbalanced Data:Review of Methods and Applications.Expert Systems with Applications,2017,73:220-239.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_20" title=" BREIMAN L.Bagging Predictors.Machine Learning,1996,24(2):123-140." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339482&amp;v=MDY0MTJySXhNWU9NTlkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNIbFZMN05KVnM9Tmo3QmFyTzRIdEhO&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         BREIMAN L.Bagging Predictors.Machine Learning,1996,24(2):123-140.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_21" title=" MOTHE J,MKHITARYAN K,HAROUTUNIAN M.Community Detection:Comparison of State of the Art Algorithms // Proc of the 11th Conference on Computer Science and Information Technologies.Washington,USA:IEEE,2017:125-129." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Community Detection:Comparison of State of the Art Algorithms">
                                        <b>[21]</b>
                                         MOTHE J,MKHITARYAN K,HAROUTUNIAN M.Community Detection:Comparison of State of the Art Algorithms // Proc of the 11th Conference on Computer Science and Information Technologies.Washington,USA:IEEE,2017:125-129.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_22" title=" BLONDEL V D,GUILLAUME J L,LAMBIOTTE R,et al.Fast Unfolding of Communities in Large Networks[C/OL].[2019-03-01].https://arxiv.org/pdf/0803.0476.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast Unfolding of Communities in Large Networks[C/OL]">
                                        <b>[22]</b>
                                         BLONDEL V D,GUILLAUME J L,LAMBIOTTE R,et al.Fast Unfolding of Communities in Large Networks[C/OL].[2019-03-01].https://arxiv.org/pdf/0803.0476.pdf.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_23" title=" HE F X,LIU T L,WEBB G I,et al.Instance-Dependent PU Learning by Bayesian Optimal Relabeling[C/OL].[2019-03-01].https://arxiv.org/pdf/1808.02180.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Instance-Dependent PU Learning by Bayesian Optimal Relabeling[C/OL]">
                                        <b>[23]</b>
                                         HE F X,LIU T L,WEBB G I,et al.Instance-Dependent PU Learning by Bayesian Optimal Relabeling[C/OL].[2019-03-01].https://arxiv.org/pdf/1808.02180.pdf.
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_24" title=" MANEVITZ L M,YONSEF M.One-Class SVMs for Document Classification.Journal of Machine Learning Research,2001,2:139-154." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=One-class SVMs for document classification">
                                        <b>[24]</b>
                                         MANEVITZ L M,YONSEF M.One-Class SVMs for Document Classification.Journal of Machine Learning Research,2001,2:139-154.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(09),793-799 DOI:10.16451/j.cnki.issn1003-6059.201909003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于PU学习的链接预测方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%90%A6&amp;code=08453261&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李琦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%99%BA%E5%BC%BA&amp;code=25200586&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王智强</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A2%81%E5%90%89%E4%B8%9A&amp;code=08408575&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">梁吉业</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B1%B1%E8%A5%BF%E5%A4%A7%E5%AD%A6%E6%99%BA%E8%83%BD%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E7%A0%94%E7%A9%B6%E6%89%80%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E4%B8%8E%E4%B8%AD%E6%96%87%E4%BF%A1%E6%81%AF%E5%A4%84%E7%90%86%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0176514&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">山西大学智能信息处理研究所计算智能与中文信息处理教育部重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于分类的链接预测方法中,由于链接未知节点对的大规模性与不确定性,选择可靠负例成为构造链接预测分类器的难点问题.为此,文中提出基于正例和无标识样本(PU)学习的链接预测方法.首先,提取节点对的拓扑信息以构造样本集.再利用社区结构确定候选负例的分布,基于分布进行多次欠采样,获得多个候选负例子集,集成多个负例集与正例集中构建的分类器选择可靠负例.最后基于正例与可靠负例构造链接预测分类器.在4个网络数据集上的实验表明文中方法预测结果较优.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%93%BE%E6%8E%A5%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">链接预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%AD%A3%E4%BE%8B%E5%92%8C%E6%97%A0%E6%A0%87%E8%AF%86%E6%A0%B7%E6%9C%AC(PU)%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">正例和无标识样本(PU)学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A4%BE%E5%8C%BA%E7%BB%93%E6%9E%84&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">社区结构;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">集成学习;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李琦，硕士研究生，主要研究方向为社交网络分析．E-mail:471581288@qq.com.&lt;image id="181" type="formula" href="images/MSSB201909004_18100.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    王智强，博士，讲师，主要研究方向为社会网络分析、机器学习．E-mail:zhiq.wang@163.com.&lt;image id="182" type="formula" href="images/MSSB201909004_18200.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                                <span>
                                    *梁吉业(通讯作者)，博士，教授，主要研究方向为人工智能、粒计算、数据挖掘、机器学习．E-mail:ljy@sxu.edu.cn.&lt;image id="183" type="formula" href="images/MSSB201909004_18300.jpg" display="inline" placement="inline"&gt;&lt;alt&gt;&lt;/alt&gt;&lt;/image&gt;;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-05-13</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(No.61876103,61906111);</span>
                                <span>山西省高等学校科技创新项目(No.2019L0023);</span>
                                <span>山西省1331工程项目资助;</span>
                    </p>
            </div>
                    <h1><b>Link Prediction Method Based on PU Learning</b></h1>
                    <h2>
                    <span>LI Qi</span>
                    <span>WANG Zhiqiang</span>
                    <span>LIANG Jiye</span>
            </h2>
                    <h2>
                    <span>Key Laboratory of Computational Intelligence and Chinese Information Processing of Ministry of Education,Institute of Intelligent Information Processing,Shanxi University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In classification-based link prediction methods, it is difficult to choose reliable negative examples to construct the link prediction classifier due to the large-scale and uncertainty of the unknown node pairs. Therefore, a link prediction method based on positive and unlabeled(PU) learning is proposed. Firstly, topological information of node pairs is extracted to construct example sets. Secondly, distribution of candidate negative examples is determined by community structure, and several candidate negative example sets are obtained through multiple under-sampling based on the distribution. Then, the classifiers constructed from multiple negative example sets and positive example sets are integrated to select reliable negative examples. Finally, the link prediction classifier is constructed based on positive examples and reliable negative examples. Experiments on four datasets show that the proposed link prediction method produces better prediction results than other related methods.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Link%20Prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Link Prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Positive%20and%20Unlabeled(PU)%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Positive and Unlabeled(PU) Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Community%20Structure&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Community Structure;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Ensemble%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Ensemble Learning;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    LI Qi,master student. Her research interests include social network analysis.;
                                </span>
                                <span>
                                    WANG Zhiqiang,Ph. D. ,lecturer. His research interests include social network analysis and machine learning.;
                                </span>
                                <span>
                                    LIANG Jiye(Corresponding author),Ph. D., professor. His research interests include artificial intelligence,granular computing,data mining and machine learning.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2019-05-13</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by National Natural Science Foundation of China(No.61876103,61906111);</span>
                                <span>Science and Technological Innovation Programs of Higher Education Institutions in Shanxi(No.2019L0023);</span>
                                <span>1331 Engineering Project of Shanxi Province;</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="61">在社交平台,如Facebook、微信和Twitter中,用户之间的链接关系构成复杂的社交网络.网络链接预测是根据已知的网络结构预测未知结构,是网络数据挖掘的重要研究问题之一<citation id="232" type="reference"><link href="184" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.链接预测对于从微观角度探究网络的演化规律具有重要意义,同时在推荐系统、生物信息等领域也发挥重要的应用价值<citation id="233" type="reference"><link href="186" rel="bibliography" /><link href="188" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="62">从有监督学习的角度预测网络节点之间是否存在链接,可看作是二分类问题,网络中存在链接的节点对为正例，不存在链接的节点对为负例<citation id="234" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>．在基于分类的链接预测方法中，特征选择是影响预测结果的因素之一．Lichtenwalter等<citation id="235" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出基于节点搭配的度量方法，用于描述节点对之间的链接方式，计算复杂度较高，不适用于大规模网络．Leskovec等<citation id="236" type="reference"><link href="194" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>针对有向符号网络，提出利用节点度和三元组(节点对及其连边)的特征．Chiang等<citation id="237" type="reference"><link href="196" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>在文献<citation id="238" type="reference">[<a class="sup">6</a>]</citation>的基础上，使用更长路径的链接方式构造特征，结果表明适当增加路径长度可以提高预测效果．De Shially等<citation id="239" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>针对加权网络，采用加权的结构相似性指标作为特征，结果表示链接权重可以提高预测效果．Chuan等<citation id="240" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>针对共同著作网络，结合著作的语义相似度扩展传统的相似性度量，提高预测结果，实验结果同时表明使用逻辑斯蒂回归(Logistics Regre-ssion,LR)和加权的支持向量机(Support Vector Machine,SVM)的预测效果优于其它分类器．上述工作大多采用基于分类模型的方法以解决链接预测问题，并随机选择网络中部分链接未知的节点对作为负例进行监督学习．</p>
                </div>
                <div class="p1">
                    <p id="66">此外,还有工作将未被选择的链接未知节点对视为无标记样本,运用半监督学习方法解决链接预测问题.Brouard等<citation id="241" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>将链接预测问题作为输出核学习问题,提出半监督惩罚输出核方法,结果表明利用无标记样本可以在标记样本少的情况下提高预测效果.Kashima等<citation id="242" type="reference"><link href="204" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>引入标签传播算法,提出链接传播算法,利用辅助信息进行张量补全,不但能预测链接强度,还能预测链接类型.Hu等<citation id="243" type="reference"><link href="206" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出基于特征值转换的半监督链接预测方法,用于揭示生物分子间的关系.上述工作采用图半监督方法,涉及样本相似性计算,在大规模网络中计算复杂度较高.</p>
                </div>
                <div class="p1">
                    <p id="67">无论是监督学习还是半监督学习,都需要正负两类样本.现实世界中的网络规模大且稀疏,只能观察到极少量有链接的节点对和大量链接未知的节点对,并且当前无链接的节点对在未来可能会产生链接.链接未知的节点对的不确定性,使其更应该看作无标记样本,已有工作随机从中选择部分节点对并直接将其视作负例是不合适的.链接预测问题从正例和无标记样本(Positive and Unlabeled, PU)中进行学习,是特殊的半监督学习,即正例和无标识样本学习问题.</p>
                </div>
                <div class="p1">
                    <p id="68">Denis<citation id="244" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>对PU学习进行理论分析.Liu等<citation id="245" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>称PU学习为部分监督学习,提出使用间谍(Spy)技术选择可靠负例、利用期望最大化(Expectation Maximum, EM)和朴素贝叶斯(Naive Bayes, NB)分类器的S-EM(Spy-Expectation Maximum)实现文本分类.Lu等<citation id="246" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出基于聚类的方法进行文本分类,通过对正例进行聚类,选择不属于任何簇的无标记样本作为可靠负例,迭代训练SVM.Yu等<citation id="247" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>采用1-DNF(Disjunctive Normal Form)选择负例,迭代训练SVM,分类用户感兴趣网页.链接预测方面,Zeng等<citation id="248" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>分别从正例和无标记样本中随机抽取相同数量的样本作为初始训练集,用于构造SVM,将距离分割平面最远的无标记样本作为负例,通过自训练得到链接预测分类器.实验表明,无标记样本的引入能提高预测效果.但选择初始训练集的方法会影响训练效果.Peng等<citation id="249" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>提出基于<i>K</i>-means和投票机制的可靠负例选择方法(Reliable Negative Selection Method Based on <i>K</i>-means Voting Mechanism, SemiPU-clus)及关系预测框架,解决异质信息网络中的关系预测问题,性能优于将无链接节点对完全视作负例的方法,但预测效果易受聚类结果影响.</p>
                </div>
                <div class="p1">
                    <p id="69">目前,PU学习中可靠负例的选择方法已有一定的研究进展,但网络中链接未知节点对具有大规模性和不确定性,从中选择可靠负例仍极为困难.为此,本文提出基于PU学习的链接预测方法,从网络社区结构与模型集成两个层面解决可靠负例的选择问题,旨在提升负例选择的可靠性.</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag">1 基于PU学习的链接预测方法</h3>
                <h4 class="anchor-tag" id="71" name="71"><b>1.1 样本集构造</b></h4>
                <div class="p1">
                    <p id="72">基于PU学习的链接预测方法首先要根据网络构造样本集.给定网络的二元组表示<i>G</i>=(<i>V</i>,<i>E</i>),其中,<i>V</i>表示网络中节点的集合,<i>E</i>表示网络中边的集合.<i>u</i>∈<i>V</i>,<i>v</i>∈<i>V</i>表示节点,<i>e</i><sup>(</sup><sup><i>u</i></sup><sup>,</sup><sup><i>v</i></sup><sup>)</sup>∈<i>E</i>表示节点对(<i>u</i>,<i>v</i>)存在链接.将节点对作为样本,<i><b>x</b></i><sup>(</sup><sup><i>u</i></sup><sup>,</sup><sup><i>v</i></sup><sup>)</sup>=(<i>x</i><sub>1</sub>,<i>x</i><sub>2</sub>,…,<i>x</i><sub><i>d</i></sub>)表示样本(<i>u</i>,<i>v</i>)的<i>d</i>维特征向量,<i>x</i><sub><i>i</i></sub>表示样本在第<i>i</i>个特征上的取值.<i>l</i><sup>(</sup><sup><i>u</i></sup><sup>,</sup><sup><i>v</i></sup><sup>)</sup>为样本标签,由节点对之间是否存在链接决定.存在链接的节点对表示正例,样本标签取值为1,链接已知的节点对构成正例集</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>,</mo><mi>l</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mi>e</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>∈</mo><mi>E</mi><mo>,</mo><mi>l</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mn>1</mn><mo stretchy="false">}</mo><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">链接未知的节点对构成无标记样本集</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>U</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mi>e</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>∉</mo><mi>E</mi><mo stretchy="false">}</mo><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">基于分类的链接预测方法中,节点对间的结构相似性指标常作为节点对样本的特征<citation id="250" type="reference"><link href="198" rel="bibliography" /><link href="200" rel="bibliography" /><link href="216" rel="bibliography" /><link href="218" rel="bibliography" /><sup>[<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">17</a>,<a class="sup">18</a>]</sup></citation>.因此,本文选取7种常用的结构相似性指标作为样本特征,包括基于局部信息的相似性指标和基于路径的相似性指标,具体如下:共同邻居数(Common Neighbors, CN)、Jaccard系数(Jaccard Coefficient, JC)、偏好性(Preferential Attachment, PA)、资源分配(Resource Allocation, RA)、邻居贡献(AdamicAd-ar,AA)、聚集系数(Clustering Coefficient,CC)、局部路程(Local Path,LP)．表1定义计算样本特征时使用的基本符号．表2定义特征及其计算公式．</p>
                </div>
                <div class="area_img" id="78">
                    <p class="img_tit"><b>表1 特征计算中使用的基本符号</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Basic symbols used in feature computing</p>
                    <p class="img_note"></p>
                    <table id="78" border="1"><tr><td><br />符号</td><td>含义</td></tr><tr><td><br /><i>u</i>,<i>v</i>,<i>z</i></td><td>节点</td></tr><tr><td><br /><i>Γ</i>(<i>u</i>)</td><td>与节点<i>u</i>的邻居节点集合</td></tr><tr><td><br /><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></mrow></math></td><td>集合<i>Γ</i>(<i>u</i>)中的元素个数</td></tr><tr><td><br /><b><i>A</i></b></td><td>网络的邻接矩阵</td></tr><tr><td><br /><i>A</i><sub><i>ij</i></sub></td><td>矩阵<b><i>A</i></b>中(<i>i</i>,<i>j</i>)位置的元素</td></tr><tr><td><br /><i>t</i><sub><i>u</i></sub></td><td><i>u</i>与<i>Γ</i>(<i>u</i>)的链接构成的三角形个数</td></tr><tr><td><br /><i>β</i></td><td>可调参数(本文取<i>β</i>=0.001)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="79">
                    <p class="img_tit"><b>表2 样本特征</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Features of examples</p>
                    <p class="img_note"></p>
                    <table id="79" border="1"><tr><td><br />特征</td><td>计算公式</td></tr><tr><td><br />CN</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>Ν</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mstyle displaystyle="true"><mo>∩</mo><mi>Γ</mi></mstyle><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></mrow></math></td></tr><tr><td><br />JC</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mi>C</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mstyle displaystyle="true"><mo>∩</mo><mi>Γ</mi></mstyle><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mstyle displaystyle="true"><mo>∪</mo><mi>Γ</mi></mstyle><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></td></tr><tr><td><br />PA</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>A</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mo>×</mo><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></mrow></math></td></tr><tr><td><br />RA</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>A</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>z</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mstyle displaystyle="true"><mo>∩</mo><mi>Γ</mi></mstyle><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></munder><mrow><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></mrow></mfrac></mrow></mstyle></mrow></math></td></tr><tr><td><br />AA</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>A</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>z</mi><mo>∈</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mstyle displaystyle="true"><mo>∩</mo><mi>Γ</mi></mstyle><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></munder><mrow><mfrac><mn>1</mn><mrow><mi>log</mi><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo></mrow></mfrac></mrow></mstyle></mrow></math></td></tr><tr><td><br />CC</td><td><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>s</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mn>2</mn><mi>t</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mrow><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mi>Γ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac><mo>,</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>C</mi><mi>C</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>+</mo><mi>s</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mtd></mtr></mtable></math></td></tr><tr><td><br />LP</td><td><i>LP</i>(<i>u</i>,<i>v</i>)=(<b><i>A</i></b><sup>2</sup>+<i>β</i><b><i>A</i></b><sup>3</sup>)<sub><i>uv</i></sub></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="80" name="80"><b>1.2 基于社区结构与集成的可靠负例选择</b></h4>
                <div class="p1">
                    <p id="81">对于拥有<i>n</i>个节点的无向网络,最多可以有<i>n</i>(<i>n</i>-1)/2条边,由于网络的稀疏性,真实存在的边数远小于<i>n</i>(<i>n</i>-1)/2.基于PU学习的链接预测问题是特殊的分类问题,即只存在正例,并且正例数量远小于无标记样本的数量.考虑到网络中无标记样本具有不确定性和大规模性,本文提出从网络中选择可靠负例的方法(Reliable Negative Examples from Network, RNEN).首先利用社区发现算法得到网络的社区结构,通过考虑节点对的位置信息确定候选负例的分布.然后,基于确定的样本分布进行多次欠采样,将得到的多个子集作为负例集,分别与正例集构成训练集,用于训练子分类器.最后,通过集成方法<citation id="251" type="reference"><link href="220" rel="bibliography" /><link href="222" rel="bibliography" /><sup>[<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>从无标记样本中选择可靠负例.</p>
                </div>
                <div class="p1">
                    <p id="82">1)基于社区结构的候选负例分布确定.社区发现算法能挖掘网络的社区结构,根据节点的链接关系将联系紧密的节点划分至同一社区,而社区之间的节点联系稀疏<citation id="252" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>.基于网络的社区结构可以得到节点之间的位置信息,从而确定候选负例的分布,并根据该分布采样得到构建子分类器的负例.</p>
                </div>
                <div class="p1">
                    <p id="83">使用<i>C</i>={<i>c</i><sub>1</sub>,<i>c</i><sub>2</sub>,…,<i>c</i><sub><i>n</i></sub>}表示节点社区索引集合,<i>c</i><sub><i>v</i></sub>表示节点<i>v</i>所在社区的索引,<i>Q</i>表示社区数量.根据节点所属社区是否一致,同一社区内链接未知的节点对构成样本集</p>
                </div>
                <div class="p1">
                    <p id="84" class="code-formula">
                        <mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>U</mi><mi>C</mi><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">|</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>∈</mo><mi>U</mi><mo>,</mo><mi>c</mi><msub><mrow></mrow><mi>u</mi></msub><mo>=</mo><mi>c</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">}</mo><mo>,</mo><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="85">不同社区之间链接未知的节点对构成样本集</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>U</mi><mi>B</mi><mi>C</mi><mo>=</mo><mo stretchy="false">{</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">|</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>∈</mo><mi>U</mi><mo>,</mo><mi>c</mi><msub><mrow></mrow><mi>u</mi></msub><mo>≠</mo><mi>c</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">}</mo><mo>.</mo><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">对<i>UC</i>和<i>UBC</i>分别进行采样,两个集合中所得样本的数目比例分别为</p>
                </div>
                <div class="area_img" id="88">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/MSSB201909004_08800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="90">对于不同社区、节点数大且稀疏的社区中链接关系未知的节点对存在链接的可能性更小.记第<i>i</i>个社区的采样比例</p>
                </div>
                <div class="p1">
                    <p id="91"><mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>γ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>Ν</mi><msub><mrow></mrow><mi>i</mi></msub><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>q</mi><mo>=</mo><mn>1</mn></mrow><mi>Q</mi></munderover><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>q</mi></msub><mi>α</mi><msub><mrow></mrow><mi>q</mi></msub></mrow></mfrac></mrow></math></mathml>,      (2)</p>
                </div>
                <div class="p1">
                    <p id="92">其中,<i>N</i><sub><i>i</i></sub>、<i>N</i><sub><i>q</i></sub>分别表示第<i>i</i>、<i>q</i>个社区的节点数,<i>α</i><sub><i>i</i></sub>、<i>α</i><sub><i>q</i></sub>分别表示第<i>i</i>、<i>q</i>个社区内链接未知的节点对数量与该社区所有节点对数量之比.本文采用文献<citation id="253" type="reference">[<a class="sup">22</a>]</citation>中社区划分算法划分节点,基于优化模块度实现,能快速高效地划分大规模网络.</p>
                </div>
                <div class="p1">
                    <p id="93">2)基于集成的可靠负例选择.网络中无标记样本数量远大于正例数量,单次采样训练难以保证所选负例的可靠性,因此,采用集成的方法提升负例选择的可靠性.</p>
                </div>
                <div class="p1">
                    <p id="94">根据上述确定的采样比例进行<i>T</i>次采样,第<i>t</i>(<i>t</i>=1,2,…,<i>T</i>)次从第<i>i</i>个社区内采集的样本子集记为<i>UC</i><mathml id="146"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup></mrow></math></mathml>,从<i>Q</i>个社区得到的样本集合记作<i>UC</i><sub><i>t</i></sub>,</p>
                </div>
                <div class="p1">
                    <p id="95"><i>UC</i><sub><i>t</i></sub>=<i>UC</i><mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mn>1</mn></msubsup></mrow></math></mathml>∪<i>UC</i><mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mn>2</mn></msubsup></mrow></math></mathml>∪…∪<i>UC</i><mathml id="149"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>t</mi><mi>Q</mi></msubsup></mrow></math></mathml>.</p>
                </div>
                <div class="p1">
                    <p id="96">从社区之间采集的样本子集记为<i>UBC</i><sub><i>t</i></sub>.由于所得样本作为训练子分类器的负例,负例与正例的样本数量需保持平衡且为整数,故第<i>i</i>个社区采样数目</p>
                </div>
                <div class="p1">
                    <p id="97"><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>U</mi><mi>C</mi><msubsup><mrow></mrow><mi>t</mi><mi>i</mi></msubsup><mo stretchy="false">|</mo><mo>=</mo><mo>⌈</mo><mi>γ</mi><msub><mrow></mrow><mi>i</mi></msub><mi>r</mi><msub><mrow></mrow><mrow><mi>U</mi><mi>C</mi></mrow></msub><mo stretchy="false">|</mo><mi>Ρ</mi><mo stretchy="false">|</mo><mo>⌉</mo></mrow></math></mathml>,      (3)</p>
                </div>
                <div class="p1">
                    <p id="98">其中「·⎤表示向上取整.从社区之间的采样数目</p>
                </div>
                <div class="p1">
                    <p id="99"><mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">|</mo><mi>U</mi><mi>B</mi><mi>C</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mo>=</mo><mo>⌈</mo><mi>r</mi><msub><mrow></mrow><mrow><mi>U</mi><mi>B</mi><mi>C</mi></mrow></msub><mo stretchy="false">|</mo><mi>Ρ</mi><mo stretchy="false">|</mo><mo>⌉</mo></mrow></math></mathml>.       (4)</p>
                </div>
                <div class="p1">
                    <p id="100">在<i>UC</i><sub><i>t</i></sub>∪<i>UBC</i><sub><i>t</i></sub>作为负例集与<i>P</i>构成的训练集上训练子分类器<i>f</i><sub><i>t</i></sub>,通过<i>T</i>次采样及训练可得到子分类器集合<i>F</i>={<i>f</i><sub>1</sub>, <i>f</i><sub>2</sub>,…, <i>f</i><sub><i>T</i></sub>}.<i>F</i>中的子分类器对<i>U</i>中的样本进行预测,记样本<i><b>x</b></i><sup>(</sup><sup><i>u</i></sup><sup>,</sup><sup><i>v</i></sup><sup>)</sup>被预测为负例的次数为<i>count</i>(<i><b>x</b></i><sup>(</sup><sup><i>u</i></sup><sup>,</sup><sup><i>v</i></sup><sup>)</sup>),<i>U</i>中样本被预测为负例的次数的均值</p>
                </div>
                <div class="p1">
                    <p id="101" class="code-formula">
                        <mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>a</mi><mi>v</mi><mi>e</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mi>U</mi><mo>|</mo></mrow></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>∈</mo><mi>U</mi></mrow></munder><mi>c</mi></mstyle><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>.</mo><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="102">从<i>U</i>中选择被预测为负例的次数不小于<i>ave</i>的样本作为可靠负例,所选样本表示不存在链接的节点对,样本标签<i>l</i><sup>(</sup><sup><i>u</i></sup><sup>,</sup><sup><i>v</i></sup><sup>)</sup>=-1.可靠负例集</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>R</mi><mi>Ν</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>,</mo><mi>l</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo stretchy="false">|</mo><mi mathvariant="bold-italic">x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>∈</mo><mi>U</mi><mo>,</mo><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>x</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>≥</mo><mi>a</mi><mi>v</mi><mi>e</mi><mo>,</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>l</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><mo>-</mo><mn>1</mn><mo stretchy="false">}</mo><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="104" name="104"><b>1.3 本文方法步骤</b></h4>
                <div class="p1">
                    <p id="105">PU学习从正例和无标记样本中学习得到分类器,用于预测无标记样本.本文方法首先根据网络构造样本集<i>P</i>和<i>U</i>,在<i>U</i>中选择<i>RN</i>;通过对<i>P</i>和<i>RN</i>构成的训练集进行监督学习得到最终的链接预测分类器<i>f</i>.对任意节点对(<i>u</i>,<i>v</i>),通过<i>f</i>能预测其存在链接的概率,从而实现链接预测,最后使用受试者工作特征曲线下方的面积(Area Under the Receiver Opera-ting Characteristic Curve, AUC)指标和准确率(Precision)指标,评价预测结果.</p>
                </div>
                <div class="p1">
                    <p id="106">本文方法步骤如算法1所示.</p>
                </div>
                <div class="p1">
                    <p id="107"><b>算法 1</b> 基于PU学习的链接预测方法</p>
                </div>
                <div class="p1">
                    <p id="108"><b>输入</b> 网络<i>G</i>=(<i>V</i>,<i>E</i>)</p>
                </div>
                <div class="p1">
                    <p id="109"><b>输出</b><i>AUC</i>,<i>Precision</i></p>
                </div>
                <div class="p1">
                    <p id="110">step 1 计算网络<i>G</i>中所有节点对的特征.</p>
                </div>
                <div class="p1">
                    <p id="111">step 2 将链接已知的节点对作为正例,链接未知的节点对作为无标记样本,构造正例集<i>P</i>和无标记样本集<i>U</i>.</p>
                </div>
                <div class="p1">
                    <p id="112">step 3 对于网络<i>G</i>中的链接关系,利用Louvain算法将节点划分至不同社区.</p>
                </div>
                <div class="p1">
                    <p id="113">step 4 结合网络社区结构,根据式(1)和式(2)计算社区之间和各社区内的采样比例.</p>
                </div>
                <div class="p1">
                    <p id="114">step 5 当<i>t</i>=1,2,…,<i>T</i>时,执行如下循环.通过随机采样得到样本集<i>UC</i><sub><i>t</i></sub>、<i>UBC</i><sub><i>t</i></sub>,采样数量分别根据式(3)和式(4)确定;令<i>UC</i><sub><i>t</i></sub>∪<i>UBC</i><sub><i>t</i></sub>中样本作为负例,与<i>P</i>构成训练集训练子分类器<i>f</i><sub><i>t</i></sub>.</p>
                </div>
                <div class="p1">
                    <p id="115">step 6 各子分类器对<i>U</i>中样本进行预测,根据式(5)从<i>U</i>中选择样本构成可靠负例集合<i>RN</i>.</p>
                </div>
                <div class="p1">
                    <p id="116">step 7 在<i>RN</i>、<i>P</i>上训练链接预测分类器<i>f</i>.</p>
                </div>
                <div class="p1">
                    <p id="117">step 8 利用<i>f</i>预测<i>U</i>中样本属于正例的概率,基于概率值计算链接预测结果的<i>AUC</i>值和<i>Precision</i>值.</p>
                </div>
                <h3 id="118" name="118" class="anchor-tag">2 实验及结果分析</h3>
                <div class="p1">
                    <p id="119">本文在GR-QC、Email-Eu-core、P2P和College-MSG数据集上进行实验.4个数据集均可在斯坦福大学的网络分析平台(Stanford Network Analysis Project, SNAP)(http://snap.stanford.edu/data)上获取.在有向网络中,若节点对有任意一个方向的链接关系,则看作该节点对存在链接关系,将有向网络转化为无向网络.表3列出4个数据集的信息.</p>
                </div>
                <div class="p1">
                    <p id="121">GR-QC数据集包括5 242名学者在广义相对论与量子宇宙学范畴的共同著作关系,有共同著作的两位学者之间存在链接关系.</p>
                </div>
                <div class="p1">
                    <p id="122">Email-Eu-core数据集为欧洲某研究机构内1 005名成员之间的电子邮件数据,两名成员之间有邮件往来则存在链接关系.</p>
                </div>
                <div class="p1">
                    <p id="123">P2P数据集为Gnutella文件共享网络中6 301台主机之间的链接关系,两台主机之间有过文件共享则存在链接关系.</p>
                </div>
                <div class="p1">
                    <p id="124">CollegeMSG数据集为加州大学欧文分校1 899名用户在社交网络上发送信息的关系,若两名用户之间发送过信息则存在链接关系.</p>
                </div>
                <div class="area_img" id="125">
                    <p class="img_tit"><b>表3 实验数据集</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Experimental datasets</p>
                    <p class="img_note"></p>
                    <table id="125" border="1"><tr><td><br />名称</td><td>节点数</td><td>边数</td><td>边密度/%</td></tr><tr><td><br />GR-QC</td><td>5242</td><td>14484</td><td>0.1054</td></tr><tr><td><br />Email-Eu-core</td><td>1005</td><td>16064</td><td>3.1840</td></tr><tr><td><br />P2P</td><td>6301</td><td>20777</td><td>0.1047</td></tr><tr><td><br />CollegeMSG</td><td>1899</td><td>13838</td><td>0.7679</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="126">在衡量预测性能时,选择如下评价指标.</p>
                </div>
                <div class="p1">
                    <p id="127">1)<i>AUC</i>指标.通过抽样方法计算时,<i>AUC</i>分别从测试集和无标记样本中各取一个样本,测试集中样本预测为正例的分值大于无标记样本预测为正例的分值的概率.<i>AUC</i>计算方式如下:</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>A</mtext><mtext>U</mtext><mtext>C</mtext><mo>=</mo><mfrac><mrow><mtext>n</mtext><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn><mtext>n</mtext><msub><mrow></mrow><mn>2</mn></msub></mrow><mtext>n</mtext></mfrac><mo>,</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="129">其中,n表示总的采样次数,n<sub>1</sub>表示n次采样中测试集中样本分值大的次数,n<sub>2</sub>表示n次采样中两者分值相等的次数.<i>AUC</i>值越高,算法效果越好.</p>
                </div>
                <div class="p1">
                    <p id="130">2)<i>Precision</i>指标.<i>Top</i>-L的链接预测准确率,即前L个节点对的预测准确率.将节点对按存在链接的可能性降序排序,若前L个节点对有m个在测试集中,Precision计算公式为</p>
                </div>
                <div class="p1">
                    <p id="131" class="code-formula">
                        <mathml id="131"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mtext>r</mtext><mtext>e</mtext><mtext>c</mtext><mtext>i</mtext><mtext>s</mtext><mtext>i</mtext><mtext>o</mtext><mtext>n</mtext><mo>=</mo><mfrac><mtext>m</mtext><mtext>L</mtext></mfrac><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="132"><i>Precision</i>越大说明算法越能把测试集中的节点对排在前面,即算法预测能力越好.</p>
                </div>
                <div class="p1">
                    <p id="133">为了验证本文方法的预测性能,对比方法如下:Spy<citation id="254" type="reference"><link href="210" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>、SemiPUclus<citation id="255" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、基于概率差的PU模型(Probabilistic Gap PU Model, PGPU)<citation id="256" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>、基于单分类SVM的方法(One-class SVM)<citation id="257" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>.选择到可靠负例后,上述方法均对正例、可靠负例构成的训练集进行监督学习,得到最终的链接预测分类器.</p>
                </div>
                <div class="p1">
                    <p id="134">实验从原始网络中存在的链接中取30%的链接构成测试网络,其余部分构成训练网络.根据训练网络计算节点对间的特征, 训 练 网 络中存在链接的节点对作为正例,训练网络中不存在链接的节点对作为无标记样本,测试网络中存在链接的节点对作为测试样本.</p>
                </div>
                <div class="p1">
                    <p id="135">在保证训练网络连通性的情况下随机对网络进行5次划分,最终结果取平均值和标准差.实验在Matlab环境下实现,RNEN中的子分类器及链接预测分类器分别选择SVM、LR、NB和决策树(Decision Tree, DT),子分类器个数设为10.</p>
                </div>
                <div class="p1">
                    <p id="136">不同方法在4个数据集上的AUC值如表4所示,不同方法在4个数据集上的Precision值如表5所示,<i>L</i>的取值等于测试集样本的数量.</p>
                </div>
                <div class="area_img" id="137">
                                            <p class="img_tit">
                                                <b>表4 不同方法在4个数据集上的AUC值对比</b>
                                                    <br />
                                                Table 4 AUC comparison of different algorithms on 4 datasets
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909004_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/MSSB201909004_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909004_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表4 不同方法在4个数据集上的AUC值对比" src="Detail/GetImg?filename=images/MSSB201909004_13700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="138">
                                            <p class="img_tit">
                                                <b>表5 不同算法在4个数据集上的Precision值</b>
                                                    <br />
                                                Table 5 Precision comparison of different algorithms on 4 datasets
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201909004_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/MSSB201909004_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201909004_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表5 不同算法在4个数据集上的Precision值" src="Detail/GetImg?filename=images/MSSB201909004_13800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="139">由表4可见,<i>RNEN</i>在各数据集上均得到最优的<i>AUC</i>值.尤其在使用<i>SVM</i>时,<i>RNEN</i>的<i>AUC</i>值在4个数据集上均为第一.实验表明,在正例和<i>RNEN</i>所选的可靠负例上进行学习,能得到预测效果更优的链接预测分类器.</p>
                </div>
                <div class="p1">
                    <p id="140"><i>SemiPUclus</i>和<i>Spy</i>的<i>AUC</i>值在多数情况下标准差较大,表明二者的预测效果不稳定,这是由于在选择可靠负例的过程中两种方法都存在一定的随机性.<i>SemiPUclus</i>在使用聚类的方法时,聚类数目和初始类中心的选择会影响聚类结果,而<i>Spy</i>在选择间谍样本时也有一定的随机性.因此,这两种方法选择的可靠负例并不稳定,对预测结果有所影响.虽然<i>RNEN</i>在采样过程中也有一定的随机性,但通过多次采样能降低影响.在<i>P</i>2<i>P</i>、<i>CollegeMSG</i>数据集上,各算法的<i>AUC</i>值均有所降低,但<i>RNEN</i>的<i>AUC</i>值仍高于其它方法,表明本文的链接预测算法在不同网络中具有一定的适应性.</p>
                </div>
                <div class="p1">
                    <p id="141">由表5可见,<i>RNEN</i>在两个数据集上能得到最优的<i>Precision</i>值,在两个数据集上仅略低于最优结果.使用<i>LR</i>、<i>DT</i>作为分类器时,<i>RNEN</i>在各数据集上的<i>Precision</i>值排名均为第一.<i>Top</i>-<i>L</i>考虑前L个样本的预测准确度,这表明<i>RNEN</i>在一定程度上能改善链接预测的准确率,进一步验证<i>RNEN</i>的有效性.</p>
                </div>
                <h3 id="142" name="142" class="anchor-tag">3 结 束 语</h3>
                <div class="p1">
                    <p id="143">本文将链接预测问题转化为<i>PU</i>学习的问题,针对其中缺乏负例,并且无标记样本数量远大于正例数量的问题,提出从网络中选择可靠负例的方法.方法结合社区结构,利用集成思想,有效解决从大量无标记样本中选择可靠负例的问题,在正例和所选可靠负例上进行监督学习,最终得到预测分类器.实验表明本文方法能得到更准确的链接预测分类器.</p>
                </div>
                <div class="p1">
                    <p id="144">本文方法主要解决面向无向网络的链接预测问题,实际中存在许多有向网络,如<i>Twitter</i>、微博等,并且这些网络中还包含节点属性、文本、标签等多种非拓扑信息.今后将进一步设计面向有向网络的可靠负例选择方法,通过考虑网络中包含的多种非拓扑信息以提升<i>PU</i>学习的链接预测结果.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="184">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DKDX201005006&amp;v=MDg3ODdUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnkva1Zyck5JU2JQZHJHNEg5SE1xbzlGWW9RS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 吕琳媛.复杂网络链路预测.电子科技大学学报,2010,39(5):651-661.(LÜ L Y.Link Prediction on Complex Networks.Journal of University of Electronic Science and Technology of China,2010,39(5):651-661.)
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ201902007&amp;v=MjY5NDJ2U2RMRzRIOWpNclk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5L2tWcnJOTHk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 王智强,梁吉业,李茹.基于信息融合的概率矩阵分解链路预测方法.计算机研究与发展,2019,56(2):306-318.(WANG Z Q,LIANG J Y,LI R.Probability Matrix Factorization for Link Prediction Based on Information Fusion.Journal of Computer Research and Development,2019,56(2):306-318.)
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDC9459C7486DA8C865BE6E12142D9FC3&amp;v=MTIzMzFPZmNmTEY5WEpwdnhDWU9NSmVBMHh2QjRWNzAwSVRncmpyaE14ZThhZE04bWNDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N202eGEwPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> WANG Z Q,LIANG J Y,LI R.A Fusion Probability Matrix Factorization Framework for Link Prediction.Knowledge-Based Systems,2018,159:72-85.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFXG201501001&amp;v=MzE4ODBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5L2tWcnJOTHl2VGFiRzRIOVRNcm85RlpZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> WANG P,XU B W,WU Y R,et al.Link Prediction in Social Networks:the State-of-the-Art.Science China(Information Sciences),2015,58(1).DOI:10.1007/s11432-014-5237-y.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Vertex collocation profiles:subgraph counting for link analysis and prediction">

                                <b>[5]</b> LICHTENWALTER R N,CHAWIA N V.Vertex Collocation Profiles:Subgraph Counting for Link Analysis and Prediction // Proc of the 21th International Conference on World Wide Web.New York,USA:ACM,2012:1019-1028.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting positive and negative links in online social networks">

                                <b>[6]</b> LESKOVEC J,HUTTENLOCHER D,KLEINBERG J.Predicting Positive and Negative Links in Online Social Networks // Proc of the 19th International Conference on World Wide Web.New York,USA:ACM,2010:641-650.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exploiting longer cycles for link prediction in signed networks">

                                <b>[7]</b> CHIANG K Y,NATARAJAN N,TEWARI A,et al.Exploiting Longer Cycles for Link Prediction in Signed Networks // Proc of the 20th ACM International Conference on Information and Knowledge Management.New York,USA:ACM,2011:1157-1162.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supervised link prediction in weighted networks">

                                <b>[8]</b> DE SÁHIALLY R,PRUDÉNCIO R B C.Supervised Link Prediction in Weighted Networks // Proc of the 21th International Joint Conference on Neural Networks.Washington,USA:IEEE,2011:2281-2288.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhance Link Prediction in Online Social Networks Using Similarity Metrics,Sampling,and Classification">

                                <b>[9]</b> CHUAN P M,GIAP C N,LE SON H,et al.Enhance Link Prediction in Online Social Networks Using Similarity Metrics,Sampling,and Classification // BHATEJA V,LE NGUYEN N,NGUYEN N G,et al.,eds.Information Systems Design and Intelligent Applications.Berlin,Germany:Springer,2018:823-833.
                            </a>
                        </p>
                        <p id="202">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Semi-supervised Penalized Output Kernel Regression for Link Prediction">

                                <b>[10]</b> BROUARD C,D′ALCHÉ-BUC F,SZAFRANSKI M.Semi-supervised Penalized Output Kernel Regression for Link Prediction // Proc of the 28th International Conference on Machine Learning.New York,USA:ACM,2011:593-600.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Link Propagation:A Fast Semi-Supervised Learning Algorithm for Link Prediction">

                                <b>[11]</b> KASHIMA H,KATO T,YAMANISHI Y,et al.Link Propagation:A Fast Semi-supervised Learning Algorithm for Link Prediction // Proc of the 9th SIAM International Conference on Data Mining.Philadelphia,USA:SIAM,2009:1100-1111.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=LPI-ETSLP:IncRNA-Protein Interaction Prediction Using Eigenvalue Transformation-Based Semi-supervised Link Prediction">

                                <b>[12]</b> HU H,ZHU C Y,AI H X,et al.LPI-ETSLP:IncRNA-Protein Interaction Prediction Using Eigenvalue Transformation-Based Semi-supervised Link Prediction.Molecular BioSystems,2017,13(9):1781-1787.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PAC learning from positive statistical queries">

                                <b>[13]</b> DENIS F.PAC Learning from Positive Statistical Queries // Proc of the 9th International Conference on Algorithmic Learning Theory.Berlin,Germany:Springer,1998:112-126.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Partially supervised classification of text documents">

                                <b>[14]</b> LIU B,LEE W S,YU P S,et al.Partially Supervised Classification of Text Documents // Proc of the 19th International Conference on Machine Learning.San Francisco,USA:Morgan Kaufmann,2002:387-394.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering-Based Method for Positive and Unlabeled Text Categorization Enhanced by Improved TFIDF">

                                <b>[15]</b> LU L,TAO P.Clustering-Based Method for Positive and Unlabeled Text Categorization Enhanced by Improved TFIDF.Journal of Information Science and Engineering,2014,30(5):1463-1481.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=PEBL:Positive example based learning for web page classification using SVM">

                                <b>[16]</b> YU H,HAN J W,CHANG K C C.PEBL:Positive Example Ba-sed Learning for Web Page Classification Using SVM // Proc of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.New York,USA:ACM,2002:239-248.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A link prediction approach using semi-supervised learning in dynamic networks">

                                <b>[17]</b> ZENG Z Z,CHEN K J,ZHANG S B,et al.A Link Prediction Approach Using Semi-supervised Learning in Dynamic Networks // Proc of the 6th International Conference on Advanced Computational Intelligence.Washington,USA:IEEE,2013:276-280.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Relation Prediction Method Based on PU Learning">

                                <b>[18]</b> PENG G J,CHEN K J,XUE S J,et al.A Relation Prediction Method Based on PU Learning // Proc of the 12th International Conference on Intelligent Systems and Knowledge Engineering.Washington,USA:IEEE,2017.DOI:10.1109/ISKE.2017.8258752.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFDEC6FD6ECC485AE16402459199FD5F1&amp;v=MDYwMTB0OVNudm5wUk04Y01UZ1FNeWVDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVORmh3N202eGEwPU5pZk9mY1hNYTZMSzJmdERFWmg4Q0hROHZtTVM3RA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> GUO H X,LI Y J,SHANG J,et al.Learning from Class-Imbalanced Data:Review of Methods and Applications.Expert Systems with Applications,2017,73:220-239.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339482&amp;v=MjM2MDdsVkw3TkpWcz1OajdCYXJPNEh0SE5ySXhNWU9NTlkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RkNI&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> BREIMAN L.Bagging Predictors.Machine Learning,1996,24(2):123-140.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Community Detection:Comparison of State of the Art Algorithms">

                                <b>[21]</b> MOTHE J,MKHITARYAN K,HAROUTUNIAN M.Community Detection:Comparison of State of the Art Algorithms // Proc of the 11th Conference on Computer Science and Information Technologies.Washington,USA:IEEE,2017:125-129.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast Unfolding of Communities in Large Networks[C/OL]">

                                <b>[22]</b> BLONDEL V D,GUILLAUME J L,LAMBIOTTE R,et al.Fast Unfolding of Communities in Large Networks[C/OL].[2019-03-01].https://arxiv.org/pdf/0803.0476.pdf.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Instance-Dependent PU Learning by Bayesian Optimal Relabeling[C/OL]">

                                <b>[23]</b> HE F X,LIU T L,WEBB G I,et al.Instance-Dependent PU Learning by Bayesian Optimal Relabeling[C/OL].[2019-03-01].https://arxiv.org/pdf/1808.02180.pdf.
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=One-class SVMs for document classification">

                                <b>[24]</b> MANEVITZ L M,YONSEF M.One-Class SVMs for Document Classification.Journal of Machine Learning Research,2001,2:139-154.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201909004" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201909004&amp;v=MTg1MTR6cXFCdEdGckNVUkxPZVplUm5GeS9rVnJyTktEN1liTEc0SDlqTXBvOUZZSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
