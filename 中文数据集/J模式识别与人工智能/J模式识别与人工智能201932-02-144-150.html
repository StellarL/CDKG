<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131439437686250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dMSSB201902006%26RESULT%3d1%26SIGN%3d8MY0lKsWgeAg%252frqd0D%252ff37vJxAg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201902006&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=MSSB201902006&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201902006&amp;v=MDkxNTh0R0ZyQ1VSTE9lWmVSbkZ5em5VTHpLS0Q3WWJMRzRIOWpNclk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#48" data-title="1 相关知识 ">1 相关知识</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="2 自适应加权在线超限学习机 ">2 自适应加权在线超限学习机</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#163" data-title="3 仿真实验及结果分析 ">3 仿真实验及结果分析</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#185" data-title="4 结 束 语 ">4 结 束 语</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#119" data-title="图1 在数据流发生概念漂移时2种方法对比">图1 在数据流发生概念漂移时2种方法对比</a></li>
                                                <li><a href="#173" data-title="&lt;b&gt;表1&lt;/b&gt;&lt;b&gt;实验数据集细节&lt;/b&gt;"><b>表1</b><b>实验数据集细节</b></a></li>
                                                <li><a href="#176" data-title="&lt;b&gt;表2&lt;/b&gt;&lt;b&gt;隐层节点个数、初始块和序列块大小&lt;/b&gt;"><b>表2</b><b>隐层节点个数、初始块和序列块大小</b></a></li>
                                                <li><a href="#180" data-title="&lt;b&gt;表3&lt;/b&gt;&lt;b&gt;分类结果对比&lt;/b&gt;"><b>表3</b><b>分类结果对比</b></a></li>
                                                <li><a href="#183" data-title="图2 AWO-ELM和WOS-ELM在12个数据集上TPR和 TNR对比">图2 AWO-ELM和WOS-ELM在12个数据集上TPR和 TNR对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="10">


                                    <a id="bibliography_1" title=" HE H B, GARCIA E A. Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering, 2009, 21 (9) : 1263-1284." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning from Imbalanced Data">
                                        <b>[1]</b>
                                         HE H B, GARCIA E A. Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering, 2009, 21 (9) : 1263-1284.
                                    </a>
                                </li>
                                <li id="12">


                                    <a id="bibliography_2" title=" CHAWLA N V, BOWYER K W, HALL L O, &lt;i&gt;et al&lt;/i&gt;. SMOTE: Synthetic Minority Over-Sampling Technique. Journal of Artificial Intelligence Research, 2002, 16 (1) : 321-357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">
                                        <b>[2]</b>
                                         CHAWLA N V, BOWYER K W, HALL L O, &lt;i&gt;et al&lt;/i&gt;. SMOTE: Synthetic Minority Over-Sampling Technique. Journal of Artificial Intelligence Research, 2002, 16 (1) : 321-357.
                                    </a>
                                </li>
                                <li id="14">


                                    <a id="bibliography_3" title=" MALDONADO S, MONTECINOS C. Robust Classification of Imba-lanced Data Using One-Class and Two-Class SVM-Based Multiclassifiers. Intelligent Data Analysis, 2014, 18 (1) : 95-112." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust classification of imbalanced datausing one-class and two-class SVM-based multiclassifiers">
                                        <b>[3]</b>
                                         MALDONADO S, MONTECINOS C. Robust Classification of Imba-lanced Data Using One-Class and Two-Class SVM-Based Multiclassifiers. Intelligent Data Analysis, 2014, 18 (1) : 95-112.
                                    </a>
                                </li>
                                <li id="16">


                                    <a id="bibliography_4" title=" ZHU W X, ZHONG P. A New One-Class SVM Based on Hidden Information. Knowledge-Based Systems, 2014, 60: 35-43." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300036228&amp;v=MjI0MTl3WmVadUh5am1VTGJJSkZ3WGFSQT1OaWZPZmJLOEh0UE5ySTlGWk9nSkRuNHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         ZHU W X, ZHONG P. A New One-Class SVM Based on Hidden Information. Knowledge-Based Systems, 2014, 60: 35-43.
                                    </a>
                                </li>
                                <li id="18">


                                    <a id="bibliography_5" title=" ZONG W W, HUANG G B, CHEN Y Q. Weighted Extreme Lear-ning Machine for Imbalance Learning. Neurocomputing, 2013, 101:229-242." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600369807&amp;v=MDE2NjRRSC9pclJkR2VycVFUTW53WmVadUh5am1VTGJJSkZ3WGFSQT1OaWZPZmJLOEh0RE1xWTlGWiswR0JIdytvQk1UNlQ0UA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         ZONG W W, HUANG G B, CHEN Y Q. Weighted Extreme Lear-ning Machine for Imbalance Learning. Neurocomputing, 2013, 101:229-242.
                                    </a>
                                </li>
                                <li id="20">


                                    <a id="bibliography_6" title=" WANG S, MINKU L L, YAO X. A Learning Framework for Online Class Imbalance Learning // Proc of the IEEE Symposium on Computational Intelligence and Ensemble Learning. Washington, USA: IEEE, 2013: 36-45." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A learning framework for online class imbalance learning">
                                        <b>[6]</b>
                                         WANG S, MINKU L L, YAO X. A Learning Framework for Online Class Imbalance Learning // Proc of the IEEE Symposium on Computational Intelligence and Ensemble Learning. Washington, USA: IEEE, 2013: 36-45.
                                    </a>
                                </li>
                                <li id="22">


                                    <a id="bibliography_7" title=" LU C B, KE H F, ZHANG G Y, &lt;i&gt;et al&lt;/i&gt;. An Improved Weighted Extreme Learning Machine for Imbalanced Data Classification[J/OL]. [2018-06-25]. https://link.springer.com/content/pdf/10.1007%2Fs12293-017-0236-3.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Improved Weighted Extreme Learning Machine for Imbalanced Data Classification">
                                        <b>[7]</b>
                                         LU C B, KE H F, ZHANG G Y, &lt;i&gt;et al&lt;/i&gt;. An Improved Weighted Extreme Learning Machine for Imbalanced Data Classification[J/OL]. [2018-06-25]. https://link.springer.com/content/pdf/10.1007%2Fs12293-017-0236-3.pdf.
                                    </a>
                                </li>
                                <li id="24">


                                    <a id="bibliography_8" title=" NIU W J, FENG Z K, CHENG C T, &lt;i&gt;et al&lt;/i&gt;. Forecasting Daily Runoff by Extreme Learning Machine Based on Quantum-Behaved Particle Swarm Optimization. Journal of Hydrologic Engineering, 2018, 23 (3) . DOI: 10.1061/ (ASCE) HE.1943-5584.0001625." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Forecasting Daily Runoff by Extreme Learning Machine Based on Quantum-Behaved Particle Swarm Optimization">
                                        <b>[8]</b>
                                         NIU W J, FENG Z K, CHENG C T, &lt;i&gt;et al&lt;/i&gt;. Forecasting Daily Runoff by Extreme Learning Machine Based on Quantum-Behaved Particle Swarm Optimization. Journal of Hydrologic Engineering, 2018, 23 (3) . DOI: 10.1061/ (ASCE) HE.1943-5584.0001625.
                                    </a>
                                </li>
                                <li id="26">


                                    <a id="bibliography_9" title=" ZHANG Y, WANG Y, ZHOU G X, &lt;i&gt;et al&lt;/i&gt;. Multi-kernel Extreme Learning Machine for EEG Classification in Brain-Computer Interfaces. Expert Systems with Applications, 2018, 96: 302-310." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-kernel extreme learning machine for EEG classification in brain-computer interfaces">
                                        <b>[9]</b>
                                         ZHANG Y, WANG Y, ZHOU G X, &lt;i&gt;et al&lt;/i&gt;. Multi-kernel Extreme Learning Machine for EEG Classification in Brain-Computer Interfaces. Expert Systems with Applications, 2018, 96: 302-310.
                                    </a>
                                </li>
                                <li id="28">


                                    <a id="bibliography_10" title=" 刘阳阳, 张骏, 高欣健, 等.基于卷积递归神经网络和核超限学习机的3D目标识别.模式识别与人工智能, 2017, 30 (12) : 1091-1099. (LIU Y Y, ZHANG J, GAO X J, &lt;i&gt;et al&lt;/i&gt;. 3D Object Recognition via Convolutional-Recursive Neural Network and Kernel Extreme Learning Machine. Pattern Recognition and Artificial Intelligence, 2017, 30 (12) : 1091-1099.) " target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201712005&amp;v=MTA2MDRSTE9lWmVSbkZ5em5VTHpLS0Q3WWJMRzRIOWJOclk5RllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         刘阳阳, 张骏, 高欣健, 等.基于卷积递归神经网络和核超限学习机的3D目标识别.模式识别与人工智能, 2017, 30 (12) : 1091-1099. (LIU Y Y, ZHANG J, GAO X J, &lt;i&gt;et al&lt;/i&gt;. 3D Object Recognition via Convolutional-Recursive Neural Network and Kernel Extreme Learning Machine. Pattern Recognition and Artificial Intelligence, 2017, 30 (12) : 1091-1099.) 
                                    </a>
                                </li>
                                <li id="30">


                                    <a id="bibliography_11" title=" LIANG N Y, HUANG G B, SARATCHANDRAN P, &lt;i&gt;et al&lt;/i&gt;. A Fast and Accurate Online Sequential Learning Algorithm for Feedforward Networks. IEEE Transactions on Neural Networks, 2006, 17 (6) : 1411-1423." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A fast and accurate online sequential learning algorithm for feedforward networks">
                                        <b>[11]</b>
                                         LIANG N Y, HUANG G B, SARATCHANDRAN P, &lt;i&gt;et al&lt;/i&gt;. A Fast and Accurate Online Sequential Learning Algorithm for Feedforward Networks. IEEE Transactions on Neural Networks, 2006, 17 (6) : 1411-1423.
                                    </a>
                                </li>
                                <li id="32">


                                    <a id="bibliography_12" title=" MIRZA B, LIN Z P, TOH K A. Weighted Online Sequential Extreme Learning Machine for Class Imbalance Learning. Neural Processing Letters, 2013, 38 (3) : 465-486." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13120400000960&amp;v=MTc3ODhlcnFRVE1ud1plWnVIeWptVUxiSUpGd1hhUkE9Tmo3QmFySzdIOVBNcTQ5RlpPc1BCWG81b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         MIRZA B, LIN Z P, TOH K A. Weighted Online Sequential Extreme Learning Machine for Class Imbalance Learning. Neural Processing Letters, 2013, 38 (3) : 465-486.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=MSSB" target="_blank">模式识别与人工智能</a>
                2019,32(02),144-150 DOI:10.16451/j.cnki.issn1003-6059.201902006            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">面向不平衡数据流的自适应加权在线超限学习机算法</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%A2%85%E9%A2%96&amp;code=08551566&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">梅颖</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E8%AF%9A%E6%B3%A2&amp;code=07930051&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢诚波</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%BD%E6%B0%B4%E5%AD%A6%E9%99%A2%E5%B7%A5%E5%AD%A6%E9%99%A2&amp;code=0002087&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">丽水学院工学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>一般的在线学习算法对不平衡数据流的分类识别会遇到较大困难, 特别是当数据流发生概念漂移时, 对其进行分类会变得更困难.文中提出面向不平衡数据流的自适应加权在线超限学习机算法, 自动调整实时到达的训练样本的惩罚参数, 达到在线学习不平衡数据流的目的.文中算法可以适用于不同偏斜程度的静态数据流的在线学习和发生概念漂移时数据流的在线学习.理论分析和在多个真实数据流上的实验表明文中算法的正确性和有效性.</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">不平衡学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%95%B0%E6%8D%AE%E6%B5%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">数据流;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">在线学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E6%9D%83%E8%B6%85%E9%99%90%E5%AD%A6%E4%B9%A0%E6%9C%BA%20(W-ELM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加权超限学习机 (W-ELM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A6%82%E5%BF%B5%E6%BC%82%E7%A7%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">概念漂移;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    梅颖, 硕士, 副教授, 主要研究方向为模式识别.E-mail:ymei@lsu.edu.cn.
;
                                </span>
                                <span>
                                    *卢诚波, 博士, 教授, 主要研究方向为机器学习、数据挖掘.E-mail:lu.chengbo@aliyun.com.;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-08-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>浙江省自然科学基金项目 (No.LY18F030003);</span>
                                <span>丽水市高层次人才项目 (2017RC01) 资助;</span>
                    </p>
            </div>
                    <h1>Adaptive Weighted Online Extreme Learning Machine for Imbalance Data Steam</h1>
                    <h2>
                    <span>MEI Ying</span>
                    <span>LU Chengbo</span>
            </h2>
                    <h2>
                    <span>School of Engineering, Lishui University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>It is problematic to classify data stream with imblanced class distributions for general online learning algorithms, especially in case of concept drift. In this paper, an adaptive weighted online extreme learning machine (AWO-ELM) is developed for imbalance data stream. AWO-ELM is an online learning method and it alleviates the class imbalance problem in chunk-by-chunk learning. Instead of adopting fixed weights, an efficient weight selection strategy is proposed to obtain better classification performance, and thus it can be applied to the task of learning static data stream with different imbalance ratio and the task of online learning with concept drift. The theoretical analysis and experimental results of several real data stream show that AWO-ELM obtains comparable or better classification performance than competing methods.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Imbalance%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Imbalance Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Data%20Stream&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Data Stream;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Online%20Learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Online Learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Weighted%20Extreme%20Learning%20Machine%20(W-ELM)%20&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Weighted Extreme Learning Machine (W-ELM) ;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Concept%20Drift&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Concept Drift;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                            <b>Author：</b>
                                                        <span>
                                    MEI Ying, master, associate professor. Her research interests include pattern recognition.
;
                                </span>
                                <span>
                                    LU Chengbo, Ph.D., professor. His research interests include machine learning and data mining.;
                                </span>
                    </p>
                                    <p><b>Received：</b> 2018-08-29</p>
                                    <p>
                            <b>Fund：</b>
                                                        <span>Supported by Natural Science Foundation of Zhejiang Province (No.LY18F030003);</span>
                                <span>Foundation of High-Level Talents in Lishui City (2017RC01);</span>
                    </p>
            </div>


        <!--brief start-->
                        <div class="p1">
                    <p id="42">在线学习是近年来数据挖掘和机器学习领域的一个研究热点, 可以根据线上反馈的数据流, 实时快速地进行模型调整, 使模型能及时反映线上的变化, 提高线上预测的准确率.相比学习静态数据集的数据挖掘算法, 数据流上的在线学习算法可以处理两个重要的挑战:1) 数据流中存在不平衡的类分布;2) 当某些数据产生的环境因素发生变化时, 新的数据流的分布规律将发生变化, 产生的概念也发生改变, 而这时利用历史数据建立的模型或概念将不适合对新数据分类或新事物的认识, 旧模型、旧概念就必须发生与时俱进的改变.这种数据流中数据分布随时间发生改变, 概念发生改变的现象为概念漂移.</p>
                </div>
                <div class="p1">
                    <p id="44">在许多数据流当中存在类分布不平衡的情形, 如计算机网络中的入侵检测、控制监控系统的故障诊断等, 在这些事件当中, 一些类中的数据比另外一些类中的数据更少或更难获得, 称这种情况为类不平衡.在二分类问题中, 通常把样本数量较多的类称为负类 (多数类) , 样本数量较少的类称为正类 (少数类) .对于不平衡数据流的学习, 由于在大量、连续的数据中, 少数类样本得不到足够的学习, 许多在线学习算法效果不佳<citation id="201" type="reference"><link href="10" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>.</p>
                </div>
                <div class="p1">
                    <p id="45">目前, 对不平衡学习的研究主要集中在离线算法上, 如数据层面上对数据集进行重采样, 使其适应标准的学习算法, 其中使用较多的过采样方法是合成少数类过采样技术 (Synthetic Minority Oversamp-ling Technique, SMOTE) <citation id="202" type="reference"><link href="12" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 通过内插方式合成少数类样本.算法层面的研究是指改进学习算法, 使其适用于不平衡数据集.在这类方法中, 较常用的是单类分类器方法<citation id="204" type="reference"><link href="14" rel="bibliography" /><link href="16" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>和代价敏感学习.加权超限学习机 (Weighted Extreme Learning Machine, WELM) <citation id="203" type="reference"><link href="18" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>是一种代价敏感学习模型, 它改进超限学习机 (Extreme Learning Machine, ELM) , 根据各类样本的数量比例, 赋予少数类样本更大的惩罚参数, 以提高少数类样本的分类正确率, 并且学习过程一次性完成, 不需迭代, 效率更高.</p>
                </div>
                <div class="p1">
                    <p id="46">对于在线算法, 更大的挑战是适应数据流中潜在概念的变化或在非稳定环境下的学习, 即适应数据流中类不平衡状态的动态变化<citation id="205" type="reference"><link href="20" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>.在许多场景下, 数据的概率分布通常随时间变化, 如大型商场中顾客的购物倾向会随时间变化, 网络安全中对入侵检测也会因用户不同而变化, 工业生产中有问题的产品共性的问题特征也不断变化.许多在线算法未考虑数据流中的概念变化问题, 当发生概念漂移的速度很快时, 原先分类器模型可能很快变得不再反映数据的分布, 或延迟反映真实的数据分布, 这时, 缓存中的分类器不但不能提供有用的信息, 甚至会恶化最后的结果.</p>
                </div>
                <div class="p1">
                    <p id="47">本文在加权超限学习机的基础上, 设计针对不平衡数据流, 应对概念漂移的自适应加权在线学习算法 (Adaptive Weighted Online ELM, AWO-ELM) , 自动调整实时到达的训练样本的惩罚参数, 达到在线学习不平衡数据流的目的.文中算法可以适用于不同偏斜程度的静态数据流的在线学习和发生概念漂移时数据流的在线学习.理论分析和在多个真实数据流上的实验表明本文算法的正确性和有效性.</p>
                </div>
                <h3 id="48" name="48" class="anchor-tag">1 相关知识</h3>
                <div class="p1">
                    <p id="49">ELM是一种单隐层前馈神经网络学习算法, 网络的输入权和隐层偏置为随机给定, 通过最小二乘法计算得到输出权, 具有执行过程简单、运行速度较快、泛化性能较好等特点, 已广泛应用到模式分类、天气预报、特征选取, 脑电信号识别、3D目标识别等各个领域<citation id="206" type="reference"><link href="22" rel="bibliography" /><link href="24" rel="bibliography" /><link href="26" rel="bibliography" /><link href="28" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>, 均取得较好效果.</p>
                </div>
                <div class="p1">
                    <p id="50">ELM与其它神经网络学习算法的主要区别在于隐层节点为随机产生, 训练样本<b><i>x</i></b>的隐层输出表示为一个行向量</p>
                </div>
                <div class="p1">
                    <p id="51" class="code-formula">
                        <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>h</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mo stretchy="false">[</mo><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>, </mo><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mn>2</mn></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo>, </mo><mo>⋯</mo><mo>, </mo><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>L</mi></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mi>L</mi></msub><mo>, </mo><mi mathvariant="bold-italic">x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="52">其中<b><i>a</i></b><sub><i>j</i></sub>, <i>b</i><sub><i>j</i></sub>, <i>j</i>=1, 2, …, <i>L</i>为随机给出的第<i>j</i>个隐层节点的学习参数, <i>G</i> (<b><i>x</i></b>) 为激励函数.给定<i>N</i>个训练样本 (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>t</i></b><sub><i>i</i></sub>) , 单隐层前馈神经网络的数学模型</p>
                </div>
                <div class="p1">
                    <p id="53"><b><i>H</i></b><i>β</i>=<b><i>T</i></b>.      (1) </p>
                </div>
                <div class="p1">
                    <p id="54">其中</p>
                </div>
                <div class="p1">
                    <p id="55"><b><i>H</i></b>=[<i>h</i> (<b><i>x</i></b><sub>1</sub>) , <i>h</i> (<b><i>x</i></b><sub>2</sub>) , …, <i>h</i> (<b><i>x</i></b><sub><i>N</i></sub>) ]<sup>T</sup></p>
                </div>
                <div class="p1">
                    <p id="56">为隐层输出矩阵, <i>β</i>为输出权矩阵, <b><i>T</i></b>为目标矩阵.由此可得</p>
                </div>
                <div class="p1">
                    <p id="57"><i>β</i>= (<b><i>H</i></b><sup>T</sup><b><i>H</i></b>) <sup>-1</sup><b><i>H</i></b><sup>T</sup><b><i>T</i></b>.      (2) </p>
                </div>
                <div class="p1">
                    <p id="58">但在面对不平衡数据集时, 和其它分类算法一样, ELM分类器也存在分类时倾向于多数类样本的错误倾向.为了适用于不平衡数据集, 文献<citation id="207" type="reference">[<a class="sup">5</a>]</citation>中的加权超限学习机将式 (2) 改进为</p>
                </div>
                <div class="p1">
                    <p id="59"><i>β</i>= (<b><i>H</i></b><sup>T</sup><b><i>WH</i></b>) <sup>-1</sup><b><i>H</i></b><sup>T</sup><b><i>WT</i></b>,      (3) </p>
                </div>
                <div class="p1">
                    <p id="60">其中<b><i>W</i></b>为由对应于每个训练样本的惩罚参数构成的<i>N</i> (训练样本个数) 阶对角矩阵.文献<citation id="208" type="reference">[<a class="sup">9</a>]</citation>中取<b><i>W</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="61" class="code-formula">
                        <mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mo>#</mo><mo stretchy="false"> (</mo><mi>q</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></mfrac><mo>, </mo><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="62"><i>w</i><sub><i>ii</i></sub>为对应于样本<b><i>x</i></b><sub><i>i</i></sub>的惩罚参数, # (<i>q</i><sub><i>i</i></sub>) 为类<i>q</i><sub><i>i</i></sub>中的样本个数.因此, 相比多数类样本, 少数类样本将获得更大的惩罚参数, 从而纠正ELM面对不平衡数据集时的错误分类倾向.特别地, 当<b><i>W</i></b>为单位矩阵, 即赋予每个不同类的样本相同的惩罚参数时, 式 (3) 退化为式 (2) .</p>
                </div>
                <div class="p1">
                    <p id="63">但是在在线学习中, 数据通常呈现大量、连续到来的特点, 而ELM及WELM无法从数据流中挖掘潜在的知识, 因此Liang等<citation id="209" type="reference"><link href="30" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出在线超限学习机算法 (Online Sequential ELM, OS-ELM) .设</p>
                </div>
                <div class="p1">
                    <p id="64" class="code-formula">
                        <mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mi mathvariant="bold-italic">Η</mi><msubsup><mrow></mrow><mn>0</mn><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">β</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>0</mn><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><msubsup><mrow></mrow><mn>0</mn><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">Η</mi><msubsup><mrow></mrow><mn>0</mn><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="65">其中, <b><i>H</i></b><sub>0</sub>为初始训练样本集的隐层输出矩阵, <b><i>T</i></b><sub>0</sub>为初始训练样本集对应的目标矩阵, <i>β</i><sub>0</sub>为初始训练样本集对应的输出权矩阵.设<b><i>H</i></b><sub><i>k</i>+1</sub>为数据流中第<i>k</i>+1块到达的训练样本对应的隐层输出矩阵, 设</p>
                </div>
                <div class="p1">
                    <p id="66"><b><i>K</i></b><sub><i>k</i>+1</sub>=<b><i>K</i></b><sub><i>k</i></sub>+<b><i>H</i></b><sup>T</sup><sub><i>k</i>+1</sub><b><i>H</i></b><sub><i>k</i>+1</sub>, </p>
                </div>
                <div class="p1">
                    <p id="67">则</p>
                </div>
                <div class="p1">
                    <p id="68"><i>β</i><sup> (<i>k</i>+1) </sup>=<i>β</i><sup> (<i>k</i>) </sup>+<b><i>K</i></b><mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml><b><i>H</i></b><sup>T</sup><sub><i>k</i>+1</sub> (<b><i>T</i></b><sub><i>k</i>+1</sub>-<b><i>H</i></b><sub><i>k</i>+1</sub><i>β</i><sup> (<i>k</i>) </sup>) ,      (4) </p>
                </div>
                <div class="p1">
                    <p id="70">其中<b><i>T</i></b><sub><i>k</i>+1</sub>为数据流中第<i>k</i>+1块到达的训练样本对应的目标矩阵.根据数据流中新到的训练样本, 利用式 (4) , 输出权矩阵由<i>β</i><sup> (<i>k</i>) </sup>调整为<i>β</i><sup> (<i>k</i>+1) </sup>, 使模型及时反映线上的变化.</p>
                </div>
                <div class="p1">
                    <p id="71">为了将OS-ELM用于不平衡数据集的在线学习, Mirza等<citation id="210" type="reference"><link href="32" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>改进OS-ELM, 提出加权在线序列超限学习机 (Weighted OS-ELM, WOS-ELM) .设</p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mi mathvariant="bold-italic">Η</mi><msubsup><mrow></mrow><mn>0</mn><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>0</mn></msub><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">β</mi><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mn>0</mn><mo stretchy="false">) </mo></mrow></msup><mo>=</mo><mrow><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Η</mi><msubsup><mrow></mrow><mn>0</mn><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo></mrow><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mi mathvariant="bold-italic">Η</mi><msubsup><mrow></mrow><mn>0</mn><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mn>0</mn></msub><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mn>0</mn></msub><mo>, </mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">其中<b><i>W</i></b><sub>0</sub>为由对应于初始训练集中每个训练样本的惩罚参数构成的<i>N</i><sub>0</sub> (初始训练集中样本个数) 阶对角矩阵.设</p>
                </div>
                <div class="p1">
                    <p id="74"><b><i>K</i></b><sub><i>k</i>+1</sub>=<b><i>K</i></b><sub><i>k</i></sub>+<b><i>H</i></b><sup>T</sup><sub><i>k</i>+1</sub><b><i>W</i></b><sub><i>k</i>+1</sub><b><i>H</i></b><sub><i>k</i>+1</sub>,      (5) </p>
                </div>
                <div class="p1">
                    <p id="75">则</p>
                </div>
                <div class="p1">
                    <p id="76"><i>β</i><sup> (<i>k</i>+1) </sup>=<i>β</i><sup> (<i>k</i>) </sup>+<b><i>K</i></b><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml><b><i>H</i></b><sup>T</sup><sub><i>k</i>+1</sub><b><i>W</i></b><sub><i>k</i>+1</sub> (<b><i>T</i></b><sub><i>k</i>+1</sub>-<b><i>H</i></b><sub><i>k</i>+1</sub><i>β</i><sup> (<i>k</i>) </sup>) ,      (6) </p>
                </div>
                <div class="p1">
                    <p id="78">其中<b><i>W</i></b><sub><i>k</i>+1</sub>为由对应于第<i>k</i>+1个序列块中的训练样本的惩罚参数构成的<i>N</i><sub><i>k</i>+1</sub> (第<i>k</i>+1个序列块中样本的个数) 阶对角矩阵.</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag">2 自适应加权在线超限学习机</h3>
                <div class="p1">
                    <p id="80">算法</p>
                </div>
                <div class="p1">
                    <p id="81">式 (5) 和式 (6) 中由于加入惩罚矩阵<b><i>W</i></b><sub><i>k</i>+1</sub>, 使OS-ELM能够学习不平衡数据流.<b><i>W</i></b><sub><i>k</i>+1</sub>的构造方式直接影响OS-ELM学习不平衡数据集的效果.WOS-ELM的<b><i>W</i></b><sub><i>k</i>+1</sub>构造如下:设<i>N</i><sub><i>i</i></sub>为第<i>i</i>个序列块中样本的个数, <i>m</i><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mo>-</mo></msubsup></mrow></math></mathml>为第<i>i</i>个序列块中负类样本的个数, <i>m</i><sup>+</sup><sub><i>i</i></sub>为第<i>i</i>个序列块中正类样本的个数, 则</p>
                </div>
                <div class="p1">
                    <p id="83"><b><i>W</i></b><sub><i>k</i>+1</sub>=diag (<i>w</i><sub><i>k</i>+1</sub>, <i>w</i><sub><i>k</i>+1</sub>, …, <i>w</i><sub><i>k</i>+1</sub>) ∈<b>R</b><sup><i>N</i><sub><i>k</i>+1</sub>×<i>N</i><sub><i>k</i>+1</sub></sup> ,      (7) </p>
                </div>
                <div class="p1">
                    <p id="84">其中</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∈</mo><mo stretchy="false">{</mo><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo></msubsup><mo>, </mo><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo>+</mo></msubsup><mo stretchy="false">}</mo><mo>, </mo><mspace width="0.25em" /><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo>-</mo></msubsup><mo>=</mo><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo>+</mo></msubsup><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>m</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>-</mo></msubsup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>m</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>+</mo></msubsup></mrow></mfrac><mspace width="0.25em" /><mo>, </mo><mspace width="0.25em" /></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86"><i>w</i><sup>-</sup><sub><i>k</i>+1</sub>为第<i>k</i>+1个序列块中负类样本的惩罚参数, <i>w</i><sup>+</sup><sub><i>k</i>+1</sub>为第<i>k</i>+1个序列块中正类样本的惩罚参数.</p>
                </div>
                <div class="p1">
                    <p id="87">上述构造将每个序列块中负类样本的惩罚参数始终取值为1, 第<i>k</i>+1个序列块中正类样本的惩罚参数取值为前<i>k</i>+1个序列块中负类样本个数总和与正类样本个数总和的比值.这种构造在数据流中的样本联合概率未发生变化时, 或者说, 各个序列块中正类样本个数与负类样本个数的比值 (不平衡率) 基本未变化时是有效的.实际上, 在这种情况下, <i>w</i><sup>+</sup><sub><i>k</i>+1</sub>取<i>w</i><sup>+</sup><sub>0</sub>也具有相同的效果.</p>
                </div>
                <div class="p1">
                    <p id="88">但数据流中的概念并非稳定不变, 经常随时间而改变, 当某些数据产生的环境因素发生变化时, 新的数据的分布规律将发生变化, 产生的概念会发生改变, 而这时利用历史数据建立的当前序列块中样本的惩罚参数很可能会延时甚至失真.假设在某个新到达的序列块中发生概念漂移, 原来的少数类和多数类在这个序列块中互换概念, 但按照式 (7) 中的构造, 如果</p>
                </div>
                <div class="p1">
                    <p id="89"><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>m</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>-</mo></msubsup><mo>&gt;</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>m</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>+</mo></msubsup></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="91">这个序列块当中新的多数类样本将获得比新的少数类样本更大的惩罚参数, 这显然是不合理的.</p>
                </div>
                <div class="p1">
                    <p id="92">实际上, 为了应对可能发生的概念漂移, 动态确定数据流中类不平衡状态的变化, 每个序列块中样本的惩罚参数应独立取值, 不受其它序列块中类分布的影响.AWO-ELM的第<i>k</i>+1个序列块的惩罚矩阵<b><i>W</i></b><sup>*</sup><sub><i>k</i>+1</sub>构造如下:由于正类和负类的概念可能会发生漂移, 所以将其中的一类称为<i>A</i>类, 另一类称为<i>B</i>类.</p>
                </div>
                <div class="p1">
                    <p id="93">设<i>N</i><sub><i>k</i>+1</sub>为第<i>k</i>+1个序列块中样本的个数, <i>m</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></math></mathml>为第<i>k</i>+1个序列块中<i>A</i>类样本的个数, <i>m</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow></math></mathml>为第<i>k</i>+1个序列块中<i>B</i>类样本的个数, 则</p>
                </div>
                <div class="p1">
                    <p id="96"><b><i>W</i></b><sup>*</sup><sub><i>k</i>+1</sub>=diag (<i>w</i><sup>*</sup><sub><i>k</i>+1</sub>, <i>w</i><sup>*</sup><sub><i>k</i>+1</sub>, …, <i>w</i><sup>*</sup><sub><i>k</i>+1</sub>) ∈<b>R</b><sup><i>N</i><sub><i>k</i>+1</sub>×<i>N</i><sub><i>k</i>+1</sub></sup> ,      (8) </p>
                </div>
                <div class="p1">
                    <p id="97">其中</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo>*</mo></msubsup><mo>∈</mo><mo stretchy="false">{</mo><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup><mo>, </mo><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup><mo stretchy="false">}</mo><mo>, </mo><mspace width="0.25em" /><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup><mo>=</mo><mn>1</mn><mo>, </mo><mspace width="0.25em" /><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup><mo>=</mo><mfrac><mrow><mi>m</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow><mrow><mi>m</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></mfrac><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99"><i>w</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></math></mathml>为第<i>k</i>+1个序列块中<i>A</i>类样本的惩罚参数, <i>w</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow></math></mathml>为第<i>k</i>+1个序列块中<i>B</i>类样本的惩罚参数.特别地, 当各个序列块中的不平衡率保持恒定时, 有</p>
                </div>
                <div class="p1">
                    <p id="102"><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>m</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow><mrow><mi>m</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></mfrac><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>m</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>-</mo></msubsup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></munderover><mi>m</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mo>+</mo></msubsup></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="104">即<b><i>W</i></b><sup>*</sup><sub><i>k</i>+1</sub>=<b><i>W</i></b><sub><i>k</i>+1</sub>.也就是说, 此时两种惩罚矩阵构造相同, 因此, AWO-ELM与WOS-ELM在数据流的类不平衡分布稳定的情况下能取得一样好的学习效果.</p>
                </div>
                <div class="p1">
                    <p id="105">实际上, 在离线学习模式下, 容易评估训练集的不平衡情况, 并且选择惩罚参数.但对于在线学习的情形, 真实的不平衡率会随时间而变化, 由于没有数据的先验知识, 很难及时捕捉真实的不平衡率.利用数据流中每个序列块中样本对惩罚参数进行独立取值, 相比利用历史样本计算惩罚参数的WOS-ELM, AWO-ELM的惩罚参数能更动态和快速地反映数据流中不平衡率的变化.</p>
                </div>
                <div class="p1">
                    <p id="106">为了检验<b><i>W</i></b><sup>*</sup><sub><i>k</i>+1</sub>的构造在数据流发生概念漂移时是否合理, 构造2个具有代表性的数据流如下.</p>
                </div>
                <div class="p1">
                    <p id="107">1) 第1步到达10个样本, 包含1个<i>A</i>类样本和9个<i>B</i>类样本;第2步到达10个样本, 包含9个<i>A</i>类样本和1个<i>B</i>类样本;…;第2<i>i</i>-1步到达10×5<sup><i>i</i>-1</sup>个样本, 包含5<sup><i>i</i>-1</sup>个<i>A</i>类样本和9×5<sup><i>i</i>-1</sup>个<i>B</i>类样本; 第2<i>i</i>步到达10×5<sup><i>i</i>-1</sup>个样本, 包含9×5<sup><i>i</i>-1</sup>个<i>A</i>类样本和5<sup><i>i</i>-1</sup>个<i>B</i>类样本, <i>i</i>=1, 2, …, 60.</p>
                </div>
                <div class="p1">
                    <p id="108">2) 前30步, 每次到达10个样本, 包含1个<i>A</i>类样本和9个<i>B</i>类样本;后30步, 每次到达10个样本, 包含9个<i>A</i>类样本和1个<i>B</i>类样本.</p>
                </div>
                <div class="p1">
                    <p id="109">在这2个数据流中, <i>A</i>类样本和<i>B</i>类样本的总个数比例均为1∶1, 第1个数据流的每步都发生概念漂移, 而第2个数据流后30步开始发生概念漂移.</p>
                </div>
                <div class="p1">
                    <p id="110">图1为2种方法在数据流发生概念漂移时惩罚参数的对比.从图中可以发现, 对于第1种情况, 虽然少数类和多数类在每个序列块中交替互换概念, 但<i>w</i><sup>+</sup><sub><i>k</i>+1</sub> (<i>A</i>类样本惩罚参数) 始终大于<i>w</i><sup>-</sup><sub><i>k</i>+1</sub> (<i>B</i>类样本惩罚参数) , 因此相比<i>A</i>类样本, <i>B</i>类样本得不到充分学习的可能性更大, 实际上, <i>A</i>类样本和<i>B</i>类样本个数的真实比例为1∶1, 此时的惩罚矩阵<b><i>W</i></b><sub><i>k</i>+1</sub>并未起到应有的作用, 对应构造的分类器分类时会偏向于<i>A</i>类样本.相比之下, <i>w</i><mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></math></mathml>和<i>w</i><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow></math></mathml>却能自动适应数据流的概念漂移, 始终赋予每个序列块中的少数类样本较大的惩罚参数、多数类样本较小的惩罚参数.对于第2种情况, 在前30步中, 数据流中的不平衡分布是静态的, 类<i>A</i>作为少数类, 此时<i>w</i><sup>+</sup><sub><i>k</i>+1</sub>=<i>w</i><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></math></mathml>, 当第31步发生概念漂移后, 类<i>A</i>变为多数类, <i>w</i><mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></math></mathml>及时做出调整, 迅速降低<i>w</i><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></math></mathml>, 而<i>w</i><sup>+</sup><sub><i>k</i>+1</sub>的下降曲线却非常缓慢, 并且<i>w</i><sup>+</sup><sub><i>k</i>+1</sub>的值始终大于<i>w</i><sup>-</sup><sub><i>k</i>+1</sub>的值, 这显然不合理.</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902006_11900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 在数据流发生概念漂移时2种方法对比" src="Detail/GetImg?filename=images/MSSB201902006_11900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 在数据流发生概念漂移时2种方法对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902006_11900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.1 Comparison of 2 methods in 2 scenarios with different concept drift of data stream</p>

                </div>
                <div class="p1">
                    <p id="120">本文算法步骤如下.</p>
                </div>
                <div class="p1">
                    <p id="121"><b>算法</b> AWO-ELM</p>
                </div>
                <div class="p1">
                    <p id="122"><b>输入</b> { (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>t</i></b><sub><i>i</i></sub>) }<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></msubsup></mrow></math></mathml>, <b><i>x</i></b><sub><i>i</i></sub>∈<b>R</b><sup><i>d</i></sup>, <b><i>t</i></b><sub><i>i</i></sub>∈<b>R</b><sup><i>q</i></sup></p>
                </div>
                <div class="p1">
                    <p id="124"><b>输出</b><i>β</i><sup> (<i>k</i>+1) </sup></p>
                </div>
                <div class="p1">
                    <p id="125">step 1 初始阶段.</p>
                </div>
                <div class="p1">
                    <p id="126">step 1.1 对于<i>N</i><sub>0</sub>个初始的训练数据{ (<b><i>x</i></b><sub><i>i</i></sub>, <b><i>t</i></b><sub><i>i</i></sub>) }<mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msubsup></mrow></math></mathml>, 选取隐层节点个数<i>L</i>, 随机设置第<i>j</i>个隐层节点的学习参数<i>a</i><sub><i>j</i></sub>, <i>b</i><sub><i>j</i></sub>, <i>j</i>=1, 2, …, <i>L</i>.</p>
                </div>
                <div class="p1">
                    <p id="128">step 1.2 计算初始隐层输出矩阵</p>
                </div>
                <div class="p1">
                    <p id="129" class="code-formula">
                        <mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>L</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mn>1</mn></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>L</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>) </mo></mrow><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="130">step 1.3 计算</p>
                </div>
                <div class="p1">
                    <p id="131"><mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mn>0</mn><mi>A</mi></msubsup><mo>=</mo><mfrac><mrow><mi>m</mi><msubsup><mrow></mrow><mn>0</mn><mi>B</mi></msubsup></mrow><mrow><mi>m</mi><msubsup><mrow></mrow><mn>0</mn><mi>A</mi></msubsup></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="133">令<i>w</i><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>0</mn><mi>B</mi></msubsup></mrow></math></mathml>=1, 构造初始样本的惩罚矩阵</p>
                </div>
                <div class="p1">
                    <p id="135"><b><i>W</i></b><sup>*</sup><sub>0</sub>=diag (<i>w</i><sup>*</sup><sub>0</sub>, <i>w</i><sup>*</sup><sub>0</sub>, …, <i>w</i><sup>*</sup><sub>0</sub>) ∈<b>R</b><sup><i>N</i><sub>0</sub>×<i>N</i><sub>0</sub></sup>, </p>
                </div>
                <div class="p1">
                    <p id="136">其中<i>w</i><sup>*</sup><sub>0</sub>∈{<i>w</i><mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>0</mn><mi>B</mi></msubsup></mrow></math></mathml>, <i>w</i><mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>0</mn><mi>A</mi></msubsup></mrow></math></mathml>}.</p>
                </div>
                <div class="p1">
                    <p id="139">step 1.4 计算初始输出权矩阵</p>
                </div>
                <div class="p1">
                    <p id="140"><i>β</i><sup> (0) </sup>=<b><i>K</i></b><sub>0</sub><sup>-1</sup><b><i>H</i></b><sup>T</sup><sub>0</sub><b><i>W</i></b><sup>*</sup><sub>0</sub><b><i>T</i></b><sub>0</sub>, </p>
                </div>
                <div class="p1">
                    <p id="141">其中</p>
                </div>
                <div class="p1">
                    <p id="142"><b><i>T</i></b><sub>0</sub>=[<b><i>t</i></b><sub>1</sub>, <b><i>t</i></b><sub>2</sub>, …, <b><i>t</i></b><sub><i>N</i><sub>0</sub></sub>]<sup>T</sup>, <b><i>K</i></b><sub>0</sub>=<b><i>H</i></b><sup>T</sup><sub>0</sub><b><i>H</i></b><sub>0</sub>.</p>
                </div>
                <div class="p1">
                    <p id="143">step 1.5 设<i>k</i>=0.</p>
                </div>
                <div class="p1">
                    <p id="144">step 2 在线学习阶段.对于第<i>k</i>+1个序列块:<mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo stretchy="false">{</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">}</mo></mrow><msubsup><mrow></mrow><mrow><msub><mrow></mrow><mrow><msub><mrow></mrow><mrow><mi>i</mi><mo>=</mo><mo stretchy="false"> (</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn></mrow></msub></mrow></msub></mrow><mrow><msup><mrow></mrow><mrow><msup><mrow></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></msup></mrow></msup></mrow></msubsup></mrow></math></mathml>, 其中<i>N</i><sub><i>k</i>+1</sub>为第<i>k</i>+1个序列块中的样本个数.</p>
                </div>
                <div class="p1">
                    <p id="146">step 2.1 计算第<i>k</i>+1个序列块对应的隐层输出矩阵</p>
                </div>
                <div class="p1">
                    <p id="147" class="code-formula">
                        <mathml id="147"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mo> (</mo><mrow><mtable><mtr><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>L</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">) </mo></mtd><mtd><mo>⋯</mo></mtd><mtd><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">a</mi><msub><mrow></mrow><mi>L</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo>+</mo><mi>b</mi><msub><mrow></mrow><mi>L</mi></msub><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mo>) </mo></mrow></mrow><mo>, </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="148">step 2.2 计算</p>
                </div>
                <div class="p1">
                    <p id="149"><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>w</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup><mo>=</mo><mfrac><mrow><mi>m</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow><mrow><mi>m</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></mfrac></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="151">令<i>w</i><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow></math></mathml>=1, 构造惩罚矩阵</p>
                </div>
                <div class="p1">
                    <p id="153"><b><i>W</i></b><sup>*</sup><sub><i>k</i>+1</sub>=diag (<i>w</i><sup>*</sup><sub><i>k</i>+1</sub>, …, <i>w</i><sup>*</sup><sub><i>k</i>+1</sub>) ∈<b>R</b><sup><i>N</i><sub><i>k</i>+1</sub>×<i>N</i><sub><i>k</i>+1</sub></sup>, </p>
                </div>
                <div class="p1">
                    <p id="154">其中<i>w</i><sup>*</sup><sub><i>k</i>+1</sub>∈{<i>w</i><mathml id="155"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>A</mi></msubsup></mrow></math></mathml>, <i>w</i><mathml id="156"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mi>B</mi></msubsup></mrow></math></mathml>}.</p>
                </div>
                <div class="p1">
                    <p id="157">step 2.3 计算输出权矩阵</p>
                </div>
                <div class="p1">
                    <p id="158"><i>β</i><sup> (<i>k</i>+1) </sup>=<i>β</i><sup> (<i>k</i>) </sup>+<b><i>K</i></b><mathml id="159"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml><b><i>H</i></b><sup>T</sup><sub><i>k</i>+1</sub><b><i>W</i></b><sup>*</sup><sub><i>k</i>+1</sub> (<b><i>T</i></b><sub><i>k</i>+1</sub>-<b><i>H</i></b><sub><i>k</i>+1</sub><i>β</i><sup> (<i>k</i>) </sup>) , </p>
                </div>
                <div class="p1">
                    <p id="160">其中</p>
                </div>
                <div class="p1">
                    <p id="161" class="code-formula">
                        <mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Τ</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>k</mi></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mn>1</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">t</mi><msub><mrow></mrow><mrow><mstyle displaystyle="true"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>j</mi></msub></mrow></msub><mo stretchy="false">]</mo></mrow><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi mathvariant="bold-italic">Κ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>+</mo><mi mathvariant="bold-italic">Η</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mtext>Τ</mtext></msubsup><mi mathvariant="bold-italic">W</mi><msubsup><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><mo>*</mo></msubsup><mi mathvariant="bold-italic">Η</mi><msub><mrow></mrow><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>.</mo></mtd></mtr></mtable></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="162">step 2.4 设<i>k</i>=<i>k</i>+1. 返回step 2.</p>
                </div>
                <h3 id="163" name="163" class="anchor-tag">3 仿真实验及结果分析</h3>
                <div class="p1">
                    <p id="164">本节使用12个在不平衡学习当中经常使用的二分类不平衡数据集测试在线算法以对比有效性.数据集的具体信息见表1. 数据集采用5-折交叉验证, 运行20次, 实验结果取平均值.</p>
                </div>
                <div class="p1">
                    <p id="165">一般地, 评价分类器的有效性标准采用全体精度, 即测试的数据集中, 正确分类的样本个数与全体样本个数的比例.但对于不平衡数据集来说, 全体精度无法体现分类器在少数类中的分类准确率.因此, 实验采用<i>G</i>-mean值评估分类器的有效性.对于二分类问题, 设<i>TP</i>、<i>TN</i>分别表示被正确分类的正类、负类样本个数, <i>FN</i>表示多数类中被误分为少数类的样本个数, <i>FP</i>表示少数类中被误分为多数类的样本个数, 则正类样本识别准确率</p>
                </div>
                <div class="p1">
                    <p id="166"><mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>Ρ</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="168">负类样本识别准确率</p>
                </div>
                <div class="p1">
                    <p id="169"><mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>Ν</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>, </p>
                </div>
                <div class="p1">
                    <p id="171">则</p>
                </div>
                <div class="p1">
                    <p id="172" class="code-formula">
                        <mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>=</mo><mroot><mrow><mi>Τ</mi><mi>Ρ</mi><mi>R</mi><mo>⋅</mo><mi>Τ</mi><mi>Ν</mi><mi>R</mi></mrow><mtext> </mtext></mroot><mspace width="0.25em" /><mo>.</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="173">
                    <p class="img_tit"><b>表1</b><b>实验数据集细节</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 1 Details of experimental datasets</p>
                    <p class="img_note"></p>
                    <table id="173" border="1"><tr><td>序号</td><td>数据集</td><td>样本个数</td><td>属性个数</td><td>不平衡率</td></tr><tr><td><br />1</td><td>abalone9_18</td><td>731</td><td>8</td><td>0.0600</td></tr><tr><td><br />2</td><td>vowel0</td><td>988</td><td>13</td><td>0.1002</td></tr><tr><td><br />3</td><td>glass0</td><td>216</td><td>9</td><td>0.4786</td></tr><tr><td><br />4</td><td>vehicle1</td><td>846</td><td>18</td><td>0.3439</td></tr><tr><td><br />5</td><td>yeast1</td><td>1484</td><td>8</td><td>0.4064</td></tr><tr><td><br />6</td><td>page-blocks0</td><td>5472</td><td>10</td><td>0.1137</td></tr><tr><td><br />7</td><td>shuttle-C0_vs_C4</td><td>1829</td><td>9</td><td>0.0726</td></tr><tr><td><br />8</td><td>adult</td><td>32561</td><td>123</td><td>0.3306</td></tr><tr><td><br />9</td><td>Colon (Gene Sel) </td><td>64</td><td>60</td><td>0.6667</td></tr><tr><td><br />10</td><td>Banana</td><td>5300</td><td>2</td><td>0.8605</td></tr><tr><td><br />11</td><td>APS Failure at <br />Scania Trucks Data Set</td><td>60000</td><td>170</td><td>0.0169</td></tr><tr><td><br />12</td><td>Bank Marketing Data Set</td><td>41188</td><td>20</td><td>0.1256</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="174">下文对比AWO-ELM、WOS-ELM、OS-ELM-SMOTE、OS-ELM-UNDER分类性能.OS-ELM-SMOTE利用SMOTE对每个序列块进行过采样, 将过采样后的序列块用于OS-ELM, 合成少数类过采样技术 (Synthetic Minority Oversampling Technique, SMOTE) 中<i>k</i>=5.类似地, OS-ELM-UNDER利用信息型欠采样方法对每个序列块进行欠采样, 将欠采样后的序列块用于OS-ELM.</p>
                </div>
                <div class="p1">
                    <p id="175">对每个数据集, 隐层节点的选取方法是节点个数<i>L</i> (<i>L</i>≤<i>N</i><sub>0</sub>) 逐渐增加, 利用初始块进行5-折交叉验证, 运行20次, 确定最优的节点数.初始块的大小和隐层节点的个数见表2.</p>
                </div>
                <div class="area_img" id="176">
                    <p class="img_tit"><b>表2</b><b>隐层节点个数、初始块和序列块大小</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 2 Number of hidden nodes, sizes of initial sets and chunks</p>
                    <p class="img_note"></p>
                    <table id="176" border="1"><tr><td><br />数据集序号</td><td>初始块大小</td><td>隐层节点个数</td><td>序列块大小</td></tr><tr><td><br />1</td><td>25 (20+, 5-) </td><td>20</td><td>100</td></tr><tr><td><br />2</td><td>50 (40+, 10-) </td><td>40</td><td>50</td></tr><tr><td><br />3</td><td>80 (60+, 20-) </td><td>50</td><td>20</td></tr><tr><td><br />4</td><td>150 (120+, 30-) </td><td>30</td><td>20</td></tr><tr><td><br />5</td><td>300 (250+, 50-) </td><td>150</td><td>50</td></tr><tr><td><br />6</td><td>500 (400+, 100-) </td><td>300</td><td>100</td></tr><tr><td><br />7</td><td>80 (60+, 20-) </td><td>30</td><td>200</td></tr><tr><td><br />8</td><td>5000 (4500+, 500-) </td><td>800</td><td>100</td></tr><tr><td><br />9</td><td>25 (20+, 5-) </td><td>20</td><td>10</td></tr><tr><td><br />10</td><td>3000 (2500+, 500-) </td><td>60</td><td>100</td></tr><tr><td><br />11</td><td>500 (400+, 100-) </td><td>530</td><td>600</td></tr><tr><td><br />12</td><td>2500 (2000+, 500-) </td><td>1050</td><td>1000</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="177">由式 (7) 和式 (8) 可知, 在静态的不平衡数据流情况下, AWO-ELM和WOS-ELM实质上一致, 因此需要构造存在概念漂移的不平衡数据流以测试算法.具体构造方式是:在每个数据集中选取样本, 使初始块中的正类样本个数多于负类样本个数, 剩余样本用于构成序列块, 形成概念漂移.</p>
                </div>
                <div class="p1">
                    <p id="178">ELM中的激励函数采用sigmoid函数.使用的仿真软件为Matlab R2017a.实验环境为: Window 7 64bit操作系统, Intel Core i5-3570 3.40 GHz, 8 GB内存.</p>
                </div>
                <div class="p1">
                    <p id="179">表3为4种算法在各数据集上的<i>G</i>-mean值, 每个数据集的最大值使用黑体数字表示.从表3中可以发现, AWO-ELM和WOS-ELM的<i>G</i>-mean值大于OS-ELM-SMOTE和OS-ELM-UNDER.总体上看, AWO-ELM的分类准确率最高, OS-ELM-UNDER的分类准确率最低.</p>
                </div>
                <div class="area_img" id="180">
                    <p class="img_tit"><b>表3</b><b>分类结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit">Table 3 Comparison of classification results</p>
                    <p class="img_note"></p>
                    <table id="180" border="1"><tr><td>数据集序号</td><td>算法</td><td><i>G</i>-mean值</td><td>数据集序号</td><td>算法</td><td><i>G</i>-mean值</td></tr><tr><td><br />1</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.7635</b><br />0.7245<br />0.6845<br />0.6689</td><td>7</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td>0.9628<br /><b>0.9765</b><br />0.9128<br />0.9342</td></tr><tr><td><br />2</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.9924</b><br />0.9831<br />0.9024<br />0.8235</td><td>8</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.7659</b><br />0.6686<br />0.7037<br />0.7263</td></tr><tr><td><br />3</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.7597</b><br />0.6981<br />0.6637<br />0.7035</td><td>9</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.8279</b><br />0.7839<br />0.7546<br />0.6638</td></tr><tr><td><br />4</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.7024</b><br />0.6754<br />0.5537<br />0.5012</td><td>10</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td>0.8227<br /><b>0.8445</b><br />0.7832<br />0.6925</td></tr><tr><td><br />5</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.6827</b><br />0.6532<br />0.5875<br />0.5196</td><td>11</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.7736</b><br />0.7464<br />0.6574<br />0.7039</td></tr><tr><td><br />6</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.9048</b><br />0.8569<br />0.7143<br />0.7681</td><td>12</td><td>AWO-ELM<br />WOS-ELM<br />OS-ELM-SMOTE<br />OS-ELM-UNDER</td><td><b>0.8613</b><br />0.8275<br />0.7287<br />0.7018</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="181">图2为AWO-ELM和WOS-ELM在12个数据集上的TPR和TNR对比.</p>
                </div>
                <div class="p1">
                    <p id="182">由图可以看出, 在大多数情况下, AWO-ELM的TPR和TNR之间的差值小于WOS-ELM, 并且WOS-ELM在其中9个数据集上的TNR大于TPR, 这表明WOS-ELM仍然存在倾向于多数类样本的现象, 惩罚矩阵未起到应有的作用.总体上看, AWO-ELM在这些数据集上的表现更好.</p>
                </div>
                <div class="area_img" id="183">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/MSSB201902006_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 AWO-ELM和WOS-ELM在12个数据集上TPR和 TNR对比" src="Detail/GetImg?filename=images/MSSB201902006_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 AWO-ELM和WOS-ELM在12个数据集上TPR和 TNR对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/MSSB201902006_183.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit">Fig.2 Comparison of TPR and TNR of AWO-ELM and WOS-ELM on 12 datasets</p>

                </div>
                <h3 id="185" name="185" class="anchor-tag">4 结 束 语</h3>
                <div class="p1">
                    <p id="186">本文提出针对不平衡数据流的自适应加权在线超限学习机算法 (AWO-ELM) , 利用惩罚矩阵自动调整实时到达的训练样本的惩罚参数, 不仅可以用于静态的不平衡数据流的学习, 而且适用于存在概念漂移的不平衡数据流.未来将进一步考虑和研究不平衡数据流中存在噪声数据的情形.</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="10">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning from Imbalanced Data">

                                <b>[1]</b> HE H B, GARCIA E A. Learning from Imbalanced Data. IEEE Transactions on Knowledge and Data Engineering, 2009, 21 (9) : 1263-1284.
                            </a>
                        </p>
                        <p id="12">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">

                                <b>[2]</b> CHAWLA N V, BOWYER K W, HALL L O, <i>et al</i>. SMOTE: Synthetic Minority Over-Sampling Technique. Journal of Artificial Intelligence Research, 2002, 16 (1) : 321-357.
                            </a>
                        </p>
                        <p id="14">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust classification of imbalanced datausing one-class and two-class SVM-based multiclassifiers">

                                <b>[3]</b> MALDONADO S, MONTECINOS C. Robust Classification of Imba-lanced Data Using One-Class and Two-Class SVM-Based Multiclassifiers. Intelligent Data Analysis, 2014, 18 (1) : 95-112.
                            </a>
                        </p>
                        <p id="16">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300036228&amp;v=MjYzNjl5am1VTGJJSkZ3WGFSQT1OaWZPZmJLOEh0UE5ySTlGWk9nSkRuNHhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> ZHU W X, ZHONG P. A New One-Class SVM Based on Hidden Information. Knowledge-Based Systems, 2014, 60: 35-43.
                            </a>
                        </p>
                        <p id="18">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600369807&amp;v=MjE2OTZmYks4SHRETXFZOUZaKzBHQkh3K29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnVIeWptVUxiSUpGd1hhUkE9TmlmTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> ZONG W W, HUANG G B, CHEN Y Q. Weighted Extreme Lear-ning Machine for Imbalance Learning. Neurocomputing, 2013, 101:229-242.
                            </a>
                        </p>
                        <p id="20">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A learning framework for online class imbalance learning">

                                <b>[6]</b> WANG S, MINKU L L, YAO X. A Learning Framework for Online Class Imbalance Learning // Proc of the IEEE Symposium on Computational Intelligence and Ensemble Learning. Washington, USA: IEEE, 2013: 36-45.
                            </a>
                        </p>
                        <p id="22">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Improved Weighted Extreme Learning Machine for Imbalanced Data Classification">

                                <b>[7]</b> LU C B, KE H F, ZHANG G Y, <i>et al</i>. An Improved Weighted Extreme Learning Machine for Imbalanced Data Classification[J/OL]. [2018-06-25]. https://link.springer.com/content/pdf/10.1007%2Fs12293-017-0236-3.pdf.
                            </a>
                        </p>
                        <p id="24">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Forecasting Daily Runoff by Extreme Learning Machine Based on Quantum-Behaved Particle Swarm Optimization">

                                <b>[8]</b> NIU W J, FENG Z K, CHENG C T, <i>et al</i>. Forecasting Daily Runoff by Extreme Learning Machine Based on Quantum-Behaved Particle Swarm Optimization. Journal of Hydrologic Engineering, 2018, 23 (3) . DOI: 10.1061/ (ASCE) HE.1943-5584.0001625.
                            </a>
                        </p>
                        <p id="26">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-kernel extreme learning machine for EEG classification in brain-computer interfaces">

                                <b>[9]</b> ZHANG Y, WANG Y, ZHOU G X, <i>et al</i>. Multi-kernel Extreme Learning Machine for EEG Classification in Brain-Computer Interfaces. Expert Systems with Applications, 2018, 96: 302-310.
                            </a>
                        </p>
                        <p id="28">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201712005&amp;v=MTQ5MjNVUkxPZVplUm5GeXpuVUx6S0tEN1liTEc0SDliTnJZOUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 刘阳阳, 张骏, 高欣健, 等.基于卷积递归神经网络和核超限学习机的3D目标识别.模式识别与人工智能, 2017, 30 (12) : 1091-1099. (LIU Y Y, ZHANG J, GAO X J, <i>et al</i>. 3D Object Recognition via Convolutional-Recursive Neural Network and Kernel Extreme Learning Machine. Pattern Recognition and Artificial Intelligence, 2017, 30 (12) : 1091-1099.) 
                            </a>
                        </p>
                        <p id="30">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A fast and accurate online sequential learning algorithm for feedforward networks">

                                <b>[11]</b> LIANG N Y, HUANG G B, SARATCHANDRAN P, <i>et al</i>. A Fast and Accurate Online Sequential Learning Algorithm for Feedforward Networks. IEEE Transactions on Neural Networks, 2006, 17 (6) : 1411-1423.
                            </a>
                        </p>
                        <p id="32">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD13120400000960&amp;v=MTk1MjU5UE1xNDlGWk9zUEJYbzVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVVMYklKRndYYVJBPU5qN0Jhcks3SA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> MIRZA B, LIN Z P, TOH K A. Weighted Online Sequential Extreme Learning Machine for Class Imbalance Learning. Neural Processing Letters, 2013, 38 (3) : 465-486.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="MSSB201902006" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201902006&amp;v=MDkxNTh0R0ZyQ1VSTE9lWmVSbkZ5em5VTHpLS0Q3WWJMRzRIOWpNclk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJkVG5hVDY3Z0JzaWFrTHVRSmVlNjhWcnBYcz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
