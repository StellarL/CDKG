

<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>

</head>

<body>

    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637131424047618750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dGUAN201905018%26RESULT%3d1%26SIGN%3d0dgubV6aiLUNRUdFwmhPi5ksfMI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GUAN201905018&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=GUAN201905018&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>


    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201905018&amp;v=MjQwMDk5ak1xbzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6a1ZMck5JampLWUxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="引 言 ">引 言</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="1 相关理论 ">1 相关理论</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#39" data-title="&lt;b&gt;1.1 HSI色彩空间&lt;/b&gt;"><b>1.1 HSI色彩空间</b></a></li>
                                                <li><a href="#43" data-title="&lt;b&gt;1.2 非下采样Shearlet变换&lt;/b&gt;"><b>1.2 非下采样Shearlet变换</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="2 基于NSST的图像去雾算法流程 ">2 基于NSST的图像去雾算法流程</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#77" data-title="3 &lt;i&gt;NSST&lt;/i&gt;域融合 ">3 <i>NSST</i>域融合</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="&lt;b&gt;3.1 NSST高频分量的保边滤波&lt;/b&gt;"><b>3.1 NSST高频分量的保边滤波</b></a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;3.2 高频系数融合规则&lt;/b&gt;"><b>3.2 高频系数融合规则</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;3.3 NSST低频反锐化掩蔽增强&lt;/b&gt;"><b>3.3 NSST低频反锐化掩蔽增强</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;3.4 低频融合规则&lt;/b&gt;"><b>3.4 低频融合规则</b></a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;3.5 NSST域图像重构&lt;/b&gt;"><b>3.5 NSST域图像重构</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="4 饱和度通道去雾 ">4 饱和度通道去雾</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#140" data-title="5 结果与讨论 ">5 结果与讨论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#151" data-title="6 结 论 ">6 结 论</a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#42" data-title="&lt;b&gt;图1 彩色可见光图像映射到三个通道的图像&lt;/b&gt;"><b>图1 彩色可见光图像映射到三个通道的图像</b></a></li>
                                                <li><a href="#52" data-title="&lt;b&gt;图2 NSST分解原理图&lt;/b&gt;"><b>图2 NSST分解原理图</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;图3 算法流程图&lt;/b&gt;"><b>图3 算法流程图</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;图4 NSST域处理后的图像对比&lt;/b&gt;"><b>图4 NSST域处理后的图像对比</b></a></li>
                                                <li><a href="#143" data-title="&lt;b&gt;图5 实验结果对比&lt;/b&gt;"><b>图5 实验结果对比</b></a></li>
                                                <li><a href="#147" data-title="&lt;b&gt;表1 图5 (1) 中融合结果的客观评价指标&lt;/b&gt;"><b>表1 图5 (1) 中融合结果的客观评价指标</b></a></li>
                                                <li><a href="#148" data-title="&lt;b&gt;表2 图5 (2) 中融合结果的量化比较&lt;/b&gt;"><b>表2 图5 (2) 中融合结果的量化比较</b></a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;表3 图5 (3) 中融合结果的客观评价指标&lt;/b&gt;"><b>表3 图5 (3) 中融合结果的客观评价指标</b></a></li>
                                                <li><a href="#150" data-title="&lt;b&gt;表4 图5 (4) 中融合结果的客观评价指标&lt;/b&gt;"><b>表4 图5 (4) 中融合结果的客观评价指标</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" ZHANG Yong-yan, WU Jiu-hui, ZENG Tao, et al (张永燕, 吴九汇, 曾涛, 等) .Acta Physics Sinaca (物理学报) , 2016, 65:158." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLXB201607019&amp;v=MjI3OTVrVkxyTk1pSFRiTEc0SDlmTXFJOUViWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXo=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         ZHANG Yong-yan, WU Jiu-hui, ZENG Tao, et al (张永燕, 吴九汇, 曾涛, 等) .Acta Physics Sinaca (物理学报) , 2016, 65:158.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" XIA Pu, LIU Xue-bin (夏璞, 刘学斌) .Spectroscopy and Spectral Analysis (光谱学与光谱分析) , 2017, 37 (8) :2331." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201708003&amp;v=MjU1OTE0TzN6cXFCdEdGckNVUkxPZVplUm5GeXprVkxyTklqaktZTEc0SDliTXA0OUZaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         XIA Pu, LIU Xue-bin (夏璞, 刘学斌) .Spectroscopy and Spectral Analysis (光谱学与光谱分析) , 2017, 37 (8) :2331.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" LIU Guo, L&#220; Qun-bo, LIU Yang-yang (刘国, 吕群波, 刘扬阳) .Acta Photonica Sinaca (光子学报) , 2018, 47:179." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201802025&amp;v=MDY3MzJyWTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6a1ZMck5JamZUYkxHNEg5bk0=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         LIU Guo, L&#220; Qun-bo, LIU Yang-yang (刘国, 吕群波, 刘扬阳) .Acta Photonica Sinaca (光子学报) , 2018, 47:179.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" He K M, Sun J, Tang X O.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33:2341." target="_blank"
                                       href="">
                                        <b>[4]</b>
                                         He K M, Sun J, Tang X O.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33:2341.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Miyazaki D, Akiyama D, Baba M, et al.Polarization-Based Dehazing Using Two Reference Objects.IEEE International Conference on Computer Vision Workshops, 2014.852." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Polarization-Based Dehazing Using Two Reference Objects">
                                        <b>[5]</b>
                                         Miyazaki D, Akiyama D, Baba M, et al.Polarization-Based Dehazing Using Two Reference Objects.IEEE International Conference on Computer Vision Workshops, 2014.852.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Yadav G, Maheshwari S, Agarwal A.Fog Removal Techniques from Images:A Comparative Review and Future Directions.International Conference on Signal Propagation and Computer Technology (ICSPCT) , 2014.44." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fog Removal Techniques from Images:A Comparative Review and Future Directions">
                                        <b>[6]</b>
                                         Yadav G, Maheshwari S, Agarwal A.Fog Removal Techniques from Images:A Comparative Review and Future Directions.International Conference on Signal Propagation and Computer Technology (ICSPCT) , 2014.44.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Zhang T, Shao C, Wang X.Atomospheric Scattering-Based Multiple Images Fog Removal.4th International Congress on Image and Signal Processing, 2011, 108." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Atmospheric scattering-based multiple images fog removal">
                                        <b>[7]</b>
                                         Zhang T, Shao C, Wang X.Atomospheric Scattering-Based Multiple Images Fog Removal.4th International Congress on Image and Signal Processing, 2011, 108.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Jiang X F, Ma W.Research of New Method for Removal Thin Cloud and Fog of the Remote Sensing Images.Symposium on Photonics and Optoelectronics, SOPO 2010-Proc.10.1109/SOPO.2010.5504180." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Research of New Method for Removal Thin Cloud and Fog of the Remote Sensing Images">
                                        <b>[8]</b>
                                         Jiang X F, Ma W.Research of New Method for Removal Thin Cloud and Fog of the Remote Sensing Images.Symposium on Photonics and Optoelectronics, SOPO 2010-Proc.10.1109/SOPO.2010.5504180.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     LIU Tong-jun (刘同军) .Journal of Hunan University of Technology (湖南工业大学学报) , 2016, 30:37.</a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Li Nan, Lu Xiaobo.Journal of Southeast University (English Edition) , 2011, 27:290." target="_blank"
                                       href="">
                                        <b>[10]</b>
                                         Li Nan, Lu Xiaobo.Journal of Southeast University (English Edition) , 2011, 27:290.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" WANG Jian-xin, ZHANG You-hui, WANG Zhi-wei (王建新, 张有会, 王志巍) .Journal of Computer Applications (计算机应用) , 2014, 34:2990." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201410048&amp;v=MTkwNTJPM3pxcUJ0R0ZyQ1VSTE9lWmVSbkZ5emtWTHJOTHo3QmQ3RzRIOVhOcjQ5QmJJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         WANG Jian-xin, ZHANG You-hui, WANG Zhi-wei (王建新, 张有会, 王志巍) .Journal of Computer Applications (计算机应用) , 2014, 34:2990.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Guo K, Labate D.Journal on Mathematical Analysis, 2007, 39:298." target="_blank"
                                       href="">
                                        <b>[12]</b>
                                         Guo K, Labate D.Journal on Mathematical Analysis, 2007, 39:298.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Philippe T, Daniel S, Unser M.IEEE Transactions on Image Processing, 2012, 21:3924." target="_blank"
                                       href="">
                                        <b>[13]</b>
                                         Philippe T, Daniel S, Unser M.IEEE Transactions on Image Processing, 2012, 21:3924.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Tarel J P, Hautiere N.Fast Visibility Restoration from a Single Color or Gray Level Image.IEEE International Conference on Computer Vision (ICCV’09) , Washington, DC:IEEE Xplore, 2009.2201." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast visibility restoration from a single color or gray level image">
                                        <b>[14]</b>
                                         Tarel J P, Hautiere N.Fast Visibility Restoration from a Single Color or Gray Level Image.IEEE International Conference on Computer Vision (ICCV’09) , Washington, DC:IEEE Xplore, 2009.2201.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=GUAN" target="_blank">光谱学与光谱分析</a>
                2019,39(05),1420-1427 DOI:10.3964/j.issn.1000-0593 (2019) 05-1420-08            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>近红外与可见光双通道传感器信息融合的去雾技术</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B2%88%E7%91%9C&amp;code=07917795&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">沈瑜</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%85%9A%E5%BB%BA%E6%AD%A6&amp;code=08547028&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">党建武</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%8B%9F%E5%90%89%E7%A5%A5&amp;code=41772948&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苟吉祥</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E7%91%9E&amp;code=25011072&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭瑞</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E6%88%90&amp;code=40778296&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘成</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E5%B0%8F%E9%B9%8F&amp;code=07917840&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王小鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%A3%8A&amp;code=27605593&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李磊</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%85%B0%E5%B7%9E%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0231149&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">兰州交通大学电子与信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%98%E8%82%83%E7%9C%81%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%B7%A5%E7%A8%8B%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83&amp;code=0758515&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">甘肃省人工智能与图形图像处理工程研究中心</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%85%B0%E5%B7%9E%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E5%85%89%E7%94%B5%E6%8A%80%E6%9C%AF%E4%B8%8E%E6%99%BA%E8%83%BD%E6%8E%A7%E5%88%B6%E6%95%99%E8%82%B2%E9%83%A8%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">兰州交通大学光电技术与智能控制教育部重点实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%B0%91%E8%A7%A3%E6%94%BE%E5%86%9B68003%E9%83%A8%E9%98%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国人民解放军68003部队</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了对雾霾天气下的图像进行去雾处理, 多幅图像去雾算法是常用的方法之一。多幅图像去雾算法也有多种形式, 部分算法面临硬件实现困难、获取途径受限或者可实施性弱等问题, 而且多幅图像比对处理时常常涉及图像配准, 造成算法的实时性差、计算复杂度高等问题。针对以上问题, 提出的算法为多幅图像去雾提供了新的思路, 基于双目传感器硬件架构能够同时捕获近红外和可见光图像, 将近红外传感器图像作为新的数据源, 近红外传感器能够在一定程度上穿透雾霾, 在雾天捕获可见光传感器无法捕获的图像细节, 而且硬件实现简单。可见光图像的颜色信息较丰富, 近红外传感器图像对近处场景细节的描述能力较好, 捕获的图像稍加校正就能实现完全配准, 将近红外图像与可见光图像进行融合, 在去雾的同时, 可以将近红外传感器图像中的原始细节提取融合到彩色可见光传感器图像中, 得到边缘、轮廓等细节信息更加丰富的去雾图像。基于上述思路, 借助近红外传感器对边缘细节的描述能力和可见光传感器对颜色信息的反映能力, 提出了一种基于近红外与可见光双通道传感器图像融合的去雾算法。首先, 将彩色可见光图像转换到HIS彩色空间, 分别得到亮度通道图像、色调通道图像和饱和度通道图像。先将其亮度通道图与近红外图像进行融合去雾处理。采用非下采样Shearlet变换 (NSST) 进行分解, 对得到的高频系数进行双指数边缘平滑滤波器保边滤波处理, 对低频系数进行反锐化掩蔽处理, 通过融合规则和反向变换得到新的亮度通道图像。然后, 在对可见光图像的色彩处理中, 建立饱和度图的退化模型, 采用暗原色原理对参数进行估计, 得到估计的饱和度图。最后, 将新的亮度通道图像, 估计的饱和度图像和原色调图像反映射到RGB空间得到去雾图像。为了验证新算法的有效性, 特选取四组雾天拍摄的真实近红外图像与可见光图像进行融合去雾处理, 将融合结果与其他两种去雾方法对于彩色可见光图像的去雾效果进行比较。实验结果表明, 该算法在提高图像的边缘对比度和视觉清晰度上有较好的效果。并提出将近红外传感器图像作为新的数据源, 采用双通道图像融合方法进行去雾处理, 为图像去雾提供的新的技术思路是可行的。该算法的优势在于:首先提出将图像融合方法与去雾算法相结合, 得到了新的去雾算法的思路。将彩色可见光图像转换到HSI色彩空间, 将其亮度通道图与近红外图像采用非下采样Shearlet变换方法进行融合处理, 在去雾的同时, 可以将近红外传感器图像中的原始细节提取融合到彩色可见光传感器图像中, 使得去雾图像中的边缘、轮廓等细节信息更加丰富。其次, 提出了在图像去雾算法中采用新的数据源——近红外传感器图像, 从图像处理的角度, 近红外传感器能够在一定程度上穿透雾霾, 对于近处场景细节的描述能力较好, 而且硬件实现简单, 捕获的图像稍加校正就能实现完全配准, 为后续的融合去雾算法带来了便利, 为图像去雾提供了新的技术途径和路线。再次, 采用的是多幅图像去雾算法, 该算法基于双目传感器获取图像, 可见光图像的颜色信息较丰富, 近红外图像对于近处场景细节的描述能力较好, 相对于单幅图像去雾算法, 有更好的效果。最后, 将可见光传感器图像映射到其他色彩空间, 对于每个通道的图像根据其特征有针对性地进行处理。可见光图像的亮度通道图和近红外图像的处理采用了图像融合和增强处理, 对于可见光图像饱和度通道的处理采用了图像复原算法, 可以从整体上提升去雾效果, 对细节特征有了进一步增强。该算法为图像去雾提供了新的技术途径和路线。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E9%80%9A%E9%81%93&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双通道;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%A0%E6%84%9F%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">传感器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%91%E7%BA%A2%E5%A4%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">近红外;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8E%BB%E9%9B%BE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">去雾;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">融合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    沈瑜, 女, 1982年生, 兰州交通大学电子与信息工程学院副教授e-mail:shenyu_sy@163.com;
                                </span>
                                <span>
                                    *党建武, e-mail:18609311366@163.com;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-04-17</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61861025, 61562057, 61663021, 61761027, 51669010);</span>
                                <span>长江学者和创新团队发展计划 (IRT_16R36);</span>
                                <span>甘肃省教育厅科技计划项目 (2017D-08);</span>
                                <span>甘肃省自然科学基金项目 (17JR5RA101);</span>
                                <span>甘肃省创新创业教育改革项目 (2017-44);</span>
                                <span>光电技术与智能控制教育部重点实验室 (兰州交通大学) 开放课题 (KFKT2018-9);</span>
                                <span>兰州市人才创新创业项目 (2018-RC-117) 资助;</span>
                    </p>
            </div>
                    <h1><b>A Dehaze Algorithm Based on Near-Infrared and Visible Dual Channel Sensor Information Fusion</b></h1>
                    <h2>
                    <span>SHEN Yu</span>
                    <span>DANG Jian-wu</span>
                    <span>GOU Ji-xiang</span>
                    <span>GUO Rui</span>
                    <span>LIU Cheng</span>
                    <span>WANG Xiao-peng</span>
                    <span>LI Lei</span>
            </h2>
                    <h2>
                    <span>School of Electronic and Information Engineering, Lanzhou Jiaotong University</span>
                    <span>Gansu Provincial Engineering Research Center for Artificial Intelligence and Graphics & Image Processing</span>
                    <span>Key Laboratory of Opto-technology and Intelligent Control, Ministry of Education, Lanzhou Jiaotong University</span>
                    <span>Troop 68003, PLA</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to defog the image under hazy weather, multiple images defogging algorithm is one of the commonly used methods. Multiple images defogging algorithm also takes many forms, some of which are usually confronted with the problems of difficult hardware implementation, limited data source achievement approaches, or poor implementation et al. Meanwhile, multiple images defogging algorithm usually needs image registration in the comparison process, causing poor real-time performance and high computation cost. For the above problems, this study supplies a new idea for multiple images defogging algorithm, the near-infrared sensor images are used as new data source. The near-infrared sensor could penetrate haze to some extent, capturing the image details that the visible light sensor could not get. Meanwhile, the hardware of dual sensor system is simple. In the dual sensor system, the visible light image has abundant color information and the near-infrared sensor image can better describe the scene details at close range. The captured images could be completely registered with little rectification. The fusion of the infrared image and visible light image could extract the image details of the near-infrared image to the color visible light image to get the defogging image with abundant edge and contour information. Therefore, this study proposed a defogging algorithm using near-infrared and visible light image fusion method based on the edge details descriptive ability of the near-infrared sensor and the expressive ability of color information. Firstly, the color visible image was transformed from RGB space to HIS color space to get the hue channel image, saturation channel image and intensity channel image. The intensity channel image and original near-infrared image were decomposed by the Non-subsampled Shearlet Transform (NSST) method to get the high frequency coefficients and the low frequency coefficients. The high frequency component was treated by the double-exponential edge smoothing filter and the low frequency component was treated by the Unsharp Masking method, then the fusion rules and the inverse NSST were adopted to get the new intensity channel image. For the color information treatment of the visible light image, the degeneration model of the saturation channel image was established and the dark channel prior was used to evaluate its parameters to get the new saturation channel image. Finally, the new intensity channel image, the new saturation channel image and the original hue channel image were inversely mapped to the RGB space to get the defogging image. In order to verify the algorithm, we adopted 4 groups of foggy near-infrared images and visible light images as the experimental data. The processed images were compared with the defogging images observed by other two defogging algorithms. The experiment results showed that the proposed algorithm has better effect in improving the edge contrast and visual clarity. This study put forward the near-infrared image as new data source and the binary channels image fusion algorithm as the defogging method, and it was verified that the new algorithm for image defogging is feasible. This algorithm has four main advantages. The first one is that we combined the image fusion method with the defogging algorithm to get a novel idea for defogging algorithm. We transformed the color visible image to HSI color space. The obtained intensity channel image and original near-infrared image were fused by the NSST method, and the image details in the near-infrared image were simultaneously extracted to the color visible image in the defogging processes. The defogged image has abundant detailed information of edge and rough. The second advantage is that this algorithm adopted near-infrared sensor image as new data source. From the perspective of image processing, the near-infrared sensor could penetrate haze to some extent, capturing the image details that the visible light sensor could not get. Meanwhile, the hardware of dual sensor system is simple. The third advantage is that we adopted multiple images defogging algorithm, which captured images by binocular sensor system, and the visible light sensor got the image with abundant color information and the near-infrared sensor got the image with good detail description ability of close shot. The fusion of the two kinds of images has better effect than the single image defogging algorithm. The fourth advantage is that the visible light image was transformed to the HIS color space, and the images of the three channels can be targetedly processed according to their data characteristics. The process of intensity channel image of visible light image and the near-infrared image adopted image fusion and enhancement methods. The process of saturation channel image of visible light image adopted image restoration method. These processing enhances the effect of defogged image on the whole. This study supplies a new technological approach and way for image defogging algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dual%20channel&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dual channel;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Sensor&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Sensor;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Near-infrared&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Near-infrared;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dehaze&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dehaze;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Fusion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-04-17</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag">引 言</h3>
                <div class="p1">
                    <p id="32">雾霾作为一种大气污染状态在全国甚至世界各地频发, 雾霾天气下空气中漂浮着水汽和气溶胶<citation id="153" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 由于光线受到水雾、 悬浮物和气溶胶粒子<citation id="154" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>的影响会使景物光发生退化, 图像传感器在获取图像的过程中造成严重的图像降质问题<citation id="155" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。 由于雾霾覆盖, 白天捕获的图像整体为灰白色, 图像对比度降低造成图像模糊、 目标无法识别, 图像质量无法满足户外监控、 卫星遥感监测、 交通运输安全的需要。 因此, 雾天图像清晰化算法的研究非常重要。</p>
                </div>
                <div class="p1">
                    <p id="33">国内外有较多学者进行图像去雾算法工作的探索和研究。 从图像去雾算法的角度通常分为两种: 一是基于图像增强的方法, 直接对于图像像素在空间域进行处理, 以增强图像的对比度、 边缘的清晰化程度、 从视觉上提升图像的效果为目的; 二是基于图像复原的方法, 由于单幅图像去雾算法中往往得不到图像景深、 大气条件等辅助信息, 所以需要建立图像的大气散射退化模型, 通过成像过程的反推过程, 然后借助一定的先验知识进行原始图像的估计, 获得目标的无雾图像。 该方法实现形式相对简单, 且对硬件要求小, 最近在这方面的研究比较多。 He等<citation id="156" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出的暗通道先验模型受到研究者的好评, 成为该方面的主要研究方法。</p>
                </div>
                <div class="p1">
                    <p id="34">从图像源的角度, 分为多幅图像去雾和单幅图像去雾。 利用多幅图像信息, 例如偏振图像、 晴天图像、 红外图像、 视频中的帧序列等作为辅助以达到去雾效果。 这类去雾算法需要辅助图像作为条件, 复原的效果也较好, 但辅助图像的获取也是相对复杂的。 所以由于硬件设备限制加上处理的复杂性, 当前大部分的研究都集中在单幅图像去雾上, 但也有少数学者对多幅图像去雾进行了研究。 Miyazaki等<citation id="157" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出一种基于多幅偏振图像的图像去雾算法, 利用不同极化条件下捕获的两幅图像进行去雾处理, 指出偏振镜只有在特定状态下才是有效的, 对偏振镜的操作要求严格, 不然容易造成人为失误。 Yadav<citation id="158" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等捕获雾天图像序列, 通过四个步骤对雾天图像进行处理, 在对图像散射、 能见度水平进行估计的基础上, 对图像进行增强和滤波处理。 Zhang<citation id="159" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>等提出了基于多幅图像的大气模型去雾算法, 采用晴天图像与雾天模糊图像作参考, 较好地估计出参数值。 Jiang<citation id="160" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等提出了遥感图像中的去雾方法, 对遥感图像序列选择色彩补偿图像, 图像在平均亮度值附近对于MSR进行拉伸使得图像得以增强, 然后得到新的色彩补偿图像, 去雾后的图像在信息熵上表现较好。 刘同军等<citation id="161" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出一种基于大气散射退化模型的多幅偏振图像去雾算法, 能够有效地得到清晰化的去雾图像。 李楠等<citation id="162" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提出一种序列交通图像去雾方法, 建立大气退化模型, 建立距离场并对距离场的分布特征进行归一化处理, 最后优化模型参数, 得到较好的去雾效果。</p>
                </div>
                <div class="p1">
                    <p id="35">通过上述分析可知, 多幅图像去雾算法有多种形式; 一种通过偏振镜得到不同极化条件下的图像进行去雾处理, 这种方法对于偏振光片依赖性强, 使用范围受限; 一种是拍摄不同空气条件下同一场景的雾天、 晴天图像进行去雾处理, 这种方法受天气和时间的约束, 实时性差, 可实施性也很弱; 还有一些情况需要不同条件下的参考图像, 这些图像在获取途径上也不容易实现。 所以多幅图像去雾算法常常面临硬件实现困难、 获取途径受限等问题, 而且多幅图像同时比对处理时还涉及图像配准的问题, 算法的实时性差、 计算复杂度高。</p>
                </div>
                <div class="p1">
                    <p id="36">因此, 我们提出一种基于近红外与可见光双目图像传感器的融合去雾算法。 首先, 将可见光传感器捕获的彩色图像转换到HSI色彩空间, 为了将近红外传感器图像中的细节特征提取到可见光彩色图像中, 将可见光图像的亮度通道图与近红外传感器捕获到的图像根据非下采样Shearlet变换方法 (non-subsampled Shearlet transform, NSST) 进行融合处理, 通过对高通分量和高频分量的滤波和增强操作, 实现对亮度图的去雾和增强操作。 对于可见光的饱和度通道, 建立其退化模型, 采用暗原色原理估计参数, 得到去雾后的饱和度图。 最后将去雾后的亮度通道图、 饱和度通道图和原色调通道图像反向映射到RGB色彩空间, 实现了去雾处理。</p>
                </div>
                <div class="p1">
                    <p id="37">本算法为多幅图像去雾提供了新的思路, 将近红外传感器图像作为新的数据源, 近红外传感器能够在一定程度上穿透雾霾, 能够在雾天捕获可见光传感器无法捕获的图像细节, 而且硬件实现简单。 基于双目传感器获取图像, 可见光图像的颜色信息较丰富, 近红外传感器图像对近处场景细节的描述能力较好, 捕获的图像稍加校正就能实现完全配准, 将近红外图像与可见光图像进行融合, 在去雾的同时, 可以将近红外图像中的原始细节提取融合到彩色可见光图像中, 使得去雾后的图像边缘、 轮廓等细节信息更加丰富。 本算法为图像去雾提供了新的技术途径和路线。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag">1 相关理论</h3>
                <h4 class="anchor-tag" id="39" name="39"><b>1.1 HSI色彩空间</b></h4>
                <div class="p1">
                    <p id="40">HSI是基于人眼视觉系统的颜色模型, 采用色调 (Hue) H通道, 饱和度 (Saturation) S通道和亮度 (Intensity) I通道, 三个通道可以独立实现颜色的调整。 它与RGB颜色模型可以相互转换。 HSI模型有其独特的性质: 一是它的亮度分量与彩色信息无关, 通道相互独立, 亮度分量的单独处理不会影响图像的颜色信息; 其二, HSI颜色模型更符合人类视觉特性, 有利于图像处理。 更重要的原因是将可见光彩色RGB图像映射到HSI空间, 色调通道不会因为雾天的影响而发生降质<citation id="163" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 该通道的数据不需要进行后续的去雾处理。 只需要对于亮度通道和饱和度通道分别处理, 简化了后续计算过程。</p>
                </div>
                <div class="p1">
                    <p id="41">将彩色可见光图像映射到三通道之后的图像如图1所示。</p>
                </div>
                <div class="area_img" id="42">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GUAN201905018_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 彩色可见光图像映射到三个通道的图像" src="Detail/GetImg?filename=images/GUAN201905018_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图1 彩色可见光图像映射到三个通道的图像</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GUAN201905018_042.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.1 Three channels mapped images of color visible image</b></p>

                </div>
                <h4 class="anchor-tag" id="43" name="43"><b>1.2 非下采样Shearlet变换</b></h4>
                <div class="p1">
                    <p id="44">非下采样Shearlet变换 (NSST) 是在Shearlet变换的基础上发展起来的, 是Guo等<citation id="164" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>由合成膨胀仿射系统构造的多尺度几何分析方法之一。 其特点是结构简单, 通过平移、 旋转、 伸缩等可以方便地生成基函数, 具有多维函数稀疏表示性能。 二维的合成膨胀仿射系统表示如式 (1) </p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>B</mi></mrow></msub><mo stretchy="false"> (</mo><mi>Ψ</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">{</mo><mi>Ψ</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mspace width="0.25em" /><mi>l</mi><mo>, </mo><mspace width="0.25em" /><mi>k</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mo stretchy="false">|</mo><mi>det</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><msup><mrow></mrow><mrow><mn>1</mn><mo>/</mo><mn>2</mn></mrow></msup><mi>Ψ</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">B</mi><msup><mrow></mrow><mi>l</mi></msup><mi>A</mi><msup><mrow></mrow><mi>j</mi></msup><mi>x</mi><mo>-</mo><mi>k</mi><mo stretchy="false">) </mo><mo>, </mo><mspace width="0.25em" /></mtd></mtr><mtr><mtd><mi>j</mi><mo>, </mo><mspace width="0.25em" /><mi>l</mi><mo>∈</mo><mi>Ζ</mi><mo>, </mo><mspace width="0.25em" /><mi>k</mi><mo>∈</mo><mi>Ζ</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">其中, <i>Ψ</i>∈<i>L</i><sup>2</sup> (<i>R</i><sup>2</sup>) , <b><i>A</i></b>和<b><i>B</i></b>代表的2×2可逆矩阵。 对于任意<i>f</i>∈<i>L</i><sup>2</sup> (<i>R</i><sup>2</sup>) , 如果<mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>, </mo><mspace width="0.25em" /><mi>l</mi><mo>, </mo><mspace width="0.25em" /><mi>k</mi></mrow></munder><mo stretchy="false">|</mo></mstyle><mo>〈</mo><mi>f</mi><mo>, </mo><mspace width="0.25em" /><mi>Ψ</mi><msub><mrow></mrow><mrow><mi>j</mi><mo>, </mo><mspace width="0.25em" /><mi>l</mi><mo>, </mo><mspace width="0.25em" /><mi>k</mi></mrow></msub><mo>〉</mo><mo stretchy="false">|</mo><mo>=</mo><mo stretchy="false">∥</mo><mi>f</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>, 那么<i>M</i><sub><i>AB</i></sub> (<i>Ψ</i>) 的元素称为合成小波。 而Shearlet是合成小波的一种特殊形式, <image id="168" type="formula" href="images/GUAN201905018_16800.jpg" display="inline" placement="inline"><alt></alt></image>决定了图像的多尺度分解, 是一种各向异性膨胀矩阵;<image id="169" type="formula" href="images/GUAN201905018_16900.jpg" display="inline" placement="inline"><alt></alt></image>为剪切矩阵, 决定了图像的多方向分解。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GUAN201905018_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 NSST分解原理图" src="Detail/GetImg?filename=images/GUAN201905018_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图2 NSST分解原理图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GUAN201905018_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.2 NSST decomposition diagram</b></p>

                </div>
                <div class="p1">
                    <p id="53">NSST是基于非下采样金字塔 (non-subsampled pyramid, NSP) 滤波组和剪切波滤波器组 (shearlet filter, SF) 两部分组成, 如图2所示。 通过NSP实现多尺度变换, 为了提取图像中的奇异性特征, 对低频系数不断进行NSP分解, <i>k</i>层分解会得到1个低频系数和<i>k</i>个高频系数。 将SF映射到笛卡尔坐标系, 通过傅里叶变换, 采用二维卷积进行滤波, 避免了下采样的操作, 使得NSST具有了平移不变性, 而且变换后的图像与源图像尺寸相同, 有利于进行图像的融合操作。</p>
                </div>
                <h3 id="54" name="54" class="anchor-tag">2 基于NSST的图像去雾算法流程</h3>
                <div class="p1">
                    <p id="55">算法流程图如图3所示。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GUAN201905018_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 算法流程图" src="Detail/GetImg?filename=images/GUAN201905018_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图3 算法流程图</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GUAN201905018_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.3 Flow diagram of algorithm</b></p>

                </div>
                <div class="p1">
                    <p id="57">Step1 将可见光传感器捕获的彩色图像<i>F</i><sub><i>Vi</i></sub>转换到HIS彩色空间, 得到色调通道图像<i>F</i><sub><i>Vi</i>, <i>H</i></sub>, 饱和度通道图像<i>F</i><sub><i>Vi</i>, <i>S</i></sub>和亮度通道图像<i>F</i><sub><i>Vi</i>, <i>I</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="58">Step2 将可见光图像的亮度图像与近红外图像<i>F</i><sub><i>In</i></sub>采用NSST方法进行分解, 得到分解后的高频系数<i>F</i><mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mi>Η</mi></msubsup></mrow></math></mathml>, <i>F</i><mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mi>Η</mi></msubsup></mrow></math></mathml>和低频系数F<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mi>L</mi></msubsup></mrow></math></mathml>, F<mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mi>L</mi></msubsup></mrow></math></mathml>;</p>
                </div>
                <div class="p1">
                    <p id="63"><i>Step</i>3 对于分解的高频系数F<mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mi>Η</mi></msubsup></mrow></math></mathml>, F<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mi>Η</mi></msubsup></mrow></math></mathml>, 采用双指数边缘平滑滤波器进行滤波, 得到滤波后的图像F<mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>Η</mi><mo>, </mo><mspace width="0.25em" /><mi>D</mi></mrow></msubsup></mrow></math></mathml>, F<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>Η</mi><mo>, </mo><mspace width="0.25em" /><mi>D</mi></mrow></msubsup></mrow></math></mathml>, 然后采用灰度相似度规则进行高频融合, 得到融合后的高频系数F<sup>H, F</sup>;</p>
                </div>
                <div class="p1">
                    <p id="68"><i>Step</i>4 对于分解的低频系数F<mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mi>L</mi></msubsup></mrow></math></mathml>, F<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mi>L</mi></msubsup></mrow></math></mathml>, 进行低频反锐化掩蔽处理, 得到图像F<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow></math></mathml>, F<mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow></math></mathml>, 通过局部区域标准方差低频系数融合规则, 得到融合后的低频系数F<sup>L, F</sup>;</p>
                </div>
                <div class="p1">
                    <p id="73"><i>Step</i>5 将得到的融合后的高频系数F<sup>H, F</sup>和低频系数F<sup>L, F</sup>进行<i>NSST</i>反向变换得到处理后的亮度通道图像F<sup><i>NSST</i></sup><sub>I</sub>;</p>
                </div>
                <div class="p1">
                    <p id="74"><i>Step</i>6 对于可见光图像的饱和度通道, 建立退化模型, 采用暗通道原理对参数进行估计, 得到估计的饱和度图F<mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>S</mi></mrow><mrow><mtext>D</mtext><mtext>a</mtext><mtext>r</mtext><mtext>k</mtext></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="76"><i>Step</i>7 将处理后的亮度通道图像F<sup><i>NSST</i></sup><sub>I</sub>, 估计的饱和度图像F<sup><i>Dark</i></sup><sub>Vi, S</sub>和原来的色调图像F<sub>Vi, H</sub>反向映射到<i>RGB</i>空间, 得到去雾后的图像F<sup>R</sup>。</p>
                </div>
                <h3 id="77" name="77" class="anchor-tag">3 <i>NSST</i>域融合</h3>
                <h4 class="anchor-tag" id="78" name="78"><b>3.1 NSST高频分量的保边滤波</b></h4>
                <div class="p1">
                    <p id="79">NSST多方向多尺度分解后的高频分量, 含有图像大部分的高频边缘、 轮廓细节, 而且噪声也属于高频成分。 大部分的滤波器在滤除噪声的同时, 常常损失很多的高频边缘等线性细节。 为了对多尺度分解后的高频系数进行滤波处理, 采用双指数边缘平滑滤波器BEEPS (bi-exponential edge-preserving smoother) 。 BEEPS滤波器是Philippe等<citation id="165" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>在2012年提出的一种保边滤波器, 它的原理类似于双边滤波器中的值域滤波, 但是摒弃了双边滤波器中的边缘梯度反转效应, 降低了计算的复杂度。 每个像素点的计算只与其上一个像素点的计算有关, 不依赖滤波参数和像素自身的灰度值。 对于包含<i>n</i>个元素的离散序列<i>x</i>[<i>n</i>]其一次BEEPS滤波结果</p>
                </div>
                <div class="p1">
                    <p id="80" class="code-formula">
                        <mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo>=</mo><mfrac><mrow><mi>φ</mi><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo>+</mo><mi>φ</mi><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo><mo>+</mo><mo stretchy="false"> (</mo><mi>λ</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo><mi>x</mi><mo stretchy="false">[</mo><mi>n</mi><mo stretchy="false">]</mo></mrow><mrow><mi>λ</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="81">BEEPS滤波器在对二维图像进行处理时, 将其看作若干个离散序列构成的二维矩阵, 先对矩阵做先水平后垂直的BEEPS滤波, 记录滤波结果; 然后再对原始矩阵做一次先垂直后水平的滤波, 记录滤波结果; 最后取两次滤波结果的平均值, 得到最终的处理结果:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>h</mi><mi>v</mi></mrow></msub><mo>+</mo><mi>F</mi><msub><mrow></mrow><mrow><mi>v</mi><mi>h</mi></mrow></msub><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>3.2 高频系数融合规则</b></h4>
                <div class="p1">
                    <p id="84">高频子带系统的融合规则是基于灰度相似度值的方法。 计算红外图像高频分量和可见光图像高频分量在<i>p</i> (<i>x</i>, <i>y</i>) 点和<i>q</i> (<i>x</i>, <i>y</i>) 点上的灰度差值大的作为相似度项, 见式 (4) </p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mspace width="0.25em" /><mi>q</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>q</mi></mrow></msub></mtd><mtd columnalign="left"><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>q</mi></mrow></msub><mo>≥</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>q</mi></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi>Ι</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>q</mi></mrow></msub></mtd><mtd columnalign="left"><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>A</mi><mi>q</mi></mrow></msub><mo>&lt;</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ρ</mi></mrow></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>q</mi></mrow></msub></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">其中, <i>I</i><sub><i>AP</i></sub>-<i>I</i><sub><i>Aq</i></sub>表示红外图像高频分量在p (x, y) 点和q (x, y) 点上的灰度值差; <i>I</i><sub><i>BP</i></sub>-<i>I</i><sub><i>Bq</i></sub>代表可见光图像高频分量在<i>p</i> (<i>x</i>, <i>y</i>) 点和<i>q</i> (<i>x</i>, <i>y</i>) 点上的灰度值差。</p>
                </div>
                <div class="p1">
                    <p id="87">根据该融合规则, 得到高频融合系数<i>F</i><sup><i>H</i>, <i>F</i></sup>。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>3.3 NSST低频反锐化掩蔽增强</b></h4>
                <div class="p1">
                    <p id="89">NSST多尺度多方向分解后的低频分量含有图像大部分的能量, 同时低频分量受到雾的污染需要进行滤波增强处理。 采用一种改进的低频反锐化掩蔽增强算法对NSST的低频分量进行处理。</p>
                </div>
                <div class="p1">
                    <p id="90">反锐化掩蔽 (Unsharp Mask) 将原图和模糊化的图像相加以达到图像增强的目的。 通常, 反锐化掩蔽的处理过程如下:</p>
                </div>
                <div class="p1">
                    <p id="91"> (1) 通过模糊模板<i>K</i><sub>low</sub>对原图像进行模糊化处理, 得到图像<i>I</i><sub>low</sub></p>
                </div>
                <div class="p1">
                    <p id="92" class="code-formula">
                        <mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msub><mo>=</mo><mi>Ι</mi><mo>⨂</mo><mi>Κ</mi><msub><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="93"> (2) 原图像减去模糊化图像<i>I</i><sub>low</sub>, 得到差值图像, 又称为掩模模板<i>I</i><sub>mark</sub></p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>a</mtext><mtext>r</mtext><mtext>k</mtext></mrow></msub><mo>=</mo><mi>Ι</mi><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>l</mtext><mtext>o</mtext><mtext>w</mtext></mrow></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95"> (3) 将掩模模板与适当的系数相乘, 然后与原图像相加, 得到高频细节增强后的图像</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>U</mtext><mtext>S</mtext><mtext>Μ</mtext></mrow></msub><mo>=</mo><mi>k</mi><mi>Ι</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>a</mtext><mtext>r</mtext><mtext>k</mtext></mrow></msub><mo>+</mo><mi>Ι</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">下面将反锐化掩蔽方法进行改进, 使之适用于NSST的低频分量增强。</p>
                </div>
                <div class="p1">
                    <p id="98">NSST低频图像受到薄雾干扰, 大气散射现象造成图像模糊, 边缘和细节不清楚, 图像对比度低。 建立NSST低频图像的大气散射模型</p>
                </div>
                <div class="p1">
                    <p id="99" class="code-formula">
                        <mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>h</mi><mo>=</mo><mi>h</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>λ</mi><mo stretchy="false">) </mo><mi>exp</mi><msup><mrow></mrow><mrow><mo>-</mo><mi>β</mi><mo stretchy="false"> (</mo><mi>λ</mi><mo stretchy="false">) </mo><mi>d</mi></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="100">其中, <i>d</i>表示图像传感器到场景的距离; <i>λ</i>表示光的波长; <i>β</i> (<i>λ</i>) 表示大气散射系数; <i>h</i><sub>0</sub> (<i>λ</i>) 表示入射光在<i>x</i>=0点的辐射度。</p>
                </div>
                <div class="p1">
                    <p id="101">对于图像<i>f</i> (<i>x</i>, <i>y</i>) , 模糊化后的图像为</p>
                </div>
                <div class="p1">
                    <p id="102" class="code-formula">
                        <mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mspace width="0.25em" /><mi>y</mi><mo stretchy="false">) </mo><mo>*</mo><mi>h</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="103">其中, <i>f</i> (<i>x</i>, <i>y</i>) 代表原图像; <i>h</i>是使图像变模糊的等效滤波器, 这里是指上述的点扩展函数。</p>
                </div>
                <div class="p1">
                    <p id="104">掩蔽模板为</p>
                </div>
                <div class="p1">
                    <p id="105" class="code-formula">
                        <mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>a</mtext><mtext>r</mtext><mtext>k</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mspace width="0.25em" /><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mspace width="0.25em" /><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mspace width="0.25em" /><mi>y</mi><mo stretchy="false">) </mo><mo>*</mo><mi>h</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="106">低频反锐化掩蔽后的图像</p>
                </div>
                <div class="p1">
                    <p id="107" class="code-formula">
                        <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><msub><mrow></mrow><mrow><mtext>U</mtext><mtext>S</mtext><mtext>Μ</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mspace width="0.25em" /><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mi>k</mi><mi>f</mi><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>a</mtext><mtext>r</mtext><mtext>k</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mspace width="0.25em" /><mi>y</mi><mo stretchy="false">) </mo><mo>+</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mspace width="0.25em" /><mi>y</mi><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="108">对于NSST的低频系数<i>F</i><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mi>L</mi></msubsup></mrow></math></mathml>, <i>F</i><mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mi>L</mi></msubsup></mrow></math></mathml>, 进行低频反锐化掩蔽处理, 通过式 (21) 得到图像F<mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow></math></mathml>, F<mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>3.4 低频融合规则</b></h4>
                <div class="p1">
                    <p id="114">低频子带系数融合规则最常见的是简单的平均法, 但是它会大幅降低图像的对比度, 融合后的图像对比度低, 会损失重要特征。 局部区域标准方差通常作为客观评价参数衡量图像清晰程度, 该参数能够描述图像区域中灰度变化的强度。 一般情况下, 图像中灰度变换相对明显的区域也能集中体现特征, 所以借助局部区域标准方差的上述特性能够提取出图像中的特征。 因此, 采用局部区域标准方差作为低频系数融合规则。 该规则具体描述如下:</p>
                </div>
                <div class="p1">
                    <p id="115">计算低频子带系数F<mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow></math></mathml>和F<mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow></math></mathml>的局部区域标准方差σ<sub>Vi, I</sub>和σ<sub>In</sub>, 其中采用的图像邻域范围N<sub>1</sub>×M<sub>1</sub>为3×3, 具体公式如下</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>σ</mi><msub><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow></msub><mo>=</mo></mtd></mtr><mtr><mtd><msqrt><mrow><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mo>-</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mo>-</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>Μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi>Μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>F</mi><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo>+</mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mover accent="true"><mrow><mi>F</mi><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>Μ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>σ</mi><msub><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow></msub><mo>=</mo></mtd></mtr><mtr><mtd><msqrt><mrow><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mo>-</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi>Ν</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mo>-</mo><mfrac><mrow><mo stretchy="false"> (</mo><mi>Μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow><mrow><mfrac><mrow><mo stretchy="false"> (</mo><mi>Μ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>F</mi><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>+</mo><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo>+</mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mover accent="true"><mrow><mi>F</mi><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup></mrow><mo stretchy="true">¯</mo></mover><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>Ν</mi><msub><mrow></mrow><mn>1</mn></msub><mo>×</mo><mi>Μ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac></mrow></msqrt><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="119">采用式 (12) 和式 (13) 以选择融合后的低频系数。 融合规则如式 (15) 所示, 其中<i>c</i>=1.5代表阈值, 通过经营选择, 范围在0.1～0.3之间。</p>
                </div>
                <div class="p1">
                    <p id="120" class="code-formula">
                        <mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>F</mi><msup><mrow></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>F</mi></mrow></msup><mo>=</mo><mi>F</mi><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo><mo>×</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>+</mo><mi>F</mi><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo><mo>×</mo><mn>0</mn><mo>.</mo><mn>5</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>F</mi><msup><mrow></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>F</mi></mrow></msup><mo>=</mo><mrow><mo>{</mo><mrow><mtable><mtr><mtd columnalign="left"><mi>F</mi><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo></mtd><mtd columnalign="left"><mi>σ</mi><msub><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow></msub><mo>-</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow></msub><mo>&gt;</mo><mi>t</mi><mi>h</mi></mtd></mtr><mtr><mtd columnalign="left"><mi>F</mi><msubsup><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo><mo>×</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>+</mo></mtd><mtd columnalign="left"></mtd></mtr><mtr><mtd columnalign="left"><mtext> </mtext><mtext> </mtext><mi>F</mi><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo><mo>×</mo><mn>0</mn><mo>.</mo><mn>5</mn></mtd><mtd columnalign="left"><mo stretchy="false">|</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow></msub><mo>-</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow></msub><mo stretchy="false">|</mo><mo>&gt;</mo><mi>t</mi><mi>h</mi></mtd></mtr><mtr><mtd columnalign="left"><mi>F</mi><msubsup><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow><mrow><mi>L</mi><mo>, </mo><mspace width="0.25em" /><mi>U</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>m</mi><mo>, </mo><mspace width="0.25em" /><mi>n</mi><mo stretchy="false">) </mo></mtd><mtd columnalign="left"><mi>σ</mi><msub><mrow></mrow><mrow><mi>V</mi><mi>i</mi><mo>, </mo><mspace width="0.25em" /><mi>Ι</mi></mrow></msub><mo>-</mo><mi>σ</mi><msub><mrow></mrow><mrow><mi>Ι</mi><mi>n</mi></mrow></msub><mo>&lt;</mo><mi>t</mi><mi>h</mi></mtd></mtr></mtable></mrow></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="121">严格执行上述过程就计算得到融合后的低频系数<i>F</i><sup><i>L</i>, <i>F</i></sup>。</p>
                </div>
                <h4 class="anchor-tag" id="122" name="122"><b>3.5 NSST域图像重构</b></h4>
                <div class="p1">
                    <p id="123">将得到的融合后的高频系数<i>F</i><sup><i>H</i>, <i>F</i></sup>和低频系数<i>F</i><sup><i>L</i>, <i>F</i></sup>进行NSST反向变换得到处理后的亮度通道图像<i>F</i><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>Ι</mi><mrow><mi>Ν</mi><mi>S</mi><mi>S</mi><mi>Τ</mi></mrow></msubsup></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="125">图4显示了<i>NSST</i>融合算法将可见光图像的亮度通道和红外图像融合在一起的结果。 融合结果表明, 增强了图像的边缘细节, 提升了图像的清晰度和对比度。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GUAN201905018_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 NSST域处理后的图像对比" src="Detail/GetImg?filename=images/GUAN201905018_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图4 NSST域处理后的图像对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GUAN201905018_126.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.4 Contrast of the processed images by the NSST domain fusion</b></p>

                </div>
                <h3 id="127" name="127" class="anchor-tag">4 饱和度通道去雾</h3>
                <div class="p1">
                    <p id="128">饱和度通道图像的退化模型与雾霾天气下退化图像模型的形式一致</p>
                </div>
                <div class="p1">
                    <p id="129" class="code-formula">
                        <mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>S</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mi>t</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>+</mo><mi>A</mi><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>t</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="130">其中, <i>A</i>表示光源照射强度; <i>S</i>表示雾天的饱和度通道图像; <i>S</i><sub>0</sub>表示无雾的饱和度通道图像; <i>t</i> (<i>x</i>) 表示透射率 (传输图或介质传输图) , 它随着图像传感器与场景之间的距离呈指数衰减。</p>
                </div>
                <div class="p1">
                    <p id="131">He等<citation id="166" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>在统计大量图像特征的基础上, 提出了暗通道的概念, 即无雾图像非天空部分的局部区域中, 至少有一个颜色通道亮度值是很低的, 甚至趋近于零</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mrow><mtext>d</mtext><mtext>a</mtext><mtext>r</mtext><mtext>k</mtext></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>c</mi><mo>∈</mo><mo stretchy="false">{</mo><mi>r</mi><mo>, </mo><mspace width="0.25em" /><mi>g</mi><mo>, </mo><mspace width="0.25em" /><mi>b</mi><mo stretchy="false">}</mo></mrow></munder><mi>J</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>→</mo><mn>0</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">其中, <i>J</i><sub><i>c</i></sub> (<i>y</i>) 为图像<i>J</i> (<i>y</i>) 的R, G, B三通道中的某一个; <i>Ω</i> (<i>x</i>) 代表以像素点x为中心的邻域。</p>
                </div>
                <div class="p1">
                    <p id="134">由暗原色先验可以得到透射率<i>t</i> (<i>x</i>) </p>
                </div>
                <div class="p1">
                    <p id="135" class="code-formula">
                        <mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>y</mi><mo>∈</mo><mi>Ω</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mrow><mo> (</mo><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>c</mi><mo>∈</mo><mo stretchy="false">{</mo><mi>r</mi><mo>, </mo><mspace width="0.25em" /><mi>g</mi><mo>, </mo><mspace width="0.25em" /><mi>b</mi><mo stretchy="false">}</mo></mrow></munder><mfrac><mrow><mi>Ι</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mi>A</mi></mfrac></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="136">其中, 光源照射强度取各颜色通道的暗通道中亮度值最高的值</p>
                </div>
                <div class="p1">
                    <p id="137" class="code-formula">
                        <mathml id="137"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>x</mi><mo>∈</mo><mi>Ι</mi></mrow></munder><mo stretchy="false"> (</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>c</mi><mo>∈</mo><mi>Ω</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></munder><mi>Ι</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo><mspace width="0.25em" /><mi>c</mi><mo>∈</mo><mo stretchy="false">{</mo><mtext>R</mtext><mo>, </mo><mspace width="0.25em" /><mtext>G</mtext><mo>, </mo><mspace width="0.25em" /><mtext>B</mtext><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="138">将估计得到的透射率和背景光带入式 (28) , 得到复原的饱和度通道图像</p>
                </div>
                <div class="p1">
                    <p id="139" class="code-formula">
                        <mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>A</mi></mrow><mrow><mi>t</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>+</mo><mi>A</mi><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h3 id="140" name="140" class="anchor-tag">5 结果与讨论</h3>
                <div class="p1">
                    <p id="141">为了验证新算法的有效性, 特选取四组雾天条件下拍摄的真实近红外图像与可见光图像进行融合去雾处理, 将融合结果与He和Tarel方法对彩色可见光图像的去雾效果进行比较。</p>
                </div>
                <div class="p1">
                    <p id="142">图5为4组图像经过He方法、 Tarel方法<citation id="167" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和本方法处理后的结果。 图5 (a) 为彩色可见光图像, 呈现场景模糊、 边缘模糊不清、 图像对比度低的降质现象; 图5 (b) 为近红外图像, 对于近处的场景能够在一定程度上穿透雾霾, 捕获到较清晰的边缘细节信息; 图5 (c) 为He方法去雾后的结果, 处理后的图像较清晰, 边缘细节较清楚, 颜色校正获得的视觉效果好, 但是部分去雾出现方块效应; 图5 (d) 为Tarel方法处理的结果, 其图像的清晰度、 对比度和细节的表达在三种方法里相对较差, 而且颜色过校正, 呈现白色调; 图5 (e) 为本方法的去雾效果, 在三种方法中表现总体是最好的, 图像的对比度有显著提升, 边缘清晰, 颜色饱满, 视觉效果较理想。</p>
                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/GUAN201905018_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 实验结果对比" src="Detail/GetImg?filename=images/GUAN201905018_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit"><b>图5 实验结果对比</b>  <a class="btn-zoomin" href="Detail/GetImg?filename=images/GUAN201905018_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"><b>Fig.5 Experiment results contrast</b></p>

                </div>
                <div class="p1">
                    <p id="144">对于雾霾图像的去雾处理的评价, 当前尚无统一的客观评价标准。 从平均梯度、 互信息量和边缘信息评价因子三个方法进行客观评价, 平均梯度AvG用来衡量微小细节的表述能力; 互信息量MI用来衡量结果图像从源图像中提取到的信息量, 这里计算的是从可见光图像中提取到的信息的多少; 边缘信息评价因子<i>Q</i><sup>AB/F</sup>用来衡量图像从源图像中提取到多少边缘信息量, 这里计算的是从可见光图像中提取到的边缘信息量的多少。 表1—表4对应图5中4组图像采用三种方法处理结果的客观评价数据。</p>
                </div>
                <div class="p1">
                    <p id="145">根据对客观指标的综合比较显示: 本方法在AvG参数上数值最大, 表明本方法对于图像细节的处理效果好, 对图像的边缘细节有很好地体现; 在互信息MI和边缘信息评价因子<i>Q</i><sup>AB/F</sup>方面, 本方法的值是最小的, 代表本方法从彩色可见光图像中提取的信息量和边缘信息量是最小的, 视觉效果是最好的, 这是因为其一可见光图像中不仅有有用信息, 还有雾霾噪声, 证明本方法的去雾效果较好; 其二, 虽然本方法从可见光图像中获取的信息量小, 但是本方法还通过NSST域的融合将近红外图像中的信息提取到了去雾后的图像中, 所以本算法的结果图像信息丰富、 图像边缘清楚、 图像对比度高, 在三种方法中的效果是最好的。</p>
                </div>
                <div class="p1">
                    <p id="146">综上所述, 本方法将可见光和近红外图像进行融合去雾处理, 能够在图像的信息量、 对比度和边缘信息的表达能力方面得到很好的效果。</p>
                </div>
                <div class="area_img" id="147">
                    <p class="img_tit"><b>表1 图5 (1) 中融合结果的客观评价指标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 1 Objective evaluation index of fusion results in Fig.5 (1</b>) </p>
                    <p class="img_note"></p>
                    <table id="147" border="1"><tr><td><br />图5 (1) </td><td>AvG</td><td>MI</td><td><i>Q</i><sup>AB/F</sup></td></tr><tr><td><br />HE</td><td>16.389 2</td><td>6.333 1</td><td>0.840 5</td></tr><tr><td><br />Tarel</td><td>19.055 9</td><td>6.084 7</td><td>0.735 6</td></tr><tr><td><br />本文</td><td>19.383 1</td><td>5.846 9</td><td>0.610 5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="148">
                    <p class="img_tit"><b>表2 图5 (2) 中融合结果的量化比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 2 Objective evaluation index of fusion results in Fig.5 (2</b>) </p>
                    <p class="img_note"></p>
                    <table id="148" border="1"><tr><td><br />图5 (2) </td><td>AvG</td><td>MI</td><td><i>Q</i><sup>AB/F</sup></td></tr><tr><td><br />HE</td><td>14.336 6</td><td>6.006 8</td><td>0.855 0</td></tr><tr><td><br />Tarel</td><td>17.814 0</td><td>5.716 6</td><td>0.749 8</td></tr><tr><td><br />本文</td><td>18.502 3</td><td>5.610 9</td><td>0.589 4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="149">
                    <p class="img_tit"><b>表3 图5 (3) 中融合结果的客观评价指标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 3 Objective evaluation index of fusion results in Fig.5 (3</b>) </p>
                    <p class="img_note"></p>
                    <table id="149" border="1"><tr><td><br />图5 (3) </td><td>AvG</td><td>MI</td><td><i>Q</i><sup>AB/F</sup></td></tr><tr><td><br />HE</td><td>6.048 0</td><td>6.313 6</td><td>0.847 0</td></tr><tr><td><br />Tarel</td><td>7.550 8</td><td>5.940 5</td><td>0.743 5</td></tr><tr><td><br />本文</td><td>14.820 2</td><td>5.818 8</td><td>0.500 5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="150">
                    <p class="img_tit"><b>表4 图5 (4) 中融合结果的客观评价指标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"><b>Table 4 Objective evaluation index of fusion results in Fig.5 (4</b>) </p>
                    <p class="img_note"></p>
                    <table id="150" border="1"><tr><td><br />图5 (4) </td><td>AvG</td><td>MI</td><td><i>Q</i><sup>AB/F</sup></td></tr><tr><td><br />HE</td><td>6.506 9</td><td>6.623 9</td><td>0.843 4</td></tr><tr><td><br />Tarel</td><td>8.078 9</td><td>6.220 2</td><td>0.739 8</td></tr><tr><td><br />本文</td><td>15.040 7</td><td>6.074 9</td><td>0.538 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="151" name="151" class="anchor-tag">6 结 论</h3>
                <div class="p1">
                    <p id="152">提出一种基于近红外与可见光双目图像传感器的融合去雾算法。 借助近红外传感器能够在雾天捕获可见光传感器无法捕获的图像细节, 将近红外图像与可见光图像进行融合, 在去雾的同时, 可以将近红外图像中的原始清晰细节提取融合到彩色可见光图像中, 得到边缘、 轮廓等特征量更加丰富的去雾图像。 实验结果表明, 本方法得到的图像在边缘信息、 对比度和信息量上具有很好的表述能力。 本算法将近红外传感器图像作为新的数据源, 近红外传感器能够在一定程度上穿透雾霾, 能够在雾天捕获可见光传感器无法捕获的图像细节, 而且硬件实现简单, 之后采用图像融合方法进行图像去雾, 为图像去雾提供了新的技术途径和路线。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WLXB201607019&amp;v=MzA1NjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6a1ZMck5NaUhUYkxHNEg5Zk1xSTlFYllRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> ZHANG Yong-yan, WU Jiu-hui, ZENG Tao, et al (张永燕, 吴九汇, 曾涛, 等) .Acta Physics Sinaca (物理学报) , 2016, 65:158.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201708003&amp;v=MjE2MTZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXprVkxyTklqaktZTEc0SDliTXA0OUY=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> XIA Pu, LIU Xue-bin (夏璞, 刘学斌) .Spectroscopy and Spectral Analysis (光谱学与光谱分析) , 2017, 37 (8) :2331.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GZXB201802025&amp;v=MzIxNzBuTXJZOUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm5GeXprVkxyTklqZlRiTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> LIU Guo, LÜ Qun-bo, LIU Yang-yang (刘国, 吕群波, 刘扬阳) .Acta Photonica Sinaca (光子学报) , 2018, 47:179.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="">

                                <b>[4]</b> He K M, Sun J, Tang X O.IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33:2341.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Polarization-Based Dehazing Using Two Reference Objects">

                                <b>[5]</b> Miyazaki D, Akiyama D, Baba M, et al.Polarization-Based Dehazing Using Two Reference Objects.IEEE International Conference on Computer Vision Workshops, 2014.852.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fog Removal Techniques from Images:A Comparative Review and Future Directions">

                                <b>[6]</b> Yadav G, Maheshwari S, Agarwal A.Fog Removal Techniques from Images:A Comparative Review and Future Directions.International Conference on Signal Propagation and Computer Technology (ICSPCT) , 2014.44.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Atmospheric scattering-based multiple images fog removal">

                                <b>[7]</b> Zhang T, Shao C, Wang X.Atomospheric Scattering-Based Multiple Images Fog Removal.4th International Congress on Image and Signal Processing, 2011, 108.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Research of New Method for Removal Thin Cloud and Fog of the Remote Sensing Images">

                                <b>[8]</b> Jiang X F, Ma W.Research of New Method for Removal Thin Cloud and Fog of the Remote Sensing Images.Symposium on Photonics and Optoelectronics, SOPO 2010-Proc.10.1109/SOPO.2010.5504180.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 LIU Tong-jun (刘同军) .Journal of Hunan University of Technology (湖南工业大学学报) , 2016, 30:37.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="">

                                <b>[10]</b> Li Nan, Lu Xiaobo.Journal of Southeast University (English Edition) , 2011, 27:290.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201410048&amp;v=MTU0MTJGeXprVkxyTkx6N0JkN0c0SDlYTnI0OUJiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplUm4=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> WANG Jian-xin, ZHANG You-hui, WANG Zhi-wei (王建新, 张有会, 王志巍) .Journal of Computer Applications (计算机应用) , 2014, 34:2990.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="">

                                <b>[12]</b> Guo K, Labate D.Journal on Mathematical Analysis, 2007, 39:298.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="">

                                <b>[13]</b> Philippe T, Daniel S, Unser M.IEEE Transactions on Image Processing, 2012, 21:3924.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast visibility restoration from a single color or gray level image">

                                <b>[14]</b> Tarel J P, Hautiere N.Fast Visibility Restoration from a Single Color or Gray Level Image.IEEE International Conference on Computer Vision (ICCV’09) , Washington, DC:IEEE Xplore, 2009.2201.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="GUAN201905018" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GUAN201905018&amp;v=MjQwMDk5ak1xbzlFYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVJuRnl6a1ZMck5JampLWUxHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEE0QVN2K0VEcmFwaThPYkVCRk9HU284ay9YQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>


    <link href="/kxreader/Content/css/LeftDetail?v=NLcKG8I1SJUaVFrQ0iGpF2klAT0OsmHRaVSZ1rKb5xg1" rel="stylesheet"/>

</body>
</html>

