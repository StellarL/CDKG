<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135595898752500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201909031%26RESULT%3d1%26SIGN%3deGITlxXaNVfWeVxokwBCNPXNd4E%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909031&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909031&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909031&amp;v=MDU4MDFyQ1VSN3FmWnVadEZ5bmhXN3JBTHpUWlpMRzRIOWpNcG85R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#63" data-title="&lt;b&gt;1 实验模型与方法&lt;/b&gt; "><b>1 实验模型与方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="&lt;b&gt;1.1 卷积神经网络&lt;/b&gt;"><b>1.1 卷积神经网络</b></a></li>
                                                <li><a href="#77" data-title="&lt;b&gt;1.2 迁移学习&lt;/b&gt;"><b>1.2 迁移学习</b></a></li>
                                                <li><a href="#81" data-title="&lt;b&gt;1.3 预训练模型&lt;/b&gt;"><b>1.3 预训练模型</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;1.4 微 调&lt;/b&gt;"><b>1.4 微 调</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;1.5 模型融合&lt;/b&gt;"><b>1.5 模型融合</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#105" data-title="&lt;b&gt;2 实验与结果分析&lt;/b&gt; "><b>2 实验与结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#106" data-title="&lt;b&gt;2.1 实验数据集&lt;/b&gt;"><b>2.1 实验数据集</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;2.2 实验设置与环境&lt;/b&gt;"><b>2.2 实验设置与环境</b></a></li>
                                                <li><a href="#112" data-title="&lt;b&gt;2.3 数据处理&lt;/b&gt;"><b>2.3 数据处理</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;2.4 模型差异性分析&lt;/b&gt;"><b>2.4 模型差异性分析</b></a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;2.5 实验结果&lt;/b&gt;"><b>2.5 实验结果</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;2.6 方法泛化性分析&lt;/b&gt;"><b>2.6 方法泛化性分析</b></a></li>
                                                <li><a href="#134" data-title="&lt;b&gt;2.7 与相关方法对比分析&lt;/b&gt;"><b>2.7 与相关方法对比分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#138" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="图1 InceptionV3中的Inception模块结构图">图1 InceptionV3中的Inception模块结构图</a></li>
                                                <li><a href="#83" data-title="&lt;b&gt;表1&lt;/b&gt; ImageNet&lt;b&gt;竞赛中部分模型对比&lt;/b&gt;"><b>表1</b> ImageNet<b>竞赛中部分模型对比</b></a></li>
                                                <li><a href="#88" data-title="图2 训练网络结构">图2 训练网络结构</a></li>
                                                <li><a href="#108" data-title="图3 部分鱼类图像示例">图3 部分鱼类图像示例</a></li>
                                                <li><a href="#111" data-title="图4 实验流程框架图">图4 实验流程框架图</a></li>
                                                <li><a href="#118" data-title="图5 数据增广效果示例">图5 数据增广效果示例</a></li>
                                                <li><a href="#123" data-title="图6 InceptionV3模型1训练过程">图6 InceptionV3模型1训练过程</a></li>
                                                <li><a href="#125" data-title="图7 InceptionV3模型10训练过程">图7 InceptionV3模型10训练过程</a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表2 实验结果&lt;/b&gt;"><b>表2 实验结果</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;表3 图像预测结果&lt;/b&gt;"><b>表3 图像预测结果</b></a></li>
                                                <li><a href="#136" data-title="&lt;b&gt;表4 准确率对比&lt;/b&gt;"><b>表4 准确率对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Melendez SHow AI Can Help Keep Ocean Fishieries Sustainable[EB/OL].https://www.fastcompany.com/3066290/how-ai-can-help-keep-ocean-fisheries-sustainable." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=How AI Can Help Keep Ocean Fishieries Sustainable">
                                        <b>[1]</b>
                                         Melendez SHow AI Can Help Keep Ocean Fishieries Sustainable[EB/OL].https://www.fastcompany.com/3066290/how-ai-can-help-keep-ocean-fisheries-sustainable.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 杜伟东,李海森,魏玉阔,等.基于 SVM 的决策融合鱼类识别方法[J].哈尔滨工程大学学报,2015,36(5):623-627." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBG201505007&amp;v=MDcyNzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5oVzd2SkxTakphYkc0SDlUTXFvOUZZNFE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         杜伟东,李海森,魏玉阔,等.基于 SVM 的决策融合鱼类识别方法[J].哈尔滨工程大学学报,2015,36(5):623-627.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 张慧,王坤峰,王飞跃.深度学习在目标视觉检测中的应用进展与展望[J].自动化学报,2017,43(8):1289-1305." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201708001&amp;v=MzE4Njk5Yk1wNDlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluaFc3dkpLQ0xmWWJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         张慧,王坤峰,王飞跃.深度学习在目标视觉检测中的应用进展与展望[J].自动化学报,2017,43(8):1289-1305.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 张俊龙,曾国荪,覃如符.基于深度学习的海底观测视频中鱼类的识别方法[J].计算机应用,2019,39(2):72-77." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201902013&amp;v=MDg4MDJDVVI3cWZadVp0RnluaFc3dkpMejdCZDdHNEg5ak1yWTlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         张俊龙,曾国荪,覃如符.基于深度学习的海底观测视频中鱼类的识别方法[J].计算机应用,2019,39(2):72-77.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Qin H,Li X,Liang J,et al.DeepFish:Accurate Underwater Live Fish Recognition with a Deep Architecture[J].Neurocomputing,2015,187:49-58." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES59F9766BCF346B34E1F2BE25A1945F4F&amp;v=MjA0NzROdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJ5M3hLaz1OaWZPZmJheGFOakxxWWszRjUwTUNIcEx6QkptNjBsL09ncmdxV00wY0xhUk03N3BDTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Qin H,Li X,Liang J,et al.DeepFish:Accurate Underwater Live Fish Recognition with a Deep Architecture[J].Neurocomputing,2015,187:49-58.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Boom B J,Huang P X,He J,et al.Supporting Ground-Truth Annotation of Image Datasets Using Clustering[C]//Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012).IEEE,2012:1542-1545." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Supporting ground-truth annotation of image datasets using clustering">
                                        <b>[6]</b>
                                         Boom B J,Huang P X,He J,et al.Supporting Ground-Truth Annotation of Image Datasets Using Clustering[C]//Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012).IEEE,2012:1542-1545.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 顾郑平,朱敏.基于深度学习的鱼类分类算法研究[J].计算机应用与软件,2018,35(1):200-205." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801036&amp;v=MjE3NzF0RnluaFc3dkpMelRaWkxHNEg5bk1ybzlHWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         顾郑平,朱敏.基于深度学习的鱼类分类算法研究[J].计算机应用与软件,2018,35(1):200-205.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 王柯力,袁红春.基于迁移学习的水产动物图像识别方法[J].计算机应用,2017,38(5):1304-1308." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201805016&amp;v=MDY0NTZxQnRHRnJDVVI3cWZadVp0RnluaFc3dkpMejdCZDdHNEg5bk1xbzlFWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         王柯力,袁红春.基于迁移学习的水产动物图像识别方法[J].计算机应用,2017,38(5):1304-1308.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" >
                                        <b>[9]</b>
                                     Yosinski J,Clune J,Bengio Y,et al.How Transferable are Features in Deep Neural Networks?[C]//Advances in Neural Information Processing Systems.2014:3320-3328.</a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Kaggle.The Nature Conservancy Fisheries Monitoring[OL].https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/data." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Nature Conservancy Fisheries Monitoring[OL]">
                                        <b>[10]</b>
                                         Kaggle.The Nature Conservancy Fisheries Monitoring[OL].https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/data.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 魏秀参.解析深度学习:卷积神经网络原理与视觉实践[M].北京:电子工业出版社,2018:13-14." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121345289000&amp;v=MDcxMDVGcXpHYks2SDlMSXFvMU5iZXNQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5tVTc3TUtGb1ZY&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         魏秀参.解析深度学习:卷积神经网络原理与视觉实践[M].北京:电子工业出版社,2018:13-14.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Rumelhart D E,Hinton G E,Williams R J.Learning Representations by Back-Propagating Errors[J].Nature,1986,323(6088):533." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning representations by backpropagating errors">
                                        <b>[12]</b>
                                         Rumelhart D E,Hinton G E,Williams R J.Learning Representations by Back-Propagating Errors[J].Nature,1986,323(6088):533.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Bouvrie J.Notes on Convolutional Neural Networks[R].MIT CBCL Tech Report,Cambridge,MA,2006." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Notes on convolutional neural networks&amp;quot;">
                                        <b>[13]</b>
                                         Bouvrie J.Notes on Convolutional Neural Networks[R].MIT CBCL Tech Report,Cambridge,MA,2006.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Szegedy C,Vanhoucke V,Ioffe S,et al.Rethinking the Inception Architecture for Computer Vision[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rethinking the Inception Architecture for Computer Vision">
                                        <b>[14]</b>
                                         Szegedy C,Vanhoucke V,Ioffe S,et al.Rethinking the Inception Architecture for Computer Vision[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Szegedy C,Liu W,Jia Y,et al.Going Deeper with Convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2015:1-9." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">
                                        <b>[15]</b>
                                         Szegedy C,Liu W,Jia Y,et al.Going Deeper with Convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2015:1-9.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[EB].arXiv preprint arXiv:1409.1556,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition[EB]">
                                        <b>[16]</b>
                                         Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[EB].arXiv preprint arXiv:1409.1556,2014.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" >
                                        <b>[17]</b>
                                     Pan S J,Yang Q.A Survey on Transfer Learning[J].IEEE Transactions on Knowledge and Data Engineering,2010,22(10):1345-1359.</a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" He K,Zhang X,Ren S,et al.Deep Residual Learning for Image Recognition[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">
                                        <b>[18]</b>
                                         He K,Zhang X,Ren S,et al.Deep Residual Learning for Image Recognition[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:770-778.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Chollet F.Keras:The Python Deep Learning library[OL].https://keras.io." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Keras:The Python Deep Learning library[OL]">
                                        <b>[19]</b>
                                         Chollet F.Keras:The Python Deep Learning library[OL].https://keras.io.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Dietterich T G.Ensemble Methods in Machine Learning[C]//International Workshop on Multiple Classifier Systems.Springer,Berlin,Heidelberg,2000:1-15." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ensemble methods in Machine Learning">
                                        <b>[20]</b>
                                         Dietterich T G.Ensemble Methods in Machine Learning[C]//International Workshop on Multiple Classifier Systems.Springer,Berlin,Heidelberg,2000:1-15.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" 周志华.机器学习[M].北京:清华大学出版社,2016:181-182." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MDI5MjJ2bktyaWZaZVp2RnlubVU3N01LRm9WWEZxekdiQzRITlhPckkxTlkrc1BEQk04enhVU21EZDlTSDduM3hFOWZi&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         周志华.机器学习[M].北京:清华大学出版社,2016:181-182.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" PengpaiSH.Kaggle_NCFM[OL].https://github.com/ pengpaiSH/Kaggle_NCFM." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Kaggle_NCFM[OL]">
                                        <b>[22]</b>
                                         PengpaiSH.Kaggle_NCFM[OL].https://github.com/ pengpaiSH/Kaggle_NCFM.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" ML Wave.Kaggle Ensembling Guide[EB/OL].https://mlwave.com/kaggle-ensembling-guide/#more-877." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Kaggle Ensembling Guide">
                                        <b>[23]</b>
                                         ML Wave.Kaggle Ensembling Guide[EB/OL].https://mlwave.com/kaggle-ensembling-guide/#more-877.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" 许枫,张乔,张纯,等.Walsh 变换对鱼类特征识别的研究[J].应用声学,2015 (5):465-470." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYSN201505017&amp;v=MjY5NjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluaFc3dkpQRFRZWUxHNEg5VE1xbzlFWTRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[24]</b>
                                         许枫,张乔,张纯,等.Walsh 变换对鱼类特征识别的研究[J].应用声学,2015 (5):465-470.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" 吴一全,殷骏,戴一冕,等.基于蜂群优化多核支持向量机的淡水鱼种类识别[J].农业工程学报,2014,30(16):312-319." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201416040&amp;v=MjA3MTQ5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmhXN3ZKS3pUTWU3RzRIOVhOcVk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[25]</b>
                                         吴一全,殷骏,戴一冕,等.基于蜂群优化多核支持向量机的淡水鱼种类识别[J].农业工程学报,2014,30(16):312-319.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" 林明旺.基于卷积神经网络的鱼类图像识别与分类[J].电子技术与软件工程,2017 (6):82-83." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZRU201706065&amp;v=MTU5NzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluaFc3dkpJVGZaZTdHNEg5Yk1xWTlEWVk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[26]</b>
                                         林明旺.基于卷积神经网络的鱼类图像识别与分类[J].电子技术与软件工程,2017 (6):82-83.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title=" 林明旺.深度学习在鱼类图像识别与分类中的应用[J].数字技术与应用,2017 (4):96-97." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SZJT201704063&amp;v=MjA2MDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmhXN3ZKTmpmQmVyRzRIOWJNcTQ5RFo0UUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[27]</b>
                                         林明旺.深度学习在鱼类图像识别与分类中的应用[J].数字技术与应用,2017 (4):96-97.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(09),168-174 DOI:10.3969/j.issn.1000-386x.2019.09.030            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于迁移学习的复杂场景海洋鱼类识别方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%9D%87%E9%B9%8F&amp;code=42745795&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李均鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A5%9D%E5%BC%80%E8%89%B3&amp;code=27277006&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">祝开艳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E6%BE%8D&amp;code=42745796&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨澍</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A7%E8%BF%9E%E6%B5%B7%E6%B4%8B%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1694046&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大连海洋大学信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%A7%E8%BF%9E%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0222286&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">大连理工大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对海洋渔业监管复杂场景下鱼类识别面临的方法落后及系统性理论研究缺乏等问题,提出一种基于迁移学习模型融合的识别方法。通过ImageNet数据集获取预训练模型InceptionV3,把其特征提取部分作为实验模型的特征提取器,在特征提取器后接入AveragePooling层和Softmax分类层,形成新的训练网络;通过NCFM数据集对新的训练网络进行十折交叉验证,得到十个新的鱼类识别模型,进行模型融合后,识别准确率达到97.368%,比单纯新网络模型提高了29.868%。实验结果表明,该方法在复杂场景下的鱼类识别准确率及其泛化性等性能均优于已有相关方法,能够为渔业捕捞监管系统的智能化升级提供可靠的技术支撑。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%8D%E6%9D%82%E5%9C%BA%E6%99%AF&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">复杂场景;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%B7%E6%B4%8B%E9%B1%BC%E7%B1%BB%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">海洋鱼类识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">迁移学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">模型融合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李均鹏,硕士生,主研领域:机器学习,目标检测。;
                                </span>
                                <span>
                                    祝开艳,博士。;
                                </span>
                                <span>
                                    杨澍,本科生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-04</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61802046);</span>
                                <span>辽宁省教育厅项目(QL2017017);</span>
                    </p>
            </div>
                    <h1><b>OCEAN FISH RECOGNITION IN COMPLEX SCENE BASED ON TRANSFER LEARNING</b></h1>
                    <h2>
                    <span>Li Junpeng</span>
                    <span>Zhu Kaiyan</span>
                    <span>Yang Shu</span>
            </h2>
                    <h2>
                    <span>School of Information Engineering, Dalian Ocean University</span>
                    <span>School of Computer Science and Technology, Dalian University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Aiming at the problems of backward methods and lack of systematic theory of ocean fish recognition in complex scene of fishery supervision, this paper proposed a recognition method based on transfer learning model fusion. The pre-trained model of InceptionV3 was obtained from the ImageNet data set, and the feature extraction part was used as the feature extractor of the experimental model. After this, the Average Pooling layer and Softmax classification layer were connected to form a new training network. Then, the NCFM data set was used to cross validate the new training network. Ten new fish recognition models were obtained. After model fusion, the recognition accuracy reached 97.368%, which was 29.868% higher than that of the simple new network model. The experimental results show that the accuracy and generalization of fish recognition in complex scenes are better than the existing methods, which can provide reliable technical support for the intelligent upgrading of fishery fishing supervision system.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Complex%20scene&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Complex scene;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Ocean%20fish%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Ocean fish recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolution%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolution neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Transfer%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Transfer learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Model%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Model fusion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-04</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="57" name="57" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="58">非法无序的海洋渔业捕捞严重危害着海洋生态的可持续发展,而现有捕捞监管方法主要有船上观察员监管、声呐检测海底鱼群数量、渔船摄像头拍摄捕捞视频后人工分析等,这些方法对人的依赖性较强<citation id="140" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,而且往往存在效率低下甚至监管不作为等问题。为了确保禁渔期鱼类生态安全,缓解高昂的人工成本,实现对渔船长时间不间断地监控,许多国家开始尝试使用渔船摄像头结合计算机视觉技术来监控渔船捕捞情况<citation id="141" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。渔船摄像头拍摄的图像场景复杂,目标物周围往往存在光照、异类相似物、遮挡等强干扰因素。复杂的监管场景需要高度智能化的捕捞监管系统,这个系统的关键则是泛化性较强的鱼类识别方法,基于机器学习的图像识别方法为我们提供了借鉴。</p>
                </div>
                <div class="p1">
                    <p id="59">目前,根据特征提取方式的不同,机器学习领域有关鱼类识别的研究方法可以分为基于传统手工设计特征的学习方法和自动提取特征的学习方法。杜伟东等<citation id="142" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>依靠传统手工设计特征方式,利用小波包变换和离散余弦变换方法提取特征,然后利用支持向量机(Support Vector Machine,SVM)分类,最终对3种鱼类的整体识别准确率达到了90%以上。虽然该系统有不错的精度,但是手工设计特征的好坏主要依赖于经验和运气<citation id="143" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>,而且手工设计的特征一般都只针对特定的环境或物种,相关学习方法往往存在泛化性不足等问题。近年来,利用深度学习方法自动提取目标特征成为最有效的特征学习方法<citation id="144" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>,基于卷积神经网络(Convolutional Neural Network,CNN)的深度学习方法是其典型代表。在鱼类识别研究领域,张俊龙等<citation id="145" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>使用CNN结合图像预处理技术,对11种海底鱼类图像进行分类,识别准确率在90%以上。Qin等<citation id="146" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>使用CNN提取图像特征,SVM作为分类器,在Fish4-know-ladge(F4K)<citation id="147" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>鱼类数据集上识别准确率为98.64%,但其模型训练成本过大。而顾郑平等<citation id="148" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>使用迁移学习结合SVM分类器,大大降低了模型训练成本,在F4K鱼类数据集上准确率达到了98.6%。王柯力<citation id="149" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等使用迁移学习的方法,对4种水产动物的识别准确率为97.4%。但上述方法所采用的实验数据背景干扰较小,和渔业监管等复杂场景存在较大差异。机器学习领域有关复杂场景海洋鱼类识别方法的探讨,目前主要存在于Kaggle平台上的过度捕捞监管图像识别(The Nature Conservancy Fisheries Monitoring,NCFM)比赛,但该平台并不公布参赛方案的识别准确率等内容,也尚未发现相关方案的理论性探讨。总体看来,当前有关鱼类识别方法的文献中尚未发现专门针对捕捞监管复杂场景的系统性理论研究。</p>
                </div>
                <div class="p1">
                    <p id="60">卷积神经网络自动学习目标特征需要花费大量的时间,但是预训练后的卷积神经网络模型(PretrainedCNN)具有良好的可迁移性<citation id="150" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。在相似的任务上,PretrainedCNN经过迁移,既可以确保较为理想的训练效果,又可以节省大量的训练时间。所以,迁移学习近年来成为图像识别领域的主要方法之一。</p>
                </div>
                <div class="p1">
                    <p id="61">我们在研究海洋渔业捕捞监管智能化系统时发现,使用迁移学习和模型融合的方法可以有效解决复杂场景下海洋鱼类识别问题。该方法从ImageNet数据集获取InceptionV3预训练模型,把此模型的特征提取部分作为实验模型的特征提取器,并把非特征提取部分替换为AveragePooling(平均池化)层和Softmax分类层,形成新的训练网络(PretrainedCNN+Softmax),随后使用目标物周围有较强干扰的NCFM数据集(海洋捕捞监控数据,Kaggle)<citation id="151" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>对实验模型的网络结构参数进行微调(fine-tune),经过十折交叉验证后,得到十个存在差异的识别模型。为了进一步提高模型的识别准确率,实验过程中利用集成学习中的模型融合策略对这十个模型进行融合优化,以强化该方法在复杂场景下的鲁棒性和泛化性。</p>
                </div>
                <div class="p1">
                    <p id="62">本研究主要贡献在于提出了一种专门针对海洋渔业捕捞监管这种复杂场景的鱼类识别方法(Transfer Learning+Model Fusion)。较之其他方法,该方法将迁移学习和模型融合进行了有效结合:利用迁移学习降低网络复杂度,减少训练时间;利用模型融合技术进一步提高识别准确率、鲁棒性和泛化性。此外,本文在训练和预测环节都采用了数据增广策略,在解决样本数量不足问题的同时,有助于增强模型的泛化性。经实验对比验证,该方法识别准确率和泛化性等性能明显优于传统方法和现有相关深度学习方法,可以为海洋渔业捕捞监管系统的智能化升级提供可靠的技术支撑。</p>
                </div>
                <h3 id="63" name="63" class="anchor-tag"><b>1 实验模型与方法</b></h3>
                <h4 class="anchor-tag" id="64" name="64"><b>1.1 卷积神经网络</b></h4>
                <h4 class="anchor-tag" id="65" name="65"><b>1.1.1 基本原理</b></h4>
                <div class="p1">
                    <p id="66">卷积神经网络本质上是一种层次模型。原始数据经由输入层传入,通过卷积、池化和非线性激活函数映射等一系列操作的层层堆叠,将低层次的具象信息逐层提取表示为高层次的抽象信息,这个过程称为前向传播<citation id="152" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。最终,卷积神经网络的最后一层把目标任务形式化为损失函数,把预测结果和真实结果进行对比,得到误差后凭借反向传播算法<citation id="153" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>将其由最后一层逐层前传,参数校正更新后再次进行前向传播,如此往复,直到最后模型收敛<citation id="154" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。卷积操作运算公式如下<citation id="155" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="67"><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msubsup><mrow></mrow><mi>j</mi><mi>L</mi></msubsup><mo>=</mo><mi>f</mi><mrow><mo>(</mo><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Μ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mi>X</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></msubsup><mo>×</mo><mi>Κ</mi><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mi>L</mi></msubsup><mo>+</mo><mi>b</mi><msubsup><mrow></mrow><mi>j</mi><mi>L</mi></msubsup></mrow><mo>)</mo></mrow></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="69">式中:<i>L</i>表示神经网络层数,<i>K</i><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mi>L</mi></msubsup></mrow></math></mathml>表示卷积核,<i>M</i><sub><i>j</i></sub>表示输入特征图,特征图的每一层输出都会有唯一的偏置项<i>b</i>,<i>f</i>(·)表示激活函数。</p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>1.1.2 InceptionV3</b></h4>
                <div class="p1">
                    <p id="72">InceptionV3<citation id="156" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>是由Google在2014年发布的GoogLeNet(InceptionV1)<citation id="157" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>改进而来。GoogLeNet采用了Inception架构,对比传统卷积的单一尺寸卷积核操作,这种Inception架构选用多种尺寸的卷积核,并且在同一个卷积层进行卷积操作。同时,为了防止多种尺寸卷积核拼接到一起后feature map宽度过大而导致的参数数量过多问题,加入了1×1的卷积核降低feature map宽度。InceptionV3中的Inception模块有三种不同的卷积操作架构,如图1所示。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909031_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 InceptionV3中的Inception模块结构图" src="Detail/GetImg?filename=images/JYRJ201909031_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 InceptionV3中的Inception模块结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909031_07500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="76">显然,到了InceptionV3版本,Inception模块不仅改进了架构,使其包含三种不同的结构,而且汲取了VGGNet<citation id="158" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>精华思想,用小尺寸卷积核代替大尺寸卷积核,减少了计算量;同时,非线性映射的增多,也扩展了模型表达能力<citation id="159" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="77" name="77"><b>1.2 迁移学习</b></h4>
                <div class="p1">
                    <p id="78">把已有知识迁移到相似领域的新环境中应用的方法称为迁移学习<citation id="160" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。迁移学习的核心思想是复用,利用现有模型去解决新环境或新领域中的问题是其基本使命。</p>
                </div>
                <div class="p1">
                    <p id="79">迁移学习涉及到了域和任务的概念。一个域<i>D</i>主要由特征空间<i>χ</i>以及<i>χ</i>上的边际概率分布<i>P</i>(<i>X</i>)组成,其中,<i>X</i>={<i>x</i><sub>1</sub>,<i>x</i><sub>2</sub>,…,<i>x</i><sub><i>n</i></sub>}∈<i>χ</i>。对于给定的特定域,一个任务<i>T</i>包含标签空间<i>Y</i>和预测函数<i>f</i>(·)两个部分,即<i>T</i>={<i>Y</i>,<i>f</i>(·)}<citation id="161" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。若给定一个源域<i>D</i><sub>s</sub>和一个相对应的任务<i>T</i><sub>s</sub>,一个目标域<i>D</i><sub>t</sub>和一个相对应的任务<i>T</i><sub>t</sub>,在保证<i>D</i><sub>s</sub>≠<i>D</i><sub>t</sub>、<i>T</i><sub>s</sub>≠<i>T</i><sub>t</sub>的情况下,把在<i>D</i><sub>s</sub>、<i>T</i><sub>s</sub>中学到的信息应用到<i>D</i><sub>t</sub>、<i>T</i><sub>t</sub>中,以期<i>T</i><sub>t</sub>中的预测函数<i>f</i>(·)得到提高。</p>
                </div>
                <div class="p1">
                    <p id="80">目标域数据较少情况下,通过对神经网络的迁移,可以把源域数据上的预训练模型应用在目标域上,改进后形成新的训练模型,从而更好地解决目标任务。</p>
                </div>
                <h4 class="anchor-tag" id="81" name="81"><b>1.3 预训练模型</b></h4>
                <div class="p1">
                    <p id="82">如表1所示,VGG16、VGG19、ResNet50<citation id="162" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、GoogLeNet等都是在ImageNet上大放异彩的模型。通过对比这些模型在ImageNet上的Top1准确率、Top5准确率、训练参数量以及网络层数,发现InceptionV3在准确率较为理想的情况下,训练参数量也相对较少。因此,本研究选择InceptionV3作为预训练模型。</p>
                </div>
                <div class="area_img" id="83">
                    <p class="img_tit"><b>表1</b> ImageNet<b>竞赛中部分模型对比</b><citation id="163" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation><sup></sup> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="83" border="1"><tr><td>模型</td><td>大小<br />/MB</td><td>Top1<br />准确率/%</td><td>Top5<br />准确率/%</td><td>参数数目</td><td>层数</td></tr><tr><td><br />VGG16</td><td>528</td><td>0.715</td><td>0.901</td><td>138 357 544</td><td>23</td></tr><tr><td><br />VGG19</td><td>549</td><td>0.727</td><td>0.910</td><td>143 667 240</td><td>26</td></tr><tr><td><br />ResNet50</td><td>99</td><td>0.759</td><td>0.929</td><td>25 636 712</td><td>168</td></tr><tr><td><br />InceptionV3</td><td>92</td><td>0.788</td><td>0.944</td><td>23 851 784</td><td>159</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>1.4 微 调</b></h4>
                <div class="p1">
                    <p id="85">Jason Yosinski等<citation id="164" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>经过实验发现,神经网络前几层训练后得到的通用特征迁移效果较好,而网络变深后学习到的一些特定特征并不适合迁移;另外,深度迁移网络中加入fine-tune,可以较好地克服数据之间的差异,在目标任务中甚至比原始网络效果更好,而且发现网络层数的迁移可以加速网络学习和优化。本实验在针对网络层数进行迁移并构建完成新的训练网络后,使用fine-tune的方法对网络进行微调训练。</p>
                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>1.4.1 网络迁移</b></h4>
                <div class="p1">
                    <p id="87">不同数据集训练出的模型在深层网络的语义信息有较大差异。本实验从预训练模型InceptionV3中取出特征提取部分,作为实验模型的特征提取器,在特征提取器后接入AveragePooling层和Softmax分类层,新的训练网络结构(PretrainedCNN+Softmax)如图2所示。</p>
                </div>
                <div class="area_img" id="88">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909031_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 训练网络结构" src="Detail/GetImg?filename=images/JYRJ201909031_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 训练网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909031_088.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="89">为初步验证方法的性能,实验针对新网络直接进行训练,最终得到的模型(未经过微调、交叉验证和模型融合)识别准确率为67.5%。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>1.4.2 通过fine-tune微调网络</b></h4>
                <div class="p1">
                    <p id="91">如图2所示,本研究搭建的新网络保留了源模型的全部特征提取能力,即预训练模型底层通用特征部分的权重参数得到保留,而高层语义特征则针对目标域数据集重新训练,这种架构更加适应目标样本。另外,新网络的特征提取部分并不需要随机初始化,往往经过小幅度调整就能够收敛。所以,本实验针对目标域数据以0.000 1的学习率对整个网络重新训练,使其在目标任务上的表现更加优秀。同时,较低的学习率确保了权重参数每轮迭代变化幅度较小,可以有效避免过拟合。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>1.5 模型融合</b></h4>
                <div class="p1">
                    <p id="93">对模型本身的改进需要较长的研究周期,相比之下,模型融合能在较短时间内提升整个系统的认知能力。所以,本实验采用了集成学习中的模型融合策略,使算法性能得到进一步优化。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>1.5.1 模型融合的核心思想</b></h4>
                <div class="p1">
                    <p id="95">综合使用若干个基学习器,不同基学习器经过训练形成不同的模型,通过恰当的融合方法可以充分发挥各个模型的优势,最终得到一个经过优化后的结果。这个结果融合了多个模型的假设,抵消了单一假设和目标假设之间的误差,往往比单一模型得到的结果具有更强的鲁棒性和泛化性<citation id="165" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>。在模型融合时,如果单体模型性能较好且各个模型之间存在一定差异,进行融合后就会得到更好的效果。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>1.5.2 模型融合方法</b></h4>
                <div class="p1">
                    <p id="97">模型融合主要有投票法、学习法和平均法。结合本研究特点,拟采用平均法进行模型融合。平均法常用于数值型输出的任务,分为简单平均法和加权平均法。简单平均法是把各个训练模型的输出结果相加求平均后的结果作为最终输出结果,公式如下<citation id="166" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>Τ</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi>h</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="100">式中:<i>T</i>表示融合模型数量;<i>h</i><sub><i>i</i></sub>(<i>x</i>)表示单个模型的输出结果。加权平均法是把各个模型的输出结果加权求平均后的结果作为最终输出结果,公式如下<citation id="167" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="101"><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Τ</mi></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>h</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="103">式中:<i>T</i>表示融合模型数量;<i>w</i><sub><i>i</i></sub>表示模型权重(由训练获得);<i>h</i><sub><i>i</i></sub>(<i>x</i>)表示单个模型的输出结果。</p>
                </div>
                <div class="p1">
                    <p id="104">一般而言,模型之间性能相差较大时采用加权平均法,性能相近但存在一定差异时则采用简单平均法。</p>
                </div>
                <h3 id="105" name="105" class="anchor-tag"><b>2 实验与结果分析</b></h3>
                <h4 class="anchor-tag" id="106" name="106"><b>2.1 实验数据集</b></h4>
                <div class="p1">
                    <p id="107">本实验采用NCFM数据集,该数据集来源于kaggle数据竞赛平台。数据集图像由渔业监管组织安装在渔船上的摄像头拍摄,主要用来监测非法捕捞情况。该数据集共有3 777幅鱼类图像,分为8种识别类别,分别为鲯鳅鱼(DOL)、长鳍金枪鱼(ALB)、黄鳍金枪鱼(YFT)、大眼金枪鱼(BET)、月鱼(LAG)、鲨鱼(SHARK)、其他鱼类(OTHER)、无鱼类(NoF),其他鱼类和无鱼类图像的存在可以更好地提升训练模型的泛化性。图3为该数据集部分鱼类图像示例。观察图像可知,目标物处于有光照、异类相似物(甲板覆盖物破洞等)、遮挡等强干扰因素的复杂场景里。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909031_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 部分鱼类图像示例" src="Detail/GetImg?filename=images/JYRJ201909031_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 部分鱼类图像示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909031_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>2.2 实验设置与环境</b></h4>
                <div class="p1">
                    <p id="110">实验在系统环境为CentOS 7.5的阿里云服务器上进行,该服务器配备一张显存为16 GB的Tesla-P100显卡。设计实验方案时,在pengpaiSH<citation id="168" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>方案公开部分(Kaggle平台TOP5%,实验复现后准确率为89.55%)的基础上,进一步采用了增加数据增广种类、十折交叉验证以及模型融合等策略。训练使用以TensorFlow为后端的Keras框架,设置训练迭代次数(epoch)为100,批处理数量为32;在使用显存为7 819 MB的情况下,整体训练时间约41小时40分钟。实验流程框架如图4所示。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909031_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 实验流程框架图" src="Detail/GetImg?filename=images/JYRJ201909031_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 实验流程框架图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909031_111.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="112" name="112"><b>2.3 数据处理</b></h4>
                <h4 class="anchor-tag" id="113" name="113"><b>2.3.1 数据集划分</b></h4>
                <div class="p1">
                    <p id="114">实验采用分层抽样方法,把NCFM数据集内3 777幅图像划分为训练集、验证集、测试集,比例为8∶1∶1。其中,3 061幅用于训练,336幅用于交叉验证,380幅用于测试。为了确保交叉验证后得到的每个模型之间存在一定差异,实验随机划分了十个不同的训练集和交叉验证集,并使用同样的测试集验证模型性能。</p>
                </div>
                <h4 class="anchor-tag" id="115" name="115"><b>2.3.2 数据归一化与数据增广</b></h4>
                <div class="p1">
                    <p id="116">根据InceptionV3模型输入要求,本实验把数据集内大小不同的图像进行归一化,调整为299×299像素。</p>
                </div>
                <div class="p1">
                    <p id="117">数据增广可以增大样本量,有效避免过拟合。为了强化模型的泛化性和鲁棒性,本实验不仅在训练过程中进行了数据增广,而且在预测过程中也进行了数据增广。模型预测原图像后,会再预测增广后的图像。把模型对原图像预测的结果和对增广图像预测的结果相加求平均,所得平均数作为最终预测结果输出。实验采用的数据增广技术为角度变换、平移、横向和纵向翻转等。数据增广效果示例如图5所示。</p>
                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909031_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 数据增广效果示例" src="Detail/GetImg?filename=images/JYRJ201909031_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 数据增广效果示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909031_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="119" name="119"><b>2.4 模型差异性分析</b></h4>
                <div class="p1">
                    <p id="120">实验进行十折交叉验证后,得到十个不同的模型,任意选取其中两个(模型1,模型10)作为对照组,通过准确率以及损失值的变化曲线来观察模型之间的差异性。如图6、图7所示。其中:训练准确率表示训练集精度的变化,交叉验证准确率表示交叉验证集精度的变化;训练损失值表示训练集误差值的变化,交叉验证损失值表示交叉验证集误差值的变化。</p>
                </div>
                <div class="p1">
                    <p id="121">观察图6、图7可知:起初两个模型准确率都比较低,且损失函数的损失值都呈快速下降趋势;大约在60次迭代以后,两者都开始趋于收敛,而且模型在训练集和验证集上的准确率以及损失值都非常接近,模型表现良好,没有出现过拟合。对比图6、图7可知,模型10训练集图像和验证集图像之间的间隙相对于模型1较小,说明模型10的拟合能力比模型1好。两者对比表明,训练出的各个模型之间虽然性能相近但也存在一定差异,这一结果与实验预期一致。</p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909031_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 InceptionV3模型1训练过程" src="Detail/GetImg?filename=images/JYRJ201909031_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 InceptionV3模型1训练过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909031_12300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909031_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 InceptionV3模型10训练过程" src="Detail/GetImg?filename=images/JYRJ201909031_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 InceptionV3模型10训练过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909031_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="126" name="126"><b>2.5 实验结果</b></h4>
                <div class="p1">
                    <p id="127">Softmax分类层最终输出结果为数值型,且由图6、图7分析可知,各模型之间整体性能相近并存在一定差异,所以本实验采用了简单平均法对各模型进行融合。另外,为了验证模型融合是否对预测准确率有提升作用,本实验任意选取了3组单个模型(模型1、模型5、模型10)的准确率分别和模型融合后的准确率进行对比,对比结果如表2所示。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表2 实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="128" border="1"><tr><td><br />模型</td><td>训练准确率</td><td>验证准确率</td><td>测试准确率</td></tr><tr><td><br />模型1</td><td>98.050</td><td>96.130</td><td>95.790</td></tr><tr><td><br />模型5</td><td>98.600</td><td>96.430</td><td>96.330</td></tr><tr><td><br />模型10</td><td>99.020</td><td>97.320</td><td>96.850</td></tr><tr><td><br />模型融合</td><td>—</td><td>—</td><td>97.368</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="129">实验结果表明,模型融合策略利用不同模型之间的差异性,对各个模型的输出结果进行融合,在整体上起到了互补作用,测试准确率有明显提升,在模型1、模型5、模型10上分别提高1.578%、1.038%、0.518%。</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>2.6 方法泛化性分析</b></h4>
                <div class="p1">
                    <p id="131">为了验证模型融合后的泛化性是否得到了提升,本实验选取了图3中的(a)图(大眼金枪鱼)进行预测结果输出,该图为测试集中的图像。在这幅图像中,目标物周围存在较多类似鱼形状的甲板覆盖物破洞、渔民对鱼的遮挡以及渔民手上的白手套等典型强干扰因素,识别难度较大。分别输出模型1、模型5、模型10以及融合后的模型对这幅图像的预测结果(概率最高的种类为预测结果),如表3所示。</p>
                </div>
                <div class="area_img" id="132">
                    <p class="img_tit"><b>表3 图像预测结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="132" border="1"><tr><td><br /> 鱼类</td><td>模型1</td><td>模型5</td><td>模型10</td><td>模型融合</td></tr><tr><td><br />ALB</td><td>0.737 046</td><td>0.375 005</td><td>0.349 574</td><td>0.404 261</td></tr><tr><td><br />BET</td><td>0.202 407</td><td>0.544 655</td><td>0.490 109</td><td>0.496 990</td></tr><tr><td><br />DOL</td><td>0.002 973</td><td>0.003 403</td><td>0.004 708</td><td>0.003 341</td></tr><tr><td><br />LAG</td><td>0.005 525</td><td>0.008 304</td><td>0.006 625</td><td>0.006 957</td></tr><tr><td><br />NoF</td><td>0.001 315</td><td>0.003 353</td><td>0.000 696</td><td>0.003 010</td></tr><tr><td><br />OTHER</td><td>0.035 725</td><td>0.019 824</td><td>0.129 541</td><td>0.056 984</td></tr><tr><td><br />SHARK</td><td>0.006 557</td><td>0.007 046</td><td>0.004 799</td><td>0.005 815</td></tr><tr><td><br />YFT</td><td>0.008 451</td><td>0.038 411</td><td>0.013 948</td><td>0.022 642</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="133">由表3可知,单个模型输出结果对错皆有,模型融合后则得到正确结果。这是因为在深度学习中,模型可能会因为学习能力的强大而学习到数据上的一些噪音,进而导致模型考虑问题相对片面,很难泛化<citation id="169" type="reference"><link href="47" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>。通过融合多个模型并使用简单平均法对结果取平均,就会降低对噪音部分的考虑,增强方法整体的泛化性和鲁棒性。</p>
                </div>
                <h4 class="anchor-tag" id="134" name="134"><b>2.7 与相关方法对比分析</b></h4>
                <div class="p1">
                    <p id="135">本文方法与相关方法准确率对比如表4所示。</p>
                </div>
                <div class="area_img" id="136">
                    <p class="img_tit"><b>表4 准确率对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="136" border="1"><tr><td><br />方法</td><td>准确率/%</td></tr><tr><td><br />Walsh谱+BP<sup>[24]</sup></td><td>70.000</td></tr><tr><td><br />小波变换+SVM<sup>[2]</sup></td><td>90.000</td></tr><tr><td><br />Krawtch矩+LS-SVM<sup>[25]</sup></td><td>83.300</td></tr><tr><td><br />PretrainedCNN+Softmax</td><td>67.500</td></tr><tr><td><br />优化VGG16<sup>[26]</sup></td><td>96.240</td></tr><tr><td><br />优化VGG16+ Object Detection<sup>[27]</sup></td><td>96.990</td></tr><tr><td><br />Transfer Learning+Model Fusion</td><td>97.368</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="137">显然,和传统方法相比,利用迁移学习和模型融合的方法对海洋渔业捕捞监管复杂场景下的鱼类图像进行识别分类,准确率有明显提升,而且不需要人为设计特征,增强了模型的可用性。综合分析表3、表4可知,相较于CNN相关模型,迁移学习和模型融合的方法不但准确率更高而且泛化性也更强,对海洋渔业捕捞监管复杂场景具有明显的适用性。</p>
                </div>
                <h3 id="138" name="138" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="139">针对海洋渔业捕捞监管复杂场景,提出了一种基于迁移学习模型融合的海洋鱼类识别方法。该方法经过迁移学习节省了大量训练时间;利用交叉验证、模型融合和数据增广等策略则确保了其识别准确率和泛化性;在NCFM数据集上进行实验,识别准确率达到了97.368%。实验结果表明,使用迁移学习和模型融合的方法可以有效解决渔业监管复杂场景下的海洋鱼类识别问题,能够为渔业捕捞监管系统智能化升级提供可靠的技术支持。后续研究中,将尝试加入目标检测和多种不同模型融合技术,进一步提升复杂场景海洋鱼类识别方法的整体性能。在此基础上,结合信号处理技术,探讨识别方法在现实环境中的落地,力争在信号可传输的海洋区域实现季节性渔业捕捞监管的智能化和即时化。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=How AI Can Help Keep Ocean Fishieries Sustainable">

                                <b>[1]</b> Melendez SHow AI Can Help Keep Ocean Fishieries Sustainable[EB/OL].https://www.fastcompany.com/3066290/how-ai-can-help-keep-ocean-fisheries-sustainable.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HEBG201505007&amp;v=Mjk3Nzc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmhXN3ZKTFNqSmFiRzRIOVRNcW85Rlk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 杜伟东,李海森,魏玉阔,等.基于 SVM 的决策融合鱼类识别方法[J].哈尔滨工程大学学报,2015,36(5):623-627.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201708001&amp;v=MzIxNzBiTXA0OUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5oVzd2SktDTGZZYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 张慧,王坤峰,王飞跃.深度学习在目标视觉检测中的应用进展与展望[J].自动化学报,2017,43(8):1289-1305.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201902013&amp;v=MTQ4ODI3QmQ3RzRIOWpNclk5RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmhXN3ZKTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 张俊龙,曾国荪,覃如符.基于深度学习的海底观测视频中鱼类的识别方法[J].计算机应用,2019,39(2):72-77.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES59F9766BCF346B34E1F2BE25A1945F4F&amp;v=MDU1MzRrM0Y1ME1DSHBMekJKbTYwbC9PZ3JncVdNMGNMYVJNNzdwQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJ5M3hLaz1OaWZPZmJheGFOakxxWQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Qin H,Li X,Liang J,et al.DeepFish:Accurate Underwater Live Fish Recognition with a Deep Architecture[J].Neurocomputing,2015,187:49-58.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Supporting ground-truth annotation of image datasets using clustering">

                                <b>[6]</b> Boom B J,Huang P X,He J,et al.Supporting Ground-Truth Annotation of Image Datasets Using Clustering[C]//Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012).IEEE,2012:1542-1545.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801036&amp;v=MTY2ODVMRzRIOW5Ncm85R1lvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmhXN3ZKTHpUWlo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 顾郑平,朱敏.基于深度学习的鱼类分类算法研究[J].计算机应用与软件,2018,35(1):200-205.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201805016&amp;v=MjkyODc0SDluTXFvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5oVzd2Skx6N0JkN0c=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 王柯力,袁红春.基于迁移学习的水产动物图像识别方法[J].计算机应用,2017,38(5):1304-1308.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" >
                                    <b>[9]</b>
                                 Yosinski J,Clune J,Bengio Y,et al.How Transferable are Features in Deep Neural Networks?[C]//Advances in Neural Information Processing Systems.2014:3320-3328.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Nature Conservancy Fisheries Monitoring[OL]">

                                <b>[10]</b> Kaggle.The Nature Conservancy Fisheries Monitoring[OL].https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/data.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121345289000&amp;v=MTQ2NDN2RnlubVU3N01LRm9WWEZxekdiSzZIOUxJcW8xTmJlc1BEQk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVa&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 魏秀参.解析深度学习:卷积神经网络原理与视觉实践[M].北京:电子工业出版社,2018:13-14.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning representations by backpropagating errors">

                                <b>[12]</b> Rumelhart D E,Hinton G E,Williams R J.Learning Representations by Back-Propagating Errors[J].Nature,1986,323(6088):533.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Notes on convolutional neural networks&amp;quot;">

                                <b>[13]</b> Bouvrie J.Notes on Convolutional Neural Networks[R].MIT CBCL Tech Report,Cambridge,MA,2006.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rethinking the Inception Architecture for Computer Vision">

                                <b>[14]</b> Szegedy C,Vanhoucke V,Ioffe S,et al.Rethinking the Inception Architecture for Computer Vision[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:2818-2826.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Going deeper with convolutions">

                                <b>[15]</b> Szegedy C,Liu W,Jia Y,et al.Going Deeper with Convolutions[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.2015:1-9.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very deep convolutional networks for large-scale image recognition[EB]">

                                <b>[16]</b> Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognition[EB].arXiv preprint arXiv:1409.1556,2014.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" >
                                    <b>[17]</b>
                                 Pan S J,Yang Q.A Survey on Transfer Learning[J].IEEE Transactions on Knowledge and Data Engineering,2010,22(10):1345-1359.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">

                                <b>[18]</b> He K,Zhang X,Ren S,et al.Deep Residual Learning for Image Recognition[C].Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2016:770-778.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Keras:The Python Deep Learning library[OL]">

                                <b>[19]</b> Chollet F.Keras:The Python Deep Learning library[OL].https://keras.io.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ensemble methods in Machine Learning">

                                <b>[20]</b> Dietterich T G.Ensemble Methods in Machine Learning[C]//International Workshop on Multiple Classifier Systems.Springer,Berlin,Heidelberg,2000:1-15.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MTMwMTRNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5tVTc3TUtGb1ZYRnF6R2JDNEhOWE9ySTFOWStzUERC&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 周志华.机器学习[M].北京:清华大学出版社,2016:181-182.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Kaggle_NCFM[OL]">

                                <b>[22]</b> PengpaiSH.Kaggle_NCFM[OL].https://github.com/ pengpaiSH/Kaggle_NCFM.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Kaggle Ensembling Guide">

                                <b>[23]</b> ML Wave.Kaggle Ensembling Guide[EB/OL].https://mlwave.com/kaggle-ensembling-guide/#more-877.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YYSN201505017&amp;v=MDA5MDVMRzRIOVRNcW85RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmhXN3ZKUERUWVk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[24]</b> 许枫,张乔,张纯,等.Walsh 变换对鱼类特征识别的研究[J].应用声学,2015 (5):465-470.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU201416040&amp;v=MDg1ODNNZTdHNEg5WE5xWTlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluaFc3dkpLelQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[25]</b> 吴一全,殷骏,戴一冕,等.基于蜂群优化多核支持向量机的淡水鱼种类识别[J].农业工程学报,2014,30(16):312-319.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZRU201706065&amp;v=MzE4NjNaZTdHNEg5Yk1xWTlEWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluaFc3dkpJVGY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[26]</b> 林明旺.基于卷积神经网络的鱼类图像识别与分类[J].电子技术与软件工程,2017 (6):82-83.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SZJT201704063&amp;v=MjM5MDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnluaFc3dkpOamZCZXJHNEg5Yk1xNDlEWjRRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[27]</b> 林明旺.深度学习在鱼类图像识别与分类中的应用[J].数字技术与应用,2017 (4):96-97.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201909031" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909031&amp;v=MDU4MDFyQ1VSN3FmWnVadEZ5bmhXN3JBTHpUWlpMRzRIOWpNcG85R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
