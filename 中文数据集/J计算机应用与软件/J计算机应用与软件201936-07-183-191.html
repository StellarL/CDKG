<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135626140315000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201907032%26RESULT%3d1%26SIGN%3dsGnwL35aFgIwCELjxV7wOLOCJtY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907032&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907032&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907032&amp;v=MjQ0NjRSN3FmWnVadEZ5amhVci9OTHpUWlpMRzRIOWpNcUk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#44" data-title="&lt;b&gt;1 手势纹理特征提取&lt;/b&gt; "><b>1 手势纹理特征提取</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="&lt;b&gt;1.1 手势纹理的GLCM特征&lt;/b&gt;"><b>1.1 手势纹理的GLCM特征</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;1.2 手势纹理的Gabor特征&lt;/b&gt;"><b>1.2 手势纹理的Gabor特征</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;1.3 手势纹理特征的构建&lt;/b&gt;"><b>1.3 手势纹理特征的构建</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#138" data-title="&lt;b&gt;2 手势识别&lt;/b&gt; "><b>2 手势识别</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#146" data-title="&lt;b&gt;3 实验结果及分析&lt;/b&gt; "><b>3 实验结果及分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#162" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="图1 本文算法流程图">图1 本文算法流程图</a></li>
                                                <li><a href="#46" data-title="图2 典型手势的灰度图像">图2 典型手势的灰度图像</a></li>
                                                <li><a href="#51" data-title="图3 圆形邻域中的位置关系">图3 圆形邻域中的位置关系</a></li>
                                                <li><a href="#54" data-title="图4 共生矩阵生成过程">图4 共生矩阵生成过程</a></li>
                                                <li><a href="#56" data-title="图5 圆形邻域中的0&#176;方向位置关系">图5 圆形邻域中的0°方向位置关系</a></li>
                                                <li><a href="#122" data-title="图6 离散像素示意图">图6 离散像素示意图</a></li>
                                                <li><a href="#132" data-title="图7 Gabor滤波器">图7 Gabor滤波器</a></li>
                                                <li><a href="#141" data-title="图8 深度堆栈自编码网络结构">图8 深度堆栈自编码网络结构</a></li>
                                                <li><a href="#144" data-title="图9 网络数据的传递过程">图9 网络数据的传递过程</a></li>
                                                <li><a href="#144" data-title="图9 网络数据的传递过程">图9 网络数据的传递过程</a></li>
                                                <li><a href="#149" data-title="图10 本文手势种类">图10 本文手势种类</a></li>
                                                <li><a href="#149" data-title="图10 本文手势种类">图10 本文手势种类</a></li>
                                                <li><a href="#151" data-title="图11 手势识别结果">图11 手势识别结果</a></li>
                                                <li><a href="#155" data-title="图12 旋转后手势识别结果">图12 旋转后手势识别结果</a></li>
                                                <li><a href="#155" data-title="图12 旋转后手势识别结果">图12 旋转后手势识别结果</a></li>
                                                <li><a href="#159" data-title="图13 缩放后手势识别结果">图13 缩放后手势识别结果</a></li>
                                                <li><a href="#159" data-title="图13 缩放后手势识别结果">图13 缩放后手势识别结果</a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表1 手势识别结果对比&lt;/b&gt;"><b>表1 手势识别结果对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 杨纪争, 冯筠, 卜起荣, 等.面向静态手势识别的边缘序列递归模型算法[J].计算机辅助设计与图形学学报, 2017, 29 (4) :599-606." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201704004&amp;v=MDU3MDVMRzRIOWJNcTQ5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVci9OTHo3QmE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         杨纪争, 冯筠, 卜起荣, 等.面向静态手势识别的边缘序列递归模型算法[J].计算机辅助设计与图形学学报, 2017, 29 (4) :599-606.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Ren Y, Xie X, Li G, et al.Hand Gesture Recognition with Multi-Scale Weighted Histogram of Contour Direction (MSWHCD) Normalization for Wearable Applications[J].IEEE Transactions on Circuits &amp;amp; Systems for Video Technology, 2018, 28 (2) :364-377." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hand Gesture Recognition with Multi-Scale Weighted Histogram of Contour Direction (MSWHCD) Normalization for Wearable Applications">
                                        <b>[2]</b>
                                         Ren Y, Xie X, Li G, et al.Hand Gesture Recognition with Multi-Scale Weighted Histogram of Contour Direction (MSWHCD) Normalization for Wearable Applications[J].IEEE Transactions on Circuits &amp;amp; Systems for Video Technology, 2018, 28 (2) :364-377.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Zhou Y, Jiang G, Lin Y.A novel finger and hand pose estimation technique for hand gesture recognition[M].Elsevier Science Inc., 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel finger and hand pose estimation technique for hand gesture recognition">
                                        <b>[3]</b>
                                         Zhou Y, Jiang G, Lin Y.A novel finger and hand pose estimation technique for hand gesture recognition[M].Elsevier Science Inc., 2016.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 文芳, 康彩琴, 陈立文, 等.基于RGBD数据的静态手势识别[J].计算机与现代化, 2018 (1) :74-77." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYXH201801017&amp;v=MjgxNDVyRzRIOW5Ncm85RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVci9OTHpUVFo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         文芳, 康彩琴, 陈立文, 等.基于RGBD数据的静态手势识别[J].计算机与现代化, 2018 (1) :74-77.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 高晨, 张亚军.基于Kinect深度图像的指尖检测与手势识别[J].计算机系统应用, 2017, 26 (4) :192-197." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201704032&amp;v=MjMyODFUblNkN0c0SDliTXE0OUdab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXIvTlA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         高晨, 张亚军.基于Kinect深度图像的指尖检测与手势识别[J].计算机系统应用, 2017, 26 (4) :192-197.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 蒲兴成, 王涛, 张毅.基于改进Hu矩算法的Kinect手势识别[J].计算机工程, 2016, 42 (7) :165-172." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201607029&amp;v=MTY4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05MejdCYmJHNEg5Zk1xSTlIYllRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         蒲兴成, 王涛, 张毅.基于改进Hu矩算法的Kinect手势识别[J].计算机工程, 2016, 42 (7) :165-172.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Chevtchenko S F, Vale R F, Macario V.Multi-objective optimization for hand posture recognition [J].Expert Systems with Applications, 2018, 92:170-181." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE7A7C3CFBCF70A0D44C6F73568ABA2AE&amp;v=MDk5NjEySVg3a3g3UG5qaHFSUTlDTURsUjh2cUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMeSt3SzA9TmlmT2ZjYS9iOWEvclB3ekZwaDVDM3hJeg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Chevtchenko S F, Vale R F, Macario V.Multi-objective optimization for hand posture recognition [J].Expert Systems with Applications, 2018, 92:170-181.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 曹雏清, 李瑞峰, 赵立军.基于深度图像技术的手势识别方法[J].计算机工程, 2012, 38 (8) :16-18." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201208008&amp;v=MDA0OTFNcDQ5RmJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVci9OTHo3QmJiRzRIOVA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         曹雏清, 李瑞峰, 赵立军.基于深度图像技术的手势识别方法[J].计算机工程, 2012, 38 (8) :16-18.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 刘淑萍, 刘羽, 於俊, 等.结合手指检测和HOG特征的分层静态手势识别[J].中国图象图形学报, 2015, 20 (6) :781-788." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201506007&amp;v=MDI5OTVoVXIvTlB5cmZiTEc0SDlUTXFZOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         刘淑萍, 刘羽, 於俊, 等.结合手指检测和HOG特征的分层静态手势识别[J].中国图象图形学报, 2015, 20 (6) :781-788.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 屈燕琴, 李昕, 卢夏衍.基于表观特征分析的手势识别及其应用[J].计算机工程与科学, 2015, 37 (1) :139-145." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201501022&amp;v=MTE5NDI3QlpiRzRIOVRNcm85SFpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVci9OTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         屈燕琴, 李昕, 卢夏衍.基于表观特征分析的手势识别及其应用[J].计算机工程与科学, 2015, 37 (1) :139-145.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 杨学文, 冯志全, 黄忠柱, 等.结合手势主方向和类-Hausdorff距离的手势识别[J].计算机辅助设计与图形学学报, 2016, 28 (1) :75-81." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201601010&amp;v=MDQ4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05MejdCYUxHNEg5Zk1ybzlFWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         杨学文, 冯志全, 黄忠柱, 等.结合手势主方向和类-Hausdorff距离的手势识别[J].计算机辅助设计与图形学学报, 2016, 28 (1) :75-81.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 曹洁, 赵修龙, 王进花.融合改进指尖点和Hu矩的手势识别[J].计算机工程与应用, 2017, 53 (21) :138-143." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201721024&amp;v=MDU0MzZxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05MejdNYWJHNEg5Yk9ybzlIWUlRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         曹洁, 赵修龙, 王进花.融合改进指尖点和Hu矩的手势识别[J].计算机工程与应用, 2017, 53 (21) :138-143.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 王龙, 刘辉, 王彬, 等.结合肤色模型和卷积神经网络的手势识别方法[J].计算机工程与应用, 2017, 53 (6) :209-214." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201706038&amp;v=MzIzOTF0RnlqaFVyL05MejdNYWJHNEg5Yk1xWTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         王龙, 刘辉, 王彬, 等.结合肤色模型和卷积神经网络的手势识别方法[J].计算机工程与应用, 2017, 53 (6) :209-214.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 吴晓凤, 张江鑫, 徐欣晨.基于Faster R-CNN的手势识别算法[J].计算机辅助设计与图形学学报, 2018, 30 (3) :468-476." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201803012&amp;v=MTQ2MDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05MejdCYUxHNEg5bk1ySTlFWm9RS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         吴晓凤, 张江鑫, 徐欣晨.基于Faster R-CNN的手势识别算法[J].计算机辅助设计与图形学学报, 2018, 30 (3) :468-476.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Gomez-Donoso F, Orts-Escolano S, Cazorla M.Robust Hand Pose Regression Using Convolutional Neural Networks[C]//ROBOT 2017:Third Iberian Robotics Conference.Springer, 2017:591-602." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust Hand Pose Regression Using Convolutional Neural Networks">
                                        <b>[15]</b>
                                         Gomez-Donoso F, Orts-Escolano S, Cazorla M.Robust Hand Pose Regression Using Convolutional Neural Networks[C]//ROBOT 2017:Third Iberian Robotics Conference.Springer, 2017:591-602.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 蒋穗峰, 李艳春, 肖南峰.基于手势识别的工业机器人操作控制方法[J].计算机应用, 2016 (12) :3486-3491." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201612045&amp;v=MDM5MDI3QmQ3RzRIOWZOclk5QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVci9OTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         蒋穗峰, 李艳春, 肖南峰.基于手势识别的工业机器人操作控制方法[J].计算机应用, 2016 (12) :3486-3491.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" 陶美平, 马力, 黄文静, 等.基于无监督特征学习的手势识别方法[J].微电子学与计算机, 2016, 33 (1) :100-103." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201601022&amp;v=MDAxNTMzenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05NalhTWkxHNEg5Zk1ybzlIWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         陶美平, 马力, 黄文静, 等.基于无监督特征学习的手势识别方法[J].微电子学与计算机, 2016, 33 (1) :100-103.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(07),183-191 DOI:10.3969/j.issn.1000-386x.2019.07.031            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于GLCM和Gabor纹理特征的手势识别算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E4%BA%91%E5%B3%B0&amp;code=13963804&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李云峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%BE%8E%E6%82%A6&amp;code=38629945&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张澎悦</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E6%9C%BA%E7%94%B5%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0207099&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南科技大学机电工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%9C%BA%E6%A2%B0%E8%A3%85%E5%A4%87%E5%85%88%E8%BF%9B%E5%88%B6%E9%80%A0%E6%B2%B3%E5%8D%97%E7%9C%81%E5%8D%8F%E5%90%8C%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">机械装备先进制造河南省协同创新中心</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对手势灰度图像的纹理特征富含手势类别信息的特点, 提出一种基于融合GLCM (灰度共生矩阵) 和Gabor小波变换提取手势图像空、频域纹理特征的手势识别方法。构建手势灰度图像的多方向共生矩阵, 并计算多方向共生矩阵的特征参数来提取手势纹理的GLCM特征;通过手势灰度图像的Gabor小波变换来提取手势纹理的Gabor特征;对所提取的两种特征进行归一化处理后串联构建手势纹理特征向量;使用基于稀疏自动编码器和softmax分类器的深度堆栈自编码网络对构建的手势纹理特征向量进行分类识别。实验表明:该方法具有较高的识别率和较好的鲁棒性, 对15种手势的平均识别率达到97.4%, 能够满足人机交互对手势识别的要求。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">手势识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">纹理特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B1%E7%94%9F%E7%9F%A9%E9%98%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">共生矩阵;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gabor%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gabor小波变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%A0%86%E6%A0%88%E8%87%AA%E7%BC%96%E7%A0%81%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度堆栈自编码网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李云峰, 副教授, 主研领域:生物特征识别, 机器学习。;
                                </span>
                                <span>
                                    张澎悦, 硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61702163);</span>
                    </p>
            </div>
                    <h1><b>GESTURE RECOGNITION ALGORITHM BASED ON TEXTURE FEATURE OF GLCM AND GABOR</b></h1>
                    <h2>
                    <span>Li Yunfeng</span>
                    <span>Zhang Pengyue</span>
            </h2>
                    <h2>
                    <span>School of Mechatronics Engineering, Henan University of Science and Technology</span>
                    <span>Collaborative Innovation Center of Machinery Equipment Advanced Manufacturing of Henan Province</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>For the characteristic that the texture feature of gray gesture image is rich in the information of gesture category, a gesture recognition method based on fusion of Gray-level Co-occurrence Matrix (GLCM) and Gabor wavelet transform was proposed to extract spatial and frequency domain texture features of gesture images. We, constructed multi-direction co-occurrence matrix of gesture gray image and calculated feature parameters of multi-direction co-occurrence matrix to extract GLCM features of gesture texture. The Gabor features of gesture texture was extracted by Gabor wavelet transform of gray gesture image. Then, the two extracted features were normalized to construct the feature vector of gesture texture in series. The deep stack encoder network based on sparse encoder and softmax classifier was used to classify and recognize feature vector of gesture texture. Experiments show that the proposed method has high recognition rate and good robustness, with the average recognition rate of 97.4% among fifteen gestures, which can meet the requirements of gesture recognition for human-computer interaction.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gesture%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gesture recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Texture%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Texture feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Co-occurrence%20matrix&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Co-occurrence matrix;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gabor%20wavelet%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gabor wavelet transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20stack%20encoder%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep stack encoder network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="38">最近几年, 人们对智能化生活的需求日益增强, 发展方便、舒适、灵活的交互方式成为研究人员的迫切要求。以人类手部为基础的手势语言具有直观、自然、丰富的特点, 符合人类的交流习惯, 手势识别正引起国内外研究学者的关注。对于手势识别, 提取手势特征是手势识别算法的重要组成部分。</p>
                </div>
                <div class="p1">
                    <p id="39">杨纪争等<citation id="164" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>从手势边缘序列角度出发, 建立跟随空间变化的时空域边缘序列, 并根据计算递归图像之间的距离完成手势识别。Ren等<citation id="165" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>利用轮廓梯度多尺度加权直方图进行手势方向的计算, 并使用轮廓点的位置与方向进行特征提取, 利用支持向量机进行手势识别。Zhou等<citation id="166" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>从手势图像中提取边缘, 通过并行边缘特征提取手势轮廓突出的边缘点, 并以手腕位置为中心, 提取手的位置、方向进行手势识别。文芳等<citation id="167" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提取手势轮廓的圆形度、凸包点以及缺陷点等信息构建特征向量进行手势识别。高晨等<citation id="168" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出一基于轮廓凸包检测指尖的算法, 并将指尖数目、相邻两个指尖夹角等作为特征向量进行手势识别。上述文献是在手势轮廓的基础上运用相应的算法进行手势识别。虽然这些算法的运算量较小, 算法结构不复杂, 具有一定的实用性, 但是手势轮廓所包含的信息有限, 较难为手势识别提供更多有效的特征, 不便进一步提升算法的性能, 具有一定的局限性。</p>
                </div>
                <div class="p1">
                    <p id="40">除了利用手势轮廓信息构建特征外, 还有研究学者使用手势的二值图像进行特征提取。蒲兴成等<citation id="169" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>利用手势二值图像的 Hu不变矩以及手指个数作为特征向量, 使用支持向量机进行手势识别。Chevtchenko等<citation id="170" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>对手势二值图像采用傅立叶描绘子、Zernike矩、伪Zernike矩、Hu矩、复数矩构建特征向量, 采用多层感知器神经网络进行分类识别。曹雏清等<citation id="171" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>利用深度传感器的数据分割出手势, 并提取手势二值图中包含的手指数量、手指间的夹角作为特征向量进行手势识别。刘淑萍等<citation id="172" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>利用形态学处理消除手掌区域, 通过计算连通域个数检测手指数量, 并结合手势图像的HOG特征进行手势识别。屈燕琴等<citation id="173" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>利用手势二值图像提取手指弧度、指间弧度、手指数目等组建特征向量进行手势识别。杨学文等<citation id="174" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>利用重心与边缘确定手势主要方向, 并建立手势直角坐标系提取空间特征, 使用手势坐标点分布特征以及距离模板进行手势识别。曹杰等<citation id="175" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>利用曲率提取手势中指尖位置, 并结合二值图像的Hu不变矩进行手势识别。上述文献多利用手势二值图像的表观特征进行手势识别。虽然这些算法提取的手势特征结合相应的识别算法在识别率上取得一定的效果, 但仍存在一些不足需要进一步改进, 如算法结构复杂, 实时性和鲁棒性不高等。</p>
                </div>
                <div class="p1">
                    <p id="41">除了上述利用轮廓、二值图像提取手势特征外, 机器学习中的一些网络模型可以从图像中自动提取相应的手势特征。王龙等<citation id="176" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>利用卷积神经网络自动提取手势图像的特征进行手势的分类与识别。吴晓凤等<citation id="177" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>利用改进的卷积神经网络Faster R-CNN对手势图像进行特征提取以及识别分类。Gomez-Donoso等<citation id="178" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>使用卷积神经网络估计手势图像中手部的关节点位置, 并利用关节信息预测手势的类别。蒋穗峰等<citation id="179" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>利用稀疏自编码器提取手势图像的特征, 并利用softmax分类器进行手势识别。陶美平等<citation id="180" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>将手势图像分块后训练稀疏自动编码器获取手势的边缘特征, 并使用该特征利用分类器进行手势识别。上述文献虽然算法复杂程度较低, 但算法的针对性不强, 平均识别率不高, 还需诸多改进来满足手势识别的要求。</p>
                </div>
                <div class="p1">
                    <p id="42">目前手势识别算法多利用轮廓、二值图像等提取相应特征, 虽然取得了诸多进展, 但是在特征提取过程中丢失较多手势的纹理信息, 如边缘轮廓细节、手掌纹路、肌肉凸凹区域、手指关节表面细节等。因此本文从手势灰度图像的纹理含有丰富的手势类别信息的角度出发, 提出一种基于GLCM和Gabor小波变换的手势纹理特征的手势识别方法。该方法首先通过构造多方向共生矩阵和Gabor滤波器来提取手势纹理的GLCM特征和Gabor特征;其次将所提取的两种纹理特征归一化后串联构建手势纹理特征向量;最后, 利用深度堆栈自编码网络对所构建的手势纹理特征向量进行学习与识别, 进一步提高手势识别方法的泛化能力。本文算法的流程图如图1所示。</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文算法流程图" src="Detail/GetImg?filename=images/JYRJ201907032_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="44" name="44" class="anchor-tag"><b>1 手势纹理特征提取</b></h3>
                <div class="p1">
                    <p id="45">如图2所示, 手势的灰度图像蕴含大量的纹理信息, 其中不仅包含现有手势识别常用的边缘轮廓细节信息等, 还蕴含人手的表面纹路、手指关节表面细节等类别信息。针对手势纹理的特点, 基于像素灰度统计的共生矩阵对纹理的局部变化特点, 如像素点之间的变化幅度、相互关联等, 有较好的表征能力;而Gabor小波变换通过Gabor滤波函数对手势灰度图像进行卷积运算, 可以得到其不同频率、尺度、方向的纹理信息, 对整体纹理的变化有较强的描述能力。因此, 为了充分利用手势灰度图像中的纹理信息, 提高所提取特征的有效性, 本文提取手势纹理的GLCM特征和Gabor特征构建手势纹理特征向量。首先构建多方向共生矩阵统计手势灰度图像中两个像素灰度级之间的联合分布, 并提取共生矩阵的角二阶矩、对比度、相关性、熵以及逆差矩作为手势纹理的GLCM特征;其次, 构建Gabor滤波器对手势灰度图像进行Gabor小波变换, 提取不同频率、方向的Gabor小波系数作为手势纹理的Gabor特征;最后分别将提取到的GLCM特征和Gabor特征进行归一化后串联构建本文的手势纹理特征向量。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 典型手势的灰度图像" src="Detail/GetImg?filename=images/JYRJ201907032_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 典型手势的灰度图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="47" name="47"><b>1.1 手势纹理的GLCM特征</b></h4>
                <h4 class="anchor-tag" id="48" name="48"><b>1.1.1 多方向共生矩阵的构建</b></h4>
                <div class="p1">
                    <p id="49">共生矩阵通过统计手势灰度图像中灰度为<i>a</i>和<i>b</i>的像素对满足某一方向位置关系次数来表征纹理分布。图像中像素对的位置关系越多, 所构建的共生矩阵数量就越多, 对手势纹理的描述就越丰富。因此本文首先建立像素对多个方向的位置关系, 以达到提取多个共生矩阵的目的。</p>
                </div>
                <div class="p1">
                    <p id="50">设<i>Q</i>代表中心像素点与其圆形邻域边界上像素点所有方向的位置关系, 规定中心像素点水平向右为该圆形邻域的0°方向, 且像素对位置关系的指向是从中心像素点至圆形邻域边界上的像素点。若以圆形邻域的0°方向为起始位置, 以角度<i>θ</i>为间隔在圆形邻域中建立像素对位置关系, 那么中心像素点与其圆形邻域边界上的像素点一共存在360°/<i>θ</i>个方向的位置关系, 即<i>Q</i>∈ [ 0°, <i>θ</i>, 2<i>θ</i>, …, <i>kθ</i>], <i>kθ</i>=360°-<i>θ</i>。图3为中心像素点与其圆形邻域边界上像素点所有方向的位置关系示意图, 其中圆形邻域半径<i>r</i>=3, 间隔角度<i>θ</i>=45°, 从而形成8个方向的位置关系。通过调整圆形邻域半径<i>r</i>与间隔角度<i>θ</i>可以形成多种不同的像素对位置关系, 进而统计生成相应的共生矩阵。</p>
                </div>
                <div class="area_img" id="51">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 圆形邻域中的位置关系" src="Detail/GetImg?filename=images/JYRJ201907032_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 圆形邻域中的位置关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_051.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="52">假设一幅手势图像<i>f</i>拥有<i>L</i>个灰度级, <i>G</i>代表一个矩阵, 则矩阵中元素<i>g</i><sub><i>i</i>, <i>j</i></sub>的值是中心像素点灰度值为<i>z</i><sub><i>i</i></sub>和其圆形邻域边界上像素点灰度值为<i>z</i><sub><i>j</i></sub>的像素对在图像<i>f</i>中符合某一方向位置关系的总次数, 其中1≤<i>i</i>, <i>j</i>≤<i>L</i>, 按此方法统计所形成的矩阵为该方向位置关系的共生矩阵。</p>
                </div>
                <div class="p1">
                    <p id="53">图4为共生矩阵生成过程。以图4 (a) 中灰度图像统计生成0°方向位置关系共生矩阵的过程为例。首先按上述形成位置关系<i>Q</i>的方法构建圆形邻域0°方向的位置关系, 位置关系的指向是从中心像素点至圆形邻域边界上0°方向的像素点, 为方便示例圆形邻域的半径<i>r</i>=1。</p>
                </div>
                <div class="area_img" id="54">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_05400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 共生矩阵生成过程" src="Detail/GetImg?filename=images/JYRJ201907032_05400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 共生矩阵生成过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_05400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="55">然后遍历图4 (a) 中的灰度图像, 统计所有中心像素点灰度值为<i>z</i><sub><i>i</i></sub>和其圆形邻域边界上像素点灰度值为<i>z</i><sub><i>j</i></sub>的像素对符合0°方向位置关系的总次数, 并将其值赋予共生矩阵中的元素<i>g</i><sub><i>i</i>, <i>j</i></sub>。当共生矩阵中所有元素均统计完毕时, 即可得到0°方向位置关系的共生矩阵。例如在图4 (a) 中所有中心像素点灰度值为1和其圆形邻域边界上像素点灰度值为2的像素对符合0°位置关系的总次数为2, 图中的实线箭头为图5中圆形邻域0°方向位置关系的简化表示, 则图4 (b) 中共生矩阵元素<i>g</i><sub>12</sub>的值为2。其他方向位置关系共生矩阵的生成方法与0°方向位置关系共生矩阵的方法相同, 只是统计时所使用位置关系的方向不同。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 圆形邻域中的0&#176;方向位置关系" src="Detail/GetImg?filename=images/JYRJ201907032_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 圆形邻域中的0°方向位置关系  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="57">根据本文建立的位置关系可以生成360°/<i>θ</i>个共生矩阵, 从而可以使共生矩阵能够统计多个方向的手势灰度纹理。另外从共生矩阵的生成方法可知所生成矩阵大小与手势图像<i>f</i>的灰度级相关, 为<i>L</i>×<i>L</i>。而手势图像的灰度级数较大, 在统计共生矩阵时较大幅度的增加算法的运算量。因此, 在使用手势灰度图像统计多个方向的共生矩阵前, 先对手势灰度图像进行灰度级数缩减处理, 减小算法运算量, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="58"><mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>f</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>n</mi></mrow><mrow><mn>2</mn><mn>5</mn><mn>6</mn></mrow></mfrac></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>f</i> (<i>x</i>, <i>y</i>) 为原手势灰度图像, <i>f</i>′ (<i>x</i>, <i>y</i>) 为灰度级缩减后的灰度图像, <i>n</i>为缩减后灰度级数。最终可以统计得到360°/<i>θ</i>个<i>n</i>×<i>n</i>大小的共生矩阵。</p>
                </div>
                <h4 class="anchor-tag" id="61" name="61"><b>1.1.2 手势纹理GLCM特征的构建</b></h4>
                <div class="p1">
                    <p id="62">通过本文共生矩阵的构造方法, 可以得到手势图像中多个方向的纹理分布特点。为了对这些纹理分布特点进行有效的表征, 本文计算所有方向共生矩阵的角二阶矩、对比度、相关性、熵、逆差矩五个特征参数作为手势纹理的GLCM特征, 从而达到描述手势纹理分布特点的目的, 公式如下所示:</p>
                </div>
                <div class="p1">
                    <p id="63">角二阶矩<i>W</i><sub>1</sub>:</p>
                </div>
                <div class="p1">
                    <p id="64"><i>W</i><sub>1</sub>=<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><b><i>G</i></b><sup>2</sup> (<i>i</i>, <i>j</i>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="66">对比度<i>W</i><sub>2</sub>:</p>
                </div>
                <div class="p1">
                    <p id="67"><i>W</i><sub>2</sub>=<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml>[ (<i>i</i>-<i>j</i>) <sup>2</sup>·<b><i>G</i></b> (<i>i</i>, <i>j</i>) ]      (3) </p>
                </div>
                <div class="p1">
                    <p id="69">相关性<i>W</i><sub>3</sub>:</p>
                </div>
                <div class="p1">
                    <p id="70"><i>W</i><sub>3</sub>=<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>i</mi><mo>⋅</mo><mi>j</mi><mo>⋅</mo><mi mathvariant="bold-italic">G</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>u</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mi>u</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>δ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⋅</mo><mi>δ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="73"><i>u</i><sub>1</sub>=<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><i>i</i>·<b><i>G</i></b> (<i>i</i>, <i>j</i>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="75"><i>u</i><sub>2</sub>=<mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><i>j</i>·<b><i>G</i></b> (<i>i</i>, <i>j</i>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="77"><i>δ</i><mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math></mathml>=<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml> (<i>i</i>-<i>u</i><sub>1</sub>) <sup>2</sup>·<b><i>G</i></b> (<i>i</i>, <i>j</i>)      (7) </p>
                </div>
                <div class="p1">
                    <p id="80"><i>δ</i><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>=<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml> (<i>j</i>-<i>u</i><sub>2</sub>) <sup>2</sup>·<b><i>G</i></b> (<i>i</i>, <i>j</i>)      (8) </p>
                </div>
                <div class="p1">
                    <p id="83">熵<i>W</i><sub>4</sub>:</p>
                </div>
                <div class="p1">
                    <p id="84"><i>W</i><sub>4</sub>=-<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml>[<b><i>G</i></b> (<i>i</i>, <i>j</i>) ·lg<b><i>G</i></b> (<i>i</i>, <i>j</i>) ]      (9) </p>
                </div>
                <div class="p1">
                    <p id="86">逆差矩<i>W</i><sub>5</sub>:</p>
                </div>
                <div class="p1">
                    <p id="87"><i>W</i><sub>5</sub>=<mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow></mrow></mstyle></mrow></math></mathml><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi mathvariant="bold-italic">G</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mrow><mn>1</mn><mo>+</mo><mo stretchy="false"> (</mo><mi>i</mi><mo>-</mo><mi>j</mi><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="90">式中:<b><i>G</i></b>为共生矩阵, <i>n</i>为共生矩阵的阶数, <i>u</i><sub>1</sub>、<i>u</i><sub>2</sub>、<i>δ</i><sub>1</sub>、<i>δ</i><sub>2</sub>为式 (4) 中的过渡参数。从而构建5×360°/<i>θ</i>维的手势纹理的GLCM特征:</p>
                </div>
                <div class="p1">
                    <p id="91"><i>α</i>= [ <i>W</i><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>0</mn></msubsup></mrow></math></mathml>, <i>W</i><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>0</mn></msubsup></mrow></math></mathml>, <i>W</i><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mn>0</mn></msubsup></mrow></math></mathml>, <i>W</i><mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mn>0</mn></msubsup></mrow></math></mathml>, <i>W</i><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>5</mn><mn>0</mn></msubsup></mrow></math></mathml>, …, <i>W</i><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mrow><mi>k</mi><mi>θ</mi></mrow></msubsup></mrow></math></mathml>, <i>W</i><mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mrow><mi>k</mi><mi>θ</mi></mrow></msubsup></mrow></math></mathml>, <i>W</i><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>3</mn><mrow><mi>k</mi><mi>θ</mi></mrow></msubsup></mrow></math></mathml>, <i>W</i><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>4</mn><mrow><mi>k</mi><mi>θ</mi></mrow></msubsup></mrow></math></mathml>, <i>W</i><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>5</mn><mrow><mi>k</mi><mi>θ</mi></mrow></msubsup></mrow></math></mathml>]</p>
                </div>
                <div class="p1">
                    <p id="102">式中:多个共生矩阵的特征参数按其统计时所对应位置关系方向的大小排列。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103"><b>1.2 手势纹理的Gabor特征</b></h4>
                <h4 class="anchor-tag" id="104" name="104"><b>1.2.1 Gabor滤波器的构建</b></h4>
                <div class="p1">
                    <p id="105">二维Gabor小波变换可以提取图像不同频率尺度和方向的纹理信息。Gabor小波变换是利用滤波器与图像进行卷积运算将原始图像转换到频域空间, 滤波器的表达式为:</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ψ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>⋅</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">∥</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></msup><mo>⋅</mo><mo stretchy="false">[</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mo stretchy="false"> (</mo><mi>i</mi><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mover accent="true"><mi>x</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">) </mo></mrow></msup><mo>-</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msup><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="107">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201907032_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="109">式中:<mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>→</mo></mover></math></mathml>为给定位置的图像坐标, <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub></mrow></math></mathml>为滤波器的中心频率, <i>λ</i>为纹理波长, <i>φ</i><sub><i>μ</i></sub>为滤波器的方向角, <i>σ</i>为滤波器窗口大小。从中可以看出Gabor滤波器的表达式为一个复函数, 实部<i>Re</i>和虚部<i>lm</i>分别可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mrow><mi>R</mi><mi>e</mi></mrow><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>⋅</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">∥</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></msup><mo>⋅</mo><mo stretchy="false">[</mo><mrow><mi>cos</mi></mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">) </mo><mo>-</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mrow><mo>) </mo></mrow></mrow></msup><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>l</mi><mi>m</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">∥</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mo>⋅</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mo stretchy="false">∥</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">∥</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></msup><mo>⋅</mo><mo stretchy="false">[</mo><mrow><mi>sin</mi></mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>k</mi><mo>→</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">从上述Gabor滤波器的表达式可知, Gabor滤波函数受参数<i>φ</i><sub><i>μ</i></sub>、<i>k</i><sub><i>ν</i></sub>和<i>σ</i>的影响。通过调整参数<i>φ</i><sub><i>μ</i></sub>、<i>k</i><sub><i>ν</i></sub>和<i>σ</i>即可得到不同方向、频带、大小的Gabor滤波器, 然后利用得到滤波器对图像进行Gabor小波变换的处理, 从而获取图像中每个像素点所对应的Gabor小波系数。对图像的Gabor变换可以用与图像卷积来表达:</p>
                </div>
                <div class="p1">
                    <p id="114"><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mrow><mo>∫</mo><mi>Ι</mi></mrow></mstyle><mo stretchy="false"> (</mo><msup><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo>′</mo></msup><mo stretchy="false">) </mo><mi>ψ</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo>-</mo><msup><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo>′</mo></msup><mo stretchy="false">) </mo><mtext>d</mtext><msup><mrow></mrow><mn>2</mn></msup><msup><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo>′</mo></msup></mrow></math></mathml>      (15) </p>
                </div>
                <div class="p1">
                    <p id="116">式中:<mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false"> (</mo><mover accent="true"><mi>x</mi><mo>→</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>为Gabor变换后像素点<mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>→</mo></mover></math></mathml>在频域的数值, 为图像中坐标为<mathml id="119"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>x</mi><mo>→</mo></mover></math></mathml>的像素点。其对图像进行Gabor小波变换的过程就是利用Gabor滤波器遍历该图像, 使Gabor滤波器与其覆盖的图像邻域利用式 (15) 作卷积运算, 并将运算结果作为当前图像邻域中心像素点在频域的数值, 即Gabor小波系数。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>1.2.2 手势纹理Gabor特征的构建</b></h4>
                <div class="p1">
                    <p id="121">对灰度图像进行Gabor小波变换后可以得到所有像素点对应的Gabor小波系数。而对于一幅手势灰度图像, 其中位置较邻近的像素点所对应的Gabor小波系数相似, 可以使用一点的小波系数代替周围的像素点。如图6所示, 在手势灰度图像中选取若干均匀分布的离散像素点, 并将灰度图像划分为与离散像素点相对应的若干邻域, 划分数量记为<i>n</i>。在对离散位置像素点进行Gabor小波变换时, 滤波器窗口<i>σ</i>的大小与离散位置像素点的邻域大小相同。在利用式 (15) 进行卷积运算时, Gabor滤波器不再遍历整个图像, 而是只与<i>n</i>个离散像素点对应的邻域进行卷积运算, 从而得到离散像素的Gabor小波系数<i>F</i><sub><i>i</i></sub>, <i>i</i>∈[1, 2, …, <i>n</i>]。提取所有离散位置像素点的Gabor小波系数, 即可得到<i>m</i>×<i>n</i>个Gabor小波系数, <i>m</i>为所构建的滤波器个数, 并将这些Gabor小波系数作为手势纹理的Gabor特征。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 离散像素示意图" src="Detail/GetImg?filename=images/JYRJ201907032_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 离散像素示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="123">本文所选取的Gabor滤波器参数如下:<i>k</i><sub><i>v</i></sub>=π/4, π/2, <i>φ</i><sub><i>μ</i></sub>=0, π/4, π/2, 3π/4, <i>σ</i>与离散点邻域的大小相同, 从而可以得到8个Gabor滤波器, 如图7所示。经过离散像素位置Gabor计算后, 最终提取到8×<i>n</i>维的手势纹理的Gabor特征:</p>
                </div>
                <div class="p1">
                    <p id="124"><i>β</i>= [ <i>F</i><mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>1</mn></msubsup></mrow></math></mathml>, <i>F</i><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>1</mn></msubsup></mrow></math></mathml>, …, <i>F</i><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mn>1</mn></msubsup></mrow></math></mathml>, <i>F</i><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>1</mn><mn>2</mn></msubsup></mrow></math></mathml>, <i>F</i><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow></math></mathml>, …, <i>F</i><mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mn>8</mn></msubsup></mrow></math></mathml>]</p>
                </div>
                <div class="p1">
                    <p id="131">式中:上标对应不同的Gabor滤波器, 下标对应所选取的离散位置像素点的标号。</p>
                </div>
                <div class="area_img" id="132">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 Gabor滤波器" src="Detail/GetImg?filename=images/JYRJ201907032_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 Gabor滤波器  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_132.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="133" name="133"><b>1.3 手势纹理特征的构建</b></h4>
                <div class="p1">
                    <p id="134">由于所提取的两种纹理特征的数量级不同, 因此先对提取到的GLCM特征和Gabor特征分别进行归一化处理, 公式如下所示:</p>
                </div>
                <div class="p1">
                    <p id="135"><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>h</mi></mrow></munder><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>h</mi></mrow></munder><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">}</mo><mo>-</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>h</mi></mrow></munder><mo stretchy="false">{</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">}</mo></mrow></mfrac></mrow></math></mathml>      (16) </p>
                </div>
                <div class="p1">
                    <p id="137">式中:<i>x</i><sub><i>i</i></sub>为特征向量中的第<i>i</i>个特征值, <i>y</i><sub><i>i</i></sub>为归一化后的结果。设<i>α</i>′、<i>β</i>′分别表示归一化后的GLCM特征和Gabor特征, 并将两者串联组成本文的手势纹理特征量<i>γ</i>=[<i>α</i>′, <i>β</i>′], 共178维, 其中手势纹理的GLCM特征50维, Gabor特征128维。</p>
                </div>
                <h3 id="138" name="138" class="anchor-tag"><b>2 手势识别</b></h3>
                <div class="p1">
                    <p id="139">本文手势纹理特征向量中包含两种不同表征意义的纹理特征量, 为了更加有效地进行手势的分类与识别, 本文利用机器学习理论中的稀疏自动编码器与softmax分类器组建深度堆栈自编码网络进行手势识别。深度堆栈自编码网络共四层, 分别为输入层、两层稀疏编码器以及softmax分类器, 如图8所示, 图中+1节点为该层的偏置项。深度堆栈自编码网络的层数和节点数远远多于传统神经网络, 通过采用逐层训练的预训练方法, 加快了网络的收敛速度并避免陷入局部最优解, 使其可以通过输入特征数据形成具有更加抽象、高级的特征, 从而发现输入数据的分布式特征表征, 到达有效学习输入特征数据的目的。其中稀疏自动编码器为3 层神经元结构, 输入层的节点数与输出层节点数相等, 隐含层节点数少于输入层的节点数, 如图9 (a) 所示, 其通过学习一个恒等函数, 使输出层的目标值接近于输入层的输入值, 从而获得输入特征数据的相关性和压缩表示。而softmax分类器则利用softmax回归模型将经过两层稀疏自动编码处理的输入特征数据进行分类, 从而完成本文纹理特征的识别分类。</p>
                </div>
                <div class="p1">
                    <p id="140">本文网络的数据传递过程如下, 首先将提取的特征数据输入第一层稀疏自动编码器, 可以得到输入数据在FeatureI层的特征表征数据, 如图9 (a) 所示;然后将FeatureI层的特征表征数据作为第二层稀疏自动编码器的输入, 可以得到FeatureII层的特征表征数据, 如图9 (b) 所示;最后将FeatureII层的特征表征数据作为softmax分类器的输入, 如图9 (c) 所示, 从而完成网络的数据传递。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 深度堆栈自编码网络结构" src="Detail/GetImg?filename=images/JYRJ201907032_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 深度堆栈自编码网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 网络数据的传递过程" src="Detail/GetImg?filename=images/JYRJ201907032_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 网络数据的传递过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_14401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 网络数据的传递过程" src="Detail/GetImg?filename=images/JYRJ201907032_14401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 网络数据的传递过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_14401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="145">本文利用逐层训练的方法对深度堆栈自编码网络进行预训练, 过程如下:首先输入手势纹理特征向量训练网络中的第一层稀疏自动编码器, 当训练完成后可以得到FeatureI层的一阶特征数据;其次输入该一阶特征数据训练第二层稀疏自动编码器, 当训练完成后可以得到FeatureII层的二阶特征数据;然后输入该二阶特征数据训练softmax分类器, 从而完成网络的预训练过程。当所有层训练完毕, 对整体网络进行微调, 从而完成对深度堆栈自编码网络的训练。通过微调可以大幅提升网络的性能表现, 首先将网络的所有层视为一个模型, 在每一次迭代中优化整体网络中所有的连接权重以及偏值项。</p>
                </div>
                <h3 id="146" name="146" class="anchor-tag"><b>3 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="147">为验证本文手势方法的有效性, 利用手势样本提取特征进行实验。本文数据库包含15种手势, 每种手势200幅图像, 如图10所示, 并从1到15进行编号。其中从本文数据库中挑选800个手势图像作为训练数据, 1 200个作为识别数据。</p>
                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 本文手势种类" src="Detail/GetImg?filename=images/JYRJ201907032_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 本文手势种类  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_14901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 本文手势种类" src="Detail/GetImg?filename=images/JYRJ201907032_14901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 本文手势种类  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_14901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="150">图11为本文、文献<citation id="181" type="reference">[<a class="sup">7</a>]</citation>以及文献<citation id="182" type="reference">[<a class="sup">13</a>]</citation>的实验结果。图12为将数据库中的样本分别旋转-20°、-10°、10°、20°后本文、文献<citation id="183" type="reference">[<a class="sup">7</a>]</citation>以及文献<citation id="184" type="reference">[<a class="sup">13</a>]</citation>的实验结果。图13为将数据库中的样本分别缩放0.5、0.75、1.25、1.5倍后本文、文献<citation id="185" type="reference">[<a class="sup">7</a>]</citation>以及文献<citation id="186" type="reference">[<a class="sup">13</a>]</citation>的实验结果。图中横坐标为手势序号, 纵坐标为相应的序号的识别率。为验证识别率的稳定性, 采用各个手势识别率的标准差作为参考, 手势识别实验结果的对比如表1所示。</p>
                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图11 手势识别结果" src="Detail/GetImg?filename=images/JYRJ201907032_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图11 手势识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="155">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_15500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 旋转后手势识别结果" src="Detail/GetImg?filename=images/JYRJ201907032_15500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 旋转后手势识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_15500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="155">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_15501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图12 旋转后手势识别结果" src="Detail/GetImg?filename=images/JYRJ201907032_15501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图12 旋转后手势识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_15501.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="159">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_15900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 缩放后手势识别结果" src="Detail/GetImg?filename=images/JYRJ201907032_15900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 缩放后手势识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_15900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="159">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907032_15901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图13 缩放后手势识别结果" src="Detail/GetImg?filename=images/JYRJ201907032_15901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图13 缩放后手势识别结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907032_15901.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表1 手势识别结果对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td><br />图像类别</td><td>参数类型</td><td colspan="3">手势识别方法</td></tr><tr><td><br />[3]本文</td><td>文献[7]</td><td>文献[13]</td><td></td><td></td></tr><tr><td><br />原始图像</td><td>平均识别率</td><td>97.4%</td><td>95.8%</td><td>94.5%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.59</td><td>0.65</td><td>0.88</td></tr><tr><td><br />旋转-20°<br />处理</td><td>平均识别率</td><td>96.8%</td><td>95.1%</td><td>94.4%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.57</td><td>0.79</td><td>0.84</td></tr><tr><td><br />旋转-10°<br />处理</td><td>平均识别率</td><td>96.9%</td><td>95.7%</td><td>94.9%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.55</td><td>0.73</td><td>0.86</td></tr><tr><td><br />旋转10°<br />处理</td><td>平均识别率</td><td>97.1%</td><td>96.1%</td><td>94.7%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.59</td><td>0.70</td><td>0.79</td></tr><tr><td><br />旋转20°<br />处理</td><td>平均识别率</td><td>96.8%</td><td>95.5%</td><td>95.1%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.61</td><td>1.07</td><td>0.85</td></tr><tr><td><br />缩放0.5<br />处理</td><td>平均识别率</td><td>97.0%</td><td>95.7%</td><td>95.3%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.65</td><td>0.86</td><td>0.72</td></tr><tr><td><br />缩放0.75<br />处理</td><td>平均识别率</td><td>96.8%</td><td>95.5%</td><td>94.8%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.60</td><td>0.74</td><td>0.90</td></tr><tr><td><br />缩放1.25<br />处理</td><td>平均识别率</td><td>97.1%</td><td>95.7%</td><td>94.3%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.61</td><td>0.94</td><td>0.76</td></tr><tr><td><br />缩放1.5<br />处理</td><td>平均识别率</td><td>96.9%</td><td>95.6%</td><td>94.0%</td></tr><tr><td><br /></td><td>识别率标准差</td><td>0.54</td><td>0.82</td><td>0.93</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="161">从上述对比实验的结果可知, 本文方法的平均识别率高于文献<citation id="187" type="reference">[<a class="sup">7</a>]</citation>以及文献<citation id="188" type="reference">[<a class="sup">13</a>]</citation>的方法, 且识别率的标准差最小。在不同旋转角度下以及缩放尺度下, 依然保持较高的识别率, 对于所有手势种类而言十分稳定, 具有良好的旋转不变性以及缩放不变性, 从而也验证了本文手势识别方法的稳定性和准确性。</p>
                </div>
                <h3 id="162" name="162" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="163">本文利用手势灰度图像的纹理含有丰富的手势类别信息的特点, 提出一种基于共生矩阵和Gabor小波变换的手势纹理特征提取方法。首先, 构建多方向共生矩阵提取手势纹理的GLCM特征;其次, 通过在手势灰度图像的Gabor小波变换提取手势纹理的Gabor特征;然后通过归一化处理将两种特征串联构建手势纹理特征, 并利用稀疏自动编码器和softmax分类组成的深度堆栈自编码网络进行手势识别。实验表明, 本文方法有效可行, 对15种手势的平均识别率为97.4%。但是本文的特征提取方法对手势图像中纹理信息的利用仍然不够充分, 还有待提升。因此下一步工作是优化本文的特征提取方法, 使其能够最大程度地利用手势纹理信息, 从而进一步提高识别的准确率以及对各种类型的手势图像的适应性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201704004&amp;v=MDAyOTJGeWpoVXIvTkx6N0JhTEc0SDliTXE0OUZZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 杨纪争, 冯筠, 卜起荣, 等.面向静态手势识别的边缘序列递归模型算法[J].计算机辅助设计与图形学学报, 2017, 29 (4) :599-606.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hand Gesture Recognition with Multi-Scale Weighted Histogram of Contour Direction (MSWHCD) Normalization for Wearable Applications">

                                <b>[2]</b> Ren Y, Xie X, Li G, et al.Hand Gesture Recognition with Multi-Scale Weighted Histogram of Contour Direction (MSWHCD) Normalization for Wearable Applications[J].IEEE Transactions on Circuits &amp; Systems for Video Technology, 2018, 28 (2) :364-377.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel finger and hand pose estimation technique for hand gesture recognition">

                                <b>[3]</b> Zhou Y, Jiang G, Lin Y.A novel finger and hand pose estimation technique for hand gesture recognition[M].Elsevier Science Inc., 2016.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYXH201801017&amp;v=MTIzODI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXIvTkx6VFRackc0SDluTXJvOUVZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 文芳, 康彩琴, 陈立文, 等.基于RGBD数据的静态手势识别[J].计算机与现代化, 2018 (1) :74-77.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XTYY201704032&amp;v=MTc0MjFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05QVG5TZDdHNEg5Yk1xNDlHWm9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 高晨, 张亚军.基于Kinect深度图像的指尖检测与手势识别[J].计算机系统应用, 2017, 26 (4) :192-197.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201607029&amp;v=MTg3MTZVci9OTHo3QmJiRzRIOWZNcUk5SGJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 蒲兴成, 王涛, 张毅.基于改进Hu矩算法的Kinect手势识别[J].计算机工程, 2016, 42 (7) :165-172.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE7A7C3CFBCF70A0D44C6F73568ABA2AE&amp;v=MTk3MTh4N1BuamhxUlE5Q01EbFI4dnFDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THkrd0swPU5pZk9mY2EvYjlhL3JQd3pGcGg1QzN4SXoySVg3aw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Chevtchenko S F, Vale R F, Macario V.Multi-objective optimization for hand posture recognition [J].Expert Systems with Applications, 2018, 92:170-181.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJC201208008&amp;v=MTk4OTVxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVci9OTHo3QmJiRzRIOVBNcDQ5RmJJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 曹雏清, 李瑞峰, 赵立军.基于深度图像技术的手势识别方法[J].计算机工程, 2012, 38 (8) :16-18.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201506007&amp;v=MDU0NDdmWnVadEZ5amhVci9OUHlyZmJMRzRIOVRNcVk5Rlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 刘淑萍, 刘羽, 於俊, 等.结合手指检测和HOG特征的分层静态手势识别[J].中国图象图形学报, 2015, 20 (6) :781-788.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201501022&amp;v=MjE3MjZHNEg5VE1ybzlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05MejdCWmI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 屈燕琴, 李昕, 卢夏衍.基于表观特征分析的手势识别及其应用[J].计算机工程与科学, 2015, 37 (1) :139-145.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201601010&amp;v=MTQ3NzFNcm85RVpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVci9OTHo3QmFMRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 杨学文, 冯志全, 黄忠柱, 等.结合手势主方向和类-Hausdorff距离的手势识别[J].计算机辅助设计与图形学学报, 2016, 28 (1) :75-81.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201721024&amp;v=MTE1MzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05MejdNYWJHNEg5Yk9ybzlIWUk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 曹洁, 赵修龙, 王进花.融合改进指尖点和Hu矩的手势识别[J].计算机工程与应用, 2017, 53 (21) :138-143.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201706038&amp;v=MDE4Njk5Yk1xWTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFVyL05MejdNYWJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 王龙, 刘辉, 王彬, 等.结合肤色模型和卷积神经网络的手势识别方法[J].计算机工程与应用, 2017, 53 (6) :209-214.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201803012&amp;v=MTk5MTJGeWpoVXIvTkx6N0JhTEc0SDluTXJJOUVab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 吴晓凤, 张江鑫, 徐欣晨.基于Faster R-CNN的手势识别算法[J].计算机辅助设计与图形学学报, 2018, 30 (3) :468-476.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust Hand Pose Regression Using Convolutional Neural Networks">

                                <b>[15]</b> Gomez-Donoso F, Orts-Escolano S, Cazorla M.Robust Hand Pose Regression Using Convolutional Neural Networks[C]//ROBOT 2017:Third Iberian Robotics Conference.Springer, 2017:591-602.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201612045&amp;v=MjU2NjdmWnVadEZ5amhVci9OTHo3QmQ3RzRIOWZOclk5QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 蒋穗峰, 李艳春, 肖南峰.基于手势识别的工业机器人操作控制方法[J].计算机应用, 2016 (12) :3486-3491.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201601022&amp;v=MjYyOTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXIvTk1qWFNaTEc0SDlmTXJvOUhab1E=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 陶美平, 马力, 黄文静, 等.基于无监督特征学习的手势识别方法[J].微电子学与计算机, 2016, 33 (1) :100-103.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201907032" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907032&amp;v=MjQ0NjRSN3FmWnVadEZ5amhVci9OTHpUWlpMRzRIOWpNcUk5R1pvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
