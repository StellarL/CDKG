<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135740666533750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201905022%26RESULT%3d1%26SIGN%3d8h%252fu4wac5bVixUmJo%252fXK3auPEfo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201905022&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201905022&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201905022&amp;v=MjA5MjhadVp0Rnl6a1U3N0tMelRaWkxHNEg5ak1xbzlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="&lt;b&gt;1 基于图割的视频分割算法&lt;/b&gt; "><b>1 基于图割的视频分割算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;1.1 能量函数&lt;/b&gt;"><b>1.1 能量函数</b></a></li>
                                                <li><a href="#49" data-title="&lt;b&gt;1.2 颜色模型&lt;/b&gt;"><b>1.2 颜色模型</b></a></li>
                                                <li><a href="#72" data-title="&lt;b&gt;1.3 对比度模型&lt;/b&gt;"><b>1.3 对比度模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#78" data-title="&lt;b&gt;2 纹理特征和Canny算子对能量函数的改进&lt;/b&gt; "><b>2 纹理特征和Canny算子对能量函数的改进</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="&lt;b&gt;2.1 纹理特征对颜色分量的改进&lt;/b&gt;"><b>2.1 纹理特征对颜色分量的改进</b></a></li>
                                                <li><a href="#103" data-title="&lt;b&gt;2.2 Canny算子对光滑项的改进&lt;/b&gt;"><b>2.2 Canny算子对光滑项的改进</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#128" data-title="&lt;b&gt;3 实验结果和讨论&lt;/b&gt; "><b>3 实验结果和讨论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#141" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="图1 颜色相似度结果">图1 颜色相似度结果</a></li>
                                                <li><a href="#158" data-title="图2 旧颜色分量结果">图2 旧颜色分量结果</a></li>
                                                <li><a href="#102" data-title="图3 新颜色分量结果">图3 新颜色分量结果</a></li>
                                                <li><a href="#109" data-title="图4 原图Canny边缘检测结果">图4 原图Canny边缘检测结果</a></li>
                                                <li><a href="#110" data-title="图5 颜色模型Canny边缘检测结果">图5 颜色模型Canny边缘检测结果</a></li>
                                                <li><a href="#126" data-title="图6 改进后对比度分量结果">图6 改进后对比度分量结果</a></li>
                                                <li><a href="#133" data-title="图7 ac视频序列本文算法结果">图7 ac视频序列本文算法结果</a></li>
                                                <li><a href="#134" data-title="图8 Background Cut算法和本文算法比较">图8 Background Cut算法和本文算法比较</a></li>
                                                <li><a href="#135" data-title="图9 Bilayer算法和本文算法比较">图9 Bilayer算法和本文算法比较</a></li>
                                                <li><a href="#136" data-title="图10 Confidence-Based Color Modeling算法和本文算法比较">图10 Confidence-Based Color Modeling算法和本文算法比较</a></li>
                                                <li><a href="#139" data-title="&lt;b&gt;表1 算法错误率统计&lt;/b&gt;"><b>表1 算法错误率统计</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="159">


                                    <a id="bibliography_1" title=" Iwan L H, Thom J A.Temporal video segmentation:detecting the end-of-act in circus performance videos[J].Multimedia Tools &amp;amp; Applications, 2017, 76 (1) :1-23." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Temporal video segmentation:detecting the end-of-act in circus performance videos">
                                        <b>[1]</b>
                                         Iwan L H, Thom J A.Temporal video segmentation:detecting the end-of-act in circus performance videos[J].Multimedia Tools &amp;amp; Applications, 2017, 76 (1) :1-23.
                                    </a>
                                </li>
                                <li id="161">


                                    <a id="bibliography_2" title=" Grundmann M, Kwatra V, Han M, et al.Efficient hierarchical graph-based video segmentation[C]//2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2010:2141-2148." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Efficient hierarchical graph-based video segmentation">
                                        <b>[2]</b>
                                         Grundmann M, Kwatra V, Han M, et al.Efficient hierarchical graph-based video segmentation[C]//2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2010:2141-2148.
                                    </a>
                                </li>
                                <li id="163">


                                    <a id="bibliography_3" title=" Bhat P, Zitnick C L, Cohen M, et al.Gradientshop:A gradient-domain optimization framework for image and video filtering[J].ACM Transactions on Graphics (TOG) , 2010, 29 (2) :10." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098920&amp;v=MjAzNDF0ak5yNDlGWk9JSEJYNDVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklKRjhVYXhBPU5pZklZN0s3SA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Bhat P, Zitnick C L, Cohen M, et al.Gradientshop:A gradient-domain optimization framework for image and video filtering[J].ACM Transactions on Graphics (TOG) , 2010, 29 (2) :10.
                                    </a>
                                </li>
                                <li id="165">


                                    <a id="bibliography_4" title=" 陈华榕, 钱康来, 王斌.结合支持向量机和图割的视频分割[J].计算机辅助设计与图形学学报, 2017, 29 (8) :1389-1395." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201708001&amp;v=MjAyMzFNcDQ5RlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emtVNzdLTHo3QmFMRzRIOWI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         陈华榕, 钱康来, 王斌.结合支持向量机和图割的视频分割[J].计算机辅助设计与图形学学报, 2017, 29 (8) :1389-1395.
                                    </a>
                                </li>
                                <li id="167">


                                    <a id="bibliography_5" title=" Boykov Y, Kolmogorov V.An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (9) :1124-1137." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision">
                                        <b>[5]</b>
                                         Boykov Y, Kolmogorov V.An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (9) :1124-1137.
                                    </a>
                                </li>
                                <li id="169">


                                    <a id="bibliography_6" title=" Boykov Y Y, Jolly M P.Interactive graph cuts for optimal boundary &amp;amp; region segmentation of objects in ND images[C]//Proceedings of IEEE International Conference on Computer Vision.IEEE, 2001:105-112." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interactive Graph Cuts for Optimal Boundary and Region Segmentation of Objects in N-D Images">
                                        <b>[6]</b>
                                         Boykov Y Y, Jolly M P.Interactive graph cuts for optimal boundary &amp;amp; region segmentation of objects in ND images[C]//Proceedings of IEEE International Conference on Computer Vision.IEEE, 2001:105-112.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_7" title=" Heikkila M, Pietikainen M.A texture-based method for modeling the background and detecting moving objects[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2006, 28 (4) :657-662." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Texture-Based Method for Modeling the Background and Detecting Moving Objects">
                                        <b>[7]</b>
                                         Heikkila M, Pietikainen M.A texture-based method for modeling the background and detecting moving objects[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2006, 28 (4) :657-662.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_8" title=" 苏剑臣, 李策, 杨峰.基于边缘帧差和高斯混合模型的行人目标检测[J].计算机应用研究, 2018, 35 (4) :1246-1249" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201804062&amp;v=MDc3OTN5emtVNzdLTHo3U1pMRzRIOW5NcTQ5RFpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         苏剑臣, 李策, 杨峰.基于边缘帧差和高斯混合模型的行人目标检测[J].计算机应用研究, 2018, 35 (4) :1246-1249
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_9" title=" 胡学刚, 严思奇.基于FCM聚类的图像分割算法[J].计算机工程与设计, 2018, 39 (1) :159-164." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201801028&amp;v=MjM4NzVrVTc3S05pZllaTEc0SDluTXJvOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         胡学刚, 严思奇.基于FCM聚类的图像分割算法[J].计算机工程与设计, 2018, 39 (1) :159-164.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_10" title=" 任大勇, 贾振红, 杨杰, 等.结合位图切割和区域合并的彩色图像分割[J].计算机工程与应用, 2019, 55 (2) :162-167." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201902026&amp;v=MDQ5MzQ5SFlvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emtVNzdLTHo3TWFiRzRIOWpNclk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         任大勇, 贾振红, 杨杰, 等.结合位图切割和区域合并的彩色图像分割[J].计算机工程与应用, 2019, 55 (2) :162-167.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_11" title=" Freedman D, Turek M W.Illumination-invariant tracking via graph cuts[C].IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2005:10-17." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Illumination-invariant tracking viagraph cuts">
                                        <b>[11]</b>
                                         Freedman D, Turek M W.Illumination-invariant tracking via graph cuts[C].IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2005:10-17.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_12" title=" Chen L C, Papandreou G, Kokkinos I, et al.DeepLab:Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2018, 40 (4) :834-848." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep Lab:semantic image segmentation with deep convolutional nets,atrous convolution,and fully connected CRFs">
                                        <b>[12]</b>
                                         Chen L C, Papandreou G, Kokkinos I, et al.DeepLab:Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2018, 40 (4) :834-848.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_13" title=" Sun J, Zhang W, Tang X, et al.Background cut[C]//European Conference on Computer Vision.Springer-Verlag, 2006:628-641." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Background cut">
                                        <b>[13]</b>
                                         Sun J, Zhang W, Tang X, et al.Background cut[C]//European Conference on Computer Vision.Springer-Verlag, 2006:628-641.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_14" title=" Criminisi A, Cross G, Blake A, et al.Bilayer Segmentation of Live Video[C]//2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2006:53-60." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bilayer segmentation of live video">
                                        <b>[14]</b>
                                         Criminisi A, Cross G, Blake A, et al.Bilayer Segmentation of Live Video[C]//2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2006:53-60.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_15" title=" Zhong F, Qin X, Chen J, et al.Confidence-based color modeling for online video segmentation[M].Computer Vision—ACCV 2009.Springer Berlin Heidelberg, 2010:697-706." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Confidence-based color modeling for online video segmentation">
                                        <b>[15]</b>
                                         Zhong F, Qin X, Chen J, et al.Confidence-based color modeling for online video segmentation[M].Computer Vision—ACCV 2009.Springer Berlin Heidelberg, 2010:697-706.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_16" title=" Microsoft Research.Cambridge.Microsoft i2i dataset[EB/OL] (2013-03-12) http://research.microsoft.com/en-us/projects/i2i/data.aspx." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Microsoft i2iDataset">
                                        <b>[16]</b>
                                         Microsoft Research.Cambridge.Microsoft i2i dataset[EB/OL] (2013-03-12) http://research.microsoft.com/en-us/projects/i2i/data.aspx.
                                    </a>
                                </li>
                                <li id="191">


                                    <a id="bibliography_17" title=" 顾攀, 张烽栋.基于神经网络的图像弱监督语义分割算法[J].计算机应用与软件, 2018, 35 (2) :284-288." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201802052&amp;v=Mjc4NDc0SDluTXJZOUFab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXprVTc3S0x6VFpaTEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         顾攀, 张烽栋.基于神经网络的图像弱监督语义分割算法[J].计算机应用与软件, 2018, 35 (2) :284-288.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(05),112-118 DOI:10.3969/j.issn.1000-386x.2019.05.021            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于LBP纹理特征和Canny算子的视频分割方法研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%96%9B%E5%AE%BE%E7%94%B0&amp;code=41743678&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">薛宾田</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%BB%BA%E4%BC%9F&amp;code=35030640&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张建伟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%8D%9A&amp;code=35030617&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘博</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%B2%B3%E5%8D%97%E7%89%A7%E4%B8%9A%E7%BB%8F%E6%B5%8E%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1699374&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">河南牧业经济学院信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对目标区域和背景区域交界处颜色相似度较高的图像分割问题, 提出基于LBP (Local Binary Patterns) 纹理特征和Canny算子的视频分割算法。构造能量函数的数据项颜色模型和光滑项对比度模型;根据当前block直方图与LBP背景模型直方图的相似度调整全局颜色模型和局部颜色模型的比例来改进颜色分量;通过Canny边缘检测方法对改进后颜色模型生成的图像进行检测, 将得到的边缘检测结果应用到对比度分量模型中来增加前景和背景对比度;使用Graph Cut算法对能量函数进行求解, 得到最终分割结果。实验结果表明, 当背景光照发生变化且前景和背景交界处颜色相似时, 该算法具有明显优势。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%89%B2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图割;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E4%BA%8C%E5%80%BC%E6%A8%A1%E5%BC%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部二值模式;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">边缘检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%83%BD%E9%87%8F%E6%9C%80%E5%B0%8F%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">能量最小化;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%9C%80%E5%A4%A7%E6%B5%81%2F%E6%9C%80%E5%B0%8F%E5%88%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">最大流/最小切;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    薛宾田, 助教, 主研领域:数字图像处理。;
                                </span>
                                <span>
                                    张建伟, 副教授。;
                                </span>
                                <span>
                                    刘博, 助教。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>河南省科技厅项目 (172102210296);</span>
                    </p>
            </div>
                    <h1><b>VIDEO SEGMENTATION ALGORITHM BASED ON LBP TEXTURE AND CANNY OPERATOR</b></h1>
                    <h2>
                    <span>Xue Bintian</span>
                    <span>Zhang Jianwei</span>
                    <span>Liu Bo</span>
            </h2>
                    <h2>
                    <span>Faculty of Information Engineering, Henan University of Animal Husbandry and Economy</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the image segmentation problem of high color similarity at the boundary of object and background region, we proposed a novel video segmentation algorithm based on local binary patterns (LBP) texture and Canny operator. The energy function was constructed containing the models in terms of item color and smooth contrast. According to similarity of the current block histogram and the LBP background model histogram, the scale of local and global color model were adjusted to improve the color components. Canny edge detection was used to detect the image generated by the improved color model. The result of edge detection was applied to the constrast component model to increase the contrast of foreground and background. The energy function was solved by Graph cut method to obtain the final segmentation result. Experiments demonstrate the proposed algorithm is superior when background illumination varies and the boundary of foreground and background has similar color.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Graph%20cut&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Graph cut;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Local%20binary%20pattern&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Local binary pattern;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Edge%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Edge detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Energy%20minimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Energy minimization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Max-flow%2Fmin-cut&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Max-flow/min-cut;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="38">视频分割是指根据一定的相似性准则将视频序列中每帧图像分割成不同区域的过程, 是计算机视觉, 数字图像处理等领域基础性研究热点之一<citation id="193" type="reference"><link href="159" rel="bibliography" /><link href="161" rel="bibliography" /><link href="191" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">17</a>]</sup></citation>。视频分割技术被广泛应用于视频目标跟踪、视频概括、虚拟演播、远程教育和增强现实等系统。</p>
                </div>
                <div class="p1">
                    <p id="39">基于Gibbs能量最小化的图割 (Graph Cut) 算法是一种有效的分割方法。通过Greig等提出的基于组合最优化的最大流/最小切求出能量函数的最小值, 从而获得视频的帧的分割结果<citation id="195" type="reference"><link href="163" rel="bibliography" /><link href="165" rel="bibliography" /><link href="167" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>。能量函授构造的好坏直接影响了视频分割效果的好坏, 本文采用文献<citation id="194" type="reference">[<a class="sup">6</a>]</citation>中提出的颜色/对比度模型, 该模型考虑了相邻像素间的相似度, 同时也考虑了前景和背景的颜色特征, 能够充分地利用视频帧中提供的信息。但是当视频背景有噪声或者背景和前景交界处颜色相似时, 该模型颜色分量和对比度分量模型都无法提供有效的分割信息, 从而导致分割不精确。</p>
                </div>
                <div class="p1">
                    <p id="40">考虑到颜色/对比度模型只使用了视频的颜色, 而基于LBP的背景模型具有灰度单调变化不会导致LBP值发生改变特点, 它对于光照的变化、摇摆的树木、起伏的湖面和闪烁的监视器这些复杂的情况, 还有背景中有新的物体进入或者旧的物体移出这些情况, 都有很好的适应性, 从而可以借助这些特点来改进能量函数的颜色分量<citation id="196" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。基于Canny算子边缘检测算法对图像中较细边缘有很好的表现<citation id="197" type="reference"><link href="173" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 该算法和其他算法相比在模糊边缘检测上更具有优势。这两点为我们解决问题提供了思路。</p>
                </div>
                <div class="p1">
                    <p id="41">本文提出的一种新的视频分割算法, 借助自动更新的LBP背景模型改进能量函数的颜色分量, 利用Canny边缘检测算法得到增强的边缘信息改进对比度分量, 解决视频背景光照发生变化或者前景和背景交界处颜色相似时分割精度较低问题。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag"><b>1 基于图割的视频分割算法</b></h3>
                <div class="p1">
                    <p id="43">设无向图<i>G</i>= (<i>V</i>, <i>E</i>) 代表当前视频帧的抽象表示, <i>I</i>代表当前视频帧图像, <i>V</i>代表<i>I</i>中所有像素的集合, <i>E</i>是所有像素的邻域集合, 邻域代表四邻域或者八邻域。把图像分割问题转化为像素的二值标记组合最优化问题。若对无向图<i>G</i>中<i>E</i>集合赋予相应的权值, 比如像素间的相似程度, 则一个图像的割总权值越小, 表明分割越合理。一般使用最大流/最小切算法对该类问题进行最优化求解<citation id="198" type="reference"><link href="175" rel="bibliography" /><link href="177" rel="bibliography" /><link href="179" rel="bibliography" /><link href="181" rel="bibliography" /><sup>[<a class="sup">9</a>,<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="44" name="44"><b>1.1 能量函数</b></h4>
                <div class="p1">
                    <p id="45">集合<i>z</i>= (<i>z</i><sub>1</sub>, <i>z</i><sub>2</sub>, …, <i>z</i><sub><i>i</i></sub>, …, <i>z</i><sub><i>N</i></sub>) 表示整幅图像, <i>Z</i><sub><i>i</i></sub>代表图像中像素, <i>α</i><sub><i>i</i></sub>∈{0, 1}表示像素<i>i</i>属于前景或背景的状态 (其中0表示背景, 1表示前景) , <i>α</i>= (<i>α</i><sub>1</sub>, <i>α</i><sub>2</sub>, …, <i>α</i><sub><i>i</i></sub>, …, <i>α</i><sub><i>N</i></sub>) 表示当前图像的一种分割状态, <i>ε</i>表示所有相邻像素的集合, 相邻像素之间的关系分为两种情况, 可以是4连通或者8连通, 对像素点以及其对应所属状态定义完成后, 能量函数<i>E</i> (<i>α</i>) 可以表现为如下的形式:</p>
                </div>
                <div class="p1">
                    <p id="46"><mathml id="47"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo stretchy="false"> (</mo><mi>α</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>i</mi></munder><mi>E</mi></mstyle><msub><mrow></mrow><mi>D</mi></msub><mo stretchy="false"> (</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>ε</mi></mrow></munder><mi>E</mi></mstyle><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false"> (</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="48">式中:<i>E</i><sub><i>D</i></sub>是数据项, 也称为颜色分量, 用来衡量第<i>i</i>个像素属于前景或者背景的代价, 表示该像素与前景或者背景的相似度, 相似度越高则能量越小, 分割时越容易被划分到相似的区域;<i>E</i><sub><i>S</i></sub>是光滑项, 也称为对比度分量, 用来衡量邻接的像素同时属于前景或背景的代价, 表示的是图像中边界信息, 对比度越高则能量越小, 分割时越容易将相邻的两点划分到不同的部分;参数<i>λ</i>是颜色分量和对比度分量之间的平衡因子, 主要用于分割时控制数据项和光滑项所占的比重。最后使用最大流/最小切算法最小化能量函数去的最优解。</p>
                </div>
                <h4 class="anchor-tag" id="49" name="49"><b>1.2 颜色模型</b></h4>
                <div class="p1">
                    <p id="50">全局颜色模型对图像整体空间具有很好的描述, 且对于噪声有较好的抑制效果, 局部颜色模型相对于全局颜色模型能够很好地体现图像细节部分, 但对噪声较敏感。结合两种模型的特点, 本文将全局颜色模型和局部模型相结合产生新的颜色模型。高斯混合模型 (GMM) 表示颜色全局模型, 背景颜色模型表示为<mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>B</mi><mo stretchy="false">) </mo><mo>, </mo></mrow></math></mathml>前景颜色模型表示为<mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>F</mi><mo stretchy="false">) </mo></mrow></math></mathml>, 具体含义为第<i>i</i>个像素属于前景和背景概率。背景颜色模型如下:</p>
                </div>
                <div class="p1">
                    <p id="53"><mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub><mo stretchy="false">|</mo><mi>B</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi><msup><mrow></mrow><mi>B</mi></msup></mrow></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>k</mi></msub><msup><mrow></mrow><mi>B</mi></msup><mi>Ν</mi><mrow><mo> (</mo><mrow><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub><mo stretchy="false">|</mo><mi>μ</mi><msub><mrow></mrow><mi>k</mi></msub><msup><mrow></mrow><mi>B</mi></msup><mo>, </mo><mi mathvariant="bold-italic">Σ</mi><msubsup><mrow></mrow><mi>k</mi><mi>B</mi></msubsup></mrow><mo>) </mo></mrow></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="55">式中:<i>N</i> (·) 表示单个高斯分布函数, <i>B</i>表示当前计算的是背景颜色模型, <i>k</i><sup><i>B</i></sup>表示高斯分布的个数, <i>ω</i><mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>B</mi></msubsup></mrow></math></mathml>、<i>μ</i><mathml id="57"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>B</mi></msubsup></mrow></math></mathml>和<i>Σ</i><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>k</mi><mi>B</mi></msubsup></mrow></math></mathml>分别代表对应第<i>k</i>个高斯分布的权重、均值和协方差矩阵。前景颜色模型<mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>F</mi><mo stretchy="false">) </mo></mrow></math></mathml>的计算方式与之相同。</p>
                </div>
                <div class="p1">
                    <p id="60">局部颜色模型利用单高斯密度分布函数来进行计算:</p>
                </div>
                <div class="p1">
                    <p id="61"><mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><msub><mrow></mrow><mrow><mi>B</mi><mspace width="0.25em" /></mrow></msub><mrow><mo> (</mo><mrow><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub><mo stretchy="false">|</mo><mi>μ</mi><msub><mrow></mrow><mi>i</mi></msub><msup><mrow></mrow><mi>B</mi></msup><mo>, </mo><mi mathvariant="bold-italic">Σ</mi><msubsup><mrow></mrow><mi>i</mi><mi>B</mi></msubsup></mrow><mo>) </mo></mrow></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="63">式中:均值<i>μ</i><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>B</mi></msubsup></mrow></math></mathml>为背景图像中第<i>i</i>个像素的颜色值, <i>Σ</i><mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mi>B</mi></msubsup></mrow></math></mathml>为背景图像的协方差矩阵。颜色模型最后表示为:</p>
                </div>
                <div class="p1">
                    <p id="66"><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>F</mi><mo stretchy="false">) </mo></mrow><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>F</mi><mo stretchy="false">) </mo><mo>+</mo><mi>p</mi><mo stretchy="false"> (</mo><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>B</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="68"><i>p</i><sub>mix</sub> (<i>z</i><sub><i>i</i></sub>) = (1-<i>λ</i>) ·<i>p</i> (<i>z</i><sub><i>i</i></sub>) +<i>λ</i>·<i>p</i><sub><i>B</i></sub> (<i>z</i><sub><i>i</i></sub>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="69">式中:<i>λ</i>用于调节全局颜色模型和局部颜色模型的比例。使用该颜色模型, 可以较为准确地计算当前视频图像中像素分别属于前景和背景的相似度。在实验中, 为了方便计算和保证数据的规范性, 会将计算结果量化到[0, 1]区间上, 使用的是文献<citation id="199" type="reference">[<a class="sup">2</a>,<a class="sup">3</a>]</citation>的方法。最后能量函数中的数据项<i>E</i><sub><i>D</i></sub>表示如下:</p>
                </div>
                <div class="area_img" id="70">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201905022_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <h4 class="anchor-tag" id="72" name="72"><b>1.3 对比度模型</b></h4>
                <div class="p1">
                    <p id="73">对于能量函数中光滑项对比度模型定义如下:</p>
                </div>
                <div class="p1">
                    <p id="74"><mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false"> (</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow><mo>⋅</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mo>-</mo><mi>β</mi><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="76">式中:<i>d</i><sub><i>ij</i></sub>表示相邻像素<i>i</i>和<i>j</i>之间梯度, <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>β</mi><mo>=</mo><mrow><mo stretchy="false"> (</mo><mn>2</mn><mo>〈</mo><mrow><mo>|</mo><mrow><mi>z</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>z</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>〉</mo><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mrow></math></mathml>是一个鲁棒性参数, 作为对比度的权值, 〈·〉表示求期望运算符。</p>
                </div>
                <h3 id="78" name="78" class="anchor-tag"><b>2 纹理特征和Canny算子对能量函数的改进</b></h3>
                <h4 class="anchor-tag" id="79" name="79"><b>2.1 纹理特征对颜色分量的改进</b></h4>
                <div class="p1">
                    <p id="80">利用高斯混合模型来计算颜色分量是一种非常有效的方式, 可以处理大多数情况下的分割问题, 但是在进行精确度较高的视频分割时, 受到背景和其他因素的干扰, 效果会受到不同程度的影响, 如图1 (b) 中, 目标任务的左边肩膀处有明显的颜色分量计算错误。</p>
                </div>
                <div class="area_img" id="82">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 颜色相似度结果" src="Detail/GetImg?filename=images/JYRJ201905022_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 颜色相似度结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_08200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="83">由于高斯混合模型只使用了前景和背景的颜色信息, 这些信息在某些情况下不具有区分性, 比如当前景和背景颜色相似时, 或者光照发生变化时。为了克服这一问题, 本文选择了纹理特征具有不受颜色和光照变化的特点, 计算速度快, 描述类型丰富的LBP特征。本文主要通过使用LBP特征来建立背景模型, 然后对待检测视频帧进行分块, 计算出每块区域属于背景模型的概率, 然后使用得到的概率值来修改能量函数中背景局部颜色模型在颜色分量中的比重。</p>
                </div>
                <div class="p1">
                    <p id="84">首先LBP纹理特征计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext><msub><mrow></mrow><mrow><mi>Ρ</mi><mo>, </mo><mi>R</mi></mrow></msub><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>c</mi></msub><mo>, </mo><mi>y</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>p</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ρ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>s</mi></mstyle><mo stretchy="false"> (</mo><mi>g</mi><msub><mrow></mrow><mi>p</mi></msub><mo>-</mo><mi>g</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">) </mo><mn>2</mn><msup><mrow></mrow><mi>p</mi></msup></mtd></mtr><mtr><mtd><mi>s</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mtext> </mtext><mi>x</mi><mo>≥</mo><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mi>x</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr></mtable></mrow></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">在对背景建模时, 本文采用基于分区的背景建模方法, 这种方法可以降低LBP特征位置因素对模型的影响, 对于前景检查更加鲁棒。即根据设计好的分块原则把一副图像分为若干个成为block的块, 可以计算出<i>k</i>个具有不同权重的直方图并进行归一化:{<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>k</i></sub>}作为背景模型, 模块的权重本文使用<i>w</i><sub><i>k</i></sub>来表示。</p>
                </div>
                <div class="p1">
                    <p id="87">对接下来视频帧进行处理时, 首先进行分块操作, 计算每个块的LBP直方图<i>x</i><sub><i>t</i></sub>, 归一化, 并和已经得到的<i>k</i>个直方图model:{<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>k</i></sub>}进行比较。本文使用最小交集法 (histogram intersection) 来计算两个直方图相似度, 该方法简单快速且有效。当前块和背景模型中相应块相似度sim<sub><i>k</i></sub>计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="88"><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>s</mtext><mtext>i</mtext><mtext>m</mtext><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mstyle displaystyle="true"><mo>∩</mo><mo stretchy="false"> (</mo></mstyle><mover accent="true"><mi>a</mi><mo>→</mo></mover><mo>, </mo><mover accent="true"><mi>b</mi><mo>→</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Ν</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mi>min</mi></mrow></mstyle><mo stretchy="false"> (</mo><mi>a</mi><msub><mrow></mrow><mi>n</mi></msub><mo>, </mo><mi>b</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="90"><i>a</i>→、<mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>b</mi><mo>→</mo></mover></math></mathml>代表两个直方图, <i>N</i>表示直方图中bins的个数。</p>
                </div>
                <div class="p1">
                    <p id="92">为了保证LBP背景模型的准确性, 本文为背景模型实时更新。更新策略如下:首先判断当前块与背景模型的距离与设置的阈值<i>Tp</i>的关系, 如果它与模型中所有的直方图距离都小于<i>Tp</i>, 那么使用该直方图替换当前<i>k</i>个model中权值最小的一个, 并对其进行权值初始化, 一般设置为0.01。如果在<i>k</i>个model中找到了大于等于设置的阈值<i>Tp</i>, 说明与当前块比较的model直方图是最佳直方图, 而且需要对其bins值和权重进行更新。</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mover accent="true"><mrow><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo stretchy="true">→</mo></mover><mo>=</mo><mi>α</mi><msub><mrow></mrow><mi>b</mi></msub><mover accent="true"><mi>h</mi><mo>→</mo></mover><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false">) </mo><mover accent="true"><mrow><mi>m</mi><msub><mrow></mrow><mi>k</mi></msub></mrow><mo stretchy="true">→</mo></mover><mtext> </mtext><mi>α</mi><msub><mrow></mrow><mi>b</mi></msub><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">]</mo></mtd></mtr><mtr><mtd><mi>w</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mi>α</mi><msub><mrow></mrow><mi>w</mi></msub><mi>Μ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>+</mo><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>w</mi></msub><mo stretchy="false">) </mo><mi>w</mi><msub><mrow></mrow><mi>k</mi></msub><mtext> </mtext><mi>α</mi><msub><mrow></mrow><mi>w</mi></msub><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo>, </mo><mn>1</mn><mo stretchy="false">]</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">式中:<i>α</i><sub><i>b</i></sub>是直方图各bins更新速率, <i>α</i><sub><i>w</i></sub>是权重更新速率。<i>M</i><sub><i>k</i></sub>值取1对于最佳匹配最直方图, 其他情况取0。背景模型的更新速度和<i>α</i><sub><i>b</i></sub>、<i>α</i><sub><i>w</i></sub>取值有关, 取值越大背景模型更新速率越快。</p>
                </div>
                <div class="p1">
                    <p id="95">根据图像分块策略不同, 每个像素可能被多个图像块重复分配, 所以可以通过计算这些图像块属于背景概率的平均值来表示每个像素与背景的相似度。</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>B</mtext><mtext>L</mtext><mtext>B</mtext><mtext>Ρ</mtext></mrow></msub><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mtext>s</mtext></mstyle><mtext>i</mtext><mtext>m</mtext><msub><mrow></mrow><mrow><mi>k</mi><mo>, </mo><mi>m</mi></mrow></msub></mrow><mrow><mi>Μ</mi><mo>⋅</mo><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="98">式中:<i>M</i>表示当前像素被分配给图像块的数量, <i>blockN</i>表示每个图像块中像素点的个数。根据LBP背景模型得到的像素与背景的相似度对能量函数颜色分量进行改进后的颜色分量计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="99"><i>p</i><sub>mix</sub> (<i>z</i><sub><i>i</i></sub>) = (1-<i>P</i><sub>BLBP</sub>) ·<i>p</i> (<i>z</i><sub><i>i</i></sub>) +<i>P</i><sub>BLBP</sub>·<i>p</i><sub><i>B</i></sub> (<i>z</i><sub><i>i</i></sub>)      (12) </p>
                </div>
                <div class="p1">
                    <p id="100">使用改进后的颜色分量进行实验。实验结果如图2、图3所示, 可以看出, 新的颜色模型计算方法较之前的颜色模型计算方法相比, 准确度有了较大的提高, 其中<i>vk</i>视频序列目标的肩部和胸部最为明显。</p>
                </div>
                <div class="area_img" id="158">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_15800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 旧颜色分量结果" src="Detail/GetImg?filename=images/JYRJ201905022_15800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 旧颜色分量结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_15800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 新颜色分量结果" src="Detail/GetImg?filename=images/JYRJ201905022_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 新颜色分量结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="103" name="103"><b>2.2 Canny算子对光滑项的改进</b></h4>
                <div class="p1">
                    <p id="104">对比度分量光滑项主要通过像素梯度值进行计算, 但是当前景和背景交界处颜色相近时梯度计算不准确, 图像分割容易产生错误。针对该问题本文使用Canny边缘检测算子的特点和优势来提高分割精度。Canny边缘检测算子与其他边缘检测算子相比具有以下优点:最优检测, 即算法尽可能多地标识出图像中的实际边缘, 漏检和误检率都尽可能小;最优定位原则, 检测到的边缘点受噪声影响程度与其距离实际边缘的距离程度成正比;检测点与边缘点一一对应。</p>
                </div>
                <div class="p1">
                    <p id="105">Canny算法的基本思想是寻找一幅图像中灰度强度变化最快的位置, 即指梯度方向, 梯度值变化最快。对平滑后的图像使用Sobel算子计算水平和竖直方向的一阶导数值 (图像梯度) (<i>G</i><sub><i>x</i></sub>和<i>G</i><sub><i>y</i></sub>) 。根据得到的这两幅梯度图找到边界的梯度和方向, 如下所示:</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>E</mi><mi>d</mi><mi>g</mi><mi>e</mi><mo>_</mo><mi>G</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false">) </mo><mo>=</mo><msqrt><mrow><mi>G</mi><msubsup><mrow></mrow><mi>x</mi><mn>2</mn></msubsup><mo>+</mo><mi>G</mi><msubsup><mrow></mrow><mi>y</mi><mn>2</mn></msubsup></mrow></msqrt></mtd></mtr><mtr><mtd><mi>A</mi><mi>n</mi><mi>g</mi><mi>l</mi><mi>e</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mi>tan</mi><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mrow><mo> (</mo><mrow><mfrac><mrow><mi>G</mi><msub><mrow></mrow><mi>x</mi></msub></mrow><mrow><mi>G</mi><msub><mrow></mrow><mi>y</mi></msub></mrow></mfrac></mrow><mo>) </mo></mrow></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">在算法分割过程中, 只有属于前景和背景之间的边缘信息对于分割能起到帮助作用, 而前景和背景之中的边缘信息则会对分割产生干扰, 因此对比度分量的计算公式具有很大改进空间, 改进的思路大致分为两个方面, 第一是加强前景和背景之间弱边缘的信息, 第二是剔除前景和背景之中的强边缘信息的干扰。</p>
                </div>
                <div class="p1">
                    <p id="108">针对弱边缘的问题, 使用Canny边缘检测算法来解决。该算法主要是为改进对比度分量设计, 用于加强视频序列中的弱边缘信息。在实验中, 直接对视频图像进行边缘检测, 效果有一定的提升, 但并未达到预期。因为在一些特殊的情况下, 前景目标的一部分和背景目标的部分非常相似, 几乎完全融合在一起, 此时该处检测不出任何弱边缘信息, 所以Canny边缘检测也失去了作用, 如图4所示。由于直接对原图进行检测算法效果不甚理想, 我们扩大了检测对象的范围, 比如改进后颜色模型的结果, 经过试验和分析, 发现颜色模型的结果中包含了丰富的前景和背景之间的边缘信息, 其中甚至包含了一些原图中无法区分的边界信息, 如图5所示。</p>
                </div>
                <div class="area_img" id="109">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 原图Canny边缘检测结果" src="Detail/GetImg?filename=images/JYRJ201905022_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 原图Canny边缘检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_10900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 颜色模型Canny边缘检测结果" src="Detail/GetImg?filename=images/JYRJ201905022_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 颜色模型Canny边缘检测结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="111">在实验中, 我们通过对颜色模型的结果做Canny边缘检测来计算新的对比度分量, 该部分能够在一定程度上解决前景和背景之间颜色相似度过高的问题。计算表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="112"><i>R</i><sub>color</sub>=Canny (<i>P</i><sub>mix</sub>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="113">式中:<i>P</i><sub>mix</sub>是颜色模型的结果, <i>R</i><sub>color</sub>表示新的图像边缘信息。</p>
                </div>
                <div class="p1">
                    <p id="114">针对强边缘的问题, 主要采取的是剔除其影响的方式。基于此种情况, 我们利用相邻帧和背景图像的信息, 假设<i>i</i>和<i>j</i>是当前输入帧的一幅图像中相邻的两个像素点, <i>I</i><sub><i>T</i></sub>表示当前帧图像, <i>I</i><sub><i>T</i>-1</sub>表示前一帧图像, <i>I</i><sub><i>B</i></sub>表示背景帧图像, <i>I</i><sub><i>R</i></sub>表示<i>T</i>与<i>T</i>-1时刻帧差法的结果。本文中, 我们同时计算当前图像和背景图像中相邻像素的差值:</p>
                </div>
                <div class="p1">
                    <p id="115" class="code-formula">
                        <mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>d</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="116">如果<i>i</i>和<i>j</i>同时属于背景时, <i>d</i><sub><i>T</i></sub> (<i>i</i>, <i>j</i>) 的值应该近似逼近<i>d</i><sub><i>B</i></sub> (<i>i</i>, <i>j</i>) , 而<i>I</i><sub><i>R</i></sub> (<i>i</i>) 和<i>I</i><sub><i>R</i></sub> (<i>j</i>) 的结果应该同时趋近与零, 根据以上特点, 我们可以剔除图像中背景强边缘对于分割的影响, 新的相邻像素差值计算方式如下:</p>
                </div>
                <div class="p1">
                    <p id="117"><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mrow><mi>Κ</mi><mo>+</mo><mi>d</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>⋅</mo><mi>exp</mi><mo stretchy="false"> (</mo><mi>max</mi><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><msub><mrow></mrow><mi>R</mi></msub><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (16) </p>
                </div>
                <div class="p1">
                    <p id="119">式中:max (<i>I</i><sub><i>R</i></sub> (<i>i</i>) , <i>I</i><sub><i>R</i></sub> (<i>j</i>) ) 表示的是像素<i>i</i>和<i>j</i>不属于背景的概率, <i>K</i>用来调节整体的比例值 (实验中设定为0.7) , 确保<i>D</i><sub><i>T</i></sub> (<i>i</i>, <i>j</i>) 在[0, 1]的区间上。</p>
                </div>
                <div class="p1">
                    <p id="120">为了能够同时完成增强期望的弱边缘和剔除不需要的强边缘, 我们将<i>R</i><sub>color</sub>和<i>D</i><sub><i>T</i></sub> (<i>i</i>, <i>j</i>) 进行一定的整合, 充分利用Canny边缘检测、LBP背景模型和背景图像的信息。主要将<i>d</i><sub><i>T</i></sub> (<i>i</i>, <i>j</i>) 和<i>d</i><sub><i>B</i></sub> (<i>i</i>, <i>j</i>) 的计算图像换成了对应的Canny边缘检测结果。</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>R</mi><msubsup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>l</mtext><mtext>o</mtext><mtext>r</mtext></mrow><mi>Τ</mi></msubsup><mo>=</mo><mtext>C</mtext><mtext>a</mtext><mtext>n</mtext><mtext>n</mtext><mtext>y</mtext><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>R</mi><msubsup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>l</mtext><mtext>o</mtext><mtext>r</mtext></mrow><mi>B</mi></msubsup><mo>=</mo><mtext>C</mtext><mtext>a</mtext><mtext>n</mtext><mtext>n</mtext><mtext>y</mtext><mo stretchy="false"> (</mo><mi>Ι</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mi>Τ</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>R</mi><msubsup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>l</mtext><mtext>o</mtext><mtext>r</mtext></mrow><mi>Τ</mi></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>-</mo><mi>R</mi><msubsup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>l</mtext><mtext>o</mtext><mtext>r</mtext></mrow><mi>Τ</mi></msubsup><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mi>d</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>R</mi><msubsup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>l</mtext><mtext>o</mtext><mtext>r</mtext></mrow><mi>B</mi></msubsup><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo>-</mo><mi>R</mi><msubsup><mrow></mrow><mrow><mtext>c</mtext><mtext>o</mtext><mtext>l</mtext><mtext>o</mtext><mtext>r</mtext></mrow><mi>B</mi></msubsup><mo stretchy="false"> (</mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mspace width="0.25em" /></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">最终将新的<i>D</i><sub><i>T</i></sub> (<i>i</i>, <i>j</i>) 代入对比度分量计算公式中, 获得新的公式:</p>
                </div>
                <div class="p1">
                    <p id="123" class="code-formula">
                        <mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mi>S</mi></msub><mo stretchy="false"> (</mo><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow><mo>⋅</mo><mrow><mi>exp</mi></mrow><mo stretchy="false"> (</mo><mo>-</mo><mi>β</mi><mo>⋅</mo><mi>D</mi><mi>Τ</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="124">改进后对比度分量结果如图6所示。</p>
                </div>
                <div class="area_img" id="126">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 改进后对比度分量结果" src="Detail/GetImg?filename=images/JYRJ201905022_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 改进后对比度分量结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_12600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="127">使用式 (12) 和式 (18) 中改进过的颜色分量和对比度分量, 组成新的能量函数, 使用最大流/最小切算法求解出结果, 确定视频帧中每个像素的分割状态, 最终得到分割结果。</p>
                </div>
                <h3 id="128" name="128" class="anchor-tag"><b>3 实验结果和讨论</b></h3>
                <div class="p1">
                    <p id="129">本文算法实现平台:机器型号为Lenovo IdeaPad Y400N-IFI;CPU:i5-3210 2.5 GHz;内存:4.0 GB;Windows 8中文版64位操作系统;开发工具:msvc2008;图像辅助库:opencv_2.4.3。我们使用的实验数据都来自微软I2I工程<citation id="200" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="130">实验首先使用微软I2I自带的视频背景图片进行混合高斯建模, 然后利用背景差分法得到前景图像并进行建模, 背景和前面模型建立完毕后完成了实验的初始化。为了证明本算法具有一定针对性的同时也适用于一般环境的视频分割, 实验中专门选择负责背景的视频进行分割, 同时也选取普通视频进行分割, 且和其他几种常见的视频分割算法做了对比, 以此来验证本文算法的有效性。</p>
                </div>
                <div class="p1">
                    <p id="131">本文算法的实验结果与Background Cut、Bilayer和Confidence-Based Color Modeling三种算法的实验结果如图7-图10所示。图7是本文算法进行视频分割后随机抽取其中某几帧的分割结果。</p>
                </div>
                <div class="p1">
                    <p id="132">图8-图10是本文算法和文献<citation id="201" type="reference">[<a class="sup">13</a>]</citation>中Background Cut视频分割算法、文献<citation id="202" type="reference">[<a class="sup">14</a>]</citation>中Bilayer视频分割算法、文献<citation id="203" type="reference">[<a class="sup">8</a>]</citation>中Confidence-Based Color Modeling视频分割算法对相同视频的分割结果对比。</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 ac视频序列本文算法结果" src="Detail/GetImg?filename=images/JYRJ201905022_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 ac视频序列本文算法结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_13300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 Background Cut算法和本文算法比较" src="Detail/GetImg?filename=images/JYRJ201905022_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 Background Cut算法和本文算法比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_13400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="135">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 Bilayer算法和本文算法比较" src="Detail/GetImg?filename=images/JYRJ201905022_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 Bilayer算法和本文算法比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="136">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905022_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图10 Confidence-Based Color Modeling算法和本文算法比较" src="Detail/GetImg?filename=images/JYRJ201905022_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图10 Confidence-Based Color Modeling算法和本文算法比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905022_13600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="137">从以上实验结果可知, 本文算法和其他三种视频分割算法相比, 在背景复杂或者背景和前景颜色相似时, 分割效果明显优于其他三种视频分割算法。在其他几种算法出现明显分割错误的情况下, 本文算法并未出现相同的错误, 分割的准确性有了较大的提高。</p>
                </div>
                <div class="p1">
                    <p id="138">为了从整体上来验证本文视频分割算法的稳定性和鲁棒性, 我们对本文视频分割算法的结果进行错误率统计, 并和其他三种视频分割算法的结果做了对比, 结果如表1所示。其中Background Cut、Bilayer和Confidence-Based Color Modeling算法的视频分割结果和错误率数据来自文献<citation id="204" type="reference">[<a class="sup">8</a>]</citation>和其发布的视频。</p>
                </div>
                <div class="area_img" id="139">
                    <p class="img_tit"><b>表1 算法错误率统计</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="139" border="1"><tr><td><br />算法/视频序列</td><td>JM</td><td>AC</td><td>VK</td><td>MS</td></tr><tr><td><br />CCM 算法</td><td>0.13</td><td>0.47</td><td>0.68</td><td>1.40</td></tr><tr><td><br />BC 算法</td><td>0.16</td><td>0.56</td><td>1.12</td><td>2.44</td></tr><tr><td><br />Bilayer 算法</td><td>0.12</td><td>0.52</td><td>-</td><td>2.59</td></tr><tr><td><br />本文算法</td><td>0.09</td><td>0.25</td><td>0.22</td><td>1.12</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="140">从表1中可以看出, 本文算法的分割错误率明显较低, 特别是针对JM视频, 因为JM视频中有大范围的背景变化, 导致其他算法分割错误率较高, 而本文算法由于LBP背景模型能够自动更新所以错误率较低。统计错误率的方式采用的是一帧中错误分割的像素占整幅图像的比值, 其中用于判断像素分割正确与否的真值数据来源于微软的I2I工程<citation id="205" type="reference"><link href="187" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <h3 id="141" name="141" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="142">针对视频中目标区域和背景区域交界处颜色相似或者背景情景较复杂图像分割不精确问题, 本文提出了基于LBP纹理特征和Canny算子的视频分割算法。首先使用LBP背景模型得到像素与背景相似度信息, 对能量函数的颜色分量进行改进, 提高前景目标像素与前景模型的相似度;然后使用Canny边缘检测算法, 增强前景和背景交界处弱边缘, 并使用背景图像和当前帧图像的梯度图消除背景中强边缘的影响;最后使用最大流/最小切算法求解改进后的能量函数, 得到分割结果。</p>
                </div>
                <div class="p1">
                    <p id="143">视频分割在当前计算机视觉研究领域应用广泛, 而且随着当前技术的发展, 视频的分辨率越来越高, 数据量越来越大, 目前视频分割技术不能满足实时分割需求。</p>
                </div>
                <div class="p1">
                    <p id="144">随着视频分割技术应用领域的不断增加, 以及当前视频录制技术的不断提高, 视频的分辨率也在不断提高, 且很多场合需要做到视频分割的实时性。所以视频分割算法的下一步研究方向是如何将视频分割算法和大数据计算框架进行结合来提高视频分割速度。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="159">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Temporal video segmentation:detecting the end-of-act in circus performance videos">

                                <b>[1]</b> Iwan L H, Thom J A.Temporal video segmentation:detecting the end-of-act in circus performance videos[J].Multimedia Tools &amp; Applications, 2017, 76 (1) :1-23.
                            </a>
                        </p>
                        <p id="161">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Efficient hierarchical graph-based video segmentation">

                                <b>[2]</b> Grundmann M, Kwatra V, Han M, et al.Efficient hierarchical graph-based video segmentation[C]//2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2010:2141-2148.
                            </a>
                        </p>
                        <p id="163">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000098920&amp;v=MTM1MzE9TmlmSVk3SzdIdGpOcjQ5RlpPSUhCWDQ1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSkY4VWF4QQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Bhat P, Zitnick C L, Cohen M, et al.Gradientshop:A gradient-domain optimization framework for image and video filtering[J].ACM Transactions on Graphics (TOG) , 2010, 29 (2) :10.
                            </a>
                        </p>
                        <p id="165">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJF201708001&amp;v=MTg3NTlHRnJDVVI3cWZadVp0Rnl6a1U3N0tMejdCYUxHNEg5Yk1wNDlGWllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 陈华榕, 钱康来, 王斌.结合支持向量机和图割的视频分割[J].计算机辅助设计与图形学学报, 2017, 29 (8) :1389-1395.
                            </a>
                        </p>
                        <p id="167">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision">

                                <b>[5]</b> Boykov Y, Kolmogorov V.An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2004, 26 (9) :1124-1137.
                            </a>
                        </p>
                        <p id="169">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interactive Graph Cuts for Optimal Boundary and Region Segmentation of Objects in N-D Images">

                                <b>[6]</b> Boykov Y Y, Jolly M P.Interactive graph cuts for optimal boundary &amp; region segmentation of objects in ND images[C]//Proceedings of IEEE International Conference on Computer Vision.IEEE, 2001:105-112.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Texture-Based Method for Modeling the Background and Detecting Moving Objects">

                                <b>[7]</b> Heikkila M, Pietikainen M.A texture-based method for modeling the background and detecting moving objects[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2006, 28 (4) :657-662.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201804062&amp;v=MTgxMDdmWnVadEZ5emtVNzdLTHo3U1pMRzRIOW5NcTQ5RFpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3E=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 苏剑臣, 李策, 杨峰.基于边缘帧差和高斯混合模型的行人目标检测[J].计算机应用研究, 2018, 35 (4) :1246-1249
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201801028&amp;v=MjM1OTNvOUhiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXprVTc3S05pZllaTEc0SDluTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 胡学刚, 严思奇.基于FCM聚类的图像分割算法[J].计算机工程与设计, 2018, 39 (1) :159-164.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201902026&amp;v=MzA4OTF0Rnl6a1U3N0tMejdNYWJHNEg5ak1yWTlIWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 任大勇, 贾振红, 杨杰, 等.结合位图切割和区域合并的彩色图像分割[J].计算机工程与应用, 2019, 55 (2) :162-167.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Illumination-invariant tracking viagraph cuts">

                                <b>[11]</b> Freedman D, Turek M W.Illumination-invariant tracking via graph cuts[C].IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2005:10-17.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep Lab:semantic image segmentation with deep convolutional nets,atrous convolution,and fully connected CRFs">

                                <b>[12]</b> Chen L C, Papandreou G, Kokkinos I, et al.DeepLab:Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2018, 40 (4) :834-848.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Background cut">

                                <b>[13]</b> Sun J, Zhang W, Tang X, et al.Background cut[C]//European Conference on Computer Vision.Springer-Verlag, 2006:628-641.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bilayer segmentation of live video">

                                <b>[14]</b> Criminisi A, Cross G, Blake A, et al.Bilayer Segmentation of Live Video[C]//2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.IEEE, 2006:53-60.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Confidence-based color modeling for online video segmentation">

                                <b>[15]</b> Zhong F, Qin X, Chen J, et al.Confidence-based color modeling for online video segmentation[M].Computer Vision—ACCV 2009.Springer Berlin Heidelberg, 2010:697-706.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Microsoft i2iDataset">

                                <b>[16]</b> Microsoft Research.Cambridge.Microsoft i2i dataset[EB/OL] (2013-03-12) http://research.microsoft.com/en-us/projects/i2i/data.aspx.
                            </a>
                        </p>
                        <p id="191">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201802052&amp;v=MTQ4OTVBWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6a1U3N0tMelRaWkxHNEg5bk1yWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 顾攀, 张烽栋.基于神经网络的图像弱监督语义分割算法[J].计算机应用与软件, 2018, 35 (2) :284-288.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201905022" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201905022&amp;v=MjA5MjhadVp0Rnl6a1U3N0tMelRaWkxHNEg5ak1xbzlIWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
