<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135647596506250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201906032%26RESULT%3d1%26SIGN%3dWWdBlHyIuoCYpRpdKamukSeQIsg%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201906032&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201906032&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201906032&amp;v=MzA1NzA1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMN0xMelRaWkxHNEg5ak1xWTlHWm9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="&lt;b&gt;1 结合贝叶斯压缩感知的HMM&lt;/b&gt; "><b>1 结合贝叶斯压缩感知的HMM</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="&lt;b&gt;2 基于BDBS-HMM的手势识别系统&lt;/b&gt; "><b>2 基于BDBS-HMM的手势识别系统</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="&lt;b&gt;2.1 图像预处理和特征提取&lt;/b&gt;"><b>2.1 图像预处理和特征提取</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;2.2 基于BS-HMM的巴氏距离&lt;/b&gt;"><b>2.2 基于BS-HMM的巴氏距离</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#81" data-title="&lt;b&gt;3 实验过程和分析&lt;/b&gt; "><b>3 实验过程和分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#82" data-title="&lt;b&gt;3.1 数据库与评价标准&lt;/b&gt;"><b>3.1 数据库与评价标准</b></a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;3.2 相关实验设置&lt;/b&gt;"><b>3.2 相关实验设置</b></a></li>
                                                <li><a href="#88" data-title="&lt;b&gt;3.3 结果与分析&lt;/b&gt;"><b>3.3 结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#98" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#85" data-title="图1 MSRGesture3D数据库和本文数据库手势深度图">图1 MSRGesture3D数据库和本文数据库手势深度图</a></li>
                                                <li><a href="#90" data-title="表1 使用MSRGesture3D数据库手势识别率">表1 使用MSRGesture3D数据库手势识别率</a></li>
                                                <li><a href="#91" data-title="表2 使用本文数据库手势识别率">表2 使用本文数据库手势识别率</a></li>
                                                <li><a href="#93" data-title="&lt;b&gt;表3 BS-HMM与BDBS-HMM的Precision、Recall和F1 Score比较&lt;/b&gt;"><b>表3 BS-HMM与BDBS-HMM的Precision、Recall和F1 Score比较</b></a></li>
                                                <li><a href="#97" data-title="图2 余弦相似度和ARD参数与迭代次数关系图">图2 余弦相似度和ARD参数与迭代次数关系图</a></li>
                                                <li><a href="#97" data-title="图2 余弦相似度和ARD参数与迭代次数关系图">图2 余弦相似度和ARD参数与迭代次数关系图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="117">


                                    <a id="bibliography_1" title="Chen Y, Luo B, Chen Y L, et al.A real-time dynamic hand gesture recognition system using kinect sensor[C]//IEEEInternational Conference on Robotics and Biomimetics.IEEE, 2016:2026-2030." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A real-time dynamic hand gesture recognition system using kinect sensor">
                                        <b>[1]</b>
                                        Chen Y, Luo B, Chen Y L, et al.A real-time dynamic hand gesture recognition system using kinect sensor[C]//IEEEInternational Conference on Robotics and Biomimetics.IEEE, 2016:2026-2030.
                                    </a>
                                </li>
                                <li id="119">


                                    <a id="bibliography_2" title="Pisharady P K, Vadakkepat P, Loh A P.Attention Based Detection and Recognition of Hand Postures Against Complex Backgrounds[J].International Journal of Computer Vision, 2013, 101 (3) :403-419." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130409055054&amp;v=MTg5MDJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5tVTd6TEoxOFdOajdCYXJLN0h0WE1wbzlBWWVzS0NC&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                        Pisharady P K, Vadakkepat P, Loh A P.Attention Based Detection and Recognition of Hand Postures Against Complex Backgrounds[J].International Journal of Computer Vision, 2013, 101 (3) :403-419.
                                    </a>
                                </li>
                                <li id="121">


                                    <a id="bibliography_3" title="Chen B, Huang Z, Yu W, et al.Object recognition and localization based on kinect camera in complex environment[C]//IEEE International Conference on Robotics&amp;amp;Biomimetics.IEEE, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Object recognition and localization based on kinect camera in complex environment">
                                        <b>[3]</b>
                                        Chen B, Huang Z, Yu W, et al.Object recognition and localization based on kinect camera in complex environment[C]//IEEE International Conference on Robotics&amp;amp;Biomimetics.IEEE, 2013.
                                    </a>
                                </li>
                                <li id="123">


                                    <a id="bibliography_4" title="Yang H, Song Z, Chen R.An incremental PCA-HOG descriptor for robust visual hand tracking[C]//International Conference on Advances in Visual Computing.Springer-Verlag, 2010:687-695." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Incremental PCA-HOG Descriptor for Robust Visual Hand Tracking">
                                        <b>[4]</b>
                                        Yang H, Song Z, Chen R.An incremental PCA-HOG descriptor for robust visual hand tracking[C]//International Conference on Advances in Visual Computing.Springer-Verlag, 2010:687-695.
                                    </a>
                                </li>
                                <li id="125">


                                    <a id="bibliography_5" title="Ji Y, Idrissi K.Automatic facial expression recognition based on spatiotemporal descriptors[J].Pattern Recognition Letters, 2012, 33 (10) :1373-1380." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413235&amp;v=MDI4OTJyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJMTBUYXhBPU5pZk9mYks3SHRET3JJOUZZT29NRG44OG9CTVQ2VDRQUUgvaQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                        Ji Y, Idrissi K.Automatic facial expression recognition based on spatiotemporal descriptors[J].Pattern Recognition Letters, 2012, 33 (10) :1373-1380.
                                    </a>
                                </li>
                                <li id="127">


                                    <a id="bibliography_6" title="Wu X, Wang G, Cong Y.Object recognition method by combining color and depth information[J].Transactions of the Chinese Society of Agricultural Engineering, 2013, 29 (25) :96-100." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU2013S1016&amp;v=MDc5MTVtVkw3S0t6VE1lN0c0SDlLdnJvOUVZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                        Wu X, Wang G, Cong Y.Object recognition method by combining color and depth information[J].Transactions of the Chinese Society of Agricultural Engineering, 2013, 29 (25) :96-100.
                                    </a>
                                </li>
                                <li id="129">


                                    <a id="bibliography_7" title="Oreifej O, Liu Z.HON4D:Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences[C]//IEEE Conference on Computer Vision&amp;amp;Pattern Recognition.IEEE Computer Society, 2013:716-723." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=HON4D:Histogram of oriented 4D normals for activity recognition from depth sequences">
                                        <b>[7]</b>
                                        Oreifej O, Liu Z.HON4D:Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences[C]//IEEE Conference on Computer Vision&amp;amp;Pattern Recognition.IEEE Computer Society, 2013:716-723.
                                    </a>
                                </li>
                                <li id="131">


                                    <a id="bibliography_8" title="Wang J, Liu Z, Chorowski J, et al.Robust 3D Action Recognition with Random Occupancy Patterns[C]//European Conference on Computer Vision.Springer-Verlag, 2012:872-885." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Robust 3d action recognition with random occupancy patterns">
                                        <b>[8]</b>
                                        Wang J, Liu Z, Chorowski J, et al.Robust 3D Action Recognition with Random Occupancy Patterns[C]//European Conference on Computer Vision.Springer-Verlag, 2012:872-885.
                                    </a>
                                </li>
                                <li id="133">


                                    <a id="bibliography_9" title="王兵, 董洪伟, 张明敏, 等.基于Kinect的动态手势识别[J].传感器与微系统, 2018, 37 (2) :143-146." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201802040&amp;v=MDU1MDJDVVI3cWZadVp0Rnl2bVZMN0tKaXJhWkxHNEg5bk1yWTlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        王兵, 董洪伟, 张明敏, 等.基于Kinect的动态手势识别[J].传感器与微系统, 2018, 37 (2) :143-146.
                                    </a>
                                </li>
                                <li id="135">


                                    <a id="bibliography_10" title="巫康伟, 袁明新, 葛玉婷, 等.一种联合几何特征和隐马尔可夫模型的手势识别算法[J].自动化技术与应用, 2017, 36 (6) :108-111." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDHJ201706026&amp;v=MTI1Nzh0R0ZyQ1VSN3FmWnVadEZ5dm1WTDdLUHluRFpMRzRIOWJNcVk5SFlvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                        巫康伟, 袁明新, 葛玉婷, 等.一种联合几何特征和隐马尔可夫模型的手势识别算法[J].自动化技术与应用, 2017, 36 (6) :108-111.
                                    </a>
                                </li>
                                <li id="137">


                                    <a id="bibliography_11" title="Saon G, Chien J T.Bayesian Sensing Hidden Markov Models[J].Audio Speech&amp;amp;Language Processing IEEE Transactions on, 2012, 20 (1) :43-54." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Bayesian Sensing Hidden Markov Models">
                                        <b>[11]</b>
                                        Saon G, Chien J T.Bayesian Sensing Hidden Markov Models[J].Audio Speech&amp;amp;Language Processing IEEE Transactions on, 2012, 20 (1) :43-54.
                                    </a>
                                </li>
                                <li id="139">


                                    <a id="bibliography_12" title="包希日莫, 高光来, 张璟.基于遗传算法的声学模型拓扑结构优化[J].计算机工程与应用, 2014, 50 (14) :5-8." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201414003&amp;v=MjU4NzJxNDlGWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMN0tMejdNYWJHNEg5WE4=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                        包希日莫, 高光来, 张璟.基于遗传算法的声学模型拓扑结构优化[J].计算机工程与应用, 2014, 50 (14) :5-8.
                                    </a>
                                </li>
                                <li id="141">


                                    <a id="bibliography_13" >
                                        <b>[13]</b>
                                    郑斌珏, 赵辽英, 王毅轩.基于Kinect深度信息的手指检测与手势识别[J].计算机科学与技术汇刊:中英文版, 2014 (1) :9-14.</a>
                                </li>
                                <li id="143">


                                    <a id="bibliography_14" title="李艳萍, 宁跃飞, 杨伟.基于限峰分离模糊直方图均衡化的图像增强算法[J].西南师范大学学报 (自然科学版) , 2018, 43 (3) :42-49." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNZK201803007&amp;v=MjYwODU3cWZadVp0Rnl2bVZMN0tQU1BSWmJHNEg5bk1ySTlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                        李艳萍, 宁跃飞, 杨伟.基于限峰分离模糊直方图均衡化的图像增强算法[J].西南师范大学学报 (自然科学版) , 2018, 43 (3) :42-49.
                                    </a>
                                </li>
                                <li id="145">


                                    <a id="bibliography_15" title="Liu F, Du B, Wang Q, et al.Hand gesture recognition using kinect via deterministic learning[C]//Control and Decision Conference.IEEE, 2017:196-199." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hand gesture recognition using kinect via deterministic learning">
                                        <b>[15]</b>
                                        Liu F, Du B, Wang Q, et al.Hand gesture recognition using kinect via deterministic learning[C]//Control and Decision Conference.IEEE, 2017:196-199.
                                    </a>
                                </li>
                                <li id="147">


                                    <a id="bibliography_16" title="Zhang B, Yang Y, Chen C, et al.Action Recognition Using3D Histograms of Texture and A Multi-class Boosting Classifier[J].IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society, 2017, 26 (10) :4648-4660." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Action Recognition Using 3D Histograms of Texture and A Multi-Class Boosting Classifier">
                                        <b>[16]</b>
                                        Zhang B, Yang Y, Chen C, et al.Action Recognition Using3D Histograms of Texture and A Multi-class Boosting Classifier[J].IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society, 2017, 26 (10) :4648-4660.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(06),163-166+253 DOI:10.3969/j.issn.1000-386x.2019.06.031            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于BS-HMM和巴式距离的手势识别技术研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">朱正伟</a>
                                <a href="javascript:;">祝磊</a>
                                <a href="javascript:;">饶鹏</a>
                </h2>
                    <h2>

                    <span>常州大学信息科学与工程学院</span>
                    <span>常州光电技术研究所</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>开发一个基于深度图像的手势识别系统, 将巴氏距离 (Bhattacharyya distance) 引入到贝叶斯感知隐马尔科夫模型 (BS-HMM) 中, 称为BDBS-HMM。使用深度摄像机Kinect捕获深度序列图, 通过骨架信息对手部位置进行跟踪, 识别手部区域, 得到手部分割图;从分割图像中提取4D曲面法线方向分布 (HON4D) 特征和方向梯度直方图 (HOG) 特征表示运动模式;将每<i>k</i>个连续的特征向量组合成一个序列分布变换所有训练特征向量, 使用分布序列来对BDBS-HMM进行训练。该系统在使用MSRGesture3D数据库和自己建立的数据库的情况下, 将BDBS-HMM与标准HMM和BS-HMM进行比较, 实验结果表明了该系统的优越性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">手势识别;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%84%9F%E7%9F%A5%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贝叶斯感知隐马尔科夫模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B7%B4%E6%B0%8F%E8%B7%9D%E7%A6%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">巴氏距离;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HON4D%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HON4D特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HOG%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HOG特征;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    朱正伟, 教授, 主研领域:智能检测技术及应用。;
                                </span>
                                <span>
                                    祝磊, 硕士生。;
                                </span>
                                <span>
                                    饶鹏, 研究员。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61772090);</span>
                    </p>
            </div>
                    <h1><b>GESTURE RECOGNITION BASED ON BS-HMM AND BHATTACHARYYA DISTANCE</b></h1>
                    <h2>
                    <span>Zhu Zhengwei</span>
                    <span>Zhu Lei</span>
                    <span>Rao Peng</span>
            </h2>
                    <h2>
                    <span>School of Information Science and Engineering, Changzhou University</span>
                    <span>Changzhou Institute of Optoelectronic Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In this paper, we developed a gesture recognition system based on depth image, and Bhattacharyya distance was incorporated into BS-HMM, named BDBS-HMM. The depth sequence image was captured by the depth camera Kinect, and the hand segment image was obtained by tracking and recognizing the hand region through the skeleton information. Then the HON4 D features and HOG features were extracted from the segmentation image to represent the motion pattern. Each <i>k</i> consecutive feature vectors were combined into a sequence distribution to transform all training feature vectors. Distribution sequence was used to train BDBS-HMM. The system was compared with the standard HMM and BS-HMM in the case of using MSRGesture3 D database and our database. The experimental results show the superiority of the system.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gesture%20recognition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gesture recognition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BS-HMM&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BS-HMM;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Bhattacharyya%20distance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Bhattacharyya distance;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HON4D%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HON4D feature;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HOG%20feature&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HOG feature;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-01</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="37" name="37" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="38">手势识别交互技术是人机交互 (HCI) 研究的主要焦点之一。目前, 对于手势识别 (HGR) 的研究方法也比较多样化, 这些方法可以根据所使用的传感器的不同进行分类<citation id="149" type="reference"><link href="117" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。一般分为基于数据手套的手势识别和基于计算机视觉的手势识别, 后者使人机交互更加自然, 已经成为手势识别研究的重点。本文提出了一种基于Kinect深度传感器的手势识别系统, 无需在用户身上穿戴任何外接设备。</p>
                </div>
                <div class="p1">
                    <p id="39">基于Kinect深度传感器的手势识别研究大致分为手势分割、跟踪定位和特征提取三个过程。Pisharady等<citation id="150" type="reference"><link href="119" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>针对在复杂背景下手势分割不准确的问题, 提出了一个多类手姿态的手势识别系统, 并取得了较理想的效果。Chen等<citation id="151" type="reference"><link href="121" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>利用系统当前环境对对象物体进行追踪, 通过Kinect捕获的图像深度信息来对前景进行提取, 并快速捕捉到目标物体。Yang等<citation id="152" type="reference"><link href="123" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>利用HOG描述符来表示手势, 阐述了传统RGB相机所捕获到的图像的局部结构特征。Ji等<citation id="153" type="reference"><link href="125" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>开发了一种RGB视频序列描述符, 将HOG的概念推广到了3D中。除了使用RGB摄像头之外, Wu等<citation id="154" type="reference"><link href="127" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>将HOG描述符运用到了深度图像中。Oreifej等<citation id="155" type="reference"><link href="129" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出了一种基于HON4D特征来描述序列深度图, 可以同时捕获手部形状及其运动信息。Wang等<citation id="156" type="reference"><link href="131" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>则为深度序列提出了随机占用模式 (ROP) 特征。</p>
                </div>
                <div class="p1">
                    <p id="40">目前, 绝大部分的手势识别系统主要使用K最近邻算法 (K-NNs) 、支持向量机 (SVM) 、神经网络和有限状态机 (FSM) 等<citation id="157" type="reference"><link href="133" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。特别是隐马尔科夫模型 (HMMs) , 每个观测都可以被视为一个混合模型, 给捕捉数据提供一个强大的概率框架, 可以直接用来识别手势<citation id="158" type="reference"><link href="135" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。值得注意的是, 在标准HMM中, 模型观测状态符合混合高斯分布, 经常使用极大似然估计 (MLE) 来对参数进行评估, 这样导致模型的训练量较大。为了解决过度拟合的问题, Saon等<citation id="159" type="reference"><link href="137" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>提出了一种结合贝叶斯压缩感知的隐马尔科夫模型 (BS-HMM) , 并将其应用到语音识别中。</p>
                </div>
                <div class="p1">
                    <p id="41">本文利用手势图像的深度信息, 将分布序列引入到BS-HMM中, 每个分布均由<i>k</i>个连续的帧图像组成作为观测, 利用巴氏距离研究每个观测序列概率分布。在该系统中, 将巴式距离结合BS-HMM对各类手势进行建模, 然后通过最大期望算法 (EM) 来训练参数, 这样做的优点如下: (1) 系统学习了基于深度图像特征的隐藏状态, 所建模型要比基于HMM的手势识别系统更加规范。 (2) 将巴式距离融入到了BS-HMM中 (称为BDBS-HMM) , 给处理深度图像特征提供了一种更直观的方式。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag"><b>1 结合贝叶斯压缩感知的HMM</b></h3>
                <div class="p1">
                    <p id="43">和标准的HMM相比, BS-HMM模型更加规范, 它最初用于语音识别中<citation id="160" type="reference"><link href="139" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。在先前的研究中, BS-HMM被运用到手势识别系统。从每一帧图像中提取出3D坐标作为一幅RGB图像的特征。假设给定的序列特征<i>Z</i>={<b><i>Z</i></b><sub><i>t</i></sub>}<mathml id="44"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mtext>Τ</mtext></msubsup></mrow></math></mathml>, <i>Z</i><sub><i>t</i></sub>∈<i>R</i><sup><i>D</i></sup>, 每个观测<i>Z</i><sub><i>t</i></sub>可以表示为状态<i>i</i>中基底<i>Φ</i><sub><i>i</i></sub>的线性组合。状态<i>i</i>下给定的观测<i>Z</i><sub><i>t</i></sub>的概率为:</p>
                </div>
                <div class="p1">
                    <p id="45" class="code-formula">
                        <mathml id="45"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ζ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>t</mi></msub><mo>, </mo><mi>λ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mi>∞</mi><mo stretchy="false">|</mo><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><msup><mrow></mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mrow><mi>exp</mi></mrow><mo stretchy="false">[</mo><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ζ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ζ</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mi mathvariant="bold-italic">Φ</mi><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="46">式中:<b><i>R</i></b><sub><i>i</i></sub>是一个状态依赖精度矩阵, <b><i>w</i></b><sub><i>t</i></sub>是先验值<i>N</i> (0, <i>A</i><sub><i>i</i></sub><sup>-1</sup>) 中的一个感知权值, <i>λ</i><sub><i>i</i></sub>={<b><i>A</i></b><sub><i>i</i></sub>, <i>Φ</i><sub><i>i</i></sub>, <b><i>R</i></b><sub><i>i</i></sub>}是状态参数。通过整合感知权值<b><i>w</i></b><sub><i>t</i></sub>, 得到序列特征<i>Z</i>的边界似然, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="47"><mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>Ζ</mi><mo stretchy="false">|</mo><mi>λ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>S</mi><mo>=</mo><mo stretchy="false">{</mo><mi>S</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">}</mo></mrow></munder><mrow><mrow><mo>[</mo><mrow><mi>π</mi><msub><mrow></mrow><mrow><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ζ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">|</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>S</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">) </mo><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><mi>Τ</mi></munderover><mi>a</mi></mstyle><msub><mrow></mrow><mrow><mi>S</mi><msub><mrow></mrow><mi>t</mi></msub><mo>-</mo><mn>1</mn><mi>S</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mi>p</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">Ζ</mi><msub><mrow></mrow><mi>t</mi></msub><mo stretchy="false">|</mo><mi>λ</mi><msub><mrow></mrow><mrow><mi>S</mi><msub><mrow></mrow><mi>t</mi></msub></mrow></msub><mo stretchy="false">) </mo></mrow><mo>]</mo></mrow></mrow></mstyle></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="49">式中:<i>p</i> (<b><i>Z</i></b><sub><i>t</i></sub>|<i>λ</i><sub><i>S</i><sub><i>t</i></sub></sub>) =∫<i>p</i> (<b><i>Z</i></b><sub><i>t</i></sub>|<b><i>w</i></b><sub><i>t</i></sub>, <i>λ</i><sub><i>S</i><sub><i>t</i></sub></sub>) <i>p</i> (<b><i>w</i></b><sub><i>t</i></sub>) d<i>w</i><sub><i>t</i></sub>, <i>π</i><sub><i>i</i></sub>是和状态<i>i</i>相关的初始概率, <i>a</i><sub><i>ij</i></sub>是状态<i>i</i>到状态<i>j</i>的转变概率, <i>λ</i>={<i>π</i><sub><i>i</i></sub>, <i>a</i><sub><i>ij</i></sub>, <b><i>A</i></b><sub><i>i</i></sub>, <i>Φ</i><sub><i>i</i></sub>, <b><i>R</i></b><sub><i>i</i></sub>}是执行参数, BS-HMM的训练过程包括对式 (2) 中参数<i>λ</i>进行优化, 使用EM算法解决最优化的问题。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag"><b>2 基于BDBS-HMM的手势识别系统</b></h3>
                <h4 class="anchor-tag" id="51" name="51"><b>2.1 图像预处理和特征提取</b></h4>
                <div class="p1">
                    <p id="52">该系统使用深度传感器Microsoft Kinect获取一系列包含几何信息的深度图像。然后, 利用骨架信息对手部进行跟踪, 通过深度阈值可以很容易地将背景分离出来<citation id="161" type="reference"><link href="141" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。根据手部的位置裁剪深度图像, 并将大小调整为50×50像素, 然后对深度图像进行标准化处理。为了细化图像纹理, 通过直方图均衡化来提高图像对比度, 同时, 采用中值滤波的方法对每个图像进行降噪<citation id="162" type="reference"><link href="143" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>, 在本文中, 使用的是5×5中值滤波器。</p>
                </div>
                <div class="p1">
                    <p id="53">针对HOG和HOG4D两种特征的效果, 对所提出的BDBS-HMM进行了研究, 从每帧图像中提取900维HOG特征, PCA降低HOG特征的维度, 生成20维的序列特征<i>Z</i>={<b><i>Z</i></b><sub><i>t</i></sub>}<mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mtext>Τ</mtext></msubsup></mrow></math></mathml>。为了获得BDBS-HMM的观测序列, 计算<i>K</i>个连续帧的HOG特征向量得到序列分布<i>H</i>={<i>h</i><sub><i>l</i></sub>}<mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup></mrow></math></mathml>, <i>h</i><sub><i>l</i></sub>= (<i>μ</i><sub><i>l</i></sub>, ∑<sub><i>l</i></sub>) , 其中<i>L</i>=<i>T</i>/<i>K</i>, 原来的HON4D特征应用于序列深度图中生成视频特征向量。在此, 本文使用每4个连续帧深度图像生成HOG4D特征对HMM和BS-HMM进行训练, 和之前一样, 形成的序列分布用来训练BDBS-HMM。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>2.2 基于BS-HMM的巴氏距离</b></h4>
                <div class="p1">
                    <p id="57">BS-HMM对一系列的数据点进行建模, 为了得到序列分布模型, 本文提出了BDBS-HMM, 将巴氏距离引入到了BS-HMM中, 巴氏距离<i>D</i><sub><i>B</i></sub>用来测量概率分布的差异, 其定义公式如下:</p>
                </div>
                <div class="p1">
                    <p id="58"><mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo>, </mo><mi>q</mi><mo stretchy="false">) </mo><mo>=</mo><mo>-</mo><mrow><mi>ln</mi></mrow><mo stretchy="false"> (</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>y</mi></munder><mrow><msqrt><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo><mi>q</mi><mo stretchy="false"> (</mo><mi>y</mi><mo stretchy="false">) </mo></mrow></msqrt></mrow></mstyle><mo stretchy="false">) </mo></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>p</i> (<i>y</i>) 和<i>q</i> (<i>y</i>) 是同一区域上的随机分布, 给定一个随机分布<i>H</i>={<i>h</i><sub><i>l</i></sub>}<mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup></mrow></math></mathml>, <i>h</i><sub><i>l</i></sub>= (<i>μ</i><sub><i>l</i></sub>, ∑<sub><i>l</i></sub>) , <i>μ</i><sub><i>l</i></sub>∈<i>R</i><sup><i>D</i></sup>, ∑<sub><i>l</i></sub>∈<i>R</i><sup><i>D</i>×<i>D</i></sup>, 状态<i>i</i>下的观测<i>h</i><sub><i>l</i></sub>的概率为:</p>
                </div>
                <div class="area_img" id="63">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201906032_06300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="64">每个观测分布<i>h</i><sub><i>l</i></sub>都是由BDBS-HMM参数<i>λ</i>={<i>π</i><sub><i>i</i></sub>, <i>a</i><sub><i>ij</i></sub>, <b><i>A</i></b><sub><i>i</i></sub>, <i>Φ</i><sub><i>i</i></sub>, <b><i>R</i></b><sub><i>i</i></sub>}生成。</p>
                </div>
                <div class="p1">
                    <p id="65">EM算法可以用来计算<i>λ</i>的极大似然估计, 在BDBS-HMM中, 状态序列<i>S</i>={<i>s</i><sub><i>l</i></sub>}<mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup></mrow></math></mathml>是一个潜在变量。在E-step中, 通过式 (5) 计算潜在变量后验分布下的数据似然期望值。</p>
                </div>
                <div class="p1">
                    <p id="67"><i>E</i>{log  <i>p</i> (<i>H</i>, <i>S</i>|<i>λ</i>) |<i>H</i>, <i>λ</i><sup>old</sup>}=∑<sub><i>S</i></sub><i>p</i> (<i>S</i>|<i>H</i>, <i>λ</i><sup>old</sup>) log <i>p</i> (<i>H</i>, <i>S</i>|<i>λ</i>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="68">式中:<i>λ</i><sup>old</sup>是当前参数值, 第二项主要是为了式 (6) 的计算。</p>
                </div>
                <div class="area_img" id="70">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201906032_07000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="71">式中:<i>Λ</i><mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></math></mathml>=<i>Φ</i><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup></mrow></math></mathml><b><i>R</i></b><sub><i>i</i></sub><i>Φ</i><sub><i>i</i></sub>+<b><i>A</i></b><sub><i>i</i></sub>, <b><i>m</i></b><sub><i>li</i></sub>=<i>Λ</i><sub><i>i</i></sub><i>Φ</i><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup></mrow></math></mathml><b><i>R</i></b><sub><i>i</i></sub><i>μ</i><sub><i>l</i></sub>。在M-step中, 通过计算式 (5) 的最大值获得最新参数值<i>λ</i><sup>new</sup>, 这里给出参数<b><i>R</i></b><sub><i>i</i></sub>的解析解。</p>
                </div>
                <div class="p1">
                    <p id="75"> (<b><i>R</i></b><mathml id="76"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mtext>n</mtext><mtext>e</mtext><mtext>w</mtext></mrow></msubsup></mrow></math></mathml>) <sup>-1</sup>=<i>Φ</i><sub><i>i</i></sub><i>Λ</i><sub><i>i</i></sub><i>Φ</i><sub><i>i</i></sub><sup>T</sup>-<b><i>R</i></b><sub><i>i</i></sub><sup>-1</sup>+</p>
                </div>
                <div class="p1">
                    <p id="77"><mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>l</mi></msub><mi>γ</mi></mstyle><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mi>l</mi></msub><mo>-</mo><mi mathvariant="bold-italic">Φ</mi><mspace width="0.25em" /><msub><mrow></mrow><mi>i</mi></msub><mi>w</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>μ</mi><msub><mrow></mrow><mi>l</mi></msub><mo>-</mo><mi mathvariant="bold-italic">Φ</mi><mspace width="0.25em" /><msub><mrow></mrow><mi>i</mi></msub><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mtext>Τ</mtext></msup><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><msubsup><mo>∑</mo><mi>l</mi><mrow><mo>-</mo><mn>1</mn></mrow></msubsup><mspace width="0.25em" /></mstyle><mo>+</mo><mo stretchy="false"> (</mo><mn>2</mn><mi mathvariant="bold-italic">R</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mstyle displaystyle="true"><msub><mo>∑</mo><mi>Ι</mi></msub><mo stretchy="false">) </mo></mstyle><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><msub><mo>∑</mo><mi>l</mi></msub><mi>γ</mi></mstyle><msub><mrow></mrow><mi>l</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="79">式中:<i>γ</i><sub><i>l</i></sub> (<i>i</i>) =<i>p</i> (<i>s</i><sub><i>l</i></sub>=<i>i</i>|<i>H</i>) 。由于平均观测分布将代替观测数据点, 参数<i>Φ</i><sub><i>i</i></sub>和<b><i>A</i></b><sub><i>i</i></sub>的解析解与使用BS-HMM所得到的解析解结果类似。初始化<i>Φ</i><sub><i>i</i></sub>的过程必须遵循BS-HMM。利用MAP (maximizing a posterior) 技术可以估算感知权值<b><i>w</i></b><sub><i>l</i></sub>, <b><i>w</i></b><mathml id="80"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>l</mi><mrow><mtext>Μ</mtext><mtext>A</mtext><mtext>Ρ</mtext></mrow></msubsup></mrow></math></mathml>=<b><i>m</i></b><sub><i>li</i></sub>。</p>
                </div>
                <h3 id="81" name="81" class="anchor-tag"><b>3 实验过程和分析</b></h3>
                <h4 class="anchor-tag" id="82" name="82"><b>3.1 数据库与评价标准</b></h4>
                <div class="p1">
                    <p id="83">通过识别手势行为动作来对所提出方法的有效性进行评价, F-measures (F值) 来评估识别效果, 评价标准包括准确率 (Precision) 、召回率 (Recall) 和F1分数 (F1 Score) <citation id="163" type="reference"><link href="145" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。本次实验是在两个数据库上进行, 数据库的原深度视频信息都是通过微软Kinect设备捕捉。第一个是MSRGesture3D数据库, 包含了12个动态美国手语手势, 共336个视频, 每个视频帧数在30～60之间<citation id="164" type="reference"><link href="147" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 图1 (a) 是一个MSRGesture3D数据库的手势深度图像示例。第二个数据库包含了在实际环境条件下的自记录数据。本文的数据库共有100个视频和上、下、左、右、旋转、禁止、停止、来、缩放和确定等10类手势, 每个视频的帧数为60。图1 (b) 是本文数据库的手势深度图像示例, 由于MSRGesture3D中的大多数手势视频都是经过分割处理的, 所以只显示手腕以上部分, 但是, 本文数据库中的视频并没有被很好地分割, 因此需要使用手势定位来对数据库进行预处理。在实验过程中, 一半文件用于手势训练, 另一半文件用于手势测试。</p>
                </div>
                <div class="area_img" id="85">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906032_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 MSRGesture3D数据库和本文数据库手势深度图" src="Detail/GetImg?filename=images/JYRJ201906032_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 MSRGesture3D数据库和本文数据库手势深度图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906032_08500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="86" name="86"><b>3.2 相关实验设置</b></h4>
                <div class="p1">
                    <p id="87">为了证实提出的BDBS-HMM的效率, 本文选择使用标准HMM作为参照, 由于HMM通常会导致模型过度拟合, 所以选择使用BS-HMM作为另一个参照。本研究共进行了两个实验, 实验一研究了HMM、BS-HMM、和BDBS-HMM在不同混合分量下的识别效果。实验二检测了训练过程中BS-HMM和BDBS-HMM基向量的相似性, 同时也研究了主动相关决策 (ARD) 参数。在这两个实验中, 对HOG和HON4D两个特征集也进行了研究。为了公平比较, HMM、BS-HMM和BDBS-HMM都使用相同的特征集。通过64分量标准HMM初始化BS-HMM和BDBS-HMM的基向量, 每个实验随机划分进行20次得出平均结果。</p>
                </div>
                <h4 class="anchor-tag" id="88" name="88"><b>3.3 结果与分析</b></h4>
                <div class="p1">
                    <p id="89">首先, 将HMM、BS-HMM和BDBS-HMM分为两个隐状态, 每个状态下, 混合分量设置为2个、4个、8个和16个, 表1和表2分别表示使用MSRGesture3D数据集和本文的数据集获得的实验结果。实验结果表明, 在大多数情况下, 本文提出的BDBS-HMM效果要比HMM和BS-HMM要好。在这里, BS- HMM和BDBS-HMM都使用64分量HMM初始化。 </p>
                </div>
                <div class="area_img" id="90">
                    <p class="img_tit">表1 使用MSRGesture3D数据库手势识别率 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="90" border="1"><tr><td>Num.mix/state</td><td>2</td><td>4</td><td>8</td><td>16</td><td>64</td></tr><tr><td><br />HOG+HMM</td><td>81.28</td><td>85.53</td><td>86.46</td><td>85.51</td><td>79.73</td></tr><tr><td><br />HOG+BS-HMM</td><td>86.72</td><td>86.92</td><td>88.21</td><td>89.79</td><td>-</td></tr><tr><td><br />HOG+BDBS-HMM</td><td>86.65</td><td>90.05</td><td>91.13</td><td>91.84</td><td>-</td></tr><tr><td><br />HON4D+HMM</td><td>79.29</td><td>83.93</td><td>87.74</td><td>87.01</td><td>87.15</td></tr><tr><td><br />HON4D+BS-HMM</td><td>93.02</td><td>93.59</td><td>93.86</td><td>93.11</td><td>-</td></tr><tr><td><br />HON4D+BDBS-HMM</td><td>91.02</td><td>93.28</td><td>93.79</td><td>94.12</td><td>-</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="91">
                    <p class="img_tit">表2 使用本文数据库手势识别率 <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="91" border="1"><tr><td><br />Num.mix/state</td><td>2</td><td>4</td><td>8</td><td>16</td><td>64</td></tr><tr><td><br />HOG+HMM</td><td>87.92</td><td>84.77</td><td>88.01</td><td>88.86</td><td>87.64</td></tr><tr><td><br />HOG+BS-HMM</td><td>86.75</td><td>92.02</td><td>92.43</td><td>92.21</td><td>-</td></tr><tr><td><br />HOG+BDBS-HMM</td><td>94.02</td><td>95.11</td><td>95.05</td><td>94.02</td><td>-</td></tr><tr><td><br />HON4D+HMM</td><td>89.14</td><td>89.83</td><td>89.81</td><td>92.25</td><td>93.17</td></tr><tr><td><br />HON4D+BS-HMM</td><td>90.98</td><td>91.29</td><td>91.75</td><td>91.71</td><td>-</td></tr><tr><td><br />HON4D+BDBS-HMM</td><td>91.75</td><td>92.09</td><td>91.23</td><td>89.49</td><td>-</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="92">接下来, 对本文提出的BDBS-HMM和BS-HMM进行更详细的比较。理论上讲, 混合分量中的基向量集在训练学习过程中会更加独立, 以训练过程中的前五次迭代为例, 图2为余弦相似度和ARD参数与迭代次数关系图。ARD的值表示感知权值的精度, BS-HMM与BDBS-HMM二者算法的比较验证了它们的收敛速度是相似的。表3使用了MSRGesture3D的数据库, 比较了BS-HMM和BDBS-HMM的平均F值, 实验结果表明, 本文提出的BDBS-HMM要优于BS-HMM。</p>
                </div>
                <div class="area_img" id="93">
                    <p class="img_tit"><b>表3 BS-HMM与BDBS-HMM的Precision、Recall和F1 Score比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="93" border="1"><tr><td><br /></td><td>Precision</td><td>Recall</td><td>F1 Score</td></tr><tr><td><br />HON4D+BS-HMM</td><td>0.938</td><td>0.938</td><td>0.939</td></tr><tr><td><br />HON4D+BDBS-HMM</td><td>0.961</td><td>0.962</td><td>0.959</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906032_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 余弦相似度和ARD参数与迭代次数关系图" src="Detail/GetImg?filename=images/JYRJ201906032_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 余弦相似度和ARD参数与迭代次数关系图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906032_09700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="97">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906032_09701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 余弦相似度和ARD参数与迭代次数关系图" src="Detail/GetImg?filename=images/JYRJ201906032_09701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 余弦相似度和ARD参数与迭代次数关系图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906032_09701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="98" name="98" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="99">本文提出了一种基于深度信息的手势识别系统, 该系统的主要创新之处在于其较好的处理概率特征的能力。为了处理序列分布形式特征, 将巴氏距离引入到BS-HMM中, 通过极大似然法对提出的BDBS-HMM参数进行预估。同时也考虑到了模型正规化, 使用EM算法推导出参数的递归解, 并将所提出的BDBS-HMM与使用标准HMM和BS-HMM的手势识别效果进行比较, 实验结果表明了在使用MSRGesture3D数据库的情况下所提出的BDBS-HMM的优越性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="117">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A real-time dynamic hand gesture recognition system using kinect sensor">

                                <b>[1]</b>Chen Y, Luo B, Chen Y L, et al.A real-time dynamic hand gesture recognition system using kinect sensor[C]//IEEEInternational Conference on Robotics and Biomimetics.IEEE, 2016:2026-2030.
                            </a>
                        </p>
                        <p id="119">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD130409055054&amp;v=MTQ4MzhubVU3ekxKMThXTmo3QmFySzdIdFhNcG85QVllc0tDQk04enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVadkZ5&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b>Pisharady P K, Vadakkepat P, Loh A P.Attention Based Detection and Recognition of Hand Postures Against Complex Backgrounds[J].International Journal of Computer Vision, 2013, 101 (3) :403-419.
                            </a>
                        </p>
                        <p id="121">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Object recognition and localization based on kinect camera in complex environment">

                                <b>[3]</b>Chen B, Huang Z, Yu W, et al.Object recognition and localization based on kinect camera in complex environment[C]//IEEE International Conference on Robotics&amp;Biomimetics.IEEE, 2013.
                            </a>
                        </p>
                        <p id="123">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Incremental PCA-HOG Descriptor for Robust Visual Hand Tracking">

                                <b>[4]</b>Yang H, Song Z, Chen R.An incremental PCA-HOG descriptor for robust visual hand tracking[C]//International Conference on Advances in Visual Computing.Springer-Verlag, 2010:687-695.
                            </a>
                        </p>
                        <p id="125">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413235&amp;v=Mjk4OTRxUVRNbndaZVp0RmlubFVyeklJMTBUYXhBPU5pZk9mYks3SHRET3JJOUZZT29NRG44OG9CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b>Ji Y, Idrissi K.Automatic facial expression recognition based on spatiotemporal descriptors[J].Pattern Recognition Letters, 2012, 33 (10) :1373-1380.
                            </a>
                        </p>
                        <p id="127">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NYGU2013S1016&amp;v=MTIwOTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5dm1WTDdLS3pUTWU3RzRIOUt2cm85RVlvUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b>Wu X, Wang G, Cong Y.Object recognition method by combining color and depth information[J].Transactions of the Chinese Society of Agricultural Engineering, 2013, 29 (25) :96-100.
                            </a>
                        </p>
                        <p id="129">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=HON4D:Histogram of oriented 4D normals for activity recognition from depth sequences">

                                <b>[7]</b>Oreifej O, Liu Z.HON4D:Histogram of Oriented 4D Normals for Activity Recognition from Depth Sequences[C]//IEEE Conference on Computer Vision&amp;Pattern Recognition.IEEE Computer Society, 2013:716-723.
                            </a>
                        </p>
                        <p id="131">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Robust 3d action recognition with random occupancy patterns">

                                <b>[8]</b>Wang J, Liu Z, Chorowski J, et al.Robust 3D Action Recognition with Random Occupancy Patterns[C]//European Conference on Computer Vision.Springer-Verlag, 2012:872-885.
                            </a>
                        </p>
                        <p id="133">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CGQJ201802040&amp;v=MjAzMTE0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkw3S0ppcmFaTEc0SDluTXJZOUJaSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>王兵, 董洪伟, 张明敏, 等.基于Kinect的动态手势识别[J].传感器与微系统, 2018, 37 (2) :143-146.
                            </a>
                        </p>
                        <p id="135">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDHJ201706026&amp;v=MDQwOTZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkw3S1B5bkRaTEc0SDliTXFZOUg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b>巫康伟, 袁明新, 葛玉婷, 等.一种联合几何特征和隐马尔可夫模型的手势识别算法[J].自动化技术与应用, 2017, 36 (6) :108-111.
                            </a>
                        </p>
                        <p id="137">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Bayesian Sensing Hidden Markov Models">

                                <b>[11]</b>Saon G, Chien J T.Bayesian Sensing Hidden Markov Models[J].Audio Speech&amp;Language Processing IEEE Transactions on, 2012, 20 (1) :43-54.
                            </a>
                        </p>
                        <p id="139">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201414003&amp;v=MzE5NDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkw3S0x6N01hYkc0SDlYTnE0OUZaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b>包希日莫, 高光来, 张璟.基于遗传算法的声学模型拓扑结构优化[J].计算机工程与应用, 2014, 50 (14) :5-8.
                            </a>
                        </p>
                        <p id="141">
                            <a id="bibliography_13" >
                                    <b>[13]</b>
                                郑斌珏, 赵辽英, 王毅轩.基于Kinect深度信息的手指检测与手势识别[J].计算机科学与技术汇刊:中英文版, 2014 (1) :9-14.
                            </a>
                        </p>
                        <p id="143">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNZK201803007&amp;v=MTM1NzNJOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkw3S1BTUFJaYkc0SDluTXI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b>李艳萍, 宁跃飞, 杨伟.基于限峰分离模糊直方图均衡化的图像增强算法[J].西南师范大学学报 (自然科学版) , 2018, 43 (3) :42-49.
                            </a>
                        </p>
                        <p id="145">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hand gesture recognition using kinect via deterministic learning">

                                <b>[15]</b>Liu F, Du B, Wang Q, et al.Hand gesture recognition using kinect via deterministic learning[C]//Control and Decision Conference.IEEE, 2017:196-199.
                            </a>
                        </p>
                        <p id="147">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Action Recognition Using 3D Histograms of Texture and A Multi-Class Boosting Classifier">

                                <b>[16]</b>Zhang B, Yang Y, Chen C, et al.Action Recognition Using3D Histograms of Texture and A Multi-class Boosting Classifier[J].IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society, 2017, 26 (10) :4648-4660.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201906032" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201906032&amp;v=MzA1NzA1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMN0xMelRaWkxHNEg5ak1xWTlHWm9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
