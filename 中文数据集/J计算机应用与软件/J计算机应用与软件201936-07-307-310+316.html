<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135629063596250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201907053%26RESULT%3d1%26SIGN%3drltLgcHQUVmxmmlEebcAAu2nNeI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907053&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907053&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907053&amp;v=MDE3MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVjc3UEx6VFpaTEc0SDlqTXFJOUFaNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#29" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;1 相关理论&lt;/b&gt; "><b>1 相关理论</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#34" data-title="&lt;b&gt;1.1 逻辑回归模型&lt;/b&gt;"><b>1.1 逻辑回归模型</b></a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;1.2 FM模型&lt;/b&gt;"><b>1.2 FM模型</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;1.3 DeepFM模型&lt;/b&gt;"><b>1.3 DeepFM模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#76" data-title="&lt;b&gt;2 实验结果&lt;/b&gt; "><b>2 实验结果</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#89" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="图1 DeepFM模型架构图">图1 DeepFM模型架构图</a></li>
                                                <li><a href="#80" data-title="&lt;b&gt;表1 混淆矩阵表&lt;/b&gt;"><b>表1 混淆矩阵表</b></a></li>
                                                <li><a href="#82" data-title="&lt;b&gt;表2 原始数据集结果&lt;/b&gt;"><b>表2 原始数据集结果</b></a></li>
                                                <li><a href="#83" data-title="图2 原始数据集ROC曲线">图2 原始数据集ROC曲线</a></li>
                                                <li><a href="#86" data-title="&lt;b&gt;表3 补充数据集结果&lt;/b&gt;"><b>表3 补充数据集结果</b></a></li>
                                                <li><a href="#87" data-title="图3 新数据集ROC曲线">图3 新数据集ROC曲线</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 陈检.基于神经网络与因子分解机的点击率预估应用研究[J].信息技术与信息化, 2018 (8) :204-207." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SDDZ201808072&amp;v=Mjk3MzlHRnJDVVI3cWZadVp0RnlqaFY3N1BOaW5QZExHNEg5bk1wNDlDWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         陈检.基于神经网络与因子分解机的点击率预估应用研究[J].信息技术与信息化, 2018 (8) :204-207.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 伊雯雯.基于多维特征组合逻辑回归模型的广告点击率预测[J].通信技术, 2016, 49 (9) :1221-1228." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXJS201609022&amp;v=MTY2NTZxQnRHRnJDVVI3cWZadVp0RnlqaFY3N1BNVFhCZmJHNEg5Zk1wbzlIWm9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         伊雯雯.基于多维特征组合逻辑回归模型的广告点击率预测[J].通信技术, 2016, 49 (9) :1221-1228.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 杨立洪, 白肇强.基于二次组合的特征工程与XGBoost模型的用户行为预测[J].科学技术与工程, 2018, 18 (14) :191-194." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201814033&amp;v=MTA0MjJDVVI3cWZadVp0RnlqaFY3N1BMalhCZmJHNEg5bk5xNDlHWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         杨立洪, 白肇强.基于二次组合的特征工程与XGBoost模型的用户行为预测[J].科学技术与工程, 2018, 18 (14) :191-194.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 潘博, 张青川, 于重重, 等.FM集成模型在广告点击率预估中的应用[J].计算机应用与软件, 2018, 35 (1) :107-111, 148." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801019&amp;v=MDY4MzlQTHpUWlpMRzRIOW5Ncm85RWJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhWNzc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         潘博, 张青川, 于重重, 等.FM集成模型在广告点击率预估中的应用[J].计算机应用与软件, 2018, 35 (1) :107-111, 148.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 黄立威, 江碧涛, 吕守业, 等.基于深度学习的推荐系统研究综述[J].计算机学报, 2018, 41 (7) :191-219." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201807011&amp;v=MTk5Nzg3UEx6N0Jkckc0SDluTXFJOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVjc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         黄立威, 江碧涛, 吕守业, 等.基于深度学习的推荐系统研究综述[J].计算机学报, 2018, 41 (7) :191-219.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 李思琴.基于深度学习的搜索广告点击率预测方法研究[D].哈尔滨:哈尔滨工业大学, 2015." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015980137.nh&amp;v=MTkzMjU3cXdIdERQcUpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhWNzdQVkYyNkc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         李思琴.基于深度学习的搜索广告点击率预测方法研究[D].哈尔滨:哈尔滨工业大学, 2015.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Lin C J, Weng R C, Keerthi S S.Trust region Newton methods for large-scale logistic regression[C]//International Conference on Machine Learning.ACM, 2007:561-568." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Trust region Newton methods for large-scale logistic regression">
                                        <b>[7]</b>
                                         Lin C J, Weng R C, Keerthi S S.Trust region Newton methods for large-scale logistic regression[C]//International Conference on Machine Learning.ACM, 2007:561-568.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 王贤.基于逻辑回归的案件关联分析[D].重庆:西南大学, 2009." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=2009104220.nh&amp;v=MTI5NDFyQ1VSN3FmWnVadEZ5amhWNzdQVjEyN0Y3SzRHdFBPcjVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         王贤.基于逻辑回归的案件关联分析[D].重庆:西南大学, 2009.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 王兵.一种基于逻辑回归模型的搜索广告点击率预估方法的研究[D].杭州:浙江大学, 2013." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013178340.nh&amp;v=MTE4MDBGckNVUjdxZlp1WnRGeWpoVjc3UFZGMjZIYksvRnRMSXI1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         王兵.一种基于逻辑回归模型的搜索广告点击率预估方法的研究[D].杭州:浙江大学, 2013.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Rendle S.Factorization Machines[C]//IEEE, International Conference on Data Mining.IEEE, 2011:995-1000." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Factorization Machines">
                                        <b>[10]</b>
                                         Rendle S.Factorization Machines[C]//IEEE, International Conference on Data Mining.IEEE, 2011:995-1000.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 马雅从.基于特征组合的展示广告点击率预估模型研究[D].广州:华南理工大学, 2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018874442.nh&amp;v=MzE4NjFGMjZGcnUvR3RYSXJaRWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVjc3UFY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         马雅从.基于特征组合的展示广告点击率预估模型研究[D].广州:华南理工大学, 2018.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Guo H, Tang R, Ye Y, et al.DeepFM:A Factorization-Machine based Neural Network for CTR Prediction[C]//Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, 2017:1725-1731." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=DeepFM:A Factorization-Machine based Neural Network for CTR Prediction">
                                        <b>[12]</b>
                                         Guo H, Tang R, Ye Y, et al.DeepFM:A Factorization-Machine based Neural Network for CTR Prediction[C]//Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, 2017:1725-1731.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Zhang T.Internet Financial Credit Evaluation Based on the Fusion of GBDT and LR[C]//2018 International Conference on Management, Economics, Education and Social Sciences (MEESS 2018) , 2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Internet Financial Credit Evaluation Based on the Fusion of GBDT and LR">
                                        <b>[13]</b>
                                         Zhang T.Internet Financial Credit Evaluation Based on the Fusion of GBDT and LR[C]//2018 International Conference on Management, Economics, Education and Social Sciences (MEESS 2018) , 2018.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(07),307-310+316 DOI:10.3969/j.issn.1000-386x.2019.07.052            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于DeepFM模型的广告推荐系统研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%81%E8%B1%B9&amp;code=37556666&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郁豹</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E6%8C%AF%E5%8D%8E&amp;code=08206112&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李振华</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%87%AF&amp;code=08213528&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张凯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E5%AE%89%E7%BF%94&amp;code=39137705&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡安翔</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B1%B1%E4%B8%9C%E5%A4%A7%E5%AD%A6%E6%8E%A7%E5%88%B6%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0237047&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">山东大学控制科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>随着移动设备普及, 移动互联网行业进入了高速发展阶段, 信息量和用户量急剧增长, 如何在有限的资源下准确地分析用户行为, 提升广告效果并保障用户体验显得尤为重要。提出一种由深度神经网络 (Deep neural network) 和因子分解机 (Factorization machine) 组成的模型——DeepFM模型来实现社交广告的个性化推荐, 其中因子分解机部分主要是提取一阶二阶特征, 深度神经网络部分主要提取高阶特征。最终通过研究发现, DeepFM模型比逻辑回归模型 (LR模型) 及因子分解机 (FM模型) 的效果都要好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=DeepFM%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">DeepFM模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B9%BF%E5%91%8A%E6%8E%A8%E8%8D%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广告推荐;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">因子分解机;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郁豹, 硕士生, 主研领域:模式识别, 机器学习, 深度学习。;
                                </span>
                                <span>
                                    李振华, 副教授。;
                                </span>
                                <span>
                                    张凯, 硕士生。;
                                </span>
                                <span>
                                    胡安翔, 硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-29</p>

            </div>
                    <h1><b>ADVERTISEMENT RECOMMENDATION SYSTEM BASED ON DEEPFM MODEL</b></h1>
                    <h2>
                    <span>Yu Bao</span>
                    <span>Li Zhenhua</span>
                    <span>Zhang Kai</span>
                    <span>Hu Anxiang</span>
            </h2>
                    <h2>
                    <span>School of Control Science and Engineering, Shandong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>With the popularity of mobile devices, the mobile Internet industry has entered a high-speed development stage, where the amount of information and users has increased dramatically. How to accurately analyze user behavior under limited resources, improve advertising effect and ensure user experience is particularly important. In this paper, a model composed of deep neural network and factorization machine, the DeepFM model, was proposed to realize personalized recommendation of social advertisements. The factor decomposer part mainly extracted first-order and second-order features, and the deep neural network part mainly extracted higher-order features. Finally, it is found that DeepFM model is better than logical regression model (LR model) and factor decomposition machine (FM model) .</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=DeepFM%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">DeepFM model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Advertisement%20recommendation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Advertisement recommendation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Factorization%20machine&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Factorization machine;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-29</p>
                            </div>


        <!--brief start-->
                        <h3 id="29" name="29" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="30">随着移动通信与互联网的高速发展, 移动互联网时代已经到来, 移动互联网广告产业也随之快速发展。传统广告在推送时, 往往会给用户推送一些不相关、用户不感兴趣的广告内容, 这些相关性较小的广告会干扰用户正常的访问, 有的甚至会泄露用户的个人隐私, 因此用户对这种“地毯式轰炸”的传统广告普遍持反感态度。根据用户的个人兴趣和行为, 挖掘用户的潜在购买需求, 面向用户需求进行个性化的广告推荐显得尤为重要<citation id="91" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。另一方面随着移动互联网时代的高速发展, 移动互联网信息量和用户数量也随之呈现出爆炸式地增长, 造成了有限的网络资源与用户日益增长的网络需求之间的矛盾愈加突出, 所以如何在有限的资源下准确高效地提取用户的行为特征, 分析用户的兴趣和需求, 有针对性的进行广告投放, 这就需要我们不断探索更优的算法来精确捕捉用户的特征。</p>
                </div>
                <div class="p1">
                    <p id="31">广告推荐的问题一般可理解为广告点击率 (CTR) 问题。广告点击率预测是广告领域重要的内容之一, 工业界已经进行了较为深入的研究, 但还是存在一些难以解决的问题, 如数据量大、数据稀疏, 异常数据等。在选用模型的时候, 复杂模型训练难度大、很容易产生过拟合现象, 训练出来的模型效果一般较差, 因此工业界一般使用一些较为浅层的模型, 而特征工程在解决问题的过程中是重要环节, 特征往往决定了模型的上限, 因此解决特征工程的特征构造问题已经成为这类问题的难点之一。文献<citation id="92" type="reference">[<a class="sup">2</a>]</citation>结合特征向量存在的层次化结构和多元化特征, 构建逻辑回归模型的多维特征组合向量, 并将其用于逻辑回归模型权重的训练。文献<citation id="93" type="reference">[<a class="sup">3</a>]</citation>基于电商平台的用户行为数据, 在原始特征集的基础上加入了二次组合统计特征, 最终用了XGBoost分类算法进行分类, 预测性能比传统的机器学习算法更佳。文献<citation id="94" type="reference">[<a class="sup">4</a>]</citation>提出了FM集成模型, 结合GBDT高层特征提取方法, 形成GBDT+FM的融合模型, 也能有效提高精度。所以多维的特征组合能够有效地提高广告推荐的准确度。文献<citation id="95" type="reference">[<a class="sup">5</a>]</citation>介绍了近几年基于深度学习的推荐系统研究进展, 比较其与传统推荐系统的区别以及优势, 最后概括了其未来的研究和应用方向。文献<citation id="96" type="reference">[<a class="sup">6</a>]</citation>研究的目标是通过给定的信息预测搜索广告的点击率, 通过使用深度学习模型, 挖掘了高维特征组合, 有效地提高了模型的预测性能。实验结果表明, 在特征相同的情况下, 使用深度神经网络模型方法能取得比主流方法更好的预测结果, 基于深度学习的卷积神经网络的搜索广告点击率预测的方法能有效地提高点击率预测的结果。</p>
                </div>
                <div class="p1">
                    <p id="32">基于社交的广告已成为互联网广告行业中发展最为迅速的广告之一, 本文将针对一个基于真实业务场景的广告技术产品——腾讯社交广告Lookalike相似人群拓展进行研究, 提出一种由深度神经网络和因子分解机组成的模型——DeepFM模型, 并验证该模型的效果。</p>
                </div>
                <h3 id="33" name="33" class="anchor-tag"><b>1 相关理论</b></h3>
                <h4 class="anchor-tag" id="34" name="34"><b>1.1 逻辑回归模型</b></h4>
                <div class="p1">
                    <p id="35">逻辑回归 (Logistic Regression, LR) 是当前业界比较常用的机器学习方法, 被广泛地应用于诸多领域, 比如搜索、推荐、广告、图像、风控等<citation id="97" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。因为它能很好地描述0/1概率问题<citation id="98" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>, 所以也常应用于广告点击率的预测问题, 也就是根据某广告被用户点击的可能性, 把最可能被用户点击的广告摆在用户能看到的地方。</p>
                </div>
                <div class="p1">
                    <p id="36">逻辑回归可以用来回归, 也可以用来分类, 主要是二分类, 由条件概率分布<i>P</i> (<i>Y</i>|<i>X</i>) 表示, 这里的自变量<i>X</i>取值为实数, 而因变量<i>Y</i>为0或者1。二项LR的条件概率如下:</p>
                </div>
                <div class="p1">
                    <p id="37"><mathml id="38"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mtext>e</mtext><msup><mrow></mrow><mrow><mi>ω</mi><mo>⋅</mo><mi>x</mi></mrow></msup></mrow><mrow><mn>1</mn><mo>+</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mi>ω</mi><mo>⋅</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="39"><mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo>=</mo><mn>0</mn><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mtext>e</mtext><msup><mrow></mrow><mrow><mi>ω</mi><mo>⋅</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="41">万物的发生都可以用可能性或者几率 (Odds) 来表达, “几率”的表达式如下:</p>
                </div>
                <div class="p1">
                    <p id="42"><mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>o</mi><mi>d</mi><mi>d</mi><mi>s</mi><mo>=</mo><mfrac><mi>p</mi><mrow><mn>1</mn><mo>-</mo><mi>p</mi></mrow></mfrac></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="44">几率的对数形式为:</p>
                </div>
                <div class="p1">
                    <p id="45"><mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>o</mi><mi>d</mi><mi>d</mi><mi>s</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>log</mi></mrow><mfrac><mi>p</mi><mrow><mn>1</mn><mo>-</mo><mi>p</mi></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="47">所以对逻辑回归而言, <i>Y</i>=1的对数几率就是:</p>
                </div>
                <div class="p1">
                    <p id="48"><mathml id="49"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>log</mi></mrow><mfrac><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">) </mo></mrow><mrow><mn>1</mn><mo>-</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></mfrac><mo>=</mo><mi>ω</mi><mo>⋅</mo><mi>x</mi></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="50">也就是说, 输出<i>Y</i>=1的对数几率是由输入<i>x</i>的线性函数表示的模型, 这就是逻辑回归模型。当<i>ω</i>·<i>x</i>的值越接近正无穷, <mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">) </mo></mrow></math></mathml>概率值也就越接近1。</p>
                </div>
                <div class="p1">
                    <p id="52">逻辑回归最基本的学习算法是最大似然。假设我们有<i>n</i>个独立的训练样本{ (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) , (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) , …, (<i>x</i><sub><i>n</i></sub>, <i>y</i><sub><i>n</i></sub>) }, <i>y</i>={0, 1}。那每一个观察到的样本 (<i>x</i><sub><i>i</i></sub>, <i>y</i><sub><i>i</i></sub>) 出现的概率为:</p>
                </div>
                <div class="p1">
                    <p id="53" class="code-formula">
                        <mathml id="53"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>6</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="54">那对整个样本集, 也就是<i>n</i>个独立的样本出现的似然函数为 (因为每个样本都是独立的, 所以<i>n</i>个样本出现的概率就是他们各自出现的概率相乘) :</p>
                </div>
                <div class="p1">
                    <p id="55" class="code-formula">
                        <mathml id="55"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>ω</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><mo>∏</mo><mi>Ρ</mi></mstyle><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo><msup><mrow></mrow><mrow><mn>1</mn><mo>-</mo><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></msup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="56">在统计学中, 似然函数常常使用极大似然估计法来求解, 即找到一组参数, 使得在这组参数下, 数据的似然度 (概率) 最大, 即求解上面的似然函数取得最大值的<i>ω</i>值。似然函数的求解过程一般先将似然函数转化为负对数似然函数形式, 该函数是一个凸函数, 求解的方法有梯度下降法、牛顿法、拟牛顿法<citation id="99" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。其中梯度下降法只用到了目标函数的一阶导数信息;牛顿法用到了目标函数的二阶导数信息;拟牛顿法改善了牛顿法的求解方法, 模拟了二阶导数信息, 牛顿法、拟牛顿法的收敛速度较快。</p>
                </div>
                <div class="p1">
                    <p id="57">最终可以求解得到逻辑回归模型的参数<i>ω</i>, 将样本输入即可得到点击率的预测值。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58"><b>1.2 FM模型</b></h4>
                <div class="p1">
                    <p id="59">FM (Factorization Machine) 是由Konstanz大学Steffen Rendle (现任职于Google) 于2010年最早提出的, 旨在解决稀疏数据下的特征组合问题<citation id="100" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。FM模型相当于在LR模型的基础上引入了二阶组合项<i>x</i><sub><i>i</i></sub><i>x</i><sub><i>j</i></sub>, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="60"><mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>ω</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>ω</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="62">式中:<i>n</i>代表样本的特征数量, <i>x</i><sub><i>i</i></sub>是第<i>i</i>个特征的值, <i>ω</i><sub>0</sub>、<i>ω</i><sub><i>i</i></sub>、<i>ω</i><sub><i>ij</i></sub>是模型参数。</p>
                </div>
                <div class="p1">
                    <p id="63">多项式模型是包含特征组合的最直观的模型。在多项式模型中, 特征<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>的组合采用<i>x</i><sub><i>i</i></sub><i>x</i><sub><i>j</i></sub>表示, 即<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>都非零时, 组合特征<i>x</i><sub><i>i</i></sub><i>x</i><sub><i>j</i></sub>才有意义。从式 (8) 可以看出一共有<mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>n</mi><mo stretchy="false"> (</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow></math></mathml>个组合特征的参数, 且任意两个参数都是独立的。然而在实际应用场景中数据稀疏性普遍存在, 二次项参数的训练是很困难的。原因在于, 每个参数<i>ω</i><sub><i>ij</i></sub>的训练需要大量<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>都非零的样本;而样本数据本来就比较稀疏, 满足“<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>都非零”的样本将会非常少。训练样本的不足, 很容易导致参数<i>ω</i><sub><i>ij</i></sub>不准确, 最终将严重影响模型的性能。所以在这里引入了一个隐向量的概念, 第<i>i</i>维特征的隐向量为<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>i</i></sub>是一个<i>K</i>维的向量, 将<i>ω</i><sub><i>ij</i></sub>替换为〈<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>〉, 可得到新的FM模型的公式如下:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula">
                        <mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>y</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mi>ω</mi><msub><mrow></mrow><mn>0</mn></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>ω</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>〈</mo></mstyle></mrow></mstyle><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo>〉</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>9</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="66">从式 (9) 〈<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>〉可知二项式的参数个数从<mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>n</mi><mo stretchy="false"> (</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mn>2</mn></mfrac></mrow></math></mathml>减少到<i>kn</i>个。原来的二项式参数之间是相互独立的, 如<i>ω</i><sub><i>mi</i></sub>和<i>ω</i><sub><i>ij</i></sub>, 采用隐向量点积形式为〈<i>v</i><sub><i>m</i></sub>, <i>v</i><sub><i>i</i></sub>〉和〈<i>v</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>〉, 此时包含共同项<i>v</i><sub><i>i</i></sub>, 即<i>x</i><sub><i>m</i></sub><i>x</i><sub><i>i</i></sub>与<i>x</i><sub><i>i</i></sub><i>x</i><sub><i>j</i></sub>的参数之间不再相互独立, 所有与<i>x</i><sub><i>i</i></sub>组合成的二项式特征都可以用来学习隐向量<i>v</i><sub><i>i</i></sub>。在计算的时候可以用下式进行优化, 可将时间复杂度从<i>O</i> (<i>kn</i><sup>2</sup>) 降低到<i>O</i> (<i>kn</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>〈</mo></mstyle></mrow></mstyle><mi>v</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>v</mi><msub><mrow></mrow><mi>j</mi></msub><mo>〉</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>f</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mrow><mrow><mo> (</mo><mrow><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>v</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>f</mi></mrow></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>v</mi></mstyle><msubsup><mrow></mrow><mrow><mi>i</mi><mo>, </mo><mi>f</mi></mrow><mn>2</mn></msubsup><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup></mrow><mo>) </mo></mrow></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>1.3 DeepFM模型</b></h4>
                <div class="p1">
                    <p id="70">由以上分析可知逻辑回归模型主要提取了一阶特征, FM模型在逻辑回归模型的基础上做了改进, 提出了用隐向量作内积来表达组合特征, 但是在实际应用中受限于计算复杂度一般只提取到二阶组合特征。广告点击率问题的重点在于如何挖掘组合, 组合特征包括二阶、三阶甚至更高阶的, 阶数越高越复杂, 越不容易学习<citation id="101" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 同时学习到这两种组合特征的性能要比只考虑其中一种的性能要好。所以本文提出了一种由深度神经网络和因子分解机组成的模型——DeepFM模型, 图1是DeepFM模型的架构图。</p>
                </div>
                <div class="area_img" id="71">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907053_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 DeepFM模型架构图" src="Detail/GetImg?filename=images/JYRJ201907053_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 DeepFM模型架构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907053_071.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="72">从图1中可以看出DeepFM模型主要分为2个部分:FM部分和深度神经网络部分, 其中FM包含一次项和二次项部分。在深度神经网络中引入了嵌入层来完成将输入向量压缩到低维稠密向量, 即FM中提出的隐向量, 一方面解决了数据稀疏性的问题, 另一方面避免了多类别特征one-hot编码之后维度过大的问题<citation id="102" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。DNN部分和FM部分的二次项共用了同一个输入, 最终同时进行训练, 结果如下:</p>
                </div>
                <div class="p1">
                    <p id="73"><mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mi>S</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy="false"> (</mo><mi>y</mi><msub><mrow></mrow><mrow><mtext>F</mtext><mtext>Μ</mtext></mrow></msub><mo>+</mo><mi>y</mi><msub><mrow></mrow><mrow><mtext>D</mtext><mtext>Ν</mtext><mtext>Ν</mtext></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="75">式中:<i>y</i><sub>FM</sub>表示FM部分的输出, <i>y</i><sub>DNN</sub>表示深度神经网络部分的输出, 通过一个Sigmoid函数将结果转化为0-1之间的数, 得到最终的点击率预估结果。</p>
                </div>
                <h3 id="76" name="76" class="anchor-tag"><b>2 实验结果</b></h3>
                <div class="p1">
                    <p id="77">本文采用的数据集主要来自于真实业务场景的广告技术产品——腾讯社交广告的公开数据集, 该数据集的用户数量约为800万, 包含1个数值型特征, 31个类别型特征 (包含11个多值类别型特征) 。因为样本正负比例不平衡 (正负样本比例约为1∶20) , 所以模型评估的方式采用AUC评分, AUC定义为ROC曲线下与坐标轴围成的面积, ROC曲线的横纵坐标分别为假正率 (FPR:<mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>F</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>和真正率 (TPR:<mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo stretchy="false">) </mo></mrow></math></mathml>。AUC评分可以理解为正样本排在负样本前面的概率, 当预测结果完全正确时AUC值为1, 所以AUC值越大表示分类的结果越准确。表1为混淆矩阵表。</p>
                </div>
                <div class="area_img" id="80">
                    <p class="img_tit"><b>表1 混淆矩阵表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="80" border="1"><tr><td rowspan="2"><br />预测实际</td><td colspan="2"><br />预测</td></tr><tr><td><br />正</td><td>负</td></tr><tr><td><br />正</td><td>TP</td><td>FP</td></tr><tr><td><br />负</td><td>FN</td><td>TN</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="81">本次实验分别对3个模型进行了多次训练, 最终结果取多次实验的平均AUC值, 实验结果如表2和图2所示。</p>
                </div>
                <div class="area_img" id="82">
                    <p class="img_tit"><b>表2 原始数据集结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="82" border="1"><tr><td><br />模型</td><td>AUC值</td></tr><tr><td><br />LR</td><td>0.724 135</td></tr><tr><td><br />FM</td><td>0.736 323</td></tr><tr><td><br />DeepFM</td><td>0.749 123</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="83">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907053_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 原始数据集ROC曲线" src="Detail/GetImg?filename=images/JYRJ201907053_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 原始数据集ROC曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907053_083.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="84">从表2的结果可以看出FM模型由于引入了二阶组合特征, 所以它的AUC值比LR模型要高, 而DeepFM模型由于加入了深度神经网络部分学习高阶特征组合, 它比LR和FM模型的AUC值都要高。分析图2可以看到, 由于正负样本比例不平衡, 所以ROC曲线的前面近似于直线<i>x</i>=0, ROC曲线的后面DeepFM的真正率高于LR和FM, 所以DeepFM的AUC值比LR和FM都要高。结合表2和图2的结果可以说明DeepFM模型能够有效挖掘出高阶组合特征, 比LR模型和FM模型的推荐效果都要好。</p>
                </div>
                <div class="p1">
                    <p id="85">在实际使用过程中, 逻辑回归模型作为一种线性模型比较依赖于人工提取的组合特征, 所以本文在原始特征的基础上, 采用了文献<citation id="103" type="reference">[<a class="sup">13</a>]</citation>中的方法, 用GBDT抽取了新的组合特征补充了数据集, 最终结果如表3和图3所示。</p>
                </div>
                <div class="area_img" id="86">
                    <p class="img_tit"><b>表3 补充数据集结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="86" border="1"><tr><td><br />模型</td><td>AUC值</td></tr><tr><td><br />GBDT+LR</td><td>0.741 241</td></tr><tr><td><br />GBDT+FM</td><td>0.751 732</td></tr><tr><td><br />GBDT+DeepFM</td><td>0.757 137</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="87">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907053_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 新数据集ROC曲线" src="Detail/GetImg?filename=images/JYRJ201907053_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 新数据集ROC曲线  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907053_087.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="88">从表3和图3可以看出在加了组合特征的情况下, 三个模型的性能都有所提高, 其中LR模型的提升幅度最大, 这是因为LR模型没有引入组合特征, 因此在加入组合特征后, 性能有了较大幅度的提升;FM、DeepFM模型中虽然可以通过模型结构自动进行特征组合, 但是显式加入这些特征一来可以降低模型训练难度, 二来也相当于寻找了更高阶的特征组合, 所以效果也有一定的提升。DeepFM模型的效果比LR和FM模型都要好。</p>
                </div>
                <h3 id="89" name="89" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="90">本文针对广告点击率问题, 提出一种由深度神经网络和因子分解机组成的模型——DeepFM模型, 并与逻辑回归模型和因子分解机模型进行了比较, 最终发现DeepFM模型的效果更好, 能挖掘出有效的高阶特征组合, 使广告推荐系统更加准确和个性化。DeepFM模型也可以解决样本数据稀疏的问题, 避免了多类别特征在one-hot编码之后导致特征维度过大的情况。所以在广告点击率预估问题上, 采用DeepFM模型对广告主来说能优化广告投放策略, 减少广告成本, 提高广告的转化率, 对于用户来说避免了接受无关的广告信息, 也能更好地保护个人隐私。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SDDZ201808072&amp;v=MDUzMjhadVp0RnlqaFY3N1BOaW5QZExHNEg5bk1wNDlDWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 陈检.基于神经网络与因子分解机的点击率预估应用研究[J].信息技术与信息化, 2018 (8) :204-207.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=TXJS201609022&amp;v=MTE3OTh0R0ZyQ1VSN3FmWnVadEZ5amhWNzdQTVRYQmZiRzRIOWZNcG85SFpvUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 伊雯雯.基于多维特征组合逻辑回归模型的广告点击率预测[J].通信技术, 2016, 49 (9) :1221-1228.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201814033&amp;v=MTM2MjBMalhCZmJHNEg5bk5xNDlHWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFY3N1A=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 杨立洪, 白肇强.基于二次组合的特征工程与XGBoost模型的用户行为预测[J].科学技术与工程, 2018, 18 (14) :191-194.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801019&amp;v=MzEwMzZiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVjc3UEx6VFpaTEc0SDluTXJvOUU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 潘博, 张青川, 于重重, 等.FM集成模型在广告点击率预估中的应用[J].计算机应用与软件, 2018, 35 (1) :107-111, 148.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201807011&amp;v=MjcyNDF6N0Jkckc0SDluTXFJOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVjc3UEw=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 黄立威, 江碧涛, 吕守业, 等.基于深度学习的推荐系统研究综述[J].计算机学报, 2018, 41 (7) :191-219.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1015980137.nh&amp;v=MTcwOTN5amhWNzdQVkYyNkc3cXdIdERQcUpFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 李思琴.基于深度学习的搜索广告点击率预测方法研究[D].哈尔滨:哈尔滨工业大学, 2015.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Trust region Newton methods for large-scale logistic regression">

                                <b>[7]</b> Lin C J, Weng R C, Keerthi S S.Trust region Newton methods for large-scale logistic regression[C]//International Conference on Machine Learning.ACM, 2007:561-568.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=2009104220.nh&amp;v=MTkxOTlQVjEyN0Y3SzRHdFBPcjVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhWNzc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 王贤.基于逻辑回归的案件关联分析[D].重庆:西南大学, 2009.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013178340.nh&amp;v=MzI2NjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhWNzdQVkYyNkhiSy9GdExJcjVFYlBJUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 王兵.一种基于逻辑回归模型的搜索广告点击率预估方法的研究[D].杭州:浙江大学, 2013.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Factorization Machines">

                                <b>[10]</b> Rendle S.Factorization Machines[C]//IEEE, International Conference on Data Mining.IEEE, 2011:995-1000.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018874442.nh&amp;v=MTM5NDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqaFY3N1BWRjI2RnJ1L0d0WElyWkViUElRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 马雅从.基于特征组合的展示广告点击率预估模型研究[D].广州:华南理工大学, 2018.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=DeepFM:A Factorization-Machine based Neural Network for CTR Prediction">

                                <b>[12]</b> Guo H, Tang R, Ye Y, et al.DeepFM:A Factorization-Machine based Neural Network for CTR Prediction[C]//Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, 2017:1725-1731.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Internet Financial Credit Evaluation Based on the Fusion of GBDT and LR">

                                <b>[13]</b> Zhang T.Internet Financial Credit Evaluation Based on the Fusion of GBDT and LR[C]//2018 International Conference on Management, Economics, Education and Social Sciences (MEESS 2018) , 2018.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201907053" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907053&amp;v=MDE3MDI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVjc3UEx6VFpaTEc0SDlqTXFJOUFaNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
