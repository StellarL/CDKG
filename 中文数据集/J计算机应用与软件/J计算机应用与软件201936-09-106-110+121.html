<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135592603127500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201909020%26RESULT%3d1%26SIGN%3dkE%252bK0A0ZnvpAcsruYGcSM5ABbu0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909020&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909020&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909020&amp;v=MjIwOTZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5oVnJ6Skx6VFpaTEc0SDlqTXBvOUg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 基础知识&lt;/b&gt; "><b>1 基础知识</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="&lt;b&gt;2 快速矩阵填充方法&lt;/b&gt; "><b>2 快速矩阵填充方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="&lt;b&gt;2.1 矩阵填充模型&lt;/b&gt;"><b>2.1 矩阵填充模型</b></a></li>
                                                <li><a href="#63" data-title="&lt;b&gt;2.2 随机快速矩阵填充方法&lt;/b&gt;"><b>2.2 随机快速矩阵填充方法</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;2.3 复杂度分析&lt;/b&gt;"><b>2.3 复杂度分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;3 实验分析&lt;/b&gt; "><b>3 实验分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#101" data-title="&lt;b&gt;3.1 仿真数据实验&lt;/b&gt;"><b>3.1 仿真数据实验</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;3.2 真实数据实验&lt;/b&gt;"><b>3.2 真实数据实验</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#128" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#106" data-title="图1 不同算法在矩阵的秩不同的情况下矩阵恢复的结果">图1 不同算法在矩阵的秩不同的情况下矩阵恢复的结果</a></li>
                                                <li><a href="#108" data-title="图2 不同算法在采样率不同的情况下矩阵恢复的结果">图2 不同算法在采样率不同的情况下矩阵恢复的结果</a></li>
                                                <li><a href="#117" data-title="图3 被噪声污染后的图像">图3 被噪声污染后的图像</a></li>
                                                <li><a href="#118" data-title="图4 经过FRPMC处理后与图3相对应的恢复后的图像">图4 经过FRPMC处理后与图3相对应的恢复后的图像</a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;表1 在不同采样率下四个算法的PSNR值&lt;/b&gt;"><b>表1 在不同采样率下四个算法的PSNR值</b></a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;表2 在不同采样率下四个算法的运行时间&lt;/b&gt;"><b>表2 在不同采样率下四个算法的运行时间</b></a></li>
                                                <li><a href="#125" data-title="图5 随机选取5幅图的实验情况">图5 随机选取5幅图的实验情况</a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;表3 图5中5幅图相对应的PSNR值和对应算法的运行时间&lt;/b&gt;"><b>表3 图5中5幅图相对应的PSNR值和对应算法的运行时间</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Rennie D M,Srebro N.Fast Maximum Margin Matrix Factorization for Collaborative Prediction[C]//Proceedings of International Conference on Machine Learning(ICML).2005:713-719." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fast maximum margin matrix factorization for collaborative prediction">
                                        <b>[1]</b>
                                         Rennie D M,Srebro N.Fast Maximum Margin Matrix Factorization for Collaborative Prediction[C]//Proceedings of International Conference on Machine Learning(ICML).2005:713-719.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Canral R S,Torre F D,Costcira J P,et al.Matrix Completion for Multi-Lable Image Classification[C]//Proceedings of Neural Information Processing Systems(NIPS).2011:190-128." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Matrix completion for multi-label image classification">
                                        <b>[2]</b>
                                         Canral R S,Torre F D,Costcira J P,et al.Matrix Completion for Multi-Lable Image Classification[C]//Proceedings of Neural Information Processing Systems(NIPS).2011:190-128.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Li W,Zhao L,Lin Z J,et al.Non-Local Image Inpainting using Low-Rank Matrix Completion[J].Computer Graphics Forum,2015,34(6):111-122." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD15092500000107&amp;v=MTc1NDFSTT1OaWZjYXJLOUh0ak9xbzlGWk9zUERYdytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJVm9SYQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Li W,Zhao L,Lin Z J,et al.Non-Local Image Inpainting using Low-Rank Matrix Completion[J].Computer Graphics Forum,2015,34(6):111-122.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Otazo R,Candes E,Sodickson D K.Low-Rank Plus Sparse Matrix Decomposition for Accelerated Dynamic MRI with Separation of Background and Dynamic Components[J].Magnetic Resonance in Medicine,2015,73(3):1125-1136." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Low‐rank plus sparse matrix decomposition for accelerated dynamic MRI with separation of background and dynamic components">
                                        <b>[4]</b>
                                         Otazo R,Candes E,Sodickson D K.Low-Rank Plus Sparse Matrix Decomposition for Accelerated Dynamic MRI with Separation of Background and Dynamic Components[J].Magnetic Resonance in Medicine,2015,73(3):1125-1136.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Gogn A,Majumdar A.Matrix Completion Incorporating Auxiliary Information for Recommender System Design[J].Expert System with Applications,2015,42(12):5789-5799." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES21670C13A700354B6D35AFF67AE3AA83&amp;v=MjQ1MTljQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJ5Nnc2az1OaWZPZmJHNUdOYk0zSTVHRmV3UERIODh5MlFWbmp4NE9RbVVxaFZFRExIbE5MSw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Gogn A,Majumdar A.Matrix Completion Incorporating Auxiliary Information for Recommender System Design[J].Expert System with Applications,2015,42(12):5789-5799.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Combettes P L,Wajs V R.Signal Recovery by Proximal Forward-Backward Splitting[J].Multiscale Modeling and Simulation,2004,4(4):1168-1200." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Signal recovery by proximal forward-backward splitting">
                                        <b>[6]</b>
                                         Combettes P L,Wajs V R.Signal Recovery by Proximal Forward-Backward Splitting[J].Multiscale Modeling and Simulation,2004,4(4):1168-1200.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Beck A,Tetruashvili L.On the Convergence of Block Coordinate Descent Methods[J].SIAM Journal on Optimization,2013,23(4):2037-2060." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=On the convergence of block coordinate descent methods">
                                        <b>[7]</b>
                                         Beck A,Tetruashvili L.On the Convergence of Block Coordinate Descent Methods[J].SIAM Journal on Optimization,2013,23(4):2037-2060.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Bregman L M.Relaxation Method for Finding a Common Point of Convex Sets and Its Application to Optimization Problems[J].Doklady Akademii nauk SSSR,1966,171(5):1019-1022." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relaxation Method for Finding a Common Point of Convex Sets and Its Application to Optimization Problems">
                                        <b>[8]</b>
                                         Bregman L M.Relaxation Method for Finding a Common Point of Convex Sets and Its Application to Optimization Problems[J].Doklady Akademii nauk SSSR,1966,171(5):1019-1022.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Tan H,Cheng B,Wang W,et al.Tensor Completion Via a Multi-linear Low-n-rank Factorization Model[J].Neurocomputing,2014,133:161-169." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300033900&amp;v=Mjk2NTFPZmJLOEh0UE5ySTlGWk9nTUJYdzVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJVm9SYVJNPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Tan H,Cheng B,Wang W,et al.Tensor Completion Via a Multi-linear Low-n-rank Factorization Model[J].Neurocomputing,2014,133:161-169.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Ma S,Goldfarb D,Chen L.Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization[J].Mathematical Programming,2009,128(1-2):321-353." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fixed point and Bregman iterative methods for matrix rank minimization">
                                        <b>[10]</b>
                                         Ma S,Goldfarb D,Chen L.Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization[J].Mathematical Programming,2009,128(1-2):321-353.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Cai J F,Cand&#232;s E J,Shen Z.A Singular Value Thresholding Algorithm for Matrix Completion[J].SIAM Journal on Optimization,2010,20(4):1956-1982." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A singular value thresholding algorithm for matrix completion">
                                        <b>[11]</b>
                                         Cai J F,Cand&#232;s E J,Shen Z.A Singular Value Thresholding Algorithm for Matrix Completion[J].SIAM Journal on Optimization,2010,20(4):1956-1982.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Toh K C,Yun S.An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Least Squares Problems[J].Pacific Journal of Optimization,2010,6(3):615-640." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems">
                                        <b>[12]</b>
                                         Toh K C,Yun S.An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Least Squares Problems[J].Pacific Journal of Optimization,2010,6(3):615-640.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" He Z S,Cichocki A,Xie S L,et al.Detecting the Number of Clusters in N-way Probabilistic Clustering[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence,2010,32(11):2006-2021." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting the Number of Clusters in n-Way Probabilistic Clustering">
                                        <b>[13]</b>
                                         He Z S,Cichocki A,Xie S L,et al.Detecting the Number of Clusters in N-way Probabilistic Clustering[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence,2010,32(11):2006-2021.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Lin Z C,Chen M M,Ma Y,et al.The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices [EB/OL].arXiv:1009.5055,2010." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices">
                                        <b>[14]</b>
                                         Lin Z C,Chen M M,Ma Y,et al.The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices [EB/OL].arXiv:1009.5055,2010.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Zhou P,Lu C,Lin Z,et al.Tensor Factorization for Low-Rank Tensor Completion[J].IEEE Transactions on Image Processing,2018,27(3):1152-1163." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Tensor Factorization for Low-Rank Tensor Completion">
                                        <b>[15]</b>
                                         Zhou P,Lu C,Lin Z,et al.Tensor Factorization for Low-Rank Tensor Completion[J].IEEE Transactions on Image Processing,2018,27(3):1152-1163.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(09),106-110+121 DOI:10.3969/j.issn.1000-386x.2019.09.019            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于快速随机投影的矩阵填充方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%86%AF%E9%9B%85%E8%8E%89&amp;code=38966212&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">冯雅莉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E4%B8%BA%E5%86%9B&amp;code=06744788&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙为军</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E4%B8%9C%E5%B7%A5%E4%B8%9A%E5%A4%A7%E5%AD%A6&amp;code=0139774&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广东工业大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了解决在矩阵填充过程中的高维度和高计算成本的问题,提出一种基于快速随机投影的矩阵填充方法(FRPMC)。利用对矩阵的随机投影的方式对需要填充的矩阵进行降维,然后构造SVD的近似模型来重构矩阵来实现矩阵填充的功能。通过仿真实验证明了该算法的可行性。与其他一些传统算法进行对比,FRPMC在图像恢复的实验中图片恢复的峰值信噪比和运行时间均比奇异值阈值法、加速近邻梯度法和增广拉格朗日乘子法要好。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A5%87%E5%BC%82%E5%80%BC%E9%98%88%E5%80%BC%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">奇异值阈值法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8A%A0%E9%80%9F%E8%BF%91%E9%82%BB%E6%A2%AF%E5%BA%A6%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">加速近邻梯度法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A2%9E%E5%B9%BF%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">增广拉格朗日乘子法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9A%8F%E6%9C%BA%E6%8A%95%E5%BD%B1%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">随机投影法;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9F%A9%E9%98%B5%E5%A1%AB%E5%85%85&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">矩阵填充;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E4%BF%AE%E5%A4%8D&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像修复;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    冯雅莉,硕士生,主研邻域:矩阵分析,张量分析。;
                                </span>
                                <span>
                                    孙为军,讲师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-13</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61673124);</span>
                    </p>
            </div>
                    <h1><b>A MATRIX COMPLETION METHOD BASED ON FAST RANDOM PROJECTION</b></h1>
                    <h2>
                    <span>Feng Yali</span>
                    <span>Sun Weijun</span>
            </h2>
                    <h2>
                    <span>Guangdong University of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the problem of high dimensionality and high computational cost in matrix completion, we a proposed matrix completion method based on fast random projection(FRPMC). The dimension of the matrix to be completed was reduced by random projection, and then the approximate model of SVD was constructed to reconstruct the matrix to realize the function of matrix completion. The feasibility of the algorithm is proved by simulation experiments. Compared with other traditional algorithms, FRPMC has better PSNR and running time in image restoration experiments than SVT, APG and ALME.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Singular%20value%20decomposition&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Singular value decomposition;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Accelerated%20proximal%20gradient&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Accelerated proximal gradient;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Augmented%20lagrange%20multipliers&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Augmented lagrange multipliers;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Random%20projection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Random projection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Matrix%20completion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Matrix completion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20inpainting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image inpainting;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-13</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="34">近年来,矩阵的使用越来越广泛和越来越受重视,而矩阵分析方法的重要性也显得越来越突出,例如矩阵分解、非负矩阵分解、低秩矩阵近似、矩阵填充等。而本文主要是关注其中的矩阵填充问题,在实际问题中,矩阵填充问题主要表现在图像和视频处理、推荐系统、文本分析和机器学习<citation id="134" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>]</sup></citation>等方面。为了方便对数据进行处理,一般我们会把数据转化成矩阵的表示形式,但这些数据转为矩阵后,经常会面临缺失,损毁和噪声污染等问题,所以如何恢复数据和对数据进行去噪是我们需要解决和研究的问题,而矩阵填充技术就是解决这类问题的其中一种有效的方法。矩阵填充技术在图像修复<citation id="131" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、核磁共振图像分割<citation id="132" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>、EEG信号处理、推荐系统<citation id="133" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>等领域中被广泛应用。</p>
                </div>
                <div class="p1">
                    <p id="35">在近二十年里,矩阵填充技术越来越受关注。它的主要目的是通过矩阵中已知的元素来恢复未知的元素,通常利用矩阵中行与行或者列与列之间的线性关系对未知元素进行估计和恢复,所以需要被填充的矩阵是低秩的,这是矩阵填充的重要前提之一。近年来,在矩阵填充领域中涌现了许多有效的算法,例如近邻梯度下降算法<citation id="135" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>(proximal gradient descent,PGD)、分块坐标下降算法<citation id="136" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、矩阵空间Bregman迭代算法<citation id="137" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、交替方向乘子法<citation id="138" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>(alternating direction method of multipliers,ADMM),还有一些随机优化方法,例如随机近邻梯度下降算法(stochastic proximal gradient descent,SPGD)。</p>
                </div>
                <div class="p1">
                    <p id="36">在解决实际的矩阵填充的问题中,对矩阵进行降维能够大大减少矩阵填充在计算中的成本,常用的方法有主成分分析(principal component analysis,PCA)和奇异值分解(singular value decomposition,SVD)。大多矩阵填充方法都是利用传统的SVD方法对原始矩阵进行降维的,但是传统的SVD的操作计算成本很高,所以不适用于大规模大尺寸的矩阵中。本文针对这个问题,提出了一种快速的随机投影方法,同时利用人工仿真数据和实际图片像素数据进行了多个实验,验证了本算法的可行性。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>1 基础知识</b></h3>
                <div class="p1">
                    <p id="38">对于秩为<i>r</i>的矩阵<b><i>X</i></b>∈<b>R</b><sup><i>m</i>×<i>n</i></sup>,它的奇异值分解为:<b><i>X</i>=<i>UΣV</i></b><sup>T</sup>,其中<b><i>U</i></b>∈<b>R</b><sup><i>m</i>×<i>r</i></sup>和<b><i>V</i></b>∈<b>R</b><sup><i>n</i>×<i>r</i></sup>满足<b><i>U</i></b><sup>T</sup><b><i>U</i>=<i>V</i></b><sup>T</sup><b><i>V</i>=<i>I</i></b>。(<b><i>I</i></b>为<i>r</i>阶单位矩阵),<i>Σ</i>=diag(<i>σ</i><sub>1</sub>,<i>σ</i><sub>2</sub>,…,<i>σ</i><sub><i>r</i></sub>)且其对角线上的元素满足<i>σ</i><sub>1</sub>≥<i>σ</i><sub>2</sub>≥…≥<i>σ</i><sub><i>r</i></sub>&gt;0,<i>σ</i><sub><i>i</i></sub>表示<b><i>X</i></b>的第<i>i</i>个奇异值。</p>
                </div>
                <div class="p1">
                    <p id="39"><b><i>X</i></b>的Frobenious范数满足:</p>
                </div>
                <div class="p1">
                    <p id="40" class="code-formula">
                        <mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">X</mi><mo>|</mo></mrow><msub><mrow></mrow><mi>F</mi></msub><mo>=</mo><msqrt><mrow><mo>〈</mo><mi mathvariant="bold-italic">X</mi><mo>,</mo><mi mathvariant="bold-italic">X</mi><mo>〉</mo></mrow></msqrt><mo>=</mo><msqrt><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>e</mi><mo>〈</mo><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mtext>Τ</mtext></msup><mi mathvariant="bold-italic">X</mi><mo>〉</mo></mrow></msqrt><mo>=</mo><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>r</mi></munderover><mi>σ</mi></mstyle><msubsup><mrow></mrow><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="41">式中:〈<b><i>X</i>,<i>X</i></b>〉表示<b><i>X</i></b>与<b><i>X</i></b>的内积,<i>trace</i>(·)表示矩阵的迹算子。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag"><b>2 快速矩阵填充方法</b></h3>
                <h4 class="anchor-tag" id="43" name="43"><b>2.1 矩阵填充模型</b></h4>
                <div class="p1">
                    <p id="44">秩是矩阵的一个重要的全局信息<citation id="139" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>,它能体现出矩阵的信息冗余度,而矩阵能够被充分地填充的前提条件是矩阵的信息是冗余的,其冗余度越低,填充难度就越高。所以矩阵填充的问题一般是最小化矩阵的秩的问题,其模型如下:</p>
                </div>
                <div class="p1">
                    <p id="45"><mathml id="46"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">X</mi></munder></mrow></math></mathml>:<i>rank</i>(<b><i>X</i></b>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="47">s.t. <b><i>X</i></b><sub><i>Ω</i></sub>=<b><i>M</i></b><sub><i>Ω</i></sub></p>
                </div>
                <div class="p1">
                    <p id="48">式中:<b><i>X</i>,<i>M</i></b>∈<b>R</b><sup><i>m</i>×<i>n</i></sup>,<b><i>M</i></b>可观察的元素的索引存放在<i>Ω</i>集合中,而索引不在<i>Ω</i>集合中的元素均为未知的。由于函数<i>rank</i>(<b><i>X</i></b>)是非凸的,在实际优化中求解非常困难。文献<citation id="140" type="reference">[<a class="sup">10</a>]</citation>提出对<i>rank</i>(<b><i>X</i></b>)的最小化问题可以转化成对<b><i>X</i></b>的核范数最小化问题,模型如下:</p>
                </div>
                <div class="p1">
                    <p id="49"><mathml id="50"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi mathvariant="bold-italic">X</mi></munder></mrow></math></mathml>:<mathml id="51"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">X</mi><mo>|</mo></mrow><msub><mrow></mrow><mo>*</mo></msub></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="52">s.t. <b><i>X</i></b><sub><i>Ω</i></sub>=<b><i>M</i></b><sub><i>Ω</i></sub></p>
                </div>
                <div class="p1">
                    <p id="53">式中:<mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow><msub><mrow></mrow><mo>*</mo></msub></mrow></math></mathml>表示核范数。</p>
                </div>
                <div class="p1">
                    <p id="55">在过去使用核范数优化模型的矩阵填充方法很多,例如奇异值阈值算法(Singular Value Thresholding,SVT)<citation id="141" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 加速近端梯度算法(Accelerated Proximal Gradient,APG)<citation id="142" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>,增广拉格朗日乘子法(Augmented Lagrange Multipliers,ALM)。</p>
                </div>
                <div class="p1">
                    <p id="56">本文引入一个新的变量<i>Z</i>,并把式(2)改写成:</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi mathvariant="bold-italic">X</mi><mo>,</mo><mi mathvariant="bold-italic">Ζ</mi></mrow></munder></mrow></math></mathml>:<mathml id="59"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">Ζ</mi><msub><mrow></mrow><mrow><mi>Ω</mi><mspace width="0.25em" /></mrow></msub><mo>-</mo><mi mathvariant="bold-italic">X</mi><msub><mrow></mrow><mrow><mi>Ω</mi><mspace width="0.25em" /></mrow></msub></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mi mathvariant="bold-italic">F</mi><mn>2</mn></msubsup></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="60"><b><i>rank</i></b>(<b><i>Z</i></b>)≤<i>rank</i>(<b><i>X</i></b>)</p>
                </div>
                <div class="p1">
                    <p id="61">式中:集合<i>Ω</i>是存放着矩阵中可观察的元素的索引,<mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mo>⋅</mo><mo>|</mo></mrow><msub><mrow></mrow><mi>F</mi></msub></mrow></math></mathml>表示Frobenius范数,等于矩阵中各项元素的绝对值的平方的总和。</p>
                </div>
                <h4 class="anchor-tag" id="63" name="63"><b>2.2 随机快速矩阵填充方法</b></h4>
                <div class="p1">
                    <p id="64">解式(3),一般采用SVD的方法,但是采用传统的SVD的方法,计算的时间和计算复杂度都非常大和高,这不利于对大尺寸的矩阵进行填充和处理,所以本文提出了一种快速的随机投影方法。</p>
                </div>
                <div class="p1">
                    <p id="65">假设一个矩阵<b><i>X</i></b>∈<b>R</b><sup><i>m</i>×<i>n</i></sup>,<i>Ω</i>和<i>Ω</i><sup><i>C</i></sup>分别表示<b><i>X</i></b>矩阵中的已知和未知元素的索引集合。为了解式(3),我们可以采用交替最小二乘法对<b><i>Z</i></b>进行更新。</p>
                </div>
                <div class="p1">
                    <p id="66">本文方法分为以下几个部分:</p>
                </div>
                <div class="p1">
                    <p id="67">第一部分是对数据进行预处理,初始化带未知元素的矩阵<b><i>X</i></b>,把矩阵<b><i>X</i></b>的未知元素用独立同分布的均值为0方差为1的高斯随机分布赋值,如下所示:</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>X</mi><msub><mrow></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mspace width="0.25em" /><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>Ω</mi></mtd></mtr><mtr><mtd><mtext>i</mtext><mo>.</mo><mtext>i</mtext><mo>.</mo><mtext>d</mtext><mo>.</mo><mspace width="0.25em" /><mi>Ν</mi><mo stretchy="false">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>∉</mo><mi>Ω</mi></mtd></mtr></mtable></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">第二部分,如果对<i>X</i>进行传统的SVD操作,则计算复杂度为<i>Ο</i>(min(<i>m</i><sup>2</sup><i>n</i>,<i>mn</i><sup>2</sup>)),随着矩阵的尺寸增大,计算的复杂度呈指数增长,所以需要对矩阵<b><i>X</i></b>进行降维,方法如下:</p>
                </div>
                <div class="p1">
                    <p id="70"><b><i>C</i>=<i>X</i>×<i>H</i></b>      (4)</p>
                </div>
                <div class="p1">
                    <p id="71">式中:<b><i>H</i></b>∈<b>R</b><sup><i>n</i>×<i>r</i></sup>,且<b><i>H</i></b>是由独立同分布的高斯随机分布组成,至于<i>r</i>是如何选择的可以参考文献<citation id="143" type="reference">[<a class="sup">13</a>]</citation>。</p>
                </div>
                <div class="p1">
                    <p id="72">第三部分,就是求出<i>X</i>的近似左奇异值矩阵:</p>
                </div>
                <div class="p1">
                    <p id="73"><b><i>U</i>=<i>C</i>×<i>V</i></b>×<i>Σ</i><sup>-1</sup>      (5)</p>
                </div>
                <div class="p1">
                    <p id="74">式中:<b><i>V</i></b>是利用对<b><i>C</i></b><sup>T</sup><b><i>C</i></b>求特征向量获得,<i>Σ</i>是通过对<b><i>C</i></b><sup>T</sup><b><i>C</i></b>求特征值开平方根获得。</p>
                </div>
                <div class="p1">
                    <p id="75">第四部分,对<b><i>X</i></b>进行矩阵填充,或者是低秩近似。因为<b><i>U</i></b>在正常情况下是<b><i>C</i></b>的一个正交矩阵,所以<b><i>UU</i></b><sup>T</sup>=<b><i>I</i></b>,而<b><i>C</i></b>是<b><i>X</i></b>的一个近似矩阵,所以我们以如下方式更新<b><i>X</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="76"><b><i>X</i>≈<i>U</i>×<i>U</i></b><sup>T</sup>×<b><i>X</i></b>      (6)</p>
                </div>
                <div class="p1">
                    <p id="77">第五部分是更新停止的条件的设定,本文采用均方差(mean squared error,MSE)来作为停止条件之一,定义如下:</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>X</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>X</mi><msub><mrow></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="80">当<i>MSE</i>小于或者等于我们设定的阈值时,或者迭代次数达到了我们设定的最大迭代次数时,迭代停止。</p>
                </div>
                <div class="p1">
                    <p id="81">本文的随机投影算法的详细步骤如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="82"><b>算法1</b> 基于随机投影的矩阵填充算法</p>
                </div>
                <div class="p1">
                    <p id="83">输入:带有未知元素的<b><i>X</i></b>矩阵(<b><i>X</i></b>∈<b>R</b><sup><i>m</i>×<i>n</i></sup>),估计的秩<i>r</i>,阈值<i>t</i>,最大迭代次数<i>M</i></p>
                </div>
                <div class="p1">
                    <p id="84">输出:填充后的矩阵<b><i>X</i></b></p>
                </div>
                <div class="p1">
                    <p id="85">初始化:<b><i>X</i></b>中的未知元素都用独立同分布的均值为0方差为1的高斯随机分布赋值</p>
                </div>
                <div class="p1">
                    <p id="86">循环: 迭代次数<i>n</i>=1:<i>M</i></p>
                </div>
                <div class="p1">
                    <p id="87">步骤1 <b><i>C</i>=<i>X</i>×<i>H</i></b>,其中<b><i>H</i></b>∈<b>R</b><sup><i>n</i>×<i>r</i></sup></p>
                </div>
                <div class="p1">
                    <p id="88">i.i.d. <i>N</i>(0,1)</p>
                </div>
                <div class="p1">
                    <p id="89">步骤2 [<b><i>V</i></b>, <i>d</i>]=<i>eig</i>(<b><i>C</i></b><sup>T</sup><b><i>C</i></b>),其中<b><i>V</i></b>是<b><i>C</i></b>的右奇异矩阵,<i>d</i>是<b><i>C</i></b><sup>T</sup><b><i>C</i></b>的特征值组</p>
                </div>
                <div class="p1">
                    <p id="90">步骤3 <b><i>U</i>=<i>C</i>×<i>V</i></b>×<i>Σ</i><sup>-1</sup>,其中</p>
                </div>
                <div class="p1">
                    <p id="91"><i>Σ</i>=diag(diag(<i>d</i>).^ 0.5)</p>
                </div>
                <div class="p1">
                    <p id="92">步骤4 <b><i>X</i>=<i>U</i>×<i>U</i></b><sup>T</sup>×<b><i>X</i></b></p>
                </div>
                <div class="p1">
                    <p id="93">当<i>MSE</i>≤<i>t</i>或者<i>n</i>=<i>M</i>时,迭代结束。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>2.3 复杂度分析</b></h4>
                <div class="p1">
                    <p id="95">算法1中,步骤1的计算复杂度为<i>Ο</i>(<i>mnr</i>),步骤2计算复杂度为<i>Ο</i>(<i>nr</i>+<i>r</i><sup>2</sup>),步骤3 的计算复杂度为<i>Ο</i>(2<i>nr</i><sup><sup>2</sup></sup>),步骤4的计算复杂度为<i>Ο</i>(<i>m</i><sup><sup>2</sup></sup><i>r</i>+<i>m</i><sup><sup>2</sup></sup><i>n</i>),所以本文算法迭代一次的计算复杂度大约为<i>Ο</i>((<i>n</i>+<i>r</i>)<i>m</i><sup><sup>2</sup></sup>+<i>mnr</i>+2<i>nr</i><sup><sup>2</sup></sup>+<i>nr</i>+<i>r</i><sup><sup>2</sup></sup>)。</p>
                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>3 实验分析</b></h3>
                <div class="p1">
                    <p id="97">将本文算法与SVT<citation id="144" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、APG<citation id="145" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和ALM<citation id="146" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>三个经典的算法进行比较,由于精确增广拉格朗日乘子法(Exact Augmented Lagrange Multipliers,EALM)的计算成本较高,所以本文仅对ALM算法中的非精确增广拉格朗日乘子法(Inexact Augmented Lagrange Multipliers,IALM)作比较。实验中,我们假设需要填充的矩阵<b><i>M</i></b>∈<b>R</b><sup><i>m</i>×<i>n</i></sup>,其秩为<i>r</i>=(<i>r</i><sub>1</sub>,<i>r</i><sub>2</sub>),实验的收敛条件为<citation id="147" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mi>i</mi></msup><mo>-</mo><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">V</mi><msup><mrow></mrow><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow><mo>|</mo></mrow></mrow></mfrac><mo>&lt;</mo><mi>ε</mi></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="100">或者是迭代次数达到设置的最大迭代次数。式中<i>V</i><sup><i>i</i></sup>表示我们需要迭代更新的第<i>i</i>个变量,<i>ε</i>表示收敛或者迭代停止的阈值,一般设定为10<sup><sup>-5</sup></sup>,本文中的最大迭代次数设置为100。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>3.1 仿真数据实验</b></h4>
                <div class="p1">
                    <p id="102">本节包含两个部分:第一部分是需要被恢复的矩阵的秩不同的情况下,四个算法的恢复情况;第二部分是在不同采样率下四个算法的恢复情况。对矩阵恢复有重要影响的两个参数为恢复矩阵的秩和采样率。我们用均方差(MSE)和运行时间来作为对矩阵恢复效果的衡量标准。</p>
                </div>
                <div class="p1">
                    <p id="103">第一部分,假设矩阵<b><i>M</i></b>∈<b>R</b><sup>100×100</sup>,在其秩从2递增至20间设计了10组实验,采样率<i>p</i>=0.5。实验结果如图1所示。由图1(a)可知,当矩阵的秩在2～20之间时,FRPMC方法的对矩阵的恢复的效果仅次于ALM算法,但图1(b)中,FRPMC的恢复的速度比ALM快了一倍。在仿真实验中虽然APG和IALM的运行速度相对比较快,但是它们矩阵恢复的相对误差较高,即恢复的精度相对较低。</p>
                </div>
                <div class="p1">
                    <p id="104">第二部分,假设矩阵<b><i>M</i></b>∈<b>R</b><sup>100×100</sup>,矩阵的秩为5,在采样率分别为0.4、0.6、0.8的条件下,用FRPMC、APG、IALM分别对矩阵进行恢复,结果如图2所示。由图2(a)可知,FRPMC方法的精度相对另外的两种算法要高,而且随着采样率的增加,恢复的精度越高,恢复效果越好,即FRPMC在高采样率的情况下,恢复效果比较显著。</p>
                </div>
                <div class="area_img" id="106">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909020_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 不同算法在矩阵的秩不同的情况下矩阵恢复的结果" src="Detail/GetImg?filename=images/JYRJ201909020_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 不同算法在矩阵的秩不同的情况下矩阵恢复的结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909020_10600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909020_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同算法在采样率不同的情况下矩阵恢复的结果" src="Detail/GetImg?filename=images/JYRJ201909020_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同算法在采样率不同的情况下矩阵恢复的结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909020_10800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>3.2 真实数据实验</b></h4>
                <div class="p1">
                    <p id="110">本节主要利用对实际的缺失的黑白图片的恢复来说明FRPMC能够实现图像恢复的功能。因为黑白图片的像素相当于一个二维的矩阵。实验将FRPMC算法与SVT、APG、EALM、IALM进行比较,并用峰值信噪比(Peak Signal-to-Noise Ratio,PSNR)<sup><a class="sup">[17]</a></sup>作为衡量图像恢复的效果的完整性的标准,定义如下:</p>
                </div>
                <div class="p1">
                    <p id="111"><mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>Ρ</mtext><mtext>S</mtext><mtext>Ν</mtext><mtext>R</mtext><mo>=</mo><mn>1</mn><mn>0</mn><mrow><mi>lg</mi></mrow><msub><mrow></mrow><mrow><mn>1</mn><mn>0</mn><mspace width="0.25em" /></mrow></msub><mrow><mo>(</mo><mrow><mfrac><mrow><mi>n</mi><mo>×</mo><mi>m</mi><mo>×</mo><mrow><mo>|</mo><mi mathvariant="bold-italic">Μ</mi><mo>|</mo></mrow><msubsup><mrow></mrow><mi>∞</mi><mn>2</mn></msubsup></mrow><mrow><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">X</mi><mo>-</mo><mi mathvariant="bold-italic">Μ</mi></mrow><mo>|</mo></mrow><msubsup><mrow></mrow><mi>F</mi><mn>2</mn></msubsup></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="113">式中:<b><i>M</i></b>∈<b>R</b><sup><i>m</i>×<i>n</i></sup>,是需要恢复的矩阵(带有缺失值的矩阵),<b><i>X</i></b>是<b><i>M</i></b>恢复后的矩阵,<mathml id="114"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">Μ</mi><mo>|</mo></mrow><msub><mrow></mrow><mi>∞</mi></msub></mrow></math></mathml>表示<b><i>M</i></b>绝对值的最大值,<mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi mathvariant="bold-italic">Μ</mi><mo>|</mo></mrow><msub><mrow></mrow><mtext>F</mtext></msub></mrow></math></mathml>表示<b><i>M</i></b>的F范数,相当于<b><i>M</i></b>的各项元素的绝对值平方的总和。</p>
                </div>
                <div class="p1">
                    <p id="116">图3中的6幅图是分别在不同随机采样下生成的,采样率从左至右分别是0.3、0.4、0.5、0.6、0.7、0.8。图4的6幅图则是图3中相对应的用FRPMC算法恢复后的图像。图4(a)是采样率为0.3的情况下恢复后的图像,从图中可以清晰地看到房子的轮廓窗、房子在水中的倒影,说明FPRMC方法能够有效恢复带有丢失数据的图像。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909020_11700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 被噪声污染后的图像" src="Detail/GetImg?filename=images/JYRJ201909020_11700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 被噪声污染后的图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909020_11700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="118">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909020_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 经过FRPMC处理后与图3相对应的恢复后的图像" src="Detail/GetImg?filename=images/JYRJ201909020_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 经过FRPMC处理后与图3相对应的恢复后的图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909020_11800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="119">接下来,随机抽取来自Berkeley Segmentation数据集中的50幅图来进行实验。首先把这50幅彩图进行灰度化,使其变成黑白图片,再进行实验。</p>
                </div>
                <div class="p1">
                    <p id="120">对这50幅处理后的黑白图片进行随机采样,采样率分别是0.3、0.4、0.5、0.6、0.7、0.8,分别用FRPMC、SVT、APG和IALM四种方法进行实验。实验假设最大迭代次数为100。实验结果如表1和表2所示。</p>
                </div>
                <div class="area_img" id="121">
                    <p class="img_tit"><b>表1 在不同采样率下四个算法的PSNR值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="121" border="1"><tr><td><br />P</td><td>FPRMC</td><td>SVT</td><td>APG</td><td>IALM</td></tr><tr><td><br />0.3</td><td><b>24.60</b></td><td>23.82</td><td>23.91</td><td>8.44</td></tr><tr><td><br />0.4</td><td><b>26.73</b></td><td>25.31</td><td>25.38</td><td>9.11</td></tr><tr><td><br />0.5</td><td><b>28.28</b></td><td>26.61</td><td>26.68</td><td>9.91</td></tr><tr><td><br />0.6</td><td><b>29.88</b></td><td>27.85</td><td>27.89</td><td>10.88</td></tr><tr><td><br />0.7</td><td><b>31.72</b></td><td>29.05</td><td>29.04</td><td>12.12</td></tr><tr><td><br />0.8</td><td><b>34.13</b></td><td>30.23</td><td>30.15</td><td>13.89</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="122">
                    <p class="img_tit"><b>表2 在不同采样率下四个算法的运行时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="122" border="1"><tr><td><br />P</td><td>FPRMC</td><td>SVT</td><td>APG</td><td>IALM</td></tr><tr><td><br />0.3</td><td><b>1.04</b></td><td>7.49</td><td>4.58</td><td>3.55</td></tr><tr><td><br />0.4</td><td><b>1.08</b></td><td>7.69</td><td>3.98</td><td>2.97</td></tr><tr><td><br />0.5</td><td><b>1.09</b></td><td>7.38</td><td>3.55</td><td>2.83</td></tr><tr><td><br />0.6</td><td><b>0.96</b></td><td>7.55</td><td>3.13</td><td>2.97</td></tr><tr><td><br />0.7</td><td><b>0.90</b></td><td>7.49</td><td>2.80</td><td>3.16</td></tr><tr><td><br />0.8</td><td><b>0.80</b></td><td>7.47</td><td>2.46</td><td>3.22</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="123">由表1可知,在图像的尺寸为512×512的情况下,即FPRMC算法对黑白图像恢复的PSNR是最高的,即效果最好的。由表2可知,FRPMC算法在实际图像恢复中的速度也是最快的。</p>
                </div>
                <div class="p1">
                    <p id="124">图5为在采样率为0.7的实验中随机选取的5幅图的实验情况。表3是图5中对应的5幅图的恢复结果,分别是PSNR值和各个算法对应的运行时间。</p>
                </div>
                <div class="area_img" id="125">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909020_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 随机选取5幅图的实验情况" src="Detail/GetImg?filename=images/JYRJ201909020_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 随机选取5幅图的实验情况  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909020_12500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="127">
                    <p class="img_tit"><b>表3 图5中5幅图相对应的PSNR值和对应算法的运行时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td rowspan="2"><br />图<br />片</td><td colspan="2"><br />FRPMC</td><td colspan="2">SVT</td><td colspan="2">APG</td><td colspan="2">IALM</td></tr><tr><td><br />PSNR</td><td>time</td><td>PSNR</td><td>time</td><td>PSNR</td><td>time</td><td>PSNR</td><td>time</td></tr><tr><td><br />1</td><td><b>39.6</b></td><td>0.9</td><td>32.2</td><td>7.7</td><td>32.3</td><td>2.3</td><td>14.5</td><td>3.3</td></tr><tr><td><br />2</td><td><b>38.4</b></td><td>0.9</td><td>29.8</td><td>7.5</td><td>30.0</td><td>2.3</td><td>8.9</td><td>3.0</td></tr><tr><td><br />3</td><td><b>37.7</b></td><td>0.9</td><td>31.8</td><td>7.4</td><td>32.0</td><td>2.6</td><td>17.1</td><td>3.0</td></tr><tr><td><br />4</td><td><b>39.9</b></td><td>0.9</td><td>33.6</td><td>7.2</td><td>33.0</td><td>2.5</td><td>18.2</td><td>3.4</td></tr><tr><td><br />5</td><td><b>37.5</b></td><td>0.9</td><td>31.7</td><td>8.0</td><td>31.9</td><td>2.7</td><td>9.4</td><td>3.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="128" name="128" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="129">传统的矩阵填充方法很难避免标准的SVD的计算操作,而随着矩阵维度的增加,SVD操作的计算复杂度呈指数增加,不适用于大规模、高维和高阶的矩阵的处理。如何设计可扩展的快速的算法是矩阵填充算法研究的核心。为了解决这个问题,本文提出了一种快速的随机投影方法,相对比于一般传统的算法。FRPMC算法主要是利用随机投影的方法对经过随机初试化的矩阵(带有缺失值)进行降维,然后再对其进行特征值和特征向量的计算,利用SVD的计算模型来设计了一个矩阵的低秩近似的模型,对矩阵进行恢复,大大减少了计算的成本。</p>
                </div>
                <div class="p1">
                    <p id="130">在今后的矩阵填充算法研究中,还将关注以下几个方面:(1) 在确保精度的情况下,提高矩阵填充的速度;(2) 设计适合不同应用场景的矩阵填充的模型;(3) 将矩阵填充扩展到高维数组中,例如张量填充问题上;(4) 研究可以利用已知元素来确定或者估计矩阵的秩的方法。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fast maximum margin matrix factorization for collaborative prediction">

                                <b>[1]</b> Rennie D M,Srebro N.Fast Maximum Margin Matrix Factorization for Collaborative Prediction[C]//Proceedings of International Conference on Machine Learning(ICML).2005:713-719.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Matrix completion for multi-label image classification">

                                <b>[2]</b> Canral R S,Torre F D,Costcira J P,et al.Matrix Completion for Multi-Lable Image Classification[C]//Proceedings of Neural Information Processing Systems(NIPS).2011:190-128.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD15092500000107&amp;v=MzI3NDIvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlWb1JhUk09TmlmY2FySzlIdGpPcW85RlpPc1BEWHcrb0JNVDZUNFBRSA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Li W,Zhao L,Lin Z J,et al.Non-Local Image Inpainting using Low-Rank Matrix Completion[J].Computer Graphics Forum,2015,34(6):111-122.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Low‐rank plus sparse matrix decomposition for accelerated dynamic MRI with separation of background and dynamic components">

                                <b>[4]</b> Otazo R,Candes E,Sodickson D K.Low-Rank Plus Sparse Matrix Decomposition for Accelerated Dynamic MRI with Separation of Background and Dynamic Components[J].Magnetic Resonance in Medicine,2015,73(3):1125-1136.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES21670C13A700354B6D35AFF67AE3AA83&amp;v=MjIwMDVld1BESDg4eTJRVm5qeDRPUW1VcWhWRURMSGxOTEtjQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJ5Nnc2az1OaWZPZmJHNUdOYk0zSTVHRg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Gogn A,Majumdar A.Matrix Completion Incorporating Auxiliary Information for Recommender System Design[J].Expert System with Applications,2015,42(12):5789-5799.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Signal recovery by proximal forward-backward splitting">

                                <b>[6]</b> Combettes P L,Wajs V R.Signal Recovery by Proximal Forward-Backward Splitting[J].Multiscale Modeling and Simulation,2004,4(4):1168-1200.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=On the convergence of block coordinate descent methods">

                                <b>[7]</b> Beck A,Tetruashvili L.On the Convergence of Block Coordinate Descent Methods[J].SIAM Journal on Optimization,2013,23(4):2037-2060.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relaxation Method for Finding a Common Point of Convex Sets and Its Application to Optimization Problems">

                                <b>[8]</b> Bregman L M.Relaxation Method for Finding a Common Point of Convex Sets and Its Application to Optimization Problems[J].Doklady Akademii nauk SSSR,1966,171(5):1019-1022.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14021300033900&amp;v=MTEyOTZIdFBOckk5RlpPZ01CWHc1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSVZvUmFSTT1OaWZPZmJLOA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Tan H,Cheng B,Wang W,et al.Tensor Completion Via a Multi-linear Low-n-rank Factorization Model[J].Neurocomputing,2014,133:161-169.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fixed point and Bregman iterative methods for matrix rank minimization">

                                <b>[10]</b> Ma S,Goldfarb D,Chen L.Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization[J].Mathematical Programming,2009,128(1-2):321-353.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A singular value thresholding algorithm for matrix completion">

                                <b>[11]</b> Cai J F,Candès E J,Shen Z.A Singular Value Thresholding Algorithm for Matrix Completion[J].SIAM Journal on Optimization,2010,20(4):1956-1982.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems">

                                <b>[12]</b> Toh K C,Yun S.An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Least Squares Problems[J].Pacific Journal of Optimization,2010,6(3):615-640.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting the Number of Clusters in n-Way Probabilistic Clustering">

                                <b>[13]</b> He Z S,Cichocki A,Xie S L,et al.Detecting the Number of Clusters in N-way Probabilistic Clustering[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence,2010,32(11):2006-2021.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices">

                                <b>[14]</b> Lin Z C,Chen M M,Ma Y,et al.The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices [EB/OL].arXiv:1009.5055,2010.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Tensor Factorization for Low-Rank Tensor Completion">

                                <b>[15]</b> Zhou P,Lu C,Lin Z,et al.Tensor Factorization for Low-Rank Tensor Completion[J].IEEE Transactions on Image Processing,2018,27(3):1152-1163.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201909020" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909020&amp;v=MjIwOTZaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5oVnJ6Skx6VFpaTEc0SDlqTXBvOUg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
