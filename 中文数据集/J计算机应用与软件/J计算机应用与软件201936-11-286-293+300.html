<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134081924162500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201911047%26RESULT%3d1%26SIGN%3dKbNCGijC%252bxKVwPDPv%252fng5azksMU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911047&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911047&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911047&amp;v=MDY3MjVMRzRIOWpOcm85Qlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hWTDNPTHpUWlo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#46" data-title="&lt;b&gt;1 研究动机和背景&lt;/b&gt; "><b>1 研究动机和背景</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#58" data-title="&lt;b&gt;2 改进的相似性度量指标&lt;/b&gt; "><b>2 改进的相似性度量指标</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#59" data-title="&lt;b&gt;2.1 修改的相似性度量&lt;/b&gt;"><b>2.1 修改的相似性度量</b></a></li>
                                                <li><a href="#72" data-title="&lt;b&gt;2.2 改进的相似性度量&lt;/b&gt;"><b>2.2 改进的相似性度量</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#79" data-title="&lt;b&gt;3 自编码器和协同过滤问题&lt;/b&gt; "><b>3 自编码器和协同过滤问题</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#80" data-title="&lt;b&gt;3.1 自编码器模型&lt;/b&gt;"><b>3.1 自编码器模型</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;3.2 基于自编码器的协同过滤问题&lt;/b&gt;"><b>3.2 基于自编码器的协同过滤问题</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="&lt;b&gt;4 深度神经网络的总体结构&lt;/b&gt; "><b>4 深度神经网络的总体结构</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#91" data-title="&lt;b&gt;4.1 UNet深度神经网络&lt;/b&gt;"><b>4.1 UNet深度神经网络</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;4.2 INet深度神经网络&lt;/b&gt;"><b>4.2 INet深度神经网络</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;4.3 学习算法&lt;/b&gt;"><b>4.3 学习算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="&lt;b&gt;5 仿真实验和结果分析&lt;/b&gt; "><b>5 仿真实验和结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#133" data-title="&lt;b&gt;5.1 实验环境和方法&lt;/b&gt;"><b>5.1 实验环境和方法</b></a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;5.2 实验分析&lt;/b&gt;"><b>5.2 实验分析</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;5.3 超参数的设置&lt;/b&gt;"><b>5.3 超参数的设置</b></a></li>
                                                <li><a href="#171" data-title="&lt;b&gt;5.4 对比实验分析&lt;/b&gt;"><b>5.4 对比实验分析</b></a></li>
                                                <li><a href="#181" data-title="&lt;b&gt;5.5 算法的时间效率&lt;/b&gt;"><b>5.5 算法的时间效率</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#186" data-title="&lt;b&gt;6 结 语&lt;/b&gt; "><b>6 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="&lt;b&gt;表1 目标用户U1不同近邻的非共同评分项数&lt;/b&gt;"><b>表1 目标用户U1不同近邻的非共同评分项数</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;表2 目标用户U1关于不同近邻的非共同评分项数&lt;/b&gt;"><b>表2 目标用户U1关于不同近邻的非共同评分项数</b></a></li>
                                                <li><a href="#61" data-title="图1 评分项&lt;i&gt;I&lt;/i&gt;&lt;sub&gt;&lt;i&gt;u&lt;/i&gt;&lt;/sub&gt;和&lt;i&gt;I&lt;/i&gt;&lt;sub&gt;&lt;i&gt;v&lt;/i&gt;&lt;/sub&gt;的关系示意图">图1 评分项<i>I</i><sub><i>u</i></sub>和<i>I</i><sub><i>v</i></sub>的关系示意图</a></li>
                                                <li><a href="#90" data-title="图2 基于自编码器的协同过滤框架">图2 基于自编码器的协同过滤框架</a></li>
                                                <li><a href="#135" data-title="&lt;b&gt;表3 实验数据集的基本信息&lt;/b&gt;"><b>表3 实验数据集的基本信息</b></a></li>
                                                <li><a href="#252" data-title="图3 改进点验证实验的结果">图3 改进点验证实验的结果</a></li>
                                                <li><a href="#253" data-title="图4 神经网络超参数的微调实验">图4 神经网络超参数的微调实验</a></li>
                                                <li><a href="#253" data-title="图4 神经网络超参数的微调实验">图4 神经网络超参数的微调实验</a></li>
                                                <li><a href="#170" data-title="图5 超参数α的微调实验">图5 超参数α的微调实验</a></li>
                                                <li><a href="#254" data-title="图6 对比实验的结果">图6 对比实验的结果</a></li>
                                                <li><a href="#183" data-title="&lt;b&gt;表4 实验数据集的训练时间 &lt;/b&gt;"><b>表4 实验数据集的训练时间 </b></a></li>
                                                <li><a href="#185" data-title="图7 推荐系统的平均响应时间">图7 推荐系统的平均响应时间</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="255">


                                    <a id="bibliography_1" title=" 董立岩,王越群,贺嘉楠,等.基于时间衰减的协同过滤推荐算法[J].吉林大学学报(工),2017,47(4):1268-1272." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201704036&amp;v=MTEzOTgzQkx5SE1kN0c0SDliTXE0OUdZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         董立岩,王越群,贺嘉楠,等.基于时间衰减的协同过滤推荐算法[J].吉林大学学报(工),2017,47(4):1268-1272.
                                    </a>
                                </li>
                                <li id="257">


                                    <a id="bibliography_2" title=" 毛宜钰,刘建勋,胡蓉,等.基于Logistic函数和用户聚类的协同过滤算法[J].浙江大学学报(工学版),2017,51(6):1252-1258." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201706024&amp;v=MDM3MzhRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFZMM0JQeW5SYmJHNEg5Yk1xWTlIWUk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         毛宜钰,刘建勋,胡蓉,等.基于Logistic函数和用户聚类的协同过滤算法[J].浙江大学学报(工学版),2017,51(6):1252-1258.
                                    </a>
                                </li>
                                <li id="259">


                                    <a id="bibliography_3" title=" 杨晋吉,胡波,王欣明,等.一种知识图谱的排序学习个性化推荐算法[J].小型微型计算机系统,2018,39(11):69-73." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201811015&amp;v=Mjc1MjZPZVplVnVGeS9oVkwzQlBUWGNkckc0SDluTnJvOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkw=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         杨晋吉,胡波,王欣明,等.一种知识图谱的排序学习个性化推荐算法[J].小型微型计算机系统,2018,39(11):69-73.
                                    </a>
                                </li>
                                <li id="261">


                                    <a id="bibliography_4" title=" Chen Y,Li X,Liu J,et al.Recommendation system for adaptive learning[J].Applied Psychological Measurement,2017,42(23):24-41." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Recommendation system for adaptive learning">
                                        <b>[4]</b>
                                         Chen Y,Li X,Liu J,et al.Recommendation system for adaptive learning[J].Applied Psychological Measurement,2017,42(23):24-41.
                                    </a>
                                </li>
                                <li id="263">


                                    <a id="bibliography_5" title=" Wei J ,He J ,Chen K ,et al.Collaborative filtering and deep learning based recommendation system for cold start items[J].Expert Systems with Applications,2017,69:29-39." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Collaborative filtering and deep learning based recommendation system for cold start items">
                                        <b>[5]</b>
                                         Wei J ,He J ,Chen K ,et al.Collaborative filtering and deep learning based recommendation system for cold start items[J].Expert Systems with Applications,2017,69:29-39.
                                    </a>
                                </li>
                                <li id="265">


                                    <a id="bibliography_6" title=" Christakopoulou E,Karypis G.Local item-item models for top-N recommendation[C]// Proceedings of the 10th ACM Conference on Recommender Systems.ACM,2016:67-74." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Local Item-Item Models for Top-N Recommen-dation">
                                        <b>[6]</b>
                                         Christakopoulou E,Karypis G.Local item-item models for top-N recommendation[C]// Proceedings of the 10th ACM Conference on Recommender Systems.ACM,2016:67-74.
                                    </a>
                                </li>
                                <li id="267">


                                    <a id="bibliography_7" title=" Jannach D,Ludewig M.When recurrent neural networks meet the neighborhood for session-based recommendation[C]// Proceedings of the Eleventh ACM Conference on Recommender Systems.ACM,2017:306-310." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation">
                                        <b>[7]</b>
                                         Jannach D,Ludewig M.When recurrent neural networks meet the neighborhood for session-based recommendation[C]// Proceedings of the Eleventh ACM Conference on Recommender Systems.ACM,2017:306-310.
                                    </a>
                                </li>
                                <li id="269">


                                    <a id="bibliography_8" title=" Wang J F,Li X,Wu W Q,et al.An algorithm of collaborative filtering based on SVD and trust factors[J].Journal of Chinese Computer Systems,2017,38(6):1290-1293." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201706022&amp;v=MDg3NTlCUFRYY2RyRzRIOWJNcVk5SFpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hWTDM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Wang J F,Li X,Wu W Q,et al.An algorithm of collaborative filtering based on SVD and trust factors[J].Journal of Chinese Computer Systems,2017,38(6):1290-1293.
                                    </a>
                                </li>
                                <li id="271">


                                    <a id="bibliography_9" title=" Li G,Zhang Z,Wang L,et al.One-class collaborative filtering based on rating prediction and ranking prediction[J].Knowledge-Based Systems,2017,45(12):3070-3075." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES27FE0C834555E6B3A36A9566945D5CFA&amp;v=MjA3MjR2UlZpNlRrTVFYcmtxaHN4Zk1hUk5zenVDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZDcGJRMzVkaGh3N3k0d3FFPU5pZk9mYkcvYUtUTTNJZEdZTzRLQ1FrLw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Li G,Zhang Z,Wang L,et al.One-class collaborative filtering based on rating prediction and ranking prediction[J].Knowledge-Based Systems,2017,45(12):3070-3075.
                                    </a>
                                </li>
                                <li id="273">


                                    <a id="bibliography_10" title=" Suzuki Y,Ozaki T.Stacked denoising autoencoder-based deep collaborative filtering using the change of similarity[C]// International Conference on Advanced Information Networking and Applications Workshops.2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stacked Denoising Autoencoder-Based Deep Collaborative Filtering Using the Change of Similarity">
                                        <b>[10]</b>
                                         Suzuki Y,Ozaki T.Stacked denoising autoencoder-based deep collaborative filtering using the change of similarity[C]// International Conference on Advanced Information Networking and Applications Workshops.2017.
                                    </a>
                                </li>
                                <li id="275">


                                    <a id="bibliography_11" title=" Yu L,Shuai W,M.Shahrukh Khan,et al.A novel deep hybrid recommender system based on auto-encoder with neural collaborative filtering[J].Big Data Mining &amp;amp; Analytics,2018,1(3):211-221." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BDMA201803003&amp;v=MjMyMjhIOW5Nckk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hWTDNCSnluR2I3RzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Yu L,Shuai W,M.Shahrukh Khan,et al.A novel deep hybrid recommender system based on auto-encoder with neural collaborative filtering[J].Big Data Mining &amp;amp; Analytics,2018,1(3):211-221.
                                    </a>
                                </li>
                                <li id="277">


                                    <a id="bibliography_12" title=" 杨家慧,刘方爱.基于巴氏系数和Jaccard系数的协同过滤算法[J].计算机应用,2016,36(7):2006-2010." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201607048&amp;v=MDQxMjVMT2VaZVZ1RnkvaFZMM0JMejdCZDdHNEg5Zk1xSTlCYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         杨家慧,刘方爱.基于巴氏系数和Jaccard系数的协同过滤算法[J].计算机应用,2016,36(7):2006-2010.
                                    </a>
                                </li>
                                <li id="279">


                                    <a id="bibliography_13" title=" 刘帆,吴小俊.基于混合核平滑自编码器的分类器设计[J].计算机应用与软件,2017,34(12):246-250." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201712046&amp;v=MzExNzA1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFZMM0JMelRaWkxHNEg5Yk5yWTlCWW9RS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         刘帆,吴小俊.基于混合核平滑自编码器的分类器设计[J].计算机应用与软件,2017,34(12):246-250.
                                    </a>
                                </li>
                                <li id="281">


                                    <a id="bibliography_14" title=" Ketkar N.Stochastic gradient descent[M]// Deep Learning with Python.2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Stochastic Gradient Descent">
                                        <b>[14]</b>
                                         Ketkar N.Stochastic gradient descent[M]// Deep Learning with Python.2017.
                                    </a>
                                </li>
                                <li id="283">


                                    <a id="bibliography_15" title=" Liu Y,Xu L,Li M.The parallelization of back propagation neural network in MapReduce and spark[J].International Journal of Parallel Programming,2017,45(4):1-20." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The parallelization of back propagation neural network in MapReduce and Spark">
                                        <b>[15]</b>
                                         Liu Y,Xu L,Li M.The parallelization of back propagation neural network in MapReduce and spark[J].International Journal of Parallel Programming,2017,45(4):1-20.
                                    </a>
                                </li>
                                <li id="285">


                                    <a id="bibliography_16" title=" Rouse R,Hunt S,Stubbings R.CIAO-Collaborative institutional assessment of open access(pilot version)[J].Biochemistry,2014,5(6):2049-2061." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CIAO-Collaborative institutional assessment of open access(pilot version)">
                                        <b>[16]</b>
                                         Rouse R,Hunt S,Stubbings R.CIAO-Collaborative institutional assessment of open access(pilot version)[J].Biochemistry,2014,5(6):2049-2061.
                                    </a>
                                </li>
                                <li id="287">


                                    <a id="bibliography_17" title=" Pan W ,Chen L.GBPR:group preference based Bayesian personalized ranking for one-class collaborative filtering[C]// Proceedings of the Twenty-Third international joint conference on Artificial Intelligence.2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Gbpr:Group preference based bayesian personal-ized ranking for one-class collaborative filtering">
                                        <b>[17]</b>
                                         Pan W ,Chen L.GBPR:group preference based Bayesian personalized ranking for one-class collaborative filtering[C]// Proceedings of the Twenty-Third international joint conference on Artificial Intelligence.2013.
                                    </a>
                                </li>
                                <li id="289">


                                    <a id="bibliography_18" title=" Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[C]//Proceedings of the thirteenth international conference on artificial intelligence and statistics.2010:249-256." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Understanding the difficulty of training deep feedforward neural networks">
                                        <b>[18]</b>
                                         Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[C]//Proceedings of the thirteenth international conference on artificial intelligence and statistics.2010:249-256.
                                    </a>
                                </li>
                                <li id="291">


                                    <a id="bibliography_19" title=" Kabbur S ,Karypis G.FISM :Factored item similarity models for top-N recommender systems[C]// Acm Sigkdd International Conference on Knowledge Discovery &amp;amp; Data Mining.ACM,2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=FISM:factored item similarity models for top-N recommender systems">
                                        <b>[19]</b>
                                         Kabbur S ,Karypis G.FISM :Factored item similarity models for top-N recommender systems[C]// Acm Sigkdd International Conference on Knowledge Discovery &amp;amp; Data Mining.ACM,2013.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(11),286-293+300 DOI:10.3969/j.issn.1000-386x.2019.11.046            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于深度神经网络和改进相似性度量的推荐算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B9%E9%94%8B&amp;code=43235607&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邹锋</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B9%BF%E5%B7%9E%E5%95%86%E5%AD%A6%E9%99%A2%E4%BF%A1%E6%81%AF%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1699550&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">广州商学院信息技术与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>为了提高协同过滤推荐系统对于稀疏数据的推荐效果,提出一种基于深度神经网络和改进相似性度量的推荐算法。分析普通Jaccard相似性度量指标处理稀疏数据集的不足之处,对Jaccard相似性提出改进方案。设计交互的两个自编码器,一个自编码器利用显式反馈数据分析用户对于项目的偏好,其优化目标为最小化重建误差和正则成对排列损失;另一个自编码器利用隐式反馈数据分析用户对于项目的潜在偏好,其学习目标是采样数据集的负项集,利用隐式反馈数据增强显式反馈自编码器的学习效果。基于不同规模稀疏数据集的实验结果显示,该算法有效地增强了稀疏数据集的推荐准确率,实现了合理的推荐效率。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">协同过滤;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">推荐系统;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">相似性度量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自编码器;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%98%BE%E5%BC%8F%E5%8F%8D%E9%A6%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">显式反馈;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    邹锋，讲师，主研领域:计算机软件和应用。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-05-31</p>

            </div>
                    <h1><b>A RECOMMENDATION ALGORITHM BASED ON DEEP NEURAL NETWORKS AND IMPROVED SIMILARITY MEASUREMENT</b></h1>
                    <h2>
                    <span>Zou Feng</span>
            </h2>
                    <h2>
                    <span>School of Information Technology and Engineering, Guangzhou College of Commerce</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In order to improve the recommendation effect of collaborative filtering recommender system on sparse datasets, this paper proposes a recommendation algorithm based on deep neural networks and improved similarity measurement. I analyzed the disadvantages of normal Jaccard similarity measurement when it was applied to sparse datasets, and I provided the improvement schema for Jaccard similarity. Two interactive auto encoders were designed. One auto encoder adopted explicit feedback data to analyze preferences of users. The optimization objectives were minimization of reconstruction error and pairwise ranking loss. The other one took advantages of implicit feedback data to analyze potential preferences of users. The learning objective was to collect the negative samples. The implicit feedback data was used to enhance the learning effects of explicit feedback auto encoder. Based on different scales of sparse datasets, experimental results indicate that the proposed algorithm effectively enhances the recommendation accuracy of sparse datasets, and realizes the reasonable recommendation efficiency.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Collaborative%20filtering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Collaborative filtering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Recommendation%20system&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Recommendation system;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Similarity%20measurement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Similarity measurement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Auto%20encoder&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Auto encoder;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Explicit%20feedback&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Explicit feedback;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-05-31</p>
                            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="42">随着网络信息量的爆炸式增长,大数据挖掘成为了一个挑战,推荐系统作为大数据挖掘的一个重要分支成为目前的研究热点。协同过滤<citation id="293" type="reference"><link href="255" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>是推荐系统中最为有效且易于实现的方案,被广泛应用于大型门户网站、电子商务网站及新闻门户网站等。协同过滤系统依赖用户的评分信息,且需要分析隐式信息来提取用户的兴趣,导致其对稀疏数据的性能不理想<citation id="294" type="reference"><link href="257" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="43">当前的top-N推荐系统可分为两个类型:基于优化的方式和基于数据类型的方式<citation id="295" type="reference"><link href="259" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。基于优化方式的目标是最小化预测评分的均方误差,或者最大化每对用户偏好的相似性<citation id="296" type="reference"><link href="261" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。基于数据类型的方式使用评分系统的显式反馈信息或者隐式反馈信息<citation id="297" type="reference"><link href="263" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。文献<citation id="298" type="reference">[<a class="sup">6</a>]</citation>提出了一种简单的个人化推荐算法,直接将项目按受欢迎度降序排列,为用户提供top-N的相似项目列表。文献<citation id="299" type="reference">[<a class="sup">7</a>]</citation>是一种基于用户-项目偏差项的协同过滤推荐系统,该系统利用递归神经网络学习用户-项目的偏差信息,结构简单且效率较高。文献<citation id="300" type="reference">[<a class="sup">8</a>]</citation>利用奇异值分解处理用户评分矩阵,引入信任信息的隐式信息来缓解冷启动问题,在推荐准确率和效率之间取得了平衡。文献<citation id="301" type="reference">[<a class="sup">9</a>]</citation>是一种经典的“扩展少即是好”协同过滤模型,该模型直接最大化平均Reciprocal Rank指标来训练预测模型。上述文献利用不同的评估准则和学习方式实现了对用户兴趣的预测,但对于稀疏数据依然未达到理想的性能。</p>
                </div>
                <div class="p1">
                    <p id="44">随着深度学习技术的出现,许多研究人员利用深度学习拟合能力强、表征能力强的优点,结合某些判断准则预测用户的兴趣。文献<citation id="302" type="reference">[<a class="sup">10</a>]</citation>将变化相似性作为学习的目标,采用栈式降噪自编码器作为深度学习模型,实现了单模型、单学习准则的协同过滤推荐系统。文献<citation id="303" type="reference">[<a class="sup">11</a>]</citation>同时考虑了显式反馈信息和隐式反馈信息,以单自编码器学习用户的显式和隐式信息,实现了较好的推荐效果。根据文献<citation id="304" type="reference">[<a class="sup">10</a>,<a class="sup">11</a>]</citation>的实验结果和分析,深度学习技术能够有效地提高协同过滤系统的预测准确率,但对于稀疏数据的推荐效果依然不理想。</p>
                </div>
                <div class="p1">
                    <p id="45">本文采用自编码器作为深度学习模型,以期提高协同过滤推荐系统的推荐效果。为了提高对稀疏数据的推荐效果,本文有两个主要贡献:改进了相似性评价指标,对Jaccard相似性做修改,提高稀疏数据的相似性评估准确率;提出了显式反馈自编码器和隐式反馈自编码器,两个自编码器交互学习数据的显式关系和隐式关系。基于4个不同规模的公开稀疏数据集分别进行实验,结果验证了本文算法的有效性。</p>
                </div>
                <h3 id="46" name="46" class="anchor-tag"><b>1 研究动机和背景</b></h3>
                <div class="p1">
                    <p id="47">目前主流推荐系统所采用的相似性度量方案主要存在以下4点不足之处:</p>
                </div>
                <div class="p1">
                    <p id="48">① 设<i>U</i><sub>1</sub>=(2,0,3,0)和<i>U</i><sub>2</sub>=(5,2,0,2)是两个用户的评分向量。<i>U</i><sub>1</sub>和<i>U</i><sub>2</sub>间存在一个共同评分项,<i>U</i><sub>1</sub>和<i>U</i><sub>2</sub>皮尔森相关系数的分母为0,所以无法计算两者的皮尔森相关系数。而<i>U</i><sub>1</sub>和<i>U</i><sub>2</sub>的余弦相似性为100%。</p>
                </div>
                <div class="p1">
                    <p id="49">② 设<i>U</i><sub>1</sub>=(2,1,3,2)和<i>U</i><sub>2</sub>=(1,2,2,3)是两个用户的评分向量。<i>U</i><sub>1</sub>和<i>U</i><sub>2</sub>的皮尔森相关系数为0。</p>
                </div>
                <div class="p1">
                    <p id="50">③ 设<i>U</i><sub>1</sub>=(2,2,0,1)和<i>U</i><sub>2</sub>=(4,4,0,2)是两个用户的评分向量。<i>U</i><sub>1</sub>和<i>U</i><sub>2</sub>的余弦相似性为1,如果两个用户的评分成倍数关系,两者的余弦相似性一般很高。</p>
                </div>
                <div class="p1">
                    <p id="51">④ 设<i>U</i><sub>1</sub>=(5,5,4,3)和<i>U</i><sub>2</sub>=(1,2,2,1)是两个用户的评分向量。Jaccard指数的总体相反相似性指数为1,但<i>U</i><sub>1</sub>和<i>U</i><sub>2</sub>的实际相似性极低。Jaccard仅关注于共同评分项目,忽略了许多相似性信息。</p>
                </div>
                <div class="p1">
                    <p id="52">传统的推荐系统通过共同评分的项目决定相似性,由此识别出最近邻居。协同过滤系统的思想是利用最近邻用户的评分预测未评分项的评分,但在许多情况下协同过滤的思想并不适用,例如:某个高度相似的用户仅仅对共同评分项进行了评分,此情况的相似用户对预测评分的价值较小。</p>
                </div>
                <div class="p1">
                    <p id="53">表1是1个用户-项目评分矩阵的案例,解释了Jaccard相似性的不足之处,符号“-”表示未评分。表1显示了不同近邻对于目标用户<i>U</i><sub>1</sub>的非共同评分项的数量。其中:<i>U</i><sub>1</sub>和用户<i>U</i><sub>2</sub>、<i>U</i><sub>3</sub>、<i>U</i><sub>4</sub>均高度相似,但<i>U</i><sub>2</sub>、<i>U</i><sub>3</sub>、<i>U</i><sub>4</sub>的非共同评分项数为0,所以这3个近邻用户对于<i>U</i><sub>1</sub>的<i>I</i><sub>2</sub>和<i>I</i><sub>5</sub>预测没有作用;用户<i>U</i><sub>5</sub>、<i>U</i><sub>6</sub>和<i>U</i><sub>1</sub>的相似性较低,而<i>U</i><sub>5</sub>和<i>U</i><sub>6</sub>对于<i>I</i><sub>2</sub>和<i>I</i><sub>5</sub>评分,所以这两个用户对于<i>U</i><sub>1</sub>的评分预测具有作用。该实例说明近邻用户的非共同评分项数量与相似性信息成比例关系,即<mathml id="189"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mspace width="0.25em" /><mi>v</mi><mo stretchy="false">)</mo><mo>∝</mo><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mover accent="true"><mi>Ι</mi><mo stretchy="true">¯</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">)</mo></mrow></math></mathml>。</p>
                </div>
                <div class="area_img" id="54">
                    <p class="img_tit"><b>表1 目标用户U1不同近邻的非共同评分项数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="54" border="1"><tr><td><br /></td><td><i>I</i><sub>1</sub></td><td><i>I</i><sub>2</sub></td><td><i>I</i><sub>3</sub></td><td><i>I</i><sub>4</sub></td><td><i>I</i><sub>5</sub></td><td><i>I</i><sub>6</sub></td><td><i>I</i><sub>7</sub></td><td><i>I</i><sub>8</sub></td></tr><tr><td><br /><i>U</i><sub>1</sub></td><td>3</td><td>*</td><td>4</td><td>2</td><td>*</td><td>5</td><td>1</td><td>1</td></tr><tr><td><br /><i>U</i><sub>2</sub></td><td>3</td><td>-</td><td>-</td><td>2</td><td>-</td><td>-</td><td>-</td><td>1</td></tr><tr><td><br /><i>U</i><sub>3</sub></td><td>3</td><td>-</td><td>4</td><td>-</td><td>-</td><td>5</td><td>-</td><td>-</td></tr><tr><td><br /><i>U</i><sub>4</sub></td><td>-</td><td>-</td><td>-</td><td>2</td><td>-</td><td>-</td><td>1</td><td>1</td></tr><tr><td><br /><i>U</i><sub>5</sub></td><td>4</td><td>2</td><td>-</td><td>2</td><td>5</td><td>5</td><td>-</td><td>2</td></tr><tr><td><br /><i>U</i><sub>6</sub></td><td>4</td><td>3</td><td>-</td><td>-</td><td>4</td><td>-</td><td>1</td><td>2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="55">表2是两个用户-项目评分矩阵的另一个案例,解释了Jaccard相似性的不足之处,符号“-”表示未评分。表2显示了目标用户<i>U</i><sub>1</sub>关于不同近邻用户的非共同评分项数。该实例仅通过一个评分计算<i>U</i><sub>1</sub>和<i>U</i><sub>2</sub>、<i>U</i><sub>3</sub>、<i>U</i><sub>4</sub>之间的相似性,并给出了目标用户<i>U</i><sub>1</sub>对于所有近邻用户<i>U</i><sub>2</sub>、<i>U</i><sub>3</sub>、<i>U</i><sub>4</sub>的非共同评分项数。用户<i>U</i><sub>1</sub>对于近邻<i>U</i><sub>5</sub>和<i>U</i><sub>6</sub>的非共同评分分别为0和1,因此<i>U</i><sub>1</sub>的所有项具有充足的信息来评估<i>U</i><sub>5</sub>和<i>U</i><sub>6</sub>间的相似性。该实例说明目标用户的非共同评分项数和相似性度量成反比例,即<mathml id="190"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mspace width="0.25em" /><mi>v</mi><mo stretchy="false">)</mo><mo>∝</mo><mo stretchy="false">(</mo><mo stretchy="false">|</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">|</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>。</p>
                </div>
                <div class="area_img" id="56">
                    <p class="img_tit"><b>表2 目标用户U1关于不同近邻的非共同评分项数</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="56" border="1"><tr><td><br /></td><td><i>I</i><sub>1</sub></td><td><i>I</i><sub>2</sub></td><td><i>I</i><sub>3</sub></td><td><i>I</i><sub>4</sub></td><td><i>I</i><sub>5</sub></td><td><i>I</i><sub>6</sub></td><td><i>I</i><sub>7</sub></td><td><i>I</i><sub>8</sub></td></tr><tr><td><br /><i>U</i><sub>1</sub></td><td>3</td><td>-</td><td>2</td><td>-</td><td>5</td><td>5</td><td>4</td><td>*</td></tr><tr><td><br /><i>U</i><sub>2</sub></td><td>2</td><td>1</td><td>-</td><td>5</td><td>-</td><td>-</td><td>-</td><td>1</td></tr><tr><td><br /><i>U</i><sub>3</sub></td><td>-</td><td>2</td><td>1</td><td>-</td><td>-</td><td>-</td><td>-</td><td>2</td></tr><tr><td><br /><i>U</i><sub>4</sub></td><td>-</td><td>-</td><td>-</td><td>4</td><td>-</td><td>4</td><td>-</td><td>1</td></tr><tr><td><br /><i>U</i><sub>5</sub></td><td>3</td><td>2</td><td>3</td><td>-</td><td>4</td><td>5</td><td>3</td><td>4</td></tr><tr><td><br /><i>U</i><sub>6</sub></td><td>4</td><td>-</td><td>2</td><td>-</td><td>-</td><td>5</td><td>4</td><td>5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="57">Jaccard相似性的另一个情况是如果共同评分项数增加,那么相似性的显著度也成比例增加,即<i>sim</i><sub><i>J</i></sub>(<i>u</i>, <i>v</i>)∝(|<i>I</i><sub><i>u</i></sub>∩<i>I</i><sub><i>v</i></sub>|)。</p>
                </div>
                <h3 id="58" name="58" class="anchor-tag"><b>2 改进的相似性度量指标</b></h3>
                <h4 class="anchor-tag" id="59" name="59"><b>2.1 修改的相似性度量</b></h4>
                <div class="p1">
                    <p id="60">Jaccard相似性<citation id="305" type="reference"><link href="277" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>度量样本集间交集和并集的比例关系,评估有限样本集间的相似性。设用户<i>u</i>和<i>v</i>的评分分别为<i>I</i><sub><i>u</i></sub>和<i>I</i><sub><i>v</i></sub>,如图1所示。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 评分项Iu和Iv的关系示意图" src="Detail/GetImg?filename=images/JYRJ201911047_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 评分项<i>I</i><sub><i>u</i></sub>和<i>I</i><sub><i>v</i></sub>的关系示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="62">Jaccard通过两个用户间共同评分的数量来评估两者的相似性:</p>
                </div>
                <div class="p1">
                    <p id="63"><mathml id="191"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∪</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>      (1)</p>
                </div>
                <div class="p1">
                    <p id="64">式中:<i>I</i><sub><i>u</i></sub>和<i>I</i><sub><i>v</i></sub>分别为用户<i>u</i>和<i>v</i>的评分项集。</p>
                </div>
                <div class="p1">
                    <p id="65">因为<i>I</i><sub><i>u</i></sub>和<i>I</i><sub><i>v</i></sub>为非互斥关系,所以根据加法规则可得:|<i>I</i><sub><i>u</i></sub>∪<i>I</i><sub><i>v</i></sub>|=|<i>I</i><sub><i>u</i></sub>|+|<i>I</i><sub><i>v</i></sub>|-|<i>I</i><sub><i>u</i></sub>∩<i>I</i><sub><i>v</i></sub>|。</p>
                </div>
                <div class="p1">
                    <p id="66"><mathml id="192"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow><mo>-</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>      (2)</p>
                </div>
                <div class="p1">
                    <p id="67">假设<mathml id="193"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow></mrow></math></mathml>和<mathml id="194"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>v</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow></mrow></math></mathml>分别为用户<i>u</i>和<i>v</i>非共同评分集合的基数,分别计算为<mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow><mo>=</mo><mo stretchy="false">|</mo><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">|</mo><mo>-</mo><mo stretchy="false">|</mo><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∪</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">|</mo></mrow></math></mathml>和<mathml id="196"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>v</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow><mo>=</mo><mrow><mo stretchy="false">|</mo><mi>Ι</mi><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">|</mo></mrow><mo>-</mo><mo stretchy="false">|</mo><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∪</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">|</mo></mrow></math></mathml>。将Jaccard相似性改写为下式:</p>
                </div>
                <div class="p1">
                    <p id="68"><mathml id="197"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>v</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="69">式(3)的分子、分母同除以|<i>I</i><sub><i>u</i></sub>∩<i>I</i><sub><i>v</i></sub>|,可获得下式:</p>
                </div>
                <div class="p1">
                    <p id="70"><mathml id="198"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>v</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></mfrac></mrow></math></mathml>      (4)</p>
                </div>
                <div class="p1">
                    <p id="71">根据式(4)可得<i>sim</i><sub><i>J</i></sub>(<i>u</i>, <i>v</i>)∝|<i>I</i><sub><i>u</i></sub>, <i>I</i><sub><i>v</i></sub>|和<mathml id="199"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mspace width="0.25em" /><mi>v</mi><mo stretchy="false">)</mo><mo>∝</mo><mo stretchy="false">(</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo>+</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>。但<mathml id="200"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mi>J</mi></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mspace width="0.25em" /><mi>v</mi><mo stretchy="false">)</mo><mo>∝</mo><mo stretchy="false">(</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo>+</mo><mover accent="true"><mi>Ι</mi><mo>¯</mo></mover><msub><mrow></mrow><mi>v</mi></msub><mo stretchy="false">)</mo><msup><mrow></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math></mathml>属性无法保证为用户提供合适的推荐,所以对<i>Jaccard</i>相似性进行了改进。</p>
                </div>
                <h4 class="anchor-tag" id="72" name="72"><b>2.2 改进的相似性度量</b></h4>
                <div class="p1">
                    <p id="73">通过共同评分项度量相似性存在许多不足,本文提出了新的相似性模型,称为相关Jaccard均方距离。首先定义了相关Jaccard相似性指标:</p>
                </div>
                <div class="p1">
                    <p id="74" class="code-formula">
                        <mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>R</mtext><mtext>J</mtext></mrow></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mfrac><mn>1</mn><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ι</mi></mstyle><msub><mrow></mrow><mi>v</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac><mo>+</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow></mrow><mrow><mn>1</mn><mo>+</mo><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>u</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mrow><mo>|</mo><mrow><mover accent="true"><mrow><mi>Ι</mi><msub><mrow></mrow><mi>v</mi></msub></mrow><mo stretchy="true">¯</mo></mover></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="75">如果|<i>I</i><sub><i>u</i></sub>∩<i>I</i><sub><i>v</i></sub>|=0,那么<i>sim</i><sub>RJ</sub>(<i>u</i>, <i>v</i>)=0。</p>
                </div>
                <div class="p1">
                    <p id="76">将相关Jaccard和均方距离矩阵相乘,获得相关Jaccard均方距离(Relative Jaccard-Mean Square Distance, RJ-MSD):</p>
                </div>
                <div class="p1">
                    <p id="77" class="code-formula">
                        <mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>R</mtext><mtext>J</mtext><mo>-</mo><mtext>Μ</mtext><mtext>S</mtext><mtext>D</mtext></mrow></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>R</mtext><mtext>J</mtext></mrow></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>×</mo><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>Μ</mtext><mtext>S</mtext><mtext>D</mtext></mrow></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>s</mi><mi>i</mi><mi>m</mi><msub><mrow></mrow><mrow><mtext>R</mtext><mtext>J</mtext></mrow></msub><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>×</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>-</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>Ι</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></munder><mo stretchy="false">(</mo></mstyle><mi>R</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo><mo>-</mo><mi>R</mi><mo stretchy="false">(</mo><mi>v</mi><mo>,</mo><mi>i</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mfrac></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="78">如果|<i>I</i><sub><i>u</i></sub>∩<i>I</i><sub><i>v</i></sub>|=0,那么<i>sim</i><sub>RJ-MSD</sub>(<i>u</i>, <i>v</i>) =0。</p>
                </div>
                <h3 id="79" name="79" class="anchor-tag"><b>3 自编码器和协同过滤问题</b></h3>
                <h4 class="anchor-tag" id="80" name="80"><b>3.1 自编码器模型</b></h4>
                <div class="p1">
                    <p id="81">自编码器<citation id="306" type="reference"><link href="279" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>是前向神经网络,通过学习隐层结构重建输入数据。设自编码器共有<i>L</i>层,输出层的维度和输入层相等,设为<i>N</i>,隐层的维度设为<i>K</i>。假设一个两层的自编码器,输入数据为<i><b>x</b></i>∈<b>R</b><sup><i>N</i></sup>,首先通过确定映射将输入数据映射到隐层,记为<i><b>h</b></i>=<i>σ</i>(<i><b>W</b></i><sup>1T</sup><i><b>x</b></i><b>+</b><i><b>b</b></i><sup>1</sup>),其中:<i><b>W</b></i><sup>1</sup>和<i><b>b</b></i><sup>1</sup>分别为<i>N</i>×<i>K</i>的权重矩阵和第1层的<i>K</i>维偏差向量,<i>σ</i>(·)为激活函数。自编码器将输入重建为<mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>˙</mo></mover><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mn>2</mn></msup><mi mathvariant="bold-italic">h</mi><mo>+</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></math></mathml>,其中<i><b>W</b></i><sup>2</sup>和<i><b>b</b></i><sup>2</sup>分别为权重矩阵和第2层的偏差向量。最终通过求解以下的优化问题学习<i><b>W</b></i><sup>1</sup>、<i><b>W</b></i><sup>2</sup>、<i><b>b</b></i><sub>1</sub>和<i><b>b</b></i><sub>2</sub>:</p>
                </div>
                <div class="p1">
                    <p id="82"><mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>Θ</mi></munder><mstyle displaystyle="true"><munder><mo>∑</mo><mi>m</mi></munder><mo stretchy="false">∥</mo></mstyle><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>m</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>˙</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mfrac><mi>β</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi>Θ</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="83">式中:第1项为重建损失,第2项为防止过拟合的L2正则项,<i>β</i>为正则化控制参数。<mathml id="203"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>˙</mo></mover><msub><mrow></mrow><mi>m</mi></msub></mrow></math></mathml>为第<i><b>m</b></i>个数据点的重建结果,<mathml id="204"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">x</mi><mo>˙</mo></mover><msub><mrow></mrow><mi>m</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">(</mo><mi>σ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">W</mi><msup><mrow></mrow><mrow><mn>1</mn><mtext>Τ</mtext></mrow></msup><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>m</mi></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mn>1</mn></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="bold-italic">b</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></math></mathml>。设<i>Θ</i>表示所有边权重和偏差的集合,采用随机梯度下降法(stochastic gradient descent, SGD)<citation id="307" type="reference"><link href="281" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和后向传播算法(Back Propagation, BP)<citation id="308" type="reference"><link href="283" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>可学习<i>Θ</i>。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>3.2 基于自编码器的协同过滤问题</b></h4>
                <div class="p1">
                    <p id="85">稀疏评分向量<i><b>r</b></i><sub><i>u</i></sub>是自编码器的输入信息,自编码器的目标是将稀疏向量重建为密集评分向量,将该过程考虑为矩阵分解模型的非线性形式。因为<i><b>r</b></i><sub><i>u</i></sub>的大多数入口为空值,所以设计了以下的稀疏损失函数来训练自编码器:<image href="images/JYRJ201911047_205.jpg" type="" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <div class="p1">
                    <p id="86"><mathml id="206"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mrow></mrow><mrow><mtext>m</mtext><mtext>s</mtext><mtext>e</mtext></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>u</mi></munder><mo stretchy="false">∥</mo></mstyle><mo stretchy="false">(</mo><mi mathvariant="bold-italic">r</mi><msub><mrow></mrow><mi>u</mi></msub><mo>-</mo><mover accent="true"><mi mathvariant="bold-italic">r</mi><mo>˙</mo></mover><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">)</mo><mo>⋅</mo><mi mathvariant="bold-italic">e</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mfrac><mi>β</mi><mn>2</mn></mfrac><mo stretchy="false">∥</mo><mi>Θ</mi><mo stretchy="false">∥</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="87">式中:<i><b>e</b></i><sub><i>u</i></sub>是<i>u</i>的指示向量,如果<i><b>r</b></i><sub><i>ui</i></sub>≠0,则<i><b>e</b></i><sub><i>ui</i></sub>=1;否则<i><b>e</b></i><sub><i>ui</i></sub>=0。将这一项和重建损失相乘,将后向传播值清零,因此网络忽略缺失的入口信息,仅考虑评分的分布。学习完网络权重和偏差信息后,再次将稀疏评分向量<i><b>r</b></i><sub><i>u</i></sub>输入自编码器,重建一个包含所有项目预测评分的密集向量。top-N推荐系统为目标用户提供<i>N</i>个最优的项目。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag"><b>4 深度神经网络的总体结构</b></h3>
                <div class="p1">
                    <p id="89">图2所示是基于自编码器的协同过滤框架,本框架包括两个自编码器:(1) 用户排序深度神经网络,简称为UNet;(2) 兴趣学习深度神经网络,简称为INet。UNet将成对正则引入自编码器,以最小化评分预测误差为网络的目标。成对损失函数需要采样负项,设负项为<i>j</i>,采样的概率分布为<i>p</i>(<i>j</i>|<i>u</i>)。INet为负项提供一个非均匀且用户相关的采样概率分布,INet通过学习用户的隐式反馈判断用户对于未评分项是否无兴趣,然后利用输出值计算采样概率。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于自编码器的协同过滤框架" src="Detail/GetImg?filename=images/JYRJ201911047_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于自编码器的协同过滤框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>4.1 UNet深度神经网络</b></h4>
                <div class="p1">
                    <p id="92">UNet的目标是通过显式反馈数据分析用户对于项目的偏好,通过优化原目标函数来训练UNet,优化目标是最小化重建误差和正则成对排列损失。用户正项和负项的定义是一个关键问题,主要有两种方式:(1) 从用户<i>u</i>评分的项集中选择项<i>i</i>,从未评分的项集中选择项<i>j</i>;(2) 从用户<i>u</i>评分的项集中任意选择一对项<i>i</i>和项<i>j</i>,且<i><b>r</b></i><sub><i>ui</i></sub>&gt;<i><b>r</b></i><sub><i>uj</i></sub>。考虑以下3个原因:</p>
                </div>
                <div class="p1">
                    <p id="93">① 第1种方式考虑了用户的评分项和未评分项,而第2种方式仅考虑了用户的评分项,在稀疏数据中评分项的比例一般较小。</p>
                </div>
                <div class="p1">
                    <p id="94">② 未评分的项目有两种情况:用户不知道该项目,但是偏好该项目;用户知道该项目,但是无兴趣。前者的未评分项对于模型训练具有意义。</p>
                </div>
                <div class="p1">
                    <p id="95">③ 第1种方式的模型从评分项和未评分项均可以获得反馈信息,本文通过开发未评分的项提高UNet的训练效果。综合考虑上述3点理由,选择第1种方式。最终UNet的目标函数定义为:</p>
                </div>
                <div class="area_img" id="96">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201911047_09600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="97">式中:第1项为重建损失,第2项为成对排列损失,<i>α</i>和<i>β</i>是平衡成对正则项和L2正则项的权重参数。采用对数似然函数建模成对排列损失,将成对排列损失作为被减项,将目标函数建模为最小化问题。</p>
                </div>
                <div class="p1">
                    <p id="98">式(9)的<i>P</i><sub><i>u</i></sub>表示<i>u</i>的一对项目,设<i>u</i>的正项集合为<i>I</i><sub><i>u</i></sub><sup>+</sup>,负项集合为<i>I</i><sub><i>u</i></sub><sup>-</sup>。<i>I</i><sub><i>u</i></sub><sup>+</sup>由<i>r</i><sub><i>ui</i></sub>≥3的评分项组成,剩下的项放入<i>I</i><sub><i>u</i></sub><sup>-</sup>,<i>u</i>未评分的所有项也放入<i>I</i><sub><i>u</i></sub><sup>-</sup>。从<i>I</i><sub><i>u</i></sub><sup>-</sup>采样项<i>j</i>,采样的概率分布为<i>p</i>(<i>j</i>| <i>u</i>),<i>I</i><sub><i>u</i></sub><sup>+</sup>内的每个项<i>i</i>组成一对项目(<i>i</i>,<i>j</i>)。设计了INet深度神经网络学习用户的隐式反馈信息来采样负项,提高总体的准确率。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>4.2 INet深度神经网络</b></h4>
                <div class="p1">
                    <p id="100">如果用户u对项i的评分缺失,其原因可能有两点:① u可能偏好i,但不知道i的存在,所以u未评分i。② u已知i,但对i无兴趣,所以u未评分i。为了提高<i>top</i>-<i>N</i>推荐的准确率,第2个原因的负项优于第1个,但难点在于判断用户对于未评分项目的兴趣。通过隐式反馈信息可观察用户对于未评分项目的兴趣,根据所有未评分项的兴趣得分计算负项的采样概率分布,兴趣得分越低,<i>UNet</i>中无评分的项被选为负项的可能性越大。</p>
                </div>
                <div class="p1">
                    <p id="101">通过最小化以下的损失函数训练<i>INet</i>:</p>
                </div>
                <div class="area_img" id="251">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201911047_25100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="103">式中:<i><b>r</b></i><mathml id="210"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup></mrow></math></mathml>为<i>u</i>的二值化评分向量,<mathml id="211"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">r</mi><mo>⌢</mo></mover><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup></mrow></math></mathml>为重建的密集向量。<i><b>r</b></i><mathml id="212"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup></mrow></math></mathml>的大多数入口为缺失项,所以该训练存在类偏斜问题。随机选择一些未评分项作为负样本,然后分别将它们在<i><b>r</b></i><mathml id="213"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup></mrow></math></mathml>和<i><b>e</b></i><sub><i>u</i></sub>中的对应入口设为0和1,该训练程序能够防止类偏斜问题。</p>
                </div>
                <div class="p1">
                    <p id="104">上述程序完成<i>Θ</i><sub>IL</sub>学习,再次向INet输入二值化评分向量<i><b>r</b></i><mathml id="214"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup></mrow></math></mathml>,然后返回所有未评分项的兴趣预测结果<mathml id="215"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">r</mi><mo>⌢</mo></mover><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup></mrow></math></mathml>。使用softmax函数定义<i>u</i>对<i>I</i><sup>+</sup><sub><i>u</i></sub>的采样概率分布:</p>
                </div>
                <div class="area_img" id="105">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201911047_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="107">最终将<i>u</i>无兴趣的项采样为负项。</p>
                </div>
                <h4 class="anchor-tag" id="108" name="108"><b>4.3 学习算法</b></h4>
                <div class="p1">
                    <p id="109">采用<i>SGD</i>和后向传播训练<i>UNet</i>和<i>INet</i>。首先最小化式(10)隐式反馈来训练<i>INet</i>,然后最小化式(9)显式反馈和<i>INet</i>训练<i>UNet</i>。给定评分矩阵<i><b>R</b></i>,最小批大小为<i>B</i>,负采样率为<i>S</i><sub>PR</sub>,学习率为<i>μ</i>,<i>Θ</i><sub>IL</sub>为训练模型参数,训练UNet的总体程序如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="110"><b>算法1</b> UNet的训练算法</p>
                </div>
                <div class="p1">
                    <p id="111">输入:评分矩阵<i><b>R</b></i>,<i>Θ</i><sub>PR</sub>,预训练<i>Θ</i><sub>IL</sub>,参数<i>B</i>, <i>μ</i>, <i>S</i><sub>PR</sub>。</p>
                </div>
                <div class="p1">
                    <p id="112">输出:<i>Θ</i>′<sub>PR</sub>。</p>
                </div>
                <div class="p1">
                    <p id="113">1. 初始化<i>Θ</i><sub>PR</sub>;</p>
                </div>
                <div class="p1">
                    <p id="114">2. <b>while</b> 不满足收敛条件 <b>do</b></p>
                </div>
                <div class="p1">
                    <p id="115">3.  采样用户<i>B</i>={<i>u</i><sub>1</sub>,<i>u</i><sub>2</sub>,…,<i>u</i><sub><i>B</i></sub>}的一个最小批;</p>
                </div>
                <div class="p1">
                    <p id="116">4.  <i>g</i>=0;</p>
                </div>
                <div class="p1">
                    <p id="117">5.  for each <i>u</i> in <i>Β</i> do</p>
                </div>
                <div class="p1">
                    <p id="118">6.  <i>P</i><sub><i>u</i></sub> = ∅;</p>
                </div>
                <div class="p1">
                    <p id="119"><mathml id="216"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>7</mn><mo>.</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mover accent="true"><mi mathvariant="bold-italic">r</mi><mo>⌢</mo></mover><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup><mo>=</mo><mtext>Ι</mtext><mtext>Ν</mtext><mtext>e</mtext><mtext>t</mtext></mrow></math></mathml>(<i><b>r</b></i><mathml id="217"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>u</mi><mi>b</mi></msubsup></mrow></math></mathml>, <i>Θ</i><sub>IL</sub>);</p>
                </div>
                <div class="p1">
                    <p id="120">8.  式(5)计算<i>p</i>(<i>j</i>| <i>u</i>);</p>
                </div>
                <div class="p1">
                    <p id="121">9.  for <i>s</i> =1 to <i>S</i><sub>PR</sub> do</p>
                </div>
                <div class="p1">
                    <p id="122">10.  <b>for</b><i>i</i>∈<i>I</i><sub><i>u</i></sub><sup>+ </sup>do</p>
                </div>
                <div class="p1">
                    <p id="123">11.  从<i>p</i>(<i>j</i>| <i>u</i>)采样<i>j</i>;</p>
                </div>
                <div class="p1">
                    <p id="124">12.  <i>P</i><sub><i>u</i></sub>=<i>P</i><sub><i>u</i></sub>∪{<i>i</i>, <i>j</i>};</p>
                </div>
                <div class="p1">
                    <p id="125">13.  <b>endfor</b></p>
                </div>
                <div class="p1">
                    <p id="126">14.  <b>endfor</b></p>
                </div>
                <div class="p1">
                    <p id="127">15.  <i>g</i>=<i>g</i>+▽<i>Θ</i><sub>PR</sub><image href="images/JYRJ201911047_218.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>PR</sub>;</p>
                </div>
                <div class="p1">
                    <p id="128">15. <b>endfor</b></p>
                </div>
                <div class="p1">
                    <p id="129">16. <i>Θ</i><sub>PR</sub>=<i>Θ</i><sub>PR</sub>-<i>gμ</i>/<image href="images/JYRJ201911047_219.jpg" type="" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <div class="p1">
                    <p id="130">16.<b>endwhile</b></p>
                </div>
                <div class="p1">
                    <p id="131">然后,向UNet输入稀疏评分向量<i><b>r</b></i><sub><i>u</i></sub>,预测未评分项目的评分,获得包含预测评分的密集向量<mathml id="220"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi mathvariant="bold-italic">r</mi><mo>⌢</mo></mover><msub><mrow></mrow><mi>u</mi></msub></mrow></math></mathml>。最终,选择预测评分最高的top-N项目构成推荐列表。</p>
                </div>
                <h3 id="132" name="132" class="anchor-tag"><b>5 仿真实验和结果分析</b></h3>
                <h4 class="anchor-tag" id="133" name="133"><b>5.1 实验环境和方法</b></h4>
                <div class="p1">
                    <p id="134">(1) 实验数据集。实验数据集为4个真实的数据集:Ciao<citation id="309" type="reference"><link href="285" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、Watcha(watcha.net)、Movielens 100K<citation id="310" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和Movielens 1M数据集<citation id="311" type="reference"><link href="287" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。表3所示是实验数据集的基本信息。</p>
                </div>
                <div class="area_img" id="135">
                    <p class="img_tit"><b>表3 实验数据集的基本信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="135" border="1"><tr><td>数据集</td><td>用户数</td><td>项数</td><td>评分数</td><td>稀疏性/%</td></tr><tr><td><br />Ciao</td><td>996</td><td>1 927</td><td>18 648</td><td>98.72</td></tr><tr><td><br />Watcha</td><td>1 391</td><td>1 927</td><td>101 073</td><td>96.98</td></tr><tr><td><br />Movielens 100K</td><td>943</td><td>1 682</td><td>100 000</td><td>93.69</td></tr><tr><td><br />Movielens 1M</td><td>6 039</td><td>3 883</td><td>1 000 209</td><td>95.72</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="136">每个数据集的评分数据随机分为两个子集:80%的评分数据作为训练集,其他的20%作为测试集。</p>
                </div>
                <div class="p1">
                    <p id="137">(2) 性能评价指标。设用户为<i>u</i>,<i>N</i><sub><i>u</i></sub>为<i>u</i>的推荐项集,<i>Rel</i><sub><i>u</i></sub>为正定集。采用推荐精度、召回率、归一化折扣累加增益(Normalized Discounted Cumulative Gain, NDCG)以及(Reciprocal Rank, RR)。精度<i>P</i><sub><i>u</i></sub><i>N</i>和召回率<i>R</i><sub><i>u</i></sub><i>N</i>重点评估<i>N</i><sub><i>u</i></sub>中包含的项目准确性,分别定义为:</p>
                </div>
                <div class="p1">
                    <p id="138"><mathml id="221"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>u</mi></msub><mi>Ν</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>R</mi><mi>e</mi><mi>l</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mi>Ν</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></mathml>      (12)</p>
                </div>
                <div class="p1">
                    <p id="139"><mathml id="222"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><msub><mrow></mrow><mi>u</mi></msub><mi>Ν</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">|</mo><mi>R</mi><mi>e</mi><mi>l</mi><msub><mrow></mrow><mi>u</mi></msub><mstyle displaystyle="true"><mo>∩</mo><mi>Ν</mi></mstyle><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">|</mo></mrow><mrow><mo stretchy="false">|</mo><mi>R</mi><mi>e</mi><mi>l</mi><msub><mrow></mrow><mi>u</mi></msub><mo stretchy="false">|</mo></mrow></mfrac></mrow></math></mathml>      (13)</p>
                </div>
                <div class="p1">
                    <p id="140">精度和召回率忽略了<i>N</i><sub><i>u</i></sub>中项目的顺序和位置, <i>DCG</i><sub><i>u</i></sub><i>N</i>和<i>RR</i><sub><i>u</i></sub><i>N</i>则考虑了推荐列表的位置,<i>DCG</i><sub><i>u</i></sub><i>N</i>的计算方法为:</p>
                </div>
                <div class="p1">
                    <p id="141"><mathml id="223"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>C</mi><mi>G</mi><msub><mrow></mrow><mi>u</mi></msub><mi>Ν</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mfrac><mrow><mn>2</mn><msup><mrow></mrow><mrow><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></msup><mo>-</mo><mn>1</mn></mrow><mrow><mi>log</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow></mstyle></mrow></math></mathml>      (14)</p>
                </div>
                <div class="p1">
                    <p id="142">式中:<i>y</i><sub><i>k</i></sub>表示<i>N</i><sub><i>u</i></sub>中第<i>k</i>个项的相关评分。</p>
                </div>
                <div class="p1">
                    <p id="143"><i>RR</i><sub><i>u</i></sub><i>N</i>的计算方法为:</p>
                </div>
                <div class="p1">
                    <p id="144"><mathml id="224"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>R</mi><msub><mrow></mrow><mi>u</mi></msub><mi>Ν</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>r</mi><mi>a</mi><mi>n</mi><mi>k</mi><msub><mrow></mrow><mrow><mn>1</mn><mtext>t</mtext><mtext>h</mtext></mrow></msub></mrow></mfrac></mrow></math></mathml>      (15)</p>
                </div>
                <div class="p1">
                    <p id="145">式中:<i>rank</i><sub>1th</sub>为<i>N</i><sub><i>u</i></sub>中第1个正确项的位置。</p>
                </div>
                <div class="p1">
                    <p id="146">实验中为测试集的每个用户提供top-N的推荐列表,然后计算所有用户4个指标的平均值,分别记为<i>PN</i>、<i>RN</i>、<i>GN</i>、<i>MN</i>。实验中选择两个<i>N</i>值:5和20。</p>
                </div>
                <div class="p1">
                    <p id="147">(3) 神经网络的具体实现。首先通过实验确定模型的超参数,UNet和INet隐层节点的激活函数为sigmoid函数,输出节点的激活函数为恒等函数,采用文献<citation id="312" type="reference">[<a class="sup">18</a>]</citation>的方法初始化神经网络的权重,mini-batch大小设为128,学习率为0.001,L2泛化系数<i>β</i>设为0.001。</p>
                </div>
                <div class="p1">
                    <p id="148">观察实验结果发现4个数据集的UNet和INet的最优模型不同,所以通过网格搜索微调神经网络的超参数,微调实验从训练集随机采样20%的样本作为验证集。定义超参数<i>h</i><sub>PR</sub>表示隐层节点对于前一层节点数量的百分比,0&lt;<i>h</i><sub>PR</sub>&lt;100。网络的输入节点数量等于数据集的项目总量,该机制使自编码器结构的中间部分变窄,输出层变宽。如果数据集共有100个项,网络的<i>h</i><sub>PR</sub>为50,隐层数量为3,自编码器输入层到输出层的节点数量分别为100、50、25、50、100。将UNet和INet的隐层数量分别设为{1,2,3,4,5}和{10,30,50,70,90},排序系数α的取值为{1, 0.5, 0.1, 0.05, 0.01, 0.005},L2泛化系数<i>β</i><sub>U</sub>和<i>β</i><sub>I</sub>的取值均为{0.1,0.01,0.001,0.000 1}。</p>
                </div>
                <h4 class="anchor-tag" id="149" name="149"><b>5.2 实验分析</b></h4>
                <div class="p1">
                    <p id="150">本文对协同过滤推荐系统提出两点改进:(1) 设计了相关Jaccard指标,以期改善对稀疏数据集的处理效果;(2) 利用隐式反馈和显式反馈训练深度神经网络,以期提高神经网络的预测准确率。为了详细测试这两个改进点的效果,对UNet和INet两种神经网络采用不同的机制组合分别进行了训练,实验结果总结如图3所示。</p>
                </div>
                <div class="area_img" id="252">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_25200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 改进点验证实验的结果" src="Detail/GetImg?filename=images/JYRJ201911047_25200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 改进点验证实验的结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_25200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="158">分析图3的结果,可总结出以下结论:(1) 改进Jaccard相似性的总体性能一致优于普通Jaccard相似性,表明本文对Jaccard相似性进行了有效的改进,通过对所有样本的相似性评估提高了相似性度量的显著性。改进的Jaccard相似性也有效地缓解了稀疏数据集的相似性问题,有助于提高自编码器预测用户偏好的准确率。(2) 显式反馈的效果优于隐式反馈,而同时使用显式反馈和隐式反馈的效果最佳。因为显式反馈和隐式反馈从不同的角度反映了用户的兴趣,隐式反馈反映了用户对于项目的兴趣,显式反馈则反映了偏好该项目的用户数量,所以这两种反馈之间具有互补性。</p>
                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>5.3 超参数的设置</b></h4>
                <div class="p1">
                    <p id="160">实验研究了以下3个超参数对模型的影响:(1) 自编码器的隐层数量。(2) 隐层节点的<i>h</i><sub><i>U</i></sub>参数。(3) 排列系数<i>α</i>。以不同的参数组合训练自编码器,以推荐的准确率为评价指标。首先,评估神经网络结构相关的超参数即<i>h</i><sub>PR</sub>和<i>L</i>的效果,结果如图4所示。</p>
                </div>
                <div class="area_img" id="253">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_25300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 神经网络超参数的微调实验" src="Detail/GetImg?filename=images/JYRJ201911047_25300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 神经网络超参数的微调实验  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_25300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="253">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_25301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 神经网络超参数的微调实验" src="Detail/GetImg?filename=images/JYRJ201911047_25301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 神经网络超参数的微调实验  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_25301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="168">由图4可知:(1) 不同数据集的最优<i>h</i><sub>U</sub>值不同,因为Ciao数据集较小且较为稀疏,所以少量的隐层节点即可提取训练数据集的最近特征,因此Ciao数据集自编码器无需大量的隐层节点来实现高准确率。而其他3个数据集需要大量的隐层节点才能实现较高的准确率。(2) 图2中隐层数量对于推荐准确率存在影响,单层自编码器结构难以提取用户-项目间复杂的非线性信息,所以准确率较低。而多层的网络结构包括较多的模型参数,容易引起过拟合问题,所以准确率也较低。</p>
                </div>
                <div class="p1">
                    <p id="169">图5所示是超参数α对实验结果的影响,图中x轴为变化的<i>α</i>值,y轴为top-N推荐的准确率。图4的结果显示,通过最小化MSE和正则成对排名损失两个指标训练本文的自编码器,有助于提高自编码器对于用户兴趣的预测准确率。</p>
                </div>
                <div class="area_img" id="170">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 超参数α的微调实验" src="Detail/GetImg?filename=images/JYRJ201911047_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 超参数α的微调实验  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_170.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="171" name="171"><b>5.4 对比实验分析</b></h4>
                <div class="p1">
                    <p id="172">根据上述超参数微调实验的结果,将每个数据集的超参数设为性能最优的参数组合。选择其他的top-N推荐算法与本文比较,包括:itemModel<citation id="313" type="reference"><link href="265" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>、itemRNN<citation id="314" type="reference"><link href="267" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、SVD<citation id="315" type="reference"><link href="269" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、xCLiMF<citation id="316" type="reference"><link href="271" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、SDAutoRec<citation id="317" type="reference"><link href="273" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、DHAutoRec<citation id="318" type="reference"><link href="275" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。其中:SVD和xCLiMF是两个经典的top-N推荐系统,SVD是经典的奇异值分解模型,xCLiMF为扩展的少即是好协同过滤模型; itemModel和itemRNN是两个针对项目显式信息的推荐系统,这两个系统的推荐效率较高;SDAutoRec和DHAutoRec是两个基于深度神经网络的推荐系统,均为单网络的结构。</p>
                </div>
                <div class="p1">
                    <p id="173">7个推荐系统的性能结果如图6所示。由图6可知:(1) 本系统对于4个数据集均实现了最优的推荐准确率,总体而言,本文算法比次优系统的推荐准确率提高约40%。(2) 本系统的top-5推荐效果优于top-20,如果对于仅需要为用户提供少量推荐列表的场景下,本系统具有比较突出的优势。</p>
                </div>
                <div class="area_img" id="254">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_25400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 对比实验的结果" src="Detail/GetImg?filename=images/JYRJ201911047_25400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 对比实验的结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_25400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="181" name="181"><b>5.5 算法的时间效率</b></h4>
                <div class="p1">
                    <p id="182">最终统计了7个推荐系统的平均训练时间和推荐响应时间。表4所示是7个算法的平均训练时间,itemModel和itemRNN均为基于项目的推荐系统,模型的训练时间较小,SDAutoRec和DHAutoRec则是单网络模型的推荐系统,其训练速度也明显快于本系统。总体而言,本文系统设计了两个自编码器的深度神经网络,改进的Jaccard相似性需要计算全部项目的相关相似性值,因此训练时间较长。</p>
                </div>
                <div class="area_img" id="183">
                    <p class="img_tit"><b>表4 实验数据集的训练时间 </b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">s</p>
                    <table id="183" border="1"><tr><td>数据集</td><td>Ciao</td><td>Watcha</td><td>Movielens 100 KB</td><td>Movielens 1 MB</td></tr><tr><td><br />itemModel</td><td>0.29</td><td>1.01</td><td>0.71</td><td>14.75</td></tr><tr><td><br />itemRNN</td><td>0.92</td><td>10.94</td><td>8.76</td><td>381.02</td></tr><tr><td><br />SVD</td><td>67.85</td><td>273.61</td><td>237.12</td><td>2 335.27</td></tr><tr><td><br />xCLiMF</td><td>24.21</td><td>108.02</td><td>121.36</td><td>2 589.92</td></tr><tr><td><br />SDAutoRec</td><td>6.31</td><td>16.32</td><td>10.78</td><td>113.80</td></tr><tr><td><br />DHAutoRec</td><td>8.75</td><td>21.65</td><td>20.69</td><td>131.29</td></tr><tr><td><br />本文系统</td><td>79.21</td><td>213.01</td><td>134.06</td><td>103.69</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="184">图7所示是7个算法的平均推荐响应时间,SVD和xCLiMF的推荐响应时间较长,并且影响了其应用价值。本文算法的响应时间略高于itemModel、itemRNN、SDAutoRec及DHAutoRec四个算法,但平均响应时间低于0.5秒,满足实时性的需求。</p>
                </div>
                <div class="area_img" id="185">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911047_185.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 推荐系统的平均响应时间" src="Detail/GetImg?filename=images/JYRJ201911047_185.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 推荐系统的平均响应时间  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911047_185.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="186" name="186" class="anchor-tag"><b>6 结 语</b></h3>
                <div class="p1">
                    <p id="187">为了提高协同过滤推荐系统对于稀疏数据的推荐效果,本文提出了一种基于深度神经网络和改进相似性度量的推荐算法。主要提出两个改进点,改进了相似性评价指标,对Jaccard相似性进行了改进,提高稀疏数据的相似性评估准确率。提出了显式反馈自编码器和隐式反馈自编码器,两个自编码器交互学习数据的显式关系和隐式关系。因为显式反馈和隐式反馈从不同的角度反映了用户的兴趣,隐式反馈反映了用户对于项目的兴趣,显式反馈则反映了偏好该项目的用户数量,所以这两种反馈之间具有互补性。</p>
                </div>
                <div class="p1">
                    <p id="188">本文采用了两个深度学习网络,并且改进Jaccard相似性需要计算全部数据集的相似性,导致模型训练的时间较长。因此本系统仅仅适用于稳定数据流的推荐问题,过长的训练时间无法满足实时训练的要求。未来将关注于引入分布式计算和云计算技术,加快深度神经网络的训练时间。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="255">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201704036&amp;v=MjI5NTMzenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFZMM0JMeUhNZDdHNEg5Yk1xNDlHWW9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 董立岩,王越群,贺嘉楠,等.基于时间衰减的协同过滤推荐算法[J].吉林大学学报(工),2017,47(4):1268-1272.
                            </a>
                        </p>
                        <p id="257">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZDZC201706024&amp;v=Mjk5MjFyQ1VSTE9lWmVWdUZ5L2hWTDNCUHluUmJiRzRIOWJNcVk5SFlJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 毛宜钰,刘建勋,胡蓉,等.基于Logistic函数和用户聚类的协同过滤算法[J].浙江大学学报(工学版),2017,51(6):1252-1258.
                            </a>
                        </p>
                        <p id="259">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201811015&amp;v=MzIyODRkckc0SDluTnJvOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVkwzQlBUWGM=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 杨晋吉,胡波,王欣明,等.一种知识图谱的排序学习个性化推荐算法[J].小型微型计算机系统,2018,39(11):69-73.
                            </a>
                        </p>
                        <p id="261">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Recommendation system for adaptive learning">

                                <b>[4]</b> Chen Y,Li X,Liu J,et al.Recommendation system for adaptive learning[J].Applied Psychological Measurement,2017,42(23):24-41.
                            </a>
                        </p>
                        <p id="263">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Collaborative filtering and deep learning based recommendation system for cold start items">

                                <b>[5]</b> Wei J ,He J ,Chen K ,et al.Collaborative filtering and deep learning based recommendation system for cold start items[J].Expert Systems with Applications,2017,69:29-39.
                            </a>
                        </p>
                        <p id="265">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Local Item-Item Models for Top-N Recommen-dation">

                                <b>[6]</b> Christakopoulou E,Karypis G.Local item-item models for top-N recommendation[C]// Proceedings of the 10th ACM Conference on Recommender Systems.ACM,2016:67-74.
                            </a>
                        </p>
                        <p id="267">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation">

                                <b>[7]</b> Jannach D,Ludewig M.When recurrent neural networks meet the neighborhood for session-based recommendation[C]// Proceedings of the Eleventh ACM Conference on Recommender Systems.ACM,2017:306-310.
                            </a>
                        </p>
                        <p id="269">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXWX201706022&amp;v=MjgzNDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvaFZMM0JQVFhjZHJHNEg5Yk1xWTlIWm9RS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Wang J F,Li X,Wu W Q,et al.An algorithm of collaborative filtering based on SVD and trust factors[J].Journal of Chinese Computer Systems,2017,38(6):1290-1293.
                            </a>
                        </p>
                        <p id="271">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES27FE0C834555E6B3A36A9566945D5CFA&amp;v=MjQ4OTZXcjdKSUZwbWFCdUhZZk9HUWxmQ3BiUTM1ZGhodzd5NHdxRT1OaWZPZmJHL2FLVE0zSWRHWU80S0NRay92UlZpNlRrTVFYcmtxaHN4Zk1hUk5zenVDT052RlNpVw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Li G,Zhang Z,Wang L,et al.One-class collaborative filtering based on rating prediction and ranking prediction[J].Knowledge-Based Systems,2017,45(12):3070-3075.
                            </a>
                        </p>
                        <p id="273">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stacked Denoising Autoencoder-Based Deep Collaborative Filtering Using the Change of Similarity">

                                <b>[10]</b> Suzuki Y,Ozaki T.Stacked denoising autoencoder-based deep collaborative filtering using the change of similarity[C]// International Conference on Advanced Information Networking and Applications Workshops.2017.
                            </a>
                        </p>
                        <p id="275">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BDMA201803003&amp;v=MTY2NTE0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9oVkwzQkp5bkdiN0c0SDluTXJJOUZaNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Yu L,Shuai W,M.Shahrukh Khan,et al.A novel deep hybrid recommender system based on auto-encoder with neural collaborative filtering[J].Big Data Mining &amp; Analytics,2018,1(3):211-221.
                            </a>
                        </p>
                        <p id="277">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201607048&amp;v=MTE3OTVxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hWTDNCTHo3QmQ3RzRIOWZNcUk5QmJJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 杨家慧,刘方爱.基于巴氏系数和Jaccard系数的协同过滤算法[J].计算机应用,2016,36(7):2006-2010.
                            </a>
                        </p>
                        <p id="279">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201712046&amp;v=MjcwNTZWTDNCTHpUWlpMRzRIOWJOclk5QllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2g=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 刘帆,吴小俊.基于混合核平滑自编码器的分类器设计[J].计算机应用与软件,2017,34(12):246-250.
                            </a>
                        </p>
                        <p id="281">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Stochastic Gradient Descent">

                                <b>[14]</b> Ketkar N.Stochastic gradient descent[M]// Deep Learning with Python.2017.
                            </a>
                        </p>
                        <p id="283">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The parallelization of back propagation neural network in MapReduce and Spark">

                                <b>[15]</b> Liu Y,Xu L,Li M.The parallelization of back propagation neural network in MapReduce and spark[J].International Journal of Parallel Programming,2017,45(4):1-20.
                            </a>
                        </p>
                        <p id="285">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CIAO-Collaborative institutional assessment of open access(pilot version)">

                                <b>[16]</b> Rouse R,Hunt S,Stubbings R.CIAO-Collaborative institutional assessment of open access(pilot version)[J].Biochemistry,2014,5(6):2049-2061.
                            </a>
                        </p>
                        <p id="287">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Gbpr:Group preference based bayesian personal-ized ranking for one-class collaborative filtering">

                                <b>[17]</b> Pan W ,Chen L.GBPR:group preference based Bayesian personalized ranking for one-class collaborative filtering[C]// Proceedings of the Twenty-Third international joint conference on Artificial Intelligence.2013.
                            </a>
                        </p>
                        <p id="289">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Understanding the difficulty of training deep feedforward neural networks">

                                <b>[18]</b> Glorot X,Bengio Y.Understanding the difficulty of training deep feedforward neural networks[C]//Proceedings of the thirteenth international conference on artificial intelligence and statistics.2010:249-256.
                            </a>
                        </p>
                        <p id="291">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=FISM:factored item similarity models for top-N recommender systems">

                                <b>[19]</b> Kabbur S ,Karypis G.FISM :Factored item similarity models for top-N recommender systems[C]// Acm Sigkdd International Conference on Knowledge Discovery &amp; Data Mining.ACM,2013.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201911047" />
        <input id="dpi" type="hidden" value="96" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911047&amp;v=MDY3MjVMRzRIOWpOcm85Qlk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2hWTDNPTHpUWlo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
