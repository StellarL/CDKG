<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135565838283750%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201910036%26RESULT%3d1%26SIGN%3dNJijvS8g8Z7tLZGG1UD1ZWfc5aI%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201910036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201910036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201910036&amp;v=MDUwMDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmtXN3JOTHpUWlpMRzRIOWpOcjQ5R1lvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#44" data-title="&lt;b&gt;1 算法设计与实现&lt;/b&gt; "><b>1 算法设计与实现</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#71" data-title="&lt;b&gt;2 实 验&lt;/b&gt; "><b>2 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#72" data-title="&lt;b&gt;2.1 实验数据&lt;/b&gt;"><b>2.1 实验数据</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;2.2 视觉定性比较&lt;/b&gt;"><b>2.2 视觉定性比较</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;2.3 抗噪能力量化比较&lt;/b&gt;"><b>2.3 抗噪能力量化比较</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;2.4 错误总量OE量化比较&lt;/b&gt;"><b>2.4 错误总量OE量化比较</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;2.5 总的准确率PCC量化比较&lt;/b&gt;"><b>2.5 总的准确率PCC量化比较</b></a></li>
                                                <li><a href="#109" data-title="&lt;b&gt;2.6 Kappa系数、召回率和F1量化比较&lt;/b&gt;"><b>2.6 Kappa系数、召回率和F1量化比较</b></a></li>
                                                <li><a href="#117" data-title="&lt;b&gt;2.7 运行时间量化比较&lt;/b&gt;"><b>2.7 运行时间量化比较</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;2.8 实验分析&lt;/b&gt;"><b>2.8 实验分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#122" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="图1 算法流程图">图1 算法流程图</a></li>
                                                <li><a href="#154" data-title="图2 渥太华">图2 渥太华</a></li>
                                                <li><a href="#155" data-title="图3 越南红河">图3 越南红河</a></li>
                                                <li><a href="#156" data-title="图4 渥太华不同检测方法结果比较图">图4 渥太华不同检测方法结果比较图</a></li>
                                                <li><a href="#157" data-title="图5 越南红河不同检测方法结果比较图">图5 越南红河不同检测方法结果比较图</a></li>
                                                <li><a href="#91" data-title="图6 渥太华不同强度斑点噪声抗噪比较图">图6 渥太华不同强度斑点噪声抗噪比较图</a></li>
                                                <li><a href="#92" data-title="图7 越南红河不同强度斑点噪声抗噪比较图">图7 越南红河不同强度斑点噪声抗噪比较图</a></li>
                                                <li><a href="#93" data-title="图8 渥太华不同强度白噪声抗噪比较图">图8 渥太华不同强度白噪声抗噪比较图</a></li>
                                                <li><a href="#94" data-title="图9 越南红河不同强度白噪声抗噪比较图">图9 越南红河不同强度白噪声抗噪比较图</a></li>
                                                <li><a href="#104" data-title="&lt;b&gt;表1 算法错误总量OE量化比较&lt;/b&gt;"><b>表1 算法错误总量OE量化比较</b></a></li>
                                                <li><a href="#108" data-title="&lt;b&gt;表2 算法总的准确率PCC量化比较&lt;/b&gt;"><b>表2 算法总的准确率PCC量化比较</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;表3 算法Kappa系数、召回率和F1量化比较&lt;/b&gt;"><b>表3 算法Kappa系数、召回率和F1量化比较</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;表4 算法运行时间Time量化比较&lt;/b&gt;"><b>表4 算法运行时间Time量化比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 王相海,朱毅欢,吕芳,等.基于Cauchy分布的非下采样Shearlet HMT模型及其图像去噪应用[J].计算机学报,2018,41(11):2496-2508." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201811006&amp;v=MTc4MjBMejdCZHJHNEg5bk5ybzlGWW9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlua1c3ck4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         王相海,朱毅欢,吕芳,等.基于Cauchy分布的非下采样Shearlet HMT模型及其图像去噪应用[J].计算机学报,2018,41(11):2496-2508.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 侯小毛,张群慧,马凌.结合无下采样Shearlet变换和改进尺度积的边缘提取[J].遥感信息,2018,33(4):91-97." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YGXX201804015&amp;v=MTAxNTM0OUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5rVzdyTlBDclRkckc0SDluTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         侯小毛,张群慧,马凌.结合无下采样Shearlet变换和改进尺度积的边缘提取[J].遥感信息,2018,33(4):91-97.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Qu Z,Xing Y,Song Y.An image enhancement method based on non-subsampled shearlet transform and directional information measurement[J].Information (Switzerland),2018,9(12):308." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An image enhancement method based on non-subsampled shearlet transform and directional information measurement">
                                        <b>[3]</b>
                                         Qu Z,Xing Y,Song Y.An image enhancement method based on non-subsampled shearlet transform and directional information measurement[J].Information (Switzerland),2018,9(12):308.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Li L,Si Y.Remote sensing image enhancement based on nonsubsampled shearlet transform and local laplacian filter[C]//Proceedings of the 3rd IEEE International Conference on Image,Vision and Computing,ICIVC 2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Remote sensing image enhancement based on nonsubsampled shearlet transform and local laplacian filter">
                                        <b>[4]</b>
                                         Li L,Si Y.Remote sensing image enhancement based on nonsubsampled shearlet transform and local laplacian filter[C]//Proceedings of the 3rd IEEE International Conference on Image,Vision and Computing,ICIVC 2018.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 韩晶,贾振红,杨杰,等.基于NSST域的引导滤波遥感图像增强方法[J].计算机工程与设计,2018,39(9):2832-2835,2906." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201809024&amp;v=MjMxOTVxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmtXN3JOTmlmWVpMRzRIOW5NcG85SFlJUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         韩晶,贾振红,杨杰,等.基于NSST域的引导滤波遥感图像增强方法[J].计算机工程与设计,2018,39(9):2832-2835,2906.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Liu Z,Feng Y,Chen H,et al.A fusion algorithm for infrared and visible based on guided filtering and phase congruency in NSST domain[J].Optics &amp;amp; Lasers in Engineering,2017,97:71-77." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES156FD310A3F8253A4804C55554FD322D&amp;v=MTI0NThjeEQ4YVhSN2pyQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJtM3hhMD1OaWZPZmJLOUdLZTRySTVGRmVoNUJINDh6R2NYNGo5NU8zcm5xUg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Liu Z,Feng Y,Chen H,et al.A fusion algorithm for infrared and visible based on guided filtering and phase congruency in NSST domain[J].Optics &amp;amp; Lasers in Engineering,2017,97:71-77.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Wu W,Qiu Z,Zhao M,et al.Visible and infrared image fusion using NSST and deep Boltzmann machine[J].Optik,2018,157:334-342." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFB1253F3F23DE92481DF2095175F0202&amp;v=MTMxMTROdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJtM3hhMD1OaWZPZmNYS0g5UEpyUGxHRXVrTWVBa3d6UkliNjBzTFNuL3JxUk15Zk1TVVI3cWRDTw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Wu W,Qiu Z,Zhao M,et al.Visible and infrared image fusion using NSST and deep Boltzmann machine[J].Optik,2018,157:334-342.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 楼建强,李俊峰,戴文战.非下采样剪切波变换的医学图像融合[J].中国图象图形学报,2017,22(11):1574-1583." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201711011&amp;v=MjY4NzhyTlB5cmZiTEc0SDliTnJvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5rVzc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         楼建强,李俊峰,戴文战.非下采样剪切波变换的医学图像融合[J].中国图象图形学报,2017,22(11):1574-1583.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 曹义亲,曹婷,黄晓生.基于NSST的CS与区域特性相结合的图像融合方法[J].计算机工程与应用,2018,54(20):190-196." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201820030&amp;v=Mjc3MjI3TWFiRzRIOW5PcjQ5R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmtXN3JOTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         曹义亲,曹婷,黄晓生.基于NSST的CS与区域特性相结合的图像融合方法[J].计算机工程与应用,2018,54(20):190-196.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 王烈,罗文,陈俊鸿,等.自适应PCNN与信息提取的红外与可见光图像融合[J].计算机工程与应用,2018,54(4):192-198." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201804031&amp;v=MDc2Mjk5bk1xNDlHWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlua1c3ck5MejdNYWJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         王烈,罗文,陈俊鸿,等.自适应PCNN与信息提取的红外与可见光图像融合[J].计算机工程与应用,2018,54(4):192-198.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Li S,Hua N.Remote sensing image segmentation based on a modified pulse coupled neural network[C]//Proceedings of the International Symposium on Optoelectronic Technology and Application 2018:Optical Sensing and Imaging Technologies and Applications 2018,OTA 2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Remote sensing image segmentation based on a modified pulse coupled neural network">
                                        <b>[11]</b>
                                         Li S,Hua N.Remote sensing image segmentation based on a modified pulse coupled neural network[C]//Proceedings of the International Symposium on Optoelectronic Technology and Application 2018:Optical Sensing and Imaging Technologies and Applications 2018,OTA 2018.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Zhang K,Huang Y,Zhao C.Remote sensing image fusion via RPCA and adaptive PCNN in NSST domain[J].International Journal of Wavelets,Multiresolution and Information Processing,2018,16(5):1850037." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Remote sensing image fusion via RPCA and adaptive PCNN in NSST domain">
                                        <b>[12]</b>
                                         Zhang K,Huang Y,Zhao C.Remote sensing image fusion via RPCA and adaptive PCNN in NSST domain[J].International Journal of Wavelets,Multiresolution and Information Processing,2018,16(5):1850037.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Li M,Yuan X,Luo Z,et al.Infrared and Visual Image Fusion Based on NSST and Improved PCNN[C]//Proceedings of the 3rd Annual International Conference on Information System and Artificial Intelligence,ISAI 2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Infrared and Visual Image Fusion Based on NSST and Improved PCNN">
                                        <b>[13]</b>
                                         Li M,Yuan X,Luo Z,et al.Infrared and Visual Image Fusion Based on NSST and Improved PCNN[C]//Proceedings of the 3rd Annual International Conference on Information System and Artificial Intelligence,ISAI 2018.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Yang H,Lin L.A novel remote sensing images fusion algorithm combining extended NSST and modified PCNN[C]//Proceedings of the 10th International Conference on Digital Image Processing,ICDIP 2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel remote sensing images fusion algorithm combining extended NSST and modified PCNN">
                                        <b>[14]</b>
                                         Yang H,Lin L.A novel remote sensing images fusion algorithm combining extended NSST and modified PCNN[C]//Proceedings of the 10th International Conference on Digital Image Processing,ICDIP 2018.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 张康,黄永东,王国芬.基于NSST变换与自适应PCNN的多特征遥感图像融合[J].激光与红外,2018,48(6):775-781." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201806020&amp;v=MDcwMzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW5rVzdyTkx5ckRlYkc0SDluTXFZOUhaSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         张康,黄永东,王国芬.基于NSST变换与自适应PCNN的多特征遥感图像融合[J].激光与红外,2018,48(6):775-781.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Gao F,Dong J,Li B,et al.Automatic Change Detection in Synthetic Aperture Radar Images Based on PCANet[J].IEEE Geoscience and Remote Sensing Letters,2016,13(12):1792-1796." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic Change Detection in Synthetic Aperture Radar Imag-es Based on PCANet">
                                        <b>[16]</b>
                                         Gao F,Dong J,Li B,et al.Automatic Change Detection in Synthetic Aperture Radar Images Based on PCANet[J].IEEE Geoscience and Remote Sensing Letters,2016,13(12):1792-1796.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Gao F,Dong J,Li B,et al.Change detection from synthetic aperture radar images based on neighborhood-based ratio and extreme learning machine[J].Journal of Applied Remote Sensing,2016,10(4):046019." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Change detection from synthetic aperture radar images based on neighborhood-based ratio and extreme learning machine">
                                        <b>[17]</b>
                                         Gao F,Dong J,Li B,et al.Change detection from synthetic aperture radar images based on neighborhood-based ratio and extreme learning machine[J].Journal of Applied Remote Sensing,2016,10(4):046019.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Gao F,Wang X,Dong J,et al.Synthetic aperture radar image change detection based on frequency-domain analysis and random multigraphs[J].Journal of Applied Remote Sensing,2018,12(1):016010." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEGF7D811441243CBF560B9A34C96879B11&amp;v=MjQxNjNKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJtM3hhMD1OaWZPYWNXL2F0bk5yb3RCWmVrTER3OUx1Uk1WNmsxME9Yem0zeHN6Y2JXZE43dWVDT052RlNpV1dyNw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Gao F,Wang X,Dong J,et al.Synthetic aperture radar image change detection based on frequency-domain analysis and random multigraphs[J].Journal of Applied Remote Sensing,2018,12(1):016010.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Wenyan Z,Zhenhong J,Yu Y,et al.SAR image change detection based on equal weight image fusion and adaptive threshold in the NSST domain[J].European Journal of Remote Sensing,2018,51(1):785-794." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SAR image change detection based on equal weight image fusion and adaptive threshold in the NSST domain">
                                        <b>[19]</b>
                                         Wenyan Z,Zhenhong J,Yu Y,et al.SAR image change detection based on equal weight image fusion and adaptive threshold in the NSST domain[J].European Journal of Remote Sensing,2018,51(1):785-794.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(10),205-210+261 DOI:10.3969/j.issn.1000-386x.2019.10.035            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种新的遥感影像变化检测算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%99%E9%93%B6%E5%B3%B0&amp;code=25315962&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">余银峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%A5%9D%E7%BE%8E%E7%8E%B2&amp;code=39403338&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">祝美玲</a>
                                <a href="javascript:;">张丽</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%96%B0%E7%96%86%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0181515&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">新疆大学信息科学与工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B9%8C%E9%B2%81%E6%9C%A8%E9%BD%90%E5%B8%82%E7%AC%AC59%E4%B8%AD%E5%AD%A6&amp;code=1580256&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">乌鲁木齐市第59中学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B7%B4%E5%B7%9E%E5%A4%96%E4%BA%8B%E4%BE%A8%E5%8A%A1%E5%8A%9E%E5%85%AC%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">巴州外事侨务办公室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对传统的遥感影像变化检测算法不能同时确保准确率高、抗噪能力强和时间成本低的现状,设计一种新的基于非下采样剪切波变换和自适应脉冲耦合神经网络相结合的遥感影像变化检测算法。充分采用邻域信息有效降低虚警数量;借助非下采样剪切波变换的多方向、多尺度分解并利用全局、局部滤波,有效降低漏警数量;非下采样剪切波变换具有平移、旋转和尺度不变性,有效提升抗噪能力;自适应脉冲耦合神经网络分类准确率高并且时间成本很低。实验结果表明,与其他算法相比,该算法具有更高的检测准确度、更强的抗噪能力和更低的时间成本。实验结果验证了该算法的优越性和可行性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E4%B8%8B%E9%87%87%E6%A0%B7%E5%89%AA%E5%88%87%E6%B3%A2%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非下采样剪切波变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%87%AA%E9%80%82%E5%BA%94%E8%84%89%E5%86%B2%E8%80%A6%E5%90%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">自适应脉冲耦合神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%98%E5%8C%96%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">变化检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    余银峰，讲师，主研领域:图像处理。;
                                </span>
                                <span>
                                    祝美玲，学士。;
                                </span>
                                <span>
                                    张丽，硕士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-20</p>

                    <p>

                            <b>基金：</b>
                                                        <span>新疆维吾尔自治区自然科学基金项目(2015211C288);</span>
                    </p>
            </div>
                    <h1><b>A NOVEL REMOTE SENSING IMAGE CHANGE DETECTION ALGORITHM</b></h1>
                    <h2>
                    <span>Yu Yinfeng</span>
                    <span>Zhu Meiling</span>
                    <span>Zhang Li</span>
            </h2>
                    <h2>
                    <span>College of Information Science and Engineering, Xinjiang University</span>
                    <span>Urumqi No.59 Middle School</span>
                    <span>Bazhou Foreign Affairs Office</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Traditional remote sensing image change detection algorithm cannot simultaneously ensure high accuracy, strong anti-noise ability and low time cost. To solve this question, this paper designed a novel remote sensing image change detection algorithm based on nonsubsampled shearlet transform and adaptive pulse coupled neural network. Neighborhood information was applied to effectively reduce the number of false alarms, and we used multi-directional and multi-scale decomposition of nonsubsampled shearlet transform and global and local filtering to effectively reduce the number of missed alarms. The nonsubsampled shearlet transform had the invariance of translation, rotation and scale, which effectively improved the anti-noise ability. The classification accuracy of the adaptive pulse coupled neural network was high and the time cost was low. The experimental results show that compared with the other algorithm, the algorithm has higher detection accuracy for OE, PCC, KC, Recall and F1 performance indicators. It has stronger anti-noise ability and lower time cost. The experimental results fully prove the superiority and feasibility of the algorithm.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nonsubsampled%20shearlet%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nonsubsampled shearlet transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Adaptive%20pulse%20coupled%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Adaptive pulse coupled neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Change%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Change detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Remote%20sensing&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Remote sensing;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-20</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="42">关于非下采样剪切波变换(Nonsubsampled Shearlet Transform,NSST)和自适应脉冲耦合神经网络(Adaptive Pulse Coupled Neural Network,APCNN)的研究、应用很多。例如:基于NSST的图像去噪<citation id="131" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>;基于NSST的边缘检测<citation id="132" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>;基于NSST域的影像增强<citation id="135" type="reference"><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><sup>[<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>;基于NSST的图像融合<citation id="136" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</sup></citation>;基于APCNN的图像融合<citation id="133" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>;基于APCNN的图像分割<citation id="134" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>;基于NSST和APCNN的图像融合<citation id="137" type="reference"><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>]</sup></citation>。基于NSST和APCNN的图像变化高效检测的研究和应用尚未发现。</p>
                </div>
                <div class="p1">
                    <p id="43">本文首次设计了一种基于NSST和APCNN的无监督类型的不同时相的遥感图像像素级别变化高效检测新算法。比较本文算法与文献<citation id="138" type="reference">[<a class="sup">16</a>]</citation>、文献<citation id="139" type="reference">[<a class="sup">17</a>]</citation>和文献<citation id="140" type="reference">[<a class="sup">18</a>]</citation>算法,两组实验结果表明:本文算法具有更强的抗噪能力、更高的检测精度和更低的时间成本。</p>
                </div>
                <h3 id="44" name="44" class="anchor-tag"><b>1 算法设计与实现</b></h3>
                <div class="p1">
                    <p id="45">本文首次将NSST与APCNN结合在一起解决遥感图的变化有效检测问题。算法的流程图如图1所示。运用自适应脉冲耦合神经网络对每个像素所对应的邻域信息进行两类分类,最终获得变化区域的结果图。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 算法流程图" src="Detail/GetImg?filename=images/JYRJ201910036_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="47">新算法实现细节的详细描述如下:</p>
                </div>
                <div class="p1">
                    <p id="48">1) 邻域均值化处理。对于一幅大小为<i>H</i>×<i>W</i>的输入图像<i>I</i>,点像素(<i>i</i>,<i>j</i>)的邻域信息通过以下公式来求得:</p>
                </div>
                <div class="p1">
                    <p id="49"><i>u</i>=max(<i>i</i>-<i>h</i>,1)      (1)</p>
                </div>
                <div class="p1">
                    <p id="50"><i>d</i>=min(<i>i</i>+<i>h</i>,<i>H</i>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="51"><i>l</i>=max(<i>j</i>-<i>w</i>,1)      (3)</p>
                </div>
                <div class="p1">
                    <p id="52"><i>r</i>=min(<i>j</i>+<i>w</i>,<i>W</i>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="53"><i>N</i>=<i>I</i>(<i>u</i>:<i>d</i>,<i>l</i>:<i>r</i>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="54"><i>X</i>(<i>i</i>,<i>j</i>)=<i>mean</i>(<i>N</i>(:))      (6)</p>
                </div>
                <div class="p1">
                    <p id="55">式中:<i>i</i>∈[1,<i>H</i>],<i>j</i>∈[1,<i>W</i>],<i>h</i>、<i>w</i>是邻域大小参数,<i>N</i>是点像素(<i>i</i>,<i>j</i>)的邻域,<i>X</i>(<i>i</i>,<i>j</i>)是点像素(<i>i</i>,<i>j</i>)的邻域信息,<i>X</i>是输入图像<i>I</i>经过邻域均值化处理的结果图像。</p>
                </div>
                <div class="p1">
                    <p id="56">2) 根据两幅不同时相输入图像获得对数比图像。</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Y</mi><mo>=</mo><mrow><mi>lg</mi></mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mi>X</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>X</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="58">式中:<i>X</i><sub>1</sub>、<i>X</i><sub>2</sub>分别是不同时相的输入图像<i>I</i><sub>1</sub>、<i>I</i><sub>2</sub>经过邻域均值化处理的结果图像。<i>Y</i>是<i>X</i><sub>1</sub>、<i>X</i><sub>2</sub>的对数比图像。</p>
                </div>
                <div class="p1">
                    <p id="59">3) 将对数比图像进行NSST,得到多尺度和多方向的系数。</p>
                </div>
                <div class="p1">
                    <p id="60"><i>C</i><sub>0</sub>=<i>NSST</i>_<i>DEC</i>(<i>Y</i>)      (8)</p>
                </div>
                <div class="p1">
                    <p id="61">4) 对多尺度和多方向的系数进行滤波处理。</p>
                </div>
                <div class="p1">
                    <p id="62"><i>C</i><sub>1</sub>=<i>Coeffs</i>_<i>denoise</i>(<i>C</i><sub>0</sub>)      (9)</p>
                </div>
                <div class="p1">
                    <p id="63">首先进行全局滤波。将所有尺度、所有方向的系数中按绝对值大小从大到小排列,将排在最后的10%的相对较小的系数设置为0。</p>
                </div>
                <div class="p1">
                    <p id="64"><i>σ</i>=<i>estimate</i>(<i>C</i><sub>1</sub>)      (10)</p>
                </div>
                <div class="p1">
                    <p id="65"><i>C</i><sub>2</sub>=<i>NSST</i>_<i>HT</i>(<i>C</i><sub>1</sub>,<i>σ</i>)      (11)</p>
                </div>
                <div class="p1">
                    <p id="66">然后进行每个方向、每个尺度的局部滤波。按照式(10)用所有方向、所有尺度的系数进行噪声估计。根据式(11)将每个尺度、每个方向的系数分别采用硬阈值去噪。</p>
                </div>
                <div class="p1">
                    <p id="67">5) 对滤波后的系数进行非下采样Shearlet逆变换。</p>
                </div>
                <div class="p1">
                    <p id="68"><i>Z</i>=<i>NSST</i>_<i>REC</i>(<i>C</i><sub>2</sub>)      (12)</p>
                </div>
                <div class="p1">
                    <p id="69">6) 用自适应脉冲耦合神经网络对非下采样Shearlet逆变换结果进行2类分类,从而得到最终的变化有效检测结果图。</p>
                </div>
                <div class="p1">
                    <p id="70"><i>CM</i>=<i>APCNN</i>(<i>Z</i>)      (13)</p>
                </div>
                <h3 id="71" name="71" class="anchor-tag"><b>2 实 验</b></h3>
                <h4 class="anchor-tag" id="72" name="72"><b>2.1 实验数据</b></h4>
                <div class="p1">
                    <p id="73">为了比较与测试算法性能,用两组遥感图片进行对比实验。图2(a)和图2(b)的图片组分别是1997年5月和1997年8月航拍的,地点是渥太华。图3(a)和图3(b)的图片组分别是1996年8月24日和1999年8月14日航拍的,地点是越南红河。图2(c)和图3(c)分别是渥太华和越南红河地区的真实变化情况图。每组三幅影像都裁切成256×256的大小。图2的实验图片在实验表格中记作T1,图3的实验图片在实验表格中记作T2。</p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 渥太华" src="Detail/GetImg?filename=images/JYRJ201910036_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 渥太华  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="155">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_15500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 越南红河" src="Detail/GetImg?filename=images/JYRJ201910036_15500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 越南红河  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_15500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="78" name="78"><b>2.2 视觉定性比较</b></h4>
                <div class="p1">
                    <p id="79">比较算法是PCANet<citation id="141" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、NR-ELM<citation id="142" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和FDA-RMG<citation id="143" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>给出的,本文算法简称为NSST-APCNN。</p>
                </div>
                <div class="p1">
                    <p id="80">首先进行视觉定性比较。渥太华地区算法结果如图4所示。越南红河地区算法结果如图5所示。图4(d)的噪声点比图4(a)、图4(c)略好,比图4(b)好得多。图5(d)的噪声点比图5(a)略好,比图5(b)、图5(c)好得多。由图4和图5可知,本文算法的检测精度比PCANet、FDA-RMG略高,比NR-ELM高。</p>
                </div>
                <div class="area_img" id="156">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 渥太华不同检测方法结果比较图" src="Detail/GetImg?filename=images/JYRJ201910036_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 渥太华不同检测方法结果比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_15600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="157">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_15700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 越南红河不同检测方法结果比较图" src="Detail/GetImg?filename=images/JYRJ201910036_15700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 越南红河不同检测方法结果比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_15700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>2.3 抗噪能力量化比较</b></h4>
                <div class="p1">
                    <p id="86">输入影像<i>I</i>,其尺寸为<i>H</i>×<i>W</i>。对其添加斑点噪声,抑或添加白噪声,合成加噪图像<i>I</i>′。加噪前后,这幅影像所获得的噪声改变可以用峰值信噪比来描述,其定义为:</p>
                </div>
                <div class="p1">
                    <p id="87" class="code-formula">
                        <mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>S</mi><mi>Ν</mi><mi>R</mi><mo>=</mo><mn>1</mn><mn>0</mn><mrow><mi>lg</mi></mrow><mrow><mo>(</mo><mrow><mfrac><mrow><mi>Η</mi><mo>×</mo><mi>W</mi><mo>×</mo><mn>2</mn><mn>5</mn><mn>5</mn><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>W</mi></munderover><mo stretchy="false">(</mo></mstyle></mrow></mstyle><mi>Ι</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>-</mo><msup><mi>Ι</mi><mo>′</mo></msup><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>)</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="88">算法的抗噪能力可由加入噪声前后导致检测结果发生变化的程度来衡量,变化程度越小,算法越稳定,说明算法的抗噪能力越好。对于不同时相的两幅大小均为<i>H</i>×<i>W</i>的输入遥感图片<i>I</i><sub>1</sub>和<i>I</i><sub>2</sub>,对<i>I</i><sub>1</sub>(也可以对<i>I</i><sub>2</sub>)添加一定程度的某种噪声得到<i>I</i>′<sub>1</sub>。输入<i>I</i><sub>1</sub>和<i>I</i><sub>2</sub>,经过某种算法处理得到没有添加噪声的检测结果<i>CM</i>;输入<i>I</i>′<sub>1</sub>和<i>I</i><sub>2</sub>,经过同一算法处理得到添加噪声的检测结果<i>CM</i>′。这部分实验进行抗噪能力的量化比较。算法的抗噪能力可由下式计算得出<citation id="144" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="89" class="code-formula">
                        <mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>τ</mi><mo>=</mo><mn>1</mn><mo>-</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Η</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>W</mi></munderover><mrow><mrow><mo>|</mo><mrow><mi>C</mi><mi>Μ</mi><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mo>-</mo><mi>C</mi><msup><mi>Μ</mi><mo>′</mo></msup><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></mstyle></mrow><mrow><mi>Η</mi><mo>×</mo><mi>W</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="90">由图6和图7可知,对于斑点噪声,在<i>PSNR</i>∈[26,51]dB,在抗噪能力方面,本文算法比PCANet、FDA-RMG略高,比NR-ELM高。由图8和图9知,对于白噪声,在<i>PSNR</i>∈[35,50]dB,在抗噪能力方面,本文算法比PCANet、FDA-RMG略高,比NR-ELM高。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 渥太华不同强度斑点噪声抗噪比较图" src="Detail/GetImg?filename=images/JYRJ201910036_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 渥太华不同强度斑点噪声抗噪比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 越南红河不同强度斑点噪声抗噪比较图" src="Detail/GetImg?filename=images/JYRJ201910036_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 越南红河不同强度斑点噪声抗噪比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="93">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 渥太华不同强度白噪声抗噪比较图" src="Detail/GetImg?filename=images/JYRJ201910036_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 渥太华不同强度白噪声抗噪比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_093.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="94">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201910036_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图9 越南红河不同强度白噪声抗噪比较图" src="Detail/GetImg?filename=images/JYRJ201910036_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图9 越南红河不同强度白噪声抗噪比较图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201910036_094.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="95">综上所述,对于白噪声和斑点噪声,在峰值信噪比不小于35 dB、不大于50 dB区域内,NSST-APCNN的抗噪能力比FDA-RMG、PCANet略高,比NR-ELM高。</p>
                </div>
                <h4 class="anchor-tag" id="96" name="96"><b>2.4 错误总量OE量化比较</b></h4>
                <div class="p1">
                    <p id="97">对于不同时相的两幅大小均为<i>H</i>×<i>W</i>的输入遥感图片<i>I</i><sub>1</sub>和<i>I</i><sub>2</sub>,地面变化参考图记作<i>GT</i>,算法的检测图记作<i>CM</i>。在检测结果中为1而在变化参考图中为0的数量就是虚警,记作<i>FP</i>。在检测结果中为0而在变化参考图中为1的数量就是漏警,记作<i>FN</i>。在检测结果中为1而在变化参考图中为1的数量就是正确检测出了变化类,记作<i>TP</i>。在检测结果中为0而在变化参考图中为0的数量就是正确检测出了未变化类,记作<i>TN</i>。</p>
                </div>
                <div class="p1">
                    <p id="98"><i>FP</i>=Count(<i>CM</i>==1 &amp;&amp; <i>GT</i>==0)      (16)</p>
                </div>
                <div class="p1">
                    <p id="99"><i>FN</i>=Count(<i>CM</i>==0 &amp;&amp; <i>GT</i>==1)      (17)</p>
                </div>
                <div class="p1">
                    <p id="100"><i>TP</i>=Count(<i>CM</i>==1 &amp;&amp; <i>GT</i>==1)      (18)</p>
                </div>
                <div class="p1">
                    <p id="101"><i>TN</i>=Count(<i>CM</i>==0 &amp;&amp; <i>GT</i>==0)      (19)</p>
                </div>
                <div class="p1">
                    <p id="102"><i>OE</i>=<i>FP</i>+<i>FN</i>      (20)</p>
                </div>
                <div class="p1">
                    <p id="103">总的错误数量<i>OE</i><citation id="145" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>是变化有效检测算法常用的一项量化比较指标,该指标值越小算法能力越好。算法的错误总量<i>OE</i>量化比较参见表1。可以看出,比较PCANet、NR-ELM、FDA-RMG与NSST-APCNN四种算法,NSST-APCNN算法的<i>OE</i>最小。换言之,就是比较算法的检测错误总量比本文所设计的算法的高。</p>
                </div>
                <div class="area_img" id="104">
                    <p class="img_tit"><b>表1 算法错误总量OE量化比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="104" border="1"><tr><td>图片</td><td>算法</td><td>FP</td><td>FN</td><td>OE</td></tr><tr><td><br />T1</td><td>NSST-APCNN</td><td>272</td><td>699</td><td>971</td></tr><tr><td><br />T1</td><td>PCANet</td><td>463</td><td>897</td><td>1 360</td></tr><tr><td><br />T1</td><td>NR-ELM</td><td>4</td><td>3 644</td><td>3 648</td></tr><tr><td><br />T1</td><td>FDA-RMG</td><td>112</td><td>1 345</td><td>1 457</td></tr><tr><td><br />T2</td><td>NSST-APCNN</td><td>565</td><td>1 427</td><td>1 992</td></tr><tr><td><br />T2</td><td>PCANet</td><td>361</td><td>1 723</td><td>2 084</td></tr><tr><td><br />T2</td><td>NR-ELM</td><td>226</td><td>2 191</td><td>2 417</td></tr><tr><td><br />T2</td><td>FDA-RMG</td><td>16</td><td>2 677</td><td>2 693</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>2.5 总的准确率PCC量化比较</b></h4>
                <div class="p1">
                    <p id="106">总的准确率PCC<citation id="146" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>是变化有效检测算法常用的一项量化比较指标,该指标值越大算法越好。算法总的准确率PCC量化比较参见表2。可以看出,比较PCANet、NR-ELM、FDA-RMG与NSST-APCNN四种算法,NSST-APCNN算法的PCC指标至少高出0.14%。换言之,就是NSST-APCNN的检测精度更高。</p>
                </div>
                <div class="p1">
                    <p id="107"><mathml id="125"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>C</mi><mi>C</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (21)</p>
                </div>
                <div class="area_img" id="108">
                    <p class="img_tit"><b>表2 算法总的准确率PCC量化比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="108" border="1"><tr><td><br />图片</td><td>算法</td><td>PCC/%</td></tr><tr><td><br />T1</td><td>NSST-APCNN</td><td>98.52</td></tr><tr><td><br />T1</td><td>PCANet</td><td>97.92</td></tr><tr><td><br />T1</td><td>NR-ELM</td><td>94.43</td></tr><tr><td><br />T1</td><td>FDA-RMG</td><td>97.78</td></tr><tr><td><br />T2</td><td>NSST-APCNN</td><td>96.96</td></tr><tr><td><br />T2</td><td>PCANet</td><td>96.82</td></tr><tr><td><br />T2</td><td>NR-ELM</td><td>96.31</td></tr><tr><td><br />T2</td><td>FDA-RMG</td><td>95.89</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="109" name="109"><b>2.6 Kappa系数、召回率和F1量化比较</b></h4>
                <div class="p1">
                    <p id="110">在本文这一部分中采用的变化高效检测算法性能的量化比较指标有以下三个: 1) Kappa系数KC<citation id="147" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>,该指标值越大算法性能越好;2) 召回率Recall,该指标值越大算法性能越好;3) F1,该指标值越大算法性能越好。算法的Kappa系数KC、召回率Recall和F1量化比较参见表3。可以看出,与文献<citation id="148" type="reference">[<a class="sup">16</a>]</citation>、文献<citation id="149" type="reference">[<a class="sup">17</a>]</citation>和文献<citation id="150" type="reference">[<a class="sup">18</a>]</citation>所提算法相比,本文设计的算法的KC指标至少高出1.04%,Recall指标至少高出1.74%, F1指标至少高出0.98%。总而言之,NSST-APCNN的检测精度更高。</p>
                </div>
                <div class="p1">
                    <p id="111"><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>R</mi><mi>E</mi><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ν</mi><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi><mo stretchy="false">)</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow></math></mathml>      (22)</p>
                </div>
                <div class="p1">
                    <p id="112"><mathml id="127"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Κ</mi><mi>C</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><mi>C</mi><mi>C</mi><mo>-</mo><mi>Ρ</mi><mi>R</mi><mi>E</mi></mrow><mrow><mn>1</mn><mo>-</mo><mi>Ρ</mi><mi>R</mi><mi>E</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (23)</p>
                </div>
                <div class="p1">
                    <p id="113"><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></math></mathml>      (24)</p>
                </div>
                <div class="p1">
                    <p id="114"><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (25)</p>
                </div>
                <div class="p1">
                    <p id="115"><mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac><mo>×</mo><mn>1</mn><mn>0</mn><mn>0</mn><mi>%</mi></mrow></math></mathml>      (26)</p>
                </div>
                <div class="area_img" id="116">
                    <p class="img_tit"><b>表3 算法Kappa系数、召回率和F1量化比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note">%</p>
                    <table id="116" border="1"><tr><td>图片</td><td>算法</td><td>KC</td><td>Recall</td><td>F1</td></tr><tr><td><br />T1</td><td>NSST-APCNN</td><td>94.77</td><td>93.88</td><td>95.67</td></tr><tr><td><br />T1</td><td>PCANet</td><td>92.68</td><td>92.14</td><td>93.93</td></tr><tr><td><br />T1</td><td>NR-ELM</td><td>77.87</td><td>68.09</td><td>81.00</td></tr><tr><td><br />T1</td><td>FDA-RMG</td><td>91.93</td><td>88.22</td><td>93.26</td></tr><tr><td><br />T2</td><td>NSST-APCNN</td><td>85.95</td><td>83.24</td><td>87.68</td></tr><tr><td><br />T2</td><td>PCANet</td><td>84.91</td><td>79.76</td><td>86.70</td></tr><tr><td><br />T2</td><td>NR-ELM</td><td>81.91</td><td>74.27</td><td>83.95</td></tr><tr><td><br />T2</td><td>FDA-RMG</td><td>79.04</td><td>68.56</td><td>81.26</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="117" name="117"><b>2.7 运行时间量化比较</b></h4>
                <div class="p1">
                    <p id="118">算法运行时间Time(单位:s) 是各类算法常用的一项量化比较指标,该指标值越小算法性能越好。算法运行时间Time量化比较参见表4。可以看出,与文献<citation id="151" type="reference">[<a class="sup">16</a>]</citation>、文献<citation id="152" type="reference">[<a class="sup">17</a>]</citation>和文献<citation id="153" type="reference">[<a class="sup">18</a>]</citation>算法相比,本文算法的运行时间低于比较算法,说明本文算法的时间成本低。</p>
                </div>
                <div class="area_img" id="119">
                    <p class="img_tit"><b>表4 算法运行时间Time量化比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="119" border="1"><tr><td><br />图片</td><td>算法</td><td>时间/s</td></tr><tr><td><br />T1</td><td>NSST-APCNN</td><td>3.96</td></tr><tr><td><br />T1</td><td>PCANet</td><td>23.39</td></tr><tr><td><br />T1</td><td>NR-ELM</td><td>8.41</td></tr><tr><td><br />T1</td><td>FDA-RMG</td><td>22.55</td></tr><tr><td><br />T2</td><td>NSST-APCNN</td><td>4.40</td></tr><tr><td><br />T2</td><td>PCANet</td><td>23.25</td></tr><tr><td><br />T2</td><td>NR-ELM</td><td>7.89</td></tr><tr><td><br />T2</td><td>FDA-RMG</td><td>7.34</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>2.8 实验分析</b></h4>
                <div class="p1">
                    <p id="121">由于充分考虑了邻域信息,有效地降低了虚警数量;由于充分借助NSST的多尺度多方向的分解并结合全局滤波、局部滤波,有效地降低了漏警数量;APCNN具有旋转、平移、尺度不变性和阈值自动确定的特点,有效地提高了算法的准确率和抗噪能力;与此同时,NSST和APCNN的算法复杂度很低,有效地降低了整个算法的复杂性。NSST-APCNN算法较之PCANet、NR-ELM和FDA-RMG算法而言所具有的更强的抗噪能力和更高的检测准确度受益于充分将邻域信息、NSST和APCNN的优势有机紧密融合在一起。与此同时,本文算法具有更低的时间成本。实验证明了本文算法的有效性和可行性。</p>
                </div>
                <h3 id="122" name="122" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="123">NSST-APCNN算法是一种应用于遥感影像的变化高效检测新算法。它既是一种像素级别的算法,也是一种无监督类型的算法。它首次应用于遥感影像的变化有效检测,是基于NSST和APCNN的新算法。PCANet、NR-ELM和FDA-RMG是三个比较算法。由两个地区的对比实验数据结果,结合实验分析得到如下结论:与PCANet、NR-ELM和FDA-RMG相比,不管是斑点噪声还是白噪声, 对于<i>PSNR</i>∈[35,50] dB,本文所设计的算法具有更强的抗噪能力。本文所提的算法的PCC指标至少高出0.14%, KC指标至少高出1.04%,Recall指标至少高出1.74%, F1指标至少高出0.98%。总而言之,NSST-APCNN算法较之于PCANet、NR-ELM和FDA-RMG算法检测精度更高。更重要的是,NSST-APCNN算法具有更低的时间成本。实验结果和实验分析都证明了本文所提算法优越性、可行性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201811006&amp;v=MTg4NzZxQnRHRnJDVVI3cWZadVp0Rnlua1c3ck5MejdCZHJHNEg5bk5ybzlGWW9RS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 王相海,朱毅欢,吕芳,等.基于Cauchy分布的非下采样Shearlet HMT模型及其图像去噪应用[J].计算机学报,2018,41(11):2496-2508.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YGXX201804015&amp;v=Mjk2NTJxNDlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlua1c3ck5QQ3JUZHJHNEg5bk0=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 侯小毛,张群慧,马凌.结合无下采样Shearlet变换和改进尺度积的边缘提取[J].遥感信息,2018,33(4):91-97.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An image enhancement method based on non-subsampled shearlet transform and directional information measurement">

                                <b>[3]</b> Qu Z,Xing Y,Song Y.An image enhancement method based on non-subsampled shearlet transform and directional information measurement[J].Information (Switzerland),2018,9(12):308.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Remote sensing image enhancement based on nonsubsampled shearlet transform and local laplacian filter">

                                <b>[4]</b> Li L,Si Y.Remote sensing image enhancement based on nonsubsampled shearlet transform and local laplacian filter[C]//Proceedings of the 3rd IEEE International Conference on Image,Vision and Computing,ICIVC 2018.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SJSJ201809024&amp;v=MjI2NzVrVzdyTk5pZllaTEc0SDluTXBvOUhZSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeW4=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 韩晶,贾振红,杨杰,等.基于NSST域的引导滤波遥感图像增强方法[J].计算机工程与设计,2018,39(9):2832-2835,2906.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES156FD310A3F8253A4804C55554FD322D&amp;v=MTkxODZOdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJtM3hhMD1OaWZPZmJLOUdLZTRySTVGRmVoNUJINDh6R2NYNGo5NU8zcm5xUmN4RDhhWFI3anJDTw==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Liu Z,Feng Y,Chen H,et al.A fusion algorithm for infrared and visible based on guided filtering and phase congruency in NSST domain[J].Optics &amp; Lasers in Engineering,2017,97:71-77.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESFB1253F3F23DE92481DF2095175F0202&amp;v=Mjk5MzhNeWZNU1VSN3FkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeGJtM3hhMD1OaWZPZmNYS0g5UEpyUGxHRXVrTWVBa3d6UkliNjBzTFNuL3JxUg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Wu W,Qiu Z,Zhao M,et al.Visible and infrared image fusion using NSST and deep Boltzmann machine[J].Optik,2018,157:334-342.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201711011&amp;v=MDI3NjVMRzRIOWJOcm85RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmtXN3JOUHlyZmI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 楼建强,李俊峰,戴文战.非下采样剪切波变换的医学图像融合[J].中国图象图形学报,2017,22(11):1574-1583.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201820030&amp;v=MDIwNzJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmtXN3JOTHo3TWFiRzRIOW5PcjQ5R1pJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 曹义亲,曹婷,黄晓生.基于NSST的CS与区域特性相结合的图像融合方法[J].计算机工程与应用,2018,54(20):190-196.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201804031&amp;v=MDkyOTlOTHo3TWFiRzRIOW5NcTQ5R1pZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmtXN3I=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 王烈,罗文,陈俊鸿,等.自适应PCNN与信息提取的红外与可见光图像融合[J].计算机工程与应用,2018,54(4):192-198.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Remote sensing image segmentation based on a modified pulse coupled neural network">

                                <b>[11]</b> Li S,Hua N.Remote sensing image segmentation based on a modified pulse coupled neural network[C]//Proceedings of the International Symposium on Optoelectronic Technology and Application 2018:Optical Sensing and Imaging Technologies and Applications 2018,OTA 2018.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Remote sensing image fusion via RPCA and adaptive PCNN in NSST domain">

                                <b>[12]</b> Zhang K,Huang Y,Zhao C.Remote sensing image fusion via RPCA and adaptive PCNN in NSST domain[J].International Journal of Wavelets,Multiresolution and Information Processing,2018,16(5):1850037.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Infrared and Visual Image Fusion Based on NSST and Improved PCNN">

                                <b>[13]</b> Li M,Yuan X,Luo Z,et al.Infrared and Visual Image Fusion Based on NSST and Improved PCNN[C]//Proceedings of the 3rd Annual International Conference on Information System and Artificial Intelligence,ISAI 2018.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel remote sensing images fusion algorithm combining extended NSST and modified PCNN">

                                <b>[14]</b> Yang H,Lin L.A novel remote sensing images fusion algorithm combining extended NSST and modified PCNN[C]//Proceedings of the 10th International Conference on Digital Image Processing,ICDIP 2018.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGHW201806020&amp;v=MjQ4OTc3ck5MeXJEZWJHNEg5bk1xWTlIWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlua1c=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 张康,黄永东,王国芬.基于NSST变换与自适应PCNN的多特征遥感图像融合[J].激光与红外,2018,48(6):775-781.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic Change Detection in Synthetic Aperture Radar Imag-es Based on PCANet">

                                <b>[16]</b> Gao F,Dong J,Li B,et al.Automatic Change Detection in Synthetic Aperture Radar Images Based on PCANet[J].IEEE Geoscience and Remote Sensing Letters,2016,13(12):1792-1796.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Change detection from synthetic aperture radar images based on neighborhood-based ratio and extreme learning machine">

                                <b>[17]</b> Gao F,Dong J,Li B,et al.Change detection from synthetic aperture radar images based on neighborhood-based ratio and extreme learning machine[J].Journal of Applied Remote Sensing,2016,10(4):046019.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJEG&amp;filename=SJEGF7D811441243CBF560B9A34C96879B11&amp;v=MTk0MDF0dGh4Ym0zeGEwPU5pZk9hY1cvYXRuTnJvdEJaZWtMRHc5THVSTVY2azEwT1h6bTN4c3pjYldkTjd1ZUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Gao F,Wang X,Dong J,et al.Synthetic aperture radar image change detection based on frequency-domain analysis and random multigraphs[J].Journal of Applied Remote Sensing,2018,12(1):016010.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SAR image change detection based on equal weight image fusion and adaptive threshold in the NSST domain">

                                <b>[19]</b> Wenyan Z,Zhenhong J,Yu Y,et al.SAR image change detection based on equal weight image fusion and adaptive threshold in the NSST domain[J].European Journal of Remote Sensing,2018,51(1):785-794.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201910036" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201910036&amp;v=MDUwMDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5bmtXN3JOTHpUWlpMRzRIOWpOcjQ5R1lvUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdXNzY2Z1OVR2ZlpVSUdIOHYva21ub0pKOEU0cz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
