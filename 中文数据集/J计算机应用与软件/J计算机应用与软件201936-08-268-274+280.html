<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135613117502500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201908046%26RESULT%3d1%26SIGN%3dG32wPxK2ApY4%252ftGVIbqRLxagmbo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908046&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908046&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908046&amp;v=MDI5MDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJTHpUWlpMRzRIOWpNcDQ5QllvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#85" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#90" data-title="&lt;b&gt;1 DPC算法&lt;/b&gt; "><b>1 DPC算法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#119" data-title="&lt;b&gt;2 基于网格划分的密度峰值聚类算法 (G-DPC&lt;/b&gt;)  "><b>2 基于网格划分的密度峰值聚类算法 (G-DPC</b>) </a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#121" data-title="&lt;b&gt;2.1 网格划分&lt;/b&gt;"><b>2.1 网格划分</b></a></li>
                                                <li><a href="#129" data-title="&lt;b&gt;2.2 数据聚类&lt;/b&gt;"><b>2.2 数据聚类</b></a></li>
                                                <li><a href="#159" data-title="&lt;b&gt;2.3 边界点与噪声点的处理&lt;/b&gt;"><b>2.3 边界点与噪声点的处理</b></a></li>
                                                <li><a href="#161" data-title="&lt;b&gt;2.4 算法实现&lt;/b&gt;"><b>2.4 算法实现</b></a></li>
                                                <li><a href="#172" data-title="&lt;b&gt;2.5 高维数据降维方法&lt;/b&gt;"><b>2.5 高维数据降维方法</b></a></li>
                                                <li><a href="#190" data-title="&lt;b&gt;2.6 聚类效果评价指标&lt;/b&gt;"><b>2.6 聚类效果评价指标</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#203" data-title="&lt;b&gt;3 实验仿真&lt;/b&gt; "><b>3 实验仿真</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#204" data-title="&lt;b&gt;3.1 数据测试&lt;/b&gt;"><b>3.1 数据测试</b></a></li>
                                                <li><a href="#223" data-title="&lt;b&gt;3.2 算法分析&lt;/b&gt;"><b>3.2 算法分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#228" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#127" data-title="图1 Birch3的数据分布">图1 Birch3的数据分布</a></li>
                                                <li><a href="#128" data-title="图2 网格划分后的数据分布">图2 网格划分后的数据分布</a></li>
                                                <li><a href="#151" data-title="图3 DPC算法决策图">图3 DPC算法决策图</a></li>
                                                <li><a href="#208" data-title="&lt;b&gt;表1 低维数据集算法效果对比&lt;/b&gt;"><b>表1 低维数据集算法效果对比</b></a></li>
                                                <li><a href="#212" data-title="图4 低维数据集的算法运行时间对比">图4 低维数据集的算法运行时间对比</a></li>
                                                <li><a href="#213" data-title="图5 低维数据集的精确度对比">图5 低维数据集的精确度对比</a></li>
                                                <li><a href="#216" data-title="图6 Birch3数据集聚类结果">图6 Birch3数据集聚类结果</a></li>
                                                <li><a href="#218" data-title="&lt;b&gt;表2 高维数据集信息&lt;/b&gt;"><b>表2 高维数据集信息</b></a></li>
                                                <li><a href="#219" data-title="图7 高维数据集精确度对比图">图7 高维数据集精确度对比图</a></li>
                                                <li><a href="#220" data-title="图8 高维数据集的算法运行时间对比">图8 高维数据集的算法运行时间对比</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Michalski R S, Stepp R E.Learning from Observation:Conceptual Clustering[M].Machine Learning:An Artificial Intelligence Approach, 1983." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning from observation:Conceptual clustering">
                                        <b>[1]</b>
                                         Michalski R S, Stepp R E.Learning from Observation:Conceptual Clustering[M].Machine Learning:An Artificial Intelligence Approach, 1983.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Fukunaue K.Introduction to Statistic Pattern Recognition[M].Academic Press, 1990." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Introduction to statistical pattern recognition">
                                        <b>[2]</b>
                                         Fukunaue K.Introduction to Statistic Pattern Recognition[M].Academic Press, 1990.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Qian W, Zhou A.Analyzing popular clustering algorithms from different viewpoints[J].Journal of Software, 2002, 13 (8) :1382-1394." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200208005&amp;v=MTU5NDJDVVI3cWZadVp0RnlqbVdyM0lOeWZUYkxHNEh0UE1wNDlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         Qian W, Zhou A.Analyzing popular clustering algorithms from different viewpoints[J].Journal of Software, 2002, 13 (8) :1382-1394.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 张琪.基于数据挖掘技术的高炉数据分析[D].马鞍山:安徽工业大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017255379.nh&amp;v=MTYzMjViRzlHOUxMcHBFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJVkYyNkc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         张琪.基于数据挖掘技术的高炉数据分析[D].马鞍山:安徽工业大学, 2017.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Hu W.Improved hierarchical K-means clustering algorithm[J].Computer Engineering and Applications, 2013, 49 (2) :157-159." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201302041&amp;v=MjU2NzN5am1XcjNJTHo3TWFiRzRIOUxNclk5QlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Hu W.Improved hierarchical K-means clustering algorithm[J].Computer Engineering and Applications, 2013, 49 (2) :157-159.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 谢娟英, 鲁肖肖, 屈亚楠, 等.粒计算优化初始聚类中心的K-medoids聚类算法[J].计算机科学与探索, 2015, 9 (5) :611-620." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201505013&amp;v=MjE2NzFNcW85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJTGpYZmZiRzRIOVQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         谢娟英, 鲁肖肖, 屈亚楠, 等.粒计算优化初始聚类中心的K-medoids聚类算法[J].计算机科学与探索, 2015, 9 (5) :611-620.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 范多锋, 徐俊刚.基于划分的聚类分析算法的改进[J].微型机与应用, 2012, 31 (18) :54-56, 59." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201218021&amp;v=MDc5MzFOcDQ5SFpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJTWpYQmQ3RzRIOVA=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         范多锋, 徐俊刚.基于划分的聚类分析算法的改进[J].微型机与应用, 2012, 31 (18) :54-56, 59.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 吴泓辰, 王新军, 成勇, 等.基于协同过滤与划分聚类的改进推荐算法[J].计算机研究与发展, 2011, 48 (S3) :205-212." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ2011S3030&amp;v=MDM2MjR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0lMeXZTZExHNEg5Q3ZySTlHWklRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         吴泓辰, 王新军, 成勇, 等.基于协同过滤与划分聚类的改进推荐算法[J].计算机研究与发展, 2011, 48 (S3) :205-212.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 逯瑞强, 马福民, 张腾飞.基于区间2-型模糊度量的粗糙K-means聚类算法[J].模式识别与人工智能, 2018, 31 (3) :265-274." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201803008&amp;v=MTM1MjlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJS0Q3WWJMRzRIOW5Nckk5RmJJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         逯瑞强, 马福民, 张腾飞.基于区间2-型模糊度量的粗糙K-means聚类算法[J].模式识别与人工智能, 2018, 31 (3) :265-274.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 王涛, 沈谦, 朱明星, 等.遗传与C-均值混合算法用于聚类分析[J].模式识别与人工智能, 1999, 12 (1) :98-103." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB199901014&amp;v=MDIwNTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptV3IzSUtEN1liTEt4RjlqTXJvOUVZSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         王涛, 沈谦, 朱明星, 等.遗传与C-均值混合算法用于聚类分析[J].模式识别与人工智能, 1999, 12 (1) :98-103.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Li X, Jiang S Y, Zhang Q S, et al.A dynamic density-based clustering algorithm appropriate to large-scale text processing[J].Acta Scientiarum Naturalium Universitatis Pekinensis, 2013, 49 (1) :133-139." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJDZ201301021&amp;v=MDMyNzlHRnJDVVI3cWZadVp0RnlqbVdyM0lKeWZQZExHNEg5TE1ybzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         Li X, Jiang S Y, Zhang Q S, et al.A dynamic density-based clustering algorithm appropriate to large-scale text processing[J].Acta Scientiarum Naturalium Universitatis Pekinensis, 2013, 49 (1) :133-139.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 张峻玮, 杨洲.一种基于改进的层次聚类的协同过滤用户推荐算法研究[J].计算机科学, 2014, 41 (12) :176-178." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201412039&amp;v=MTgxNTA1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0lMejdCYjdHNEg5WE5yWTlHYllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         张峻玮, 杨洲.一种基于改进的层次聚类的协同过滤用户推荐算法研究[J].计算机科学, 2014, 41 (12) :176-178.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Ester B M, Kriegel H P, Sander J, et al.A Density Based algorithm for discovering clusters in large spatial databases[C]//Proceedings of International Conference on knowledge Discovery and Data Mining.AAAI, 1996:226-231." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A density-based algorithm for discovering clusters in large spatial databases">
                                        <b>[13]</b>
                                         Ester B M, Kriegel H P, Sander J, et al.A Density Based algorithm for discovering clusters in large spatial databases[C]//Proceedings of International Conference on knowledge Discovery and Data Mining.AAAI, 1996:226-231.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Sander J, Ester M, Kriegel H P, et al.Density Based Clustering in Spatial Databases:The Algorithm GDBSCAN and Its Applications[J].Data Mining &amp;amp;Knowledge Discovery, 1998, 2 (2) :169-194." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002157171&amp;v=MTM2MTE3UjdxZForWnVGaXZsVTd6QklsND1OajdCYXJPNEh0SE9yb3BDWmV3T1kzazV6QmRoNGo5OVNYcVJyeG94Y01I&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Sander J, Ester M, Kriegel H P, et al.Density Based Clustering in Spatial Databases:The Algorithm GDBSCAN and Its Applications[J].Data Mining &amp;amp;Knowledge Discovery, 1998, 2 (2) :169-194.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Ankerst M, Breuniu M M, Kriegel H P, et al.OPTICS:Ordering Points to Identify the Clustering Structure[J].Stanford Research Inst Memo Stanford University, 1999, 28 (2) :49-60." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optics: Ordering points to identify the clustering structure">
                                        <b>[15]</b>
                                         Ankerst M, Breuniu M M, Kriegel H P, et al.OPTICS:Ordering Points to Identify the Clustering Structure[J].Stanford Research Inst Memo Stanford University, 1999, 28 (2) :49-60.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Xie J Y, Gao H C, Xie W X, et al.Robust clustering by detecting density peaks and assigning points based on fuzzy weighted K-nearest neighbors[J].Information Sciences, 2016, 354:19-40." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDCAAB7D6814491E651048799347196C0&amp;v=Mjk2MTEwNXR0aHhMdTJ3cWc9TmlmT2ZjZkxiNkMrcVB0RGJPb0xDSFU0dWhBVzZ6OTVRSGpycFJFeGZyT2RROG1mQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Xie J Y, Gao H C, Xie W X, et al.Robust clustering by detecting density peaks and assigning points based on fuzzy weighted K-nearest neighbors[J].Information Sciences, 2016, 354:19-40.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Sheikhleslami G, Chatterjee S, Zhanu A.Wave Cluster:A Multi-Resolution Clustering Approach for Very Large Spatial Databases[C]//International Conference on Very Large Data Bases.Morgan Kaufmann Publishers Inc.1998:428-439." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=WaveCluster: A multi-resolution clustering approach for very large spatial databases">
                                        <b>[17]</b>
                                         Sheikhleslami G, Chatterjee S, Zhanu A.Wave Cluster:A Multi-Resolution Clustering Approach for Very Large Spatial Databases[C]//International Conference on Very Large Data Bases.Morgan Kaufmann Publishers Inc.1998:428-439.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Agrawal R, Gehrke J E, Gunopulos D, et al.Automatic subspace clustering of high dimensional data for datamining applications[M]//ACM SIGMOD Record.ACM, 1998:94-105." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000068877&amp;v=MTYyMzhubFVyeklJRjBkYUJJPU5pZklZN0s3SHRqTnI0OUZaTzBIQkhzK29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Agrawal R, Gehrke J E, Gunopulos D, et al.Automatic subspace clustering of high dimensional data for datamining applications[M]//ACM SIGMOD Record.ACM, 1998:94-105.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Wang J, Wang S T, Deng Z H, et al.Survey on challenges in clustering analysis research[J].Control and Decision, 2012, 27 (3) :321-328." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201203002&amp;v=MDczNzJGeWptV3IzSUxqZlNiYkc0SDlQTXJJOUZab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Wang J, Wang S T, Deng Z H, et al.Survey on challenges in clustering analysis research[J].Control and Decision, 2012, 27 (3) :321-328.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" 冯振华, 钱雪忠, 赵娜娜.Greedy DBSCAN:一种针对多密度聚类的DBSCAN改进算法[J].计算机应用研究, 2016 (9) :2693-2696." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201609030&amp;v=MzI2MjFyQ1VSN3FmWnVadEZ5am1XcjNJTHo3U1pMRzRIOWZNcG85R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         冯振华, 钱雪忠, 赵娜娜.Greedy DBSCAN:一种针对多密度聚类的DBSCAN改进算法[J].计算机应用研究, 2016 (9) :2693-2696.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" 谭颖, 胡瑞飞, 殷国富.多密度阈值的DBSCAN改进算法[J].计算机应用, 2008, 28 (3) :745-748." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY200803060&amp;v=MjkwMDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptV3IzSUx6N0JkN0c0SHRuTXJJOURaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         谭颖, 胡瑞飞, 殷国富.多密度阈值的DBSCAN改进算法[J].计算机应用, 2008, 28 (3) :745-748.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" 陈刚, 刘秉权, 吴岩.一种基于高斯分布的自适应DBSCAN算法[J].微电子学与计算机, 2013, 30 (3) :27-30." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201303006&amp;v=Mjg4MjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptV3IzSU1qWFNaTEc0SDlMTXJJOUZZb1FLREg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         陈刚, 刘秉权, 吴岩.一种基于高斯分布的自适应DBSCAN算法[J].微电子学与计算机, 2013, 30 (3) :27-30.
                                    </a>
                                </li>
                                <li id="47">


                                    <a id="bibliography_23" title=" 刘淑芬, 孟冬雪, 王晓燕.基于网格单元的DBSCAN算法[J].吉林大学学报:工学版, 2014 (4) :1135-1139." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201404035&amp;v=MTk4MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0lMeUhNZDdHNEg5WE1xNDlHWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[23]</b>
                                         刘淑芬, 孟冬雪, 王晓燕.基于网格单元的DBSCAN算法[J].吉林大学学报:工学版, 2014 (4) :1135-1139.
                                    </a>
                                </li>
                                <li id="49">


                                    <a id="bibliography_24" title=" Rodriguez A, Liao A.Clustering by fast search and find of density peaks[J].Science, 2014, 344 (6191) :1492-1496." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Clustering by fast search and find of densitypeaks">
                                        <b>[24]</b>
                                         Rodriguez A, Liao A.Clustering by fast search and find of density peaks[J].Science, 2014, 344 (6191) :1492-1496.
                                    </a>
                                </li>
                                <li id="51">


                                    <a id="bibliography_25" title=" Wang W, Yang J, Muntz R R.STING:a statistical information grid approach to spatial data mining[C]//Proceedings of the 23rd International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1997:186-195." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=STING: A statistical information grid approach to spatial data mining">
                                        <b>[25]</b>
                                         Wang W, Yang J, Muntz R R.STING:a statistical information grid approach to spatial data mining[C]//Proceedings of the 23rd International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1997:186-195.
                                    </a>
                                </li>
                                <li id="53">


                                    <a id="bibliography_26" title=" Chen L, Yu T, Chirkova R.Wave cluster with differential privacy[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.New York:ACM, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wave cluster with differential privacy">
                                        <b>[26]</b>
                                         Chen L, Yu T, Chirkova R.Wave cluster with differential privacy[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.New York:ACM, 2015.
                                    </a>
                                </li>
                                <li id="55">


                                    <a id="bibliography_27" title=" Xu W H, Chang Y, Qin Z.A Framework for Classifying Uncertain and Evolving Data Streams[J].Information Technology Journal, 2011, 10 (10) :1926-1933." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A framework for classifying uncertain and evolving data streams">
                                        <b>[27]</b>
                                         Xu W H, Chang Y, Qin Z.A Framework for Classifying Uncertain and Evolving Data Streams[J].Information Technology Journal, 2011, 10 (10) :1926-1933.
                                    </a>
                                </li>
                                <li id="57">


                                    <a id="bibliography_28" title=" Mehmood R, Bie R, Dawood H, et al.Fuzzy clustering by fast search and find of density peaks[C]//International Conference on Identification, Information, and Knowledge in the Internet of Things.IEEE, 2016:258-261." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fuzzy clustering by fast search and find of density peaks">
                                        <b>[28]</b>
                                         Mehmood R, Bie R, Dawood H, et al.Fuzzy clustering by fast search and find of density peaks[C]//International Conference on Identification, Information, and Knowledge in the Internet of Things.IEEE, 2016:258-261.
                                    </a>
                                </li>
                                <li id="59">


                                    <a id="bibliography_29" title=" 马春来, 单洪, 马涛.一种基于簇中心点自动选择策略的密度峰值聚类算法[J].计算机科学, 2016 (7) :255-258." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201607049&amp;v=MjMxMzVxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJTHo3QmI3RzRIOWZNcUk5QmJZUUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[29]</b>
                                         马春来, 单洪, 马涛.一种基于簇中心点自动选择策略的密度峰值聚类算法[J].计算机科学, 2016 (7) :255-258.
                                    </a>
                                </li>
                                <li id="61">


                                    <a id="bibliography_30" title=" 王建忠.高维数据几何结构及降维[M].北京:高等教育出版社, 2012." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787040317046001&amp;v=MjgxNjBYRnF6R2JPOEh0TE5xSTlCWXVzUERSTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2RnlubVU3L0xLVndV&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[30]</b>
                                         王建忠.高维数据几何结构及降维[M].北京:高等教育出版社, 2012.
                                    </a>
                                </li>
                                <li id="63">


                                    <a id="bibliography_31" title=" Tenenbaum J B.A Global Geometric Framework for Nonlinear Dimensionality Reduction[J].Science, 2000, 290 (5500) :2319-2323." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A global geometric framework for nonlinear dimensionality reduction">
                                        <b>[31]</b>
                                         Tenenbaum J B.A Global Geometric Framework for Nonlinear Dimensionality Reduction[J].Science, 2000, 290 (5500) :2319-2323.
                                    </a>
                                </li>
                                <li id="65">


                                    <a id="bibliography_32" title=" Roweis S T.Nonlinear Dimensionality Reduction by Locally Linear Embedding[J].Science, 2000, 290 (5500) :2323-2326." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">
                                        <b>[32]</b>
                                         Roweis S T.Nonlinear Dimensionality Reduction by Locally Linear Embedding[J].Science, 2000, 290 (5500) :2323-2326.
                                    </a>
                                </li>
                                <li id="67">


                                    <a id="bibliography_33" title=" Saul L K, Roweis S T.Think Globally, Fit Locally:Unsupervised Learning of Low Dimensional Manifold[J].Journal of Machine Learning Research, 2003, 4 (2) :119-155." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Think globally, fit locally: unsupervised learning of low dimensional manifolds">
                                        <b>[33]</b>
                                         Saul L K, Roweis S T.Think Globally, Fit Locally:Unsupervised Learning of Low Dimensional Manifold[J].Journal of Machine Learning Research, 2003, 4 (2) :119-155.
                                    </a>
                                </li>
                                <li id="69">


                                    <a id="bibliography_34" title=" Belkin M, Niyogi P.Laplacian Eigenmaps for Dimensionality Reduction and Data Representation[J].Neural Computation, 2003, 15 (6) :1373-1396." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012194&amp;v=MjE3OTdSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlGMGRhQkk9TmlmSlpiSzlIdGpNcW85RlpPb05EWFU5b0JNVDZUNFBRSC9pcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[34]</b>
                                         Belkin M, Niyogi P.Laplacian Eigenmaps for Dimensionality Reduction and Data Representation[J].Neural Computation, 2003, 15 (6) :1373-1396.
                                    </a>
                                </li>
                                <li id="71">


                                    <a id="bibliography_35" title=" Vinh N X, Epps J, Bailey J.Information theoretic measures for clusterings comparison:is a correction for chance necessary?[C]//Proceedings of the 26th Annual International Conference on Machine Learning.ACM, 2009:1073-1080." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Information theoretic measures for clusterings comparison:is a correction for chance necessary?">
                                        <b>[35]</b>
                                         Vinh N X, Epps J, Bailey J.Information theoretic measures for clusterings comparison:is a correction for chance necessary?[C]//Proceedings of the 26th Annual International Conference on Machine Learning.ACM, 2009:1073-1080.
                                    </a>
                                </li>
                                <li id="73">


                                    <a id="bibliography_36" title=" Zahn C T.Graph-Theoretical Methods for Detecting and Describing Gestalt Clusters[J].IEEE Transactions on Computers, 1971, C-20 (1) :68-86." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Graph-theoretical methods for detecting and describing gestalt clusters">
                                        <b>[36]</b>
                                         Zahn C T.Graph-Theoretical Methods for Detecting and Describing Gestalt Clusters[J].IEEE Transactions on Computers, 1971, C-20 (1) :68-86.
                                    </a>
                                </li>
                                <li id="75">


                                    <a id="bibliography_37" title=" Gionis A, Mannila H, Tsaparas P.Clustering aggregation[J].ACM Transactions on Knowledge Discovery from Data, 2007, 1 (1) :4." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000093142&amp;v=MDE1NDd0RmlubFVyeklJRjBkYUJJPU5pZklZN0s3SHRqTnI0OUZaT0lNRFhnN29CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[37]</b>
                                         Gionis A, Mannila H, Tsaparas P.Clustering aggregation[J].ACM Transactions on Knowledge Discovery from Data, 2007, 1 (1) :4.
                                    </a>
                                </li>
                                <li id="77">


                                    <a id="bibliography_38" title=" Kim P, Kim S.Detecting overlapping and hierarchical communities in complex network using interaction-based edge clustering[J].Physica A Statistical Mechanics &amp;amp; Its Applications, 2015, 417 (C) :46-56." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600662698&amp;v=MDY5MTl0RmlubFVyeklJRjBkYUJJPU5pZk9mYks5SDlQT3FZOUZZdTBOQ25VeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[38]</b>
                                         Kim P, Kim S.Detecting overlapping and hierarchical communities in complex network using interaction-based edge clustering[J].Physica A Statistical Mechanics &amp;amp; Its Applications, 2015, 417 (C) :46-56.
                                    </a>
                                </li>
                                <li id="79">


                                    <a id="bibliography_39" title=" Lancichinetti A, Fortunato S, Kertesz J.Detecting the overlapping and hierarchical community structure in complex networks[J].New Journal of Physics, 2009, 11 (3) :033015." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPD00000024572&amp;v=MDUzNzdpVGJhck80SHRITXI0MUJZZXdOWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXZsVTd6QklsND1O&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[39]</b>
                                         Lancichinetti A, Fortunato S, Kertesz J.Detecting the overlapping and hierarchical community structure in complex networks[J].New Journal of Physics, 2009, 11 (3) :033015.
                                    </a>
                                </li>
                                <li id="81">


                                    <a id="bibliography_40" title=" Karypis G, Han E H, Kumar V.Chameleon:hierarchical clustering using dynamic modeling[J].Computer, 1999, 32 (8) :68-75." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Chameleon: Hierarchical Clustering Using Dynamic Modeling">
                                        <b>[40]</b>
                                         Karypis G, Han E H, Kumar V.Chameleon:hierarchical clustering using dynamic modeling[J].Computer, 1999, 32 (8) :68-75.
                                    </a>
                                </li>
                                <li id="83">


                                    <a id="bibliography_41" title=" Zhang T, Ramakrishnan R, Livny M.BIRCH:A new data clustering algorithm and its applications[J].Data Mining and Knowledge Discovery, 1997, 1 (2) :141-182." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002157106&amp;v=MTEzODNsVTd6QklsND1OajdCYXJPNEh0SE9yb3BDWmVzSlkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1Rml2&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[41]</b>
                                         Zhang T, Ramakrishnan R, Livny M.BIRCH:A new data clustering algorithm and its applications[J].Data Mining and Knowledge Discovery, 1997, 1 (2) :141-182.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(08),268-274+280 DOI:10.3969/j.issn.1000-386x.2019.08.045            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于网格划分的密度峰值聚类改进算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%B1%9F%E5%B9%B3%E5%B9%B3&amp;code=42373486&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">江平平</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E5%BA%86%E9%B9%8F&amp;code=11392273&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曾庆鹏</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E6%98%8C%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0252160&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南昌大学信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对密度峰值聚类 (Density Peak Clustering, DPC) 算法具有时空复杂度高而降低了对大规模数据集聚类的有效性, 以及依靠决策图人工选取聚类中心等缺点, 提出基于网格的密度峰值聚类 (G-DPC) 算法。采用基于网格的方式进行网格划分, 用网格代表点替换网格单元整体;对各代表点聚类, 通过改进的自适应方法选出核心网格代表点作为聚类中心;将剩余点归类, 剔除噪声点。仿真实验验证了该算法对大规模数据集和高维数据集聚类的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AF%86%E5%BA%A6%E5%B3%B0%E5%80%BC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">密度峰值;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%BD%91%E6%A0%BC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">网格;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚类算法;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    江平平, 硕士生, 主研领域:网络, 信息安全。;
                                </span>
                                <span>
                                    曾庆鹏, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-11</p>

                    <p>

                            <b>基金：</b>
                                                        <span>江西省自然科学基金项目 (20171BAB202027);</span>
                    </p>
            </div>
                    <h1><b>AN IMPROVED DENSITY PEAK CLUSTERING ALGORITHM BASED ON GRID</b></h1>
                    <h2>
                    <span>Jiang Pingping</span>
                    <span>Zeng Qingpeng</span>
            </h2>
                    <h2>
                    <span>School of Information Engineering, Nanchang University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The high spatial complexity of density peak clustering algorithm (DPC) reduces the validity of large data clustering, and the cluster center needs to be manually selected by decision graph. To solve these problems, we proposed an improved DPC algorithm based on grid (G-DPC) . This algorithm adopted the grid clustering algorithm to divide the grid and replaced the grid cell with grid representative point. Then, all grid representative points were clustered, and the core grid representative points were selected as the cluster center by the improved adaptive method. Finally, the remaining points were classified and the noise points were eliminated. Simulation results show that the algorithm is effective for large data sets and high dimensional data clustering.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Density%20peaks&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Density peaks;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Grid&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Grid;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Clustering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Clustering;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-11</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="85" name="85" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="86">聚类分析作为数据挖掘技术中有力的工具之一, 其应用范围普及较广, 关联机器学习<citation id="230" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、模式识别<citation id="231" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>、数据分析、图像处理和市场研究<citation id="232" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等多个领域。聚类分析的目是将有差异的对象集合划分到不同的类或簇中, 相似对象的集合划为同一类, 且不同类中的对象差别较大<citation id="233" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="87">聚类算法大体上可分为:基于划分的方法<citation id="245" type="reference"><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><link href="19" rel="bibliography" /><link href="21" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>,<a class="sup">10</a>]</sup></citation>;基于层次的方法<citation id="246" type="reference"><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><sup>[<a class="sup">11</a>,<a class="sup">12</a>]</sup></citation>;基于密度的方法如DBSCAN<citation id="234" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>、GDBSCAN<citation id="235" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>和OPTICS<citation id="236" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>等;基于网格的方法如STING<citation id="237" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>、WavcClustcr<citation id="238" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>和Clique<citation id="239" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>等;基于模型的方法<citation id="240" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>等。不同的聚类算法各有其优缺点, 如基于密度的DBSCAN算法具有处理任意形状的簇类以及对噪音点进行过滤等长处, 然而该算法需耗费大量时间和空间对距离矩阵进行计算, 且对输入参数较为敏感。因此, 各学者提出了众多改进方法<citation id="247" type="reference"><link href="41" rel="bibliography" /><link href="43" rel="bibliography" /><link href="45" rel="bibliography" /><link href="47" rel="bibliography" /><sup>[<a class="sup">20</a>,<a class="sup">21</a>,<a class="sup">22</a>,<a class="sup">23</a>]</sup></citation>。文献<citation id="241" type="reference">[<a class="sup">20</a>]</citation>和文献<citation id="242" type="reference">[<a class="sup">21</a>]</citation>对半径参数进行自适应改进, 但领域密度阈值仍需靠经验方法选取;文献<citation id="243" type="reference">[<a class="sup">22</a>]</citation>解决的参数选择困难的缺陷, 但时间开销较大;文献<citation id="244" type="reference">[<a class="sup">23</a>]</citation>提高了运行效率, 但对于多维数据集的处理存在局限性。</p>
                </div>
                <div class="p1">
                    <p id="88">Alex <citation id="249" type="reference"><link href="49" rel="bibliography" />Rodriguez和Alessandro Laio于2014</citation>年在《Science》杂志上发表的基于密度峰值聚类算法DPC<citation id="248" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>能够处理任意形状的簇、能将数据点准确归类, 并除去噪声点。然而该算法时空复杂度高, 且对一些较为复杂的数据集, 难以准确地依据决策图人工选取聚类中心。</p>
                </div>
                <div class="p1">
                    <p id="89">针对DPC算法聚类时空复杂度高, 无法有效处理大数据集且需人工选取聚类中心的问题。本文提出一种改良的基于网格的密度峰值聚类算法, 先对网格代表点进行聚类, 自动确定聚类中心;之后将非核心代表点和各网格中数据点进行归类;最后对边界的代表点和噪声点进行处理完成聚类。</p>
                </div>
                <h3 id="90" name="90" class="anchor-tag"><b>1 DPC算法</b></h3>
                <div class="p1">
                    <p id="91">快速搜索和发现密度峰值聚类算法DPC的聚类中心具有两个特征:1) 数据点自身的局部密度大;2) 局部密度大的点相对之间的间隔较远。对于各数据点 <i>x</i><sub><i>i</i></sub>皆需计算其局部密度<i>ρ</i><sub><i>i</i></sub>以及高局部密度距离<i>δ</i><sub><i>i</i></sub>, 通过这个两个值来构建决策图<citation id="250" type="reference"><link href="49" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>, 人工选取<i>ρ</i><sub><i>i</i></sub>和<i>δ</i><sub><i>i</i></sub>相对大的点作为聚类中心, 然后将其他数据点归类并剔除噪声点。</p>
                </div>
                <div class="p1">
                    <p id="92"><b>定义1</b> 局部密度:一个数据点一定半径内其他点的个数。点<i>x</i><sub><i>i</i></sub>的局部密度<i>ρ</i><sub><i>i</i></sub>为:</p>
                </div>
                <div class="p1">
                    <p id="93"><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi>χ</mi></mstyle><mo stretchy="false"> (</mo><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>d</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="95">式中:<i>d</i><sub><i>ij</i></sub>=<i>dist</i> (<i>x</i><sub><i>i</i></sub>, <i>x</i><sub><i>j</i></sub>) 代表<i>x</i><sub><i>i</i></sub>和<i>x</i><sub><i>j</i></sub>的距离, <i>d</i><sub>c</sub>为所有样本点间距离的最小2%的距离中的最大距离。函数<i>χ</i> (<i>x</i>) 定义如下:</p>
                </div>
                <div class="area_img" id="96">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201908046_09600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="98">当数据点为连续时, 局部密度<i>ρ</i><sub><i>i</i></sub>为:</p>
                </div>
                <div class="p1">
                    <p id="99"><mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mtext>e</mtext></mstyle><msup><mrow></mrow><mrow><mo>-</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>d</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><mrow><mi>d</mi><msub><mrow></mrow><mtext>c</mtext></msub></mrow></mfrac></mrow><mo>) </mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></msup></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="101">式中:参数<i>d</i><sub>c</sub>&gt;0, 为截断距离, 需要人工指定。</p>
                </div>
                <div class="p1">
                    <p id="102"><b>定义2</b> 高密度距离:比自身局部密度高的点中, 与离自身最近的那个点之间的距离。对于任一点<i>x</i><sub><i>i</i></sub>的高密度距离<i>δ</i><sub><i>i</i></sub>为:</p>
                </div>
                <div class="area_img" id="103">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201908046_10300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="105">式中:对应指标集<i>I</i><sub>S</sub>定义为:</p>
                </div>
                <div class="p1">
                    <p id="106"><i>I</i><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mtext>S</mtext><mi>i</mi></msubsup></mrow></math></mathml>={<i>k</i>∈<i>I</i><sub>S</sub>:<i>ρ</i><sub><i>k</i></sub>&gt;<i>ρ</i><sub><i>i</i></sub>}      (5) </p>
                </div>
                <div class="p1">
                    <p id="108">DPC算法特征值<i>ρ</i><sub><i>i</i></sub>和<i>δ</i><sub><i>i</i></sub>画出决策图, 人工选出这两个数值都相对较高的数据点作为聚类中心, 将剩余点按局部密度倒序排序, 依次归入局部密度更大且距离最近的数据点所在类中。</p>
                </div>
                <div class="p1">
                    <p id="109"><b>定义3</b> 边界点:如果一个已分配的数据点与其他类中的点的距离在阶段距离<i>d</i><sub><i>c</i></sub>内, 则该点为边界点。</p>
                </div>
                <div class="p1">
                    <p id="110">DPC算法的最后一步是对边界点的处理, 利用密度参数<i>d</i><sub>c</sub>算出类边界点集, 然后指定边界点集中密度最高点的密度值作为划分核心点和噪音点的阈值。DPC算法步骤:</p>
                </div>
                <div class="p1">
                    <p id="111"> (1) 初始化参数<i>d</i><sub>c</sub>;</p>
                </div>
                <div class="p1">
                    <p id="112"> (2) 根据式 (1) 计算数据点的局部密度<i>ρ</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="113"> (3) 按局部密度<i>ρ</i><sub><i>i</i></sub>倒序排序;</p>
                </div>
                <div class="p1">
                    <p id="114"> (4) 根据式 (4) 计算数据点的相对距离<i>δ</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="115"> (5) 构建基于<i>ρ</i><sub><i>i</i></sub>和<i>δ</i><sub><i>i</i></sub>的决策图, 并手动选取聚类中心点;</p>
                </div>
                <div class="p1">
                    <p id="116"> (6) 将剩余非聚类中心点归类;</p>
                </div>
                <div class="p1">
                    <p id="117"> (7) 对边界点处理, 检测噪声点。</p>
                </div>
                <div class="p1">
                    <p id="118">DPC算法具有可发现非球形簇, 所需参数少, 无需进行迭代等优点。然而该算法同时也存在处理大规模数据集时运行时间过长, 耗费内存空间过大, 人工难以准确地选取聚类中心等缺陷。</p>
                </div>
                <h3 id="119" name="119" class="anchor-tag"><b>2 基于网格划分的密度峰值聚类算法 (G-DPC</b>) </h3>
                <div class="p1">
                    <p id="120">针对DPC算法时空复杂度高以及人工选取聚类中心易造成偏差的问题, 本文提出了一种改进的基于网格划分的密度峰值聚类算法G-DPC。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121"><b>2.1 网格划分</b></h4>
                <div class="p1">
                    <p id="122"><b>定义4</b> 网格边长:假定存在一个<i>d</i>维数据集<i>X</i>={<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>n</i></sub>}, <i>n</i>∈<i>N</i><sup>+</sup>, <i>x</i><sub><i>i</i></sub>∈<i>R</i><sup><i>d</i></sup>。属性 (<i>A</i><sub>1</sub>, <i>A</i><sub>2</sub>, …, <i>A</i><sub><i>d</i></sub>) 都是有界的, 设第<i>i</i>维上的值在范围[<i>l</i><sub><i>i</i></sub>, <i>h</i><sub><i>i</i></sub>) 中, <i>i</i>=1, 2, …, <i>d</i>, 则<i>S</i>=[[<i>l</i><sub>1</sub>, <i>h</i><sub>1</sub>) ×[<i>l</i><sub>2</sub>, <i>h</i><sub>2</sub>) ×…×[<i>l</i><sub><i>d</i></sub>, <i>h</i><sub><i>d</i></sub>) ]即是<i>d</i>维数据空间。将数据空间各个维度划分成均等且不相交的网格单元<citation id="251" type="reference"><link href="51" rel="bibliography" /><link href="53" rel="bibliography" /><sup>[<a class="sup">25</a>,<a class="sup">26</a>]</sup></citation>。网格边长<i>side</i>计算公式为:</p>
                </div>
                <div class="p1">
                    <p id="123"><mathml id="124"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo>=</mo><mi>α</mi><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>h</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>l</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo>/</mo><mi>n</mi></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mi>d</mi></mfrac></mrow></msup></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="125">式中:ɑ为控制参数, 网格划分边长<i>side</i>的取值会对数据聚类的效果造成影响, 太大会降低聚类精度;太小则影响处理速度。当ɑ∈ (0, 2]时, 算法的聚类效果较好。本文实验中选取ɑ值为1.5。</p>
                </div>
                <div class="p1">
                    <p id="126">例1:图1为Birch3<citation id="252" type="reference"><link href="55" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>的原始数据集分布情况, 若依照式 (6) 对该数据集进行网格划分, 划分后如图2所示, 将网格单元点的统计信息取代原先的数据点, 从而实现数据压缩的效果, 利于选取聚类中心。</p>
                </div>
                <div class="area_img" id="127">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Birch3的数据分布" src="Detail/GetImg?filename=images/JYRJ201908046_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Birch3的数据分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_127.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 网格划分后的数据分布" src="Detail/GetImg?filename=images/JYRJ201908046_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 网格划分后的数据分布  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="129" name="129"><b>2.2 数据聚类</b></h4>
                <h4 class="anchor-tag" id="130" name="130"><b>2.2.1 自动选择聚类中心</b></h4>
                <div class="p1">
                    <p id="131"><b>定义5</b> 网格代表点:假定网格<i>j</i>的中心点为<i>g</i><sub><i>j</i></sub>= (<i>g</i><mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mn>1</mn></msubsup></mrow></math></mathml>, <i>g</i><mathml id="133"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup></mrow></math></mathml>, …, <i>g</i><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>d</mi></msubsup></mrow></math></mathml>) , <i>j</i>=1, 2, …, <i>K</i>, <i>K</i>为网格的总个数, 其中<i>g</i><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>j</mi><mi>d</mi></msubsup></mrow></math></mathml>表示在<i>d</i>维上网格<i>j</i>的中心点的坐标, 因此网格<i>G</i><sub><i>j</i></sub>可表示为:</p>
                </div>
                <div class="p1">
                    <p id="136" class="code-formula">
                        <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>G</mi><mo>=</mo><mrow><mo> (</mo><mrow><mrow><mo>[</mo><mrow><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mn>1</mn></msubsup><mo>-</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac><mo>, </mo><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mn>1</mn></msubsup><mo>+</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac></mrow><mo>]</mo></mrow><mo>, </mo><mrow><mo>[</mo><mrow><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup><mo>-</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac><mo>, </mo><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mn>2</mn></msubsup><mo>+</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac></mrow><mo>]</mo></mrow><mo>, </mo><mo>⋯</mo><mo>, </mo></mrow></mrow></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mrow><mrow><mrow><mo>[</mo><mrow><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mi>d</mi></msubsup><mo>-</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac><mo>, </mo><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mi>d</mi></msubsup><mo>+</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac></mrow><mo>]</mo></mrow></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="137">网格<i>j</i>中点的集合为<i>P</i>={<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>l</i><sub><i>j</i></sub></sub>}, <i>l</i><sub><i>j</i></sub>为该网格<i>j</i>内数据点的总个数。则该网格的代表点为:</p>
                </div>
                <div class="p1">
                    <p id="138"><mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>G</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mi>x</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="140"><b>定义6</b> 代表点局部密度值:网格代表点<i>P</i><sub><i>j</i></sub>的局部密度是网格<i>j</i>内数据点的个数, 网格<i>j</i>中点的个数为:</p>
                </div>
                <div class="p1">
                    <p id="141"><mathml id="142"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>f</mi></mstyle><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>G</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="143">式中:</p>
                </div>
                <div class="p1">
                    <p id="144" class="code-formula">
                        <mathml id="144"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>G</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mtext> </mtext><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mi>h</mi></msubsup><mo>-</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac><mo>≤</mo><mi>x</mi><msubsup><mrow></mrow><mi>i</mi><mi>h</mi></msubsup><mo>&lt;</mo><mi>g</mi><msubsup><mrow></mrow><mi>j</mi><mi>h</mi></msubsup><mo>+</mo><mfrac><mrow><mi>s</mi><mi>i</mi><mi>d</mi><mi>e</mi></mrow><mn>2</mn></mfrac><mo>, </mo><mo>∀</mo><mi>h</mi></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="145">则网格代表点<i>P</i><sub><i>j</i></sub>的局部密度为<i>ρ</i><sub><i>j</i></sub>=<i>l</i><sub><i>j</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="146"><b>定义7</b> 代表点高密度距离值:以网格代表点<i>P</i><sub><i>j</i></sub>更高密度代表点<i>P</i><sub><i>k</i></sub>的最近距离, 作为网格代表点<i>P</i><sub><i>j</i></sub>的距离值, 记为<i>δ</i><sub><i>j</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="147"><mathml id="148"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>δ</mi><msub><mrow></mrow><mi>j</mi></msub><mo>=</mo><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>k</mi><mo>:</mo><mi>ρ</mi><msub><mrow></mrow><mi>k</mi></msub><mo>&gt;</mo><mi>ρ</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></munder><mo stretchy="false"> (</mo><mi>D</mi><msub><mrow></mrow><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="149">式中:<i>D</i><sub><i>kj</i></sub>是网格代表点<i>P</i><sub><i>k</i></sub>与网格代表点<i>P</i><sub><i>j</i></sub>的距离。</p>
                </div>
                <div class="p1">
                    <p id="150">在选取聚类中心时, 文献<citation id="253" type="reference">[<a class="sup">24</a>]</citation>采取对决策图进行观察后再由人工选择中心的方式, 筛选局部密度和高密度距离值均较大的点作为聚类中心, 这种方法在处理数据分布差距大的小规模数据集时较为简单, 然而在处理大规模数据集时, 如图3所示, 决策图中点的分布差距不明显时便难以准确选择聚类中心的数目。</p>
                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 DPC算法决策图" src="Detail/GetImg?filename=images/JYRJ201908046_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 DPC算法决策图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_151.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="152">为解决上述问题, 众多学者提出了解决方案, 例如, 文献<citation id="254" type="reference">[<a class="sup">28</a>]</citation>中的Fuzz-CFSFDP算法使用基于上模糊规则自适应地选择集群中心, 然而该算法同样对参数<i>d</i><sub>c</sub>的取值敏感, 数据集的测试精确度较低;文献<citation id="255" type="reference">[<a class="sup">29</a>]</citation>中采用根据簇中心权值的变化趋势的算法来寻找聚类中心, 该方法虽能有效避免手动选取聚类中心带来的误差, 但只适用于低维数据集分析。本文给出一种改进自适应的方法, 无需人工干预选择确切聚类中心的数量。其判定函数为:</p>
                </div>
                <div class="p1">
                    <p id="153"><i>ρ</i><sub><i>C</i><sub><i>i</i></sub></sub>-<i>μ</i> (<i>ρ</i><sub><i>i</i></sub>) ≥0      (12) </p>
                </div>
                <div class="p1">
                    <p id="154"> (<i>δ</i><sub><i>C</i><sub><i>i</i></sub></sub>-<i>E</i> (<i>δ</i><sub><i>i</i></sub>) ) /2≥<i>σ</i> (<i>δ</i><sub><i>i</i></sub>)      (13) </p>
                </div>
                <div class="p1">
                    <p id="155">式中:<i>ρ</i><sub><i>C</i><sub><i>i</i></sub></sub>是聚类中心网格代表点的密度, <i>μ</i> (<i>ρ</i><sub><i>i</i></sub>) 是所有网格代表点密度的均值, <i>δ</i><sub><i>C</i><sub><i>i</i></sub></sub>是同一个类簇中网格代表点距聚类中心代表点最小的距离, <i>E</i> (<i>δ</i><sub><i>i</i></sub>) 是所有<i>δ</i><sub><i>i</i></sub>的期望。式 (12) 表示该网格代表点的局部密度值大于所有网格代表点局部密度的均值, 这样的判定方法满足密度峰值算法中聚类中心往往分布在相对高密度区域这一条件;式 (13) 的判定方法满足聚类中心间的相对距离较远这个条件。</p>
                </div>
                <div class="p1">
                    <p id="156">因此, 当网格代表点对象符合以上两个公式条件时, 将该网格代表点选定为聚类中心。</p>
                </div>
                <h4 class="anchor-tag" id="157" name="157"><b>2.2.2 数据点归类</b></h4>
                <div class="p1">
                    <p id="158">本文采用原DPC算法中的最近邻算法对剩余数据点进行归类。在完成聚类中心代表点的选择之后, 将剩下的非聚类中心代表点按照<i>ρ</i><sub><i>i</i></sub>降序分类到距其最近且局部密度大于该点的代表点所在类中, 并将原数据集中的数据点归属到其网格代表点所在类中。</p>
                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>2.3 边界点与噪声点的处理</b></h4>
                <div class="p1">
                    <p id="160">本文G-DPC算法中, 边界点的对象是符合定义3的网格代表点。首先根据密度参数<i>d</i><sub>c</sub>计算出当前类簇中边界网格代表点的集合, 在边界点集中找出拥有最高密度的网格代表点, 将该代表点的密度作为阈值以划分出核心代表点和噪声点, 保留密度大于等于该密度阈值的代表点作为簇内核心代表点;剔除当前类别中小于此密度阈值的噪声代表点, 同时将该噪声代表点所在网格中的数据点也一并剔除。</p>
                </div>
                <h4 class="anchor-tag" id="161" name="161"><b>2.4 算法实现</b></h4>
                <div class="p1">
                    <p id="162">G-DPC算法实现的具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="163"> (1) 将数据集标准化处理;</p>
                </div>
                <div class="p1">
                    <p id="164"> (2) 依据式 (6) 计算出网格划分参数<i>side</i>, 将数据空间划分为均等且不相交的网格单元;</p>
                </div>
                <div class="p1">
                    <p id="165"> (3) 将数据点映射至相应的网格单元中, 由式 (7) 和式 (8) 求出各网格的代表点, 并统计每个网格中分别所含数据点数目;</p>
                </div>
                <div class="p1">
                    <p id="166"> (4) 根据式 (9) 和式 (10) 计算网格代表点<i>P</i><sub><i>i</i></sub>的局部密度<i>ρ</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="167"> (5) 计算网格代表点之间的距离矩阵<b><i>D</i></b><sub><i>ij</i></sub>, 并求出密度参数<i>d</i><sub>c</sub>;</p>
                </div>
                <div class="p1">
                    <p id="168"> (6) 将网格代表点按<i>ρ</i><sub><i>i</i></sub>进行倒序排列, 由式 (11) 计算各网格代表点的高密度距离<i>δ</i><sub><i>i</i></sub>;</p>
                </div>
                <div class="p1">
                    <p id="169"> (7) 由式 (12) 和式 (13) 自适应确定聚类中心代表点, 按照<i>ρ</i><sub><i>i</i></sub>降序分类到距其最短的且局部密度大于该点的网格代表点所在类中, 将原数据集中所有数据点归类到其所在网格代表点所属类中;</p>
                </div>
                <div class="p1">
                    <p id="170"> (8) 由密度参数<i>d</i><sub><i>c</i></sub>计算出当前类的边界点集, 选出边界点集中密度最大的代表点, 并将该点的密度作为划分当前类的核心代表点和噪声点的阈值, 剔除当前类别中小于此密度阈值的代表点及代表点所在网格中的其他数据点;</p>
                </div>
                <div class="p1">
                    <p id="171"> (9) 返回最终聚类结果。</p>
                </div>
                <h4 class="anchor-tag" id="172" name="172"><b>2.5 高维数据降维方法</b></h4>
                <div class="p1">
                    <p id="173">降维是处理高维数据的一种有效方法, 降维技术分为线性降维和非线性降维。线性降维方法主要有主成分分析 (Principal Component Analysis, PCA) 和多维尺度分析 (Multi-Dimensional Scaling, MDS) <citation id="256" type="reference"><link href="61" rel="bibliography" /><sup>[<a class="sup">30</a>]</sup></citation>等;非线性流形降维方法主要有等距映射 (Isomap) <citation id="257" type="reference"><link href="63" rel="bibliography" /><sup>[<a class="sup">31</a>]</sup></citation>、局部线性嵌入 (Local Linear Embedding, LLE) <citation id="259" type="reference"><link href="65" rel="bibliography" /><link href="67" rel="bibliography" /><sup>[<a class="sup">32</a>,<a class="sup">33</a>]</sup></citation>和拉普拉斯特征映射 (Laplacian Eigenmaps, LE) <citation id="258" type="reference"><link href="69" rel="bibliography" /><sup>[<a class="sup">34</a>]</sup></citation>等。与传统的线性降维方法相比, 非线性降维方法能更有效地发现复杂高维数据内嵌的低维结构。</p>
                </div>
                <div class="p1">
                    <p id="174">本文采用LE方法进行降维, 该方法用局部的角度去构建数据之间的关系。其主要思想是高维空间中距离近的点投影到低维空间后距离也应尽量接近。</p>
                </div>
                <div class="p1">
                    <p id="175">设数据点的数目为<i>n</i>, 目标子空间的维度为<i>m</i>。定义<i>n</i>×<i>m</i>大小的矩阵<b><i>Y</i></b>, 其中每一个行向量<b><i>y</i></b><mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup></mrow></math></mathml>是数据点<i>i</i>在目标<i>m</i>维子空间中的向量表示, 则需优化的目标函数表示为:</p>
                </div>
                <div class="p1">
                    <p id="177"><mathml id="178"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>min</mi></mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></munder><mi mathvariant="bold-italic">W</mi></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mi>j</mi></mrow></msub><mrow><mo>|</mo><mrow><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi mathvariant="bold-italic">y</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (14) </p>
                </div>
                <div class="p1">
                    <p id="179">定义对角矩阵<b><i>D</i></b>, 对角线上 (<i>i</i>, <i>j</i>) 位置元素等于矩阵<b><i>W</i></b>的第<i>i</i>行之和, 经过线性代数变换, 上述优化问题可以用矩阵向量形式表示如下:</p>
                </div>
                <div class="p1">
                    <p id="180">min<i>tr</i> (<b><i>Y</i></b><sup>T</sup><b><i>LY</i></b>) s.t. <b><i>Y</i></b><sup>T</sup><b><i>DY</i></b>=1      (15) </p>
                </div>
                <div class="p1">
                    <p id="181">式中:矩阵<b><i>L</i>=<i>D</i>-<i>W</i></b>是图拉普拉斯矩阵。限制条件<b><i>Y</i></b><sup>T</sup><b><i>DY</i></b>=1保证优化问题有解, 并且保证映射后的数据点不会被“压缩”到一个小于<i>m</i>维的子空间中。算法具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="182"> (1) 使用K最近邻方法构建稀疏邻接图, 若<i>i</i>在<i>j</i>的<i>k</i>个最近邻之中, 则<i>i</i>和<i>j</i>有边, 否则无边;</p>
                </div>
                <div class="p1">
                    <p id="183"> (2) 采用直接映射方法为每条边赋值权重。若<i>i</i>、<i>j</i>相连, 则<i>w</i><sub><i>ij</i></sub>取值1, 否则为0;</p>
                </div>
                <div class="p1">
                    <p id="184"> (3) 通过式 (16) 计算拉普拉斯矩阵<b><i>L</i></b>的特征向量与特征值:</p>
                </div>
                <div class="p1">
                    <p id="185"><b><i>L</i></b><sub><i>y</i></sub>=<i>λ</i><b><i>D</i></b><sub><i>y</i></sub>      (16) </p>
                </div>
                <div class="p1">
                    <p id="186">式中:<b><i>D</i></b>是对角矩阵, 满足式 (17) 和式 (18) , 选择最小的<i>m</i>个非零特征值对应的特征向量作为降维后的结果输出。</p>
                </div>
                <div class="p1">
                    <p id="187"><mathml id="188"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">D</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow></msub><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mi>j</mi></munder><mi mathvariant="bold-italic">W</mi></mstyle><msub><mrow></mrow><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow></math></mathml>      (17) </p>
                </div>
                <div class="p1">
                    <p id="189"><b><i>L</i>=<i>D</i>-<i>W</i></b>      (18) </p>
                </div>
                <h4 class="anchor-tag" id="190" name="190"><b>2.6 聚类效果评价指标</b></h4>
                <div class="p1">
                    <p id="191">本文通过聚类精度 (Accuracy) 和归一化信息熵 (Normalized Mutual Ingormation, NMI) 两种聚类评价指标来检测G-DPC算法的聚类效果。同时, 也将该算法与其他算法的运行时间对比作为聚类效率的主要评价指标。此外, 还通过对算法的时间复杂度和空间复杂度进行探讨以分析算法效率。</p>
                </div>
                <div class="p1">
                    <p id="192"> (1) Accuracy作为聚类效果的评价指标, 其公式如下:</p>
                </div>
                <div class="p1">
                    <p id="193"><mathml id="194"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>δ</mi></mstyle><mo stretchy="false"> (</mo><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mstyle><mo>^</mo></mover><mo>, </mo><mi>m</mi><mi>a</mi><mi>p</mi><mo stretchy="false"> (</mo><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mi>n</mi></mfrac></mrow></math></mathml>      (19) </p>
                </div>
                <div class="p1">
                    <p id="195">式中:<mathml id="196"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mstyle><mo>^</mo></mover></mrow></math></mathml>是数据<i>i</i>的真实类标号, <i>c</i><sub><i>i</i></sub>是聚类结果。函数<i>δ</i> (<i>x</i>, <i>y</i>) 用于对比两个变量的一致性, 若<i>x</i>=<i>y</i>, 则<i>δ</i> (<i>x</i>, <i>y</i>) =1;否则<i>δ</i> (<i>x</i>, <i>y</i>) =0。<i>map</i> (·) 首先找到聚类结果中属于同种类别的全部数据对象, 然后求出它们的真正种类标号频次, 并根据与真实类别标号的匹配给定真实种类标号。聚类精度值介于[0, 1], 越高则效果越好。</p>
                </div>
                <div class="p1">
                    <p id="197"> (2) NMI评价标准通过计算聚类结果与真实类别标号之间的互信息来评价聚类结果与真实类别标号的一致性<citation id="260" type="reference"><link href="71" rel="bibliography" /><sup>[<a class="sup">35</a>]</sup></citation>, 其公式如下:</p>
                </div>
                <div class="p1">
                    <p id="198"><mathml id="199"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ν</mi><mi>Μ</mi><mi>Ι</mi><mo>=</mo><mfrac><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>c</mi><mo>, </mo><mover accent="true"><mi>c</mi><mo>^</mo></mover><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>c</mi><mo stretchy="false">) </mo><mi>Η</mi><mo stretchy="false"> (</mo><mover accent="true"><mi>c</mi><mo>^</mo></mover><mo stretchy="false">) </mo></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (20) </p>
                </div>
                <div class="p1">
                    <p id="200">式中:<mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ι</mi><mo stretchy="false"> (</mo><mi>c</mi><mo>, </mo><mover accent="true"><mi>c</mi><mo>^</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>是聚类结果<i>c</i>和真实类别标号<mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>c</mi><mo>^</mo></mover></math></mathml>之间的互信息, <i>H</i> (·) 表示单个类别向量的信息熵。<i>NMI</i>值介于[0, 1]之间, 越高则聚类效果越好。</p>
                </div>
                <h3 id="203" name="203" class="anchor-tag"><b>3 实验仿真</b></h3>
                <h4 class="anchor-tag" id="204" name="204"><b>3.1 数据测试</b></h4>
                <div class="p1">
                    <p id="205">本文实验所采用的计算机硬件配置为Intel Core i7处理器 (主频3.4 GHz) 、16 GB内存;实验的软件环境为Windows10操作系统, 采用MATLAB编程实现本文算法。</p>
                </div>
                <div class="p1">
                    <p id="206">本实验选取两组数据集进行测试。</p>
                </div>
                <div class="p1">
                    <p id="207">第一组采用六个不同数据量且维度都为2的低维人工数据集, 主要用来分析随着数据量的增加, G-DPC算法与DPCA算法、DBSCAN算法以及GRIDBSCAN算法的时间效率。其中Compound<citation id="261" type="reference"><link href="73" rel="bibliography" /><sup>[<a class="sup">36</a>]</sup></citation>、Aggregation<citation id="262" type="reference"><link href="75" rel="bibliography" /><sup>[<a class="sup">37</a>]</sup></citation>、unbalace<citation id="263" type="reference"><link href="77" rel="bibliography" /><sup>[<a class="sup">38</a>]</sup></citation>、D31<citation id="264" type="reference"><link href="79" rel="bibliography" /><sup>[<a class="sup">39</a>]</sup></citation>、t4.8k<citation id="265" type="reference"><link href="81" rel="bibliography" /><sup>[<a class="sup">40</a>]</sup></citation>为小规模数据集, Birch3<citation id="266" type="reference"><link href="83" rel="bibliography" /><sup>[<a class="sup">41</a>]</sup></citation>为较大规模数据集, 共有10万条。实验中关涉的相似度矩阵计算均采取欧几里得方法。各数据集的详细信息及实验对照结果如表1所示。</p>
                </div>
                <div class="area_img" id="208">
                                            <p class="img_tit">
                                                <b>表1 低维数据集算法效果对比</b>
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_20800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JYRJ201908046_20800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_20800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表1 低维数据集算法效果对比" src="Detail/GetImg?filename=images/JYRJ201908046_20800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="209"><b>续表1</b></p>
                </div>
                <div class="area_img" id="210">
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_21000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="" src="Detail/GetImg?filename=images/JYRJ201908046_21000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="p1">
                    <p id="211">为了更直观地对比DPC算法和G-DPC算法DPCA算法、DBSCAN算法以及GRIDBSCAN算法的效率, 通过表1数据给出了几种算法的运行时间和精确率对比图, 如图4和图5所示。因Birch3数据集过大, DPC算法运行过程中内存溢出而无法完成聚类, 所以只对前五个数据集进行可视化。</p>
                </div>
                <div class="area_img" id="212">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_212.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 低维数据集的算法运行时间对比" src="Detail/GetImg?filename=images/JYRJ201908046_212.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 低维数据集的算法运行时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_212.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="213">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 低维数据集的精确度对比" src="Detail/GetImg?filename=images/JYRJ201908046_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 低维数据集的精确度对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_213.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="214">通过表1、图4和图5可以得出, DPC算法和DBSCAN算法随着数据量的增加算法开销的时间成指数型增长, 而本文的G-DPC算法时间增长和数据量成线性关系, 且比GRIDBSCAN算法更快。</p>
                </div>
                <div class="p1">
                    <p id="215">图6为G-DPC算法在数据集Birch3上的聚类效果图, 聚类结果基本符合图1中的数据分布情况。因此本文中算法在处理大范围数据集上有着明显的优势, 由于是基于网格的算法, 在精确度指标上稍逊于DPC算法, 但是差距很小, 总体效果依然优异。</p>
                </div>
                <div class="area_img" id="216">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 Birch3数据集聚类结果" src="Detail/GetImg?filename=images/JYRJ201908046_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 Birch3数据集聚类结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_216.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="217">第二组数据采用UCI公共数据集中的Iris、seeds、wine和ring四个高维数据集对G-DPC和DPCA算法、DBSCAN算法以及GRIDBSCAN算法进行试验, 采用拉普拉斯特征映射方法降维, 并对照几种算法对高维数据的运行效率。各数据集的详细信息如表2所示, 图7和图8分别为各算法的运行时间对比图以及精确率对比图。</p>
                </div>
                <div class="area_img" id="218">
                                            <p class="img_tit">
                                                <b>表2 高维数据集信息</b>
                                                
                                                &nbsp;&nbsp;
                                                <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_21800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a>
                                                <a class="table downimg" data-tablename="Detail/GetImg?filename=images/JYRJ201908046_21800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">下载原表</a>
                                            </p>
                                    <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_21800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <img alt="表2 高维数据集信息" src="Detail/GetImg?filename=images/JYRJ201908046_21800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                    </a>

                </div>
                <div class="area_img" id="219">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 高维数据集精确度对比图" src="Detail/GetImg?filename=images/JYRJ201908046_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 高维数据集精确度对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_219.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="220">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908046_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 高维数据集的算法运行时间对比" src="Detail/GetImg?filename=images/JYRJ201908046_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 高维数据集的算法运行时间对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908046_220.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="221">由图7和图8可以看出, G-DPC算法在高维数据集上聚类精度相较于低维数据集略低, 但总体来说聚类效果依然良好。在精确度指标上, G-DPC算法和DPC算法结果相差不大, 聚类质量基本持平, 均远高于DBSCAN算法和GRIDBSCAN算法。而在对高维数据集处理的时间效率上G-DPC算法远远优于DPC算法。</p>
                </div>
                <div class="p1">
                    <p id="222">由上述实验可得, G-DPC算法极大地减少了内存和计算的开销, 降低了时空复杂度, 提升了运行速度。虽然该算法因为基于网格划分而对噪声点的处理较为敏感, 精确率略有偏差, 但并不影响总体效果。</p>
                </div>
                <h4 class="anchor-tag" id="223" name="223"><b>3.2 算法分析</b></h4>
                <div class="p1">
                    <p id="224">本文提出的G-DPC算法在时间上的开销包括网格划分、数据聚类、数据点归类和边界点处理共四个部分。其中:网格划分包括数据点映射至相应网格, 和对网格单元信息的统计, 时间复杂度为<i>O</i> (<i>n</i>) ;数据聚类的过程中耗费的最大时间代价为各网格代表点距离矩阵的计算, 时间复杂度为<i>O</i> (<i>k</i><sup>2</sup>) ;数据点归类是先将非核心代表点归类到核心点, 时间复杂度为<i>O</i> (<i>k</i><sup>2</sup>) , 其次将网格中的数据点归入其代表点所属类中, 复杂度为<i>O</i> (<i>n</i>) ;对边界点的处理是先找到每个类中的边界代表点集, 选出其中最高密度代表点密度作为阈值划分核心点和噪声点, 时间复杂度为<i>O</i> (<i>bk</i>) , 其中<i>b</i>表示边界点代表点的个数。因此G-DPC算法的时间复杂度为:</p>
                </div>
                <div class="p1">
                    <p id="225"><i>T</i><sub>all</sub>=2×<i>O</i> (<i>n</i>) +2×<i>O</i> (<i>k</i><sup>2</sup>) +<i>O</i> (<i>bk</i>)      (14) </p>
                </div>
                <div class="p1">
                    <p id="226">而原始的DPC算法在时间的开销上包含数据点之间的距离矩阵的计算, 寻找聚类中心和非聚类中心的归类, 所耗费的时间复杂度为<i>O</i> (<i>n</i><sup>2</sup>) 。</p>
                </div>
                <div class="p1">
                    <p id="227">空间复杂度方面, G-DPC算法将数据点映射到<i>k</i>个网格单元中 (假设为理想状态, 数据均匀划分) , 其空间复杂度为<i>O</i> (<i>k</i><sup>2</sup>) , 而原DPC算法中构建距离矩阵的过程与数据总数有关, 其空间复杂度为<i>O</i> (<i>n</i><sup>2</sup>) 。</p>
                </div>
                <h3 id="228" name="228" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="229">DPC算法需人工指定聚类中心个数, 对数据对象距离矩阵的计算需耗费大量的时间和空间, 限制了对大规模数据集的处理。本文基于网格聚类的思想进行网格划分, 用网格代表点替代网格单元整体, 从而减少计算次数。然后对各代表点进行聚类, 大大降低了距离矩阵计算的时空复杂度, 通过自动确定聚类中心的方法降低了人工取值带来的误差。在多种标准数据集的实验结果验证了G-DPC算法对大小规模数据集进行聚类的有效性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning from observation:Conceptual clustering">

                                <b>[1]</b> Michalski R S, Stepp R E.Learning from Observation:Conceptual Clustering[M].Machine Learning:An Artificial Intelligence Approach, 1983.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Introduction to statistical pattern recognition">

                                <b>[2]</b> Fukunaue K.Introduction to Statistic Pattern Recognition[M].Academic Press, 1990.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB200208005&amp;v=MDEzNjZxZlp1WnRGeWptV3IzSU55ZlRiTEc0SHRQTXA0OUZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> Qian W, Zhou A.Analyzing popular clustering algorithms from different viewpoints[J].Journal of Software, 2002, 13 (8) :1382-1394.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017255379.nh&amp;v=MjAxMzMzenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0lWRjI2R2JHOUc5TExwcEViUElRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 张琪.基于数据挖掘技术的高炉数据分析[D].马鞍山:安徽工业大学, 2017.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201302041&amp;v=MDg2NzE0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptV3IzSUx6N01hYkc0SDlMTXJZOUJaWVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Hu W.Improved hierarchical K-means clustering algorithm[J].Computer Engineering and Applications, 2013, 49 (2) :157-159.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201505013&amp;v=MjMwMjJDVVI3cWZadVp0RnlqbVdyM0lMalhmZmJHNEg5VE1xbzlFWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 谢娟英, 鲁肖肖, 屈亚楠, 等.粒计算优化初始聚类中心的K-medoids聚类算法[J].计算机科学与探索, 2015, 9 (5) :611-620.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXJY201218021&amp;v=MDc5Mjc0SDlQTnA0OUhaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptV3IzSU1qWEJkN0c=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 范多锋, 徐俊刚.基于划分的聚类分析算法的改进[J].微型机与应用, 2012, 31 (18) :54-56, 59.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JFYZ2011S3030&amp;v=MTY2MTdyM0lMeXZTZExHNEg5Q3ZySTlHWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 吴泓辰, 王新军, 成勇, 等.基于协同过滤与划分聚类的改进推荐算法[J].计算机研究与发展, 2011, 48 (S3) :205-212.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB201803008&amp;v=MDc2NDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJS0Q3WWJMRzRIOW5Nckk5RmJJUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 逯瑞强, 马福民, 张腾飞.基于区间2-型模糊度量的粗糙K-means聚类算法[J].模式识别与人工智能, 2018, 31 (3) :265-274.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MSSB199901014&amp;v=MTU1NzA1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0lLRDdZYkxLeEY5ak1ybzlFWUlRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 王涛, 沈谦, 朱明星, 等.遗传与C-均值混合算法用于聚类分析[J].模式识别与人工智能, 1999, 12 (1) :98-103.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BJDZ201301021&amp;v=MDEwMDU3cWZadVp0RnlqbVdyM0lKeWZQZExHNEg5TE1ybzlIWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> Li X, Jiang S Y, Zhang Q S, et al.A dynamic density-based clustering algorithm appropriate to large-scale text processing[J].Acta Scientiarum Naturalium Universitatis Pekinensis, 2013, 49 (1) :133-139.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201412039&amp;v=MTI5MDBMejdCYjdHNEg5WE5yWTlHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0k=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 张峻玮, 杨洲.一种基于改进的层次聚类的协同过滤用户推荐算法研究[J].计算机科学, 2014, 41 (12) :176-178.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A density-based algorithm for discovering clusters in large spatial databases">

                                <b>[13]</b> Ester B M, Kriegel H P, Sander J, et al.A Density Based algorithm for discovering clusters in large spatial databases[C]//Proceedings of International Conference on knowledge Discovery and Data Mining.AAAI, 1996:226-231.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002157171&amp;v=MDMyMjVCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXZsVTd6QklsND1OajdCYXJPNEh0SE9yb3BDWmV3T1kzazV6&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Sander J, Ester M, Kriegel H P, et al.Density Based Clustering in Spatial Databases:The Algorithm GDBSCAN and Its Applications[J].Data Mining &amp;Knowledge Discovery, 1998, 2 (2) :169-194.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optics: Ordering points to identify the clustering structure">

                                <b>[15]</b> Ankerst M, Breuniu M M, Kriegel H P, et al.OPTICS:Ordering Points to Identify the Clustering Structure[J].Stanford Research Inst Memo Stanford University, 1999, 28 (2) :49-60.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDCAAB7D6814491E651048799347196C0&amp;v=MTQ5NDBwUkV4ZnJPZFE4bWZDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THUyd3FnPU5pZk9mY2ZMYjZDK3FQdERiT29MQ0hVNHVoQVc2ejk1UUhqcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Xie J Y, Gao H C, Xie W X, et al.Robust clustering by detecting density peaks and assigning points based on fuzzy weighted K-nearest neighbors[J].Information Sciences, 2016, 354:19-40.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=WaveCluster: A multi-resolution clustering approach for very large spatial databases">

                                <b>[17]</b> Sheikhleslami G, Chatterjee S, Zhanu A.Wave Cluster:A Multi-Resolution Clustering Approach for Very Large Spatial Databases[C]//International Conference on Very Large Data Bases.Morgan Kaufmann Publishers Inc.1998:428-439.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000068877&amp;v=Mjk3ODdJWTdLN0h0ak5yNDlGWk8wSEJIcytvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRjBkYUJJPU5pZg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Agrawal R, Gehrke J E, Gunopulos D, et al.Automatic subspace clustering of high dimensional data for datamining applications[M]//ACM SIGMOD Record.ACM, 1998:94-105.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KZYC201203002&amp;v=MjEzMDk5UE1ySTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0lMamZTYmJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Wang J, Wang S T, Deng Z H, et al.Survey on challenges in clustering analysis research[J].Control and Decision, 2012, 27 (3) :321-328.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYJ201609030&amp;v=MTk0MzZXcjNJTHo3U1pMRzRIOWZNcG85R1pJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am0=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 冯振华, 钱雪忠, 赵娜娜.Greedy DBSCAN:一种针对多密度聚类的DBSCAN改进算法[J].计算机应用研究, 2016 (9) :2693-2696.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY200803060&amp;v=MTE3ODlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJTHo3QmQ3RzRIdG5Nckk5RFpJUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 谭颖, 胡瑞飞, 殷国富.多密度阈值的DBSCAN改进算法[J].计算机应用, 2008, 28 (3) :745-748.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201303006&amp;v=MTYwMTBadEZ5am1XcjNJTWpYU1pMRzRIOUxNckk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 陈刚, 刘秉权, 吴岩.一种基于高斯分布的自适应DBSCAN算法[J].微电子学与计算机, 2013, 30 (3) :27-30.
                            </a>
                        </p>
                        <p id="47">
                            <a id="bibliography_23" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JLGY201404035&amp;v=MjIwNTMzenFxQnRHRnJDVVI3cWZadVp0RnlqbVdyM0lMeUhNZDdHNEg5WE1xNDlHWVlRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[23]</b> 刘淑芬, 孟冬雪, 王晓燕.基于网格单元的DBSCAN算法[J].吉林大学学报:工学版, 2014 (4) :1135-1139.
                            </a>
                        </p>
                        <p id="49">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Clustering by fast search and find of densitypeaks">

                                <b>[24]</b> Rodriguez A, Liao A.Clustering by fast search and find of density peaks[J].Science, 2014, 344 (6191) :1492-1496.
                            </a>
                        </p>
                        <p id="51">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=STING: A statistical information grid approach to spatial data mining">

                                <b>[25]</b> Wang W, Yang J, Muntz R R.STING:a statistical information grid approach to spatial data mining[C]//Proceedings of the 23rd International Conference on Very Large Data Bases.San Francisco, CA:Morgan Kaufmann, 1997:186-195.
                            </a>
                        </p>
                        <p id="53">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wave cluster with differential privacy">

                                <b>[26]</b> Chen L, Yu T, Chirkova R.Wave cluster with differential privacy[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.New York:ACM, 2015.
                            </a>
                        </p>
                        <p id="55">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A framework for classifying uncertain and evolving data streams">

                                <b>[27]</b> Xu W H, Chang Y, Qin Z.A Framework for Classifying Uncertain and Evolving Data Streams[J].Information Technology Journal, 2011, 10 (10) :1926-1933.
                            </a>
                        </p>
                        <p id="57">
                            <a id="bibliography_28" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fuzzy clustering by fast search and find of density peaks">

                                <b>[28]</b> Mehmood R, Bie R, Dawood H, et al.Fuzzy clustering by fast search and find of density peaks[C]//International Conference on Identification, Information, and Knowledge in the Internet of Things.IEEE, 2016:258-261.
                            </a>
                        </p>
                        <p id="59">
                            <a id="bibliography_29" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201607049&amp;v=MTEwMjU3cWZadVp0RnlqbVdyM0lMejdCYjdHNEg5Zk1xSTlCYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[29]</b> 马春来, 单洪, 马涛.一种基于簇中心点自动选择策略的密度峰值聚类算法[J].计算机科学, 2016 (7) :255-258.
                            </a>
                        </p>
                        <p id="61">
                            <a id="bibliography_30" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787040317046001&amp;v=MTMzODBHYk84SHRMTnFJOUJZdXNQRFJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlplWnZGeW5tVTcvTEtWd1VYRnF6&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[30]</b> 王建忠.高维数据几何结构及降维[M].北京:高等教育出版社, 2012.
                            </a>
                        </p>
                        <p id="63">
                            <a id="bibliography_31" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A global geometric framework for nonlinear dimensionality reduction">

                                <b>[31]</b> Tenenbaum J B.A Global Geometric Framework for Nonlinear Dimensionality Reduction[J].Science, 2000, 290 (5500) :2319-2323.
                            </a>
                        </p>
                        <p id="65">
                            <a id="bibliography_32" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">

                                <b>[32]</b> Roweis S T.Nonlinear Dimensionality Reduction by Locally Linear Embedding[J].Science, 2000, 290 (5500) :2323-2326.
                            </a>
                        </p>
                        <p id="67">
                            <a id="bibliography_33" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Think globally, fit locally: unsupervised learning of low dimensional manifolds">

                                <b>[33]</b> Saul L K, Roweis S T.Think Globally, Fit Locally:Unsupervised Learning of Low Dimensional Manifold[J].Journal of Machine Learning Research, 2003, 4 (2) :119-155.
                            </a>
                        </p>
                        <p id="69">
                            <a id="bibliography_34" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500012194&amp;v=MTIwODBUTW53WmVadEZpbmxVcnpJSUYwZGFCST1OaWZKWmJLOUh0ak1xbzlGWk9vTkRYVTlvQk1UNlQ0UFFIL2lyUmRHZXJxUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[34]</b> Belkin M, Niyogi P.Laplacian Eigenmaps for Dimensionality Reduction and Data Representation[J].Neural Computation, 2003, 15 (6) :1373-1396.
                            </a>
                        </p>
                        <p id="71">
                            <a id="bibliography_35" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Information theoretic measures for clusterings comparison:is a correction for chance necessary?">

                                <b>[35]</b> Vinh N X, Epps J, Bailey J.Information theoretic measures for clusterings comparison:is a correction for chance necessary?[C]//Proceedings of the 26th Annual International Conference on Machine Learning.ACM, 2009:1073-1080.
                            </a>
                        </p>
                        <p id="73">
                            <a id="bibliography_36" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Graph-theoretical methods for detecting and describing gestalt clusters">

                                <b>[36]</b> Zahn C T.Graph-Theoretical Methods for Detecting and Describing Gestalt Clusters[J].IEEE Transactions on Computers, 1971, C-20 (1) :68-86.
                            </a>
                        </p>
                        <p id="75">
                            <a id="bibliography_37" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000093142&amp;v=MTIxNzJOaWZJWTdLN0h0ak5yNDlGWk9JTURYZzdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRjBkYUJJPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[37]</b> Gionis A, Mannila H, Tsaparas P.Clustering aggregation[J].ACM Transactions on Knowledge Discovery from Data, 2007, 1 (1) :4.
                            </a>
                        </p>
                        <p id="77">
                            <a id="bibliography_38" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES15122600662698&amp;v=MzIwMDllWnRGaW5sVXJ6SUlGMGRhQkk9TmlmT2ZiSzlIOVBPcVk5Rll1ME5DblV4b0JNVDZUNFBRSC9pclJkR2VycVFUTW53Wg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[38]</b> Kim P, Kim S.Detecting overlapping and hierarchical communities in complex network using interaction-based edge clustering[J].Physica A Statistical Mechanics &amp; Its Applications, 2015, 417 (C) :46-56.
                            </a>
                        </p>
                        <p id="79">
                            <a id="bibliography_39" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPD00000024572&amp;v=MDA3ODRZZXdOWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZForWnVGaXZsVTd6QklsND1OaVRiYXJPNEh0SE1yNDFC&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[39]</b> Lancichinetti A, Fortunato S, Kertesz J.Detecting the overlapping and hierarchical community structure in complex networks[J].New Journal of Physics, 2009, 11 (3) :033015.
                            </a>
                        </p>
                        <p id="81">
                            <a id="bibliography_40" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Chameleon: Hierarchical Clustering Using Dynamic Modeling">

                                <b>[40]</b> Karypis G, Han E H, Kumar V.Chameleon:hierarchical clustering using dynamic modeling[J].Computer, 1999, 32 (8) :68-75.
                            </a>
                        </p>
                        <p id="83">
                            <a id="bibliography_41" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00002157106&amp;v=MjIyNTl1Rml2bFU3ekJJbDQ9Tmo3QmFyTzRIdEhPcm9wQ1plc0pZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWita&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[41]</b> Zhang T, Ramakrishnan R, Livny M.BIRCH:A new data clustering algorithm and its applications[J].Data Mining and Knowledge Discovery, 1997, 1 (2) :141-182.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201908046" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908046&amp;v=MDI5MDlqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5am1XcjNJTHpUWlpMRzRIOWpNcDQ5QllvUUtESDg0dlI0VDY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
