<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136397218877500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201903040%26RESULT%3d1%26SIGN%3dY1OOH%252bCFbG%252bdVCxy03Qb8qtu2xA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903040&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903040&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903040&amp;v=MDI0MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEbFY3L09MelRaWkxHNEg5ak1ySTlCWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;1.1 基于卷积神经网路的图像超分辨率方法&lt;/b&gt;"><b>1.1 基于卷积神经网路的图像超分辨率方法</b></a></li>
                                                <li><a href="#62" data-title="&lt;b&gt;1.2 优化相关技术&lt;/b&gt;"><b>1.2 优化相关技术</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#73" data-title="&lt;b&gt;2 改进的SRCNN方法&lt;/b&gt; "><b>2 改进的SRCNN方法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#94" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#95" data-title="&lt;b&gt;3.1 实验设计及评价标准&lt;/b&gt;"><b>3.1 实验设计及评价标准</b></a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;3.2 实验结果分析&lt;/b&gt;"><b>3.2 实验结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="图1 SRCNN网络模型结构图">图1 SRCNN网络模型结构图</a></li>
                                                <li><a href="#70" data-title="图2 残差网络示意图">图2 残差网络示意图</a></li>
                                                <li><a href="#92" data-title="图3 本文方法网络流程示意图">图3 本文方法网络流程示意图</a></li>
                                                <li><a href="#100" data-title="图4 测试图像1">图4 测试图像1</a></li>
                                                <li><a href="#103" data-title="图5 测试图像2">图5 测试图像2</a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表1 图像重建结果的&lt;i&gt;PSNR&lt;/i&gt;&lt;/b&gt;"><b>表1 图像重建结果的<i>PSNR</i></b></a></li>
                                                <li><a href="#121" data-title="&lt;b&gt;表2 图像重建结果的&lt;i&gt;SSIM&lt;/i&gt;&lt;/b&gt;"><b>表2 图像重建结果的<i>SSIM</i></b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Park S C, Min K P, Kang M G. Super-resolution image reconstruction: a technical overview[J]. IEEE Signal Processing Magazine, 2003, 20 (3) :21-36." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Super-resolution image reconstruction: a technical overview">
                                        <b>[1]</b>
                                         Park S C, Min K P, Kang M G. Super-resolution image reconstruction: a technical overview[J]. IEEE Signal Processing Magazine, 2003, 20 (3) :21-36.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 韩小虎. 基于深度学习的图像超分辨算法研究[D]. 开封:河南大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016207680.nh&amp;v=MTE3NTlPVkYyNkdMRzRHZGZFcjVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWNy8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         韩小虎. 基于深度学习的图像超分辨算法研究[D]. 开封:河南大学, 2016.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 黄冬冬. 基于深度学习的图像超分辨率重建算法研究[D]. 马鞍山:安徽工业大学, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017255388.nh&amp;v=MTc3NTVsVjcvT1ZGMjZHYkc5RzlMRXA1RWJQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaUQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         黄冬冬. 基于深度学习的图像超分辨率重建算法研究[D]. 马鞍山:安徽工业大学, 2017.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 首照宇, 廖敏璐, 陈利霞. 改进的基于稀疏表示的图像超分辨率重建算法[J]. 计算机应用与软件, 2014, 31 (4) :201-204." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201404052&amp;v=MDc2NjBGckNVUjdxZlp1WnNGaURsVjcvT0x6VFpaTEc0SDlYTXE0OUFab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         首照宇, 廖敏璐, 陈利霞. 改进的基于稀疏表示的图像超分辨率重建算法[J]. 计算机应用与软件, 2014, 31 (4) :201-204.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Schultz R R, Stevenson R L. A Bayesian approach to image expansion for improved definition.[J]. Image Processing IEEE Transactions on, 1994, 3 (3) :233-242." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Bayesian approach to image expansion for improved definition">
                                        <b>[5]</b>
                                         Schultz R R, Stevenson R L. A Bayesian approach to image expansion for improved definition.[J]. Image Processing IEEE Transactions on, 1994, 3 (3) :233-242.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Hou H, Andrews H. Cubic splines for image interpolation and digital filtering[J]. IEEE Transactions on Acoustics Speech &amp;amp; Signal Processing, 1978, 26 (6) :508-517." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cubic splines for image interpolation and digital filtering">
                                        <b>[6]</b>
                                         Hou H, Andrews H. Cubic splines for image interpolation and digital filtering[J]. IEEE Transactions on Acoustics Speech &amp;amp; Signal Processing, 1978, 26 (6) :508-517.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Li X, Orchard M T. New edge-directed interpolation.[J]. IEEE Trans Image Process, 2001, 10 (10) :1521-1527." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=New edge-directed interpolation">
                                        <b>[7]</b>
                                         Li X, Orchard M T. New edge-directed interpolation.[J]. IEEE Trans Image Process, 2001, 10 (10) :1521-1527.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Irani M, Peleg S. Improving resolution by image registration[J]. Cvgip Graphical Models &amp;amp; Image Processing, 1991, 53 (3) :231-239." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improving resolution by image registration">
                                        <b>[8]</b>
                                         Irani M, Peleg S. Improving resolution by image registration[J]. Cvgip Graphical Models &amp;amp; Image Processing, 1991, 53 (3) :231-239.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Stark H, Oskoui P. High-resolution image recovery from image-plane arrays, using convex projections[J]. Journal of the Optical Society of America A Optics &amp;amp; Image Science, 1989, 6 (11) :1715." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-resolution image recovery from image-plane arrays, using convex projections">
                                        <b>[9]</b>
                                         Stark H, Oskoui P. High-resolution image recovery from image-plane arrays, using convex projections[J]. Journal of the Optical Society of America A Optics &amp;amp; Image Science, 1989, 6 (11) :1715.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Schultz R R, Stevenson R L. Improved definition video frame enhancement[C]//International Conference on Acoustics, Speech, and Signal Processing. IEEE, 1995, 4:2169-2172." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Improved Definition Video Frame Enhancement">
                                        <b>[10]</b>
                                         Schultz R R, Stevenson R L. Improved definition video frame enhancement[C]//International Conference on Acoustics, Speech, and Signal Processing. IEEE, 1995, 4:2169-2172.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Roweis S T, Saul L K. Nonlinear Dimensionality Reduction by Locally Linear Embedding[J]. Science, 2000, 290 (5500) :2323-2326." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">
                                        <b>[11]</b>
                                         Roweis S T, Saul L K. Nonlinear Dimensionality Reduction by Locally Linear Embedding[J]. Science, 2000, 290 (5500) :2323-2326.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Yang J, Wright J, Huang T, et al. Image super-resolution as sparse representation of raw image patches[C]//2008 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2008:1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Super-Resolution as Sparse Representation of Raw Image Patches">
                                        <b>[12]</b>
                                         Yang J, Wright J, Huang T, et al. Image super-resolution as sparse representation of raw image patches[C]//2008 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2008:1-8.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Dong C, Loy C C, He K, et al. Image super-resolution using deep convolutional networks[J]. IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2016, 38 (2) :295-307." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">
                                        <b>[13]</b>
                                         Dong C, Loy C C, He K, et al. Image super-resolution using deep convolutional networks[J]. IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence, 2016, 38 (2) :295-307.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 王学文. 基于学习的图像超分辨率算法研究[D]. 武汉:华中科技大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016920440.nh&amp;v=Mjg3MTlHRnJDVVI3cWZadVpzRmlEbFY3L09WRjI2R0xxNkh0WElyNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         王学文. 基于学习的图像超分辨率算法研究[D]. 武汉:华中科技大学, 2016.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 龙法宁, 朱晓姝, 胡春娇. 基于深层卷积网络的单幅图像超分辨率重建模型[J]. 广西科学, 2017, 24 (3) : 231-235." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXKK201703003&amp;v=MzE3OTVsVjcvT0lqWEFaYkc0SDliTXJJOUZaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaUQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         龙法宁, 朱晓姝, 胡春娇. 基于深层卷积网络的单幅图像超分辨率重建模型[J]. 广西科学, 2017, 24 (3) : 231-235.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016: 770-778." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">
                                        <b>[16]</b>
                                         He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016: 770-778.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" 王一宁, 秦品乐, 李传朋, 等. 基于残差神经网络的图像超分辨率改进算法[J]. 计算机应用, 2018, 38 (1) :246-254." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201801044&amp;v=MTkzNzNpRGxWNy9PTHo3QmQ3RzRIOW5Ncm85QllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         王一宁, 秦品乐, 李传朋, 等. 基于残差神经网络的图像超分辨率改进算法[J]. 计算机应用, 2018, 38 (1) :246-254.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Ioffe S, Szegedy C . Batch normalization: accelerating deep network training by reducing internal covariate shift[C]//International Conference on International Conference on Machine Learning. JMLR.org, 2015:448-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">
                                        <b>[18]</b>
                                         Ioffe S, Szegedy C . Batch normalization: accelerating deep network training by reducing internal covariate shift[C]//International Conference on International Conference on Machine Learning. JMLR.org, 2015:448-456.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" 王晓斌, 黄金杰, 刘文举. 基于优化卷积神经网络结构的交通标志识别[J]. 计算机应用, 2017, 37 (2) :530-534." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201702040&amp;v=MjAxOTA1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEbFY3L09MejdCZDdHNEg5Yk1yWTlCWklRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         王晓斌, 黄金杰, 刘文举. 基于优化卷积神经网络结构的交通标志识别[J]. 计算机应用, 2017, 37 (2) :530-534.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Shi W, Caballero J, Husz&#225;r F, et al. Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016:1874-1883." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network">
                                        <b>[20]</b>
                                         Shi W, Caballero J, Husz&#225;r F, et al. Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016:1874-1883.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" Dong C, Chen C L, Tang X. Accelerating the super-resolution convolutional neural network[C]//Proceedings of the 14th European Conference on Computer Vision, ECCV 2016, 2016:391-407." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Accelerating the super-resolution convolutional neural network">
                                        <b>[21]</b>
                                         Dong C, Chen C L, Tang X. Accelerating the super-resolution convolutional neural network[C]//Proceedings of the 14th European Conference on Computer Vision, ECCV 2016, 2016:391-407.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(03),214-218 DOI:10.3969/j.issn.1000-386x.2019.03.039            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>改进的基于卷积神经网络的图像超分辨率方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E6%97%BA&amp;code=41287806&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王旺</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BE%90%E4%BF%8A%E6%AD%A6&amp;code=32876941&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">徐俊武</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E9%A2%96%E5%85%88&amp;code=41287807&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李颖先</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%AD%A6%E6%B1%89%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0202782&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">武汉工程大学计算机科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>图像超分辨率是计算机视觉领域的经典问题。使用深度神经网络来解决图像超分辨率的问题目前得到越来越多的研究学者的关注和青睐。为改善基于卷积神经网络的图像超分辨率方法的图像生成效果, 提出一种改进的方法。在神经网络层中加深网络层数, 并且针对加深网络可能出现的退化现象引入残差网络结构, 并将图像上采样步骤放入网络中。实验表明, 在与传统的插值法和原始的基于卷积神经网络方法的对比中, 该优化方法生成的图像观感更加锐利清晰、细节丰富, 而且无论在峰值信噪比和结构相似性上均有明显提高, 验证了该方法的有效性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">超分辨率;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    王旺, 硕士生, 主研领域:图像处理。;
                                </span>
                                <span>
                                    徐俊武, 副教授。;
                                </span>
                                <span>
                                    李颖先, 硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-11</p>

            </div>
                    <h1><b>AN IMPROVED IMAGE SUPER-RESOLUTION METHOD BASED ON CONVOLUTION NEURAL NETWORK</b></h1>
                    <h2>
                    <span>Wang Wang</span>
                    <span>Xu Junwu</span>
                    <span>Li Yingxian</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Engineering, Wuhan Institute of Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Image super-resolution is a classical problem in the field of computer vision. The use of depth neural network to solve the problem of image super-resolution has attracted more and more attention and favor of researchers. In order to improve the image generation effect of image super-resolution method based on convolution neural network, an improved method was proposed. It mainly increased the number of network layers in the neural network layer, introduced residual network structure for the degradation phenomenon that might occur in the deepening network, and put the image sampling steps into the network. Experiments show that compared with the traditional interpolation method and the original method based on convolutional neural network, the optimization method generates sharper and clear image with richer details. And it has significant improvement both in peak signal-to-noise ratio and structural similarity, which verifies the effectiveness of this method.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Super-resolution&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Super-resolution;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolution%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolution neural network;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-11</p>
                            </div>


        <!--brief start-->
                        <h3 id="45" name="45" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="46">图像的超分辨率SR (Super Resolution) 技术, 是通过软件算法来把低分辨率LR (Low Resolution) 的图像转换成为高分辨率HR (High Resolution) 图像的技术<citation id="126" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。目前在许多重要的领域都十分需要这门技术的支持, 例如在医学图像处理领域, 高分辨率图像可以帮助医生掌握病情, 看到人眼不易察觉到的病灶, 可以更好地针对治疗<citation id="127" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="47">SR技术最早可以追溯到20世纪60年代, 提出者为Harris<citation id="128" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。当时的主流是方法是插值法, 之后随着技术的发展, 有新的方法被研究者提出, 主要归纳为基于重建的方法和基于学习的方法<citation id="129" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。插值法具有最简单的计算过程和最低的复杂度, 常见的有邻插值法<citation id="130" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>、双线性插值法<citation id="131" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和双三次插值法<citation id="132" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>;基于重建的方法在一段时间内颇为热门, 经典的有迭代反投影法<citation id="133" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>、凸集投影法<citation id="134" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和最大后验概率估计法<citation id="135" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>, 这种方法最大的问题在于放大倍数有限, 生成效果也不及后来者;基于学习的方法分为基于浅层网络的学习方法, 主要有流形学习<citation id="136" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>和稀疏表示<citation id="137" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>;另一种基于学习的方法就是基于深度网络的方法。</p>
                </div>
                <div class="p1">
                    <p id="48">将深度学习应用于图像超分辨率领域, 最早由Dong等<citation id="138" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>提出, 也就是经典的基于卷积神经网络的超分辨率方法 (SRCNN) , 之后不断地有学者进行优化和改进。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag"><b>1 相关工作</b></h3>
                <h4 class="anchor-tag" id="50" name="50"><b>1.1 基于卷积神经网路的图像超分辨率方法</b></h4>
                <div class="p1">
                    <p id="51">基于卷积神经网络的超分辨率 (SRCNN) 方法是最先将深度学习引入图像超分辨率重建的问题。超分辨率方法将一张LR图像放大为一张HR图像, 尺寸的变化造成像素点总量的变化, 其中最难的挑战是如何在新增的像素位置进行值的填充。SRCNN使LR图像能通过一定的算法升为HR图像, 主要是两者之间存在“共同特征”, 所以在SRCNN中, 将超分辨率过程分为三个阶段<citation id="139" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="52"> (1) 特征提取。此阶段就是对LR图像进行特征提取和特征表示, 利用卷积网络的性质提取图像块的特征, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="53"><i>F</i><sub>1</sub> (<i>Y</i>) =max (0, <i>W</i><sub>1</sub>×<i>Y</i>+<i>B</i><sub>1</sub>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="54"> (2) 非线性映射。将第一阶段提取的<i>n</i><sub>1</sub>维特征映射至<i>n</i><sub>2</sub>维, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="55"><i>F</i><sub>2</sub> (<i>Y</i>) =max (0, <i>W</i><sub>2</sub>×<i>F</i><sub>1</sub> (<i>Y</i>) +<i>B</i><sub>2</sub>)      (2) </p>
                </div>
                <div class="p1">
                    <p id="56"> (3) 重建。这个阶段是将第二阶段映射后的特征恢复为HR图像, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="57"><i>F</i> (<i>Y</i>) =<i>W</i><sub>3</sub>+<i>F</i><sub>2</sub> (<i>Y</i>) +<i>B</i><sub>3</sub>      (3) </p>
                </div>
                <div class="p1">
                    <p id="58">式中:<i>W</i>和<i>B</i>分别代表卷积模板和偏置参数。</p>
                </div>
                <div class="p1">
                    <p id="59">SRCNN的网络模型结构如图1所示。文献<citation id="140" type="reference">[<a class="sup">13</a>]</citation>只使用了3层简单的卷积神经网络, 分别进行上述三个阶段。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903040_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SRCNN网络模型结构图" src="Detail/GetImg?filename=images/JYRJ201903040_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SRCNN网络模型结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903040_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="61">在SRCNN中, 使用MSE作为损失函数, 在图像输入前需要使用双三次插值放大至目标尺寸。此时虽然图像尺寸达到了, 但是仍然称之为低分辨率图像, 然后再进行输入。输出的是最终重建高分辨率图像。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>1.2 优化相关技术</b></h4>
                <h4 class="anchor-tag" id="63" name="63"> (1) 亚像素卷积层。</h4>
                <div class="p1">
                    <p id="64">亚像素卷积层<citation id="141" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>在输入原始低分辨率图像之后, 经过卷积之后, 得到通道数为<i>r</i><sup>2</sup>的与输入图像大小一样的特征图像。然后将每个像素的<i>r</i><sup>2</sup>通道再排列, 成为<i>r</i>×<i>r</i>的区域, 则每个像素都成为<i>r</i>×<i>r</i>大小, 从而大小为<i>H</i>×<i>W</i>×<i>r</i><sup>2</sup>的特征图像被重新排列成<i>rH</i>×<i>rW</i>的高分辨率图像。需要注意的是亚像素卷积层的输入维度为输出维度前<i>r</i><sup>2</sup>倍, 且<i>r</i>为放大倍数。</p>
                </div>
                <h4 class="anchor-tag" id="65" name="65"> (2) 残差网络。</h4>
                <div class="p1">
                    <p id="66">通过加深网络的深度可以很好地提高网络的性能, 但是可能会出现退化问题, 随着网络层数的增加, 在训练集上的准确率却饱和甚至下降。深度残差网络<citation id="142" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>的出现主要是为了退化的问题。</p>
                </div>
                <div class="p1">
                    <p id="67">出现退化的原因, 主要是因为神经网络在反向传播过程中要不断地传播梯度, 而当网络层数加深的时候, 梯度在传播过程中会逐渐消失<citation id="143" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="68">残差网络解决退化现象的原理如图2所示, 将某一层的输入<i>x</i>直接传到后几层的输出中。这种方式被称为捷径连接, 也就是最终的输出结果<i>H</i> (<i>x</i>) 为原本的输出<i>F</i> (<i>x</i>) 加上前几层的输入<i>x</i>, 即:</p>
                </div>
                <div class="p1">
                    <p id="69"><i>H</i> (<i>x</i>) =<i>F</i> (<i>x</i>) +<i>x</i>      (4) </p>
                </div>
                <div class="area_img" id="70">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903040_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 残差网络示意图" src="Detail/GetImg?filename=images/JYRJ201903040_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 残差网络示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903040_070.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="71">这样做的好处在于, 当<i>F</i> (<i>x</i>) 由于退化问题变为0的时候, 那么至少输出<i>H</i> (<i>x</i>) 还是有值的。当<i>H</i> (<i>x</i>) =<i>x</i>的时候, 被称为恒等映射, 由于还有输出, 那么梯度还可以继续传递。</p>
                </div>
                <div class="p1">
                    <p id="72">同时在残差块中也会加入批量归一化BN<citation id="144" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>层, 添加BN的最大优点是, 减少梯度消失, 加快收敛速度。根据研究表明, BN层需要添加在网络层后激活函数前<citation id="145" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>, 效果最佳。</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag"><b>2 改进的SRCNN方法</b></h3>
                <div class="p1">
                    <p id="74">本文提出基于SRCNN的图像超分辨率的优化方法, 主要在SRCNN的基础上做出如下修改:</p>
                </div>
                <div class="p1">
                    <p id="75">1) 在输入方面, 本方法在最后以两层亚像素卷积层<citation id="146" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>的形式放大图像尺寸, 因此可以直接将原始低清图像作为输入, 而无需像SRCNN那样先以双三次插值的方式放大尺寸再输入。</p>
                </div>
                <div class="p1">
                    <p id="76">2) 本方法还改变特征维数, 使用更小的卷积核和使用更多的映射层, SRCNN总共只有3层网络, 映射层只有一层, 加深网络可以有效提升网络能力。</p>
                </div>
                <div class="p1">
                    <p id="77">3) 本方法由于并非在网络外部进行放大图像的操作, 所以更具有灵活性。当需要不同的上采样倍率时, 只需要微调后面的上采样层就可以了, 前面的映射层不变。</p>
                </div>
                <div class="p1">
                    <p id="78">在SRCNN方法中, 超分辨率的工作是在高分辨率的基础上完成的, 这样并不是最优的办法, 而且计算量很大。如果可以在网络内部进行超分辨率, 通过训练学习将低分辨率特征映射到高分辨率输出, 这样就能够减轻计算量, 并且效果也更优。</p>
                </div>
                <div class="p1">
                    <p id="79">在本方法中, 网络模型可以分为3个部分:</p>
                </div>
                <div class="p1">
                    <p id="80">1) 特征提取。SRCNN中的特征提取是对插值后的高分辨率图像进行提取, 卷积核大小为9×9;本方法是直接对原始的低分辨率进行操作, 因此可以选择小一些, 设置为3×3。</p>
                </div>
                <div class="p1">
                    <p id="81">2) 非线性映射。由于感受野大, 能够表现得更好, 在SRCNN中采用的是5×5的卷积核, 但是卷积核大的计算量会比较大, 用两个串联的3×3的卷积核可以替代一个5×5的。同时两个串联的小卷积核需要的参数数量为18, 而5×5的参数数量为25, 所以本方法使用多个3×3的小卷积层, 兼顾计算量和网络能力。</p>
                </div>
                <div class="p1">
                    <p id="82">3) 上采样。使用亚像素卷积层进行上采样。</p>
                </div>
                <div class="p1">
                    <p id="83">具体流程描述如下:</p>
                </div>
                <div class="p1">
                    <p id="84">1) 输入图像张量, 维度为3;</p>
                </div>
                <div class="p1">
                    <p id="85">2) 进入卷积层, 输入维度为3, 输出维度为64, 卷积核为3×3, 步长为1, 之后接入激活函数ReLU;</p>
                </div>
                <div class="p1">
                    <p id="86">3) 进入残差块, 内部含有4个小残差块和一个卷积层, 每个小残差块内部含有两个卷积层, 每层卷积之后都加入BN层, 激活函数为ReLU;</p>
                </div>
                <div class="p1">
                    <p id="87">4) 进入卷积层, 输入维度为64, 输出维度为256, 卷积核为1×1, 步长为1, 之后接入BN层, 再激活函数ReLU;</p>
                </div>
                <div class="p1">
                    <p id="88">5) 上采样卷积之前需要计算维度, 先使用卷积层将维度升到一定高度再进行上采样, 该卷积层输入维度为64, 输出维度256, 卷积核为3×3, 步长为1, 之后再进行上采样层, 输出维度64, ReLU激活;</p>
                </div>
                <div class="p1">
                    <p id="89">6) 再重复步骤5, 两次上采样将图像尺寸提升4倍;</p>
                </div>
                <div class="p1">
                    <p id="90">7) 最后以1×1卷积核降维到3, 激活函数改为Tanh, 输出大尺寸图像。</p>
                </div>
                <div class="p1">
                    <p id="91">网络流程见图3。</p>
                </div>
                <div class="area_img" id="92">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903040_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 本文方法网络流程示意图" src="Detail/GetImg?filename=images/JYRJ201903040_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 本文方法网络流程示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903040_092.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="93">在本文方法中, 损失函数依然使用MSE, 优化器选用Adam。</p>
                </div>
                <h3 id="94" name="94" class="anchor-tag"><b>3 实 验</b></h3>
                <h4 class="anchor-tag" id="95" name="95"><b>3.1 实验设计及评价标准</b></h4>
                <div class="p1">
                    <p id="96">实验采用DIV2K数据集的图像作为训练集, 训练完成后使用测试图像进行重建生成高分辨率图像用于查看效果。</p>
                </div>
                <div class="p1">
                    <p id="97">由于实验中的低分辨率图像是从高分辨率图像进行1/4倍降采样得到, 所以本实验有原始高分辨率图像作为对照。同时一起列出用双三次插值法重建图像;还另外用相同的训练集和训练次数训练SRCNN方法、ESPCN<citation id="147" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>方法和FSRCNN<citation id="148" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>方法并将测试图像生成结果一起列出。图4和图5分别展示这三种方法重建生成图像的结果和原始图像, 都是截取了关键部分, 以便查看细节部分。</p>
                </div>
                <div class="area_img" id="100">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903040_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 测试图像1" src="Detail/GetImg?filename=images/JYRJ201903040_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 测试图像1  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903040_10000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903040_10300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 测试图像2" src="Detail/GetImg?filename=images/JYRJ201903040_10300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 测试图像2  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903040_10300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="104">本实验评价采用主观评价和客观评价共同分析生成图像质量。其中主观评价就是在图像的视觉效果上感受图像的效果, 对比各种方法生成的图像之间的差异;客观评价以峰值信噪比PSNR和结构相似性SSIM来进行衡量。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"> (1) 峰值信噪比。</h4>
                <div class="p1">
                    <p id="106">峰值信噪比是重建的高分辨率图像真实高分辨率图像之间的像素差值的量度, 可以用来衡量被处理后图像的质量, 单位为dB。定义如下:</p>
                </div>
                <div class="p1">
                    <p id="107"><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>Ν</mi><mi>S</mi><mi>R</mi><mo>=</mo><mn>1</mn><mn>0</mn><mrow><mi>lg</mi></mrow><mrow><mo> (</mo><mrow><mfrac><mrow><mn>2</mn><mn>5</mn><mn>5</mn><msup><mrow></mrow><mn>2</mn></msup></mrow><mrow><mi>Μ</mi><mi>S</mi><mi>E</mi></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>      (5) </p>
                </div>
                <div class="area_img" id="149">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201903040_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="111">式中:<i>I</i>为真实图像, <i>K</i>为生成图像, <i>m</i>和<i>n</i>分别为图像和长和宽。</p>
                </div>
                <h4 class="anchor-tag" id="112" name="112"> (2) 结构相似性。</h4>
                <div class="p1">
                    <p id="113">结构相似性为两幅图像结构相似度的度量的标准, 取值范围为[0, 1], 值越大就越表示两幅图像结构相似程度越高。定义如下:</p>
                </div>
                <div class="p1">
                    <p id="114"><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><mi>S</mi><mi>Ι</mi><mi>Μ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mn>4</mn><mi>μ</mi><msub><mrow></mrow><mi>x</mi></msub><mi>μ</mi><msub><mrow></mrow><mi>y</mi></msub><mi>σ</mi><msub><mrow></mrow><mrow><mi>x</mi><mi>y</mi></mrow></msub></mrow><mrow><mo stretchy="false"> (</mo><mi>μ</mi><msubsup><mrow></mrow><mi>x</mi><mn>2</mn></msubsup><mo>+</mo><mi>μ</mi><msubsup><mrow></mrow><mi>y</mi><mn>2</mn></msubsup><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>σ</mi><msubsup><mrow></mrow><mi>x</mi><mn>2</mn></msubsup><mo>+</mo><mi>σ</mi><msubsup><mrow></mrow><mi>y</mi><mn>2</mn></msubsup><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="116">式中:<i>μ</i><sub><i>x</i></sub>和<i>μ</i><sub><i>y</i></sub>分别是<i>x</i>和<i>y</i>的平均值;<i>σ</i><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>x</mi><mn>2</mn></msubsup></mrow></math></mathml>和<i>σ</i><mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>y</mi><mn>2</mn></msubsup></mrow></math></mathml>分别是<i>x</i>和<i>y</i>的方差;<i>σ</i><sub><i>xy</i></sub>是<i>x</i>和<i>y</i>的协方差。</p>
                </div>
                <div class="p1">
                    <p id="119">表1和表2分别列出了4组测试图像的生成图像和原始图像进行计算的<i>PSNR</i>和<i>SSIM</i>的值。</p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表1 图像重建结果的<i>PSNR</i></b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td><br />使用方法</td><td>图像1</td><td>图像2</td><td>图像3</td><td>图像4</td></tr><tr><td><br />插值法</td><td>22.55</td><td>17.57</td><td>19.81</td><td>21.37</td></tr><tr><td><br />SRCNN</td><td>22.58</td><td>17.53</td><td>19.73</td><td>21.41</td></tr><tr><td><br />FSRCNN</td><td>21.30</td><td>16.10</td><td>20.13</td><td>20.52</td></tr><tr><td><br />ESPCN</td><td>23.87</td><td>18.05</td><td>19.67</td><td>21.46</td></tr><tr><td><br />本文方法</td><td>26.52</td><td>19.46</td><td>20.67</td><td>21.64</td></tr><tr><td><br />原图像</td><td>∞</td><td>∞</td><td>∞</td><td>∞</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="121">
                    <p class="img_tit"><b>表2 图像重建结果的<i>SSIM</i></b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="121" border="1"><tr><td><br />使用方法</td><td>图像1</td><td>图像2</td><td>图像3</td><td>图像4</td></tr><tr><td><br />插值法</td><td>0.949 3</td><td>0.815 3</td><td>0.936 3</td><td>0.958 7</td></tr><tr><td><br />SRCNN</td><td>0.949 5</td><td>0.812 7</td><td>0.936 0</td><td>0.964 2</td></tr><tr><td><br />FSRCNN</td><td>0.926 9</td><td>0.760 7</td><td>0.931 5</td><td>0.948 9</td></tr><tr><td><br />ESPCN</td><td>0.962 7</td><td>0.843 9</td><td>0.940 7</td><td>0.961 4</td></tr><tr><td><br />本文方法</td><td>0.980 8</td><td>0.893 0</td><td>0.946 8</td><td>0.958 9</td></tr><tr><td><br />原图像</td><td>1</td><td>1</td><td>1</td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="122" name="122"><b>3.2 实验结果分析</b></h4>
                <div class="p1">
                    <p id="123">从图4和图5的实验结果可以看出, 使用本文方法生成的图像略优于其他方法。如图4的花瓣的边缘, 图4 (a) 和 (b) 不够锐利清晰, (c) 和 (d) 也比较模糊, 且花瓣层次不明显, 有一些波纹, (e) 花瓣边缘则较为清晰, 花瓣层次也比较明显, 整体观感会比较舒适。图5的建筑外墙, 图5 (a) 、 (b) 和 (c) 的外墙窗户十分模糊, 窗户的边缘线条不清晰, (d) 的外墙观感稍可, 但是整体观感还是比较模糊, (e) 的观感最为舒适纯净, 外墙窗户边缘较为清晰, 细节较为丰富处理效果更胜一筹。其中SRCNN、FSRCNN和ESPCN三种方法和本文方法使用了相同的训练集和训练次数, 在同样的训练条件下, 本文的优化方法是有一定的优化效果的。这在表1和表2中的数据也能得到证明, 在计算出的<i>PSNR</i>和<i>SSIM</i>值中, 可以看出使用本文方法在客观评价方面, 较其他的方法高出不少。</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="125">本文提出一种改进的基于卷积神经网络的图像超分辨率方法。主要在经典的SRCNN方法的基础上进行了改进, 即加深了网络层并且引入残差网络避免退化问题, 而且将上采样过程改为在网络内部进行。这样可以加强网络能力并且减轻计算量, 最终得到效果更好的图像, 而且训练次数要求更低。实验结果表明, 本文方法从主观和客观角度, 生成图像均好于双三次插值法和SRCNN方法, 证明本文提出的改进是有效的。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Super-resolution image reconstruction: a technical overview">

                                <b>[1]</b> Park S C, Min K P, Kang M G. Super-resolution image reconstruction: a technical overview[J]. IEEE Signal Processing Magazine, 2003, 20 (3) :21-36.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016207680.nh&amp;v=MTk0MTlHRnJDVVI3cWZadVpzRmlEbFY3L09WRjI2R0xHNEdkZkVyNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 韩小虎. 基于深度学习的图像超分辨算法研究[D]. 开封:河南大学, 2016.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1017255388.nh&amp;v=MjgzOTFFcDVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGxWNy9PVkYyNkdiRzlHOUw=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 黄冬冬. 基于深度学习的图像超分辨率重建算法研究[D]. 马鞍山:安徽工业大学, 2017.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201404052&amp;v=MjgzMzVBWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEbFY3L09MelRaWkxHNEg5WE1xNDk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 首照宇, 廖敏璐, 陈利霞. 改进的基于稀疏表示的图像超分辨率重建算法[J]. 计算机应用与软件, 2014, 31 (4) :201-204.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Bayesian approach to image expansion for improved definition">

                                <b>[5]</b> Schultz R R, Stevenson R L. A Bayesian approach to image expansion for improved definition.[J]. Image Processing IEEE Transactions on, 1994, 3 (3) :233-242.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cubic splines for image interpolation and digital filtering">

                                <b>[6]</b> Hou H, Andrews H. Cubic splines for image interpolation and digital filtering[J]. IEEE Transactions on Acoustics Speech &amp; Signal Processing, 1978, 26 (6) :508-517.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=New edge-directed interpolation">

                                <b>[7]</b> Li X, Orchard M T. New edge-directed interpolation.[J]. IEEE Trans Image Process, 2001, 10 (10) :1521-1527.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improving resolution by image registration">

                                <b>[8]</b> Irani M, Peleg S. Improving resolution by image registration[J]. Cvgip Graphical Models &amp; Image Processing, 1991, 53 (3) :231-239.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-resolution image recovery from image-plane arrays, using convex projections">

                                <b>[9]</b> Stark H, Oskoui P. High-resolution image recovery from image-plane arrays, using convex projections[J]. Journal of the Optical Society of America A Optics &amp; Image Science, 1989, 6 (11) :1715.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Improved Definition Video Frame Enhancement">

                                <b>[10]</b> Schultz R R, Stevenson R L. Improved definition video frame enhancement[C]//International Conference on Acoustics, Speech, and Signal Processing. IEEE, 1995, 4:2169-2172.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Nonlinear dimensionality reduction by locally linear embedding">

                                <b>[11]</b> Roweis S T, Saul L K. Nonlinear Dimensionality Reduction by Locally Linear Embedding[J]. Science, 2000, 290 (5500) :2323-2326.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Super-Resolution as Sparse Representation of Raw Image Patches">

                                <b>[12]</b> Yang J, Wright J, Huang T, et al. Image super-resolution as sparse representation of raw image patches[C]//2008 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2008:1-8.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">

                                <b>[13]</b> Dong C, Loy C C, He K, et al. Image super-resolution using deep convolutional networks[J]. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2016, 38 (2) :295-307.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016920440.nh&amp;v=MjA0MTZQSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURsVjcvT1ZGMjZHTHE2SHRYSXI1RWI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 王学文. 基于学习的图像超分辨率算法研究[D]. 武汉:华中科技大学, 2016.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GXKK201703003&amp;v=MzExNzA1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEbFY3L09JalhBWmJHNEg5Yk1ySTlGWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 龙法宁, 朱晓姝, 胡春娇. 基于深层卷积网络的单幅图像超分辨率重建模型[J]. 广西科学, 2017, 24 (3) : 231-235.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep residual learning for image recognition">

                                <b>[16]</b> He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016: 770-778.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201801044&amp;v=MDIyNTE0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURsVjcvT0x6N0JkN0c0SDluTXJvOUJZSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 王一宁, 秦品乐, 李传朋, 等. 基于残差神经网络的图像超分辨率改进算法[J]. 计算机应用, 2018, 38 (1) :246-254.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">

                                <b>[18]</b> Ioffe S, Szegedy C . Batch normalization: accelerating deep network training by reducing internal covariate shift[C]//International Conference on International Conference on Machine Learning. JMLR.org, 2015:448-456.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201702040&amp;v=MDU3NDRSN3FmWnVac0ZpRGxWNy9PTHo3QmQ3RzRIOWJNclk5QlpJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> 王晓斌, 黄金杰, 刘文举. 基于优化卷积神经网络结构的交通标志识别[J]. 计算机应用, 2017, 37 (2) :530-534.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network">

                                <b>[20]</b> Shi W, Caballero J, Huszár F, et al. Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network[C]//2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2016:1874-1883.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Accelerating the super-resolution convolutional neural network">

                                <b>[21]</b> Dong C, Chen C L, Tang X. Accelerating the super-resolution convolutional neural network[C]//Proceedings of the 14th European Conference on Computer Vision, ECCV 2016, 2016:391-407.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201903040" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903040&amp;v=MDI0MjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEbFY3L09MelRaWkxHNEg5ak1ySTlCWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1VWdqSmZRZ2l1bjJRM2RRZz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
