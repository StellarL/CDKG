<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135741444502500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201905036%26RESULT%3d1%26SIGN%3dnIFE1I4y6xpXszVbjfmezXA%252bhLY%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201905036&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201905036&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201905036&amp;v=MDc3MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emtVTHpKTHpUWlpMRzRIOWpNcW85R1lvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#50" data-title="&lt;b&gt;1 方法设计&lt;/b&gt; "><b>1 方法设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#51" data-title="&lt;b&gt;1.1 系统框架&lt;/b&gt;"><b>1.1 系统框架</b></a></li>
                                                <li><a href="#54" data-title="&lt;b&gt;1.2 双边伽马校正曲线设计&lt;/b&gt;"><b>1.2 双边伽马校正曲线设计</b></a></li>
                                                <li><a href="#85" data-title="&lt;b&gt;1.3 双边伽马校正后图像的融合处理&lt;/b&gt;"><b>1.3 双边伽马校正后图像的融合处理</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="&lt;b&gt;2 实 验&lt;/b&gt; "><b>2 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#125" data-title="&lt;b&gt;2.1 评价指标&lt;/b&gt;"><b>2.1 评价指标</b></a></li>
                                                <li><a href="#133" data-title="&lt;b&gt;2.2 实验结果及分析&lt;/b&gt;"><b>2.2 实验结果及分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#161" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#53" data-title="图1 本文方法的流程图">图1 本文方法的流程图</a></li>
                                                <li><a href="#60" data-title="图2 伽马值&lt;i&gt;γ&lt;/i&gt;对亮度和对比度的影响">图2 伽马值<i>γ</i>对亮度和对比度的影响</a></li>
                                                <li><a href="#70" data-title="&lt;b&gt;表1 伽马校正曲线段对亮度区域的改善效果&lt;/b&gt;"><b>表1 伽马校正曲线段对亮度区域的改善效果</b></a></li>
                                                <li><a href="#144" data-title="图3 输入图像名为“Carnev”的视觉效果对比">图3 输入图像名为“Carnev”的视觉效果对比</a></li>
                                                <li><a href="#145" data-title="&lt;b&gt;表2 输入图像名为Carnev的客观评价指标对比&lt;/b&gt;"><b>表2 输入图像名为Carnev的客观评价指标对比</b></a></li>
                                                <li><a href="#149" data-title="图4 输入图像名为“House”的视觉效果对比">图4 输入图像名为“House”的视觉效果对比</a></li>
                                                <li><a href="#150" data-title="&lt;b&gt;表3 输入图像名为House的客观评价指标对比&lt;/b&gt;"><b>表3 输入图像名为House的客观评价指标对比</b></a></li>
                                                <li><a href="#154" data-title="图5 输入图像名为“Barch”的视觉效果对比">图5 输入图像名为“Barch”的视觉效果对比</a></li>
                                                <li><a href="#155" data-title="&lt;b&gt;表4 输入图像名为Barch的客观评价指标对比&lt;/b&gt;"><b>表4 输入图像名为Barch的客观评价指标对比</b></a></li>
                                                <li><a href="#159" data-title="图6 输入图像名为“Flash”的视觉效果对比">图6 输入图像名为“Flash”的视觉效果对比</a></li>
                                                <li><a href="#160" data-title="&lt;b&gt;表5 输入图像名为Flash的客观评价指标对比&lt;/b&gt;"><b>表5 输入图像名为Flash的客观评价指标对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Menotti D, Najman L, Facon J, et al.Multi-Histogram Equalization Methods for Contrast Enhancement and Brightness Preserving[J].IEEE Transactions on Consumer Electronics, 2007, 53 (3) :1186-1194." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-Histogram Equalization Methods for Contrast Enhancement and Brightness Preserving">
                                        <b>[1]</b>
                                         Menotti D, Najman L, Facon J, et al.Multi-Histogram Equalization Methods for Contrast Enhancement and Brightness Preserving[J].IEEE Transactions on Consumer Electronics, 2007, 53 (3) :1186-1194.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Senthamarai G, Santhi K.Dynamic multi-histogram equalisation for image contrast enhancement with improved brightness preservation[C]//International Conference on Electronics and Communication Systems.IEEE, 2015:1205-1209." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic multi-histogram equalisation for image contrast enhancement with improved brightness preservation">
                                        <b>[2]</b>
                                         Senthamarai G, Santhi K.Dynamic multi-histogram equalisation for image contrast enhancement with improved brightness preservation[C]//International Conference on Electronics and Communication Systems.IEEE, 2015:1205-1209.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Wang C, Ye Z.Brightness preserving histogram equalization with maximum entropy:a variational perspective[J].IEEE Transactions on Consumer Electronics, 2005, 51 (4) :1326-1334." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Brightness preserving histogram equalization with maximum entropy: A variational perspective">
                                        <b>[3]</b>
                                         Wang C, Ye Z.Brightness preserving histogram equalization with maximum entropy:a variational perspective[J].IEEE Transactions on Consumer Electronics, 2005, 51 (4) :1326-1334.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Magudeeswaran V, Ravichandran C G, Thirumurugan P.Brightness preserving bi‐level fuzzy histogram equalization for MRI brain image contrast enhancement[J].International Journal of Imaging Systems &amp;amp; Technology, 2017, 27 (2) :153-161" target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD8B7DBC56D2E2AC816AC54AE546702590&amp;v=MTA5MTNyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh3TG04dzZnPU5pZmNhcnZLR2FXKzNJcERFT2w2RGcxS3h4Y1ZtMHg0VEE2WHFSWXpmcktXUUxPZkNPTnZGU2lXVw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Magudeeswaran V, Ravichandran C G, Thirumurugan P.Brightness preserving bi‐level fuzzy histogram equalization for MRI brain image contrast enhancement[J].International Journal of Imaging Systems &amp;amp; Technology, 2017, 27 (2) :153-161
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Chen S D, Ramli A R.Minimum mean brightness error bi-histogram equalization in contrast enhancement[J].IEEE Transactions on Consumer Electronics, 2004, 49 (4) :1310-1319." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Minimum mean brightness error bi-histogram equalization in contrast enhancement">
                                        <b>[5]</b>
                                         Chen S D, Ramli A R.Minimum mean brightness error bi-histogram equalization in contrast enhancement[J].IEEE Transactions on Consumer Electronics, 2004, 49 (4) :1310-1319.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Chen S D, Ramli A R.Contrast enhancement using recursive mean-separate histogram equalization for scalable brightness preservation[J].IEEE Transactions on Consumer Electronics, 2003, 49 (4) :1301-1309." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement using recursive mean-separate histogram equalization for scalable brightness preservation">
                                        <b>[6]</b>
                                         Chen S D, Ramli A R.Contrast enhancement using recursive mean-separate histogram equalization for scalable brightness preservation[J].IEEE Transactions on Consumer Electronics, 2003, 49 (4) :1301-1309.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Wang Y, Chen Q, Zhang B.Image enhancement based on equal area dualistic sub-image histogram equalization method[J].IEEE Transactions on Consumer Electronics, 1999, 45 (1) :68-75." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image enhancement based on equal area dualistic sub-image histogram equalization method">
                                        <b>[7]</b>
                                         Wang Y, Chen Q, Zhang B.Image enhancement based on equal area dualistic sub-image histogram equalization method[J].IEEE Transactions on Consumer Electronics, 1999, 45 (1) :68-75.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Kim Y T.Contrast enhancement using brightness preserving bi-histogram equalization[J].IEEE Transactions on Consumer Electronics, 1997, 43 (1) :1-8." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement using brightness preserving bi-histogram equalization">
                                        <b>[8]</b>
                                         Kim Y T.Contrast enhancement using brightness preserving bi-histogram equalization[J].IEEE Transactions on Consumer Electronics, 1997, 43 (1) :1-8.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Yao Z, Lai Z, Wang C, et al.Brightness preserving and contrast limited bi-histogram equalization for image enhancement[C]//International Conference on Systems and Informatics.IEEE, 2017:866-870." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Brightness preserving and contrast limited bi-histogram equalization for image enhancement">
                                        <b>[9]</b>
                                         Yao Z, Lai Z, Wang C, et al.Brightness preserving and contrast limited bi-histogram equalization for image enhancement[C]//International Conference on Systems and Informatics.IEEE, 2017:866-870.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Jordanski M, Arsic A, Tuba M.Dynamic recursive subimage histogram equalization algorithm for image contrast enhancement[C]//Telecommunications Forum Telfor.IEEE, 2016:819-822." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Dynamic recursive subimage histogram equalization algorithm for image contrast enhancement">
                                        <b>[10]</b>
                                         Jordanski M, Arsic A, Tuba M.Dynamic recursive subimage histogram equalization algorithm for image contrast enhancement[C]//Telecommunications Forum Telfor.IEEE, 2016:819-822.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Yao Z, Lai Z, Wang C, et al.Brightness preserving and contrast limited bi-histogram equalization for image enhancement[C]//International Conference on Systems and Informatics.IEEE, 2017:866-870." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Brightness preserving and contrast limited bi-histogram equalization for image enhancement">
                                        <b>[11]</b>
                                         Yao Z, Lai Z, Wang C, et al.Brightness preserving and contrast limited bi-histogram equalization for image enhancement[C]//International Conference on Systems and Informatics.IEEE, 2017:866-870.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Li H, Qiu H, Yu Z, et al.Infrared and visible image fusion scheme based on NSCT and low-level visual features[J].Infrared Physics &amp;amp; Technology, 2016, 76:174-184." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES84C7605F8374EBAF444887E50F9112C3&amp;v=MDgyNThPR1FsZkJyTFUwNXR0aHdMbTh3Nmc9TmlmT2ZidThiZGJLcjRvemJPZ0lDQWxMdm1BWDdqdDFRSGlYcVJKRGNMT1ZSOG1jQ09OdkZTaVdXcjdKSUZwbWFCdUhZZg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         Li H, Qiu H, Yu Z, et al.Infrared and visible image fusion scheme based on NSCT and low-level visual features[J].Infrared Physics &amp;amp; Technology, 2016, 76:174-184.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Shi Y, Yang J, Wu R.Reducing Illumination Based on Nonlinear Gamma Correction[C]//IEEE International Conference on Image Processing.IEEE, 2007:I-529-I-532." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot; Reducing Illumination Based on Nonlinear Gamma Correction&amp;quot;">
                                        <b>[13]</b>
                                         Shi Y, Yang J, Wu R.Reducing Illumination Based on Nonlinear Gamma Correction[C]//IEEE International Conference on Image Processing.IEEE, 2007:I-529-I-532.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Kubinger W, Vincze M, Ayromlou M.The role of gamma correction in colour image processing[C]//9th European Signal Processing Conference (EUSIPCO 1998) .IEEE, 1998." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The role of gamma correction in colour image processing">
                                        <b>[14]</b>
                                         Kubinger W, Vincze M, Ayromlou M.The role of gamma correction in colour image processing[C]//9th European Signal Processing Conference (EUSIPCO 1998) .IEEE, 1998.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Jagger W S, Muntz W R.Aquatic vision and the modulation transfer properties of unlighted and diffusely lighted natural waters[J].Vision Research, 1993, 33 (13) :1755-1763." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Aquatic vision and the modulation transfer properties of unlighted and diffusely lighted natural waters">
                                        <b>[15]</b>
                                         Jagger W S, Muntz W R.Aquatic vision and the modulation transfer properties of unlighted and diffusely lighted natural waters[J].Vision Research, 1993, 33 (13) :1755-1763.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Chou C H, Li Y C.A perceptually tuned subband image coder based on the measure of just-noticeable-distortion profile[J].IEEE Transactions on Circuits and Systems for Video Technology, 2002, 5 (6) :467-476." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A perceptually tuned subband image coder based on the measure of just-noticeable-distortion profile">
                                        <b>[16]</b>
                                         Chou C H, Li Y C.A perceptually tuned subband image coder based on the measure of just-noticeable-distortion profile[J].IEEE Transactions on Circuits and Systems for Video Technology, 2002, 5 (6) :467-476.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Burt P J, Kolczynski R J.Enhanced image capture through fusion[C]//1993 (4th) International Conference on Computer Vision.IEEE, 1993:173-182." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhanced image capture through fusion">
                                        <b>[17]</b>
                                         Burt P J, Kolczynski R J.Enhanced image capture through fusion[C]//1993 (4th) International Conference on Computer Vision.IEEE, 1993:173-182.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" CVG-URG[DB/OL].http://decsai.ugr.es/cvg/dbimagenes." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=CVG-URG">
                                        <b>[18]</b>
                                         CVG-URG[DB/OL].http://decsai.ugr.es/cvg/dbimagenes.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Burt P J, Adelson E H.The Laplacian pyramid as a compact image code[J].IEEE Transactions on Communications, 1983, 31 (4) :532-540." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The laplacian pyramid as a compact image code">
                                        <b>[19]</b>
                                         Burt P J, Adelson E H.The Laplacian pyramid as a compact image code[J].IEEE Transactions on Communications, 1983, 31 (4) :532-540.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" 牛爽, 尚媛园, 丁辉, 等.基于亮度传播图的低照度图像增强算法[J].计算机应用与软件, 2016, 33 (6) :168-171." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201606041&amp;v=MjI2NzVrVUx6SUx6VFpaTEc0SDlmTXFZOUJaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         牛爽, 尚媛园, 丁辉, 等.基于亮度传播图的低照度图像增强算法[J].计算机应用与软件, 2016, 33 (6) :168-171.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" 王淑青, 姚伟, 陈进, 等.基于直方图均衡化与形态学处理的边缘检测[J].计算机应用与软件, 2016, 33 (3) :193-196." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201603045&amp;v=MjUzOTFNckk5QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emtVTHpJTHpUWlpMRzRIOWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         王淑青, 姚伟, 陈进, 等.基于直方图均衡化与形态学处理的边缘检测[J].计算机应用与软件, 2016, 33 (3) :193-196.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" 全永奇, 邓家先, 寇计萍, 等.一种新的NSCT域图像增强算法[J].计算机应用与软件, 2016, 33 (3) :206-209, 221." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201603048&amp;v=Mjc0MjRaTEc0SDlmTXJJOUJiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXprVUx6SUx6VFo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         全永奇, 邓家先, 寇计萍, 等.一种新的NSCT域图像增强算法[J].计算机应用与软件, 2016, 33 (3) :206-209, 221.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(05),204-210+241 DOI:10.3969/j.issn.1000-386x.2019.05.035            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于双边伽马校正的保亮度图像增强方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E9%92%B0&amp;code=41743686&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡钰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%94%9C%E7%94%9C&amp;code=30201926&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李甜甜</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%BB%84%E6%A2%81%E6%9D%BE&amp;code=28723485&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">黄梁松</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%8E%89%E9%9C%9E&amp;code=08234066&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李玉霞</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%B1%B1%E4%B8%9C%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%94%B5%E6%B0%94%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0049968&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">山东科技大学电气与自动化工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>图像增强的许多实际应用需要保持输入图像的亮度, 因此提出基于伽马校正及多尺度图像融合的保亮度图像增强方法。分析伽马校正曲线对图像中过暗和过亮区域的影响, 设计能够同时改善过暗和过亮区域对比度的双边伽马校正曲线。对双边伽马校正所生成的两幅校正图像进行多尺度图像融合, 其中低频子带图像采用加权平均融合规则以保持亮度, 高频子带图像采用平均选取融合规则以突出细节。该方法是一种空频域相结合的保亮度图像增强方法。实验结果表明, 该方法在避免过增强、保亮度和突出细节三方面均取得良好效果, 且优于一些经典的基于直方图均衡化思想的图像增强方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%9D%E4%BA%AE%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">保亮度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">图像增强;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BC%BD%E9%A9%AC%E6%A0%A1%E6%AD%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">伽马校正;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%B0%BA%E5%BA%A6%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多尺度图像融合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    胡钰, 硕士, 主研领域:模式识别与智能系统。;
                                </span>
                                <span>
                                    李甜甜, 硕士。;
                                </span>
                                <span>
                                    黄梁松, 讲师。;
                                </span>
                                <span>
                                    李玉霞, 教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>山东省重大科技创新工程项目 (2017CXGC0901);</span>
                    </p>
            </div>
                    <h1><b>BRIGHTNESS PRESERVING IMAGE ENHANCEMENT METHOD BASED ON BILATERAL GAMMA CORRECTION</b></h1>
                    <h2>
                    <span>Hu Yu</span>
                    <span>Li Tiantian</span>
                    <span>Huang Liangsong</span>
                    <span>Li Yuxia</span>
            </h2>
                    <h2>
                    <span>College of Electrical Engineering and Automation, Shandong University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Maintaining the brightness of input images are required to many practical applications of image enhancement. Therefore, this paper presented a brightness preserving image enhancement method based on gamma correction and multi-scale image fusion. We designed bi-gamma correction curves to improve the contrast of over-bright and over-dark regions by analyzing the influence of gamma correction curve on both regions. Then, these two revised images, generated by bi-gamma correction, were integrated by multi-scale image fusion. A weighted average fusion rule was adopted for low frequency sub-band images to keep brightness, and an average and selection fusion rule was adopted for high frequency sub-band images to highlight details. This method was performed by a combination of spatial and frequency domain. Experimental results indicate that this method yields good performance in three aspects of avoiding over-enhancement, preserving brightness and enhancing details, and outperforms some image enhancement methods based on the concept of histogram equalization.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Brightness%20preserving&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Brightness preserving;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Image%20enhancement&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Image enhancement;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Gamma%20correction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Gamma correction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-scale%20image%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-scale image fusion;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="48">保亮度图像增强方法在消费电子产品中有着广泛的用途, 比如电视视频信号为了避免视觉效果失真, 在图像增强过程中会尽量保持视频序列的亮度不变。传统的直方图均衡化方法具有输出图像亮度与输入图像亮度无关的特点, 使得经过该方法增强后的图像往往出现“过增强”或“伪影”现象, 破坏了图像固有的自然效果, 相应地限制了该方法在消费电子产品中的应用<citation id="171" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。针对传统直方图均衡化方法 (CHE) 的如上缺点, 近年来国际上不断提出改进方法<citation id="172" type="reference"><link href="3" rel="bibliography" /><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>。1997年, Kim提出双边直方图均衡化方法 (BBHE) <citation id="164" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>;1999年, Wang提出等区域二元子图直方图均衡化方法 (DISHE) <citation id="165" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>;2003年, Chen提出迭代均值分割直方图均衡化方法 (RMSHE) <citation id="166" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和最小亮度差双边直方图均衡化方法 (MMBEBHE) <citation id="167" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>;2005年, Wang从变分的角度提出最大熵亮度保持直方图均衡化方法 (BPHEME) <citation id="168" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>;2007年, Menotti提出多直方图均衡化方法 (MHE) <citation id="169" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。上述直方图均衡化思想方法的共同点是通过寻找某种约束下的一个或多个直方图分隔点来实现图像的保亮度, 借助直方图均衡化方法固有的对比度拉伸特性来提高图像对比度。基于直方图均衡化思想<citation id="173" type="reference"><link href="21" rel="bibliography" /><link href="23" rel="bibliography" /><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><link href="31" rel="bibliography" /><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><link href="41" rel="bibliography" /><sup>[<a class="sup">10</a>,<a class="sup">11</a>,<a class="sup">12</a>,<a class="sup">13</a>,<a class="sup">14</a>,<a class="sup">15</a>,<a class="sup">16</a>,<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>,<a class="sup">20</a>]</sup></citation>的图像增强方法存在两个局限性:其一, 根据整幅图像或局部图像的灰度统计特性来调整图像亮度, 而忽视中心像素点与其邻域像素点的空间相关性, 因此容易导致图像“过增强”现象;其二, 该类方法是在空间域增强, 在确定直方图分割点后, 难以在灰度级子图内利用直方图均衡化同时增强对比度和保图像亮度<citation id="170" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="49">传统的伽马校正通常会改变输入图像的亮度且难以同时在过暗和过亮区域同时取得良好的增强效果。本文设计的双边伽马校正曲线, 在空域能够同时改善输入图像中的过暗区域和过亮区域视觉效果。多尺度图像分解能够使得图像亮度和细节单独处理, 其中决定图像的亮度信息主要集中在低频, 细节信息主要集中在高频<citation id="174" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>。基于上述两点, 本文提出一种空域频域相结合的保亮度图像增强方法。首先在空域将输入的图像进行双边伽马校正, 然后对双边伽马校正所生成的两幅图像进行多尺度图像融合<citation id="175" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 其中在低频子带图像采用加权平均融合规则以保图像亮度, 在高频子带图像采用平均选择融合规则以突出细节。</p>
                </div>
                <h3 id="50" name="50" class="anchor-tag"><b>1 方法设计</b></h3>
                <h4 class="anchor-tag" id="51" name="51"><b>1.1 系统框架</b></h4>
                <div class="p1">
                    <p id="52">伽马校正通常会改变输入图像的亮度<citation id="176" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>, 而图像融合方法则要求输入多幅图像<citation id="177" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 因此伽马校正或图像融合方法很少用于保亮度的图像增强。本文首先根据伽马校正设计了双边伽马校正曲线, 然后将双边伽马校正与多尺度图像融合方法相结合用于保亮度图像增强。图1是本文方法的流程图。</p>
                </div>
                <div class="area_img" id="53">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905036_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文方法的流程图" src="Detail/GetImg?filename=images/JYRJ201905036_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文方法的流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905036_053.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="54" name="54"><b>1.2 双边伽马校正曲线设计</b></h4>
                <div class="p1">
                    <p id="55">伽马校正已经广泛地应用于改善光照不均匀的退化图像<citation id="178" type="reference"><link href="25" rel="bibliography" /><link href="27" rel="bibliography" /><sup>[<a class="sup">12</a>,<a class="sup">13</a>]</sup></citation>, 其简化形式表示为:</p>
                </div>
                <div class="p1">
                    <p id="56"><i>g</i> (<i>u</i>) =<i>u</i><sup><i>γ</i></sup>      (1) </p>
                </div>
                <div class="p1">
                    <p id="57">式中:<i>u</i>是灰度值, <i>γ</i>是伽马值。鉴于不同<i>γ</i>的伽马校正曲线对亮区域和暗区域的改善效果不同, 本文设计了双边伽马校正曲线。</p>
                </div>
                <h4 class="anchor-tag" id="58" name="58"><b>1.2.1 曲线段特性分析</b></h4>
                <div class="p1">
                    <p id="59">图2 (a) 表明, <i>γ</i>&lt;1时, 曲线<i>OAB</i>使得每个灰度级 (除两端点) 的亮度都得到了提升, 有利于提高过暗区域的亮度;图2 (b) 表明, <i>γ</i>&gt;1时, 曲线<i>OAB</i>使得 (除两端点) 每个灰度级的亮度都得到了衰减, 有利于抑制过亮区域的亮度增加。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905036_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 伽马值γ对亮度和对比度的影响" src="Detail/GetImg?filename=images/JYRJ201905036_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 伽马值<i>γ</i>对亮度和对比度的影响  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905036_06000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="61">文献<citation id="179" type="reference">[<a class="sup">14</a>]</citation>给出了两像素点间的对比度定义为:</p>
                </div>
                <div class="p1">
                    <p id="62"><mathml id="63"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>C</mtext><mtext>o</mtext><mtext>n</mtext><mtext>t</mtext><mtext>r</mtext><mtext>a</mtext><mtext>s</mtext><mtext>t</mtext><mo>=</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>+</mo><mi>Ι</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="64">式 (2) 直观地表明在亮度差<mathml id="65"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>不变的情况下, 背景亮度的增加使得图像对比度下降, 视觉效果变差。事实上在亮度差不变的条件下对过暗区域进行亮度提高后, 人眼通常会观察到更多的细节信息, 视觉效果反而得到提高, 其原因可用人眼视觉系统的亮度阈值效应曲线<citation id="180" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>给予解释:在低灰度区间, 灰度的增加将使得临界可见偏差JND降低, 因此在经过背景亮度提高后的过暗区域人眼通常会观察到更多的细节信息。</p>
                </div>
                <div class="p1">
                    <p id="66">在图2 (a) 中, 点<i>A</i>是曲线斜率为1的点, 其坐标为 (<i>u</i><sub><i>a</i></sub>, <i>g</i> (<i>u</i><sub><i>a</i></sub>) ) 。假定图像中过暗区域灰度值在[0, <i>x</i><sub><i>a</i></sub>]内, 由于图2 (a) 中曲线段<i>OA</i>的斜率大于1, 所以曲线段<i>OA</i>提高了灰度值在[0, <i>x</i><sub><i>a</i></sub>]内过暗区域的亮度和梯度值, 抑制了背景亮度提高引起的对比度衰减。此外, 亮度阈值曲线影响, 曲线段<i>OA</i>使得过暗区域更多的细节将被显示。</p>
                </div>
                <div class="p1">
                    <p id="67">在图2 (b) 中, 点<i>A</i>是曲线斜率等于1的点, 其对应坐标记为 (<i>u</i><sub><i>a</i></sub>, <i>g</i> (<i>u</i><sub><i>a</i></sub>) ) 。图2 (b) 中曲线段<i>AB</i>使得灰度值介于[<i>u</i><sub><i>a</i></sub>, 1]内的过亮区域的亮度降低, 另一方面该曲线段的斜率大于1使得相邻像素间的亮度差<mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>Ι</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mi>Ι</mi><msub><mrow></mrow><mi>j</mi></msub></mrow><mo>|</mo></mrow></mrow></math></mathml>提高, 两者共同提高了对比度。</p>
                </div>
                <div class="p1">
                    <p id="69">上述分析表明, 图2 (a) 的曲线段<i>OA</i>适用于过暗区域的亮度提高和对比度增强, 从而改善过暗区域的视觉效果;图2 (a) 的曲线段<i>AB</i>显然会使得灰度值在[<i>u</i><sub><i>a</i></sub>, 1]内的区域亮度增加, 同时削弱该区域的对比度, 从而导致该区域的视觉效果恶化。图2 (b) 的曲线段<i>OA</i>部分, 显然使得灰度值在[0, <i>u</i><sub><i>a</i></sub>]内的区域亮度降低, 同时削弱其图像对比度, 从而造成该区域的视觉效果恶化;图2 (b) 的曲线段<i>AB</i>抑制了灰度值分布在区间[<i>u</i><sub><i>a</i></sub>, 1]内的过亮区域的亮度, 提高了该区域的图像对比度, 从而改善了该区域的图像视觉效果。表1是伽马校正曲线段对不同亮度区域增强效果的总结。</p>
                </div>
                <div class="area_img" id="70">
                    <p class="img_tit"><b>表1 伽马校正曲线段对亮度区域的改善效果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="70" border="1"><tr><td><br /><i>γ</i></td><td colspan="2"><i>γ</i>&lt;1</td><td colspan="2"><i>γ</i>&gt;1</td></tr><tr><td><br />区域所属的亮度范围</td><td>[0, <i>u</i><sub><i>a</i></sub>]</td><td>[<i>u</i><sub><i>a</i></sub>, 1]</td><td>[0, <i>u</i><sub><i>a</i></sub>]</td><td>[<i>u</i><sub><i>a</i></sub>, 1]</td></tr><tr><td><br />曲线段</td><td><i>OA</i></td><td><i>AB</i></td><td><i>OA</i></td><td><i>AB</i></td></tr><tr><td><br />亮度</td><td>+</td><td>+</td><td>-</td><td>-</td></tr><tr><td><br />对比度</td><td>+</td><td>-</td><td>-</td><td>+</td></tr><tr><td><br />视觉效果</td><td>改善</td><td>恶化</td><td>恶化</td><td>改善</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="71" name="71"><b>1.2.2 伽马值<i>γ</i>的确定</b></h4>
                <div class="p1">
                    <p id="72">确定伽马校正曲线的关键步骤是确定伽马值<i>γ</i>。图2中, 点<i>A</i>是伽马校正曲线斜率为1的点。不同的伽马校正曲线对应的点<i>A</i>位置不同;反之, 给定点<i>A</i>的位置也就唯一地确定了伽马校正曲线。因此可通点<i>A</i>来间接地确定伽马校正曲线。根据式 (1) 求得导数为:</p>
                </div>
                <div class="p1">
                    <p id="73"><i>g</i>′ (<i>u</i>) =<i>ru</i><sup><i>γ</i>-1</sup>      (3) </p>
                </div>
                <div class="p1">
                    <p id="74">令<mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msup><mi>g</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>u</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo><msub><mrow></mrow><mrow><mi>u</mi><mo>=</mo><mi>u</mi><msub><mrow></mrow><mn>0</mn></msub></mrow></msub><mo>=</mo><msup><mi>g</mi><mo>′</mo></msup><mo stretchy="false"> (</mo><mi>u</mi><msub><mrow></mrow><mn>0</mn></msub><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mrow></math></mathml>, 则可导出<i>u</i><sub>0</sub>关于<i>γ</i>的函数为:</p>
                </div>
                <div class="p1">
                    <p id="76"><mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>u</mi><msub><mrow></mrow><mn>0</mn></msub><mo>=</mo><mi>r</mi><msup><mrow></mrow><mrow><mrow><mo> (</mo><mrow><mfrac><mn>1</mn><mrow><mn>1</mn><mo>-</mo><mi>r</mi></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></msup><mtext> </mtext><mo stretchy="false">{</mo><mi>r</mi></mrow></math></mathml>:0&lt;<i>r</i>&lt;1∪1&lt;<i>r</i>&lt;+∞}      (4) </p>
                </div>
                <div class="p1">
                    <p id="78">该公式表明在已知<i>u</i><sub>0</sub>条件下可求解出<i>γ</i>。</p>
                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>1.2.3 参数值<i>u</i></b><sub><b>0</b></sub><b>的确定</b></h4>
                <div class="p1">
                    <p id="80">参数值<i>u</i><sub>0</sub>的确定通过估计过暗区域和过亮区域的灰度值分布范围来完成。若<i>γ</i>&lt;1, 理想的<i>u</i><sub>0</sub>值使得[0, <i>u</i><sub>0</sub>]尽可能地覆盖过暗区域的灰度值范围, 且其取值尽可能小;若<i>γ</i>&gt;1, 理想的<i>u</i><sub>0</sub>值使得[<i>u</i><sub>0</sub>, 1]尽可能地覆盖过亮区域的灰度值分布范围, 且其取值尽可能大。本文给出两种估计参数值<i>u</i><sub>0</sub>的策略:</p>
                </div>
                <div class="p1">
                    <p id="81"> (1) 预先设定策略。由场景明暗区域的大致灰度区间分布预先设定参数值<i>u</i><sub>0</sub>;</p>
                </div>
                <div class="p1">
                    <p id="82"> (2) 直方图统计策略。根据图像的灰度统计直方图, 找出过暗区域和过亮区域的灰度值分界点来确定参数值<i>u</i><sub>0</sub>。</p>
                </div>
                <h4 class="anchor-tag" id="83" name="83"><b>1.2.4 设计流程</b></h4>
                <div class="p1">
                    <p id="84">综上所述, 双边伽马校正曲线的设计流程归纳为:首先在<i>γ</i>&lt;1条件下, 确定用于改善过暗区域的<i>u</i><sub>0</sub>值;在<i>γ</i>&gt;1条件下, 确定用于改善过亮区域的<i>u</i><sub>0</sub>值。然后根据式 (4) 确定出一组伽马值 (对应两条伽马校正曲线) , 最终生成同时改善图像中过暗区域和过亮区域视觉效果的双边伽马校正曲线。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>1.3 双边伽马校正后图像的融合处理</b></h4>
                <div class="p1">
                    <p id="86">表1表明双边伽马校正所生成的两幅图像中视觉效果改善和视觉恶化均存在, 且双边伽马校正改变了输入图像的亮度。因此, 优化两者视觉效果和保亮度需要对图像进行融合处理。在空域将伽马校正所生成的两幅图像进行加权平均图像融合会造成图像对比度下降, 因此本文后端采用基于频率思想的多尺度图像融合处理方法。</p>
                </div>
                <div class="p1">
                    <p id="87">多尺度图像融合优势在于它将图像分解到不同的频率域, 在不同的频率域运用不同的融合规则, 使得融合图像保留了输入图像在不同频率域的显著特征<citation id="181" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。通常在多尺度分析中, 图像的低频分量集中了图像的绝大部分能量, 低频分量决定图像亮度, 高频分量决定图像细节<citation id="182" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>。因此本文方法首先利用多尺度分解实现双边伽马校正后图像的亮度和细节相分离, 然后根据亮度和细节的优化目标设计不同的融合规则, 具体如下:</p>
                </div>
                <div class="p1">
                    <p id="88">假定<i>f</i><sub><i>A</i></sub>表示输入图像, 其图像均值记为<i>m</i><sub><i>A</i></sub>;<i>f</i><sub><i>B</i></sub>和<i>f</i><sub><i>C</i></sub>分别表示经双边伽马校正生成的两幅校正图像, 其均值分别记为<i>m</i><sub><i>B</i></sub>和<i>m</i><sub><i>C</i></sub>。将<i>f</i><sub><i>B</i></sub>和<i>f</i><sub><i>C</i></sub>进行<i>N</i>层多尺度分解成具有两个多尺度图像序列<i>f</i><sup><i>N</i></sup><sub><i>B</i></sub>和<i>f</i><sup><i>N</i></sup><sub><i>C</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="89"><i>f</i><sup><i>N</i></sup><sub><i>X</i></sub>={<i>f</i><sup><i>k</i>, <i>L</i></sup><sub><i>X</i></sub><i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>X</i></sub>} <i>k</i>=1, 2, …, <i>N</i>;<i>X</i>={<i>B</i>, <i>C</i>}      (5) </p>
                </div>
                <div class="p1">
                    <p id="90">式中:<i>f</i><sup><i>k</i>, <i>L</i></sup><sub><i>X</i></sub>为第<i>k</i>层上的低频子带图像, <i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>X</i></sub>为第<i>k</i>层上第<i>z</i>方向上的高频子带图像。</p>
                </div>
                <div class="p1">
                    <p id="91">若多尺度分解方法是拉普拉斯塔形分解 (每一层包含两个子空间) , 则式 (5) 可改写为:</p>
                </div>
                <div class="p1">
                    <p id="92"><i>f</i><sup><i>N</i></sup><sub><i>X</i></sub>={<i>f</i><sup><i>k</i>, <i>L</i></sup><sub><i>X</i></sub><i>f</i><sup><i>k</i>, <i>H</i></sup><sub><i>X</i></sub>} <i>k</i>=1, 2, …, <i>N</i>;<i>X</i>={<i>B</i>, <i>C</i>}      (6) </p>
                </div>
                <div class="p1">
                    <p id="93">若多尺度分解方法是小波分解 (每一层包含四个子空间) , 则式 (5) 可改写为:</p>
                </div>
                <div class="p1">
                    <p id="94"><i>f</i><sup><i>N</i></sup><sub><i>X</i></sub>={<i>f</i><sup><i>k</i>, <i>LL</i></sup><sub><i>X</i></sub>, <i>f</i><sup><i>k</i>, <i>LH</i></sup><sub><i>X</i></sub>, <i>f</i><sup><i>k</i>, <i>HL</i></sup><sub><i>X</i></sub><i>f</i><sup><i>k</i>, <i>HH</i></sup><sub><i>X</i></sub>} <i>k</i>=1, 2, …, <i>N</i>;<i>X</i>={<i>B</i>, <i>C</i>}      (7) </p>
                </div>
                <div class="p1">
                    <p id="95">由于本文方法与多尺度分解方法具有相同的基本思路, 所以统一采用式 (5) 作为基本形式进行阐述。</p>
                </div>
                <div class="p1">
                    <p id="96">为了保持输入图像亮度, 本文采用如下加权平价融合规则融合低频子带图像<i>f</i><sup><i>N</i>, <i>L</i></sup><sub><i>B</i></sub>和<i>f</i><sup><i>N</i>, <i>L</i></sup><sub><i>C</i></sub>, 记融合后的低频子带图像<i>f</i><sup><i>N</i>, <i>L</i></sup><sub><i>F</i></sub>为:</p>
                </div>
                <div class="p1">
                    <p id="97"><i>f</i><sup><i>N</i>, <i>L</i></sup><sub><i>F</i></sub>=<i>α</i>·<i>f</i><sup><i>N</i>, <i>L</i></sup><sub><i>B</i></sub>+<i>β</i>·<i>f</i><sup><i>N</i>, <i>L</i></sup><sub><i>C</i></sub>      (8) </p>
                </div>
                <div class="p1">
                    <p id="98">式中:<mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>×</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>m</mi><msub><mrow></mrow><mi>A</mi></msub></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>B</mi></msub></mrow></mfrac></mrow><mo>) </mo></mrow><mo>, </mo><mi>β</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>×</mo><mrow><mo> (</mo><mrow><mfrac><mrow><mi>m</mi><msub><mrow></mrow><mi>A</mi></msub></mrow><mrow><mi>m</mi><msub><mrow></mrow><mi>C</mi></msub></mrow></mfrac></mrow><mo>) </mo></mrow></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="100">为了突出图像细节, 本文采用Burt提出的平均选择融合规则<citation id="183" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>融合高频子带图像<i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>B</i></sub>和<i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>C</i></sub>。计算融合后高频子带图像<i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>F</i></sub>的步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="101">1) 分别计算<i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>B</i></sub>和<i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>C</i></sub>在像素位置<i>p</i>处的局部区域能量<i>E</i><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>B</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup></mrow></math></mathml>和<i>E</i><mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>C</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup></mrow></math></mathml>, 得:</p>
                </div>
                <div class="p1">
                    <p id="104"><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msubsup><mrow></mrow><mi>X</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Q</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></munder><mi>w</mi></mstyle><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo><mo stretchy="false">[</mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>X</mi></msub><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="106">式中:<i>E</i><mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>X</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup></mrow></math></mathml> (<i>p</i>) 表示图像<i>f</i><sub><i>X</i></sub>, <i>X</i>={<i>B</i>, <i>C</i>}中第<i>k</i>层, 第<i>z</i>方向上以<i>p</i>为中心位置, 区域<i>Q</i><sub><i>p</i></sub>内的局部区域能量, 其中<i>w</i> (<i>q</i>) 为权值, 且满足<mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Q</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></munder><mi>w</mi></mstyle><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn></mrow></math></mathml>。当<i>Q</i><sub><i>p</i></sub>窗口尺寸分别为3×3和5×5时, <i>w</i>的取值分别为:</p>
                </div>
                <div class="p1">
                    <p id="109" class="code-formula">
                        <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mn>1</mn><mn>6</mn></mrow></mfrac><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>2</mn></mtd><mtd><mn>4</mn></mtd><mtd><mn>2</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>2</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="110">和</p>
                </div>
                <div class="p1">
                    <p id="111" class="code-formula">
                        <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mn>1</mn><mrow><mn>2</mn><mn>5</mn><mn>6</mn></mrow></mfrac><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>4</mn></mtd><mtd><mn>6</mn></mtd><mtd><mn>4</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>4</mn></mtd><mtd><mn>1</mn><mn>6</mn></mtd><mtd><mn>2</mn><mn>4</mn></mtd><mtd><mn>1</mn><mn>6</mn></mtd><mtd><mn>4</mn></mtd></mtr><mtr><mtd><mn>1</mn><mn>6</mn></mtd><mtd><mn>2</mn><mn>4</mn></mtd><mtd><mn>3</mn><mn>6</mn></mtd><mtd><mn>2</mn><mn>4</mn></mtd><mtd><mn>6</mn></mtd></mtr><mtr><mtd><mn>4</mn></mtd><mtd><mn>1</mn><mn>6</mn></mtd><mtd><mn>2</mn><mn>4</mn></mtd><mtd><mn>1</mn><mn>6</mn></mtd><mtd><mn>4</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>4</mn></mtd><mtd><mn>6</mn></mtd><mtd><mn>4</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="112">2) 计算<i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>B</i></sub>和<i>f</i><sup><i>k</i>, <i>Hz</i></sup><sub><i>C</i></sub>对应区域的匹配度<i>M</i><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>B</mi><mi>C</mi></mrow><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup></mrow></math></mathml>的公式为:</p>
                </div>
                <div class="p1">
                    <p id="114"><mathml id="115"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msubsup><mrow></mrow><mrow><mi>B</mi><mi>C</mi></mrow><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mn>2</mn><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Q</mi><msub><mrow></mrow><mi>p</mi></msub></mrow></munder><mi>w</mi></mstyle><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo></mrow><mrow><mi>E</mi><msubsup><mrow></mrow><mi>B</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>+</mo><mi>E</mi><msubsup><mrow></mrow><mi>C</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="116">3) 确定融合算子。先给定义一匹配度阈值<i>T</i>, 满足条件0.5≤<i>T</i>≤1。若<i>M</i><mathml id="117"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>B</mi><mi>C</mi></mrow><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup></mrow></math></mathml> (<i>p</i>) &lt;<i>T</i>, 则:</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>F</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mtext> </mtext><mi>E</mi><msubsup><mrow></mrow><mi>B</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>≥</mo><mi>E</mi><msubsup><mrow></mrow><mi>C</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>F</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>E</mi><msubsup><mrow></mrow><mi>B</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>&lt;</mo><mi>E</mi><msubsup><mrow></mrow><mi>C</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="119">若<i>M</i><mathml id="120"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>B</mi><mi>C</mi></mrow><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup></mrow></math></mathml> (<i>p</i>) ≥<i>T</i>, 则:</p>
                </div>
                <div class="p1">
                    <p id="121" class="code-formula">
                        <mathml id="121"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>F</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mi>W</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>+</mo><mi>W</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mi>E</mi><msubsup><mrow></mrow><mi>B</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>≥</mo><mi>E</mi><msubsup><mrow></mrow><mi>C</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>F</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mi>W</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>B</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>+</mo><mi>W</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mi>f</mi><msup><mrow></mrow><mspace width="0.25em" /></msup><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow><msub><mrow></mrow><mi>C</mi></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mi>E</mi><msubsup><mrow></mrow><mi>B</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>&lt;</mo><mi>E</mi><msubsup><mrow></mrow><mi>C</mi><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="122">式中:<mathml id="123"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo> (</mo><mrow><mfrac><mrow><mn>1</mn><mo>-</mo><mi>Μ</mi><msubsup><mrow></mrow><mrow><mi>B</mi><mi>C</mi></mrow><mrow><mi>k</mi><mo>, </mo><mi>Η</mi><mi>z</mi></mrow></msubsup><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mrow><mrow><mn>1</mn><mo>-</mo><mi>Τ</mi></mrow></mfrac></mrow><mo>) </mo></mrow><mo>, </mo><mi>W</mi><msub><mrow></mrow><mrow><mi>max</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo><mo>=</mo><mn>1</mn><mo>-</mo><mi>W</mi><msub><mrow></mrow><mrow><mi>min</mi></mrow></msub><mo stretchy="false"> (</mo><mi>p</mi><mo stretchy="false">) </mo></mrow></math></mathml>。</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag"><b>2 实 验</b></h3>
                <h4 class="anchor-tag" id="125" name="125"><b>2.1 评价指标</b></h4>
                <div class="p1">
                    <p id="126">本文采用主观视觉效果和客观图像质量评价指标来综合评价保亮度图像增强方法。本文采用亮度B、亮度差BD、平均局部标准差MLSD作为客观评价指标<citation id="184" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 具体内容如下:</p>
                </div>
                <div class="p1">
                    <p id="127">亮度B在保亮度图像增强方法中用图像平均灰度值来表征<citation id="185" type="reference"><link href="3" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">8</a>]</sup></citation>, 因此亮度差BD也可以用输出图像和输入图像的平均灰度差绝对值来表征。若BD值越小, 表明输出图像对应的增强方法保亮度性能越优, 反之越差。</p>
                </div>
                <div class="p1">
                    <p id="128">通常“过增强”图像具有较大的MLSD值, 因此在不发生“过增强”基础上讨论MLSD指标才具有意义。在不发生“过增强”前提下, MLSD值越大表明其局部对比度越好, 其中MLSD指标定义为:</p>
                </div>
                <div class="p1">
                    <p id="129"><mathml id="130"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>L</mi><mi>S</mi><mi>D</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>R</mi><mi>o</mi><mi>w</mi><mo>×</mo><mi>C</mi><mi>o</mi><mi>l</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><mrow><mtext>R</mtext><mtext>o</mtext><mtext>w</mtext></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>y</mi><mo>=</mo><mn>1</mn></mrow><mrow><mtext>C</mtext><mtext>o</mtext><mtext>l</mtext></mrow></munderover><mi>L</mi></mstyle></mrow></mstyle><mi>S</mi><mi>D</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="131">式中:<i>LSD</i> (<i>x</i>, <i>y</i>) =<mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>Μ</mi><mo>×</mo><mi>Ν</mi></mrow></mfrac><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>q</mi><mo>∈</mo><mi>Q</mi></mrow></munder><mo stretchy="false">[</mo></mstyle><mi>u</mi><mo stretchy="false"> (</mo><mi>q</mi><mo stretchy="false">) </mo><mo>-</mo><mi>m</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></math></mathml>, <i>M</i>×<i>N</i>表示以 (<i>x</i>, <i>y</i>) 为中心的滑动窗口<i>Q</i>的尺寸, 本文取滑动窗口尺寸为50×50。</p>
                </div>
                <h4 class="anchor-tag" id="133" name="133"><b>2.2 实验结果及分析</b></h4>
                <div class="p1">
                    <p id="134">本文以四幅不同亮度的标准图像<citation id="186" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>作为输入图像设计了两组实验。实验中的四幅图像分别被命名为Carnev、House、Barch和Flash, 它们的平均灰度值分别为20.085、159.338、126.593、91.617。为了与其他算法进行比较, 我们采用了CHE、BBHE、DSIHE、MMBEBHE、RMSHE (r=2) 、BPHEME等不同的算法以及我们提出的算法对图像进行增强。</p>
                </div>
                <div class="p1">
                    <p id="135">在我们提出的图像增强方法中, 实验过程分为两个步骤。第一步是双伽马矫正的过程, 采用预先设定策略分别在r&lt;1条件下, 取u<sub>0</sub>=0.2;在r≥1条件下, 取u<sub>0</sub>=0.5。第二步是多尺度图像融合的过程, 采用拉普拉斯金字塔分解<citation id="187" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>将双伽马校正后的图像分解为三层, 然后进行融合, 在高频子带图像融合过程中, 滑动窗口的尺寸为3×3。</p>
                </div>
                <div class="p1">
                    <p id="136">图3-图6反映了四组实验的结果, 表2-表5中显示B、BD和MLSD值, 可作为评价图像处理效果的评价标准。</p>
                </div>
                <div class="p1">
                    <p id="137">分析结果如下:</p>
                </div>
                <div class="p1">
                    <p id="138">1) 在过增强方面。我们可以通过视觉来判断过增强, 在图3中BBHE、DSIHE、MMBEBHE和RMSHE四种增强方法均出现明显的“过增强”现象;而基于HE方法所得到的图像在图4、图5和图6中都产生了图像过度增强, 因为图4-图6比图3的平均灰度值大, 所以图4、图6的过增强不明显。但是在图3-图6中本文方法均没有出现“过增强”现象, 表明本文方法能够抑制“过增强”现象。</p>
                </div>
                <div class="p1">
                    <p id="139">2) 在亮度保持方面。由于BD反映了两幅图像的亮度差异, 因此BD是判断图像亮度保存效果的最直接标准。我们可以看到在表2、表3、表4、表5中BD值分别为0.119、0.011、0.020和0.290, 远小于其他方法。实验结果表明, 无论图像的平均灰度值大小, 该方法都具有良好稳定的亮度保持性能。</p>
                </div>
                <div class="p1">
                    <p id="140">3) 在“过增强”和 保亮度前提下分析MLSD。MLSD能够反映局部区域对比度的变化, MLSD值越大, 越容易产生图像的边缘, 因此MLSD值越大越好。我们可以从表2到表5中看到本方法的MLSD值分别为42.919、48.390、42.051和52.476, 虽然这些值不全是每组中最大的值, 但是它们是较大的值之一, 实验表明, 本文方法没有发生“过增强”且有效保亮度, 其指标大约1.5倍于输入图像的MLSD指标, 表明本文方法能够增强输入图像细节。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905036_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 输入图像名为“Carnev”的视觉效果对比" src="Detail/GetImg?filename=images/JYRJ201905036_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 输入图像名为“Carnev”的视觉效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905036_14400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="145">
                    <p class="img_tit"><b>表2 输入图像名为Carnev的客观评价指标对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="145" border="1"><tr><td><br />方法</td><td>B</td><td>BD</td><td>MLSD</td></tr><tr><td><br />输入图像</td><td>20.085</td><td></td><td>24.440</td></tr><tr><td><br />CHE</td><td>142.722</td><td>122.637</td><td>45.733</td></tr><tr><td><br />BBHE</td><td>47.168</td><td>27.083</td><td>49.498</td></tr><tr><td><br />DSIHE</td><td>65.939</td><td>45.854</td><td>64.138</td></tr><tr><td><br />MMBEBHE</td><td>45.294</td><td>25.209</td><td>41.563</td></tr><tr><td><br />RMSHE (r=2) </td><td>28.849</td><td>8.764</td><td>37.680</td></tr><tr><td><br />BPHEME</td><td>21.860</td><td>1.775</td><td>13.905</td></tr><tr><td><br />本文方法</td><td>19.966</td><td><u>0.119</u></td><td><u>42.919</u></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905036_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 输入图像名为“House”的视觉效果对比" src="Detail/GetImg?filename=images/JYRJ201905036_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 输入图像名为“House”的视觉效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905036_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="150">
                    <p class="img_tit"><b>表3 输入图像名为House的客观评价指标对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="150" border="1"><tr><td><br />方法</td><td>B</td><td>BD</td><td>MLSD</td></tr><tr><td><br />输入图像</td><td>159.338</td><td></td><td>41.796</td></tr><tr><td><br />CHE</td><td>128.635</td><td>30.703</td><td>62.046</td></tr><tr><td><br />BBHE</td><td>151.858</td><td>7.480</td><td>63.478</td></tr><tr><td><br />DSIHE</td><td>148.768</td><td>10.570</td><td>64.232</td></tr><tr><td><br />MMBEBHE</td><td>160.308</td><td>0.970</td><td>51.185</td></tr><tr><td><br />RMSHE (r=2) </td><td>162.662</td><td>3.324</td><td>52.923</td></tr><tr><td><br />BPHEME</td><td>160.223</td><td>0.885</td><td>59.715</td></tr><tr><td><br />本文方法</td><td><u>159.349</u></td><td><u>0.011</u></td><td><u>48.390</u></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905036_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 输入图像名为“Barch”的视觉效果对比" src="Detail/GetImg?filename=images/JYRJ201905036_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 输入图像名为“Barch”的视觉效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905036_15400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="155">
                    <p class="img_tit"><b>表4 输入图像名为Barch的客观评价指标对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="155" border="1"><tr><td><br />方法</td><td>B</td><td>BD</td><td>MLSD</td></tr><tr><td><br />输入图像</td><td>126.593</td><td></td><td>38.801</td></tr><tr><td><br />CHE</td><td>128.643</td><td>2.050</td><td>57.806</td></tr><tr><td><br />BBHE</td><td>146.169</td><td>19.580</td><td>55.667</td></tr><tr><td><br />DSIHE</td><td>137.021</td><td>10.430</td><td>57.615</td></tr><tr><td><br />MMBEBHE</td><td>127.645</td><td>1.050</td><td>57.847</td></tr><tr><td><br />RMSHE (r=2) </td><td>137.145</td><td>10.550</td><td>51.900</td></tr><tr><td><br />BPHEME</td><td>127.796</td><td>1.200</td><td>57.855</td></tr><tr><td><br />本文方法</td><td><u>126.608</u></td><td><u>0.020</u></td><td><u>42.051</u></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="159">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201905036_15900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 输入图像名为“Flash”的视觉效果对比" src="Detail/GetImg?filename=images/JYRJ201905036_15900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 输入图像名为“Flash”的视觉效果对比  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201905036_15900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="160">
                    <p class="img_tit"><b>表5 输入图像名为Flash的客观评价指标对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="160" border="1"><tr><td><br />方法</td><td>B</td><td>BD</td><td>MLSD</td></tr><tr><td><br />输入图像</td><td>91.617</td><td></td><td>44.573</td></tr><tr><td><br />CHE</td><td>134.105</td><td>42.490</td><td>43.456</td></tr><tr><td><br />BBHE</td><td>117.266</td><td>25.650</td><td>46.826</td></tr><tr><td><br />DSIHE</td><td>116.636</td><td>25.020</td><td>46.649</td></tr><tr><td><br />MMBEBHE</td><td>102.225</td><td>10.610</td><td>54.971</td></tr><tr><td><br />RMSHE (r=2) </td><td>103.850</td><td>12.230</td><td>49.801</td></tr><tr><td><br />BPHEME</td><td>95.647</td><td>4.030</td><td>44.960</td></tr><tr><td><br />本文方法</td><td><u>91.326</u></td><td><u>0.290</u></td><td><u>52.476</u></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="161" name="161" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="162">保亮度图像增强处理本质上是一种在亮度不变约束下的图像优化过程, 其优化目标是增强图像对比度 (突出细节) , 同时避免“过增强”现象。目前国际上的典型方法是借助于改进直方图均衡化思想进行图像增强, 但直方图均衡化思想的图像增强方法存在其固有局限性。</p>
                </div>
                <div class="p1">
                    <p id="163">本文方法与其他方法相比的优点:与直方图中“尖峰”处对应的灰度变换曲线相比, 双边伽马曲线是相对平滑曲线, 不易出现过度灰度拉升, 避免了过增强现象。此外, 双边伽马曲线也为后端的图像融合创造了条件, 多尺度图像融合从频域上实现了亮度和细节分离, 使得亮度和细节能够分别融合处理。亮度信息主要集中在低频, 本文采用加权平均融合策略实现保亮度的目标。细节突出 (或对比度增强) 与相邻像素亮度值密切相关, 本文方法在融合高频子带图像过程中通过在滑动窗内融合, 因此充分考虑了像素间的空间相关性。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-Histogram Equalization Methods for Contrast Enhancement and Brightness Preserving">

                                <b>[1]</b> Menotti D, Najman L, Facon J, et al.Multi-Histogram Equalization Methods for Contrast Enhancement and Brightness Preserving[J].IEEE Transactions on Consumer Electronics, 2007, 53 (3) :1186-1194.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic multi-histogram equalisation for image contrast enhancement with improved brightness preservation">

                                <b>[2]</b> Senthamarai G, Santhi K.Dynamic multi-histogram equalisation for image contrast enhancement with improved brightness preservation[C]//International Conference on Electronics and Communication Systems.IEEE, 2015:1205-1209.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Brightness preserving histogram equalization with maximum entropy: A variational perspective">

                                <b>[3]</b> Wang C, Ye Z.Brightness preserving histogram equalization with maximum entropy:a variational perspective[J].IEEE Transactions on Consumer Electronics, 2005, 51 (4) :1326-1334.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD8B7DBC56D2E2AC816AC54AE546702590&amp;v=MjE2NzRpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh3TG04dzZnPU5pZmNhcnZLR2FXKzNJcERFT2w2RGcxS3h4Y1ZtMHg0VEE2WHFSWXpmcktXUUxPZkNPTnZGUw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Magudeeswaran V, Ravichandran C G, Thirumurugan P.Brightness preserving bi‐level fuzzy histogram equalization for MRI brain image contrast enhancement[J].International Journal of Imaging Systems &amp; Technology, 2017, 27 (2) :153-161
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Minimum mean brightness error bi-histogram equalization in contrast enhancement">

                                <b>[5]</b> Chen S D, Ramli A R.Minimum mean brightness error bi-histogram equalization in contrast enhancement[J].IEEE Transactions on Consumer Electronics, 2004, 49 (4) :1310-1319.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement using recursive mean-separate histogram equalization for scalable brightness preservation">

                                <b>[6]</b> Chen S D, Ramli A R.Contrast enhancement using recursive mean-separate histogram equalization for scalable brightness preservation[J].IEEE Transactions on Consumer Electronics, 2003, 49 (4) :1301-1309.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image enhancement based on equal area dualistic sub-image histogram equalization method">

                                <b>[7]</b> Wang Y, Chen Q, Zhang B.Image enhancement based on equal area dualistic sub-image histogram equalization method[J].IEEE Transactions on Consumer Electronics, 1999, 45 (1) :68-75.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contrast enhancement using brightness preserving bi-histogram equalization">

                                <b>[8]</b> Kim Y T.Contrast enhancement using brightness preserving bi-histogram equalization[J].IEEE Transactions on Consumer Electronics, 1997, 43 (1) :1-8.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Brightness preserving and contrast limited bi-histogram equalization for image enhancement">

                                <b>[9]</b> Yao Z, Lai Z, Wang C, et al.Brightness preserving and contrast limited bi-histogram equalization for image enhancement[C]//International Conference on Systems and Informatics.IEEE, 2017:866-870.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Dynamic recursive subimage histogram equalization algorithm for image contrast enhancement">

                                <b>[10]</b> Jordanski M, Arsic A, Tuba M.Dynamic recursive subimage histogram equalization algorithm for image contrast enhancement[C]//Telecommunications Forum Telfor.IEEE, 2016:819-822.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Brightness preserving and contrast limited bi-histogram equalization for image enhancement">

                                <b>[11]</b> Yao Z, Lai Z, Wang C, et al.Brightness preserving and contrast limited bi-histogram equalization for image enhancement[C]//International Conference on Systems and Informatics.IEEE, 2017:866-870.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES84C7605F8374EBAF444887E50F9112C3&amp;v=MjcxMTBwbWFCdUhZZk9HUWxmQnJMVTA1dHRod0xtOHc2Zz1OaWZPZmJ1OGJkYktyNG96Yk9nSUNBbEx2bUFYN2p0MVFIaVhxUkpEY0xPVlI4bWNDT052RlNpV1dyN0pJRg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> Li H, Qiu H, Yu Z, et al.Infrared and visible image fusion scheme based on NSCT and low-level visual features[J].Infrared Physics &amp; Technology, 2016, 76:174-184.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot; Reducing Illumination Based on Nonlinear Gamma Correction&amp;quot;">

                                <b>[13]</b> Shi Y, Yang J, Wu R.Reducing Illumination Based on Nonlinear Gamma Correction[C]//IEEE International Conference on Image Processing.IEEE, 2007:I-529-I-532.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The role of gamma correction in colour image processing">

                                <b>[14]</b> Kubinger W, Vincze M, Ayromlou M.The role of gamma correction in colour image processing[C]//9th European Signal Processing Conference (EUSIPCO 1998) .IEEE, 1998.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Aquatic vision and the modulation transfer properties of unlighted and diffusely lighted natural waters">

                                <b>[15]</b> Jagger W S, Muntz W R.Aquatic vision and the modulation transfer properties of unlighted and diffusely lighted natural waters[J].Vision Research, 1993, 33 (13) :1755-1763.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A perceptually tuned subband image coder based on the measure of just-noticeable-distortion profile">

                                <b>[16]</b> Chou C H, Li Y C.A perceptually tuned subband image coder based on the measure of just-noticeable-distortion profile[J].IEEE Transactions on Circuits and Systems for Video Technology, 2002, 5 (6) :467-476.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhanced image capture through fusion">

                                <b>[17]</b> Burt P J, Kolczynski R J.Enhanced image capture through fusion[C]//1993 (4th) International Conference on Computer Vision.IEEE, 1993:173-182.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=CVG-URG">

                                <b>[18]</b> CVG-URG[DB/OL].http://decsai.ugr.es/cvg/dbimagenes.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The laplacian pyramid as a compact image code">

                                <b>[19]</b> Burt P J, Adelson E H.The Laplacian pyramid as a compact image code[J].IEEE Transactions on Communications, 1983, 31 (4) :532-540.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201606041&amp;v=MjkzOTlJTHpUWlpMRzRIOWZNcVk5QlpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emtVTHo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 牛爽, 尚媛园, 丁辉, 等.基于亮度传播图的低照度图像增强算法[J].计算机应用与软件, 2016, 33 (6) :168-171.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201603045&amp;v=MDA5MDhIOWZNckk5QllZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emtVTHpJTHpUWlpMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> 王淑青, 姚伟, 陈进, 等.基于直方图均衡化与形态学处理的边缘检测[J].计算机应用与软件, 2016, 33 (3) :193-196.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201603048&amp;v=MzIzODhadVp0Rnl6a1VMeklMelRaWkxHNEg5Zk1ySTlCYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 全永奇, 邓家先, 寇计萍, 等.一种新的NSCT域图像增强算法[J].计算机应用与软件, 2016, 33 (3) :206-209, 221.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201905036" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201905036&amp;v=MDc3MDM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emtVTHpKTHpUWlpMRzRIOWpNcW85R1lvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="1" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
