<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135647809162500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201906038%26RESULT%3d1%26SIGN%3dnU6XTMAFt8mKFQ6QOwCEP6W8ZQM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201906038&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201906038&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201906038&amp;v=MTIyNzlHRnJDVVI3cWZadVp0Rnl2bVZMek5MelRaWkxHNEg5ak1xWTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#45" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="&lt;b&gt;1 数学形态学边缘检测&lt;/b&gt; "><b>1 数学形态学边缘检测</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="&lt;b&gt;1.1 形态学边缘检测方法&lt;/b&gt;"><b>1.1 形态学边缘检测方法</b></a></li>
                                                <li><a href="#62" data-title="&lt;b&gt;1.2 形态学算法改进&lt;/b&gt;"><b>1.2 形态学算法改进</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#106" data-title="&lt;b&gt;2 RCF的边缘检测方法&lt;/b&gt; "><b>2 RCF的边缘检测方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#107" data-title="&lt;b&gt;2.1 CNN用于边缘检测&lt;/b&gt;"><b>2.1 CNN用于边缘检测</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;2.2 RCF的边缘检测方法&lt;/b&gt;"><b>2.2 RCF的边缘检测方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#137" data-title="&lt;b&gt;3 图像融合的边缘检测方法&lt;/b&gt; "><b>3 图像融合的边缘检测方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#138" data-title="&lt;b&gt;3.1 小波融合技术&lt;/b&gt;"><b>3.1 小波融合技术</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;3.2 图像融合的边缘检测方法&lt;/b&gt;"><b>3.2 图像融合的边缘检测方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#145" data-title="&lt;b&gt;4 实验结果及分析&lt;/b&gt; "><b>4 实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#146" data-title="&lt;b&gt;4.1 实验结果&lt;/b&gt;"><b>4.1 实验结果</b></a></li>
                                                <li><a href="#157" data-title="&lt;b&gt;4.2 结果分析&lt;/b&gt;"><b>4.2 结果分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#169" data-title="&lt;b&gt;5 结 语&lt;/b&gt; "><b>5 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#79" data-title="图1 3&#215;3的图像子块">图1 3×3的图像子块</a></li>
                                                <li><a href="#111" data-title="图2 卷积层输出">图2 卷积层输出</a></li>
                                                <li><a href="#117" data-title="图3 RCF网络结构">图3 RCF网络结构</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表1 VGG16网络模型感受野和步长&lt;/b&gt;"><b>表1 VGG16网络模型感受野和步长</b></a></li>
                                                <li><a href="#128" data-title="图4 RCF模型每阶段输出">图4 RCF模型每阶段输出</a></li>
                                                <li><a href="#141" data-title="图5 图像融合流程图">图5 图像融合流程图</a></li>
                                                <li><a href="#144" data-title="图6 本文算法流程图">图6 本文算法流程图</a></li>
                                                <li><a href="#151" data-title="图7 唐卡图像边缘检测">图7 唐卡图像边缘检测</a></li>
                                                <li><a href="#207" data-title="图8 唐卡阿弥陀佛往生图像边缘检测">图8 唐卡阿弥陀佛往生图像边缘检测</a></li>
                                                <li><a href="#207" data-title="图8 唐卡阿弥陀佛往生图像边缘检测">图8 唐卡阿弥陀佛往生图像边缘检测</a></li>
                                                <li><a href="#168" data-title="&lt;b&gt;表2 五种算法关于指标&lt;/b&gt;EPI&lt;b&gt;和&lt;/b&gt;PSNR&lt;b&gt;的比较&lt;/b&gt;"><b>表2 五种算法关于指标</b>EPI<b>和</b>PSNR<b>的比较</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="208">


                                    <a id="bibliography_1" title=" 葛阿雷.Canny算子与形态学相融合的边缘检测算法研究与应用[D].银川:宁夏大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016270014.nh&amp;v=MDAxODIyNkdMRy9IdEhOcTVFYlBJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5dm1WTHpOVkY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         葛阿雷.Canny算子与形态学相融合的边缘检测算法研究与应用[D].银川:宁夏大学, 2016.
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_2" title=" Dong C, Loy C C, He K, et al.Image Super-Resolution Using Deep Convolutional Networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) :295-307." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">
                                        <b>[2]</b>
                                         Dong C, Loy C C, He K, et al.Image Super-Resolution Using Deep Convolutional Networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) :295-307.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_3" title=" Liu Y, Cheng M M, Hu X, et al.Richer Convolutional Features for Edge Detection[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .2017, 1:5872-5881." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Richer Convolutional Features for Edge Detection">
                                        <b>[3]</b>
                                         Liu Y, Cheng M M, Hu X, et al.Richer Convolutional Features for Edge Detection[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .2017, 1:5872-5881.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_4" title=" 赵新亚.基于深度卷积网络的图像边缘检测方法[J].现代制造工程, 2018 (2) :144-149." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXGY201802027&amp;v=MjI1MjBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5dm1WTHpOUFRYTWQ3RzRIOW5Nclk5SFk0UUs=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         赵新亚.基于深度卷积网络的图像边缘检测方法[J].现代制造工程, 2018 (2) :144-149.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_5" title=" 朱梓豪, 张帅, 葛欣.基于机器学习的图像边缘检测方法的研究与应用[J].信息与电脑 (理论版) , 2018 (4) :61-63." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXDL201804025&amp;v=MTEzNjdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMek5QVFhQWXJHNEg5bk1xNDlIWVlRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         朱梓豪, 张帅, 葛欣.基于机器学习的图像边缘检测方法的研究与应用[J].信息与电脑 (理论版) , 2018 (4) :61-63.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_6" title=" Canny J F.A computational approach to edge detection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, 8 (6) :679-698." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computational approach to edge detection">
                                        <b>[6]</b>
                                         Canny J F.A computational approach to edge detection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, 8 (6) :679-698.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_7" title=" Bertasius G, Shi J, Torresani L.High-for-Low and Low-for-High:Efficient Boundary Detection from Deep Object Features and its Applications to High-Level Vision[C]//2015 IEEE International Conference on Computer Vision (ICCV) , 2015, 1:504-512." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=High-for-Low and Low-for-High:Efficient Boundary Detection from Deep Object Features and Its Applications to High-Level Vision">
                                        <b>[7]</b>
                                         Bertasius G, Shi J, Torresani L.High-for-Low and Low-for-High:Efficient Boundary Detection from Deep Object Features and its Applications to High-Level Vision[C]//2015 IEEE International Conference on Computer Vision (ICCV) , 2015, 1:504-512.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_8" title=" 葛阿雷, 史伟.改进的适应形态学边缘检测[J].宁夏大学学报, 2016, 37 (1) :34-38." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NXDZ201601007&amp;v=MTU0NjJDVVI3cWZadVp0Rnl2bVZMek5LelhQZExHNEg5Zk1ybzlGWTRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         葛阿雷, 史伟.改进的适应形态学边缘检测[J].宁夏大学学报, 2016, 37 (1) :34-38.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_9" title=" 曹晓琳.基于数学形态学的图像边缘检测方法[D].哈尔滨:哈尔滨工业大学, 2012." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013037116.nh&amp;v=MjA2NThRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMek5WRjI2SGJPN0dkRE5xWkViUEk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         曹晓琳.基于数学形态学的图像边缘检测方法[D].哈尔滨:哈尔滨工业大学, 2012.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_10" title=" 罗山.基于改进数学形态学的含噪图像边缘检测[J].攀枝花学院学报, 2013, 30 (4) :121-125." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZHD201304033&amp;v=MTY5OTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkx6Tk5UZkRhckc0SDlMTXE0OUdaNFE=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         罗山.基于改进数学形态学的含噪图像边缘检测[J].攀枝花学院学报, 2013, 30 (4) :121-125.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_11" title=" Simonyan K, Zisserman A.Very Deep Convolutional Networks for Large-Scale Image Recognition[EB].arXiv preprint arXiv:1409.1556, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition[EB]">
                                        <b>[11]</b>
                                         Simonyan K, Zisserman A.Very Deep Convolutional Networks for Large-Scale Image Recognition[EB].arXiv preprint arXiv:1409.1556, 2014.
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_12" title=" Ganin Y, Lempitsky V.N&lt;sup&gt;4&lt;/sup&gt;-Fields:Neural network nearest neighbor fields for image transforms[C]//12th Asian Conference on Computer Vision, 2014:536-551." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=N^ 4-Fields:Neural Network Nearest Neighbor Fields for Image Transforms">
                                        <b>[12]</b>
                                         Ganin Y, Lempitsky V.N&lt;sup&gt;4&lt;/sup&gt;-Fields:Neural network nearest neighbor fields for image transforms[C]//12th Asian Conference on Computer Vision, 2014:536-551.
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_13" title=" Shen W, Wang X, Wang Y, et al.DeepContour:A deep convolutional feature learned by positive-sharing loss for contour detection[C]//2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2015:3982-3991." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deepcontour:A deep convolutional feature learned by positivesharing loss for contour detection">
                                        <b>[13]</b>
                                         Shen W, Wang X, Wang Y, et al.DeepContour:A deep convolutional feature learned by positive-sharing loss for contour detection[C]//2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2015:3982-3991.
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_14" title=" Hwang J J, Liu T L.Pixel-wise Deep Learning for Contour Detection[EB].arXiv preprint arXiv:1504.01989, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pixel-wise Deep Learning for Contour Detection[EB]">
                                        <b>[14]</b>
                                         Hwang J J, Liu T L.Pixel-wise Deep Learning for Contour Detection[EB].arXiv preprint arXiv:1504.01989, 2015.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_15" title=" Xie S, Tu Z.Holistically-Nested Edge Detection[J].International Journal of Computer Vision, 2015, 125 (1/3) :3-18." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD6BB00EB93AC104C12EB55DFC97247B75&amp;v=MTIwODEwMTRUUXVVM3hzeWU3YVRONzJhQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeDd1NHc2MD1OajdCYXJYS2JOSE0ydjFNWjVwOERYdzl2QmNSbg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Xie S, Tu Z.Holistically-Nested Edge Detection[J].International Journal of Computer Vision, 2015, 125 (1/3) :3-18.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_16" title=" 陈浩, 王延杰.基于小波变换的图像融合技术研究[J].微电子学与计算机, 2010, 27 (5) :39-41." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201005011&amp;v=MzEyNDBGckNVUjdxZlp1WnRGeXZtVkx6Tk1qWFNaTEc0SDlITXFvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         陈浩, 王延杰.基于小波变换的图像融合技术研究[J].微电子学与计算机, 2010, 27 (5) :39-41.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_17" title=" 王丹, 周锦程.一种基于小波变换的图像融合改进算法[J].黔南民族师范学院学报, 2010, 30 (3) :8-12." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QNNS201003004&amp;v=MDg0NjZHNEg5SE1ySTlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMek5OQ1BGZmI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         王丹, 周锦程.一种基于小波变换的图像融合改进算法[J].黔南民族师范学院学报, 2010, 30 (3) :8-12.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_18" title=" Li Z, Shi W, Zhang H, et al.Change Detection Based on Gabor Wavelet Features for Very High Resolution Remote Sensing Images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (5) :783-787." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Change detection based on gabor wavelet features for very high resolution remote sensing images">
                                        <b>[18]</b>
                                         Li Z, Shi W, Zhang H, et al.Change Detection Based on Gabor Wavelet Features for Very High Resolution Remote Sensing Images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (5) :783-787.
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_19" title=" Arbelaez P, Maire M, Fowlkes C, et al.Contour Detection and Hierarchical Image Segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (5) :898-916." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Contour Detection and Hierarchical Image Segmentation">
                                        <b>[19]</b>
                                         Arbelaez P, Maire M, Fowlkes C, et al.Contour Detection and Hierarchical Image Segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (5) :898-916.
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_20" title=" 张涛.小波变换在图像去噪和边缘检测中的研究与应用[D].贵阳:贵州大学, 2016." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016742404.nh&amp;v=MDkxMzdJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5dm1WTHpOVkYyNkdMUzhITlhNcTVFYlA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[20]</b>
                                         张涛.小波变换在图像去噪和边缘检测中的研究与应用[D].贵阳:贵州大学, 2016.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_21" title=" Jaberi M, Bebis G, Hussain M, et al.Accurate and robust localization of duplicated region in copy-move image forgery[J].Machine Vision and Applications, 2014, 25 (2) :451-475." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300015603&amp;v=MTg3NjRhUmM9Tmo3QmFySzhIdExNckk5RlpPb0tDbnc2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSTEwVA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         Jaberi M, Bebis G, Hussain M, et al.Accurate and robust localization of duplicated region in copy-move image forgery[J].Machine Vision and Applications, 2014, 25 (2) :451-475.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(06),196-201+242 DOI:10.3969/j.issn.1000-386x.2019.06.037            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>形态学与RCF相结合的唐卡图像边缘检测算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E5%8D%83&amp;code=41979469&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘千</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%91%9B%E9%98%BF%E9%9B%B7&amp;code=34596903&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">葛阿雷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8F%B2%E4%BC%9F&amp;code=08125065&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">史伟</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%AE%81%E5%A4%8F%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0206435&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宁夏大学信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>唐卡图像的内容丰富, 纹理信息复杂。边缘检测在唐卡图像分析研究中具有非常重要的意义, 因为唐卡图像轮廓含有大量的图像数据信息。数学形态学方法提取的边缘光滑连续, 但是对复杂的边缘检测时会存在模糊不清晰的现象<sup>[1]</sup>。卷积神经网络 (CNN) 可以提取很多高层的、多尺度的信息<sup>[2]</sup>。为此提出的边缘检测方法, 用优化的数学形态学算法提取原图像边缘;利用训练的RCF网络模型<sup>[3]</sup>提取原图像的边缘。根据小波变换的分解与重构原理将以上方法得出的图像边缘融合, 从而得到更加完整光滑的图像边缘。实验表明, 融合后的图像边缘更加清晰连续, 轮廓信息更符合人类的视觉认知, 去掉了无效的细节纹理, 更有利于唐卡图像后续研究。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%94%90%E5%8D%A1%E5%9B%BE%E5%83%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">唐卡图像;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">边缘检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=CNN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">CNN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BD%A2%E6%80%81%E5%AD%A6%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">形态学边缘检测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=RCF%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">RCF网络模型;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">小波变换;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    刘千, 硕士生, 主研领域:西夏文物数字化保护, 数字图像处理。;
                                </span>
                                <span>
                                    葛阿雷, 硕士生。;
                                </span>
                                <span>
                                    史伟, 教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61662060);</span>
                    </p>
            </div>
                    <h1><b>THANG KA IMAGE EDGE DETECTION ALGORITHM BASED ON MORPHOLOGY AND RCF</b></h1>
                    <h2>
                    <span>Liu Qian</span>
                    <span>Ge Alei</span>
                    <span>Shi Wei</span>
            </h2>
                    <h2>
                    <span>School of Information Engineering, Ningxia University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Thang ka image is rich in content and complex in texture information. Edge detection is very important in the analysis of Thang ka image, because Thang ka image contour contains a lot of image data information. The edges extracted by mathematical morphology method are smooth and continuous, but there is ambiguity in complex edge detection. Convolutional neural network (CNN) can extract a lot of high-level and multi-scale information. The proposed edge detection method used the optimized mathematical morphology algorithm to extract the original image edge. Then, the training RCF network model was used to extract the edges of the original image. According to the decomposition and reconstruction principle of wavelet transform, we obtained the image edges by the above method to fuse, getting more complete and smooth image edges. Experiments show that the fused image edge is clearer and more continuous, the contour information is more in line with human visual cognition, and the invalid detail texture is removed. It is more conducive to the follow-up study of Thang ka image.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Thang%20ka%20image&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Thang ka image;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Edge%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Edge detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=CNN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">CNN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Morphological%20edge%20detection&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Morphological edge detection;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=RCF%20network%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">RCF network model;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Wavelet%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Wavelet transform;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-24</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="45" name="45" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="46">边缘检测是图像处理和计算机视觉的基本问题, 通过识别数字图像中亮度变化明显的点, 来捕捉图像属性中的显著变化, 包括深度上的不连续、表面方向的不连续、物质属性变化、和场景照明变化等<citation id="250" type="reference"><link href="214" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>。图像边缘中含有大量有价值的信息, 所以, 图像边缘检测在图像分析、图像分割和计算机视觉中占据着重要的地位<citation id="251" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="47">传统的边缘检测算法计算简单, 容易实现, 实时性较好, 如Canny算子、Roberts算子、Laplacian算子、Sobel算子、Prewitt算子和LOG算子<citation id="252" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>等, 然而精确度较低, 很难适用于信息复杂的唐卡图像。数学形态学边缘检测算法是基于集合的运算, 具有非线性特征, 它的边缘检测方法提取的边缘光滑连续, 且实时性较强, 但是对于复杂的边缘检测时会存在模糊不清晰的现象<citation id="253" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。近年来, 卷积神经网络 (CNN) 已经成为计算机视觉领域的主流, 它极大地提高了图像分类、目标检测和语义分割等各种任务的技术水平。由于CNN具有很强的自动学习自然图像高层次表示的能力, 人们越来越倾向于通过训练神经网络模型进行边缘检测<citation id="254" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。用CNN的方法进行边缘检测更容易只将图像外轮廓提取出来, 去掉繁杂的内部细节。</p>
                </div>
                <div class="p1">
                    <p id="48">为了得到更加清晰连续的图像边缘, 本文提出了数学形态学和RCF (Richer Convolutional Features) 网络模型<citation id="255" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>相结合的边缘检测。该方法首先用形态学方法对原图像进行边缘检测;然后, 用训练好的RCF网络模型对原图像边缘提取;最后, 对用两种方法得出的边缘图像进行基于小波变换的融合, 得到更加完整清晰的图像边缘。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag"><b>1 数学形态学边缘检测</b></h3>
                <h4 class="anchor-tag" id="50" name="50"><b>1.1 形态学边缘检测方法</b></h4>
                <div class="p1">
                    <p id="51">形态学边缘检测算子主要是由结构元素对图像进行膨胀、腐蚀或开启、闭合之后再做差运算得到的<citation id="256" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52"> (1) 腐蚀与膨胀:</h4>
                <div class="p1">
                    <p id="53">设<i>f</i> (<i>x</i>, <i>y</i>) 为原图像, <i>g</i> (<i>i</i>, <i>j</i>) 为结构元素, ⊕代表膨胀运算符, <i>Θ</i>代表腐蚀运算符, <i>D</i><sub><i>f</i></sub>和<i>D</i><sub><i>g</i></sub>分别为<i>f</i>和<i>g</i>的定义域, 则<i>f</i>与<i>g</i>膨胀和腐蚀运算可分别定义为<citation id="257" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="54" class="code-formula">
                        <mathml id="54"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>⊕</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>max</mi></mrow><mo stretchy="false">{</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>i</mi><mo>, </mo><mi>y</mi><mo>-</mo><mi>j</mi><mo stretchy="false">) </mo><mo>+</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>-</mo><mi>i</mi><mo>, </mo><mi>y</mi><mo>-</mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>D</mi><msub><mrow></mrow><mi>f</mi></msub><mo>, </mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>D</mi><msub><mrow></mrow><mi>g</mi></msub><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mi>Θ</mi><mi>g</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>min</mi></mrow><mo stretchy="false">{</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo>, </mo><mi>y</mi><mo>+</mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>g</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">|</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo>, </mo><mi>y</mi><mo>+</mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>D</mi><msub><mrow></mrow><mi>f</mi></msub><mo>, </mo><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>∈</mo><mi>D</mi><msub><mrow></mrow><mi>g</mi></msub><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="55" name="55"> (2) 开启与闭合:</h4>
                <div class="p1">
                    <p id="56">。 表示开运算符, ·表示闭运算符, 开闭运算定义<citation id="258" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="57"><i>f</i>。 <i>g</i>= (<i>f</i>⊕<i>g</i>) <i>Θg</i>      (3) </p>
                </div>
                <div class="p1">
                    <p id="58"><i>f</i>·<i>g</i>= (<i>f</i>⊕<i>g</i>) <i>Θg</i>      (4) </p>
                </div>
                <div class="p1">
                    <p id="59">设<i>E</i>表示边缘图像, 多结构抗噪形态学边缘检测算子的边缘定义为<citation id="259" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="60" class="code-formula">
                        <mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">[</mo><mo stretchy="false"> (</mo><mi>f</mi><mi>Θ</mi><mi>g</mi><msub><mrow></mrow><mn>1</mn></msub><mo>⊕</mo><mi>g</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mo>⊕</mo><mi>g</mi><msub><mrow></mrow><mn>3</mn></msub><mo>-</mo><mo stretchy="false"> (</mo><mi>f</mi><mo>⊕</mo><mi>g</mi><msub><mrow></mrow><mn>1</mn></msub><mi>Θ</mi><mi>g</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">) </mo><mi>Θ</mi><mi>g</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="61">用简单的形态学算法得到的边缘图像实用性较差, 抗噪能力低, 下面对此算法改进。</p>
                </div>
                <h4 class="anchor-tag" id="62" name="62"><b>1.2 形态学算法改进</b></h4>
                <h4 class="anchor-tag" id="63" name="63"> (1) 算子的改进及结构元素的选取:</h4>
                <div class="p1">
                    <p id="64">设<i>f</i> (<i>x</i>, <i>y</i>) 为原图像, <i>g</i><sub>1</sub>、<i>g</i><sub>2</sub>、<i>g</i><sub>3<i>i</i></sub>为结构元素, 则对形态学边缘检测算子的改进如下:</p>
                </div>
                <div class="area_img" id="206">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201906038_20600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="67">式中:<i>g</i><sub>1</sub>、<i>g</i><sub>2</sub>分别为十字形和菱形结构元素<citation id="260" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 如下所示:</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mi>g</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69"><mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∪</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover><mi>g</mi></mstyle><msub><mrow></mrow><mrow><mn>3</mn><mi>i</mi></mrow></msub></mrow></math></mathml>由四个方向不同的结构元素组合而成, 结构如下:</p>
                </div>
                <div class="p1">
                    <p id="71" class="code-formula">
                        <mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mrow><mn>3</mn><mn>1</mn></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mi>g</mi><msub><mrow></mrow><mrow><mn>3</mn><mn>2</mn></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="72" class="code-formula">
                        <mathml id="72"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><msub><mrow></mrow><mrow><mn>3</mn><mn>3</mn></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mi>g</mi><msub><mrow></mrow><mrow><mn>3</mn><mn>4</mn></mrow></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mi>g</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr><mtr><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="73">这4个结构元素包含了<i>g</i><sub>3</sub>中的所有线条的走向, 使得图像各个方向的边缘都可以被检测到, 保证了边缘的完整化<citation id="261" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"> (2) 计算欧式距离:</h4>
                <div class="p1">
                    <p id="75">本文采用上述四个方向的结构元素, 通过计算原图像各像素点四个方向的欧氏距离, 实现不同结构元素对权值的自适应选取<citation id="262" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>, 具体方法如下。</p>
                </div>
                <div class="p1">
                    <p id="76">如图1所示为所选取的3×3图像子块模型, 中心点<i>P</i><sub>1</sub>与其临近像素点的灰度距离公式表示为:</p>
                </div>
                <div class="p1">
                    <p id="77"><mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mi>m</mi></msub><mo>=</mo><mrow><mo>|</mo><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>m</mi></msub><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>|</mo></mrow><mtext> </mtext><mi>m</mi><mo>=</mo><mn>2</mn><mo>, </mo><mn>3</mn><mo>, </mo><mo>⋯</mo><mo>, </mo><mn>9</mn></mrow></math></mathml>      (7) </p>
                </div>
                <div class="area_img" id="79">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 3&#215;3的图像子块" src="Detail/GetImg?filename=images/JYRJ201906038_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 3×3的图像子块  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_079.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="80">由式 (7) 可知:临近像素点的灰度距离越大, 灰度突变越大, 根据中心像素点与其邻近像素点之间的灰度距离可以表示边缘的方向性<citation id="263" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。设目标区域的中心点为<i>P</i><sub>1</sub> (<i>i</i>, <i>j</i>) 、<i>O</i><sub>1</sub>、<i>O</i><sub>2</sub>、<i>O</i><sub>3</sub>、<i>O</i><sub>4</sub>分别表示水平、垂直、45°、135°四个方向边缘的欧氏距离, 它们的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="81"><mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>3</mn></mrow><mn>5</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>7</mn></mrow><mn>9</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="83"><mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>5</mn></mrow><mn>7</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>2</mn></mrow><mn>3</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup><mo>+</mo><mi>Ο</mi><msubsup><mrow></mrow><mn>9</mn><mn>2</mn></msubsup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="85"><mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mn>3</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>4</mn></mrow><mn>6</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>8</mn></mrow><mn>9</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup><mo>+</mo><mi>Ο</mi><msubsup><mrow></mrow><mn>2</mn><mn>2</mn></msubsup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="87"><mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ο</mi><msub><mrow></mrow><mn>4</mn></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>6</mn></mrow><mn>9</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>2</mn></mrow><mn>4</mn></munderover><mi>Ο</mi></mstyle><msubsup><mrow></mrow><mi>m</mi><mn>2</mn></msubsup></mrow><mo>) </mo></mrow><msup><mrow></mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow></msup></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="89">那么, 对于一幅<i>M</i>×<i>N</i>的整体图像来说, 各方向边缘的欧氏距离公式为:</p>
                </div>
                <div class="p1">
                    <p id="90"><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mi>Ο</mi><msub><mrow></mrow><mi>k</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>2</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>2</mn></mrow><mrow><mi>Ν</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>Ο</mi></mstyle></mrow></mstyle><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow></math></mathml><i>k</i>=1, 2, 3, 4      (12) </p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"> (3) 计算权值和图像边缘:</h4>
                <div class="p1">
                    <p id="93">根据式 (12) 计算出四个方向的欧氏距离, 其对应方向为边界曲线最可能的走向, 实验测试图像边界走向与结构元素方向的组合后, 得出选取与图像边缘走向垂直方向的结构元素对这个区域检测效果最好<citation id="264" type="reference"><link href="208" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="94">所以令<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mi>Ο</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover><mi>Η</mi></mstyle><mi>Ο</mi><msub><mrow></mrow><mi>k</mi></msub></mrow></math></mathml>, 则图像0°、45°、90°和135°方向的结构权值分别为<i>ω</i><sub>1</sub>、<i>ω</i><sub>2</sub>、<i>ω</i><sub>3</sub>和<i>ω</i><sub>4</sub>, 公式如下所示:</p>
                </div>
                <div class="p1">
                    <p id="96" class="code-formula">
                        <mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>ω</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mi>Η</mi><mi>Ο</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>Η</mi><mi>Ο</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mi>ω</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mfrac><mrow><mi>Η</mi><mi>Ο</mi><msub><mrow></mrow><mn>4</mn></msub></mrow><mrow><mi>Η</mi><mi>Ο</mi></mrow></mfrac></mtd></mtr><mtr><mtd><mi>ω</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mfrac><mrow><mi>Η</mi><mi>Ο</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mrow><mi>Η</mi><mi>Ο</mi></mrow></mfrac><mtext> </mtext><mtext> </mtext><mi>ω</mi><msub><mrow></mrow><mn>4</mn></msub><mo>=</mo><mfrac><mrow><mi>Η</mi><mi>Ο</mi><msub><mrow></mrow><mn>3</mn></msub></mrow><mrow><mi>Η</mi><mi>Ο</mi></mrow></mfrac></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>3</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="97">最后把式 (6) 和式 (13) 代入式 (14) 中, 则各个方向边缘的加权和为形态学方法得到的边缘:</p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover><mo stretchy="false"> (</mo></mstyle><mi>ω</mi><msub><mrow></mrow><mi>i</mi></msub><mi>G</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (14) </p>
                </div>
                <h4 class="anchor-tag" id="100" name="100"> (4) 算法步骤:</h4>
                <div class="p1">
                    <p id="101">自适应数学形态学图像边缘检测算法具体步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="102">① 用结构元素<i>g</i><sub>1</sub>、<i>g</i><sub>2</sub>对加入椒盐噪声的图像去噪;</p>
                </div>
                <div class="p1">
                    <p id="103">② 用欧氏距离计算出原图像各像素点四个方向的权值;</p>
                </div>
                <div class="p1">
                    <p id="104">③ 用式 (6) 对去噪后的图像进行四个方向的边缘检测;</p>
                </div>
                <div class="p1">
                    <p id="105">④ 根据式 (14) 求图像各方向的边缘加权和, 得到完整的图像边缘。</p>
                </div>
                <h3 id="106" name="106" class="anchor-tag"><b>2 RCF的边缘检测方法</b></h3>
                <h4 class="anchor-tag" id="107" name="107"><b>2.1 CNN用于边缘检测</b></h4>
                <div class="p1">
                    <p id="108">传统方法通过提取局部的亮度、颜色、梯度、纹理或其他人工设计特征对图像的像素点进行边缘或非边缘的分类。但是图像边缘通常具有丰富的语义信息, 仅通过局部线索难以得到令人满意的结果。</p>
                </div>
                <div class="p1">
                    <p id="109">卷积神经网络通常能够提取高层次信息, 为了查看不同卷积层在边缘检测中获得的信息, 我们使用VGG16网络<citation id="265" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>生成中间层的边输出, 该网络有5个阶段。如图2所示, 显示了第二阶段和第三阶段的卷积层输出。我们发现随着网络模型阶段的增加, 卷积特征逐渐变得粗化, 中间层包含大量有用的细节, 因此充分地利用CNN提取的所有层的特征。</p>
                </div>
                <div class="area_img" id="111">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 卷积层输出" src="Detail/GetImg?filename=images/JYRJ201906038_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 卷积层输出  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_11100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="112">近期, 许多应用CNN的边缘检测方法被提出。Ganin等通过CNN和最近邻搜索, 提出N4-Fields<citation id="266" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。Shen将轮廓数据分成子类, 并通过学习模型参数在子类上拟合, 提出DeepContour<citation id="267" type="reference"><link href="232" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。Hwang等将轮廓检测作为逐像素的分类问题, 利用DenseNet对每个像素点提取特征, 然后用SVM进行分类, 提出Pixel-wise Deep Learning for Contour Detection (CSCNN) <citation id="268" type="reference"><link href="234" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。Xie等提出Holistically-Nested Edge Detection (HED) , 实现图像到图像的训练和预测, 其网络模型是以VGG16为基础, 通过一个内核大小为1的conv层、一个deconv层和一个softmax层, 实现多个side output, 并将这些输出融合得到边缘检测结果<citation id="269" type="reference"><link href="236" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="113">综上, 这些基于CNN的方法大多只利用了每个卷积阶段的最后一层的特征, 由于不同卷积层之间的信息是可以互补的, 所以存在信息利用不充分的问题。本文应用的RCF是一种全卷积网络高效地利用了每一个CNN层的特征来完成边缘检测。</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>2.2 RCF的边缘检测方法</b></h4>
                <h4 class="anchor-tag" id="115" name="115"><b>2.2.1 RCF边缘检测及网络结构</b></h4>
                <div class="p1">
                    <p id="116">RCF网络结构是通过修改VGG16网络结构<citation id="270" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>得到的, 由13个conv层和3个完全连接层组成, 它的conv层分为5个阶段, 在每个阶段之后连接一个池化层。每个conv层获得的有用信息随着感受野大小的增加而变得更粗。图3为RCF网络结构<citation id="271" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 表1为VGG16网络的详细感受野和步长<citation id="272" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 RCF网络结构" src="Detail/GetImg?filename=images/JYRJ201906038_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 RCF网络结构  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表1 VGG16网络模型感受野和步长</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td>layer</td><td>conv1_1</td><td>conv1_2</td><td>pool1</td><td>conv2_1</td><td>conv2_2</td><td>pool2</td></tr><tr><td><br />rf size</td><td>3</td><td>5</td><td>6</td><td>10</td><td>14</td><td>16</td></tr><tr><td><br />stride</td><td>1</td><td>1</td><td>2</td><td>2</td><td>2</td><td>4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="119">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="119" border="1"><tr><td>layer</td><td>conv3_1</td><td>conv3_2</td><td>conv3_3</td><td>pool3</td><td>conv4_1</td><td>conv4_2</td></tr><tr><td><br />rf size</td><td>24</td><td>32</td><td>40</td><td>44</td><td>60</td><td>76</td></tr><tr><td><br />stride</td><td>4</td><td>4</td><td>4</td><td>8</td><td>8</td><td>8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td>layer</td><td>conv4_3</td><td>pool4</td><td>conv5_1</td><td>conv5_2</td><td>conv5_3</td><td>pool5</td></tr><tr><td><br />rf size</td><td>92</td><td>100</td><td>132</td><td>164</td><td>196</td><td>212</td></tr><tr><td><br />stride</td><td>8</td><td>16</td><td>16</td><td>16</td><td>16</td><td>32</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="121">RCF网络结构与VGG16相比, 进行修改如下:</p>
                </div>
                <div class="p1">
                    <p id="122"> (1) 去掉所有的全连接层和第五池化层。去除所有的全连接层主要目的是得到全卷积网络, 存在第五池化层会使步幅增加两倍, 不利于图像边缘定位。</p>
                </div>
                <div class="p1">
                    <p id="123"> (2) 对VGG16中的每个卷积层连接一个卷积核大小为1×1×21的卷积层, 每个stage中所有的1×1×21卷积输出进行元素相加 (eltwise layer) , 得到一个复合特征。</p>
                </div>
                <div class="p1">
                    <p id="124"> (3) 每个eltwise layer后面加一个deconv layer用于放大特征图尺寸。</p>
                </div>
                <div class="p1">
                    <p id="125"> (4) 在每个deconv layer后面连接一个cross-entropy loss/sigmoid layer。</p>
                </div>
                <div class="p1">
                    <p id="126"> (5) 所有的deconv layer输出进行连接, 随后使用一个1×1 conv layer进行特征图融合, 最后使用一个cross-entropy loss/sigmoid layer得到输出。</p>
                </div>
                <div class="p1">
                    <p id="127">由于VGG16中conv层的大小不同, 它可以学习包括底层和对象层在内的多尺度信息, 这些信息有助于边缘检测。图4显示了唐卡图像在RCF模型中从上到下每个阶段的输出。RCF模型结合了所有可访问的conv层使用了更丰富的特性, 因此它能够实现更高的精度。</p>
                </div>
                <div class="area_img" id="128">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 RCF模型每阶段输出" src="Detail/GetImg?filename=images/JYRJ201906038_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 RCF模型每阶段输出  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_128.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="129" name="129"><b>2.2.2 损失函数</b></h4>
                <div class="p1">
                    <p id="130">RCF网络模型在设计损失函数时, 首先将数据集中的每张图像, 根据人工标记结果, 产生一张边缘概率图, 范围从0到1。0表示在这个像素上没有人标记为边缘点, 1表示在这个像素上所有人都标记为边缘点。概率高于<i>η</i>的像素点为正样品, 概率等于0的像素点为负样本。像素边缘概率少于<i>η</i>的点为有争议点不计入损失函数的计算中。</p>
                </div>
                <div class="p1">
                    <p id="131">损失函数为:</p>
                </div>
                <div class="p1">
                    <p id="132" class="code-formula">
                        <mathml id="132"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false"> (</mo><mi>W</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></munderover><mrow><mrow><mo> (</mo><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mi>l</mi></mstyle><mo stretchy="false"> (</mo><mi>X</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msubsup><mo>;</mo><mi>W</mi><mo stretchy="false">) </mo><mo>+</mo><mi>l</mi><mo stretchy="false"> (</mo><mi>X</mi><msubsup><mrow></mrow><mi>i</mi><mrow><mtext>f</mtext><mtext>u</mtext><mtext>s</mtext><mtext>e</mtext></mrow></msubsup><mo>;</mo><mi>W</mi><mo stretchy="false">) </mo></mrow><mo>) </mo></mrow></mrow></mstyle><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="133">式中:<i>X</i><mathml id="134"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo></mrow></msubsup></mrow></math></mathml>为<i>k</i>阶段的激活值, <i>X</i><mathml id="135"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mrow><mtext>f</mtext><mtext>u</mtext><mtext>s</mtext><mtext>e</mtext></mrow></msubsup></mrow></math></mathml>为融合层激活值, <mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>Ι</mi><mo>|</mo></mrow></mrow></math></mathml>为图像总的像素数, <i>K</i>为RCF网络模型总阶段数。</p>
                </div>
                <h3 id="137" name="137" class="anchor-tag"><b>3 图像融合的边缘检测方法</b></h3>
                <h4 class="anchor-tag" id="138" name="138"><b>3.1 小波融合技术</b></h4>
                <div class="p1">
                    <p id="139">图像融合是将相同对象的两幅或多幅图像合成为一幅图像, 从而获取到对同一场景的更为精确、更为连续、更为全面的图像描述<citation id="273" type="reference"><link href="238" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="140">本实验采用离散小波变换DWT (Discrete Wavelet Transform) <citation id="274" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>融合用改进的形态学边缘检测算子和RCF边缘检测模型两种方法得到的边缘图像。图像融合的基本流程如图5所示。</p>
                </div>
                <div class="area_img" id="141">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 图像融合流程图" src="Detail/GetImg?filename=images/JYRJ201906038_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 图像融合流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_141.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="142" name="142"><b>3.2 图像融合的边缘检测方法</b></h4>
                <div class="p1">
                    <p id="143">基于以上改进的形态学边缘检测算子和RCF边缘检测模型, 本文采用三层二维DWT<citation id="275" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>进行图像融合, 具体算法流程如图6所示。</p>
                </div>
                <div class="area_img" id="144">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 本文算法流程图" src="Detail/GetImg?filename=images/JYRJ201906038_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 本文算法流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_144.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="145" name="145" class="anchor-tag"><b>4 实验结果及分析</b></h3>
                <h4 class="anchor-tag" id="146" name="146"><b>4.1 实验结果</b></h4>
                <div class="p1">
                    <p id="147">实验中改进的形态学边缘检测算子和图像融合是在Win10系统下利用MATLAB 2017b编程实现的;RCF网络模型是在Linux系统caffe框架下对训练好的VGG16模型进行修改后在标准数据集上训练得到的。</p>
                </div>
                <div class="p1">
                    <p id="148">分别用形态学算法、RCF边缘检测模型以及融合这两种边缘图像的方法对唐卡图像边缘提取, 检测结果如图7、图8所示。</p>
                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 唐卡图像边缘检测" src="Detail/GetImg?filename=images/JYRJ201906038_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 唐卡图像边缘检测  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="207">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_20700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 唐卡阿弥陀佛往生图像边缘检测" src="Detail/GetImg?filename=images/JYRJ201906038_20700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 唐卡阿弥陀佛往生图像边缘检测  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_20700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="207">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201906038_20701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 唐卡阿弥陀佛往生图像边缘检测" src="Detail/GetImg?filename=images/JYRJ201906038_20701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 唐卡阿弥陀佛往生图像边缘检测  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201906038_20701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="155">实验表明, 相比单个的形态学算法和RCF边缘检测<citation id="276" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>模型, 本文的方法提取出图像的边缘更加完整清晰, 目标物体的内部和外部的轮廓都比较完整, 同时去掉了更多无效的细节信息, 总体更符合人类的视觉认知, 更有利于唐卡图像后续的分析研究。</p>
                </div>
                <div class="p1">
                    <p id="156">本文应用BSDS500<citation id="277" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>作为数据集。BSDS500是一种广泛应用于边缘检测的数据集。它由200个训练图像、100个验证图像和200个测试图像组成<citation id="278" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。我们利用训练集和验证集优化网络模型, 并利用测试集评估网络模型。</p>
                </div>
                <h4 class="anchor-tag" id="157" name="157"><b>4.2 结果分析</b></h4>
                <div class="p1">
                    <p id="158">为了从客观上说明不同边缘检测所表现出的效果, 本文使用峰值信噪比PSNR<citation id="279" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation> (Peak Signal to Noise Ratio) 和边缘保持度EPI<citation id="280" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation> (Edge Preservation index) 作为评价指标来衡量边缘检测效率。</p>
                </div>
                <h4 class="anchor-tag" id="159" name="159"> (1) 峰值信噪比定义为:</h4>
                <div class="p1">
                    <p id="160"><i>PSNR</i>=10×log (255<sup>2</sup>/<i>MSE</i>)      (16) </p>
                </div>
                <div class="p1">
                    <p id="161">其中255是8 bits表示法的最大值 (Peak) , <i>MSE</i>表示原图像与处理图像之间均方误差MSE<citation id="281" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation> (Mean Square Error) :</p>
                </div>
                <div class="p1">
                    <p id="162"><mathml id="163"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mrow><mi>m</mi><mo>⋅</mo><mi>n</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>m</mi><mo>-</mo><mn>1</mn></mrow></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>Ι</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Κ</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (17) </p>
                </div>
                <div class="p1">
                    <p id="164">式中:<i>m</i>、<i>n</i>表示图像的尺寸, <i>I</i>、<i>K</i>分别表示原图像和处理后的图像, PSNR值越大, 说明噪声含量越小。给数据集BSDS500<citation id="282" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>加入5%椒盐噪声以增强RCF模型的抵抗噪的能力。</p>
                </div>
                <h4 class="anchor-tag" id="165" name="165"> (2) 边缘保持度定义为:</h4>
                <div class="p1">
                    <p id="166" class="code-formula">
                        <mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><mi>Ρ</mi><mi>Ι</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><mo>∑</mo><mo stretchy="false"> (</mo></mstyle><mrow><mo>|</mo><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mi>s</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow><mrow><mstyle displaystyle="true"><mo>∑</mo><mo stretchy="false"> (</mo></mstyle><mrow><mo>|</mo><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow><mo>+</mo><mrow><mo>|</mo><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Ρ</mi><msub><mrow></mrow><mi>o</mi></msub><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mfrac></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="167">式中:<i>P</i><sub><i>s</i></sub>为用本文方法提取的边缘图像, <i>P</i><sub><i>o</i></sub>为标准数据集人工标注的边缘图像, <i>i</i>为行数, <i>j</i>为列数。EPI的值越大, 说明边缘信息保留的越丰富全面。唐卡图像EPI值和PSNR值如表2所示。</p>
                </div>
                <div class="area_img" id="168">
                    <p class="img_tit"><b>表2 五种算法关于指标</b>EPI<b>和</b>PSNR<b>的比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="168" border="1"><tr><td><br />算法</td><td>EPI</td><td>PSNR</td></tr><tr><td><br />传统Canny</td><td>0.006 3</td><td>3.367 1</td></tr><tr><td><br />改进形态学</td><td>0.438 1</td><td>4.090 5</td></tr><tr><td><br />HED</td><td>0.504 8</td><td>4.860 9</td></tr><tr><td><br />RCF</td><td>0.518 5</td><td>4.991 4</td></tr><tr><td><br />本文算法</td><td>0.705 2</td><td>5.302 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h3 id="169" name="169" class="anchor-tag"><b>5 结 语</b></h3>
                <div class="p1">
                    <p id="170">对于改进的形态学边缘检测算法和RCF边缘检测<citation id="283" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>存在的不足, 本文给出了一种基于改进的形态学与RCF边缘检测<citation id="284" type="reference"><link href="212" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>相结合的边缘检测算法。该算法将分别用改进的形态学算法和RCF网络模型提取的边缘图像进行基于小波变换的融合得到新的边缘。既提高了图像边缘的平滑性, 又提取到了更清晰完整的轮廓, 同时还获得了更强的抗噪声能力, 较之前的方法更加符合人类的视觉认知, 有利于后续研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="208">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016270014.nh&amp;v=MjA5OTdMek5WRjI2R0xHL0h0SE5xNUViUElRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 葛阿雷.Canny算子与形态学相融合的边缘检测算法研究与应用[D].银川:宁夏大学, 2016.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image super-resolution using deep convolutional networks">

                                <b>[2]</b> Dong C, Loy C C, He K, et al.Image Super-Resolution Using Deep Convolutional Networks[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38 (2) :295-307.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Richer Convolutional Features for Edge Detection">

                                <b>[3]</b> Liu Y, Cheng M M, Hu X, et al.Richer Convolutional Features for Edge Detection[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .2017, 1:5872-5881.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXGY201802027&amp;v=MDEzOTBuTXJZOUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkx6TlBUWE1kN0c0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 赵新亚.基于深度卷积网络的图像边缘检测方法[J].现代制造工程, 2018 (2) :144-149.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XXDL201804025&amp;v=MDUwOTJGeXZtVkx6TlBUWFBZckc0SDluTXE0OUhZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 朱梓豪, 张帅, 葛欣.基于机器学习的图像边缘检测方法的研究与应用[J].信息与电脑 (理论版) , 2018 (4) :61-63.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computational approach to edge detection">

                                <b>[6]</b> Canny J F.A computational approach to edge detection[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 1986, 8 (6) :679-698.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=High-for-Low and Low-for-High:Efficient Boundary Detection from Deep Object Features and Its Applications to High-Level Vision">

                                <b>[7]</b> Bertasius G, Shi J, Torresani L.High-for-Low and Low-for-High:Efficient Boundary Detection from Deep Object Features and its Applications to High-Level Vision[C]//2015 IEEE International Conference on Computer Vision (ICCV) , 2015, 1:504-512.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=NXDZ201601007&amp;v=MzEyNjc0SDlmTXJvOUZZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXZtVkx6Tkt6WFBkTEc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 葛阿雷, 史伟.改进的适应形态学边缘检测[J].宁夏大学学报, 2016, 37 (1) :34-38.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1013037116.nh&amp;v=MTIxNDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMek5WRjI2SGJPN0dkRE5xWkViUElRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 曹晓琳.基于数学形态学的图像边缘检测方法[D].哈尔滨:哈尔滨工业大学, 2012.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=PZHD201304033&amp;v=MTY1NDNVUjdxZlp1WnRGeXZtVkx6Tk5UZkRhckc0SDlMTXE0OUdaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 罗山.基于改进数学形态学的含噪图像边缘检测[J].攀枝花学院学报, 2013, 30 (4) :121-125.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Very Deep Convolutional Networks for Large-Scale Image Recognition[EB]">

                                <b>[11]</b> Simonyan K, Zisserman A.Very Deep Convolutional Networks for Large-Scale Image Recognition[EB].arXiv preprint arXiv:1409.1556, 2014.
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=N^ 4-Fields:Neural Network Nearest Neighbor Fields for Image Transforms">

                                <b>[12]</b> Ganin Y, Lempitsky V.N<sup>4</sup>-Fields:Neural network nearest neighbor fields for image transforms[C]//12th Asian Conference on Computer Vision, 2014:536-551.
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deepcontour:A deep convolutional feature learned by positivesharing loss for contour detection">

                                <b>[13]</b> Shen W, Wang X, Wang Y, et al.DeepContour:A deep convolutional feature learned by positive-sharing loss for contour detection[C]//2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) .IEEE, 2015:3982-3991.
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pixel-wise Deep Learning for Contour Detection[EB]">

                                <b>[14]</b> Hwang J J, Liu T L.Pixel-wise Deep Learning for Contour Detection[EB].arXiv preprint arXiv:1504.01989, 2015.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD6BB00EB93AC104C12EB55DFC97247B75&amp;v=MzIzMjBuMDE0VFF1VTN4c3llN2FUTjcyYUNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHg3dTR3NjA9Tmo3QmFyWEtiTkhNMnYxTVo1cDhEWHc5dkJjUg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Xie S, Tu Z.Holistically-Nested Edge Detection[J].International Journal of Computer Vision, 2015, 125 (1/3) :3-18.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=WXYJ201005011&amp;v=MDkzNTBadEZ5dm1WTHpOTWpYU1pMRzRIOUhNcW85RVpZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 陈浩, 王延杰.基于小波变换的图像融合技术研究[J].微电子学与计算机, 2010, 27 (5) :39-41.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=QNNS201003004&amp;v=MTUzOTlHRnJDVVI3cWZadVp0Rnl2bVZMek5OQ1BGZmJHNEg5SE1ySTlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> 王丹, 周锦程.一种基于小波变换的图像融合改进算法[J].黔南民族师范学院学报, 2010, 30 (3) :8-12.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Change detection based on gabor wavelet features for very high resolution remote sensing images">

                                <b>[18]</b> Li Z, Shi W, Zhang H, et al.Change Detection Based on Gabor Wavelet Features for Very High Resolution Remote Sensing Images[J].IEEE Geoscience and Remote Sensing Letters, 2017, 14 (5) :783-787.
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Contour Detection and Hierarchical Image Segmentation">

                                <b>[19]</b> Arbelaez P, Maire M, Fowlkes C, et al.Contour Detection and Hierarchical Image Segmentation[J].IEEE Transactions on Pattern Analysis and Machine Intelligence, 2011, 33 (5) :898-916.
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_20" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1016742404.nh&amp;v=MDc3MDR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl2bVZMek5WRjI2R0xTOEhOWE1xNUViUElRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[20]</b> 张涛.小波变换在图像去噪和边缘检测中的研究与应用[D].贵阳:贵州大学, 2016.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14030300015603&amp;v=MjU5MTRLOEh0TE1ySTlGWk9vS0NudzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJMTBUYVJjPU5qN0Jhcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> Jaberi M, Bebis G, Hussain M, et al.Accurate and robust localization of duplicated region in copy-move image forgery[J].Machine Vision and Applications, 2014, 25 (2) :451-475.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201906038" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201906038&amp;v=MTIyNzlHRnJDVVI3cWZadVp0Rnl2bVZMek5MelRaWkxHNEg5ak1xWTlHYklRS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ28xeDVteFZmK0p3enVSVkNoMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
