<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135754465283750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201904039%26RESULT%3d1%26SIGN%3d6hiS8U3JYABd0lTycIHgb00bbYA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904039&amp;v=Mjg0NzA1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6bVZyN01MelRaWkxHNEg5ak1xNDlHYllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#25" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#30" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#34" data-title="&lt;b&gt;2 实体关系抽取&lt;/b&gt; "><b>2 实体关系抽取</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#35" data-title="&lt;b&gt;2.1 实体关系抽取模型&lt;/b&gt;"><b>2.1 实体关系抽取模型</b></a></li>
                                                <li><a href="#41" data-title="&lt;b&gt;2.2 词向量表示&lt;/b&gt;"><b>2.2 词向量表示</b></a></li>
                                                <li><a href="#50" data-title="&lt;b&gt;2.3 依存分析&lt;/b&gt;"><b>2.3 依存分析</b></a></li>
                                                <li><a href="#59" data-title="&lt;b&gt;2.4 卷积过程&lt;/b&gt;"><b>2.4 卷积过程</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;2.5 分段最大池化过程&lt;/b&gt;"><b>2.5 分段最大池化过程</b></a></li>
                                                <li><a href="#84" data-title="&lt;b&gt;2.6 Dropout及分类层&lt;/b&gt;"><b>2.6 Dropout及分类层</b></a></li>
                                                <li><a href="#91" data-title="&lt;b&gt;2.7 模型训练&lt;/b&gt;"><b>2.7 模型训练</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#97" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#99" data-title="&lt;b&gt;3.1 数据集&lt;/b&gt;"><b>3.1 数据集</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;3.2 超参数设置&lt;/b&gt;"><b>3.2 超参数设置</b></a></li>
                                                <li><a href="#111" data-title="&lt;b&gt;3.3 不同池化策略对比&lt;/b&gt;"><b>3.3 不同池化策略对比</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;3.4 实验结果与分析&lt;/b&gt;"><b>3.4 实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#123" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#37" data-title="图1 神经网络结构模型示意图">图1 神经网络结构模型示意图</a></li>
                                                <li><a href="#40" data-title="图2 实体关系抽取流程图">图2 实体关系抽取流程图</a></li>
                                                <li><a href="#46" data-title="&lt;b&gt;表1 词结构表现形式&lt;/b&gt;"><b>表1 词结构表现形式</b></a></li>
                                                <li><a href="#56" data-title="图3 语义依存分析示例">图3 语义依存分析示例</a></li>
                                                <li><a href="#58" data-title="&lt;b&gt;表2 Stanford CoreNLP输出结果&lt;/b&gt;"><b>表2 Stanford CoreNLP输出结果</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;表3 10种实体关系&lt;/b&gt;"><b>表3 10种实体关系</b></a></li>
                                                <li><a href="#107" data-title="&lt;b&gt;表4 超参数设置表&lt;/b&gt;"><b>表4 超参数设置表</b></a></li>
                                                <li><a href="#110" data-title="图4 交叉验证结果">图4 交叉验证结果</a></li>
                                                <li><a href="#110" data-title="图4 交叉验证结果">图4 交叉验证结果</a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;表5 不同池化策略下的实验结果&lt;/b&gt;"><b>表5 不同池化策略下的实验结果</b></a></li>
                                                <li><a href="#116" data-title="&lt;b&gt;表6 各模型性能表&lt;/b&gt;"><b>表6 各模型性能表</b></a></li>
                                                <li><a href="#119" data-title="图5 各项类别的F1值">图5 各项类别的F1值</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="169">


                                    <a id="bibliography_1" title="陈宇, 郑德权, 赵铁军.基于Deep Belief Nets的中文名实体关系抽取[J].软件学报, 2012, 23 (10) :2572-2585." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201210005&amp;v=MDc0NDZHNEg5UE5yNDlGWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6bVZyN01OeWZUYkw=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                        陈宇, 郑德权, 赵铁军.基于Deep Belief Nets的中文名实体关系抽取[J].软件学报, 2012, 23 (10) :2572-2585.
                                    </a>
                                </li>
                                <li id="171">


                                    <a id="bibliography_2" title="Liu C Y, Sun W B, Chao W H, et al.Convolution neural network for relation extraction[C]//International Conference on Advanced Data Mining and Applications.Springer, Berlin, Heidelberg, 2013:231-242." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolution neural network for relation extraction">
                                        <b>[2]</b>
                                        Liu C Y, Sun W B, Chao W H, et al.Convolution neural network for relation extraction[C]//International Conference on Advanced Data Mining and Applications.Springer, Berlin, Heidelberg, 2013:231-242.
                                    </a>
                                </li>
                                <li id="173">


                                    <a id="bibliography_3" title="Zeng D, Liu K, Lai S, et al.Relation classification via convolutional deep neural network[C]//Proceedings of COLING2014, the 25th International Conference on Computational Linguistics:Technical Papers, 2014:2335-2344." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relation classification via convolutional deep neural network">
                                        <b>[3]</b>
                                        Zeng D, Liu K, Lai S, et al.Relation classification via convolutional deep neural network[C]//Proceedings of COLING2014, the 25th International Conference on Computational Linguistics:Technical Papers, 2014:2335-2344.
                                    </a>
                                </li>
                                <li id="175">


                                    <a id="bibliography_4" title="Nguyen T H, Grishman R.Relation Extraction:Perspective from Convolutional Neural Networks[C]//The Workshop on Vector Space Modeling for Natural Language Processing, 2015:39-48." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relation Extraction:Perspective from Convolutional Neural Networks">
                                        <b>[4]</b>
                                        Nguyen T H, Grishman R.Relation Extraction:Perspective from Convolutional Neural Networks[C]//The Workshop on Vector Space Modeling for Natural Language Processing, 2015:39-48.
                                    </a>
                                </li>
                                <li id="177">


                                    <a id="bibliography_5" title="Santos C N D, Xiang B, Zhou B.Classifying relations by ranking with convolutional neural networks[J].Computer Science, 2015, 86 (86) :132-137." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Classifying Relations by Ranking with Convolutional Neural Networks">
                                        <b>[5]</b>
                                        Santos C N D, Xiang B, Zhou B.Classifying relations by ranking with convolutional neural networks[J].Computer Science, 2015, 86 (86) :132-137.
                                    </a>
                                </li>
                                <li id="179">


                                    <a id="bibliography_6" title="Zhang D, Wang D.Relation classification via recurrent neural network[EB].ar Xiv:1508.01006, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Relation classification via recurrent neural network[EB]">
                                        <b>[6]</b>
                                        Zhang D, Wang D.Relation classification via recurrent neural network[EB].ar Xiv:1508.01006, 2015.
                                    </a>
                                </li>
                                <li id="181">


                                    <a id="bibliography_7" title="Zeng D, Liu K, Chen Y, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C]//Conference on Empirical Methods in Natural Language Processing.2015:1753-1762." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks">
                                        <b>[7]</b>
                                        Zeng D, Liu K, Chen Y, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C]//Conference on Empirical Methods in Natural Language Processing.2015:1753-1762.
                                    </a>
                                </li>
                                <li id="183">


                                    <a id="bibliography_8" title="Lin Y, Shen S, Liu Z, et al.Neural relation extraction with selective attention over instances[C]//Meeting of the Association for Computational Linguistics, 2016:2124-2133." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural Relation Extraction with Selective Attention over Instances">
                                        <b>[8]</b>
                                        Lin Y, Shen S, Liu Z, et al.Neural relation extraction with selective attention over instances[C]//Meeting of the Association for Computational Linguistics, 2016:2124-2133.
                                    </a>
                                </li>
                                <li id="185">


                                    <a id="bibliography_9" title="Kim Y.Convolutional neural networks for sentence classification[C]//2017 XLIII Latin American Computer Conference (CLEI) .IEEE, 2014:1746-1751." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">
                                        <b>[9]</b>
                                        Kim Y.Convolutional neural networks for sentence classification[C]//2017 XLIII Latin American Computer Conference (CLEI) .IEEE, 2014:1746-1751.
                                    </a>
                                </li>
                                <li id="187">


                                    <a id="bibliography_10" title="Liu Y, Wei F, Li S, et al.A dependency-based neural network for relation classification[EB].ar Xiv:1507.04646, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A dependency-based neural network for relation classification[EB]">
                                        <b>[10]</b>
                                        Liu Y, Wei F, Li S, et al.A dependency-based neural network for relation classification[EB].ar Xiv:1507.04646, 2015.
                                    </a>
                                </li>
                                <li id="189">


                                    <a id="bibliography_11" title="Manning C D, Surdeanu M, Bauer J, et al.The Stanford Core NLP Natural Language Processing Toolkit[C]//Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics:System Demonstrations, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Stanford Core NLP Natural Language Processing Toolkit">
                                        <b>[11]</b>
                                        Manning C D, Surdeanu M, Bauer J, et al.The Stanford Core NLP Natural Language Processing Toolkit[C]//Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics:System Demonstrations, 2014.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(04),241-246+267 DOI:10.3969/j.issn.1000-386x.2019.04.038            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于依存关系和双通道卷积神经网络关系抽取方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E4%BD%B3%E6%98%8C&amp;code=41483482&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴佳昌</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E8%A7%82%E8%8C%82&amp;code=06155642&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴观茂</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%AE%89%E5%BE%BD%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0167619&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">安徽理工大学计算机科学与工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>关系抽取是自然语言中的一项重要任务, 其结果对后续的信息抽取和自动问答系统有重要的影响。随着深度学习的日益火热, 基于卷积神经网络的实体关系抽取已取得了不错的结果。不过词向量表示比较单一, 提取的特征也有限。针对这个问题, 将Word2vec训练的词向量和由自然语言处理工具得出的依存关系对分别作为模型两通道的输入向量, 使用双通道卷积神经网络提取特征来实现实体关系抽取。该模型可以提取更深层的语义信息, 并取得了比传统词向量更好的效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">关系抽取;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BE%9D%E5%AD%98%E5%85%B3%E7%B3%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">依存关系;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%8C%E9%80%9A%E9%81%93&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">双通道;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    吴佳昌, 硕士生, 主研领域:人工智能, 数据挖掘。;
                                </span>
                                <span>
                                    吴观茂, 博士。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-19</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61471004);</span>
                    </p>
            </div>
                    <h1><b>RELATIONSHIP EXTRACTION METHOD BASED ON DEPENDENCY RELATION AND TWO-CHANNEL CONVOLUTIONAL NEURAL NETWORK</b></h1>
                    <h2>
                    <span>Wu Jiachang</span>
                    <span>Wu Guanmao</span>
            </h2>
                    <h2>
                    <span>School of Computer Engineering and Technology, Anhui University of Science and Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Relation extraction is an important task in natural language, and its result has important influence on subsequent information extraction and automatic question-answering system. With the increasing popularity of deep learning, the entity relation extraction based on convolutional neural network has achieved good results. However, the word vector representation is relatively single, and the extracted features are limited. In view of this problem, the word vector trained by Word2 vec and the dependency relationship obtained by the natural language processing tool were used as the input vectors of the two channels in the model. Two-channel convolutional neural network was adopted to extract features to realize entity relationship extraction. This model can extract deeper semantic information and achieve better results than traditional word vectors.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Relation%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Relation extraction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Dependency%20relationship&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Dependency relationship;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Two-channel&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Two-channel;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-19</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="25" name="25" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="26">关系抽取作为自然语言处理中最重要的任务之一, 其结果直接影响着接下来信息抽取、机器翻译、自动问答系统等任务的进行, 所以好的关系抽取结果则是进行其他任务的前提条件。</p>
                </div>
                <div class="p1">
                    <p id="27">关系抽取方法主要分为三类:有监督、半监督和无监督的学习方法。有监督的学习方法虽然能够有不错的表现, 能提取更有效的特征和更高的准确率和召回率, 但比较依赖于人工标注语料。作为无监督的学习方法, 其假设拥有相同语义关系的实体对拥有相似的上下文关系, 用相似的上下文信息来对语义关系进行聚类, 相对来说准确率没有有监督的学习方法高。</p>
                </div>
                <div class="p1">
                    <p id="28">针对有监督学习方法需要大量人工标注语料和无监督学习方法的低准确率, Mintz提出了远程监督的学习方法。这是一种标注方法, 把知识库中存在的实体与实体的关系引入到正常的自然语言中进行训练。</p>
                </div>
                <div class="p1">
                    <p id="29">作为深度学习中的重要技术, 卷积神经网络有很强的提取深层特征的能力, 在图片识别领域取得了重要的成功, 在文本分类方面也表现不错。但是对于单通道、单一词向量的模型输入, 所提取的特征还是不够完整。本文重点研究有监督学习, 并针对上述问题提出双通道卷积神经网络, 一个通道输入词向量训练模型得出的句子向量, 另一个通道输入句子的依存关系向量, 然后进行特征的自动提取, 通过softmax分类器进行分类。这个模型相对于单通道、单一词向量的卷积神经网络有一定的提升。</p>
                </div>
                <h3 id="30" name="30" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="31">关于实体关系抽取任务, 经历了很长时间的探索和发展, 也尝试采用了很多方法来实现关系抽取, 比如说基于特征工程的方法<citation id="191" type="reference"><link href="169" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、基于核函数的方法等。有监督的分类方法是最常用的实现方法, 而且也有很好的表现。近几年越来越多的人开始使用神经网络来解决关系抽取问题。Liu等<citation id="192" type="reference"><link href="171" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>第一次提出使用卷积神经网络 (CNN) 来解决关系抽取问题, 虽然效果不错, 但是因为结构比较简单、没有池化层, 而存在较多噪声。文献<citation id="193" type="reference">[<a class="sup">3</a>]</citation>使用了较完整的CNN模型, pre-train的词向量, 而且其中加入了词的位置特征向量, 不过只有一种卷积核, 特征比较单一。针对卷积核大小单一的问题, 文献<citation id="194" type="reference">[<a class="sup">4</a>]</citation>提出了多尺寸卷积核的CNN模型, 不过还是传统的CNN结构, 没有明显的提升。文献<citation id="195" type="reference">[<a class="sup">5</a>]</citation>在CNN结构上没有太多变化, 只是采用了Ranking Loss的损失函数, 比之前的softmax效果好。文献<citation id="196" type="reference">[<a class="sup">6</a>]</citation>采用双向RNN (递归神经网络) 结构, 加入了实体的位置标签, 取得的效果与CNN模型差不多。</p>
                </div>
                <div class="p1">
                    <p id="32">文献<citation id="197" type="reference">[<a class="sup">7</a>]</citation>开始在大规模的数据集上做关系抽取, 使用了多实例学习来减弱远程监督带来的噪声问题, 而且在池化层也做了改进, 采用了分段最大池化, 更充分有效提取句子特征信息, 也取得了较好的结果。文献<citation id="198" type="reference">[<a class="sup">8</a>]</citation>在文献<citation id="199" type="reference">[<a class="sup">4</a>]</citation>的基础上加入了attention机制, 给赋予句子不同的权重, 突出想要的信息, 过滤掉噪声, 充分利用信息, 但是CNN模型还是适合用于短文本, RNN模型更适合长文本。文献<citation id="200" type="reference">[<a class="sup">9</a>]</citation>中加入句子级别的attention机制, 使用CNN模型结合静态词向量就取得了很好的效果。</p>
                </div>
                <div class="p1">
                    <p id="33">从上述文献中可以看出, 深度学习的方法在实体关系提取方面取得了不错的效果。如果加上的传统自然语言标注信息, 效果可能更好。针对这个想法, 本文提出了双通道卷积神经网络模型, 其中利用自然语言处理工具加入了语义依存分析信息, 能够深层次的提取两个单词之间的语义关系, 通过实验证明了其有效性。</p>
                </div>
                <h3 id="34" name="34" class="anchor-tag"><b>2 实体关系抽取</b></h3>
                <h4 class="anchor-tag" id="35" name="35"><b>2.1 实体关系抽取模型</b></h4>
                <div class="p1">
                    <p id="36">为了进一步提升深度学习实体关系抽取的能力, 结合自然语言处理工具, 将依存关系加入到特征提取中, 使网络提取更深的提取能力。本文提出基于依存分析和双通道卷积神经网络的实体关系抽取模型如图1所示。此模型包含有映射层、卷积层、池化层和输出层。与一般卷积神经网络不同的是它拥有两个通道的输入向量:通道一使用Word2vec训练的词向量;通道二使用权威自然语言处理工具标注之后得到的词性和依存关系对向量。通过卷积核将两个通道的特征提取到一个总的特征图, 再经过分段池化层的过滤, 得到相对于最大池化更多的特征, 最后送入分类器进行分类。</p>
                </div>
                <div class="area_img" id="37">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904039_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 神经网络结构模型示意图" src="Detail/GetImg?filename=images/JYRJ201904039_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 神经网络结构模型示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904039_037.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="38">作为深度学习中一种著名的神经网络, 卷积神经网络已经广泛应用于图像识别、语音识别等领域, 并取得出色的结果。它有出色的特征提取能力, 能够提取深层特征, 并且还能消除一定的噪声。卷积神经网络包括输入层、卷积层、采样层和输出层。针对不同的任务, 构造不同的模型结构, 达到最好的效果。</p>
                </div>
                <div class="p1">
                    <p id="39">整个实体关系抽取流程如图2所示。将数据集中的数据分别进行依存分析和词向量训练, 得到的向量矩阵再送入双通道卷积神经网络中进行实体关系抽取。</p>
                </div>
                <div class="area_img" id="40">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904039_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 实体关系抽取流程图" src="Detail/GetImg?filename=images/JYRJ201904039_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 实体关系抽取流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904039_040.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="41" name="41"><b>2.2 词向量表示</b></h4>
                <div class="p1">
                    <p id="42">词向量是词的一种基于神经网络的分布式表示, 是基于分布式假说对目标词进行建模, 其思想就是相似的上下文信息, 那么其所对应的语义关系也相似。主要的工作就是上下文的表示, 以及对上下文和实体词之间的关系建模。词向量将每个词映射到一个某个<i>k</i>维的真值向量, 维数较低而且能很好地捕获句子语义和句法特征, 所以在很多NLP任务都有很好的表现。</p>
                </div>
                <div class="p1">
                    <p id="43">目前对于训练词向量的方法常用的两种:Word2vec和GloVe。其中的Word2vec是由Google提供的开源词向量训练工序。CBOW和Skip-gram是Word2vec中两种训练模型, CBOW是通过上下文来预测目标词, 而Skip-gram是通过目标词来预测上下文, 总的思想都是相似的上下文有相似的目标词。本文使用Skip-gram来训练词向量, 词向量的维数默认设置为300维。</p>
                </div>
                <div class="p1">
                    <p id="44">为了更精确地表示和映射出词嵌入, 我们在每个词嵌入的后面附加了其位置信息, 就是体现当前这个词与句中实体的距离大小。其表达形式为 (d1, d2) 的一个元组。</p>
                </div>
                <div class="p1">
                    <p id="45">例如某个单词的位置信息元组为 (3, -2) , 3为单词到实体e1的矢量距离, 而-2为单词到实体e2的矢量距离, 从左到右表示矢量正向, 从右到左表示矢量负向, 正数表示单词在实体的右侧, 复数表示单词在实体的左侧。将每个词的位置信息加到每个词向量之后, 组成一个新的向量。加入了位置信息的单词结构表现形式为【word, d1, d2】, 其中:word表示某个单词;d1表示单词到实体1的距离;d2表示单词到实体2的距离。词结构表现形式如表1所示。</p>
                </div>
                <div class="area_img" id="46">
                    <p class="img_tit"><b>表1 词结构表现形式</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="46" border="1"><tr><td><br />word</td><td>d1</td><td>d2</td></tr><tr><td><br />Adults</td><td>0</td><td>-5</td></tr><tr><td><br />use</td><td>1</td><td>-4</td></tr><tr><td><br />drugs</td><td>2</td><td>-3</td></tr><tr><td><br />for</td><td>3</td><td>-2</td></tr><tr><td><br />this</td><td>4</td><td>-1</td></tr><tr><td><br />purpose</td><td>5</td><td>0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="47">加入位置信息后的词序列按照单词的顺序划分为:</p>
                </div>
                <div class="p1">
                    <p id="48"><i>S</i>={<i>s</i><sub>1</sub>, <i>s</i><sub>2</sub>, …, <i>s</i><sub><i>n</i></sub>}</p>
                </div>
                <div class="p1">
                    <p id="49">然后使用Word2vec中训练好的Skip-gram模型得到词向量, 每个词向量形如[0.792, -0.177, -0.107, 0.109, -0.542, …]是一种低维向量, 相较于独热向量表示方法, 既不会造成维数灾难也能表示词与词之间关联, 包含的语义信息也更丰富。这些词向量按照词原有的顺序排列, 组成一个矩阵, 长度为<i>n</i>, 宽度为<i>d</i>, 然后将这个矩阵作为卷积神经网络一个通道的输入。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50"><b>2.3 依存分析</b></h4>
                <div class="p1">
                    <p id="51">依存分析的目的是为了发现两个单词之间的句法结构和语义关系, 这种两个单词之间的关系被称为依存关系。</p>
                </div>
                <div class="p1">
                    <p id="52">依存分析包括依存句法分析和语义依存分析。依存句法分析主要是通过识别句中词语成分如“主谓宾, 定状补”, 来分析各成分之间的依赖关系, 并分析句子的句法结构。语义依存分析能够分析两个词语之间更深层次的语义关系, 跨越句法结构的束缚, 不同的句法结构可能表达的语义是相同的。文献<citation id="201" type="reference">[<a class="sup">10</a>]</citation>中使用RNN来得到句子的最短依存路径, 然后加入到词向量中, 使用卷积神经网络来提取特征, 取得了不错的效果。</p>
                </div>
                <div class="p1">
                    <p id="53">本文使用的是来自斯坦福大学开发的自然语言处理工具Stanford CoreNLP, 这是被广泛认可的自然语言处理工具。利用Standford CoreNLP对句子进行预处理, 包括分词、词性标注、命名实体识别和依存句法分析。</p>
                </div>
                <div class="p1">
                    <p id="54">依存关系对表现形式为:依存关系 (依存词, 核心词) , 依存关系是核心词和依存词之间的关系, 而且这个关系是有方向的, 依存词指向核心词, 支配词支配依存词, 这种支配关系不受距离的影响。</p>
                </div>
                <div class="p1">
                    <p id="55">例如对句子“Adults use drugs for this purpose.”进行语义依存分析, 结果如图3所示。图3中每个单词上方的大写字母缩写表示它们的词性, NNS表示复数名词;VBP表示非第三人称动词;IN表示连词;DT表示限定词;NN表示单数名词。这个句子的依存关系对表示为:nsubj (use-2, Adults-1) , root (ROOT-0, use-2) , dobj (use-2, drugs-3) , case (purpose-6, for-4) , det (purpose-6, this-5) , nmod (drugs-3, purpose-6) 。nsubj表示名词性主语, 这里指的是“Adults”;root表示根节点, 一般指向句子中的谓语, 这里指向“use”;dobj表示直接宾语;case表示格位标志;det表示限定词;nmod表示复合名词修饰。这些依存关系在图中表现为两个词通过一条有向弧线连接, 由一端的依存词指向另一端的核心词。每个单词后所带的数字表示它在句子中的序号。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904039_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 语义依存分析示例" src="Detail/GetImg?filename=images/JYRJ201904039_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 语义依存分析示例  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904039_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="57">本文首先将数据集中的数据进行依存分析之后, 输出一个以单词为单位的元组, 其结构表示为【POS, DR】, 其中:POS表示句子中单词的词性;DR表示依存关系。其对应的是每个单词和其依赖词汇组成的依存对, 表现形式为<i>r</i> (<i>n</i><sub>1</sub>, <i>n</i><sub>2</sub>) , <i>r</i>是两个单词的依存关系;<i>n</i><sub>1</sub>是依存词在句子中的序号;<i>n</i><sub>2</sub>是核心词在句子中的序号。Stanford CoreNLP输出结果如表2所示。这<i>n</i>个元组按词序排列, 同样使用Word2vec训练得到词向量矩阵, 这个矩阵宽度是<i>d</i>, 长度是<i>n</i> (<i>n</i>为句子的长度) , 记为<i>R</i>1∈<i>R</i><sup><i>n</i>×<i>d</i></sup>, 作为通道一的输入向量。</p>
                </div>
                <div class="area_img" id="58">
                    <p class="img_tit"><b>表2 Stanford CoreNLP输出结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="58" border="1"><tr><td><br />词性</td><td>依存关系</td><td>依存词序号</td><td>核心词序号</td></tr><tr><td><br />NNS</td><td>nsubj</td><td>2</td><td>1</td></tr><tr><td><br />VBP</td><td>root</td><td>0</td><td>2</td></tr><tr><td><br />NNS</td><td>dobj</td><td>2</td><td>3</td></tr><tr><td><br />IN</td><td>case</td><td>6</td><td>4</td></tr><tr><td><br />DT</td><td>det</td><td>6</td><td>5</td></tr><tr><td><br />NN</td><td>nmod</td><td>3</td><td>6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="59" name="59"><b>2.4 卷积过程</b></h4>
                <div class="p1">
                    <p id="60">卷积层中, 通过滑动卷积核 (也称过滤器) , 与输入向量进行卷积操作, 最后得到一个特征图。<b><i>R</i></b>1, <b><i>R</i></b>2∈<b><i>R</i></b><sup><i>d</i>×<i>n</i></sup>作为卷积层的输入矩阵, 其中<i>n</i>为句子<i>S</i>的长度 (词的个数) , <i>d</i>为矩阵宽度。</p>
                </div>
                <div class="p1">
                    <p id="61">两通道的输入矩阵宽度是一致的, 从而方便了两个通道的卷积操作。两个向量矩阵上下排列, 然后每个过滤器从通道一慢慢滑动到通道二, 完成一次完整的卷积操作。</p>
                </div>
                <div class="p1">
                    <p id="62">这样的连接方式好处是:1) 减少了参数的个数, 一定程度上减少了过拟合的可能性, 从而提高了训练速度;2) 破坏了结构对称性, 从而能提取出不同特征。</p>
                </div>
                <div class="p1">
                    <p id="63">过滤器的宽度为<i>d</i>, 与输入矩阵宽度一致, 高度为<i>h</i>, 而过滤器的权值向量被随机初始化<i>W</i>, 其中<i>W</i>={<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, …, <i>w</i><sub><i>m</i></sub>}, 有<i>m</i>个过滤器, 每个过滤器包含<i>h</i>*<i>d</i>个参数, <b><i>R</i></b>表示输入向量矩阵, <b><i>R</i></b>[<i>i</i>:<i>j</i>]表示矩阵<b><i>R</i></b>中第<i>i</i>行到第<i>j</i>行, 其中<i>j</i>=<i>i</i>+<i>h</i>-1。</p>
                </div>
                <div class="p1">
                    <p id="64">在卷积过程中, 有两种滑动情况如下:</p>
                </div>
                <div class="p1">
                    <p id="65">1) 过滤器在同一个通道滑动, 即过滤器和矩阵<i>R</i>的第<i>i</i>行到第<i>j</i>行进行卷积操作。</p>
                </div>
                <div class="p1">
                    <p id="66"><i>c</i><sub><i>ki</i></sub>=<i>f</i> (<b><i>W</i></b><sub><i>k</i></sub>·<b><i>R</i></b>[<i>i</i>:<i>j</i>]+<i>b</i>) </p>
                </div>
                <div class="p1">
                    <p id="67">1≤<i>i</i>≤<i>n</i>, <i>i</i>≤<i>j</i>≤<i>n</i>, <i>j</i>=<i>i</i>+<i>h</i>-1      (1) </p>
                </div>
                <div class="p1">
                    <p id="68">式中:<i>b</i>表示偏置;<i>f</i>为非线性激励函数ReLU, 能够快速得到较为精确的正确特征。</p>
                </div>
                <div class="p1">
                    <p id="69">2) 过滤器在两个通道中同时滑动。</p>
                </div>
                <div class="p1">
                    <p id="70"><i>c</i><sub><i>ki</i></sub>=<i>f</i> (<i>W</i><sub><i>k</i></sub>·{<b><i>R</i></b>1[<i>i</i>:<i>n</i>]:<b><i>R</i></b>2[1:<i>j</i>]}+<i>b</i>) </p>
                </div>
                <div class="p1">
                    <p id="71"><i>n</i>-<i>h</i>&lt;<i>i</i>≤<i>n</i>, <i>i</i>≤<i>j</i>&lt;<i>h</i>, <i>j</i>=<i>h</i>-<i>n</i>+<i>i</i>+1      (2) </p>
                </div>
                <div class="p1">
                    <p id="72">式中:<b><i>R</i></b>1、<b><i>R</i></b>2分别是通道一、通道二的输入向量矩阵。过滤器从通道一滑动到通道二, 横跨两个通道, 经过完整卷积操作之后得到一个特征图<i>C</i>。</p>
                </div>
                <div class="p1">
                    <p id="73"><i>C</i>={<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, …, <i>c</i><sub><i>m</i></sub>}∈<b><i>R</i></b><sup><i>m</i>× (2<i>s</i>-<i>h</i>+1) </sup></p>
                </div>
                <div class="p1">
                    <p id="74">式中:2<i>s</i>-<i>h</i>+1为特征图<i>C</i>高度;<i>m</i>是<i>C</i>的宽度。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.5 分段最大池化过程</b></h4>
                <div class="p1">
                    <p id="76">池化层能降低输出结果的维度, 还能保留最主要的特征。对于常见的最大池化操作, 就是为了让输出的特征与其输入的句子长度无关, 也就是无论输入的句子长度是多少, 输出的特征长度是不变的。单独的最大池化操作被普遍使用, 但是却不足以用于实体关系抽取。其用来提取特征太过粗糙, 也无法准确提取两个实体之间的结构性信息, 因此本文采用分段式最大池化操作。</p>
                </div>
                <div class="p1">
                    <p id="77">如图1所示, 将卷积层得到的特征图分为三段。第一段、第三段分别是对通道一和通道二进行卷积操作得到的特征图, 第二段是对两通道同时进行卷积操作得到的特征图, 将此特征图进行分段最大池化 (<i>piecewise max</i>-<i>pooling</i>) 。高度为4、5的过滤器也是同样操作。</p>
                </div>
                <div class="p1">
                    <p id="78"><i>p</i><sub><i>ki</i></sub>=max{<i>c</i><sub><i>ki</i></sub>}      (3) </p>
                </div>
                <div class="p1">
                    <p id="79">式中:1≤<i>k</i>≤<i>n</i> , <i>i</i>=1, 2, 3对应着卷积层的三段输出, 每一段进行最大池化操作得出<i>p</i><sub><i>k</i></sub>={<i>p</i><sub><i>k</i>1</sub>, <i>p</i><sub><i>k</i>2</sub>, <i>p</i><sub><i>k</i>3</sub>}, 将所有得到的<i>p</i><sub><i>k</i></sub>拼接起来, 得到一个特征向量。记</p>
                </div>
                <div class="p1">
                    <p id="80"><i>p</i><sub>1:<i>m</i></sub>=[<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>m</i></sub>]</p>
                </div>
                <div class="p1">
                    <p id="81">再通过一个非线性激励函数最后输出结果向量。</p>
                </div>
                <div class="p1">
                    <p id="82"><i>y</i>=tanh (<i>p</i><sub>1:<i>m</i></sub>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="83"><i>y</i>∈<b><i>R</i></b><sup><i>m</i></sup>的大小是固定的而且和输入句子的长度<i>n</i>无关。最后将得到特征向量送入softmax分类器进行分类。</p>
                </div>
                <h4 class="anchor-tag" id="84" name="84"><b>2.6 Dropout及分类层</b></h4>
                <div class="p1">
                    <p id="85">针对深度学习训练过程中出现的过拟合问题, <i>Hinton</i>提出了<i>Dropout</i>技术。过拟合问题有两个原因:一是训练样本数量太少, 二是构建的模型复杂度过高。通常可以采用增加训练样本的数量、数据扩充和正则化约束。<i>Dropout</i>思想就是正则化约束的一种实现形式, 通过随机丢弃一些隐藏层神经元, 使用修改过后的网络进行前向传播和反向传播, 能够有效地防止过拟合的发生。</p>
                </div>
                <div class="p1">
                    <p id="86">本文在最后第二层加入<i>Dropout</i>技术来实现正则化, 在前向传播途中, 以一定的概率p来丢弃一些隐藏层神经元来防止过拟合。</p>
                </div>
                <div class="p1">
                    <p id="87"><i>g</i>= (<i>y</i>⨂<b><i>r</i></b>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="88">式中:<b><i>r</i>∈<i>R</i></b><sup><i>m</i></sup>是以概率为<i>p</i>的Bernoulli随机变量向量;⨂表示按位相乘;<i>y</i>∈<i>R</i><sup><i>m</i></sup>则是池化层的输出结果。最后将经过Dropout处理得到的向量<b><i>g</i></b>输入到softmax分类器中。</p>
                </div>
                <div class="p1">
                    <p id="89"><i>O</i>=<b><i>W</i></b><sub><i>t</i></sub><b><i>g</i></b>      (6) </p>
                </div>
                <div class="p1">
                    <p id="90">式中:<b><i>W</i></b><sub><i>t</i></sub>∈<b><i>R</i></b><sup><i>m</i>1×<i>m</i></sup>是一个转换矩阵, 而<i>O</i>=[<i>O</i><sub>1</sub>, <i>O</i><sub>2</sub>, …, <i>O</i><sub><i>m</i>1</sub>]∈<b><i>R</i></b><sup><i>m</i>1</sup>, ∑<i>O</i><sub><i>i</i></sub>=1, 这是softmax层也是最后的输出结果。其中每个元素表示其对应类别的概率, 概率最大元素所对应的类别就是分类结果。m1表示可能的关系类型数目, 实验数据使用的是SemEval 2010 Task8数据集, 其中包含10种关系类型分类。</p>
                </div>
                <h4 class="anchor-tag" id="91" name="91"><b>2.7 模型训练</b></h4>
                <div class="p1">
                    <p id="92">本文模型中可训练参数为<i>θ</i>= (<b><i>R</i></b>1, <b><i>R</i></b>2, <i>W</i>, <b><i>W</i></b><sub><i>t</i></sub>) , 其中<b><i>R</i></b>1, <b><i>R</i></b>2分别是通道一和通道二训练好的向量矩阵, <b><i>W</i>∈<i>R</i></b><sup><i>d</i>×<i>h</i></sup>是卷积核参数, <b><i>W</i></b><sub><i>t</i></sub>是softmax分类器的转换矩阵。本文使用的损失函数为:</p>
                </div>
                <div class="p1">
                    <p id="93"><mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>J</mi><mo stretchy="false"> (</mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mrow><mi>log</mi></mrow></mstyle><mspace width="0.25em" /><mi>p</mi><mo stretchy="false"> (</mo><mi>o</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">|</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>, </mo><mi>θ</mi><mo stretchy="false">) </mo></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="95">式中:<i>N</i>表示样本的数量;<i>o</i><sub><i>i</i></sub>表示输出的分类<i>i</i>;<i>x</i><sub><i>i</i></sub>表示样本;<i>θ</i>表示参数集合, 其中条件概率<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>p</mi><mo stretchy="false"> (</mo><mi>o</mi><mo stretchy="false">|</mo><mi>x</mi><mo>, </mo><mi>θ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy="false"> (</mo><mi>o</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi><mn>1</mn></mrow></munderover><mtext>e</mtext></mstyle><mtext>x</mtext><mtext>p</mtext><mo stretchy="false"> (</mo><mi>o</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>;<i>m</i>1是总的分类个数;<i>o</i>是最后神经网络的输出结果。为了快速又准确的进行优化, 本文采用Adam优化算法, 进行快速地收敛损失函数, 然后再使用随机梯度下降算法进行微调, 使损失函数最小化。</p>
                </div>
                <h3 id="97" name="97" class="anchor-tag"><b>3 实 验</b></h3>
                <div class="p1">
                    <p id="98">首先介绍数据集, 然后通过交叉验证确定模型参数, 比较不同池化策略的池化效果, 将本文方法和不加入词性和依存关系的模型在整体识别率和各个类别的识别率上相比较, 最后得出结论依存关系对实体关系抽取的影响。</p>
                </div>
                <h4 class="anchor-tag" id="99" name="99"><b>3.1 数据集</b></h4>
                <div class="p1">
                    <p id="100">本文使用的数据集是<i>SemEval</i> 2010 <i>Task</i>8数据集, 其中包括8 000条训练数据, 2 717条测试数据, 数据集中训练样例如下所示:</p>
                </div>
                <div class="p1">
                    <p id="101">″&lt;e1&gt;People&lt;/e1&gt; have been moving back into &lt;e2&gt;downtown&lt;/e2&gt;.″</p>
                </div>
                <div class="p1">
                    <p id="102">Entity-Destination (e1, e2) </p>
                </div>
                <div class="p1">
                    <p id="103">Comment:</p>
                </div>
                <div class="p1">
                    <p id="104">第一行是句子, 其中两个实体已经通过“&lt;e1&gt;, &lt;/e1&gt;, &lt;e2&gt;, &lt;/e2&gt;”标注出来;第二行是两个实体的关系;第三行是备注。这个训练数据集包含10种实体关系, 如表3所示。</p>
                </div>
                <div class="area_img" id="105">
                    <p class="img_tit"><b>表3 10种实体关系</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="105" border="1"><tr><td><br />关系类型</td></tr><tr><td><br />Cause-Effect</td></tr><tr><td><br />Product-Producer</td></tr><tr><td><br />Entity-Origin</td></tr><tr><td><br />Instrument-Agency</td></tr><tr><td><br />Component-Whole</td></tr><tr><td><br />Content-Container</td></tr><tr><td><br />Entity-Destination</td></tr><tr><td><br />Member-Collection</td></tr><tr><td><br />Message-Topic</td></tr><tr><td><br />Other</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="106" name="106"><b>3.2 超参数设置</b></h4>
                <div class="area_img" id="107">
                    <p class="img_tit"><b>表4 超参数设置表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="107" border="1"><tr><td><br />超参数</td><td>值</td></tr><tr><td><br />卷积核个数<i>m</i></td><td>150*3</td></tr><tr><td><br />卷积核高度<i>h</i></td><td>3, 4, 5</td></tr><tr><td><br />学习速率<i>η</i></td><td>0.01</td></tr><tr><td><br />Dropout比率<i>D</i></td><td>0.6</td></tr><tr><td><br />词向量维度<i>d</i></td><td>300</td></tr><tr><td><br />正则化项</td><td>4</td></tr><tr><td><br />最小训练样本集值</td><td>50</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="108">其中词向量维度、学习速率、卷积核高度、正则化项设置为默认值, 其他项通过十折交叉验证法得到。通过将训练集分成十份, 轮流将其中一份作为测试集, 其他9份作为训练集, 经过多次实验得到上述参数。图4分别列出了卷积核个数和Dropout比率对F1值的影响。可以看出, 在此实验中随着卷积核数量和Dropout比率的增加, F1值逐渐增大, 当卷积核数量为150和Dropout比率为0.6时, F1值最高。但随着它们的继续增大, F1值反而下降, 说明过多的卷积核数量并不能提取更多有效特征, 更高的Dropout比率反而会导致准确率的下降。</p>
                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904039_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 交叉验证结果" src="Detail/GetImg?filename=images/JYRJ201904039_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 交叉验证结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904039_11000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="110">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904039_11001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 交叉验证结果" src="Detail/GetImg?filename=images/JYRJ201904039_11001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 交叉验证结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904039_11001.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="111" name="111"><b>3.3 不同池化策略对比</b></h4>
                <div class="p1">
                    <p id="112">不同的池化策略有不同的过滤效果, 对最后的分类效果也会产生影响, 表5讨论了在三种池化策略下模型的F1值表现。三段池化是本文采用的策略, 根据卷积操作形成的三段特征图进行分段最大池化;二段池化则是以同时通过两通道的部分为界, 对上下两部分进行最大池化。从结果看来, 分段最大池化比最大池化效果有0.8%的提升, 三段池化相对于二段池化有略微提升。</p>
                </div>
                <div class="area_img" id="113">
                    <p class="img_tit"><b>表5 不同池化策略下的实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="113" border="1"><tr><td><br />池化策略</td><td>F1值</td></tr><tr><td><br />最大池化</td><td>84.3</td></tr><tr><td><br />二段最大池化</td><td>84.9</td></tr><tr><td><br />三段最大池化</td><td>85.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>3.4 实验结果与分析</b></h4>
                <div class="p1">
                    <p id="115">本文使用准确率、召回率和F1值来评价这个模型的性能。各模型性能参照如表6所示。</p>
                </div>
                <div class="area_img" id="116">
                    <p class="img_tit"><b>表6 各模型性能表</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="116" border="1"><tr><td><br />模型</td><td>准确率</td><td>召回率</td><td>F1值</td></tr><tr><td><br />CNNs</td><td>81.8</td><td>83.6</td><td>82.7</td></tr><tr><td><br />PCNNs</td><td>82.3</td><td>83.9</td><td>83.1</td></tr><tr><td><br />PCNNs+POS</td><td>83.7</td><td>84.1</td><td>83.9</td></tr><tr><td><br />PCNNs+DR</td><td>84.6</td><td>84.2</td><td>84.4</td></tr><tr><td><br />PCNNs+POS+DR</td><td>86</td><td>84.3</td><td>85.1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="117">通过实验数据可以看出, 在使用普通的CNNs和PCNNs (分段卷积神经网络) , F1值只有82.7和83.1, 而PCNNs加上词性标注POS, F1值有83.9;PCNNs加上依存关系DR之后, F1值变为84.4;而本文模型 (PCNNs+POS+DR) 所获得的F1值为85.1。本文方法相对于传统卷积神经网络来说有约2.4%的提升, 也比单纯加入词性和依存关系的模型有提升。</p>
                </div>
                <div class="p1">
                    <p id="118">另外, 本文方法相对于PCNNs在每项类别上的识别效果如图5所示。使用本文方法后, 相对于PCNNs有总体2%的提升, 从每个类别识别效果来看, 提升的大小不同, 类别Entity-Origin和类别Entity-Destination大约有3%的提升, 而类别Instrument-Agency和类别Other提升较少, 说明加入了语义依存分析之后对整体识别效果有一定的提升, 但是个别类别的识别效果提升不大。</p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904039_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 各项类别的F1值" src="Detail/GetImg?filename=images/JYRJ201904039_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 各项类别的F1值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904039_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="120">根据实验可以得出以下结论 :</p>
                </div>
                <div class="p1">
                    <p id="121"> (1) 在引入依存分析作为特征之后, 明显比单纯从Word2vec训练的词向量中提取特征来得更加准确, 因为此模型能从语义层次提取句子中的信息, 更好地反映句子的语法结构, 分类性能也更好。综上, 加入的特征越多, 分类的结果也越准确, 当然也得考虑不能有过多的参数, 不然很难拟合。</p>
                </div>
                <div class="p1">
                    <p id="122"> (2) 使用卷积神经网络模型和自然语言处理工具相结合, 比单一使用卷积神经网络等机器学习模型来得效果好, 再加上卷积神经模型善于提取平面特征, 能够出色地完成关系抽取任务。</p>
                </div>
                <h3 id="123" name="123" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="124">本文针对单一使用训练之后的词向量提取特征或者自然语言处理工具来实现关系抽取, 提出了一种基于依存关系的双通道卷积神经网络模型。Word2vec训练的词向量和由自然语言处理工具得出的依存关系对分别作为模型两通道的输入向量, 经过实验表明, 两者结合能够有效提高F1值。不过这是基于有监督的情况下, 更多的时候需要从一些无结构的语句中提出实体关系, 而且要做到准确率高, 还需要继续研究。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="169">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJXB201210005&amp;v=MDAzNzZZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXptVnI3TU55ZlRiTEc0SDlQTnI0OUY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b>陈宇, 郑德权, 赵铁军.基于Deep Belief Nets的中文名实体关系抽取[J].软件学报, 2012, 23 (10) :2572-2585.
                            </a>
                        </p>
                        <p id="171">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolution neural network for relation extraction">

                                <b>[2]</b>Liu C Y, Sun W B, Chao W H, et al.Convolution neural network for relation extraction[C]//International Conference on Advanced Data Mining and Applications.Springer, Berlin, Heidelberg, 2013:231-242.
                            </a>
                        </p>
                        <p id="173">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relation classification via convolutional deep neural network">

                                <b>[3]</b>Zeng D, Liu K, Lai S, et al.Relation classification via convolutional deep neural network[C]//Proceedings of COLING2014, the 25th International Conference on Computational Linguistics:Technical Papers, 2014:2335-2344.
                            </a>
                        </p>
                        <p id="175">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relation Extraction:Perspective from Convolutional Neural Networks">

                                <b>[4]</b>Nguyen T H, Grishman R.Relation Extraction:Perspective from Convolutional Neural Networks[C]//The Workshop on Vector Space Modeling for Natural Language Processing, 2015:39-48.
                            </a>
                        </p>
                        <p id="177">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Classifying Relations by Ranking with Convolutional Neural Networks">

                                <b>[5]</b>Santos C N D, Xiang B, Zhou B.Classifying relations by ranking with convolutional neural networks[J].Computer Science, 2015, 86 (86) :132-137.
                            </a>
                        </p>
                        <p id="179">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Relation classification via recurrent neural network[EB]">

                                <b>[6]</b>Zhang D, Wang D.Relation classification via recurrent neural network[EB].ar Xiv:1508.01006, 2015.
                            </a>
                        </p>
                        <p id="181">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks">

                                <b>[7]</b>Zeng D, Liu K, Chen Y, et al.Distant supervision for relation extraction via piecewise convolutional neural networks[C]//Conference on Empirical Methods in Natural Language Processing.2015:1753-1762.
                            </a>
                        </p>
                        <p id="183">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural Relation Extraction with Selective Attention over Instances">

                                <b>[8]</b>Lin Y, Shen S, Liu Z, et al.Neural relation extraction with selective attention over instances[C]//Meeting of the Association for Computational Linguistics, 2016:2124-2133.
                            </a>
                        </p>
                        <p id="185">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification">

                                <b>[9]</b>Kim Y.Convolutional neural networks for sentence classification[C]//2017 XLIII Latin American Computer Conference (CLEI) .IEEE, 2014:1746-1751.
                            </a>
                        </p>
                        <p id="187">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A dependency-based neural network for relation classification[EB]">

                                <b>[10]</b>Liu Y, Wei F, Li S, et al.A dependency-based neural network for relation classification[EB].ar Xiv:1507.04646, 2015.
                            </a>
                        </p>
                        <p id="189">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Stanford Core NLP Natural Language Processing Toolkit">

                                <b>[11]</b>Manning C D, Surdeanu M, Bauer J, et al.The Stanford Core NLP Natural Language Processing Toolkit[C]//Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics:System Demonstrations, 2014.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201904039" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904039&amp;v=Mjg0NzA1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6bVZyN01MelRaWkxHNEg5ak1xNDlHYllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
