<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135598070783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201909048%26RESULT%3d1%26SIGN%3dBXYPHDJEFme1iuHcTAjD1Y99Jm0%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909048&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909048&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909048&amp;v=MjYzNzdCdEdGckNVUjdxZlp1WnRGeWprVWJ6T0x6VFpaTEc0SDlqTXBvOUJiSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#25" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#30" data-title="&lt;b&gt;1 TDSFC核心算法&lt;/b&gt; "><b>1 TDSFC核心算法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#33" data-title="&lt;b&gt;1.1 核心内容提取算法&lt;/b&gt;"><b>1.1 核心内容提取算法</b></a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;1.2 链接优先级算法&lt;/b&gt;"><b>1.2 链接优先级算法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="&lt;b&gt;2 结合文本密度的聚焦爬虫算法&lt;/b&gt; "><b>2 结合文本密度的聚焦爬虫算法</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#124" data-title="&lt;b&gt;3 实验和分析&lt;/b&gt; "><b>3 实验和分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#125" data-title="&lt;b&gt;3.1 实验设定&lt;/b&gt;"><b>3.1 实验设定</b></a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;3.2 实验结果和分析&lt;/b&gt;"><b>3.2 实验结果和分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#156" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#75" data-title="图1 Word2vec词向量模型">图1 Word2vec词向量模型</a></li>
                                                <li><a href="#89" data-title="图2 TDSFC框架图">图2 TDSFC框架图</a></li>
                                                <li><a href="#139" data-title="图3 &lt;i&gt;δ&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;、&lt;i&gt;δ&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;、&lt;i&gt;δ&lt;/i&gt;&lt;sub&gt;3&lt;/sub&gt;参数对比实验">图3 <i>δ</i><sub>1</sub>、<i>δ</i><sub>2</sub>、<i>δ</i><sub>3</sub>参数对比实验</a></li>
                                                <li><a href="#141" data-title="&lt;b&gt;表1 核心内容提取算法性能测试&lt;/b&gt;"><b>表1 核心内容提取算法性能测试</b></a></li>
                                                <li><a href="#149" data-title="&lt;b&gt;表2 部分获取率对比实验数据&lt;/b&gt;"><b>表2 部分获取率对比实验数据</b></a></li>
                                                <li><a href="#150" data-title="图4 爬虫获取率对比图">图4 爬虫获取率对比图</a></li>
                                                <li><a href="#153" data-title="&lt;b&gt;表3 部分平均相似度对比实验数据&lt;/b&gt;"><b>表3 部分平均相似度对比实验数据</b></a></li>
                                                <li><a href="#154" data-title="图5 聚焦爬虫平均相似度对比图">图5 聚焦爬虫平均相似度对比图</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Khan M N A,Mahmood A.A distinctive approach to obtain higher page rank through search engine optimization[J].Sādhanā,2018,43(3):43." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A distinctive approach to obtain higher page rank through search engine optimization">
                                        <b>[1]</b>
                                         Khan M N A,Mahmood A.A distinctive approach to obtain higher page rank through search engine optimization[J].Sādhanā,2018,43(3):43.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 肖江,季节.基于Heritrix的主题爬虫在互联网舆情系统中应用[J].电子设计工程,2015,23(6):30-32." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201506009&amp;v=MTc5OTlPSWpyUGRMRzRIOVRNcVk5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYno=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         肖江,季节.基于Heritrix的主题爬虫在互联网舆情系统中应用[J].电子设计工程,2015,23(6):30-32.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 费晨杰,刘柏嵩.基于LDA扩展主题词库的主题爬虫研究[J].计算机应用与软件,2018,35(4):49-54." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201804010&amp;v=MTEwODNVUjdxZlp1WnRGeWprVWJ6T0x6VFpaTEc0SDluTXE0OUVaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         费晨杰,刘柏嵩.基于LDA扩展主题词库的主题爬虫研究[J].计算机应用与软件,2018,35(4):49-54.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Seyfi A.A Focused Crawler Combinatory Link and Content Model Based on T-Graph Principles[J].Computer Standards &amp;amp; Interfaces,2016,43:1-11." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEAC9F67ECEA8B4CD0793697776EC7809&amp;v=MjI2MjF0dGh4TG05dzY0PU5pZk9mY2JKYmRpNnFZZ3dGNTUrQkE0OXZHSVQ3VForVG5ibHF4VXpETUdUVGJxV0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Seyfi A.A Focused Crawler Combinatory Link and Content Model Based on T-Graph Principles[J].Computer Standards &amp;amp; Interfaces,2016,43:1-11.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Du Y,Liu W,Lv X,et al.An improved focused crawler based on Semantic Similarity Vector Space Model[J].Applied Soft Computing,2015,36(C):392-407." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1B022DC49F5A1077A33ABB0CB60F9C97&amp;v=MjA0MjM9TmlmT2ZiTEtIdFBPMi94QmJaMEtmWDA1eUJGaTZUd01PZzNpMzJBemVjU2ROck9ZQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeExtOXc2NA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Du Y,Liu W,Lv X,et al.An improved focused crawler based on Semantic Similarity Vector Space Model[J].Applied Soft Computing,2015,36(C):392-407.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Tarik B,Mahmoud D D,Zakaria E.Classifying Web Pages by Aimed Nation Using Machine Learning[J].International Journal of Organizational and Collective Intelligence,2017,7(1):20-35." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJIG&amp;filename=SJIG5A7621198581E9340886AC2096F92D64&amp;v=MzAxMDFPNEhEUWt3ekJJVDRqZDdPUXpnckJzekQ3dVdNYnliQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeExtOXc2ND1OaWZDYWJiSkdkZk9ybzVNYg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Tarik B,Mahmoud D D,Zakaria E.Classifying Web Pages by Aimed Nation Using Machine Learning[J].International Journal of Organizational and Collective Intelligence,2017,7(1):20-35.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Gali N,Mariescu-Istodor R,Fr&#228;nti P.Using linguistic features to automatically extract web page title[J].Expert Systems with Applications,2017,79:296-312." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9264F61D30D2EB75BCC1E7B4D361D6DB&amp;v=MDIxMDMwNXR0aHhMbTl3NjQ9TmlmT2ZicTZHTlc2cVk0eFordDdEZ2xMeUJOaG1VeDhQWGlRcUdZMmY3UGdRODd0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Gali N,Mariescu-Istodor R,Fr&#228;nti P.Using linguistic features to automatically extract web page title[J].Expert Systems with Applications,2017,79:296-312.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 王飞,谭新.一种基于Word2vec的训练效果优化策略研究[J].计算机应用与软件,2018,35(1):97-102,174." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801017&amp;v=MDI5NzdCdEdGckNVUjdxZlp1WnRGeWprVWJ6T0x6VFpaTEc0SDluTXJvOUVZNFFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         王飞,谭新.一种基于Word2vec的训练效果优化策略研究[J].计算机应用与软件,2018,35(1):97-102,174.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Wensen L,Zewen C,Jun W,et al.Short text classification based on Wikipedia and Word2vec[C]//IEEE International Conference on Computer &amp;amp; Communications.IEEE,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Short text classification based on Wikipedia and Word2vec">
                                        <b>[9]</b>
                                         Wensen L,Zewen C,Jun W,et al.Short text classification based on Wikipedia and Word2vec[C]//IEEE International Conference on Computer &amp;amp; Communications.IEEE,2017.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Putri I,Kusumaningrum R.Latent Dirichlet Allocation(LDA) for Sentiment Analysis Toward Tourism Review in Indonesia[J].Journal of Physics:Conference Series,2017,801:012073." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPDA87076D5CD63E89DAF51A30785F6B99D&amp;v=MTQ2MjlpVGJhc0t3R2RITHFmdEFGNThKRHdreHhtSmluRHA4T1h6aXF4b3dEN1RtVExQckNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMbTl3NjQ9Tg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Putri I,Kusumaningrum R.Latent Dirichlet Allocation(LDA) for Sentiment Analysis Toward Tourism Review in Indonesia[J].Journal of Physics:Conference Series,2017,801:012073.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Yan W,Pan L.Designing focused crawler based on improved genetic algorithm[C]//Tenth International Conference on Advanced Computational Intelligence.IEEE,2018." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Designing focused crawler based on improved genetic algorithm">
                                        <b>[11]</b>
                                         Yan W,Pan L.Designing focused crawler based on improved genetic algorithm[C]//Tenth International Conference on Advanced Computational Intelligence.IEEE,2018.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(09),270-275 DOI:10.3969/j.issn.1000-386x.2019.09.047            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>结合文本密度的语义聚焦爬虫方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9E%97%E6%A4%B9%E5%B0%A0&amp;code=28319192&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">林椹尠</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%A2%81%E6%9F%B1&amp;code=41743693&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">袁柱</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%B0%8F%E5%B9%B3&amp;code=35806358&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李小平</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E7%90%86%E5%AD%A6%E9%99%A2&amp;code=1698419&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安邮电大学理学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E9%82%AE%E7%94%B5%E5%A4%A7%E5%AD%A6%E9%80%9A%E4%BF%A1%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安邮电大学通信与信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对聚焦爬虫网页核心内容提取算法准确性偏低以及相似度计算模型语义信息考虑不充分造成的爬取准确度和效率偏低的问题,提出结合文本密度的语义聚焦爬虫方法。引入核心内容提取算法,使用标题结合LCS算法定位核心内容文本的起始和终止位置,提取网页核心内容。引入基于Word2vec的主题相关度算法计算核心内容的主题相关度,改进PageRank算法计算链接主题重要度。结合主题相关度和主题重要度计算链接优先级。此外,为提高聚焦爬虫的全局搜索性能,结合主题词使用搜索引擎扩展链接集。与通用爬虫和多种聚焦爬虫相比,该方法爬虫爬取准确度和效率更优。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%81%9A%E7%84%A6%E7%88%AC%E8%99%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聚焦爬虫;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">核心内容;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LCS&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LCS;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Word2vec&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Word2vec;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%93%BE%E6%8E%A5%E4%BC%98%E5%85%88%E7%BA%A7&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">链接优先级;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    林椹尠,教授,主研领域:自然语言处理。;
                                </span>
                                <span>
                                    袁柱,硕士生。;
                                </span>
                                <span>
                                    李小平,讲师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>陕西省教育厅专项科学研究基金项目(18JK0699);</span>
                    </p>
            </div>
                    <h1><b>SEMANTIC FOCUSED CRAWLER METHOD COMBINING TEXT DENSITY</b></h1>
                    <h2>
                    <span>Lin Zhenxian</span>
                    <span>Yuan Zhu</span>
                    <span>Li Xiaoping</span>
            </h2>
                    <h2>
                    <span>School of Science, Xi'an University of Post and Telecommunications</span>
                    <span>School of Communication and Information Engineering, Xi'an University of Post and Telecommunications</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>In view of the problems of low accuracy and low efficiency of focused crawler caused by the low accuracy in web core content extraction algorithm and insufficient consideration of semantic information in similarity computing model, we proposed a semantic focused crawler method combining text density. The core content extraction algorithm was introduced to use the title combined with the LCS algorithm to locate the starting and ending positions of the core content, then extracted the core content of the web page. A topic relevance algorithm based on Word2 vec was introduced to calculate the topic relevance of core content, and the PageRank algorithm was improved to calculate the importance between the link and the topic. We combined topic relevance and topic importance to calculate the link priority. In addition, in order to improve the global search performance of focused crawler, search engine was used to expand the link set with keywords. Compared with universal crawlers and multiple focused crawlers, our method is more accurate and efficient.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Focused%20crawler&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Focused crawler;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Core%20content&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Core content;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=LCS&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">LCS;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Word2vec&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Word2vec;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Link%20priority&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Link priority;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-24</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="25" name="25" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="26">网络爬虫作为获取网络信息的一种手段,通过自动下载网页,获取网络信息<citation id="159" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。传统的基于广度优先的通用爬虫(Breadth First Crawler,BFC),由于忽略了未访问链接的优先级,下载大量无关网页,爬取效率低下,浪费资源<citation id="160" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。作为改进,聚焦爬虫引入主题相似度算法,通过计算未访问链接的优先级,引导爬虫抓取主题相关的网页<citation id="161" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="27">Seyfi等<citation id="162" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出基于向量空间的聚焦爬虫(Vector Space Model Crawler,VSMC),通过构建词向量计算网页文档和锚文本的主题相似度,结合两相似度计算未访问链接的优先级,引导爬虫抓取主题相关的网页,不仅提高了爬取准确度,在一定程度上还降低了资源损耗。但是,通过VSM计算的主题相似度忽略了词项的语义信息。作为改进,Du等<citation id="163" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出一种基于语义相似向量空间的聚焦爬虫(Semantic Similarity Vector Space Model Crawler,SSVSMC),通过构建主题词项和文本语义向量计算主题相似度,一定程度上提高了爬取准确度。但是,其通过HTML标签提取网页核心内容,需要人为根据网页结构编写模板,扩展性较低。为提高扩展性,Tarik等<citation id="164" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出以HTML文档中的行作为基本单元,根据HTML行文本特征训练有监督的学习分类器,提取网页中的正文内容用于爬虫主题相似度计算,提高了扩展性,取得了不错的效果。</p>
                </div>
                <div class="p1">
                    <p id="28">上述聚焦爬虫通过改进相似度计算模型,在一定程度上提高了爬取准确度。但是,利用HTML标签或行文本特征很难完整地提取网页核心内容,不仅效率低下且容易引入噪声信息,对爬虫主题相似度计算造成负面影响。此外,爬虫相似度计算模型语义信息考虑仍不充分,爬取准确度有待提高。</p>
                </div>
                <div class="p1">
                    <p id="29">为了能够准确提取网页核心内容用于爬虫主题相似度计算,提高爬虫爬取准确度和效率。提出结合文本密度的语义聚焦爬虫方法(Text Density Semantic Focused Crawler,TDSFC)。引入核心内容提取算法,使用网页标题结合最长公共子序列算法(Longest Common Subsequence,LCS)定位网页核心内容的起始和终止位置,提取网页核心内容。结合核心内容主题相关度和链接主题重要度引导爬虫抓取主题相关网页。此外,为提高聚焦爬虫的全局搜索性能,使用主题词结合搜索引擎对链接集进行扩展。</p>
                </div>
                <h3 id="30" name="30" class="anchor-tag"><b>1 TDSFC核心算法</b></h3>
                <div class="p1">
                    <p id="31">网页核心内容提取算法以及链接优先级算法是TDSFC的两个核心算法。</p>
                </div>
                <div class="p1">
                    <p id="32">网页核心内容提取算法通过使用网页标题结合LCS算法定位网页核心内容的起始和终止位置,过滤噪声信息,提取网页核心内容。链接优先级算法通过结合核心内容的主题相关度和链接的主题重要度对链接进行排序,引导爬虫抓取主题相关的网页。</p>
                </div>
                <h4 class="anchor-tag" id="33" name="33"><b>1.1 核心内容提取算法</b></h4>
                <div class="p1">
                    <p id="34">网页核心内容的提取是爬虫主题相似度计算的前提。BFC、VSMC以及SSVSMC通过直接分析HTML文档提取网页核心内容,方法简单且准确率相对较高,但没有统一的标准,扩展性较低且易提取与网页主题不相关的内容,直接影响了聚焦爬虫的爬取准确度和效率。有监督的网页核心内容提取方法虽提升了扩展性,但需要大量的训练数据,消耗大量的时间和内存空间。</p>
                </div>
                <div class="p1">
                    <p id="35">标题是对网页内容的高度概括,与网页核心内容具有很强的语义相关性<citation id="165" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。因此,提出一种使用网页标题结合LCS算法的核心内容提取算法,算法设计如下:</p>
                </div>
                <div class="p1">
                    <p id="36">1) 输入HTML文档<i>d</i>,初始化网页纯文本内容<i>Dtext</i>={<i>dtext</i><sub>1</sub>,<i>dtext</i><sub>2</sub>,…,<i>dtext</i><sub><i>n</i></sub>}和有效文本内容<i>Ctext</i>={<i>ctext</i><sub>1</sub>,<i>ctext</i><sub>2</sub>,…,<i>ctext</i><sub><i>m</i></sub>}。其中<i>dtext</i><sub><i>n</i></sub>为<i>Dtext</i>的第<i>n</i>行内容,<i>ctext</i><sub><i>m</i></sub>为<i>Ctext</i>的第<i>m</i>行内容。</p>
                </div>
                <div class="p1">
                    <p id="37">2) 提取网页内容的标题<i>title</i>,调用<i>parse</i>函数对<i>d</i>进行处理。首先,剔除&lt;script&gt;和&lt;style&gt;标签内容以及注释、空格和特殊字符等内容。随后,剔除所有标签仅保留文本内容<i>Dtext</i>。</p>
                </div>
                <div class="p1">
                    <p id="38">3) 设定最小行文本有效长度<i>δ</i><sub>1</sub>以及最小行标点有效长度<i>δ</i><sub>2</sub>。对<i>Dtext</i>处理,提取有效文本<i>Ctext</i>。</p>
                </div>
                <div class="p1">
                    <p id="39">4) 通过使用<i>title</i>结合LCS算法同时定位网页核心内容的起始位置<i>start</i>和终止位置<i>end</i>来提取网页核心内容<i>Content</i>。对于<i>Ctext</i>={<i>c</i><sub>1</sub>,<i>c</i><sub>2</sub>,…,<i>c</i><sub><i>i</i></sub>,…,<i>c</i><sub><i>m</i></sub>},<i>title</i>={<i>t</i><sub>1</sub>,<i>t</i><sub>2</sub>,…,<i>t</i><sub><i>j</i></sub>,…,<i>t</i><sub><i>n</i></sub>},LCS算法如下所示:</p>
                </div>
                <div class="p1">
                    <p id="40" class="code-formula">
                        <mathml id="40"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>C</mi><mi>S</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>0</mn><mspace width="0.25em" /><mi>i</mi><mo>=</mo><mn>0</mn><mspace width="0.25em" /><mtext>o</mtext><mtext>r</mtext><mspace width="0.25em" /><mi>j</mi><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>L</mi><mi>C</mi><mi>S</mi><mo stretchy="false">[</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo>+</mo><mn>1</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>&gt;</mo><mn>0</mn><mspace width="0.25em" /><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>t</mi><msub><mrow></mrow><mi>j</mi></msub></mtd></mtr><mtr><mtd><mi>max</mi><mo stretchy="false">{</mo><mi>L</mi><mi>C</mi><mi>S</mi><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>j</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo>,</mo><mi>L</mi><mi>C</mi><mi>S</mi><mo stretchy="false">[</mo><mi>i</mi><mo>-</mo><mn>1</mn><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo><mo stretchy="false">}</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>&gt;</mo><mn>0</mn><mspace width="0.25em" /><mi>c</mi><msub><mrow></mrow><mi>i</mi></msub><mo>≠</mo><mi>t</mi><msub><mrow></mrow><mi>j</mi></msub></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="41">式中:<i>c</i><sub><i>i</i></sub>为有效文本<i>Ctext</i>的第<i>i</i>行文本,<i>t</i><sub><i>j</i></sub>为标题<i>title</i>的第<i>j</i>个词项,<i>L</i>为有效文本行数。<i>L</i><sub>LCS</sub>为第<i>i</i>行文本<i>c</i><sub><i>i</i></sub>与<i>title</i>由LCS算法所求值。当<mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mfrac><mi>L</mi><mn>2</mn></mfrac></mrow></math></mathml>时,若在<i>i</i>位置<i>L</i><sub>LCS</sub>取值首次大于阈值<i>δ</i><sub>3</sub>(<i>δ</i><sub>3</sub>表示<i>title</i>和<i>c</i><sub><i>i</i></sub>中含有的相同词项最少数目),则认为位置<i>i</i>为网页核心内容的起始位置。同理,当<mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mi>L</mi><mn>2</mn></mfrac><mo>&lt;</mo><mi>i</mi><mo>≤</mo><mi>L</mi></mrow></math></mathml>时,从第<i>L</i>行开始遍历,若在<i>i</i>位置<i>L</i><sub>LCS</sub>取值首次大于<i>δ</i><sub>3</sub>,则认为位置<i>i</i>为网页核心内容的终止位置。具体核心内容提取算法如算法1所示。</p>
                </div>
                <div class="p1">
                    <p id="44"><b>算法1</b> 核心内容提取算法。</p>
                </div>
                <div class="p1">
                    <p id="45">1. 输入:网页文档<i>d</i>,<i>Dtext</i>={},<i>Ctext</i>={}</p>
                </div>
                <div class="p1">
                    <p id="46">2. 输出:核心内容<i>Content</i></p>
                </div>
                <div class="p1">
                    <p id="47">3. <i>title</i>=<i>get</i>_<i>title</i>(<i>d</i>)</p>
                </div>
                <div class="p1">
                    <p id="48">4. <i>Dtext</i>=<i>parse</i>(<i>d</i>)</p>
                </div>
                <div class="p1">
                    <p id="49">5. for <i>dtext</i> in <i>range</i>(<i>Dtext</i>)</p>
                </div>
                <div class="p1">
                    <p id="50">6.  <i>l</i>1=<i>len</i>_<i>t</i>(<i>dtext</i>),<i>l</i>2=<i>len</i>_<i>p</i>(<i>dtext</i>)</p>
                </div>
                <div class="p1">
                    <p id="51">7.  if (<i>l</i>1&lt;<i>δ</i><sub>1</sub>‖<i>l</i>2&lt;<i>δ</i><sub>2</sub>)</p>
                </div>
                <div class="p1">
                    <p id="52">8.  continue</p>
                </div>
                <div class="p1">
                    <p id="53">9.  else:</p>
                </div>
                <div class="p1">
                    <p id="54">10.  <i>Ctext</i>.<i>append</i>(<i>dtext</i>)</p>
                </div>
                <div class="p1">
                    <p id="55">11. <i>L</i>=<i>len</i>_<i>row</i>(<i>Ctext</i>)</p>
                </div>
                <div class="p1">
                    <p id="56">12. for (<i>i</i>=1;<i>i</i>&lt;=<i>L</i>/2;<i>i</i>++)</p>
                </div>
                <div class="p1">
                    <p id="57">13.  <i>LLCS</i>=<i>LCS</i>(<i>Ctext</i>[<i>i</i>],<i>title</i>)</p>
                </div>
                <div class="p1">
                    <p id="58">14.  if (<i>LLCS</i>&gt;<i>δ</i><sub>3</sub>)</p>
                </div>
                <div class="p1">
                    <p id="59">15.  <i>start</i>=<i>i</i></p>
                </div>
                <div class="p1">
                    <p id="60">16.  break</p>
                </div>
                <div class="p1">
                    <p id="61">17.  else:</p>
                </div>
                <div class="p1">
                    <p id="62">18.  continue</p>
                </div>
                <div class="p1">
                    <p id="63">19. for (<i>i</i>=<i>L</i>;<i>i</i>&gt;<i>L</i>/2;<i>i</i>--)</p>
                </div>
                <div class="p1">
                    <p id="64">20.  <i>LLCS</i>=<i>LCS</i>(<i>Ctext</i>[<i>i</i>],<i>title</i>)</p>
                </div>
                <div class="p1">
                    <p id="65">21.  if (<i>LLCS</i>&gt;<i>δ</i><sub>3</sub>)</p>
                </div>
                <div class="p1">
                    <p id="66">22.  <i>end</i>=<i>i</i></p>
                </div>
                <div class="p1">
                    <p id="67">23.  break</p>
                </div>
                <div class="p1">
                    <p id="68">24.  else:</p>
                </div>
                <div class="p1">
                    <p id="69">25.  continue</p>
                </div>
                <div class="p1">
                    <p id="70">26. for <i>i</i> in <i>range</i>(<i>start</i>,<i>end</i>)</p>
                </div>
                <div class="p1">
                    <p id="71">27.  <i>Content</i>=<i>Contend</i>+<i>Ctext</i>[<i>i</i>]</p>
                </div>
                <div class="p1">
                    <p id="72">28. return <i>Content</i></p>
                </div>
                <h4 class="anchor-tag" id="73" name="73"><b>1.2 链接优先级算法</b></h4>
                <div class="p1">
                    <p id="74">主题相似度计算以Word2vec为基础,Word2vec词向量模型可以较好地表达不同词之间相似和类比关系。Mikolov等提出的Word2vec模型可以快速高效的训练词向量<citation id="166" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。其两个主要模型分别为Skip-Gram模型和连续词袋模型(Continuous Bag Of Words,CBOW),如图1所示。</p>
                </div>
                <div class="area_img" id="75">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909048_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 Word2vec词向量模型" src="Detail/GetImg?filename=images/JYRJ201909048_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 Word2vec词向量模型  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909048_075.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="76">维基百科是全球领先的基于网络的百科全书,其信息全面且准确,并且覆盖了不同的主题<citation id="167" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。为了提高语义相似度计算的准确度,选取最新中文维基百科语料库训练Word2vec词向量模型,用于主题相似度的计算。相关概念的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="77"><b>定义1</b> (主题) 主题可以描述为关键词集合<i>topic</i>={<i>key</i><sub>1</sub>:<i>α</i><sub>1</sub>,<i>key</i><sub>2</sub>:<i>α</i><sub>2</sub>,…,<i>key</i><sub><i>n</i></sub>:<i>α</i><sub><i>n</i></sub>},<i>key</i><sub><i>n</i></sub>表示主题的第<i>n</i>个关键词。为了增加主题表述的准确性,为主题词<i>key</i><sub><i>n</i></sub>设定合理的权重<i>α</i><sub><i>n</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="78"><b>定义2</b> (主题相关度) 主题相关度表示文本与主题的相关程度,公式如下:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>S</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>d</mi><mi>o</mi><mi>c</mi><mo>,</mo><mi>t</mi><mi>o</mi><mi>p</mi><mi>i</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mi>S</mi></mstyle><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>t</mi><mi>e</mi><mi>r</mi><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>t</mi><mi>o</mi><mi>p</mi><mi>i</mi><mi>c</mi><mo stretchy="false">)</mo><mo>×</mo><mi>β</mi><msub><mrow></mrow><mrow><mi>i</mi><mi>i</mi></mrow></msub></mtd></mtr><mtr><mtd><mi>S</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>t</mi><mi>e</mi><mi>r</mi><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>t</mi><mi>o</mi><mi>p</mi><mi>i</mi><mi>c</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mtext>c</mtext></mstyle><mtext>o</mtext><mtext>s</mtext><mo stretchy="false">(</mo><mi>t</mi><mi>e</mi><mi>r</mi><mi>m</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>k</mi><mi>e</mi><mi>y</mi><msub><mrow></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mi>α</mi><msub><mrow></mrow><mi>j</mi></msub></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">式中:<i>Sim</i>(<i>doc</i>,<i>topic</i>)为文本与主题的相关度,<i>doc</i>={<i>term</i><sub>1</sub>:<i>β</i><sub>1</sub>,<i>term</i><sub>2</sub>:<i>β</i><sub>2</sub>,…,<i>term</i><sub><i>m</i></sub>:<i>β</i><sub><i>m</i></sub>},<i>term</i><sub><i>i</i></sub>为文本<i>doc</i>中的第<i>i</i>个词项,<i>β</i><sub><i>i</i></sub>表示的是<i>term</i><sub><i>i</i></sub>的词频。<i>Sim</i>(<i>term</i><sub><i>i</i></sub>,<i>topic</i>)表示<i>term</i><sub><i>i</i></sub>与整个主题的相关度。cos(<i>term</i><sub><i>i</i></sub>,<i>key</i><sub><i>j</i></sub>)表示的是通过Word2vec计算得到的<i>term</i><sub><i>i</i></sub>和<i>key</i><sub><i>j</i></sub>之间的余弦相似度值。</p>
                </div>
                <div class="p1">
                    <p id="81"><b>定义3</b> (主题重要度) 主题重要度表示链接的重要度,公式如下:</p>
                </div>
                <div class="p1">
                    <p id="82" class="code-formula">
                        <mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><mi>R</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>-</mo><mi>λ</mi><mo stretchy="false">)</mo><mo>/</mo><mi>Ν</mi><mo>+</mo><mi>λ</mi><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi>C</mi><msub><mrow></mrow><mi>A</mi></msub></mrow></munder><mi>Ρ</mi></mstyle><mi>R</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>Ρ</mi><mi>R</mi><msub><mrow></mrow><mi>A</mi></msub><mo stretchy="false">(</mo><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>∈</mo><mi>L</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></munder><mi>S</mi></mstyle><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></mfrac><mi>Ρ</mi><mi>R</mi><mo stretchy="false">(</mo><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="83">式(3)是基于PageRank改进的模型<citation id="168" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。其中<i>PR</i>(<i>A</i>)为网页<i>A</i>的PageRank值,<i>PR</i><sub><i>A</i></sub>(<i>P</i><sub><i>i</i></sub>)为包含链接<i>A</i>的网页<i>P</i><sub><i>i</i></sub>传递给<i>A</i>的PageRank值,通过式(2)计算锚文本主题相关度进行分配。<i>L</i><sub><i>i</i></sub>为<i>P</i><sub><i>i</i></sub>中的链接,<i>Sim</i>(<i>j</i>)表示由式(2)求得的描述链接<i>j</i>的锚文本主题相关度。<i>C</i><sub><i>A</i></sub>表示所有指向<i>A</i>的网页。</p>
                </div>
                <div class="p1">
                    <p id="84">结合核心内容主题相关度以及链接的主题重要度计算链接优先级,具体算法如下:</p>
                </div>
                <div class="p1">
                    <p id="85"><i>priority</i>(<i>A</i>)=<i>μSim</i>(<i>A</i>)+(1-<i>μ</i>)<i>PR</i>(<i>A</i>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="86">式中:<i>priority</i>(<i>A</i>)为链接<i>A</i>的优先级,<i>Sim</i>(<i>A</i>)为<i>A</i>的核心内容文本的主题相关度,由式(2)求得。<i>PR</i>(<i>A</i>)为改进的PageRank值,通过式(3)求得。<i>μ</i>为权重系数,表示主题相关度和重要度的权重关系,取经验值为0.5。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag"><b>2 结合文本密度的聚焦爬虫算法</b></h3>
                <div class="p1">
                    <p id="88">TDSFC爬虫框架如图2所示。</p>
                </div>
                <div class="area_img" id="89">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909048_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 TDSFC框架图" src="Detail/GetImg?filename=images/JYRJ201909048_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 TDSFC框架图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909048_089.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="90">首先,初始化模块设定主题词<i>topic</i>和种子链接集<i>seeds</i>,将<i>seeds</i>置入等待队列,启动爬虫。</p>
                </div>
                <div class="p1">
                    <p id="91">其次,结合主题重要度提取链接集,使用搜索引擎扩展链接集。结合核心内容提取算法以及链接优先级算法对链接进行排序,引导爬虫抓取主题相关的网页。具体如算法2所示。</p>
                </div>
                <div class="p1">
                    <p id="92"><b>算法2</b> 结合文本密度的聚焦爬虫算法。</p>
                </div>
                <div class="p1">
                    <p id="93">1. 输入:<i>topic</i>,<i>seeds</i></p>
                </div>
                <div class="p1">
                    <p id="94">2. 输出:<i>out</i>_<i>list</i></p>
                </div>
                <div class="p1">
                    <p id="95">3. <i>Waitqueue</i>=[],<i>out</i>_<i>list</i>=[]</p>
                </div>
                <div class="p1">
                    <p id="96">4. <i>Waitqueue</i>.<i>add</i>(<i>seeds</i>)</p>
                </div>
                <div class="p1">
                    <p id="97">5. while(Failure to reach termination conditions)</p>
                </div>
                <div class="p1">
                    <p id="98">6.  <i>url</i>_<i>list</i>=<i>extract</i>_<i>surl</i>(<i>Waitqueue</i>)</p>
                </div>
                <div class="p1">
                    <p id="99">7.  for <i>url</i> in <i>url</i>_<i>list</i>:</p>
                </div>
                <div class="p1">
                    <p id="100">8.  <i>i</i>_<i>value</i>=<i>impor</i> tan <i>ce</i>(<i>url</i>)</p>
                </div>
                <div class="p1">
                    <p id="101">9.  <i>i</i>_<i>value</i>_<i>list</i>.<i>append</i>(<i>i</i>_<i>value</i>)</p>
                </div>
                <div class="p1">
                    <p id="102">10. end for</p>
                </div>
                <div class="p1">
                    <p id="103">11. <i>r</i> 0=<i>sum</i>(<i>i</i>_<i>value</i>_<i>list</i>)/<i>len</i>(<i>i</i>_<i>value</i>_<i>list</i>)</p>
                </div>
                <div class="p1">
                    <p id="104">12. <i>url</i>_<i>list</i>1=<i>select</i>_<i>url</i>1(<i>url</i>_<i>list</i>,<i>r</i> 0)</p>
                </div>
                <div class="p1">
                    <p id="105">13. <i>search</i>_<i>key</i>=<i>random</i>(<i>topic</i>)</p>
                </div>
                <div class="p1">
                    <p id="106">14. <i>purl</i>_<i>list</i>=<i>extract</i>_<i>purl</i>(<i>search</i>_<i>key</i>)</p>
                </div>
                <div class="p1">
                    <p id="107">15. for <i>url</i> in <i>purl</i>_<i>list</i>:</p>
                </div>
                <div class="p1">
                    <p id="108">16.  <i>s</i>_<i>value</i>=<i>sim</i>(<i>ancor</i>(<i>url</i>),<i>topic</i>)</p>
                </div>
                <div class="p1">
                    <p id="109">17.  <i>s</i>_<i>value</i>_<i>list</i>.<i>append</i>(<i>s</i>_<i>value</i>)</p>
                </div>
                <div class="p1">
                    <p id="110">18. end for</p>
                </div>
                <div class="p1">
                    <p id="111">19. <i>url</i>_<i>list</i>2=<i>select</i>_<i>url</i>2(<i>s</i>_<i>value</i>_<i>list</i>)</p>
                </div>
                <div class="p1">
                    <p id="112">20. <i>url</i>_<i>list</i>3=<i>dlt</i>_<i>dump</i>(<i>url</i>)</p>
                </div>
                <div class="p1">
                    <p id="113">21. for <i>url</i> in <i>url</i>_<i>list</i>3:</p>
                </div>
                <div class="p1">
                    <p id="114">22.  <i>priority</i>=<i>calcu</i>_<i>priority</i>(<i>url</i>)</p>
                </div>
                <div class="p1">
                    <p id="115">23.  <i>priority</i>_<i>list</i>.<i>append</i>(<i>priority</i>)</p>
                </div>
                <div class="p1">
                    <p id="116">24.  end for</p>
                </div>
                <div class="p1">
                    <p id="117">25.  <i>t</i> arg <i>et</i>_<i>url</i>=<i>select</i>(<i>priority</i>_<i>list</i>)</p>
                </div>
                <div class="p1">
                    <p id="118">26.  <i>out</i>_<i>list</i>.<i>add</i>(<i>t</i> arg <i>et</i>_<i>urls</i>)</p>
                </div>
                <div class="p1">
                    <p id="119">27.  <i>Waitqueue</i>.<i>add</i>(<i>t</i> arg <i>et</i>_<i>urls</i>)</p>
                </div>
                <div class="p1">
                    <p id="120">28. end while</p>
                </div>
                <div class="p1">
                    <p id="121">29. return <i>out</i>_<i>list</i></p>
                </div>
                <div class="p1">
                    <p id="122">爬虫通过遍历等待队列<i>Waitqueue</i>中的链接,使用<i>extract</i>_<i>surl</i>提取链接置入<i>url</i>_<i>list</i>。构建有向图,求得每一个链接的主题重要度<i>i</i>_<i>value</i>,设定阈值<i>r</i>0,提取主题重要度高的链接置入<i>url</i>_<i>list</i>1中。从<i>topic</i>中随机选取词项<i>search</i>_<i>key</i>作为搜索关键词,调用函数<i>extract</i>_<i>purl</i>使用搜索引擎检索链接,计算链接的锚文本主题相关度,提取相关度高的前20%个链接扩展链接集置入<i>url</i>_<i>list</i>2。通过<i>dlt</i>_<i>dump</i>函数对<i>url</i>_<i>list</i>1和<i>url</i>_<i>list</i>2的链接去重存入<i>url</i>_<i>list</i>3中。</p>
                </div>
                <div class="p1">
                    <p id="123">链接优先级计算模块,通过遍历<i>url</i>_<i>list</i>3中的每一条链接,结合核心内容提取算法计算每一条链接的核心内容主题相关度和主题重要度。结合主题相关度和重要度计算每一条链接的优先级<i>priority</i>,提取优先级高的前20%的链接置入输出链接集<i>out</i>_<i>list</i>以及<i>Waitqueue</i>中,反复执行,直到满足终止条件为止。</p>
                </div>
                <h3 id="124" name="124" class="anchor-tag"><b>3 实验和分析</b></h3>
                <h4 class="anchor-tag" id="125" name="125"><b>3.1 实验设定</b></h4>
                <div class="p1">
                    <p id="126">对核心内容提取算法参数进行设定,选择{<i>δ</i><sub>1</sub>|0&lt;<i>δ</i><sub>1</sub>&lt;10,<i>δ</i><sub>1</sub>∈<i>N</i>},{<i>δ</i><sub>2</sub>|0&lt;<i>δ</i><sub>2</sub>&lt;10,<i>δ</i><sub>2</sub>∈<i>N</i>} ,{<i>δ</i><sub>3</sub>|0&lt;<i>δ</i><sub>3</sub>&lt;10,<i>δ</i><sub>3</sub>∈<i>N</i>},其中<i>N</i>为自然数。取最优配置为<i>δ</i><sub>1</sub>=4,<i>δ</i><sub>2</sub>=1,<i>δ</i><sub>3</sub>=2。为了降低主题漂移和主题误判对主题相似度计算造成的负面影响,采用专家确定主题词集的方法<citation id="169" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。实验选取“美食”、“小吃”、“大排档”、“美味”、“鲁菜”、“甜点”等六个词语初始化主题词集。选取10个与主题高度相关的URL作为种子URL,启动爬虫。</p>
                </div>
                <div class="p1">
                    <p id="127">设定两组实验,第一组实验的目的是验证核心内容提取算法参数<i>δ</i><sub>1</sub>、<i>δ</i><sub>2</sub>、<i>δ</i><sub>3</sub>选择的合理性以及核心内容提取算法的性能。第二组实验的目的是验证TDSFC在爬取准确度和效率方面的性能,通过设置对照试验与BFC和VSMC以及SSVSMC进行对比。</p>
                </div>
                <h4 class="anchor-tag" id="128" name="128"><b>3.2 实验结果和分析</b></h4>
                <div class="p1">
                    <p id="129">第一组实验,选取种子URL启动爬虫。随机选取1 000个链接,调用Beautiful Soup模块解析每一个网页,调用Regular Expression模块对HTML文档进行处理,剔除HTML文档中的标签、注释、空格和特殊字符等内容,提取纯文本行。记录每一个网页通过核心内容提取算法提取的核心内容文本行数以及提取的总文本行数。</p>
                </div>
                <div class="p1">
                    <p id="130">衡量网页核心内容提取算法的指标为网页核心内容行提取的回归率<i>RC</i>(<i>d</i>)以及准确率<i>PC</i>(<i>d</i>),公式如下:</p>
                </div>
                <div class="p1">
                    <p id="131"><i>RC</i>(<i>d</i>)=<i>MC</i>(<i>d</i>)/<i>NC</i>(<i>d</i>)      (5)</p>
                </div>
                <div class="p1">
                    <p id="132"><i>PC</i>(<i>d</i>)=<i>MC</i>(<i>d</i>)/<i>AC</i>(<i>d</i>)      (6)</p>
                </div>
                <div class="p1">
                    <p id="133">式中:<i>MC</i>(<i>d</i>)、<i>NC</i>(<i>d</i>)、<i>AC</i>(<i>d</i>)分别为从网页<i>d</i>中提取的核心内容文本行数、网页<i>d</i>中核心内容文本行总数、从网页<i>d</i>中提取的文本行总数。</p>
                </div>
                <div class="p1">
                    <p id="134">充分考虑<i>RC</i>(<i>d</i>)、<i>PC</i>(<i>d</i>)构造<i>F</i><sub><i>d</i></sub>值,公式如下:</p>
                </div>
                <div class="p1">
                    <p id="135"><mathml id="136"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mi>d</mi></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mo>×</mo><mi>R</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>×</mo><mi>Ρ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><mrow><mi>R</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>+</mo><mi>Ρ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="137">通过固定<i>δ</i><sub>1</sub>、<i>δ</i><sub>2</sub>的值,改变<i>δ</i><sub>3</sub>的值,分析参数<i>δ</i><sub>3</sub>取值选择的合理性,取测试链接集中所有网页<i>F</i><sub><i>d</i></sub>值的均值<mathml id="138"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>F</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mi>i</mi><mi>n</mi></munderover><mi>F</mi></mstyle><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">(</mo><mi>p</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mi>n</mi></mfrac></mrow></math></mathml>作为指标。同理,分析<i>δ</i><sub>1</sub>、<i>δ</i><sub>2</sub>参数设置的合理性。最终,取最优参数<i>δ</i><sub>1</sub>=4,<i>δ</i><sub>2</sub>=1,<i>δ</i><sub>3</sub>=2。实验结果如图3所示。</p>
                </div>
                <div class="area_img" id="139">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909048_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 δ1、δ2、δ3参数对比实验" src="Detail/GetImg?filename=images/JYRJ201909048_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 <i>δ</i><sub>1</sub>、<i>δ</i><sub>2</sub>、<i>δ</i><sub>3</sub>参数对比实验  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909048_139.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="140">取最优参数,启动爬虫。分别使用核心内容提取算法、HTML行文本特征提取算法、有监督的核心内容提取算法对随机抽取的500个网页提取核心内容文本。统计三种方法提取的每一个网页核心内容的<i>F</i><sub><i>d</i></sub>值,记为<i>F</i><sub><i>d</i>1</sub>、<i>F</i><sub><i>d</i>2</sub>、<i>F</i><sub><i>d</i>3</sub>。最终求得由三种方法提取的网页核心内容<i>F</i><sub><i>d</i></sub>均值记为<i>AF</i><sub>1</sub>、<i>AF</i><sub>2</sub>、<i>AF</i><sub>3</sub>。部分实验结果如表1所示。</p>
                </div>
                <div class="area_img" id="141">
                    <p class="img_tit"><b>表1 核心内容提取算法性能测试</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="141" border="1"><tr><td><br />Web Page</td><td><i>F</i><sub><i>d</i>1</sub></td><td><i>F</i><sub><i>d</i>2</sub></td><td><i>F</i><sub><i>d</i>3</sub></td></tr><tr><td><br />www.ttmeishi.com</td><td>0.951</td><td>0.942</td><td>0.931</td></tr><tr><td><br />chihe.sohu.com</td><td>0.963</td><td>0.952</td><td>0.945</td></tr><tr><td><br />cd.qq.com/ieat</td><td>0.955</td><td>0.943</td><td>0.927</td></tr><tr><td><br />www.haodou.com</td><td>0.981</td><td>0.963</td><td>0.942</td></tr><tr><td><br />travel.163.com/food</td><td>0.955</td><td>0.933</td><td>0.924</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="142">计算随机抽取的500个网页的<i>F</i><sub><i>d</i></sub>均值<i>AF</i><sub>1</sub>=0.956,<i>AF</i><sub>2</sub>=0.938, <i>AF</i><sub>3</sub>=0.925。从而验证了核心内容提取算法的有效性,可以准确提取到网页核心内容用于主题相似度计算。</p>
                </div>
                <div class="p1">
                    <p id="143">第二组实验,分别使用获取率<i>HR</i>和平均相似度<i>AS</i>验证爬虫的爬取效率和准确度。其中<i>HR</i>为爬取主题相关网页的数量占爬取网页总量的比率,代表爬取效率<citation id="170" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。<i>AS</i>为对所有爬取到的主题相关网页计算的主题相关度均值,代表爬取准确度<citation id="171" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。具体算法如下所示:</p>
                </div>
                <div class="p1">
                    <p id="144"><mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>S</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>S</mi></mstyle><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>C</mi><msub><mrow></mrow><mi>i</mi></msub><mo>,</mo><mi>t</mi><mi>o</mi><mi>p</mi><mi>i</mi><mi>c</mi><mo stretchy="false">)</mo></mrow></math></mathml>      (8)</p>
                </div>
                <div class="p1">
                    <p id="146"><i>HR</i>=<i>n</i>/<i>N</i>      (9)</p>
                </div>
                <div class="p1">
                    <p id="147">式中:<i>n</i>为主题相关网页的数量,<i>Sim</i>(<i>C</i><sub><i>i</i></sub>,<i>topic</i>)为通过式(2)计算的主题相关网页<i>P</i><sub><i>i</i></sub>使用算法1提取的核心内容文本<i>C</i><sub><i>i</i></sub>与主题<i>topic</i>的相关度,<i>N</i>为抓取的网页总数量。</p>
                </div>
                <div class="p1">
                    <p id="148">根据表2所示的部分获取率对比实验数据对TDSFC的爬取效率进行分析。如图4所示,由于启动爬虫设定的种子链接集与主题高度相关,因此,抓取网页数量较少时,各爬虫获取率随着爬取网页数量的增多而持续上升。但是,随着抓取网页数量的增多,大量不相关网页的出现,导致各爬虫获取率下降。由于TDSFC采用了核心内容提取算法,通过使用标题结合LCS算法准确定位网页核心内容起始和终止位置,过滤网页的噪声信息,准确地提取到网页核心内容,提高了抓取网页的效率。此外,通过结合主题词使用搜索引擎扩展链接集,将主题相关的网页扩充至链接集,优化了聚焦爬虫的全局搜索性能使得获取率下降速率明显低于SSVSMC、VSMC以及BFC,抓取相同数量的网页,TDSFC爬取效率更高。</p>
                </div>
                <div class="area_img" id="149">
                    <p class="img_tit"><b>表2 部分获取率对比实验数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="149" border="1"><tr><td><i>N</i></td><td>BFC</td><td>VSMC</td><td>SSVSMC</td><td>TDSFC</td></tr><tr><td><br />1 000</td><td>0.260</td><td>0.475</td><td>0.296</td><td>0.735</td></tr><tr><td><br />2 000</td><td>0.174</td><td>0.390</td><td>0.272</td><td>0.680</td></tr><tr><td><br />3 000</td><td>0.167</td><td>0.329</td><td>0.310</td><td>0.621</td></tr><tr><td><br />4 000</td><td>0.124</td><td>0.256</td><td>0.296</td><td>0.573</td></tr><tr><td><br />5 000</td><td>0.102</td><td>0.216</td><td>0.303</td><td>0.557</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="150">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909048_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 爬虫获取率对比图" src="Detail/GetImg?filename=images/JYRJ201909048_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 爬虫获取率对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909048_150.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="151">通过对表2数据以及图4分析可知,随着爬取网页数量的增多,TDSFC获取率较其他爬虫优势会更加明显,爬取效率更高。</p>
                </div>
                <div class="p1">
                    <p id="152">根据表3所示的部分平均相似度对比实验数据分析TDSFC爬取准确度,如图5所示,由于BFC采用广度优先策略抓取网页,缺少主题相关度算法使得爬虫无法准确识别网页的主题相关性,相较于其他爬虫,BFC抓取的主题相关网页平均相似度较低。由于TDSFC采用了结合主题相关度和主题重要度模型来引导爬虫抓取主题相关的网页。此外,通过核心内容提取算法准确定位网页核心内容的起始和终止位置,对网页噪声信息进行过滤能够准确抓取网页核心内容,提高了主题相似度计算的准确度,进而引导爬虫抓取更多主题相关的网页。因此,相较于SSVSMC以及VSMC,TDSFC抓取的网页平均相似度较高。</p>
                </div>
                <div class="area_img" id="153">
                    <p class="img_tit"><b>表3 部分平均相似度对比实验数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="153" border="1"><tr><td><i>N</i></td><td>BFC</td><td>VSMC</td><td>SSVSMC</td><td>TDSFC</td></tr><tr><td><br />1 000</td><td>0.782</td><td>0.914</td><td>0.922</td><td>0.939</td></tr><tr><td><br />2 000</td><td>0.781</td><td>0.901</td><td>0.909</td><td>0.922</td></tr><tr><td><br />3 000</td><td>0.784</td><td>0.932</td><td>0.901</td><td>0.929</td></tr><tr><td><br />4 000</td><td>0.781</td><td>0.931</td><td>0.906</td><td>0.948</td></tr><tr><td><br />5 000</td><td>0.777</td><td>0.928</td><td>0.901</td><td>0.944</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="154">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909048_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 聚焦爬虫平均相似度对比图" src="Detail/GetImg?filename=images/JYRJ201909048_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 聚焦爬虫平均相似度对比图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909048_154.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="155">由于爬取网页数量有限,TDSFC、SSVSMC以及VSMC的平均相似度数值上差异并不明显,但是通过对表3数据以及图5分析可知,随着爬取网数量的增多,TDSFC爬取准确度优势会更明显。</p>
                </div>
                <h3 id="156" name="156" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="157">爬虫的爬取准确度和效率是衡量爬虫性能的重要指标。提出的结合文本密度的语义聚焦爬虫方法,通过使用网页标题结合LCS算法提取网页核心内容,提高了主题相似度计算的准确度。考虑词项语义信息引入主题相关度计算模型,结合主题重要度计算链接优先级,优化链接的提取。此外,为了提高全局搜索性能,结合关键词使用搜索引擎扩展链接集。结果显示,TDSFC能够提高爬虫的爬取准确度和爬取效率。</p>
                </div>
                <div class="p1">
                    <p id="158">TDSFC虽能通过核心文本内容提取算法准确提取网页核心内容文本,但是整个爬虫仍然需要不断处理大量文本内容,爬取效率有待提高。下一步考虑提取网页文本内容特征用于主题相似度计算,进一步优化主题相似度计算模型。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A distinctive approach to obtain higher page rank through search engine optimization">

                                <b>[1]</b> Khan M N A,Mahmood A.A distinctive approach to obtain higher page rank through search engine optimization[J].Sādhanā,2018,43(3):43.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GWDZ201506009&amp;v=MDMxMzQ5RmJZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYnpPSWpyUGRMRzRIOVRNcVk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 肖江,季节.基于Heritrix的主题爬虫在互联网舆情系统中应用[J].电子设计工程,2015,23(6):30-32.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201804010&amp;v=MTQxMzR6cXFCdEdGckNVUjdxZlp1WnRGeWprVWJ6T0x6VFpaTEc0SDluTXE0OUVaSVFLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 费晨杰,刘柏嵩.基于LDA扩展主题词库的主题爬虫研究[J].计算机应用与软件,2018,35(4):49-54.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESEAC9F67ECEA8B4CD0793697776EC7809&amp;v=MjU1ODZpNnFZZ3dGNTUrQkE0OXZHSVQ3VForVG5ibHF4VXpETUdUVGJxV0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMbTl3NjQ9TmlmT2ZjYkpiZA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Seyfi A.A Focused Crawler Combinatory Link and Content Model Based on T-Graph Principles[J].Computer Standards &amp; Interfaces,2016,43:1-11.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES1B022DC49F5A1077A33ABB0CB60F9C97&amp;v=MTc3OTV6ZWNTZE5yT1lDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4TG05dzY0PU5pZk9mYkxLSHRQTzIveEJiWjBLZlgwNXlCRmk2VHdNT2czaTMyQQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Du Y,Liu W,Lv X,et al.An improved focused crawler based on Semantic Similarity Vector Space Model[J].Applied Soft Computing,2015,36(C):392-407.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJIG&amp;filename=SJIG5A7621198581E9340886AC2096F92D64&amp;v=MjIzOTFnckJzekQ3dVdNYnliQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeExtOXc2ND1OaWZDYWJiSkdkZk9ybzVNYk80SERRa3d6QklUNGpkN09Reg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Tarik B,Mahmoud D D,Zakaria E.Classifying Web Pages by Aimed Nation Using Machine Learning[J].International Journal of Organizational and Collective Intelligence,2017,7(1):20-35.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES9264F61D30D2EB75BCC1E7B4D361D6DB&amp;v=Mjk2NTBOaG1VeDhQWGlRcUdZMmY3UGdRODd0Q09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeExtOXc2ND1OaWZPZmJxNkdOVzZxWTR4Wit0N0RnbEx5Qg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Gali N,Mariescu-Istodor R,Fränti P.Using linguistic features to automatically extract web page title[J].Expert Systems with Applications,2017,79:296-312.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201801017&amp;v=MDE0MTZxQnRHRnJDVVI3cWZadVp0Rnlqa1Viek9MelRaWkxHNEg5bk1ybzlFWTRRS0RIODR2UjRUNmo1NE8zenE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 王飞,谭新.一种基于Word2vec的训练效果优化策略研究[J].计算机应用与软件,2018,35(1):97-102,174.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Short text classification based on Wikipedia and Word2vec">

                                <b>[9]</b> Wensen L,Zewen C,Jun W,et al.Short text classification based on Wikipedia and Word2vec[C]//IEEE International Conference on Computer &amp; Communications.IEEE,2017.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SIPD&amp;filename=SIPDA87076D5CD63E89DAF51A30785F6B99D&amp;v=MTczNDhGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMbTl3NjQ9TmlUYmFzS3dHZEhMcWZ0QUY1OEpEd2t4eG1KaW5EcDhPWHppcXhvd0Q3VG1UTFByQ09Odg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Putri I,Kusumaningrum R.Latent Dirichlet Allocation(LDA) for Sentiment Analysis Toward Tourism Review in Indonesia[J].Journal of Physics:Conference Series,2017,801:012073.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Designing focused crawler based on improved genetic algorithm">

                                <b>[11]</b> Yan W,Pan L.Designing focused crawler based on improved genetic algorithm[C]//Tenth International Conference on Advanced Computational Intelligence.IEEE,2018.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201909048" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909048&amp;v=MjYzNzdCdEdGckNVUjdxZlp1WnRGeWprVWJ6T0x6VFpaTEc0SDlqTXBvOUJiSVFLREg4NHZSNFQ2ajU0TzN6cXE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
