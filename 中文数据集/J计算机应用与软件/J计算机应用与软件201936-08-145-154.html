<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135610656877500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201908027%26RESULT%3d1%26SIGN%3dLGARHtLpOU%252fv6MTTG%252bb1jGd7up8%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908027&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201908027&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908027&amp;v=MjA0Njc0SDlqTXA0OUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptVnJ6TUx6VFpaTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#57" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#62" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#70" data-title="&lt;b&gt;2 模 型&lt;/b&gt; "><b>2 模 型</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#74" data-title="&lt;b&gt;2.1 词嵌入层&lt;/b&gt;"><b>2.1 词嵌入层</b></a></li>
                                                <li><a href="#76" data-title="&lt;b&gt;2.2 单词层面:带门机制的卷积层&lt;/b&gt;"><b>2.2 单词层面:带门机制的卷积层</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;2.3 评论层面:场景上下文感知的评论建模&lt;/b&gt;"><b>2.3 评论层面:场景上下文感知的评论建模</b></a></li>
                                                <li><a href="#164" data-title="&lt;b&gt;2.4 预测层&lt;/b&gt;"><b>2.4 预测层</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#177" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#183" data-title="&lt;b&gt;3.1 数据集&lt;/b&gt;"><b>3.1 数据集</b></a></li>
                                                <li><a href="#186" data-title="&lt;b&gt;3.2 基 线&lt;/b&gt;"><b>3.2 基 线</b></a></li>
                                                <li><a href="#193" data-title="&lt;b&gt;3.3 实验设置&lt;/b&gt;"><b>3.3 实验设置</b></a></li>
                                                <li><a href="#209" data-title="&lt;b&gt;3.4 实验结果&lt;/b&gt;"><b>3.4 实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#230" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#72" data-title="图1 SCRM整体结构图">图1 SCRM整体结构图</a></li>
                                                <li><a href="#78" data-title="图2 单词层面建模图">图2 单词层面建模图</a></li>
                                                <li><a href="#107" data-title="图3 键值对记忆网络查询图">图3 键值对记忆网络查询图</a></li>
                                                <li><a href="#185" data-title="&lt;b&gt;表1 四个数据集的统计数据&lt;/b&gt;"><b>表1 四个数据集的统计数据</b></a></li>
                                                <li><a href="#212" data-title="&lt;b&gt;表2 模型总体表现对比 (统计显著性&lt;i&gt;p&lt;/i&gt;&amp;lt;0.01&lt;/b&gt;) "><b>表2 模型总体表现对比 (统计显著性<i>p</i>&lt;0.01</b>) </a></li>
                                                <li><a href="#213" data-title="&lt;b&gt;表3 SCRM性能提升百分比&lt;/b&gt;"><b>表3 SCRM性能提升百分比</b></a></li>
                                                <li><a href="#218" data-title="&lt;b&gt;表4&lt;/b&gt; “&lt;b&gt;单词”层面表现对比&lt;/b&gt;"><b>表4</b> “<b>单词”层面表现对比</b></a></li>
                                                <li><a href="#223" data-title="&lt;b&gt;表5&lt;/b&gt; “&lt;b&gt;评论”层面表现对比&lt;/b&gt;"><b>表5</b> “<b>评论”层面表现对比</b></a></li>
                                                <li><a href="#228" data-title="&lt;b&gt;表6 单层建模与层次化建模表现对比&lt;/b&gt;"><b>表6 单层建模与层次化建模表现对比</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="413">


                                    <a id="bibliography_1" title="Seo S, Huang J, Yang H, et al.Interpretable convolutional neural networks with dual local and global attention for review rating prediction[C]//Proceedings of the Eleventh ACM Conference on Recommender Systems.ACM, 2017:297-305." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction">
                                        <b>[1]</b>
                                        Seo S, Huang J, Yang H, et al.Interpretable convolutional neural networks with dual local and global attention for review rating prediction[C]//Proceedings of the Eleventh ACM Conference on Recommender Systems.ACM, 2017:297-305.
                                    </a>
                                </li>
                                <li id="415">


                                    <a id="bibliography_2" title="Chen C, Zhang M, Liu Y, et al.Neural attentional rating regression with review-level explanations[C]//Proceedings of the 2018 World Wide Web Conference on World Wide Web.International World Wide Web Conferences Steering Committee, 2018:1583-1592." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Neural attentional rating regression with review-level explanations">
                                        <b>[2]</b>
                                        Chen C, Zhang M, Liu Y, et al.Neural attentional rating regression with review-level explanations[C]//Proceedings of the 2018 World Wide Web Conference on World Wide Web.International World Wide Web Conferences Steering Committee, 2018:1583-1592.
                                    </a>
                                </li>
                                <li id="417">


                                    <a id="bibliography_3" title="Zheng L, Noroozi V, Yu P S.Joint deep modeling of users and items using reviews for recommendation[C]//Proceedings of the Tenth ACM International Conference on Web Search and Data Mining.ACM, 2017:425-434." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Joint deep modeling of users and items using reviews for recommendation">
                                        <b>[3]</b>
                                        Zheng L, Noroozi V, Yu P S.Joint deep modeling of users and items using reviews for recommendation[C]//Proceedings of the Tenth ACM International Conference on Web Search and Data Mining.ACM, 2017:425-434.
                                    </a>
                                </li>
                                <li id="419">


                                    <a id="bibliography_4" title="Koren Y, Bell R, Volinsky C.Matrix factorization techniques for recommender systems[J].Computer, 2009 (8) :30-37." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Matrix Factorization Techniques for Recommender Systems">
                                        <b>[4]</b>
                                        Koren Y, Bell R, Volinsky C.Matrix factorization techniques for recommender systems[J].Computer, 2009 (8) :30-37.
                                    </a>
                                </li>
                                <li id="421">


                                    <a id="bibliography_5" title="Rendle S.Factorization machines[C]//Proceedings of the2010 IEEE International Conference on Data Mining.IEEE, 2010:995-1000." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Factorization Machines">
                                        <b>[5]</b>
                                        Rendle S.Factorization machines[C]//Proceedings of the2010 IEEE International Conference on Data Mining.IEEE, 2010:995-1000.
                                    </a>
                                </li>
                                <li id="423">


                                    <a id="bibliography_6" title="Dauphin Y N, Fan A, Auli M, et al.Language modeling with gated convolutional networks[EB].ar Xiv preprint ar X-iv:1612.08083, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Language modeling with gated convolutional networks[EB]">
                                        <b>[6]</b>
                                        Dauphin Y N, Fan A, Auli M, et al.Language modeling with gated convolutional networks[EB].ar Xiv preprint ar X-iv:1612.08083, 2016.
                                    </a>
                                </li>
                                <li id="425">


                                    <a id="bibliography_7" title="Kim Y.Convolutional neural networks for sentence classification[EB].ar Xiv preprint ar Xiv:1408.5882, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification[EB]">
                                        <b>[7]</b>
                                        Kim Y.Convolutional neural networks for sentence classification[EB].ar Xiv preprint ar Xiv:1408.5882, 2014.
                                    </a>
                                </li>
                                <li id="427">


                                    <a id="bibliography_8" title="Kalchbrenner N, Grefenstette E, Blunsom P.A convolutional neural network for modelling sentences[EB].ar Xiv preprint ar Xiv:1404.2188, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network for modelling sentences[EB]">
                                        <b>[8]</b>
                                        Kalchbrenner N, Grefenstette E, Blunsom P.A convolutional neural network for modelling sentences[EB].ar Xiv preprint ar Xiv:1404.2188, 2014.
                                    </a>
                                </li>
                                <li id="429">


                                    <a id="bibliography_9" title="Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural computation, 1997, 9 (8) :1735-1780." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=Mjk2NTU5SHRqTXFvOUZaT29MRFhVeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlGMFJhUlU9TmlmSlpiSw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                        Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural computation, 1997, 9 (8) :1735-1780.
                                    </a>
                                </li>
                                <li id="431">


                                    <a id="bibliography_10" title="van den Oord A, Kalchbrenner N, Espeholt L, et al.Conditional image generation with pixelcnn decoders[C]//Advances in Neural Information Processing Systems.2016:4790-4798." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Conditional image generation with pixelCNN decoders">
                                        <b>[10]</b>
                                        van den Oord A, Kalchbrenner N, Espeholt L, et al.Conditional image generation with pixelcnn decoders[C]//Advances in Neural Information Processing Systems.2016:4790-4798.
                                    </a>
                                </li>
                                <li id="433">


                                    <a id="bibliography_11" title="Gehring J, Auli M, Grangier D, et al.Convolutional sequence to sequence learning[EB].ar Xiv preprint ar Xiv:1705.03122, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional sequence to sequence learning[EB]">
                                        <b>[11]</b>
                                        Gehring J, Auli M, Grangier D, et al.Convolutional sequence to sequence learning[EB].ar Xiv preprint ar Xiv:1705.03122, 2017.
                                    </a>
                                </li>
                                <li id="435">


                                    <a id="bibliography_12" title="Collobert R, Weston J, Bottou L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12:2493-2537." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Natural language processing (almost) from scratch">
                                        <b>[12]</b>
                                        Collobert R, Weston J, Bottou L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12:2493-2537.
                                    </a>
                                </li>
                                <li id="437">


                                    <a id="bibliography_13" title="Miller A, Fisch A, Dodge J, et al.Key-value memory networks for directly reading documents[EB].ar Xiv preprint ar Xiv:1606.03126, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Key-value memory networks for directly reading documents[EB]">
                                        <b>[13]</b>
                                        Miller A, Fisch A, Dodge J, et al.Key-value memory networks for directly reading documents[EB].ar Xiv preprint ar Xiv:1606.03126, 2016.
                                    </a>
                                </li>
                                <li id="439">


                                    <a id="bibliography_14" title="Vaswani A, Shazeer N, Parmar N, et al.Attention is all you need[C]//Advances in Neural Information Processing Systems.2017:5998-6008." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Attention is all you need">
                                        <b>[14]</b>
                                        Vaswani A, Shazeer N, Parmar N, et al.Attention is all you need[C]//Advances in Neural Information Processing Systems.2017:5998-6008.
                                    </a>
                                </li>
                                <li id="441">


                                    <a id="bibliography_15" title="Xiong C, Callan J, Liu T Y.Learning to attend and to rank with word-entity duets[C]//Proceedings of the annual international ACM SIGIR conference on research and development in information retrieval.2017, 763:772." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning to attend and to rank with word-entity duets">
                                        <b>[15]</b>
                                        Xiong C, Callan J, Liu T Y.Learning to attend and to rank with word-entity duets[C]//Proceedings of the annual international ACM SIGIR conference on research and development in information retrieval.2017, 763:772.
                                    </a>
                                </li>
                                <li id="443">


                                    <a id="bibliography_16" title="Lin M, Chen Q, Yan S.Network in network[EB].ar Xiv preprint ar Xiv:1312.4400, 2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Network in network[EB]">
                                        <b>[16]</b>
                                        Lin M, Chen Q, Yan S.Network in network[EB].ar Xiv preprint ar Xiv:1312.4400, 2013.
                                    </a>
                                </li>
                                <li id="445">


                                    <a id="bibliography_17" title="He R, McAuley J.Ups and downs:Modeling the visual evolution of fashion trends with one-class collaborative filtering[C]//Proceedings of the 25th international conference on world wide web.International World Wide Web Conferences Steering Committee, 2016:507-517." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ups and downs:Modeling the visual evolution of fashion trends with one-class collaborative filtering">
                                        <b>[17]</b>
                                        He R, McAuley J.Ups and downs:Modeling the visual evolution of fashion trends with one-class collaborative filtering[C]//Proceedings of the 25th international conference on world wide web.International World Wide Web Conferences Steering Committee, 2016:507-517.
                                    </a>
                                </li>
                                <li id="447">


                                    <a id="bibliography_18" title="Kingma D P, Ba J.Adam:A method for stochastic optimization[EB].ar Xiv preprint ar Xiv:1412.6980, 2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization[EB]">
                                        <b>[18]</b>
                                        Kingma D P, Ba J.Adam:A method for stochastic optimization[EB].ar Xiv preprint ar Xiv:1412.6980, 2014.
                                    </a>
                                </li>
                                <li id="449">


                                    <a id="bibliography_19" title="Pennington J, Socher R, Manning C.Glove:Global vectors for word representation[C]//Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) .2014:1532-1543." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">
                                        <b>[19]</b>
                                        Pennington J, Socher R, Manning C.Glove:Global vectors for word representation[C]//Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) .2014:1532-1543.
                                    </a>
                                </li>
                                <li id="451">


                                    <a id="bibliography_20" >
                                        <b>[20]</b>
                                    Blei D M, Ng A Y, Jordan M I.Latent dirichlet allocation[J].Journal of machine Learning research, 2003, 3:993-1022.</a>
                                </li>
                                <li id="453">


                                    <a id="bibliography_21" title="McAuley J, Leskovec J.Hidden factors and hidden topics:understanding rating dimensions with review text[C]//Proceedings of the 7th ACM conference on Recommender systems.ACM, 2013:165-172." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Hidden factors and hidden topics:understanding rating dimensions with review text">
                                        <b>[21]</b>
                                        McAuley J, Leskovec J.Hidden factors and hidden topics:understanding rating dimensions with review text[C]//Proceedings of the 7th ACM conference on Recommender systems.ACM, 2013:165-172.
                                    </a>
                                </li>
                                <li id="455">


                                    <a id="bibliography_22" title="Ling G, Lyu M R, King I.Ratings meet reviews, a combined approach to recommend[C]//Proceedings of the 8th ACM Conference on Recommender systems.ACM, 2014:105-112." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ratings meet reviews, a combined approach to recommend">
                                        <b>[22]</b>
                                        Ling G, Lyu M R, King I.Ratings meet reviews, a combined approach to recommend[C]//Proceedings of the 8th ACM Conference on Recommender systems.ACM, 2014:105-112.
                                    </a>
                                </li>
                                <li id="457">


                                    <a id="bibliography_23" title="Zhang Y, Lai G, Zhang M, et al.Explicit factor models for explainable recommendation based on phrase-level sentiment analysis[C]//Proceedings of the 37th international ACM SI-GIR conference on Research&amp;amp;development in information retrieval.ACM, 2014:83-92." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Explicit factor models for explainable recommendation based on phrase-level sentiment analysis">
                                        <b>[23]</b>
                                        Zhang Y, Lai G, Zhang M, et al.Explicit factor models for explainable recommendation based on phrase-level sentiment analysis[C]//Proceedings of the 37th international ACM SI-GIR conference on Research&amp;amp;development in information retrieval.ACM, 2014:83-92.
                                    </a>
                                </li>
                                <li id="459">


                                    <a id="bibliography_24" title="He X, Chen T, Kan M Y, et al.Trirank:Review-aware explainable recommendation by modeling aspects[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.ACM, 2015:1661-1670." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Trirank:Review-aware explainable recommendation by modeling aspects">
                                        <b>[24]</b>
                                        He X, Chen T, Kan M Y, et al.Trirank:Review-aware explainable recommendation by modeling aspects[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.ACM, 2015:1661-1670.
                                    </a>
                                </li>
                                <li id="461">


                                    <a id="bibliography_25" title="Tan Y, Zhang M, Liu Y, et al.Rating-Boosted Latent Topics:Understanding Users and Items with Ratings and Reviews[C]//IJCAI.2016:2640-2646." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Rating-Boosted Latent Topics:Understanding Users and Items with Ratings and Reviews">
                                        <b>[25]</b>
                                        Tan Y, Zhang M, Liu Y, et al.Rating-Boosted Latent Topics:Understanding Users and Items with Ratings and Reviews[C]//IJCAI.2016:2640-2646.
                                    </a>
                                </li>
                                <li id="463">


                                    <a id="bibliography_26" title="Ren Z, Liang S, Li P, et al.Social collaborative viewpoint regression with explainable recommendations[C]//Proceedings of the tenth ACM international conference on web search and data mining.ACM, 2017:485-494." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Social Collaborative Viewpoint Regression with Explainable Recommendations">
                                        <b>[26]</b>
                                        Ren Z, Liang S, Li P, et al.Social collaborative viewpoint regression with explainable recommendations[C]//Proceedings of the tenth ACM international conference on web search and data mining.ACM, 2017:485-494.
                                    </a>
                                </li>
                                <li id="465">


                                    <a id="bibliography_27" title="Miller A, Fisch A, Dodge J, et al.Key-value memory networks for directly reading documents[EB].ar Xiv preprint ar Xiv:1606.03126, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Key-value memory networks for directly reading documents[EB]">
                                        <b>[27]</b>
                                        Miller A, Fisch A, Dodge J, et al.Key-value memory networks for directly reading documents[EB].ar Xiv preprint ar Xiv:1606.03126, 2016.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(08),145-154 DOI:10.3969/j.issn.1000-386x.2019.08.026            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>多层次场景感知评分预测研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E6%9C%9B&amp;code=42375720&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭望</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%83%A1%E6%96%87%E5%BF%83&amp;code=07528308&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">胡文心</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%90%B4%E9%9B%AF&amp;code=07533774&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吴雯</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B4%BA%E6%A8%91&amp;code=07536655&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">贺樑</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%AA%A6%E4%BA%AE&amp;code=07530151&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">窦亮</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%8E%E4%B8%9C%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0092795&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">华东师范大学计算机科学与软件工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%9B%BD%E5%AE%B6%E6%96%B0%E9%97%BB%E5%87%BA%E7%89%88%E5%B9%BF%E7%94%B5%E6%80%BB%E5%B1%80%E5%87%BA%E7%89%88%E8%9E%8D%E5%90%88%E5%8F%91%E5%B1%95(%E5%8D%8E%E4%B8%9C%E5%B8%88%E5%A4%A7%E7%A4%BE)%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">国家新闻出版广电总局出版融合发展(华东师大社)重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>近年来, 评论在电商等网络平台中起着越来越重要的作用。充分利用评论信息, 可以更好地理解用户兴趣和物品性质, 提升推荐系统的性能。但是, 现有的基于评论的推荐模型都只在“单词”层面或“评论”层面之一建模, 且没有考虑交互场景对用户兴趣和物品性质的影响。因此提出一个新模型SCRM (Scene Context-aware Rating Prediction at Muti-level) , 同时在两个层面层次化、细粒度地抽取相关特征;在“评论”层面加入了场景上下文信息, 突出当前场景中起主要影响的因素。在来自Amazon的不同领域上的四个公开数据集上进行了实验, 结果显示基于均方误差SCRM整体上显著地超过了最先进的方法, 包括MF、DeepCoNN、D-ATT和NARRE。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A8%E8%8D%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">推荐;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E8%AF%84%E5%88%86%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">评分预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%9F%BA%E4%BA%8E%E8%AF%84%E8%AE%BA%E7%9A%84%E6%8E%A8%E8%8D%90&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">基于评论的推荐;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%82%E6%AC%A1%E5%8C%96%E5%BB%BA%E6%A8%A1&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">层次化建模;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郭望, 硕士生, 主研领域:推荐系统, 自然语言处理。;
                                </span>
                                <span>
                                    胡文心, 高工。;
                                </span>
                                <span>
                                    吴雯, 讲师。;
                                </span>
                                <span>
                                    贺樑, 教授。;
                                </span>
                                <span>
                                    窦亮, 讲师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-12-31</p>

                    <p>

                            <b>基金：</b>
                                                        <span>上海市科委项目 (17511102000);</span>
                    </p>
            </div>
                    <h1><b>SCENE CONTEXT-AWARE RATING PREDICTION AT MULTI-LEVEL</b></h1>
                    <h2>
                    <span>Guo Wang</span>
                    <span>Hu Wenxin</span>
                    <span>Wu Wen</span>
                    <span>He Liang</span>
                    <span>Dou Liang</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Software Engineering, East China Normal University</span>
                    <span>SAPPRFT Key Laboratory of Publishing Integration Development, ECNUP</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Recently, reviews have played an increasingly important role in online platforms such as e-commerce. Review information is useful to better understand the user's interests and the nature of the item and improve the performance of the recommendation system. However, the existing review-based recommendation models are modeled only at one of the “word” level or the “review” level, and do not consider the impact of the interaction scene on user interests and the nature of the item. Therefore, we proposed a new model SCRM (Scene Context-aware Rating Prediction at Multi-level) . It extracted relevant features hierarchically at two levels, and added scene context information at the “review” level to highlight the main influence factors in the current scene. Experiments on four public datasets from different areas of Amazon are conducted, and our results show that SCRM constantly and significantly outperform existing state-of-the-art models, including MF, DeepCoNN, D-ATT, and NARRE.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Recommendation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Recommendation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Rating%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Rating prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Review-based%20recommendation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Review-based recommendation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Hierarchical%20modeling&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Hierarchical modeling;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-12-31</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="57" name="57" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="58">基于评论的推荐, 利用用户评论文本作为评分的补充。评论文本解释了用户对物品打分高低的原因, 用户的评论集合反映了用户不同方面的兴趣, 物品的评论集合反映了物品的性质。</p>
                </div>
                <div class="p1">
                    <p id="59">同时在两个层面层次化地构建用户和物品的表示可以更加细粒度地挖掘用户和物品特征, 但是现有工作大多只单独在“单词”层面或“评论”层面之一过滤重要特征, 例如D-ATT<citation id="467" type="reference"><link href="413" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation> (“单词”层面) 和NARRE<citation id="468" type="reference"><link href="415" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation> (“评论”层面) 。此外, D-ATT在“单词”层面建模中先过滤重要单词再使用CNN编码文本的方法容易在过滤中丢失一个单词的上下文, 先编码每个单词的上下文表示再过滤可以有效缓解这个问题。</p>
                </div>
                <div class="p1">
                    <p id="60">用户兴趣与物品性质是随场景动态变化的。对于给定用户其面对不同物品时表现出的兴趣方面是不同的, 对于给定物品其面对不同用户时表现出的主要性质也是与具体用户相关的。例如一个喜欢篮球运动的用户, 面对一个球星代言的手机可能会打分较高, 此时交互场景中“篮球”的特征被凸显了, 而与手机其他特性 (屏幕大小、性能等) 关系较小。然而现有工作大多在用户和物品编码为固定维度的静态向量, 两者再进行交互, 例如DeepCoNN<citation id="469" type="reference"><link href="417" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>, 不能突出场景中的主要因素。因此, 使用户和物品的向量表示根据交互场景的上下文动态变化, 可以更好捕捉两者的交互关系。</p>
                </div>
                <div class="p1">
                    <p id="61">本文提出了一种基于用户评论的多层次评分预测模型SCRM。每个用户和物品都表示为<i>L</i>个评论的集合, 其中每个评论<i>N</i>个单词。用户和物品的表示通过两个平行的网络建模, 两者结构相同。以用户为例, 在“单词”层面, 通过CNN编码每个单词的局部上下文并使用“门机制”提取用户兴趣特征, 去除冗余信息, 得到每个评论的表示。在“评论”层面, 通过注意力机制计算单个用户评论的交互场景上下文。具体地, 计算单个用户评论到所有物品评论的相关性权重, 将所有物品评论加权求和作为单个用户评论的上下文表示, 与单个用户评论的表示进行融合, 构成“交互场景感知”的用户评论表示。对于每个用户评论重复同样的过程, 并将它们聚合得到用户的最终表示。最后, 将用户和物品的最终表示在交互层进行匹配, 计算预测评分。</p>
                </div>
                <h3 id="62" name="62" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="63">在推荐系统中, 评论文本已经广泛地在许多工作中使用, 例如HFT<citation id="470" type="reference"><link href="453" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、RMR<citation id="471" type="reference"><link href="455" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>、EFM<citation id="472" type="reference"><link href="457" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>、TriRank<citation id="473" type="reference"><link href="459" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>、RBLT<citation id="474" type="reference"><link href="461" rel="bibliography" /><sup>[<a class="sup">25</a>]</sup></citation>和sCVR<citation id="475" type="reference"><link href="463" rel="bibliography" /><sup>[<a class="sup">26</a>]</sup></citation>。这些工作大多将用户表示为他过去写的所有评论的集合, 同样地将物品表示为用户为它写过的所有评论的集合。评论文本不仅缓解了冷启动问题, 也为建模用户兴趣和物品性质提供了更丰富的语义信息。</p>
                </div>
                <div class="p1">
                    <p id="64">较早的工作大多基于主题模型LDA<citation id="476" type="reference"><link href="451" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>, 将从评论中学习到的主题分布作为用户和物品的表示。例如HFT<citation id="477" type="reference"><link href="453" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>将LDA和MF统一在同一个框架中, 将评论文本主题分布的似然函数作为正则项与MF的目标函数相结合, 拟合评分数据。</p>
                </div>
                <div class="p1">
                    <p id="65">近来的工作明显地转向深度学习模型。神经网络在评论建模中具有明显的优势, 例如自动的特征学习和十分有竞争力的性能。最近的工作在网络结构上大多由 “编码层”和“交互层”构成, 例如DeepCoNN<citation id="478" type="reference"><link href="417" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>、D-ATT<citation id="479" type="reference"><link href="413" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>和NARRE<citation id="480" type="reference"><link href="415" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。在编码层, 使用卷积神经网络 (CNN) 抽取文本中的特征, 将用户和物品分别编码成两个低维向量。在交互层, 对两个向量进行匹配, 计算预测评分。</p>
                </div>
                <div class="p1">
                    <p id="66">基于深度神经网络的模型, 较早的是DeepCoNN。在编码层, 它同时将用户和物品用两个平行的网络处理, 通过CNN编码为固定长度向量。在交互层, 用户和物品向量通过Factorization Machines (FM) 进行匹配。</p>
                </div>
                <div class="p1">
                    <p id="67">DeepCoNN的结构相对简单, 近来提出的D-ATT在CNN编码层之前, 加入了注意力机制。其核心思想是, 根据局部和全局上下文信息衡量每个单词的重要性。它使用两个平行的网络分别过滤相对于局部和全局重要的单词。</p>
                </div>
                <div class="p1">
                    <p id="68">将评论集合中所有评论拼接, 作为用户 (物品) 的表示, 存在比较大的噪声。因为用户的每个评论是在不同时期写的, 代表用户不同方面的兴趣。NARRE对每个评论单独编码其表示, 并衡量每个评论的有用性, 使用注意力机制为每个评论分配权重, 最后将全部加权求和作为用户 (物品) 的最终表示。</p>
                </div>
                <div class="p1">
                    <p id="69">然而, 这些模型都只单独在“单词”层面或“评论”层面之一过滤重要特征, 缺少更加细粒度建模。此外, D-ATT由于先过滤重要单词, 再用CNN编码单词的上下文表示, 导致单词的上下文在编码前已经丢失了。而NARRE从评论有用性的角度计算评论的权重, 却没有考虑具体的“用户-物品”交互场景对评论表示的影响。事实上, 每个评论中所体现的用户兴趣和物品性质是与交互场景上下文相关的。</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag"><b>2 模 型</b></h3>
                <div class="p1">
                    <p id="71">图1显示了SCRM整体的网络结构。我们对于用户和物品使用同样的网络结构, 因此下文只详细介绍用户网络。</p>
                </div>
                <div class="area_img" id="72">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908027_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SCRM整体结构图" src="Detail/GetImg?filename=images/JYRJ201908027_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SCRM整体结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908027_072.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="73">网络接受一个评论集合, 包含多个评论{<i>r</i><sub>1</sub>, <i>r</i><sub>2</sub>, …, <i>r</i><sub><i>l</i></sub>}, 其中<i>l</i>代表评论的最大数量。每个评论经过“词嵌入层”映射为词向量序列, 接着在“单词层面”通过“带门机制的卷积层”编码为固定维度的向量。编码后的评论表示在“评论层面”融合交互场景的上下文。最后将所有评论表示聚合为用户 (物品) 的最终表示, 在“交互层”使用FM进行匹配。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"><b>2.1 词嵌入层</b></h4>
                <div class="p1">
                    <p id="75">每个评论都是一个长度为<i>T</i>的单词序列, 每个单词是用独热 (one-hot) 编码表示的向量。每个单词都通过嵌入矩阵<b><i>W</i></b><sup><i>d</i>×|<i>V</i>|</sup>将独热编码映射到一个<i>d</i>维稠密向量, 其中<i>V</i>是词汇表的大小。</p>
                </div>
                <h4 class="anchor-tag" id="76" name="76"><b>2.2 单词层面:带门机制的卷积层</b></h4>
                <div class="p1">
                    <p id="77">近年来, 卷积神经网络 (CNN) 在文本编码方面得到了广泛的应用<citation id="481" type="reference"><link href="435" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>, 例如TextCNN<citation id="482" type="reference"><link href="425" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>、DCNN<citation id="483" type="reference"><link href="427" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。如图2所示, 模型使用CNN来抽取单个评论的表示, 包括一个卷积层和一个池化层。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908027_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 单词层面建模图" src="Detail/GetImg?filename=images/JYRJ201908027_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 单词层面建模图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908027_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>2.2.1 卷积层</b></h4>
                <div class="p1">
                    <p id="80">在卷积层, 输入是一个长度为<i>T</i>的评论, 包含一个单词序列{<i>x</i><sub>1</sub>, <i>x</i><sub>2</sub>, …, <i>x</i><sub><i>T</i></sub>}。将评论表示为一个矩阵<b><i>X</i></b>∈ℝ<sup><i>T</i>×<i>d</i></sup>, 矩阵中的每一行为每个单词对应的<i>d</i>维词向量。我们使用卷积操作对句子中每个大小为<i>h</i>的窗口内的单词进行卷积, 例如{<i>x</i><sub>1:<i>h</i></sub>, <i>x</i><sub>2:<i>h</i>+1</sub>, …, <i>x</i><sub><i>T</i>-<i>h</i>+1:<i>T</i></sub>}。每个窗口内卷积得到的特征图是窗口内“中心词”的上下文表示, 例如窗口<i>x</i><sub><i>i</i>:<i>h</i>+<i>i</i></sub>编码的是单词<mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>x</mi><msub><mrow></mrow><mrow><mfrac><mrow><mi>h</mi><mo>+</mo><mn>2</mn><mi>i</mi></mrow><mn>2</mn></mfrac></mrow></msub></mrow></math></mathml>的上下文表示。</p>
                </div>
                <div class="p1">
                    <p id="82">为了获得每个单词的上下文表示, 使用一个大小为<i>h</i>的滑动窗口对整个评论文本进行卷积得到特征图<b><i>A</i></b>:</p>
                </div>
                <div class="p1">
                    <p id="83"><b><i>A</i></b>=<i>f</i> (<b><i>W</i>*<i>X</i>+<i>b</i></b>) </p>
                </div>
                <div class="p1">
                    <p id="84">式中:*表示卷积运算, 参数<b><i>W</i></b>∈ℝ<sup><i>K</i>×<i>h</i>×<i>d</i></sup>为卷积核权重, 参数<b><i>b</i></b>∈ℝ<sup><i>K</i></sup>为偏置项, <i>K</i>是卷积核的数量。<i>f</i> (·) 为激活函数。为了编码单词在局部的上下文, 实现中把<i>h</i>设置为3, 过大的窗口容易引入太多噪声。</p>
                </div>
                <h4 class="anchor-tag" id="85" name="85"><b>2.2.2 门机制</b></h4>
                <div class="p1">
                    <p id="86">带门机制的卷积神经网络 (gated CNN) <citation id="484" type="reference"><link href="431" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>在语言建模<citation id="485" type="reference"><link href="423" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>和机器翻译<citation id="486" type="reference"><link href="433" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>等领域取得了良好的性能。长短期记忆网络 (LSTM) <citation id="487" type="reference"><link href="429" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>中使用门机制决定特征的记忆与遗忘, 受其启发, 这里为CNN加入门机制。</p>
                </div>
                <div class="p1">
                    <p id="87"><b><i>A</i></b>∈ℝ<sup><i>K</i>× (<i>T</i>-<i>h</i>+1) </sup>中每一列对应一个单词的上下文表示。每个单词的重要性不同, 每个单词上下文中不同特征的重要性也不同。因此, 使用门机制给予<b><i>A</i></b>中特征不同权重来过滤相关信息, 得到<b><i>A</i></b><sub><i>g</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="88"><b><i>A</i></b><sub><i>g</i></sub>=<b><i>A</i>⨂<i>G</i></b>=</p>
                </div>
                <div class="p1">
                    <p id="89"><i>f</i> (<b><i>W</i>*<i>X</i>+<i>b</i></b>) ⨂<i>σ</i> (<b><i>V</i>*<i>X</i>+<i>c</i></b>) </p>
                </div>
                <div class="p1">
                    <p id="90">式中:<b><i>G</i></b>=<i>σ</i> (<b><i>V</i>*<i>X</i>+<i>c</i></b>) ∈ℝ<sup><i>K</i>× (<i>T</i>-<i>h</i>+1) </sup>为门机制, 控制<b><i>A</i></b>中特征的通过率。由于引入了非线性的门机制, 实现中, 激活函数<i>f</i> (·) 使用恒等映射, 即<i>f</i> (<i>t</i>) =<i>t</i>。参数<b><i>W</i>, <i>V</i></b>∈ℝ<sup><i>K</i>×<i>h</i>×<i>d</i></sup>为卷积核权重, 参数<b><i>b</i>, <i>c</i></b>∈ℝ<sup><i>K</i></sup>为偏置项。<i>σ</i>为sigmoid函数。⨂为矩阵间的按元素乘法。</p>
                </div>
                <div class="p1">
                    <p id="91">门机制<b><i>G</i></b>的作用体现在两个层面的:一方面根据单词的上下文过滤重要的单词, 另一方面利用按元素乘法, 在每个单词的上下文表示中过滤更相关的特征。相比只是给予不同单词权重, 门机制<b><i>G</i></b>进行了更细粒度的处理。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>2.2.3 池化层</b></h4>
                <div class="p1">
                    <p id="93">在池化层, 将卷积层输出的单个评论表示<b><i>A</i></b><sub><i>g</i></sub>每行取最大值, 得到向量<b><i>a</i></b>∈ℝ<sup><i>K</i></sup>。</p>
                </div>
                <div class="p1">
                    <p id="94" class="code-formula">
                        <mathml id="94"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">a</mi><mo>=</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mn>1</mn><mo>, </mo><mn>1</mn></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mn>1</mn><mo>, </mo><mo stretchy="false"> (</mo><mi>Τ</mi><mo>-</mo><mi>h</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mn>2</mn><mo>, </mo><mn>2</mn></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mn>2</mn><mo>, </mo><mo stretchy="false"> (</mo><mi>Τ</mi><mo>-</mo><mi>h</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>max</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mi>Κ</mi><mo>, </mo><mn>1</mn></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mi>Κ</mi><mo>, </mo><mn>2</mn></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">A</mi><msubsup><mrow></mrow><mi>g</mi><mrow><mi>Κ</mi><mo>, </mo><mo stretchy="false"> (</mo><mi>Τ</mi><mo>-</mo><mi>h</mi><mo>+</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="95">式中:<b><i>A</i></b><mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>g</mi><mrow><mi>i</mi><mo>, </mo><mi>j</mi></mrow></msubsup></mrow></math></mathml>表示<b><i>A</i></b><sub><i>g</i></sub>中的第<i>i</i>行第<i>j</i>列的元素。最大池化操作是为了保留每个评论中比较显著的单词特征及其上下文特征。</p>
                </div>
                <div class="p1">
                    <p id="97">为了方便起见, 实验中设置<i>K</i>=<i>d</i>。</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98"><b>2.3 评论层面:场景上下文感知的评论建模</b></h4>
                <div class="p1">
                    <p id="99">评论层面的输入是用户评论向量集合{<i>u</i><sub>1</sub>, <i>u</i><sub>2</sub>, …, <i>u</i><sub><i>l</i></sub>}和物品评论向量集合{<i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, …, <i>p</i><sub><i>l</i></sub>}, 分别用<b><i>U</i></b><sub><i>o</i></sub>, <b><i>P</i></b><sub><i>o</i></sub>∈ℝ<sup><i>l</i>×<i>d</i></sup>表示。<b><i>U</i></b><sub><i>o</i></sub>中的每行代表一个用户评论的向量表示, <b><i>P</i></b><sub><i>o</i></sub>中的每行代表一个物品评论的向量表示。</p>
                </div>
                <div class="p1">
                    <p id="100">评论层面为每个评论表示计算场景上下文, 然后将“原评论表示”和“场景上下文表示”融合为“评论的动态表示”, 动态的含义是评论的表示根据当前场景上下文动态变化。SCRM在评论层面主要分为三个部分:场景上下文编码层、评论动态表示编码层和平均池化层。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>2.3.1 场景上下文编码层</b></h4>
                <div class="p1">
                    <p id="102">场景上下文编码层根据用户评论集合<b><i>U</i></b><sub><i>o</i></sub>和物品评论集合<b><i>P</i></b><sub><i>o</i></sub>计算每一个单个评论的上下文表示, 得到用户评论的场景上下文集合<b><i>U</i></b><sub><i>c</i></sub>和物品评论的场景上下文集合<b><i>P</i></b><sub><i>c</i></sub>。</p>
                </div>
                <h4 class="anchor-tag" id="103" name="103"> (1) 键值对记忆网络:</h4>
                <div class="p1">
                    <p id="104">注意力机制广泛的应用于许多任务, 例如信息检索<citation id="488" type="reference"><link href="441" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、推荐系统<citation id="489" type="reference"><link href="413" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>、阅读理解<citation id="490" type="reference"><link href="437" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>和机器翻译<citation id="491" type="reference"><link href="439" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。基于注意力机制, SCRM使用“键值对记忆网络”<sup></sup><citation id="492" type="reference"><link href="465" rel="bibliography" /><sup>[<a class="sup">27</a>]</sup></citation>为每个原评论表示计算场景上下文表示。</p>
                </div>
                <div class="p1">
                    <p id="105">“键值对记忆网络”的组成包括一个查询向量<b><i>q</i></b>∈ℝ<sup><i>d</i></sup>和一个“键值对记忆<i>M</i>”, 目的是根据查询向量<b><i>q</i></b>从<i>M</i>中寻找相关的内容。键值对记忆网络的查询过程如图3所示。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201908027_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 键值对记忆网络查询图" src="Detail/GetImg?filename=images/JYRJ201908027_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 键值对记忆网络查询图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201908027_10700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="108">“键值对记忆<i>M</i>”中包含若干键值对 (<i>k</i><sub><i>i</i></sub>, <i>v</i><sub><i>i</i></sub>) , <i>k</i><sub><i>i</i></sub>, <i>v</i><sub><i>i</i></sub>∈ℝ<sup><i>d</i></sup>。将所有键值对表示为两个矩阵<b><i>K</i>, <i>V</i></b>∈ℝ<sup><i>l</i>×<i>d</i></sup>, 其中<b><i>K</i>、<i>V</i></b>中对应的同一行的两个向量代表一个键值对 (<i>k</i><sub><i>i</i></sub>, <i>v</i><sub><i>i</i></sub>) , <i>l</i>表示键值对的数目。给定查询向量<b><i>q</i></b>∈ℝ<sup><i>d</i></sup>, 基于注意力机制可以从<i>M</i>中查询所有与<b><i>q</i></b>相关的键<i>k</i><sub><i>i</i></sub>并得到对应的<i>v</i><sub><i>i</i></sub>作为查询结果返回。使用“基于点积的注意力机制”可以更好地基于<b><i>q</i></b>与<i>k</i><sub><i>i</i></sub>的内容相似性进行查询。</p>
                </div>
                <div class="p1">
                    <p id="109">给定查询向量<b><i>q</i></b>和键值对矩阵<b><i>K</i>×<i>V</i></b>, 使用注意力机制<i>Attention</i><sub>vector</sub> (<b><i>q</i>, <i>K</i>, <i>V</i></b>) 查询:</p>
                </div>
                <div class="p1">
                    <p id="110"><i>s</i>=<i>softmax</i> (<b><i>Kq</i></b>) </p>
                </div>
                <div class="p1">
                    <p id="111"><b><i>ans</i></b>=<i>Attention</i><sub>vector</sub> (<b><i>q</i>, <i>K</i>, <i>V</i></b>) =<b><i>V</i></b><i>s</i>=</p>
                </div>
                <div class="p1">
                    <p id="112"><b><i>V</i></b><i>softmax</i> (<b><i>Kq</i></b>) </p>
                </div>
                <div class="p1">
                    <p id="113">式中:<i>s</i>∈ℝ<sup><i>l</i></sup>表示<b><i>q</i></b>对所有键<b><i>K</i></b>的相似性分布, 这里利用<i>softmax</i>函数对相似性分布进行归一化。</p>
                </div>
                <div class="p1">
                    <p id="114"><b><i>ans</i></b>∈ℝ<sup><i>d</i></sup>表示查询结果向量。<b><i>V</i></b><i>s</i>的含义是:如果<b><i>q</i></b>和<i>k</i><sub><i>i</i></sub>相关度大, 那么就返回相应的<i>v</i><sub><i>i</i></sub>作为查询结果。需要注意的是, <b><i>q</i></b>可能与多个<i>k</i><sub><i>i</i></sub>相关, 基于注意力机制的查询方式会将多个<i>v</i><sub><i>i</i></sub>按相关度加权求和作为查询结果。</p>
                </div>
                <div class="p1">
                    <p id="115">键值对记忆网络中, 查询可以批量进行。如果有一组查询<i>q</i><sub><i>i</i></sub>∈ℝ<sup><i>d</i></sup>, 其中<i>i</i>=1, 2, …, <i>n</i><sub><i>q</i></sub>, <i>n</i><sub><i>q</i></sub>为查询的数量, 可以将所有查询表示为一个矩阵<b><i>Q</i></b>∈ℝ<sup><i>n</i><sub><i>q</i></sub>×<i>d</i></sup>, 利用对矩阵运算优化良好的处理器进行加速。</p>
                </div>
                <div class="p1">
                    <p id="116">给定查询矩阵<b><i>Q</i></b>和键值对矩阵 (<b><i>K</i>, <i>V</i></b>) , 使用注意力机制<i>Attention</i><sub>matrix</sub> (<b><i>Q</i>, <i>K</i>, <i>V</i></b>) 查询:</p>
                </div>
                <div class="p1">
                    <p id="117"><b><i>S</i></b>=<i>softmax</i> (<b><i>QK</i></b><sup>T</sup>) </p>
                </div>
                <div class="p1">
                    <p id="118"><b><i>Ans</i></b>=<i>Attention</i><sub>matrix</sub> (<b><i>Q</i>, <i>K</i>, <i>V</i></b>) =<b><i>SV</i></b>=</p>
                </div>
                <div class="p1">
                    <p id="119"><i>softmax</i> (<b><i>QK</i></b><sup>T</sup>) <b><i>V</i></b></p>
                </div>
                <div class="p1">
                    <p id="120">式中:<b><i>S</i></b>∈ℝ<sup><i>n</i><sub><i>q</i></sub>×<i>l</i></sup>中的第<i>i</i>行<i>s</i><sub><i>i</i></sub>∈ℝ<sup><i>l</i></sup>, 表示查询向量<b><i>q</i></b><sub><i>i</i></sub>∈ℝ<sup><i>d</i></sup>对所有键<b><i>K</i></b>的相似性分布。这里利用<i>softmax</i>函数对<b><i>S</i></b>中的每一行进行行内归一化。<b><i>Ans</i></b>∈ℝ<sup><i>n</i><sub><i>q</i></sub>×<i>d</i></sup>表示查询结果向量, 其中的每一行代表<b><i>Q</i></b>中对应行的查询结果。</p>
                </div>
                <h4 class="anchor-tag" id="121" name="121"> (2) 场景上下文编码:</h4>
                <div class="p1">
                    <p id="122">交互场景由用户和物品的关系定义, 用户多方面的兴趣和物品多方面的性质之间存在复杂的依赖关系, 将这种相关性的语义通过注意力机制编码可以表达“场景上下文”的语义。</p>
                </div>
                <div class="p1">
                    <p id="123">以用户为例, “用户的上下文”中需要考虑当前面对的物品各方面的性质, 而每个物品评论反映了某一方面的性质, 因此根据整个物品评论集合计算用户的上下文。此外, 用户兴趣是多方面的, 每个用户评论体现了不同方面的用户兴趣, 所以逐一为每个用户评论计算上下文。类似地, “物品的上下文”也根据整个用户评论集合计算。</p>
                </div>
                <div class="p1">
                    <p id="124">SCRM使用“键值对记忆网络”为每个评论编码其“场景上下文表示”, 以用户的上下文来说明计算方法:对于单个用户评论<b><i>u</i></b><sub><i>o</i></sub>∈ℝ<sup><i>d</i></sup>, 其上下文表示根据所有物品评论集合<b><i>P</i></b><sub><i>o</i></sub>计算。在键值对记忆网络中, 令<i>Attention</i><sub>vector</sub> (<b><i>q</i>, <i>K</i>, <i>V</i></b>) 中<b><i>q</i>=<i>u</i></b><sub><i>o</i></sub>, <b><i>K</i>=<i>P</i></b><sub><i>o</i></sub>, <b><i>V</i>=<i>P</i></b><sub><i>o</i></sub>。那么<b><i>u</i></b><sub><i>o</i></sub>的场景上下文<b><i>u</i></b><sub><i>c</i></sub>∈ℝ<sup><i>d</i></sup>计算如下:</p>
                </div>
                <div class="p1">
                    <p id="125"><b><i>u</i></b><sub><i>c</i></sub>=<i>Attention</i><sub>vector</sub> (<b><i>u</i></b><sub><i>o</i></sub>, <b><i>P</i></b><sub><i>o</i></sub>, <b><i>P</i></b><sub><i>o</i></sub>) =</p>
                </div>
                <div class="p1">
                    <p id="126"><b><i>P</i></b><sub><i>o</i></sub><i>softmax</i> (<b><i>P</i></b><sub><i>o</i></sub><b><i>u</i></b><sub><i>o</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="127">“键值对记忆网络”为整个用户评论集合<b><i>U</i></b><sub><i>o</i></sub>∈ℝ<sup><i>l</i>×<i>d</i></sup>逐一计算其中每个评论<b><i>u</i></b><mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>o</mi><mi>i</mi></msubsup></mrow></math></mathml>∈ℝ<sup><i>d</i></sup>的场景上下文表示<b><i>u</i></b><mathml id="129"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>c</mi><mi>i</mi></msubsup></mrow></math></mathml>∈ℝ<sup><i>d</i></sup>。其中<i>i</i>=1, 2, …, <i>l</i>表示用户评论集合中的第<i>i</i>个评论。</p>
                </div>
                <div class="p1">
                    <p id="130">使用键值对记忆网络中批量查询方式, 可以得到所有用户评论的场景上下文表示, 使用一个矩阵<b><i>U</i></b><sub><i>c</i></sub>∈ℝ<sup><i>l</i>×<i>d</i></sup>表示。令<i>Attention</i><sub>matrix</sub> (<b><i>Q</i>, <i>K</i>, <i>V</i></b>) 中<b><i>Q</i>=<i>U</i></b><sub><i>o</i></sub>, <b><i>K</i>=<i>P</i></b><sub><i>o</i></sub>, <b><i>V</i>=<i>P</i></b><sub><i>o</i></sub>, 得到:</p>
                </div>
                <div class="p1">
                    <p id="131"><b><i>U</i></b><sub><i>c</i></sub>=<i>Attention</i><sub>matrix</sub> (<b><i>U</i></b><sub><i>o</i></sub>, <b><i>P</i></b><sub><i>o</i></sub>, <b><i>P</i></b><sub><i>o</i></sub>) =</p>
                </div>
                <div class="p1">
                    <p id="132"><i>softmax</i> (<b><i>U</i></b><sub><i>o</i></sub><b><i>P</i></b><sub><i>o</i></sub><sup>T</sup>) <b><i>P</i></b><sub><i>o</i></sub></p>
                </div>
                <div class="p1">
                    <p id="133">类似地, 为整个物品评论集合<b><i>P</i></b><sub><i>o</i></sub>∈ℝ<sup><i>l</i>×<i>d</i></sup>计算物品评论的场景上下文集合<b><i>P</i></b><sub><i>c</i></sub>∈ℝ<sup><i>l</i>×<i>d</i></sup>。令<i>Attention</i><sub>matrix</sub> (<b><i>Q</i>, <i>K</i>, <i>V</i></b>) 中<b><i>Q</i>=<i>P</i></b><sub><i>o</i></sub>, <b><i>K</i>=<i>U</i></b><sub><i>o</i></sub>, <b><i>V</i>=<i>U</i></b><sub><i>o</i></sub>, 得到:</p>
                </div>
                <div class="p1">
                    <p id="134"><b><i>P</i></b><sub><i>c</i></sub>=<i>Attention</i><sub>matrix</sub> (<b><i>P</i></b><sub><i>o</i></sub>, <b><i>U</i></b><sub><i>o</i></sub>, <b><i>U</i></b><sub><i>o</i></sub>) =</p>
                </div>
                <div class="p1">
                    <p id="135"><i>softmax</i> (<b><i>P</i></b><sub><i>o</i></sub><b><i>U</i></b><sub><i>o</i></sub><sup>T</sup>) <b><i>U</i></b><sub><i>o</i></sub></p>
                </div>
                <div class="p1">
                    <p id="136">在“场景上下文编码层”, 我们最终得到用户评论的场景上下文集合<b><i>U</i></b><sub><i>c</i></sub>和物品评论的场景上下文集合<b><i>P</i></b><sub><i>c</i></sub>。</p>
                </div>
                <h4 class="anchor-tag" id="137" name="137"><b>2.3.2 评论动态表示编码层</b></h4>
                <div class="p1">
                    <p id="138">在评论动态表示编码层, 将每个评论的“原表示”和“场景上下文表示”进行融合, 输出评论的动态表示。</p>
                </div>
                <div class="p1">
                    <p id="139">对于用户, “评论的原表示”反映了用户某一个方面的兴趣, 对于物品, “评论的原表示”也反映了物品某一个方面的性质。但是这种用户兴趣或物品性质是静态的, 即使是很强的信号也不一定与当前交互场景相关, 需要借助交互场景的上下文来确定用户兴趣或物品性质中真实有效的信号。</p>
                </div>
                <h4 class="anchor-tag" id="140" name="140"> (1) 合并层:</h4>
                <div class="p1">
                    <p id="141">在合并层, 输入用户 (或物品) 评论集合的“原表示”矩阵和“场景上下文表示”矩阵, 将它们逐评论拼接并输出。</p>
                </div>
                <div class="p1">
                    <p id="142">对于用户, 合并后的评论集合表示<b><i>U</i></b><sub><i>oc</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="143" class="code-formula">
                        <mathml id="143"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>c</mi><mspace width="0.25em" /></mrow></msub><mo>=</mo><mspace width="0.25em" /><mspace width="0.25em" /><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi>o</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>1</mn></msup><mspace width="0.25em" /><mtext> </mtext><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi>c</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>1</mn></msup></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi>o</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi>c</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mo>⋮</mo><mtext> </mtext><mo>⋮</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi>o</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mi>l</mi></msup><mtext> </mtext><mi mathvariant="bold-italic">U</mi><msub><mrow></mrow><mrow><mi>c</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mi>l</mi></msup></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="144">对于物品, 合并后的评论集合表示<b><i>P</i></b><sub><i>oc</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="145" class="code-formula">
                        <mathml id="145"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>o</mi><mi>c</mi><mspace width="0.25em" /></mrow></msub><mo>=</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>o</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>1</mn></msup><mspace width="0.25em" /><mtext> </mtext><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>c</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>1</mn></msup></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>o</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>c</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mn>2</mn></msup></mtd></mtr><mtr><mtd><mo>⋮</mo><mtext> </mtext><mo>⋮</mo></mtd></mtr><mtr><mtd><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>o</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mi>l</mi></msup><mtext> </mtext><mi mathvariant="bold-italic">Ρ</mi><msub><mrow></mrow><mrow><mi>c</mi><mspace width="0.25em" /></mrow></msub><msup><mrow></mrow><mi>l</mi></msup></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="146">式中:<b><i>U</i></b><sub><i>o</i></sub>、<b><i>P</i></b><sub><i>o</i></sub>分别为用户和物品评论集合的“原表示”矩阵, <b><i>U</i></b><sub><i>o</i></sub><sup><i>i</i></sup>、<b><i>P</i></b><sub><i>o</i></sub><sup><i>i</i></sup>为其中的一行。<b><i>P</i></b><sub><i>c</i></sub>、<b><i>U</i></b><sub><i>c</i></sub>分别为用户和物品评论集合的“场景上下文表示”矩阵, <b><i>P</i></b><sub><i>c</i></sub><sup><i>i</i></sup>、<b><i>U</i></b><sub><i>c</i></sub><sup><i>i</i></sup>为其中的一行。经过拼接后的<b><i>U</i></b><sub><i>oc</i></sub>∈ℝ<sup><i>l</i>×2<i>d</i></sup>和<b><i>P</i></b><sub><i>oc</i></sub>∈ℝ<sup><i>l</i>×2<i>d</i></sup>每行的维度由扩展到了2<i>d</i>。</p>
                </div>
                <h4 class="anchor-tag" id="147" name="147"> (2) 融合层:</h4>
                <div class="p1">
                    <p id="148">在融合层, 将每个评论的“原表示”和“场景上下文表示”进行融合, 得到每个评论的“动态表示”。</p>
                </div>
                <div class="p1">
                    <p id="149">以用户为例, 给定拼接后的<b><i>U</i></b><sub><i>oc</i></sub>用户评论表示集合, 其中的每一行为一个评论拼接后的表示。使用窗口大小为1的gated CNN对每个评论进行卷积 (1×1卷积最早在文献<citation id="493" type="reference">[<a class="sup">16</a>]</citation>中提出, 用于压缩图片的通道数) 。令<i>u</i><mathml id="150"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>o</mi><mi>c</mi></mrow><mi>i</mi></msubsup></mrow></math></mathml>∈ℝ<sup>2<i>d</i></sup>为第<i>i</i>个评论, 则每个窗口为{ <i>u</i><mathml id="151"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>o</mi><mi>c</mi><mspace width="0.25em" /></mrow><mn>1</mn></msubsup></mrow></math></mathml>, <i>u</i><mathml id="152"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>o</mi><mi>c</mi><mspace width="0.25em" /></mrow><mn>2</mn></msubsup></mrow></math></mathml>, …, <i>u</i><mathml id="153"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mrow><mi>o</mi><mi>c</mi><mspace width="0.25em" /></mrow><mi>l</mi></msubsup></mrow></math></mathml>} 。卷积后的特征图为<b><i>U</i></b><sub>dynamic</sub>:</p>
                </div>
                <div class="p1">
                    <p id="154"><b><i>U</i></b><sub>dynamic</sub>=<b><i>U</i></b><sub>conv</sub>⨂<b><i>G</i></b><sub>conv</sub>=</p>
                </div>
                <div class="p1">
                    <p id="155"> (<b><i>W</i></b><sub><i>oc</i></sub>*<b><i>U</i></b><sub><i>oc</i></sub>+<i>b</i><sub><i>oc</i></sub>) ⨂<i>σ</i> (<b><i>V</i></b><sub><i>oc</i></sub>*<b><i>U</i></b><sub><i>oc</i></sub>+<i>c</i><sub><i>oc</i></sub>) </p>
                </div>
                <div class="p1">
                    <p id="156">式中:*表示卷积运算, 参数<b><i>W</i></b><sub><i>oc</i></sub>, <b><i>V</i></b><sub><i>oc</i></sub>∈ℝ<sup><i>K</i>×<i>h</i>×2<i>d</i></sup>为卷积核权重, 参数<i>b</i><sub><i>oc</i></sub>, <i>c</i><sub><i>oc</i></sub>∈ℝ<sup><i>K</i></sup>为偏置项, <i>K</i>是卷积核的数量, 实现中设置<i>K</i>=2<i>d</i>。</p>
                </div>
                <div class="p1">
                    <p id="157"><b><i>U</i></b><sub>dynamic</sub>=<b><i>W</i></b><sub><i>oc</i></sub>*<b><i>U</i></b><sub><i>oc</i></sub>+<i>b</i><sub><i>oc</i></sub>将每个评论拼接后的表示<i>u</i><sub><i>oc</i></sub><sup><i>i</i></sup>投影到一个新的语义空间, 融合了两种表示。<b><i>G</i></b><sub>conv</sub>=<i>σ</i> (<b><i>V</i></b><sub>oc</sub>*<b><i>U</i></b><sub><i>oc</i></sub>+<i>c</i><sub><i>oc</i></sub>) 为门机制, 给予评论表示中不同特征以不同权重。<b><i>U</i></b><sub>dynamic</sub>=<b><i>U</i></b><sub>conv</sub>⨂<b><i>G</i></b><sub>conv</sub>将两者按元素相乘, 达到根据场景上下文动态生成评论表示的目的。 类似地, 对于物品, 也对拼接后的<b><i>P</i></b><sub><i>oc</i></sub>物品评论表示集合进行卷积, 并利用门机制动态生成评论表示<b><i>P</i></b><sub>dynamic</sub>。</p>
                </div>
                <h4 class="anchor-tag" id="158" name="158"><b>2.3.3 平均池化层</b></h4>
                <div class="p1">
                    <p id="159">在平均池化层, 输入用户评论的动态表示集合<b><i>U</i></b><sub>dynamic</sub>∈ℝ<sup><i>l</i>×2<i>d</i></sup>和物品评论的动态表示集合<b><i>P</i></b><sub>dynamic</sub>∈ℝ<sup><i>l</i>×2<i>d</i></sup>, 输出用户的最终表示<b><i>u</i></b><sub>pool</sub>和物品的最终表示<b><i>p</i></b><sub>pool</sub>。</p>
                </div>
                <div class="p1">
                    <p id="160">以用户为例, 对<b><i>U</i></b><sub>dynamic</sub>中每列取平均值, 得到向量<b><i>u</i></b><sub>pool</sub>∈ℝ<sup><i>d</i></sup>:</p>
                </div>
                <div class="p1">
                    <p id="161" class="code-formula">
                        <mathml id="161"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">u</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>o</mtext><mtext>o</mtext><mtext>l</mtext></mrow></msub><mo>=</mo><mrow><mo>[</mo><mtable columnalign="left"><mtr><mtd><mi>A</mi><mi>V</mi><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mn>1</mn><mo>, </mo><mn>1</mn></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mn>2</mn><mo>, </mo><mn>1</mn></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mi>l</mi><mo>, </mo><mn>1</mn></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>A</mi><mi>V</mi><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mn>2</mn><mo>, </mo><mn>2</mn></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mi>l</mi><mo>, </mo><mn>2</mn></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mo>⋮</mo></mtd></mtr><mtr><mtd><mi>A</mi><mi>V</mi><mi>G</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mn>1</mn><mo>, </mo><mn>2</mn><mi>d</mi></mrow></msubsup><mo>, </mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mn>2</mn><mo>, </mo><mn>2</mn><mi>d</mi></mrow></msubsup><mo>, </mo><mo>⋯</mo><mo>, </mo><mi mathvariant="bold-italic">U</mi><msubsup><mrow></mrow><mrow><mtext>d</mtext><mtext>y</mtext><mtext>n</mtext><mtext>a</mtext><mtext>m</mtext><mtext>i</mtext><mtext>c</mtext></mrow><mrow><mi>l</mi><mo>, </mo><mn>2</mn><mi>d</mi></mrow></msubsup><mo stretchy="false">) </mo></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="162">类似地, 对于物品, 根据<b><i>P</i></b><sub>dynamic</sub>得到向量<b><i>p</i></b><sub>pool</sub>∈ℝ<sup><i>d</i></sup>。</p>
                </div>
                <div class="p1">
                    <p id="163">平均池化可以反映用户评论集合中的多个方面的特征和总体情况。而最大池化希望观察到的是强特征, 可以去除冗余的噪声, 在“单词”层面使用最大池化, 可以去除很多没有信息量的单词的影响, 突出一个评论内部所反映的强信号。但是在“评论”层面, 每个评论反映的用户兴趣和物品性质不同, 最大池化会丢失较弱的信号。</p>
                </div>
                <h4 class="anchor-tag" id="164" name="164"><b>2.4 预测层</b></h4>
                <div class="p1">
                    <p id="165">评论文本解释了部分用户打分高低的原因, 但是还有一些评分中反映的因素是没有在用户主观的评论中体现的, 因此将用户和物品的交互分为两个部分, 第一个部分基于评分数据学习, 第二个部分基于评论文本学习。具体地, 用户<i>u</i>对物品<i>i</i>的预测打分<mathml id="166"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub></mrow></math></mathml>通过下式估计:</p>
                </div>
                <div class="p1">
                    <p id="167" class="code-formula">
                        <mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub><mo>=</mo><mi>r</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>a</mtext><mtext>t</mtext><mtext>i</mtext><mtext>n</mtext><mtext>g</mtext><mo>-</mo><mtext>b</mtext><mtext>a</mtext><mtext>s</mtext><mtext>e</mtext><mtext>d</mtext></mrow></msub><mo>+</mo><mi>r</mi><msub><mrow></mrow><mrow><mtext>r</mtext><mtext>e</mtext><mtext>v</mtext><mtext>i</mtext><mtext>e</mtext><mtext>w</mtext><mo>-</mo><mtext>b</mtext><mtext>a</mtext><mtext>s</mtext><mtext>e</mtext><mtext>d</mtext></mrow></msub></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="168">第一部分<i>r</i><sub>rating-based</sub>使用隐含因子模型 (LFM) <citation id="494" type="reference"><link href="419" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>来建模评分数据中反映的用户物品关系。LFM将用户和物品表示为从历史评分数据中推断出的向量:</p>
                </div>
                <div class="p1">
                    <p id="169"><i>r</i><sub>rating-based</sub>=<i>μ</i>+<i>b</i><sub><i>u</i></sub>+<i>b</i><sub><i>i</i></sub>+<b><i>q</i></b><mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup></mrow></math></mathml><i>p</i><sub><i>u</i></sub></p>
                </div>
                <div class="p1">
                    <p id="171">式中:<i>p</i><sub><i>u</i></sub>和<i>q</i><sub><i>i</i></sub>分别是代表用户兴趣和物品性质的<i>k</i>维向量, <b><i>q</i></b><mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>i</mi><mtext>Τ</mtext></msubsup></mrow></math></mathml><i>p</i><sub><i>u</i></sub>表示两者的交互。<i>b</i><sub><i>u</i></sub>和<i>b</i><sub><i>i</i></sub>分别代表用户和物品的偏置, <i>μ</i>代表全局平均打分。</p>
                </div>
                <div class="p1">
                    <p id="173">第二部分<i>r</i><sub>review-based</sub>中, 将从评论文本中学习得到的用户表示<b><i>u</i></b><sub>pool</sub>和物品表示<b><i>p</i></b><sub>pool</sub>拼接为<b><i>z</i></b>=[<b><i>u</i></b><sub>pool</sub>, <b><i>p</i></b><sub>pool</sub>]∈ℝ<sup>2<i>d</i></sup> 并输入到分解机 (FM) 中。FM接受一个特征向量<i>z</i>并建模特征之间的一阶和二阶关系:</p>
                </div>
                <div class="p1">
                    <p id="174"><i>r</i><sub>review-based </sub>=<i>w</i><sub>0 </sub>+<mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>z</mi><mo stretchy="false">|</mo></mrow></munderover><mi>w</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub><mi>z</mi><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>z</mi><mo stretchy="false">|</mo></mrow></munderover><mrow></mrow></mstyle><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>z</mi><mo stretchy="false">|</mo></mrow></munderover><mrow></mrow></mstyle></mrow></math></mathml><b><i>v</i></b><sub><i>i</i></sub><sup>T</sup><b><i>v</i></b><sub><i>j</i></sub><i>z</i><sub><i>i</i></sub><i>z</i><sub><i>j</i></sub></p>
                </div>
                <div class="p1">
                    <p id="176">式中:<i>w</i><sub>0</sub>是全局偏置;<i>w</i><sub><i>i</i></sub>用于捕捉用户和物品之间的一阶交互强度;<b><i>v</i></b><sub><i>i</i></sub><sup>T</sup><b><i>v</i></b><sub><i>j</i></sub>用于捕捉用户和物品之间的二阶交互强度。</p>
                </div>
                <h3 id="177" name="177" class="anchor-tag"><b>3 实 验</b></h3>
                <div class="p1">
                    <p id="178">实验部分给出了实验设置和经验性的评估。我们设计实验来回答以下几个问题:</p>
                </div>
                <div class="p1">
                    <p id="179">问题1: SCRM是否超过了最先进的方法, 例如D-ATT和NARRE?相应的提高为多少?</p>
                </div>
                <div class="p1">
                    <p id="180">问题2:本文在“单词”层面的建模方法, 是否缓解了D-ATT中上下文丢失的问题?</p>
                </div>
                <div class="p1">
                    <p id="181">问题3:本文在“评论”层面的建模方法, 相比NARRE中不考虑场景上下文的方法, 是否带来了性能的提升?</p>
                </div>
                <div class="p1">
                    <p id="182">问题4:本文同时在“单词”和“评论”层面抽取评论文本的表示, 是否带来了性能的提升?</p>
                </div>
                <h4 class="anchor-tag" id="183" name="183"><b>3.1 数据集</b></h4>
                <div class="p1">
                    <p id="184">在实验中, 使用了来自不同领域的四个公开数据集来评估SCRM, 表1给出了相关的统计数据。四个数据集来自Amazon 5-core<citation id="495" type="reference"><link href="445" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>的Digital Music、Toys and Games、Cell Phones and Accessories、Office Products。后续实验中将它们简称为“Music”、“Toy”、“Phone”和“Office”。</p>
                </div>
                <div class="area_img" id="185">
                    <p class="img_tit"><b>表1 四个数据集的统计数据</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="185" border="1"><tr><td>数据</td><td>Digital<br />Music</td><td>Toys and<br />Games</td><td>Cell Phones<br />and Accessories</td><td>Office<br />Products</td></tr><tr><td><br />用户数</td><td>5 542</td><td>19 413</td><td>27 880</td><td>4 906</td></tr><tr><td><br />物品数</td><td>3 569</td><td>11 925</td><td>10 430</td><td>2 421</td></tr><tr><td><br />评论数</td><td>64 706</td><td>167 597</td><td>194 439</td><td>53 258</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="186" name="186"><b>3.2 基 线</b></h4>
                <div class="p1">
                    <p id="187">将SCRM和一系列基线方法相比较。</p>
                </div>
                <div class="p1">
                    <p id="502">1) 矩阵分解模型 (MF) <citation id="504" type="reference"><link href="419" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>是协同过滤方法中标准而知名的基线，它将预测评分表示为用户表示和物品表示的点积:<image id="503" type="formula" href="images/JYRJ201908027_50300.jpg" display="inline" placement="inline"><alt></alt></image>。</p>
                </div>
                <div class="p1">
                    <p id="190">2) DeepCoNN<citation id="496" type="reference"><link href="417" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation> (2017) 是一个基于评论的推荐模型。在编码层它将用户 (物品) 的评论集合中所有评论拼接, 通过卷积神经网络 (CNN) 编码其表示。在交互层它使用分解机 (FM) 建模用户和物品的交互关系并计算预测评分。</p>
                </div>
                <div class="p1">
                    <p id="191">3) D-ATT<citation id="497" type="reference"><link href="413" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation> (2017) 是一个近来提出的模型, 在多个数据集上达到的最先进性能的模型之一。它的主要特点是, 使用局部注意力和全局注意力在“单词”层面过滤重要的单词, 通过卷积神经网络 (CNN) 编码其表示, 然后将局部表示和全局表示进行拼接作为最终表示。在交互层, 它使用点积建模用户和物品的交互关系并计算预测评分。</p>
                </div>
                <div class="p1">
                    <p id="192">4) NARRE<citation id="498" type="reference"><link href="415" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation> (2018) 是一个近来提出的模型, 在多个数据集上达到的最先进性能的模型之一。它在“评论”层面对每个评论单独编码其表示, 并使用注意力机制为每个评论分配权重, 最后将全部加权求和作为用户 (物品) 的最终表示。在交互层, 将隐含因子模型 (LFM) 中的用户表示和物品表示扩展成“基于评分的表示”和“基于评论文本的表示”并计算预测评分。</p>
                </div>
                <h4 class="anchor-tag" id="193" name="193"><b>3.3 实验设置</b></h4>
                <div class="p1">
                    <p id="194">我们随机将数据集划分为训练集、测试集、验证集, 其中使用“留一法” (leave-one-out) 构造测试集和验证集, 即保证集合中每个用户有且只有一个样本, 并将测试集和验证集中出现过的评论文本从训练集中删除以避免数据泄漏。同时, 在计算用户<i>u</i>对物品<i>i</i>的预测评分<mathml id="195"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub></mrow></math></mathml>时把用户撰写的真实评论文本<i>review</i><sub><i>ui</i></sub>从用户评论集合和物品评论集合中删除, 避免从一个推荐任务退化为一个带噪声的情感分类任务。</p>
                </div>
                <div class="p1">
                    <p id="196">我们在Tensorflow中实现了所有的模型并使用了Adam<citation id="499" type="reference"><link href="447" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>进行优化, 初始学习率设定为0.002。将所有模型训练至连续5轮验证集性能都不再提升, 使用“早停” (early stopping) 选择验证集上表现最佳的模型参数, 并汇报最佳参数在测试集上的结果。实验中发现, MF需要35轮左右才能收敛, 其他模型都在20轮以内收敛。我们重复实验20次, 并汇报平均结果。</p>
                </div>
                <h4 class="anchor-tag" id="197" name="197"><b>3.3.1 评价指标</b></h4>
                <div class="p1">
                    <p id="198">本文使用均方误差 (MSE) 来评估模型的性能。MSE广泛应用于推荐系统中的评分预测任务, 较低的MSE代表好的性能。给定用户<i>u</i>对物品<i>i</i>的预测评分<mathml id="199"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub></mrow></math></mathml>和真实评分<i>r</i><sub><i>ui</i></sub>, MSE由下式计算:</p>
                </div>
                <div class="p1">
                    <p id="200" class="code-formula"><mathml id="201"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mi>Ν</mi></mfrac></mrow></math></mathml><mathml id="202"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>u</mi><mo>, </mo><mi>i</mi></mrow></munder><mrow></mrow></mstyle></mrow></math></mathml><mathml id="203"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false"> (</mo><mover accent="true"><mi>r</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub><mo>-</mo><mi>r</mi><msub><mrow></mrow><mrow><mi>u</mi><mi>i</mi></mrow></msub><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="204">式中:<i>N</i>表示用户对物品评分的总数。</p>
                </div>
                <h4 class="anchor-tag" id="205" name="205"><b>3.3.2 参数设置</b></h4>
                <div class="p1">
                    <p id="206">对于矩阵分解模型 (MF) , 将用户 (物品) 向量维度设置为50。对于DeepCoNN和NARRE, 将卷积核窗口大小设置为3。对于D-ATT, 根据原文中的设定将“局部注意力模块”中的卷积核窗口大小设置为3, “全局注意力模块”中的卷积核窗口大小设置为{2, 3, 4}。所有模型的词向量均维度均设置为50, 并使用预训练的Glove<citation id="500" type="reference"><link href="449" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>词向量初始化。对含有隐含因子模型 (LFM) 的交互层中<i>b</i><sub><i>u</i></sub>、<i>b</i><sub><i>i</i></sub>、<i>q</i><sub><i>i</i></sub>、<i>p</i><sub><i>u</i></sub>均使用了系数为0.2的L2正则化。对含有FM的交互层中使用了概率为0.5的dropout, 并将FM中的权重因子维度设置为10。</p>
                </div>
                <h4 class="anchor-tag" id="207" name="207"><b>3.3.3 数据预处理</b></h4>
                <div class="p1">
                    <p id="208">本文将单个评论文本的最大长度设置为30个单词, 评论集合中最多包含20个评论。在实验中, 我们发现这样设置可以比较合理地反映不同模型的性能。对于DeepCoNN和D-ATT, 将评论集合中所有评论拼接。</p>
                </div>
                <h4 class="anchor-tag" id="209" name="209"><b>3.4 实验结果</b></h4>
                <h4 class="anchor-tag" id="210" name="210"><b>3.4.1 模型总体表现</b></h4>
                <div class="p1">
                    <p id="211">表2中汇报了实验结果。对于“问题1”, 我们发现SCRM在四个数据集上都是表现最好的。表3中汇报了SCRM相对于其他模型的提升, 其中本文基于提升= (<i>MSE</i><sub>high</sub>-<i>MSE</i><sub>low</sub>) /<i>MSE</i><sub>high</sub>×100%计算模型之间的相对提升。“提升1”-“提升3”分别表示SCRM相对于DeepCoNN、D-ATT和NARRE的提升百分比, “提升4”表示SCRM相对于表现最好的模型的提升百分比。SCRM稳定而显著地超过了近来有竞争力的基于评论的推荐模型DeepCoNN、D-ATT和NARRE (统计显著性<i>p</i>&lt;0.01) , 其中提升最多达到13.0% (DeepCoNN) 、4.6% (D-ATT) 和5.6% (NARRE) , 相对其中表现最好的模型提升最多达到3.8%。提升平均为8.8% (DeepCoNN) 、3.58% (D-ATT) 和4.0% (NARRE) , 相对表现最好的模型提升平均达到3.3%。SCRM通过层次化的细粒度建模和动态适应交互场景的特征表示, 全面地超过了现有方法。</p>
                </div>
                <div class="area_img" id="212">
                    <p class="img_tit"><b>表2 模型总体表现对比 (统计显著性<i>p</i>&lt;0.01</b>)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="212" border="1"><tr><td>模型</td><td>Music</td><td>Toy</td><td>Phone</td><td>Office</td></tr><tr><td><br />MF</td><td>1.306</td><td>2.230</td><td>3.249</td><td>1.190</td></tr><tr><td><br />DeepCoNN</td><td>1.006</td><td>0.911</td><td>1.439</td><td>0.867</td></tr><tr><td><br />D-ATT</td><td>0.917</td><td>0.866</td><td>1.403</td><td>0.820</td></tr><tr><td><br />NARRE</td><td>0.905</td><td>0.882</td><td>1.411</td><td>0.824</td></tr><tr><td><br />SCRM</td><td>0.875</td><td>0.833</td><td>1.360</td><td>0.797</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="213">
                    <p class="img_tit"><b>表3 SCRM性能提升百分比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="213" border="1"><tr><td><br />模型 (%) </td><td>Music</td><td>Toy</td><td>Phone</td><td>Office</td></tr><tr><td><br />提升1</td><td>13.0</td><td>8.6</td><td>5.5</td><td>8.1</td></tr><tr><td><br />提升2</td><td>4.6</td><td>3.8</td><td>3.1</td><td>2.8</td></tr><tr><td><br />提升3</td><td>3.3</td><td>5.6</td><td>3.6</td><td>3.3</td></tr><tr><td><br />提升4</td><td>3.3</td><td>3.8</td><td>3.1</td><td>2.8</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="214">此外我们发现, D-ATT和NARRE的表现稳定地超过DeepCoNN, 这来源于它们对在“单词”层面或“评论”层面对评论更细粒度的处理。D-ATT和NARRE的相对排名在不同数据集上的有所不同, 我们认为不同领域对于“单词”层面和“评论”层面的关注程度不同。NARRE在Digital Music数据集上超过了D-ATT, 因为在音乐领域用户的兴趣相对更加多样性和主观性的, 因此在“评论”层面对每个评论独立建模更有助于区分不同方面的兴趣。D-ATT在其他三个数据集上表现更好, 例如Toys and Games数据集上, 我们观察到大多是父母为孩子买玩具, 相对于音乐电影等文化产品而言兴趣相对集中, 此时“单词”层面的细粒度建模就会体现出更大的作用, 可以更清晰地反映用户的具体兴趣。与两个基线模型不同的是, SCRM在不同领域上都有良好的表现, 这来源于兼顾多层面的用户兴趣建模, 使得两个层面相辅相成、互相促进。例如在Digital Music数据集上SCRM相对D-ATT和 NARRE的提高分别为4.6%和3.3%, 根据领域特点SCRM更多弥补了“评论”层面的缺失。相反地, 在Toys and Games数据集上提高分别为3.8%和5.6%, SCRM更多弥补了“单词”层面的缺失。</p>
                </div>
                <h4 class="anchor-tag" id="215" name="215"><b>3.4.2</b> “<b>单词”层建模:缓解了单词上下文丢失</b></h4>
                <div class="p1">
                    <p id="216">对于“问题2”, 本文设计了实验来比较D-ATT与SCRM在只有“单词”层面建模的情况下性能。为了公平起见, 我们对两个模型做了两点修改:首先, 保证它们都只在“单词层面”上建模, 并且将评论集合中所有评论拼接作为输入。其次, 保证它们具有相同的交互层, 避免交互层不同带来的影响。具体地, 本文将修改后的D-ATT命名为“D-ATT-2”, 其中只保留了局部注意力模块 (SCRM也在“单词”层面只考虑局部上下文) , 在交互层更换为FM。SCRM修改后命名为“SCRM-2”, 只保留“单词”层面的gated CNN, 去除了“评论”层面的部分, 并在交互层只使用FM。</p>
                </div>
                <div class="p1">
                    <p id="217">表4汇报了在四个数据集上“D-ATT-2”和“SCRM-2”的结果, 并将原始的D-ATT模型的结果作为参照。“提升”一行表示“SCRM-2”相对“D-ATT-2”的性能提升。</p>
                </div>
                <div class="area_img" id="218">
                    <p class="img_tit"><b>表4</b> “<b>单词”层面表现对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="218" border="1"><tr><td>模型</td><td>Music</td><td>Toy</td><td>Phone</td><td>Office</td></tr><tr><td><br />D-ATT</td><td>0.917</td><td>0.866</td><td>1.403</td><td>0.82</td></tr><tr><td><br />D-ATT-2</td><td>0.939</td><td>0.876</td><td>1.412</td><td>0.829</td></tr><tr><td><br />SCRM-2</td><td>0.912</td><td>0.863</td><td>1.399</td><td>0.812</td></tr><tr><td><br />提升/%</td><td>2.9</td><td>1.4</td><td>0.9</td><td>2.0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="219">我们发现, 在四个数据集上, SCRM-2在“单词”层面的表现都超过了D-ATT-2。我们认为这是D-ATT“单词”层面存在单词上下文丢失的问题引起的。D-ATT利用局部注意力机制给予每个单词不同权重来选择重要的单词, 然后再将过滤后的评论送入CNN中编码每个单词的上下文表示。例如, 评论中的一句话“I like Memory Of Trees too.”, Memory Of Trees是一首歌曲的名字。在D-ATT中, 局部注意力根据上下文“Memory Of Trees”会保留中心词“Of”, 因为这三个词经常作为词组出现, 但是根据上下文“like Memory Of”丢弃中心词“Memory”, 根据上下文“Of Trees too”会丢弃中心词“Trees”, 因为它的上下文没有特殊意义。过滤后的评论表示变为“xxx like xxx Of xxx xxx”的形式, 此时CNN再希望编码“Memory Of Trees”作为一个整体词组的表示时, 已经丢失了“Of”的上下文“Memory”和“Trees”。</p>
                </div>
                <div class="p1">
                    <p id="220">相反, SCRM先编码滑动窗口内每个单词上下文表示, 然后再过滤有意义的单词上下文或词组。例如, 先在gated CNN得到所有三元组“I like Memory”、“like Memory Of”、” Memory Of Trees”、“Of Trees too”, 再利用“门机制”过滤得到“I like Memory”和” Memory Of Trees”两个有意义的三元组。最后将“I like Memory”中无意义的部分过滤, 得到“xxx like xxx”和” Memory Of Trees”, 它们表达了用户对歌曲喜爱的情感。此外, gated CNN中的“门机制”与“注意力机制”不同, “注意力机制”为每个单词上下文向量<b><i>a</i></b>∈ℝ<sup><i>d</i></sup>生成一个标量权重<b><i>w</i></b>∈ℝ<sup>1</sup>, 而“门机制”生成权重向量<b><i>w</i></b>∈ℝ<sup><i>d</i></sup>, 更加细粒度地过滤相关特征。</p>
                </div>
                <h4 class="anchor-tag" id="221" name="221"><b>3.4.3</b> “<b>评论”层建模:场景上下文的作用</b></h4>
                <div class="p1">
                    <p id="222">对于“问题3”, 本文设计了实验来评估在“评论”层面的引入场景上下文的方法相对于只是从评论有用性的角度计算评论的权重的NARRE是否带来了性能的提升。为了公平起见, 本文也对NARRE进行了修改:原本NARRE没有在“单词”层面过滤有效信息, 因此为它加入word-level gated CNN保证两个模型在“单词”层面相同, 然后比较它们在“评论”层面建模的差异。此外, 两个模型在交互层也略有不同, 但是都是将LFM扩展成“基于评分”和“基于评论”两部分, 这里把交互层都统一改为FM。本文将修改后的NARRE命名为“NARRE-3”和“SCRM-3”。表5汇报了在四个数据集上的结果, 并将原始的NARRE模型的结果作为参照。“提升”一行表示“SCRM-3”相对“NARRE-3”的性能提升。</p>
                </div>
                <div class="area_img" id="223">
                    <p class="img_tit"><b>表5</b> “<b>评论”层面表现对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="223" border="1"><tr><td><br />模型</td><td>Music</td><td>Toy</td><td>Phone</td><td>Office</td></tr><tr><td><br />NARRE</td><td>0.905</td><td>0.882</td><td>1.411</td><td>0.824</td></tr><tr><td><br />NARRE-4</td><td>0.903</td><td>0.864</td><td>1.385</td><td>0.819</td></tr><tr><td><br />NARRE-3</td><td>0.906</td><td>0.868</td><td>1.389</td><td>0.818</td></tr><tr><td><br />SCRM-3</td><td>0.875</td><td>0.832</td><td>1.362</td><td>0.794</td></tr><tr><td><br />提升/%</td><td>3.0</td><td>3.6</td><td>1.8</td><td>2.6</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="224">我们发现, 在四个数据集上SCRM-3在“评论”层面的表现都超过了NARRE-3。NARRE在“评论”层面使用注意力机制给予每个评论表示权重, 并进行平均池化为一个固定维度的向量作为用户 (物品) 表示。在交互层之前, 用户表示和物品表示都没有联系, 反映的是静态的用户兴趣和物品性质。SCRM考虑到交互场景的不同对用户和物品表示的影响, 在平均池化之前编码了每个评论的场景上下文, 并与原表示融合, 生成动态的用户和物品表示, 消除了场景无关的信息, 突出了场景中重要的特征。</p>
                </div>
                <div class="p1">
                    <p id="225">此外, 我们尝试保留NARRE的原始交互层, 但是加入“单词”层面模块, 表5中的“NARRE-4”一行汇报了相应的结果。将第一行和第二行的“NARRE”和“NARRE-4”比较, 我们发现增加“单词”层面的建模对Digital Music数据集提升不大, 但是其他三个数据集均有明显提升。这再次验证了在问题1中的推断:不同领域中用户兴趣的多样性程度不同, 音乐电影等领域中“评论”层面的建模显得更加重要。</p>
                </div>
                <h4 class="anchor-tag" id="226" name="226"><b>3.4.4 层次化建模的作用</b></h4>
                <div class="p1">
                    <p id="227">对于“问题4”, 本文设计了实验比较只有“单词”层面建模和同时在“单词”和“评论”两个层面建模的不同, 将这两种的情况命名为“SCRM-4”和“SCRM-5”。表6汇报了在四个数据集上比较的结果。“提升”一栏表示“两个层面”同时建模相对于只有“单词”层面建模的提升。</p>
                </div>
                <div class="area_img" id="228">
                    <p class="img_tit"><b>表6 单层建模与层次化建模表现对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="228" border="1"><tr><td><br />模型</td><td>Music</td><td>Toy</td><td>Phone</td><td>Office</td></tr><tr><td><br />SCRM-4</td><td>0.888</td><td>0.843</td><td>1.373</td><td>0.803</td></tr><tr><td><br />SCRM-5</td><td>0.875</td><td>0.833</td><td>1.36</td><td>0.797</td></tr><tr><td><br />提升/%</td><td>1.4</td><td>1.2</td><td>0.9</td><td>0.7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="229">我们发现, 同时在“单词”和“评论”两个层面建模, 相比只在“单词”层面有了提高。层次化的特征抽取一方面对“评论内特征”进行了更细粒度的抽取, 另一方面通过独立建模每个评论, 对不同评论所代表的多方面兴趣的进行区分并融合场景信息, 更好地突出了场景中显著的某一方面的兴趣。此外, 在表5中我们发现“NARRE-4”超过了原始的NARRE, 再次证明了多层次建模的必要性。</p>
                </div>
                <h3 id="230" name="230" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="231">在推荐系统中, 只根据“用户-物品评分矩阵”推断出用户和物品的表示, 在数据稀疏时会出现严重的冷启动问题, 从评论文本中挖掘用户兴趣和物品性质作为补充成为主流的方法。</p>
                </div>
                <div class="p1">
                    <p id="232">本文主要的贡献是: (1) 同时在“单词”和“评论”层面更加细粒度地从评论文本中抽取特征。 (2) 在“单词”层面, 编码每个单词的局部上下文表示、过滤相关的上下文特征, 并缓解了D-ATT<citation id="505" type="reference">[<a class="sup">1</a>]</citation>中单词上下文丢失的情况, 保留更丰富的语义。 (3) 在“评论”层面, 编码每个评论在当前交互场景中的上下文, 动态生成用户和物品表示, 突出在当前交互场景中决定用户打分的主要因素。 (4) 在多个数据集上进行了实验。SCRM在每个数据集上都显著地超过了基准MF、DeepCoNN、D-ATT和NARRE, 并在“单词”层面超过了D-ATT, 在“评论”层面超过了NARRE。</p>
                </div>
                <div class="p1">
                    <p id="233">但是SCRM仍然存在一些不足之处:第一, 对于单个评论仍然将评论内所有句子拼接, 丢失了句子级别的语义。第二, 对于每个单词而言, 只编码了局部的上下文, 没有更进一步的复杂语义, 例如“我喜欢在周末听Memory Of Trees”中“周末”代表的时间场景和歌曲“Memory Of Trees”不能建立关系。</p>
                </div>
                <div class="p1">
                    <p id="234">本研究对“层次化的评论建模”和“场景相关的推荐”提供了一些新思路, 我们将来的方向是, 加入“句子”层面的细粒度兴趣建模以抽取更丰富的语义关系。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="413">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Interpretable Convolutional Neural Networks with Dual Local and Global Attention for Review Rating Prediction">

                                <b>[1]</b>Seo S, Huang J, Yang H, et al.Interpretable convolutional neural networks with dual local and global attention for review rating prediction[C]//Proceedings of the Eleventh ACM Conference on Recommender Systems.ACM, 2017:297-305.
                            </a>
                        </p>
                        <p id="415">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Neural attentional rating regression with review-level explanations">

                                <b>[2]</b>Chen C, Zhang M, Liu Y, et al.Neural attentional rating regression with review-level explanations[C]//Proceedings of the 2018 World Wide Web Conference on World Wide Web.International World Wide Web Conferences Steering Committee, 2018:1583-1592.
                            </a>
                        </p>
                        <p id="417">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Joint deep modeling of users and items using reviews for recommendation">

                                <b>[3]</b>Zheng L, Noroozi V, Yu P S.Joint deep modeling of users and items using reviews for recommendation[C]//Proceedings of the Tenth ACM International Conference on Web Search and Data Mining.ACM, 2017:425-434.
                            </a>
                        </p>
                        <p id="419">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Matrix Factorization Techniques for Recommender Systems">

                                <b>[4]</b>Koren Y, Bell R, Volinsky C.Matrix factorization techniques for recommender systems[J].Computer, 2009 (8) :30-37.
                            </a>
                        </p>
                        <p id="421">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Factorization Machines">

                                <b>[5]</b>Rendle S.Factorization machines[C]//Proceedings of the2010 IEEE International Conference on Data Mining.IEEE, 2010:995-1000.
                            </a>
                        </p>
                        <p id="423">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Language modeling with gated convolutional networks[EB]">

                                <b>[6]</b>Dauphin Y N, Fan A, Auli M, et al.Language modeling with gated convolutional networks[EB].ar Xiv preprint ar X-iv:1612.08083, 2016.
                            </a>
                        </p>
                        <p id="425">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural networks for sentence classification[EB]">

                                <b>[7]</b>Kim Y.Convolutional neural networks for sentence classification[EB].ar Xiv preprint ar Xiv:1408.5882, 2014.
                            </a>
                        </p>
                        <p id="427">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A convolutional neural network for modelling sentences[EB]">

                                <b>[8]</b>Kalchbrenner N, Grefenstette E, Blunsom P.A convolutional neural network for modelling sentences[EB].ar Xiv preprint ar Xiv:1404.2188, 2014.
                            </a>
                        </p>
                        <p id="429">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MDA0OTRvTERYVXhvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRjBSYVJVPU5pZkpaYks5SHRqTXFvOUZaTw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b>Hochreiter S, Schmidhuber J.Long short-term memory[J].Neural computation, 1997, 9 (8) :1735-1780.
                            </a>
                        </p>
                        <p id="431">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Conditional image generation with pixelCNN decoders">

                                <b>[10]</b>van den Oord A, Kalchbrenner N, Espeholt L, et al.Conditional image generation with pixelcnn decoders[C]//Advances in Neural Information Processing Systems.2016:4790-4798.
                            </a>
                        </p>
                        <p id="433">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional sequence to sequence learning[EB]">

                                <b>[11]</b>Gehring J, Auli M, Grangier D, et al.Convolutional sequence to sequence learning[EB].ar Xiv preprint ar Xiv:1705.03122, 2017.
                            </a>
                        </p>
                        <p id="435">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Natural language processing (almost) from scratch">

                                <b>[12]</b>Collobert R, Weston J, Bottou L, et al.Natural language processing (almost) from scratch[J].Journal of Machine Learning Research, 2011, 12:2493-2537.
                            </a>
                        </p>
                        <p id="437">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Key-value memory networks for directly reading documents[EB]">

                                <b>[13]</b>Miller A, Fisch A, Dodge J, et al.Key-value memory networks for directly reading documents[EB].ar Xiv preprint ar Xiv:1606.03126, 2016.
                            </a>
                        </p>
                        <p id="439">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Attention is all you need">

                                <b>[14]</b>Vaswani A, Shazeer N, Parmar N, et al.Attention is all you need[C]//Advances in Neural Information Processing Systems.2017:5998-6008.
                            </a>
                        </p>
                        <p id="441">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning to attend and to rank with word-entity duets">

                                <b>[15]</b>Xiong C, Callan J, Liu T Y.Learning to attend and to rank with word-entity duets[C]//Proceedings of the annual international ACM SIGIR conference on research and development in information retrieval.2017, 763:772.
                            </a>
                        </p>
                        <p id="443">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Network in network[EB]">

                                <b>[16]</b>Lin M, Chen Q, Yan S.Network in network[EB].ar Xiv preprint ar Xiv:1312.4400, 2013.
                            </a>
                        </p>
                        <p id="445">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ups and downs:Modeling the visual evolution of fashion trends with one-class collaborative filtering">

                                <b>[17]</b>He R, McAuley J.Ups and downs:Modeling the visual evolution of fashion trends with one-class collaborative filtering[C]//Proceedings of the 25th international conference on world wide web.International World Wide Web Conferences Steering Committee, 2016:507-517.
                            </a>
                        </p>
                        <p id="447">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adam:A method for stochastic optimization[EB]">

                                <b>[18]</b>Kingma D P, Ba J.Adam:A method for stochastic optimization[EB].ar Xiv preprint ar Xiv:1412.6980, 2014.
                            </a>
                        </p>
                        <p id="449">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Glove:Global Vectors for Word Representation">

                                <b>[19]</b>Pennington J, Socher R, Manning C.Glove:Global vectors for word representation[C]//Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) .2014:1532-1543.
                            </a>
                        </p>
                        <p id="451">
                            <a id="bibliography_20" >
                                    <b>[20]</b>
                                Blei D M, Ng A Y, Jordan M I.Latent dirichlet allocation[J].Journal of machine Learning research, 2003, 3:993-1022.
                            </a>
                        </p>
                        <p id="453">
                            <a id="bibliography_21" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Hidden factors and hidden topics:understanding rating dimensions with review text">

                                <b>[21]</b>McAuley J, Leskovec J.Hidden factors and hidden topics:understanding rating dimensions with review text[C]//Proceedings of the 7th ACM conference on Recommender systems.ACM, 2013:165-172.
                            </a>
                        </p>
                        <p id="455">
                            <a id="bibliography_22" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ratings meet reviews, a combined approach to recommend">

                                <b>[22]</b>Ling G, Lyu M R, King I.Ratings meet reviews, a combined approach to recommend[C]//Proceedings of the 8th ACM Conference on Recommender systems.ACM, 2014:105-112.
                            </a>
                        </p>
                        <p id="457">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Explicit factor models for explainable recommendation based on phrase-level sentiment analysis">

                                <b>[23]</b>Zhang Y, Lai G, Zhang M, et al.Explicit factor models for explainable recommendation based on phrase-level sentiment analysis[C]//Proceedings of the 37th international ACM SI-GIR conference on Research&amp;development in information retrieval.ACM, 2014:83-92.
                            </a>
                        </p>
                        <p id="459">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Trirank:Review-aware explainable recommendation by modeling aspects">

                                <b>[24]</b>He X, Chen T, Kan M Y, et al.Trirank:Review-aware explainable recommendation by modeling aspects[C]//Proceedings of the 24th ACM International on Conference on Information and Knowledge Management.ACM, 2015:1661-1670.
                            </a>
                        </p>
                        <p id="461">
                            <a id="bibliography_25" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Rating-Boosted Latent Topics:Understanding Users and Items with Ratings and Reviews">

                                <b>[25]</b>Tan Y, Zhang M, Liu Y, et al.Rating-Boosted Latent Topics:Understanding Users and Items with Ratings and Reviews[C]//IJCAI.2016:2640-2646.
                            </a>
                        </p>
                        <p id="463">
                            <a id="bibliography_26" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Social Collaborative Viewpoint Regression with Explainable Recommendations">

                                <b>[26]</b>Ren Z, Liang S, Li P, et al.Social collaborative viewpoint regression with explainable recommendations[C]//Proceedings of the tenth ACM international conference on web search and data mining.ACM, 2017:485-494.
                            </a>
                        </p>
                        <p id="465">
                            <a id="bibliography_27" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Key-value memory networks for directly reading documents[EB]">

                                <b>[27]</b>Miller A, Fisch A, Dodge J, et al.Key-value memory networks for directly reading documents[EB].ar Xiv preprint ar Xiv:1606.03126, 2016.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201908027" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201908027&amp;v=MjA0Njc0SDlqTXA0OUhZNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWptVnJ6TUx6VFpaTEc=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
