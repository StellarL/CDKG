<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135597785783750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201909039%26RESULT%3d1%26SIGN%3dZ5xe%252bFRuElU6%252b7lkCVKUA1rnw2M%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909039&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909039&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909039&amp;v=MDEzNTA1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlqa1VMdkJMelRaWkxHNEg5ak1wbzlHYllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;1 相关工作&lt;/b&gt; "><b>1 相关工作</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#44" data-title="&lt;b&gt;2 方 法&lt;/b&gt; "><b>2 方 法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#47" data-title="&lt;b&gt;2.1 改进的AlexNet模型&lt;/b&gt;"><b>2.1 改进的AlexNet模型</b></a></li>
                                                <li><a href="#54" data-title="&lt;b&gt;2.2 同步深度监督策略——SDS&lt;/b&gt;"><b>2.2 同步深度监督策略——SDS</b></a></li>
                                                <li><a href="#78" data-title="&lt;b&gt;2.3 多尺度空间金字塔池化策略——MSPP&lt;/b&gt;"><b>2.3 多尺度空间金字塔池化策略——MSPP</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="&lt;b&gt;3 实验结果及分析&lt;/b&gt; "><b>3 实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="&lt;b&gt;3.1 数据集描述&lt;/b&gt;"><b>3.1 数据集描述</b></a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;3.2 实验方案&lt;/b&gt;"><b>3.2 实验方案</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;3.3 评价标准&lt;/b&gt;"><b>3.3 评价标准</b></a></li>
                                                <li><a href="#95" data-title="&lt;b&gt;3.4 模型性能比较&lt;/b&gt;"><b>3.4 模型性能比较</b></a></li>
                                                <li><a href="#101" data-title="&lt;b&gt;3.5 不同分类器同步监督结果比较&lt;/b&gt;"><b>3.5 不同分类器同步监督结果比较</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;3.6 多层次池化结果比较&lt;/b&gt;"><b>3.6 多层次池化结果比较</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="图1 整体模型架构图">图1 整体模型架构图</a></li>
                                                <li><a href="#51" data-title="&lt;b&gt;表1 AlexNet模型改进前后对比&lt;/b&gt;"><b>表1 AlexNet模型改进前后对比</b></a></li>
                                                <li><a href="#56" data-title="图2 SDS的执行过程示意图">图2 SDS的执行过程示意图</a></li>
                                                <li><a href="#80" data-title="图3 多尺度ROI图">图3 多尺度ROI图</a></li>
                                                <li><a href="#84" data-title="图4 MSPP网络结构图">图4 MSPP网络结构图</a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;表2 评价指标计算公式&lt;/b&gt;"><b>表2 评价指标计算公式</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;表3 基于LIDC数据集的肺结节分类不同算法比较&lt;/b&gt;"><b>表3 基于LIDC数据集的肺结节分类不同算法比较</b></a></li>
                                                <li><a href="#98" data-title="图5 不同模型的ROC曲线图">图5 不同模型的ROC曲线图</a></li>
                                                <li><a href="#103" data-title="图6 不同分类器性能比较">图6 不同分类器性能比较</a></li>
                                                <li><a href="#107" data-title="图7 多层次池化结果比较">图7 多层次池化结果比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Siegel R L,Miller K D,Jemal A.Cancer statistics,2018[J].CA:A Cancer Journal For Clinicians,2018,68(suppl 12):277-300." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Cancer statistics,2018">
                                        <b>[1]</b>
                                         Siegel R L,Miller K D,Jemal A.Cancer statistics,2018[J].CA:A Cancer Journal For Clinicians,2018,68(suppl 12):277-300.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Suzuki K.Computer-Aided Detection of Lung Cancer[M]//Image-Based Computer-Assisted Radiation Therapy.Springer Singapore,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Computer-Aided Detection of Lung Cancer">
                                        <b>[2]</b>
                                         Suzuki K.Computer-Aided Detection of Lung Cancer[M]//Image-Based Computer-Assisted Radiation Therapy.Springer Singapore,2017.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Li X X,Li B,Tian L F,et al.Automatic benign and malignant classification of pulmonary nodules in thoracic computed tomography based on RF algorithm[J].Iet Image Processing,2018,12(7):1253-1264." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Automatic benign and malignant classification of pulmonary nodules in thoracic computed tomography based on RF algorithm">
                                        <b>[3]</b>
                                         Li X X,Li B,Tian L F,et al.Automatic benign and malignant classification of pulmonary nodules in thoracic computed tomography based on RF algorithm[J].Iet Image Processing,2018,12(7):1253-1264.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Andersen A H,Haan J M D,Tan Z H,et al.Non-Intrusive Speech Intelligibility Prediction using Convolutional Neural Networks[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2018,26(10):1925-1939." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Non-Intrusive Speech Intelligibility Prediction using Convolutional Neural Networks">
                                        <b>[4]</b>
                                         Andersen A H,Haan J M D,Tan Z H,et al.Non-Intrusive Speech Intelligibility Prediction using Convolutional Neural Networks[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2018,26(10):1925-1939.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Quan W,Wang K,Yan D M,et al.Distinguishing Between Natural and Computer-Generated Images Using Convolutional Neural Networks[J].IEEE Transactions on Information Forensics and Security,2018,13(11):2772-2787." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distinguishing Between Natural and Computer-Generated Images Using Convolutional Neural Networks">
                                        <b>[5]</b>
                                         Quan W,Wang K,Yan D M,et al.Distinguishing Between Natural and Computer-Generated Images Using Convolutional Neural Networks[J].IEEE Transactions on Information Forensics and Security,2018,13(11):2772-2787.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Akcay S,Kundegorski M E,Willcocks C G,et al.Using Deep Convolutional Neural Network Architectures for Object Classification and Detection within X-ray Baggage Security Imagery[J].IEEE Transactions on Information Forensics and Security,2018,13(9):2203-2215." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using Deep Convolutional Neural Network Architectures for Object Classification and Detection within X-ray Baggage Security Imagery">
                                        <b>[6]</b>
                                         Akcay S,Kundegorski M E,Willcocks C G,et al.Using Deep Convolutional Neural Network Architectures for Object Classification and Detection within X-ray Baggage Security Imagery[J].IEEE Transactions on Information Forensics and Security,2018,13(9):2203-2215.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Kyathanahally S P,D&#246;ring A,Kreis R.Deep learning approaches for detection and removal of ghosting artifacts in MR spectroscopy[J].Magnetic Resonance in Medicine,2018,80(3):851-863." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWDA8F2207912D8A88BACFE5692116AA186&amp;v=MjMxNDFPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMbTh4S0U9TmlmY2FzS3dhTlBPcjRoTVplbDdCQTB4eDJSaW1Va0lUWG5ycmhNMGY4UGxSTEtaQw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Kyathanahally S P,D&#246;ring A,Kreis R.Deep learning approaches for detection and removal of ghosting artifacts in MR spectroscopy[J].Magnetic Resonance in Medicine,2018,80(3):851-863.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Almasni M A,Alantari M A,Choi M T,et al.Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks[J].Computer Methods and Programs in Biomedicine,2018,162:221-231." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDF2EB89017F5A2C8C92AF5831DBA3D52&amp;v=MTc4MTVKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeExtOHhLRT1OaWZPZmNmT0hLUytwNFpGWmV4NUNRMDd2QjVnNHowTVBucnFyeE5CQzhPWE1iK2RDT052RlNpV1dyNw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Almasni M A,Alantari M A,Choi M T,et al.Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks[J].Computer Methods and Programs in Biomedicine,2018,162:221-231.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Shen W,Zhou M,Yang F,et al.Multi-scale Convolutional Neural Networks for Lung Nodule Classification[C]//International Conference on Information Processing in Medical Imaging,2015:588-599." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-scale Convolutional Neural Networks for lung nodule classification">
                                        <b>[9]</b>
                                         Shen W,Zhou M,Yang F,et al.Multi-scale Convolutional Neural Networks for Lung Nodule Classification[C]//International Conference on Information Processing in Medical Imaging,2015:588-599.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Ciompi F,De H B,van Riel S J,et al.Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of 2D views and a convolutional neural network out-of-the-box[J].Medical Image Analysis,2015,26(1):195-202." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE0DF32BC1A8A7ADD7A304AB40CE063A6&amp;v=MjM4MTJyTFUwNXR0aHhMbTh4S0U9TmlmT2ZjYTRhcWZQcmYwMlpab0hmWHRJdTJJVW16eDlUQTZRcUJKR0RMS1NSc3VaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Ciompi F,De H B,van Riel S J,et al.Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of 2D views and a convolutional neural network out-of-the-box[J].Medical Image Analysis,2015,26(1):195-202.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Sermanet P,Eigen D,Zhang X,et al.OverFeat:Integrated Recognition,Localization and Detection using Convolutional Networks[EB].arXiv:1312.6229,2013." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=OverFeat:Integrated Recognition,Localization and Detection using Convolutional Networks[EB]">
                                        <b>[11]</b>
                                         Sermanet P,Eigen D,Zhang X,et al.OverFeat:Integrated Recognition,Localization and Detection using Convolutional Networks[EB].arXiv:1312.6229,2013.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Setio A A,Ciompi F,Litjens G,et al.Pulmonary nodule detection in CT images:false positive reduction using multi-view convolutional networks[J].IEEE Transactions on Medical Imaging,2016,35(5):1160-1169." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pulmonary nodule detection in CT images:False positive reduction using multi-view convolutional networks">
                                        <b>[12]</b>
                                         Setio A A,Ciompi F,Litjens G,et al.Pulmonary nodule detection in CT images:false positive reduction using multi-view convolutional networks[J].IEEE Transactions on Medical Imaging,2016,35(5):1160-1169.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Krizhevsky A,Sutskever I,Hinton G E.ImageNet Classification with Deep Convolutional Neural Networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems.2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">
                                        <b>[13]</b>
                                         Krizhevsky A,Sutskever I,Hinton G E.ImageNet Classification with Deep Convolutional Neural Networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems.2012:1097-1105.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Chen S,Tian Y L.Pyramid of Spatial Relatons for Scene-Level Land Use Classification[J].IEEE Transactions on Geoscience and Remote Sensing,2015,53(4):1947-1957." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pyramid of Spatial Relatons for Scene-Level Land Use Classification">
                                        <b>[14]</b>
                                         Chen S,Tian Y L.Pyramid of Spatial Relatons for Scene-Level Land Use Classification[J].IEEE Transactions on Geoscience and Remote Sensing,2015,53(4):1947-1957.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" He K,Zhang X,Ren S,et al.Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence,2015,37(9):1904-1916." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition">
                                        <b>[15]</b>
                                         He K,Zhang X,Ren S,et al.Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition[J].IEEE Transactions on Pattern Analysis &amp;amp; Machine Intelligence,2015,37(9):1904-1916.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Lee C Y,Xie S,Gallagher P,et al.Deeply-Supervised Nets[EB].eprint arXiv:1409.5185,2014." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deeply-Supervised Nets[EB]">
                                        <b>[16]</b>
                                         Lee C Y,Xie S,Gallagher P,et al.Deeply-Supervised Nets[EB].eprint arXiv:1409.5185,2014.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Armato S G,Mclennan G,Bidaut L,et al.The Lung Image Database Consortium(LIDC) and Image Database Resource Initiative(IDRI):A Completed Reference Database of Lung Nodules on CT Scans[J].Academic Radiology,2011,14(12):1455-1463." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Lung Image Database Consortium(LIDC) and Image Database Resource Initiative(IDRI):A Completed Reference Database of Lung Nodules on CT Scans">
                                        <b>[17]</b>
                                         Armato S G,Mclennan G,Bidaut L,et al.The Lung Image Database Consortium(LIDC) and Image Database Resource Initiative(IDRI):A Completed Reference Database of Lung Nodules on CT Scans[J].Academic Radiology,2011,14(12):1455-1463.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Nibali A,He Z,Wollersheim D.Pulmonary nodule classification with deep residual networks[J].International Journal of Computer Assisted Radiology and Surgery,2017,12(10):1799-1808." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDEE5BB467A73534609121595F7A9CA357&amp;v=MDA0MTVZQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeExtOHhLRT1OajdCYXNiTkc2TytxNGxDRmV3TUNYODl5UllhNnoxOFRYYm4yaFZFY01IbFJyKw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Nibali A,He Z,Wollersheim D.Pulmonary nodule classification with deep residual networks[J].International Journal of Computer Assisted Radiology and Surgery,2017,12(10):1799-1808.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(09),214-219 DOI:10.3969/j.issn.1000-386x.2019.09.038            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于同步深度监督的多尺度肺结节分类</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E4%B8%BD&amp;code=08868744&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张丽</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%BA%E5%BD%A6&amp;code=10563303&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">强彦</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%B0%8F%E9%BE%99&amp;code=31712383&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张小龙</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E4%B8%89%E8%99%8E&amp;code=26143456&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王三虎</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%A4%AA%E5%8E%9F%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0077528&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">太原理工大学计算机科学与技术学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%90%95%E6%A2%81%E5%AD%A6%E9%99%A2%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E7%B3%BB&amp;code=1686150&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">吕梁学院计算机科学与技术系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%AE%BE%E5%A4%95%E6%B3%95%E5%B0%BC%E4%BA%9A%E5%B7%9E%E7%AB%8B%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0055578&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">宾夕法尼亚州立大学信息科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对在肺结节分类中容易产生过拟合的问题,提出一种基于同步深度监督的多尺度肺结节分类方法。解决梯度消失问题,最小化分类错误并实现同一框架中同步训练多尺度肺结节图像,提高肺结节分类精确度。改进经典的AlexNet网络,使其更适合肺结节图像分类;将同步深度监督(SDS)策略纳入到AlexNet架构中,向隐藏层提供集成的同步监督;通过多尺度空间金字塔策略提取多尺度肺结节图像特征。实验结果表明,该方法的准确性达到93.68%,且在准确性、敏感度、特异度、ROC曲线下面积值上均优于其他分类方法。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%90%8C%E6%AD%A5%E6%B7%B1%E5%BA%A6%E7%9B%91%E7%9D%A3&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">同步深度监督;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%A4%9A%E5%B0%BA%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">多尺度;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卷积神经网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">特征提取;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张丽,硕士生,主研领域:医学图像处理,深度学习。;
                                </span>
                                <span>
                                    强彦,教授。;
                                </span>
                                <span>
                                    张小龙,教授。;
                                </span>
                                <span>
                                    王三虎,教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-25</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61572344);</span>
                                <span>虚拟现实技术与系统国家重点实验室开放基金项目(VRLAB2018A08);</span>
                                <span>山西省回国留学人员科研项目(2016-038);</span>
                    </p>
            </div>
                    <h1><b>CLASSIFICATION OF MULTI-SCALE LUNG NODULES BASED ON SYNCHRONIZED DEEP SUPERVISION</b></h1>
                    <h2>
                    <span>Zhang Li</span>
                    <span>Qiang Yan</span>
                    <span>Zhang Xiaolong</span>
                    <span>Wang Sanhu</span>
            </h2>
                    <h2>
                    <span>College of Computer Science and Technology, Taiyuan University of Technology</span>
                    <span>Department of Computer Science and Technology,Lvliang University</span>
                    <span>College of Information Science and Technology, Pennsylvania State University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>To solve the problem of over-fitting in the classification of lung nodules, We proposed a classification method of multi-scale lung nodules based on synchronized deep supervision. It solved the problem of gradient disappearance, minimized classification errors, and achieved simultaneous training of multi-scale pulmonary nodule images in the same framework. It improved the accuracy of pulmonary nodule classification. The classic AlexNet network was improved to make it more suitable for the classification of images of lung nodules. The synchronized deep supervision(SDS) strategy was integrated into AlexNet architecture to provide integrated synchronized supervision to the hidden layers. And the multi-scale spatial pyramid strategy was used to extract the features of multi-scale lung nodules. The experimental results show that the accuracy of this method is 93.68%. It is superior to other ones in terms of accuracy, sensitivity, specificity, and area under the ROC curve.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Synchronized%20deep%20supervision&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Synchronized deep supervision;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Multi-scale&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Multi-scale;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Convolutional%20neural%20network&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Convolutional neural network;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Feature%20extraction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Feature extraction;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-25</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="40">肺癌已成为全世界发病率与致死率最高的恶性肿瘤之一<citation id="111" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。肺癌死亡率逐年增高的最主要原因是其早期的病变特征不易被发现,一经确诊,治愈率很低。计算机辅助诊断(CAD)系统<citation id="112" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>能通过帮助放射科医师做出正确的分类决策并降低手动读取扫描所产生的成本,显著提高基于计算机断层扫描(CT)的筛查程序的可行性。本文应用基于同步深度监督的多尺度肺结节分类方法显著提高了CAD系统决策的准确率。</p>
                </div>
                <h3 id="41" name="41" class="anchor-tag"><b>1 相关工作</b></h3>
                <div class="p1">
                    <p id="42">计算机辅助诊断方法在肺癌早期筛查中发挥着重要作用。Li等<citation id="113" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>提出了一种改进的随机森林(RF)算法用于肺结节良恶性分类,在LIDC数据集上达到了0.90的准确率,这是传统的计算机辅助诊断方法。近年来,深度学习已经成功应用于语音识别、图像识别<citation id="118" type="reference"><link href="9" rel="bibliography" /><link href="11" rel="bibliography" /><link href="13" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>,<a class="sup">6</a>]</sup></citation>等领域,在医学图像处理中深度学习技术也得到广泛的应用<citation id="119" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>,其中卷积神经网络(CNN)在肺部医学图像处理中取得一定的研究成果,使用CNN的一个显著优点是它们不需要从图像中手工提取任何类型的特征,而是直接从数据中学习辨别特征。Shen等<citation id="114" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>使用2层卷积神经网络在不同尺度的多个结节上成功地对恶性肺结节进行分类。Ciompi等<citation id="115" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>使用现有的预训练CNN(称为OverFeat<citation id="116" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>,具有8个加权层)对周围结节进行分类。Setio等<citation id="117" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>在不同的结节视图(轴向、冠状、矢状和六个对角线平面)上使用9个独立的CNN(每个有三个卷积层)进行分类,以确定结节的存在。通过将CNN输出与完全连接的层融合来获得最终的分类结果。</p>
                </div>
                <div class="p1">
                    <p id="43">尽管目前的CNN模型在肺部医学图像处理中取得一定的研究成果,但针对肺结节占肺部CT影像面积小且结节大小不一的特点,选择适当的网络架构提取特定输入数据特征仍是一个巨大的挑战。AlexNet<citation id="120" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>由Hinton提出并在2012年ImageNet竞赛中成功使用,与其他结构复杂的深度CNN架构相比(例如GoogLeNet、VGG等),AlexNet是一种结构简单的CNN架构,易于训练和优化,但它并不是针对医学图像的网络模型。针对肺部结节的特征,本文改进了典型的AlexNet模型以适应肺部医学图像的分析与处理。但是改进的AlexNet模型并不能直接处理肺结节的多尺度现象,并且容易产生梯度消失、过拟合等现象。Chen等<citation id="121" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>提出了空间金字塔模型(PSR)来捕获局部特征的绝对和相对空间关系,在遥感图像分类中表现出优异的性能。He等<citation id="122" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>提出了空间金字塔池化策略,用于物体检测和分类任务。Lee等<citation id="123" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>提出深度监督网络,通过对隐藏层使用监督功能,在MNIST、CIFAR-10、CIFAR-100及SVHN等数据集中均取得良好的分类效果。鉴于此,本文提出了基于同步深度监督的多尺度肺结节分类方法。</p>
                </div>
                <h3 id="44" name="44" class="anchor-tag"><b>2 方 法</b></h3>
                <div class="p1">
                    <p id="45">本文充分考虑肺结节的图像特征,改进了AlexNet架构,减小了卷积核尺寸,舍弃了部分池化层,使其能够作为一种简单有效的医学图像分类模型。在该网络模型中为每个隐藏层引入“伴随”目标函数,为隐藏层提供集成的同步监督,以减少分类错误并提高隐藏层学习过程的直接性和透明度。为了处理多尺度肺结节现象,本文将空间金字塔池化作为一种有效的多尺度池化操作添加到网络架构中,以允许该模型能够处理多尺度信息并有效提取对肺结节分类有强影响的特征。整体模型架构如图1所示。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909039_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 整体模型架构图" src="Detail/GetImg?filename=images/JYRJ201909039_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 整体模型架构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909039_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="47" name="47"><b>2.1 改进的AlexNet模型</b></h4>
                <div class="p1">
                    <p id="48">AlexNet主要由卷积层、池化层、整流线性单元(ReLU)层和完全连接层组成。AlexNet较传统神经网络的优势是因为其使用了ReLu激活函数和DropOut正则化技术。如式(1)所示,ReLU具有半波整流器功能,其可以显著加速训练阶段并防止过度拟合。AlexNet通过引入多种权值组合的DropOut方法控制过拟合,在训练过程中,通过将多个输入神经元或隐藏神经元随机设置为零来减少神经元间复杂的互适应。</p>
                </div>
                <div class="p1">
                    <p id="49"><i>f</i>(<i>x</i>)=max(<i>x</i>,0)      (1)</p>
                </div>
                <div class="p1">
                    <p id="50">传统的AlexNet卷积神经网络模型主要用于分辨率较高、图片尺寸较大的图片识别。受限于肺部ROI图像的大小,原AlexNet模型的卷积核过大,不适合处理肺部医学影像数据,因此要针对本文中数据源的特点,对AlexNet模型进行针对性改进。改进后的AlexNet模型对比如表1所示。</p>
                </div>
                <div class="area_img" id="51">
                    <p class="img_tit"><b>表1 AlexNet模型改进前后对比</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="51" border="1"><tr><td rowspan="2"><br />卷积层</td><td colspan="2"><br />经典AlexNet模型</td><td colspan="2">改进后AlexNet模型</td></tr><tr><td><br />卷积核</td><td>步长</td><td>卷积核</td><td>步长</td></tr><tr><td><br />Conv1</td><td>11*11</td><td>4</td><td>5*5</td><td>1</td></tr><tr><td><br />Pool1</td><td>3*3</td><td>2</td><td>3*3</td><td>1</td></tr><tr><td><br />Conv2</td><td>5*5</td><td>1</td><td>5*5</td><td>1</td></tr><tr><td><br />Pool2</td><td>3*3</td><td>2</td><td>—</td><td>—</td></tr><tr><td><br />Conv3</td><td>3*3</td><td>1</td><td>3*3</td><td>1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="52"><b>续表1</b></p>
                </div>
                <div class="area_img" id="53">
                    <p class="img_tit"> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="53" border="1"><tr><td rowspan="2"><br />卷积层</td><td colspan="2"><br />经典AlexNet模型</td><td colspan="2">改进后AlexNet模型</td></tr><tr><td><br />卷积核</td><td>步长</td><td>卷积核</td><td>步长</td></tr><tr><td><br />Conv4</td><td>3*3</td><td>1</td><td>3*3</td><td>1</td></tr><tr><td><br />Conv5</td><td>3*3</td><td>1</td><td>—</td><td>—</td></tr><tr><td><br />Pool5</td><td>3*3</td><td>2</td><td>—</td><td>—</td></tr><tr><td><br /></td><td colspan="2">向量个数</td><td colspan="2">向量个数</td></tr><tr><td><br />Fc6</td><td colspan="2">4 096</td><td colspan="2">250</td></tr><tr><td><br />Fc7</td><td colspan="2">4 096</td><td colspan="2">100</td></tr><tr><td><br />Fc8</td><td colspan="2">1 000</td><td colspan="2">2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="54" name="54"><b>2.2 同步深度监督策略——SDS</b></h4>
                <div class="p1">
                    <p id="55">改进的AlexNet架构是一种有效的端到端肺部医学影像数据分类框架,但当前框架存在三个明显的问题。第一个问题是在整个分类过程中,中间层的不透明性使得训练过程难以观察。第二个问题涉及学习特征的鲁棒性和判别能力,特别是在网络的后一层,会严重影响性能。第三个问题是在梯度“爆炸”和“消失”的情况下,训练效果差。为了更好地处理当前改进的AlexNet架构中存在的问题,将同步深度监督策略纳入到改进的AlexNet架构中。这种方法可以同时最小化分类错误并提高隐藏层学习过程的直接性和透明度。SDS的核心思想旨在为隐藏层提供集成的同步监督,这与仅在输出层提供监督并将该监督传播回早期层的标准方法形成对比。SDS为每个隐藏层引入“伴随”目标函数,这些伴随目标函数可以被视为学习过程中的附加约束。图2表示SDS的执行过程。</p>
                </div>
                <div class="area_img" id="56">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909039_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 SDS的执行过程示意图" src="Detail/GetImg?filename=images/JYRJ201909039_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 SDS的执行过程示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909039_056.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="57">为了更好地理解融合SDS策略的AlexNet架构,下面给出了一个例子。假设输入样值<i>X</i><sub><i>i</i></sub>∈<b><i>R</i></b><sup><i>n</i></sup>表示原始输入数据,<i>y</i><sub><i>i</i></sub>∈{1,2,…,<i>K</i>}表示样本<i>X</i><sub><i>i</i></sub>所对应的标签。假设改进的AlexNet架构中总共有<i>M</i>个层,其权重组合是<i>W</i>=(<i>W</i><sup>(1)</sup>,<i>W</i><sup>(2)</sup>,…,<i>W</i><sup>(<i>M</i>)</sup>)。改进的AlexNet架构的每个隐藏层中的分类器,相应的权重是<i>w</i>=(<i>W</i><sup>(1)</sup>,<i>W</i><sup>(2)</sup>,…,<i>W</i><sup>(<i>M</i>-1)</sup>)。在改进的AlexNet架构中,权重参数和滤波器之间的关系分别为:</p>
                </div>
                <div class="p1">
                    <p id="58"><i>Z</i><sup>(<i>m</i>)</sup>=<i>f</i>(<i>Q</i><sup>(<i>m</i>)</sup>),<i>Z</i><sup>(0)</sup>=<i>X</i>      (2)</p>
                </div>
                <div class="p1">
                    <p id="59"><i>Q</i><sup>(<i>m</i>)</sup>=<i>W</i><sup>(<i>m</i>)</sup>×<i>Z</i><sup>(<i>m</i>-1)</sup>      (3)</p>
                </div>
                <div class="p1">
                    <p id="60">式中:<i>m</i>指网络中的特定层;<i>W</i><sup>(<i>M</i>)</sup>,<i>m</i>=1,2,…,<i>M</i>是要学习的网络权重;<i>Z</i><sup>(<i>m</i>-1)</sup>为第<i>m</i>-1层的特征图,<i>Q</i><sup>(<i>m</i>)</sup>为先前特征图上的卷积响应;<i>f</i>()为<i>Q</i>上的池化函数。本文网络架构的总目标函数如下式:</p>
                </div>
                <div class="p1">
                    <p id="61"><i>F</i>(<i>W</i>)=<i>P</i>(<i>W</i>)+<i>Q</i>(<i>W</i>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="62">式中:<i>P</i>(<i>W</i>)和<i>Q</i>(<i>W</i>)分别为输出目标和总伴随目标,其定义如下:</p>
                </div>
                <div class="p1">
                    <p id="63"><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>|</mo><mrow><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow></msup></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo>,</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="65"><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mo stretchy="false">[</mo></mstyle><mrow><mo>|</mo><mrow><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>Μ</mi><mo stretchy="false">)</mo></mrow></msup></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>l</mi><mo stretchy="false">(</mo><mi>W</mi><mo>,</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>-</mo><mi>r</mi><mo stretchy="false">]</mo><msub><mrow></mrow><mo>+</mo></msub></mrow></math></mathml>      (6)</p>
                </div>
                <div class="p1">
                    <p id="67">式中:<i>M</i>表示网络总层数,<i>w</i><sup>(out)</sup>是指输出层的分类器权重。改进的AlexNet架构的最终组合目标函数定义如下:</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow></msup></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo>,</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>Μ</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>m</mi></msub><mo stretchy="false">[</mo><mrow><mo>|</mo><mrow><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msup></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>l</mi><mo stretchy="false">(</mo><mi>W</mi><mo>,</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>-</mo><mi>r</mi><mo stretchy="false">]</mo><msub><mrow></mrow><mo>+</mo></msub><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">式中:<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow></msup></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>和<i>L</i>(<i>W</i>,<i>w</i><sup>(out)</sup>)分别是向量机分类器在输出层的边缘和总铰链损失。<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msup></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>和<i>l</i>(<i>W</i>,<i>w</i><sup>(<i>m</i>)</sup>)分别是向量机分类器在每个隐藏层的边缘和伴随铰链损失。</p>
                </div>
                <div class="p1">
                    <p id="72">式(7)中输出层<i>L</i>(<i>W</i>,<i>w</i><sup>(out)</sup>)的总损失为:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>W</mi><mo>,</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub><mo>≠</mo><mi>y</mi></mrow></munder><mo stretchy="false">[</mo></mstyle><mn>1</mn><mo>-</mo><mo>〈</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mtext>o</mtext><mtext>u</mtext><mtext>t</mtext><mo stretchy="false">)</mo></mrow></msup><mo>,</mo><mtext>ϕ</mtext><mo stretchy="false">(</mo><mi>Ζ</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>Μ</mi><mo stretchy="false">)</mo></mrow></msup><mo>,</mo><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>〉</mo><mo stretchy="false">]</mo><msubsup><mrow></mrow><mo>+</mo><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">在式(7)中,作为隐藏层的伴随损失<i>l</i>(<i>W</i>,<i>w</i><sup>(<i>m</i>)</sup>)为:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>W</mi><mo>,</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub><mo>≠</mo><mi>y</mi></mrow></munder><mo stretchy="false">[</mo></mstyle><mn>1</mn><mo>-</mo><mo>〈</mo><mi>w</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msup><mo>,</mo><mtext>ϕ</mtext><mo stretchy="false">(</mo><mi>Ζ</mi><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mi>Μ</mi><mo stretchy="false">)</mo></mrow></msup><mo>,</mo><mi>y</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">)</mo><mo>〉</mo><mo stretchy="false">]</mo><msubsup><mrow></mrow><mo>+</mo><mn>2</mn></msubsup><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>9</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">式(8)和式(9)都是预测误差的铰链损失,可以看出,改进的AlexNet架构不仅学习卷积核<i>W</i><sup>*</sup>,而且在每个隐藏层中强制执行约束,以直接进行良好的标签预测,并强烈推动每个单独的层具有辨别力和敏感性。注意,对于每个<i>l</i>(<i>W</i>,<i>w</i><sup>(<i>m</i>)</sup>),<i>w</i><sup>(<i>m</i>)</sup>直接取决于<i>Z</i><sup>(<i>m</i>)</sup>,其取决于<i>W</i><sup>1</sup>,<i>W</i><sup>2</sup>,…,<i>W</i><sup><i>m</i></sup>直到第<i>m</i>层。在训练过程中,常把式(7)中的第二项设置为零。这样,在输出层产生良好分类结果的总体目标不会改变,并且伴随目标只是作为代理或正规化。为了实现该目标,通常在式(6)的第二项中设置阈值<i>r</i>。该伴随函数的工作机制是当隐藏层的(伴随目标)总值达到或低于<i>r</i>时,整体功能和伴随目标函数的铰链损失消失,并不在学习过程中发挥作用。平衡参数<i>α</i><sub><i>m</i></sub>为输出目标和伴随目标间的平衡参数。</p>
                </div>
                <div class="p1">
                    <p id="77">总而言之,通过改进每个隐藏层中的分类器,同步深度监督(SDS)将隐藏层的特征质量同步执行优化,舍弃弱影响冗余特征,有效解决了梯度消失现象,减少过拟合,具有较好的分类性能。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78"><b>2.3 多尺度空间金字塔池化策略——MSPP</b></h4>
                <div class="p1">
                    <p id="79">本文使用肺部影像公开数据集LIDC-IDRI<citation id="124" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>,其中标注的肺结节大小范围为3～30 mm,像素级别的范围为6×6～60×60像素,为保证大规模数据下批量训练及数据的原始性,将图片调整为32×32、48×48、64×64像素3个尺度。如图3所示。</p>
                </div>
                <div class="area_img" id="80">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909039_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 多尺度ROI图" src="Detail/GetImg?filename=images/JYRJ201909039_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 多尺度ROI图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909039_08000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="81">常用的CNN都需要输入的图像尺寸是固定的,这是由CNN的结构决定的。</p>
                </div>
                <div class="p1">
                    <p id="82">在以往的肺结节分类任务中,往往采用特定大小ROI作为网络输入,但这种做法降低了分类结果的准确度。也有采用多尺度ROI作为输入,但需要设计多个网络模型,这增加了训练的复杂度。</p>
                </div>
                <div class="p1">
                    <p id="83">本文使用了空间金字塔池化策略,用来处理多尺度卷积特征图以生成固定长度的池化表示。即在最后一个卷积层conv4后加入MSPP层。MSPP层对特征进行池化,并产生固定长度的输出,将此输出作为全连接层的输入。空间金字塔的输出是一个<i>k</i>×<i>M</i>维向量,<i>M</i>代表金字塔块的数量,<i>k</i>代表最后一层卷积层的卷积核的数量。这个固定维度的向量就是全连接层的输入。本文使用四个尺度的图像输入到同一个深度网络,当输入图像处于不同的空间尺度时,带有相同大小卷积核的网络就可以在不同的尺度上抽取特征,最后生成固定维度的向量。MSPP网络结构如图4所示。</p>
                </div>
                <div class="area_img" id="84">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909039_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 MSPP网络结构图" src="Detail/GetImg?filename=images/JYRJ201909039_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 MSPP网络结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909039_084.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="85">如图4所示,将最后一层卷积后产生的特征图输入空间金字塔池化层中,该金字塔层由4层组成,都使用全局池化进行特征映射。第1层为1×1,将特征映射的整个区域r<sub>1</sub><sup>1</sup>汇集到R<sub>1</sub>中。第2层为2×2,将特征映射区域r<sub>2</sub><sup>1</sup>、r<sub>2</sub><sup>2</sup>、r<sub>2</sub><sup>3</sup>、r<sub>2</sub><sup>4</sup>汇集到R<sub>2</sub>中。同理,将第3层和第4层将特征映射区域分别汇集到R<sub>3</sub>、R<sub>4</sub>中。因此,每个特征图通过空间金字塔池合并为30个单元。由于前一层具有64个特征图,因此空间金字塔池化层的输出被连接以形成30×64维向量,然后,将该矢量送入全连接层以进行后续的分类。</p>
                </div>
                <div class="p1">
                    <p id="86">将MSPP策略纳入改进的AlexNet-SDS架构,可以使网络模型适用于多尺度图像同时输入到同一个网络中,它能在输入尺寸任意的情况下产生固定大小的输出,并将卷积特征汇集在任意比例区域中以生成固定长度表示。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag"><b>3 实验结果及分析</b></h3>
                <h4 class="anchor-tag" id="88" name="88"><b>3.1 数据集描述</b></h4>
                <div class="p1">
                    <p id="89">本实验基于来自LIDC-IDRI数据库,包含1 010组医疗记录和1 018套胸部CT图像,共有244 527个胸部CT图像,每个图像由4位经验丰富的放射科医师进行标记。每组数据中的标记信息以XML格式存储,包含轮廓坐标和肺结节的恶性程度。放射科医师将肺结节的恶性程度<i>M</i>量化为1、2、3、4、5五个等级,分别表示极不可能、适度不可能、不确定、适度怀疑、高度怀疑。</p>
                </div>
                <h4 class="anchor-tag" id="90" name="90"><b>3.2 实验方案</b></h4>
                <div class="p1">
                    <p id="91">为了提高准确性,选取至少有三个医师同时标注恶性度的结节,并取其平均值。去除了平均值为3的结节,若平均值低于3,则认为该结节属于良性结节;若平均值高于3,则认为该结节属于恶性结节。共得到1 265个结节,其中良性结节779,恶性结节486。为了增强数据集,将预处理后的ROI图像分别进行90°、180°、270°旋转及水平和垂直翻转。使用10折交叉验证,经过大量实验调整,将初始学习率设置为0.3,并使用动态学习率;动量和权重衰减分别设置为0.9和0.000 5。平衡参数<i>α</i><sub><i>m</i></sub>设置为0.001。在训练期间增加了L2范数权重衰减缓解过拟合。在实验中分别使用两种分类器,具有径向基函数核的SVM分类器和RF分类器。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>3.3 评价标准</b></h4>
                <div class="p1">
                    <p id="93">在肺结节分类实验中,通常使用准确性、灵敏度、特异度、ROC曲线等作为评价指标<citation id="125" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>。评估分类指数的公式如表2所示,其中:TP代表真阳性,TN代表真阴性,FP代表假阳性,FN代表假阴性。ROC曲线指受试者工作特征曲线,是反映敏感性和特异性连续变量的综合指标,曲线下面积越大,诊断准确性越高。最后实验结果是在重复运行基础上由平均值和标准差的形式给出。</p>
                </div>
                <div class="area_img" id="94">
                    <p class="img_tit"><b>表2 评价指标计算公式</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="94" border="1"><tr><td><br />评价指标</td><td>计算公式</td></tr><tr><td><br />准确率(AC)</td><td>(TP/TN)/(TP+EP+FN+TN)</td></tr><tr><td><br />敏感性(SE)</td><td>TP/(TP+FN)</td></tr><tr><td><br />特异性(SP)</td><td>FN/(TP+FN)</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="95" name="95"><b>3.4 模型性能比较</b></h4>
                <div class="p1">
                    <p id="96">为了评估本文所提出的方法的性能,与最近发表的论文中使用基于LIDC数据集的肺结节传统分类方法及深度学习分类方法进行比较,结果列于表3和图5中。</p>
                </div>
                <div class="area_img" id="97">
                    <p class="img_tit"><b>表3 基于LIDC数据集的肺结节分类不同算法比较</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="97" border="1"><tr><td><br />分类模型</td><td>AC+SD</td><td>SE+SD</td><td>SP+SD</td></tr><tr><td><br />Improved-RF<sup>[3]</sup></td><td>84.86±2.57</td><td>83.54±2.45</td><td>86.12±2.81</td></tr><tr><td><br />Overfeat<sup>[11]</sup></td><td>82.03±4.25</td><td>82.98±3.64</td><td>81.83±4.05</td></tr><tr><td><br />Setio-CNN<sup>[12]</sup></td><td>86.46±4.03</td><td>87.91±3.84</td><td>84.52±3.63</td></tr><tr><td><br />AlexNet<sup>[13]</sup></td><td>84.50±4.70</td><td>85.87±4.16</td><td>82.63±3.86</td></tr><tr><td><br />Imp-AlexNet-SDS</td><td>92.07±2.56</td><td>92.86±2.69</td><td>89.58±3.71</td></tr><tr><td><br />Ours</td><td>93.68±2.86</td><td>95.17±3.12</td><td>93.92±3.65</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="98">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909039_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同模型的ROC曲线图" src="Detail/GetImg?filename=images/JYRJ201909039_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同模型的ROC曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909039_098.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="99">从表3可以看出,本文提出的方法精度为93.68,与其他方法相比有更好的肺结节分类性能,同时也说明改进的AlexNet网络融合SDS策略能有效提高肺结节分类性能,其精确度能达到92.07。本文提出的方法与传统的分类方法(Improved-RF)相比,精确度提升了8.82;与其他深度网络(Setio-CNN,Overfeat)相比,精确度分别提升了7.22、11.65。</p>
                </div>
                <div class="p1">
                    <p id="100">从图5中可以看出,不同诊断方法的结果存在一定的差异性,本文方法的ROC曲线较其他方法更靠近坐标左上方,AUC值最大,在肺结节良恶性诊断上具有明显的优势。</p>
                </div>
                <h4 class="anchor-tag" id="101" name="101"><b>3.5 不同分类器同步监督结果比较</b></h4>
                <div class="p1">
                    <p id="102">不同分类器同步监督结果比较如图6所示。</p>
                </div>
                <div class="area_img" id="103">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909039_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同分类器性能比较" src="Detail/GetImg?filename=images/JYRJ201909039_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同分类器性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909039_103.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="104">可以看出,两种分类器均能达到较好的效果,但RF分类器的分类精度更高。两个分类器的整体性能表明加入同步监督策略可以使分类结果更加准确。这归功于分层同步监督策略选择强影响特征,消除了许多弱影响冗余特征。</p>
                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>3.6 多层次池化结果比较</b></h4>
                <div class="p1">
                    <p id="106">为了研究MSPP层数对本文方法的影响,保持其他参数不变。设置MSPP层的数量分别为1层、2层、3层和4层。当MSPP层为1层时,设置局部空间块为1×1,即得到1个块。当MSPP层为2层时,第1层块数保持不变,设置第2层局部空间块为2×2,即第2层得到4个块。当MSPP层为3层时,第1～2层块数保持不变,设置第3层局部空间块为3×3,即得到9个块。当MSPP层为4层时,第1～3层块数保持不变,设置第4层局部空间块为4×4,即得到16个块,结果如图7所示。</p>
                </div>
                <div class="area_img" id="107">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909039_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 多层次池化结果比较" src="Detail/GetImg?filename=images/JYRJ201909039_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 多层次池化结果比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909039_107.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="108">可以看出,随着训练次数的增加,当金字塔层数为4层时分类精确度最高;金字塔为3层时的精度与4层很接近;但是金字塔层数为1时,精度明显降低,最高只有89.61%。由此证明,金字塔层数对提高模型精确度有着至关重要的影响。</p>
                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="110">本文提出了一种基于同步深度监督的多尺度肺结节分类方法,该方法改进了经典的AlexNet模型使其更适用于医学图像分类,融合了同步深度监督策略,解决了梯度消失现象,减少了过拟合;应用SPP策略,解决了不同尺度图像不能输入同一模型进行训练的难题,实现了多尺度肺结节ROI图像端到端的分类诊断,提高了肺结节分类精度。通过实验证明,本文方法优于当前几种比较流行的深度分类方法以及传统分类算法。在下一步工作中,尝试在3D-CNN模型中融入同步深度监督策略,从而实现更精确的肺结节恶性度分类。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Cancer statistics,2018">

                                <b>[1]</b> Siegel R L,Miller K D,Jemal A.Cancer statistics,2018[J].CA:A Cancer Journal For Clinicians,2018,68(suppl 12):277-300.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Computer-Aided Detection of Lung Cancer">

                                <b>[2]</b> Suzuki K.Computer-Aided Detection of Lung Cancer[M]//Image-Based Computer-Assisted Radiation Therapy.Springer Singapore,2017.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Automatic benign and malignant classification of pulmonary nodules in thoracic computed tomography based on RF algorithm">

                                <b>[3]</b> Li X X,Li B,Tian L F,et al.Automatic benign and malignant classification of pulmonary nodules in thoracic computed tomography based on RF algorithm[J].Iet Image Processing,2018,12(7):1253-1264.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Non-Intrusive Speech Intelligibility Prediction using Convolutional Neural Networks">

                                <b>[4]</b> Andersen A H,Haan J M D,Tan Z H,et al.Non-Intrusive Speech Intelligibility Prediction using Convolutional Neural Networks[J].IEEE/ACM Transactions on Audio,Speech,and Language Processing,2018,26(10):1925-1939.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distinguishing Between Natural and Computer-Generated Images Using Convolutional Neural Networks">

                                <b>[5]</b> Quan W,Wang K,Yan D M,et al.Distinguishing Between Natural and Computer-Generated Images Using Convolutional Neural Networks[J].IEEE Transactions on Information Forensics and Security,2018,13(11):2772-2787.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using Deep Convolutional Neural Network Architectures for Object Classification and Detection within X-ray Baggage Security Imagery">

                                <b>[6]</b> Akcay S,Kundegorski M E,Willcocks C G,et al.Using Deep Convolutional Neural Network Architectures for Object Classification and Detection within X-ray Baggage Security Imagery[J].IEEE Transactions on Information Forensics and Security,2018,13(9):2203-2215.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWDA8F2207912D8A88BACFE5692116AA186&amp;v=MTI2MzJtVWtJVFhucnJoTTBmOFBsUkxLWkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMbTh4S0U9TmlmY2FzS3dhTlBPcjRoTVplbDdCQTB4eDJSaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Kyathanahally S P,Döring A,Kreis R.Deep learning approaches for detection and removal of ghosting artifacts in MR spectroscopy[J].Magnetic Resonance in Medicine,2018,80(3):851-863.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESDF2EB89017F5A2C8C92AF5831DBA3D52&amp;v=Mjg0MTRVMDV0dGh4TG04eEtFPU5pZk9mY2ZPSEtTK3A0WkZaZXg1Q1EwN3ZCNWc0ejBNUG5ycXJ4TkJDOE9YTWIrZENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Almasni M A,Alantari M A,Choi M T,et al.Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks[J].Computer Methods and Programs in Biomedicine,2018,162:221-231.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-scale Convolutional Neural Networks for lung nodule classification">

                                <b>[9]</b> Shen W,Zhou M,Yang F,et al.Multi-scale Convolutional Neural Networks for Lung Nodule Classification[C]//International Conference on Information Processing in Medical Imaging,2015:588-599.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESE0DF32BC1A8A7ADD7A304AB40CE063A6&amp;v=MDgwMTJhcWZQcmYwMlpab0hmWHRJdTJJVW16eDlUQTZRcUJKR0RMS1NSc3VaQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRoeExtOHhLRT1OaWZPZmNhNA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Ciompi F,De H B,van Riel S J,et al.Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of 2D views and a convolutional neural network out-of-the-box[J].Medical Image Analysis,2015,26(1):195-202.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=OverFeat:Integrated Recognition,Localization and Detection using Convolutional Networks[EB]">

                                <b>[11]</b> Sermanet P,Eigen D,Zhang X,et al.OverFeat:Integrated Recognition,Localization and Detection using Convolutional Networks[EB].arXiv:1312.6229,2013.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pulmonary nodule detection in CT images:False positive reduction using multi-view convolutional networks">

                                <b>[12]</b> Setio A A,Ciompi F,Litjens G,et al.Pulmonary nodule detection in CT images:false positive reduction using multi-view convolutional networks[J].IEEE Transactions on Medical Imaging,2016,35(5):1160-1169.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet classification with deep convolutional neural networks">

                                <b>[13]</b> Krizhevsky A,Sutskever I,Hinton G E.ImageNet Classification with Deep Convolutional Neural Networks[C]//Proceedings of the 25th International Conference on Neural Information Processing Systems.2012:1097-1105.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pyramid of Spatial Relatons for Scene-Level Land Use Classification">

                                <b>[14]</b> Chen S,Tian Y L.Pyramid of Spatial Relatons for Scene-Level Land Use Classification[J].IEEE Transactions on Geoscience and Remote Sensing,2015,53(4):1947-1957.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition">

                                <b>[15]</b> He K,Zhang X,Ren S,et al.Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition[J].IEEE Transactions on Pattern Analysis &amp; Machine Intelligence,2015,37(9):1904-1916.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deeply-Supervised Nets[EB]">

                                <b>[16]</b> Lee C Y,Xie S,Gallagher P,et al.Deeply-Supervised Nets[EB].eprint arXiv:1409.5185,2014.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Lung Image Database Consortium(LIDC) and Image Database Resource Initiative(IDRI):A Completed Reference Database of Lung Nodules on CT Scans">

                                <b>[17]</b> Armato S G,Mclennan G,Bidaut L,et al.The Lung Image Database Consortium(LIDC) and Image Database Resource Initiative(IDRI):A Completed Reference Database of Lung Nodules on CT Scans[J].Academic Radiology,2011,14(12):1455-1463.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDEE5BB467A73534609121595F7A9CA357&amp;v=MDkxMDhOajdCYXNiTkc2TytxNGxDRmV3TUNYODl5UllhNnoxOFRYYm4yaFZFY01IbFJyK1lDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4TG04eEtFPQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Nibali A,He Z,Wollersheim D.Pulmonary nodule classification with deep residual networks[J].International Journal of Computer Assisted Radiology and Surgery,2017,12(10):1799-1808.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201909039" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909039&amp;v=MDEzNTA1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlqa1VMdkJMelRaWkxHNEg5ak1wbzlHYllRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
