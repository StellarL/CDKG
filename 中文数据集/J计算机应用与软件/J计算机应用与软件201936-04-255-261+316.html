<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135764601533750%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201904042%26RESULT%3d1%26SIGN%3dE8ilu39D3aWFjmeID%252bRsRntoFGM%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904042&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904042&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904042&amp;v=MTU1NzMzenFxQnRHRnJDVVI3cWZadVp0Rnl6Z1VydlBMelRaWkxHNEg5ak1xNDlCWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#38" data-title="&lt;b&gt;1 算法设计&lt;/b&gt; "><b>1 算法设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#40" data-title="&lt;b&gt;1.1 SMOTE算法&lt;/b&gt;"><b>1.1 SMOTE算法</b></a></li>
                                                <li><a href="#50" data-title="&lt;b&gt;1.2 非平衡数据集学习算法SCSMOTE&lt;/b&gt;"><b>1.2 非平衡数据集学习算法SCSMOTE</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#87" data-title="&lt;b&gt;2 实验与结果分析&lt;/b&gt; "><b>2 实验与结果分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#88" data-title="&lt;b&gt;2.1 数据集&lt;/b&gt;"><b>2.1 数据集</b></a></li>
                                                <li><a href="#92" data-title="&lt;b&gt;2.2 评价度量&lt;/b&gt;"><b>2.2 评价度量</b></a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;2.3 实验数据分析&lt;/b&gt;"><b>2.3 实验数据分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#127" data-title="&lt;b&gt;3 结 语&lt;/b&gt; "><b>3 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#78" data-title="图1 SCSMOTE算法原理图">图1 SCSMOTE算法原理图</a></li>
                                                <li><a href="#90" data-title="&lt;b&gt;表1 各数据集样本分布&lt;/b&gt;"><b>表1 各数据集样本分布</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;表2 混淆矩阵&lt;/b&gt;"><b>表2 混淆矩阵</b></a></li>
                                                <li><a href="#113" data-title="图2 不同近邻参数取值下的F-value值">图2 不同近邻参数取值下的F-value值</a></li>
                                                <li><a href="#113" data-title="图2 不同近邻参数取值下的F-value值">图2 不同近邻参数取值下的F-value值</a></li>
                                                <li><a href="#114" data-title="图3 不同近邻参数取值下的G-mean值">图3 不同近邻参数取值下的G-mean值</a></li>
                                                <li><a href="#117" data-title="图4 少数类准确率 (Recall) 变化曲线图">图4 少数类准确率 (Recall) 变化曲线图</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表3 少数类准确率 (Recall&lt;/b&gt;) "><b>表3 少数类准确率 (Recall</b>) </a></li>
                                                <li><a href="#119" data-title="图5 准确率 (Precision) 变化曲线图">图5 准确率 (Precision) 变化曲线图</a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;表4 准确率 (Precision&lt;/b&gt;) "><b>表4 准确率 (Precision</b>) </a></li>
                                                <li><a href="#121" data-title="图6 F-value变化曲线图">图6 F-value变化曲线图</a></li>
                                                <li><a href="#122" data-title="&lt;b&gt;表5 F-value值&lt;/b&gt;"><b>表5 F-value值</b></a></li>
                                                <li><a href="#123" data-title="图7 G-mean变化曲线图">图7 G-mean变化曲线图</a></li>
                                                <li><a href="#124" data-title="&lt;b&gt;表6 G-mean值&lt;/b&gt;"><b>表6 G-mean值</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Breiman L. Random forests[J]. Machine Learning, 2001, 45 (1) :5-32." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MDUwOTdNSDdSN3FkWitadUZpdmxWN3JKSkZrPU5qN0Jhck80SHRITnJJdEZadXdPWTNrNXpCZGg0ajk5U1hxUnJ4b3hj&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Breiman L. Random forests[J]. Machine Learning, 2001, 45 (1) :5-32.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" He H B, Garcia E A. Learning from imbalanced data[J].IEEE Transactions on Knowledge and Data Engineering, 2009, 21 (9) :1263-1284." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning from Imbalanced Data">
                                        <b>[2]</b>
                                         He H B, Garcia E A. Learning from imbalanced data[J].IEEE Transactions on Knowledge and Data Engineering, 2009, 21 (9) :1263-1284.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 黄衍, 查伟雄.随机森林与支持向量机分类性能比较[J].软件, 2012, 33 (6) :107-110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJZZ201206039&amp;v=MTY1MTJxWTlHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6Z1VydlBOeWZSZExHNEg5UE0=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         黄衍, 查伟雄.随机森林与支持向量机分类性能比较[J].软件, 2012, 33 (6) :107-110.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 吴琼, 李运田, 郑献文.面向非平衡训练集分类的随机森林算法优化[J].工业控制计算机, 2013, 26 (7) :89-90." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GYKJ201307042&amp;v=MjM5ODZxZlp1WnRGeXpnVXJ2UElqVEFaTEc0SDlMTXFJOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         吴琼, 李运田, 郑献文.面向非平衡训练集分类的随机森林算法优化[J].工业控制计算机, 2013, 26 (7) :89-90.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Chawla N V, Bowyer K W, Hall L O, et al.SMOTE: synthetic minority over-sampling technique[J].Journal of artificial intelligence research, 2002, 16 (1) :321-357." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">
                                        <b>[5]</b>
                                         Chawla N V, Bowyer K W, Hall L O, et al.SMOTE: synthetic minority over-sampling technique[J].Journal of artificial intelligence research, 2002, 16 (1) :321-357.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" S&#225;ez J A, Krawczyk B , Wozniak M. Analyzing the oversampling of different classes and types of examples in multi-class imbalanced datasets[J]. Pattern Recognition, 2016, 57:164-178." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Analyzing the oversampling of different classes and types of examples in multi-class imbalanced datasets">
                                        <b>[6]</b>
                                         S&#225;ez J A, Krawczyk B , Wozniak M. Analyzing the oversampling of different classes and types of examples in multi-class imbalanced datasets[J]. Pattern Recognition, 2016, 57:164-178.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Han H , Wang W Y , Mao B H . Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning[C]// Proceedings of the 2005 international conference on Advances in Intelligent Computing-Volume Part I. Springer-Verlag , 2005:878-887." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Borderline-SMOTE:A New Over-Sampling Method in Imbalanced Data Sets Learning">
                                        <b>[7]</b>
                                         Han H , Wang W Y , Mao B H . Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning[C]// Proceedings of the 2005 international conference on Advances in Intelligent Computing-Volume Part I. Springer-Verlag , 2005:878-887.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 李雄飞, 李军, 董元方, 等.一种新的非平衡数据学习算法PCBoost[J].计算机学报, 2012, 35 (2) :202-209." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201202003&amp;v=MTMyOTA1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6Z1VydlBMejdCZHJHNEg5UE1yWTlGWjRRS0RIODR2UjRUNmo=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         李雄飞, 李军, 董元方, 等.一种新的非平衡数据学习算法PCBoost[J].计算机学报, 2012, 35 (2) :202-209.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Gu Y X, Ding S F. Advances of support vector machines (SVM) [J]. Computer Science, 2011, 38 (2) :14-17." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201102006&amp;v=MDkxNjFyQ1VSN3FmWnVadEZ5emdVcnZQTHo3QmI3RzRIOURNclk5RllvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Gu Y X, Ding S F. Advances of support vector machines (SVM) [J]. Computer Science, 2011, 38 (2) :14-17.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Naganjaneyulu S, Kuppa M R.A novel frame work for class imbalance learning using intelligent under sampling[J].Progress in artificial intelligence, 2013, 2 (1) :73-84." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A novel framework for class imbalance learning using intelligent under-sampling">
                                        <b>[10]</b>
                                         Naganjaneyulu S, Kuppa M R.A novel frame work for class imbalance learning using intelligent under sampling[J].Progress in artificial intelligence, 2013, 2 (1) :73-84.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Zhan X, Song Q, Wang G, et al. A dissimilarity based imbalance data classification algorithm[J]. Applied Intelligence, 2015, 42 (3) :544-565." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A dissimilarity-based imbalance data classification algorithm">
                                        <b>[11]</b>
                                         Zhan X, Song Q, Wang G, et al. A dissimilarity based imbalance data classification algorithm[J]. Applied Intelligence, 2015, 42 (3) :544-565.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Jiang K, Lu J, Xia K. A novel algorithm for imbalance data classification based on genetic algorithm improved SMOTE[J].Arabian journal for science and engineering, 2016, 41 (8) :3255-3266." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A Novel Algorithm for Imbalance Data Classification Based on Genetic Algorithm Improved SMOTE">
                                        <b>[12]</b>
                                         Jiang K, Lu J, Xia K. A novel algorithm for imbalance data classification based on genetic algorithm improved SMOTE[J].Arabian journal for science and engineering, 2016, 41 (8) :3255-3266.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Xu Y, Yang Z, Zhang Y, et al. A maximum margin and minimum volume hyper-spheres machine with pinball loss for imbalanced data classification[J]. Knowledge Based Systems, 2016, 95:75-85." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB212599FFB63BC8B3A8C580CC357CA10&amp;v=MTg2MzZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHdMMit4Szg9TmlmT2ZjRzZIOVBKcG9ZekVwa0pEdzVLeDJRUW16Y09UWGZpMzJFMmZMWG5OTHVmQ09Odg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Xu Y, Yang Z, Zhang Y, et al. A maximum margin and minimum volume hyper-spheres machine with pinball loss for imbalanced data classification[J]. Knowledge Based Systems, 2016, 95:75-85.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Anwar N , And G J , Ganesh S . Measurement of data complexity for classification problems with unbalanced data[J]. Statistical Analysis &amp;amp; Data Mining the Asa Data Science Journal, 2014, 7 (3) :194-211." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD14052800000284&amp;v=MjIzNTV0RmlubFVyeklKRnNWYmhVPU5pZmNhcks4SHRUT3A0OUZaT3NQRG5ROW9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         Anwar N , And G J , Ganesh S . Measurement of data complexity for classification problems with unbalanced data[J]. Statistical Analysis &amp;amp; Data Mining the Asa Data Science Journal, 2014, 7 (3) :194-211.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(04),255-261+316 DOI:10.3969/j.issn.1000-386x.2019.04.041            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种非平衡数据分类的过采样随机森林算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E9%94%A6%E9%98%B3&amp;code=39109405&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵锦阳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%8D%A2%E4%BC%9A%E5%9B%BD&amp;code=37748785&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">卢会国</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%92%8B%E5%A8%9F%E8%90%8D&amp;code=39109404&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">蒋娟萍</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%A2%81%E5%9F%B9%E5%9F%B9&amp;code=41483484&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">袁培培</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9F%B3%E5%AD%A6%E4%B8%BD&amp;code=41483485&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">柳学丽</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E6%88%90%E9%83%BD%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=1699079&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">成都信息工程大学电子工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%B8%AD%E5%9B%BD%E6%B0%94%E8%B1%A1%E5%B1%80%E5%A4%A7%E6%B0%94%E6%8E%A2%E6%B5%8B%E9%87%8D%E7%82%B9%E5%BC%80%E6%94%BE%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=0022107&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中国气象局大气探测重点开放实验室</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E8%88%AA%E7%A9%BA%E8%88%AA%E5%A4%A9%E5%AD%A6%E9%99%A2&amp;code=0178313&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电子科技大学航空航天学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8D%97%E4%BA%AC%E8%B4%A2%E7%BB%8F%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0251839&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">南京财经大学信息工程学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>在灾害天气、故障诊断、网络攻击和金融欺诈等领域经常存在不平衡的数据集。针对随机森林算法在非平衡数据集上表现的分类性能差的问题, 提出一种新的过采样方法:SCSMOTE (Seed Center Synthetic Minority Over-sampling Technique) 算法。该算法的关键是在数据集的少数类样本中找出合适的候选样本, 计算出候选样本的中心, 在候选样本与样本中心之间产生新的少数类样本, 实现了对合成少数类样本质量的控制。结合SCSMOTE算法与随机森林算法来处理非平衡数据集, 通过在UCI数据集上对比实验结果表明, 该算法有效提高了随机森林在非平衡数据集上的分类性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E5%B9%B3%E8%A1%A1%E6%95%B0%E6%8D%AE%E9%9B%86&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非平衡数据集;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B0%91%E6%95%B0%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">少数类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%90%88%E6%88%90%E6%A0%B7%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">合成样本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    赵锦阳, 硕士生, 主研领域:信号与信息处理。;
                                </span>
                                <span>
                                    卢会国, 副教授。;
                                </span>
                                <span>
                                    蒋娟萍, 讲师。;
                                </span>
                                <span>
                                    袁培培, 硕士生。;
                                </span>
                                <span>
                                    柳学丽, 硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>四川省教育厅重点科技计划资助项目 (14ZA0170);</span>
                    </p>
            </div>
                    <h1><b>AN OVERSAMPLING RANDOM FOREST ALGORITHM FOR CLASSIFICATION OF IMBALANCE DATA</b></h1>
                    <h2>
                    <span>Zhao Jinyang</span>
                    <span>Lu Huiguo</span>
                    <span>Jiang Juanping</span>
                    <span>Yuan Peipei</span>
                    <span>Liu Xueli</span>
            </h2>
                    <h2>
                    <span>College of Electronic Engineering, Chengdu University of Information Technology</span>
                    <span>Key Laboratory of Atmospheric Sounding of CMA</span>
                    <span>School of Astronautics and Aeronautic, University of Electronic Science and Technology of China</span>
                    <span>College of Information Engineering, Nanjing University of Finance and Economics</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>There are often imbalanced datasets in disaster weather, fault diagnosis, network attacks and financial fraud. In view of the poor classification performance of random forest algorithm on imbalanced datasets, this paper proposed a new oversampling method: SCSMOTE (Seed Center Synthetic Minority Over-sampling Technique) . The key of the algorithm is to find appropriate candidate samples from the minority samples of the dataset. Then we calculated the center of the candidate samples, produced new minority samples between the candidate samples and the sample center, and realized the control of the quality of synthesis the minority class samples. SCSMOTE algorithm and random forest algorithm were combined to deal with imbalance datasets. The experimental results on UCI data sets show that the algorithm effectively improves the classification performance of random forest on imbalanced datasets.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Imbalance%20dataset&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Imbalance dataset;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Minority%20class&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Minority class;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Synthetic%20sample&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Synthetic sample;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Classification&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Classification;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="31" name="31" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="32">随机森林RF<citation id="129" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>比单个决策树分类器有较高的分类精度和较低的预测误差, 其适合多种环境, 不需要剪枝, 对噪声数据不敏感等众多优点, 已在众多领域得到了广泛的应用;但和其分类器一样, 数据集的非平衡程度会很大地干扰分类器的分类。在现实生活中, 非平衡数据的少数类样本往往受到广泛关注, 例如在金融欺诈领域, 不安全的数据信息所占的比例很小, 然而这些很少的数据会造成重大的后果<citation id="130" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。因此对非平衡数据的准确分类已成为重要话题, 如何提高随机森林对非平衡数据集的分类精度已受到业界人士的广泛关注。</p>
                </div>
                <div class="p1">
                    <p id="33">黄衍等<citation id="131" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>通过比较随机森林和支持向量机在非平衡数据集分类问题上的性能, 得出支持向量机在处理非平衡数据集要优于随机森林。根据随机森林的构造过程可知其对非平衡数据集分类差的原因在于随机森林使用Bagging随机选取训练集, 因为原训练集为非平衡数据集, 故少数类有较低的选中概率, 进行多次循环之后, 被选中的少数类势必与原始数据集的少数类在数量上有较大差别, 这样使得训练出的森林过于依赖多数类样本, 失去了代表性。对于面向非平衡数据集的随机森林, 如何提高少数类样本被选中的概率, 是优化森林算法的关键所在。</p>
                </div>
                <div class="p1">
                    <p id="34">目前主要对数据层进行处理和改进分类器自身构建过程来提高分类器的预测精度。改进分类器自身算法主要涉及随机森林中单个决策树的生成, 合理选择属性, 使得森林中各决策树之间的关联度降到最低, 同时使得各决策树充分生长。而数据层方面主要将原始数据进行预处理, 筛选出需要的数据信息, 并将处理后的数据与分类器算法相结合进行分类。</p>
                </div>
                <div class="p1">
                    <p id="35">对于数据预处理方法, 吴琼等<citation id="132" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出将NCL技术引入随机森林算法, 对非平衡数据进行NCL处理, 然后用随机森林算法对处理后的数据进行分类, 结果表明改进后的随机森林算法分类效果更好。由上述面向非平衡数据集的随机森林分类差的原因, 以及现有研究可知, 对非平衡数据集进行预处理, 可有效地提高随机森林的预测精度。目前比较常用的数据层处理方法是对数据进行重采样 (欠采样和过采样) 。欠采样方法是适当的选取一部分多数类样本 (负类) , 使得新数据集的多数类和少数类样本的个数处于均衡状态, 由此可知选取的多数类样本可能会丢失有效信息, 从而造成合成的数据集与原数据集相差很大, 不具有代表性;过采样方法采用增加少数类样本 (正类) 的思想, 使得原数据集中重要信息保留下来, 合成的数据能够较好地表现出原数据的特征, 因此在处理不平衡数据时, 过采样技术成为了主流方法。</p>
                </div>
                <div class="p1">
                    <p id="36">过采样技术中最为经典的是Chawla提出的SMOTE算法, 其主要思想是找出数据集中少数类样本集, 在少数类样本与其K近邻之间的连线上产生合成样本<citation id="133" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。由其理论可知, SMOTE算法虽然增加了少数类样本个数, 但只是不加分析的复制样本, 并且在合成过程中也会出现重复问题, 从而使得随机森林对合成后的数据集分类性能没有本质上的提高。</p>
                </div>
                <div class="p1">
                    <p id="37">本文提出一种改进的算法——SCSMOTE算法, 根据少数类样本与多数类样本的边界区分程度, 得到合适的候选样本, 并且计算出候选样本的中心, 在候选样本与其中心连线上产生合成样本, 从而达到数据集的平衡。</p>
                </div>
                <h3 id="38" name="38" class="anchor-tag"><b>1 算法设计</b></h3>
                <div class="p1">
                    <p id="39">本节结合SMOTE算法的思想, 提出一种基于候选样本集中心的过采样技术方法。</p>
                </div>
                <h4 class="anchor-tag" id="40" name="40"><b>1.1 SMOTE算法</b></h4>
                <div class="p1">
                    <p id="41">SMOTE是过采样方法中的经典算法<citation id="134" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>, 其主要思想基于k近邻算法, 每个少数类样本确定k个近邻的少数类, 然后在少数类样本与其近邻样本的连线上合成新的少数类样本, 通常近邻参数k取5。</p>
                </div>
                <div class="p1">
                    <p id="42">算法实现如下。</p>
                </div>
                <div class="p1">
                    <p id="43">1) 对于每个正类样本<i>P</i>_<i>i</i>, 在正类样本集中选取<i>K</i>个近邻样本, 记为<i>Q</i>_<i>k</i>。</p>
                </div>
                <div class="p1">
                    <p id="44">2) 按式 (1) 合成<i>syn</i>_<i>i</i>, 其中<i>g</i>为确定合成样本位置的随机数, 其值在 (0, 1) 之间:</p>
                </div>
                <div class="p1">
                    <p id="45"><i>syn</i>_<i>i</i>=<i>P</i>_<i>i</i>+<i>g</i>× (<i>Q</i>_<i>k</i>-<i>P</i>_<i>i</i>)      (1) </p>
                </div>
                <div class="p1">
                    <p id="46">3) 将合成的<i>syn</i>_<i>i</i>样本添加到原始正类集中得<i>syn</i>_<i>dat</i>样本。</p>
                </div>
                <div class="p1">
                    <p id="47">由上可知, 如果一数据集正类样本边缘化严重, 那么由于不加分析地在正类样本之间复制产生新样本, 势必会使原本就边缘化的数据更加边缘化, 从而使得边界更加难以区分。这种情况虽然在数量上改善了数据集的平衡性, 但造成了随机森林算法进行分类时的难度。</p>
                </div>
                <div class="p1">
                    <p id="48">本文认为边界样本在分类中比远离边界的样本更容易被错分。但由上述可知, 在产生新样本时又不能刻意避开边界样本, 因为一个类的边界样本或多或少会携带原始数据集的信息。因此本文根据少数类样本与多数类样本的边界区分程度进行分析, 对于存在有危险区域 (正类边界样本的k近邻样本中负类样本数量多于正类样本数量) 的数据集<citation id="135" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>而言, 当危险区域中的数据样本在全体正类样本个数占比较高时, 在合成新样本时要尽量克服SMOTE算法不加分析复制边界样本的缺点, 对危险区域样本进行合理控制, 从而减少分类器对边界样本的错分率。对于有清晰边界的数据集而言, 即危险区域的正类样本个数在全体正类样本个数占比较少, 此时危险区域不具有代表性, 要尽可能克服SMOTE算法过采样过程中模糊边缘的问题。</p>
                </div>
                <div class="p1">
                    <p id="49">本文认为危险区域的正类样本数大于总正类样本数量的四分之一时, 边界样本携带原始数据集的多数信息, 分类器容易把边界样本中的正类样本判为负类样本。故在合成新样本时要对危险区域样本加大学习力度, 并进行合理控制。此时计算出危险区域的样本中心, 并把危险区域中的样本作为候选样本;对于危险区域的正类样本个数小于总正类样本数量的四分之一时, 认为边界样本占据原始数据集的信息比重较小, 此时计算全体正类样本的中心, 把全体正类作为候选样本。用得到的候选样本和样本中心, 得出一种新的学习算法:找出数据集的危险区域, 若此区域中的正类样本能较好地代表整体正类样本, 则把此区域作为候选样本 (反之以全体正类样本为候选样本) , 计算候选样本中心。在候选样本和候选样本中心的连线上产生新的正类样本, 把产生的新样本合并到原始数据集中, 从而使得数据平衡化。</p>
                </div>
                <h4 class="anchor-tag" id="50" name="50"><b>1.2 非平衡数据集学习算法SCSMOTE</b></h4>
                <div class="p1">
                    <p id="51">计算需要合成的正类样本数量并得到合适的候选样本, 最后计算合成样本位置实现对非平衡数据集的平衡化处理。</p>
                </div>
                <h4 class="anchor-tag" id="52" name="52"><b>1.2.1</b> 正类样本数据的合成</h4>
                <div class="p1">
                    <p id="53">设原始数据集<i>T</i>, 其中负类样本集合<i>N</i>={<i>N</i><sub>1</sub>, <i>N</i><sub>2</sub>, …, <i>N</i><sub><i>nnum</i></sub>}, <i>N</i><sub><i>i</i></sub>= (<i>n</i><sub><i>i</i>1</sub>, <i>n</i><sub><i>i</i>2</sub>, …, <i>n</i><sub><i>ir</i></sub>) , 其中<i>nnum</i>表示负类样本数量, <i>r</i>代表样本特征个数;正类样本集合<i>P</i>={<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub>, …, <i>P</i><sub><i>pnum</i></sub>}, <i>P</i><sub><i>i</i></sub>= (<i>p</i><sub><i>i</i>1</sub>, <i>p</i><sub><i>i</i>2</sub>, …, <i>p</i><sub><i>ir</i></sub>) , 其中<i>r</i>代表样本特征个数, <i>pnum</i>表示正类数量。</p>
                </div>
                <div class="p1">
                    <p id="54"><b>定义1</b> 危险区域</p>
                </div>
                <div class="p1">
                    <p id="55">对于正类<i>P</i>集合中的每个正类<i>P</i><sub><i>i</i></sub>= (<i>i</i>=1, 2, …, <i>pnum</i>) , 计算并找出其在原始数据集中的k近邻, 规定k近邻中多数类样本数量为<i>k</i>′, 可知0≤<i>k</i>′≤<i>k</i>。当<mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mfrac><mi>k</mi><mn>2</mn></mfrac><mo>≤</mo></mrow><msup><mi>k</mi><mo>′</mo></msup><mo>≤</mo><mi>k</mi></mrow></math></mathml>, 即<i>P</i><sub><i>i</i></sub>的k近邻中负类样本数量多于正类样本数量, 此时正类样本容易被错分, 故将其放入危险区域集<i>S</i>。危险区域中的样本必为正类的边界, 并且<i>S</i>⊆<i>P</i>。假设危险区域集<i>S</i>={<i>P</i>′<sub>1</sub>, <i>P</i>′<sub>2</sub>, …, <i>P</i>′<sub><i>dnum</i></sub>}, <i>S</i><sub><i>i</i></sub>= (<i>p</i>′<sub><i>i</i>1</sub>, <i>p</i>′<sub><i>i</i>2</sub>, …, <i>p</i>′<sub><i>ir</i></sub>) , 其中0≤<i>dnum</i>≤<i>pnum</i>。</p>
                </div>
                <div class="p1">
                    <p id="57"><b>定义2</b> 危险区域样本中心</p>
                </div>
                <div class="p1">
                    <p id="58">危险区域样本中心是指上述危险区域集<i>S</i>数据空间的中心, <i>S</i><sub>center</sub>是与样本维数相同的向量, 计算公式表示为:</p>
                </div>
                <div class="p1">
                    <p id="59" class="code-formula"><mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>e</mtext><mtext>n</mtext><mtext>t</mtext><mtext>e</mtext><mtext>r</mtext></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac></mrow></math></mathml><mathml id="61"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><mi>S</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="62" class="code-formula">
                        <mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo> (</mo><mrow><mfrac><mn>1</mn><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><msup><mi>Ρ</mi><mo>′</mo></msup></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mfrac><mn>1</mn><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><msup><mi>Ρ</mi><mo>′</mo></msup></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mfrac><mn>1</mn><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>d</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><msup><mi>Ρ</mi><mo>′</mo></msup></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>r</mi></mrow></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>2</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="63"><b>定义3</b> 正类样本中心</p>
                </div>
                <div class="p1">
                    <p id="64">正类样本中心即正类样本的中心点, 记为<i>P</i><sub>center</sub>, 根据上述定义及向量的概念, 可得:</p>
                </div>
                <div class="p1">
                    <p id="65" class="code-formula"><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mtext>e</mtext><mtext>n</mtext><mtext>t</mtext><mtext>e</mtext><mtext>r</mtext></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac></mrow></math></mathml><mathml id="67"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><mrow></mrow></mstyle></mrow></math></mathml></p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Ρ</mi><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mtext> </mtext><mrow><mo> (</mo><mrow><mfrac><mn>1</mn><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><mi>Ρ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mn>1</mn></mrow></msub><mo>, </mo><mfrac><mn>1</mn><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><mi>Ρ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mn>2</mn></mrow></msub><mo>, </mo><mo>⋯</mo><mo>, </mo><mfrac><mn>1</mn><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>p</mi><mi>n</mi><mi>u</mi><mi>m</mi></mrow></munderover><mi>Ρ</mi></mstyle><msub><mrow></mrow><mrow><mi>i</mi><mi>r</mi></mrow></msub></mrow><mo>) </mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>3</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">根据上述定义, 本文首先选择候选样本集, 对于危险区域样本占比总正类样本数较大的原始数据集而言, 处于边界的样本经常会被错分。因此选取危险区域的正类样本为候选样本集, 此区域的样本中心为候选样本中心。对于危险区域样本占比较小的原始数据集而言, 为了避免在合成人造数据时使边界区分度降低, 选取总体正类样本为候选样本, 正类中心为候选样本中心。根据SMOTE算法思想, 此算法根据危险区域正类样本占比总正类样本数的大小, 分别用式 (4) 、式 (5) 在候选样本与候选样本中心之间合成新样本。</p>
                </div>
                <div class="p1">
                    <p id="70"><i>P</i><sub>synj</sub>=<i>S</i><sub><i>i</i></sub>+<i>rand</i> (0, 1) × (<i>S</i><sub>center</sub>-<i>S</i><sub><i>i</i></sub>)      (4) </p>
                </div>
                <div class="p1">
                    <p id="71">式中:<i>S</i><sub><i>i</i></sub> (<i>i</i>=1, 2, …, <i>dnum</i>) 为危险区域的正类样本, <i>dnum</i>为此区域的正类样本的总个数;</p>
                </div>
                <div class="p1">
                    <p id="72"><i>S</i><sub>center</sub>为此区域正类样本的中心点;</p>
                </div>
                <div class="p1">
                    <p id="73"><i>P</i><sub>synj</sub>为合成的样本;</p>
                </div>
                <div class="p1">
                    <p id="74"><i>rand</i> (0, 1) 用于确定合成样本在连线上的具体位置;</p>
                </div>
                <div class="p1">
                    <p id="75"><i>P</i><sub>synj</sub>=<i>P</i><sub><i>i</i></sub>+<i>rand</i> (0, 1) × (<i>P</i><sub>center</sub>-<i>P</i><sub><i>i</i></sub>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="76">式中:<i>P</i><sub><i>i</i></sub> (<i>i</i>=1, 2, …, <i>pnum</i>) 为正类样本, <i>pnum</i>为正类样本总个数;<i>P</i><sub>center</sub>为正类样本的中心点。</p>
                </div>
                <div class="p1">
                    <p id="77">图1给出了SCSMOTE算法合成新样本的原理图, 其中空心圆代表正类样本, 正方形代表负类样本, 三角形代表候选样本中心, 实心黑点代表合成正类样本。其合成新样本的位置已在图中标示。P1样本的5个近邻分别是P2、N1、N2、N3、N4, 可知其5个近邻中正类有1个, 负类有4个, 即把P1划分到危险区域;而对于P2而言, 其5个近邻分别是P1、P3、P4、N1、N2, 可知其近邻中正类个数多于负类个数, 故不能把P2划分到危险区域。对每一个正类P_i进行上述过程, 此时候选样本为危险区域的样本, 计算出候选样本中心, 在候选样本和候选样本中心之间产生新的少数类样本。</p>
                </div>
                <div class="area_img" id="78">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 SCSMOTE算法原理图" src="Detail/GetImg?filename=images/JYRJ201904042_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 SCSMOTE算法原理图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_078.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="79" name="79"><b>1.2.2</b> 算法实现</h4>
                <div class="p1">
                    <p id="80">在以上定义以及SMOTE算法的基础上, 基于R语言开发环境实现算法。设程序中原始样本集合为X, target是数据集X的目标类属性的向量, K、C为近邻参数, 用于标记指定样本的近邻个数, 默认值为5。</p>
                </div>
                <div class="p1">
                    <p id="81"><b>算法1</b> SCSMOTE (X, target, K, C) </p>
                </div>
                <div class="p1">
                    <p id="82">1) 对于初始数据集X, 计算并找出正类集合P_set, 在整个初始集合X中对P_set中的每一个样本P_i根据k近邻算法原理计算其C个近邻。若其C个近邻类别中负类数量多于正类数量, 且不全部为正类, 则把此样本放入危险区域Danger集合中。</p>
                </div>
                <div class="p1">
                    <p id="83">2) 统计Danger区域样本数量, 当其小于 (等于) 总体正类数量的四分之一, 即认为此时得到的危险区域不具有代表性, 计算正类集合中心synP_center, 把全体正类样本作为候选样本。</p>
                </div>
                <div class="p1">
                    <p id="84">3) 当Danger区域样本数量大于总体正类数量的四分之一, 计算危险区域集合的中心syn_center, 把危险区域中的样本作为候选样本。</p>
                </div>
                <div class="p1">
                    <p id="85">4) 计算需要合成正类个数的平衡因子sum_dup。</p>
                </div>
                <div class="p1">
                    <p id="86">5) 按条件选择式 (4) 、式 (5) 确定合成样本syn_dat。</p>
                </div>
                <h3 id="87" name="87" class="anchor-tag"><b>2 实验与结果分析</b></h3>
                <h4 class="anchor-tag" id="88" name="88"><b>2.1 数据集</b></h4>
                <div class="p1">
                    <p id="89">为了更好地验证算法的有效性, 从UCI数据集中选择11个数据集作为验证集, 本文将选取的数据集分为训练集和测试集, 各数据集的基本信息见表1。</p>
                </div>
                <div class="area_img" id="90">
                    <p class="img_tit"><b>表1 各数据集样本分布</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="90" border="1"><tr><td rowspan="2">数据集</td><td rowspan="2">实例数</td><td rowspan="2">少数<br />类数</td><td rowspan="2">多数<br />类数</td><td colspan="3"><br />经过处理后的样本分布</td></tr><tr><td><br />训练集<br /> (正, 负) </td><td>样本比例</td><td>测试集</td></tr><tr><td>Yeast_I</td><td>498</td><td>35</td><td>463</td><td>405 (5, 400) </td><td>0.012 5:1</td><td>93 (30, 63) </td></tr><tr><td><br />Ecoli_I</td><td>336</td><td>77</td><td>259</td><td>232 (24, 208) </td><td>0.115 4:1</td><td>104 (53, 51) </td></tr><tr><td><br />Glass_I</td><td>214</td><td>51</td><td>163</td><td>136 (21, 115) </td><td>0.182 6:1</td><td>78 (30, 48) </td></tr><tr><td><br />Iris</td><td>150</td><td>50</td><td>100</td><td>85 (10, 75) </td><td>0.133 3:1</td><td>65 (40, 25) </td></tr><tr><td><br />SPECTE</td><td>267</td><td>55</td><td>212</td><td>212 (40, 172) </td><td>0.232 6:1</td><td>55 (15, 40) </td></tr><tr><td><br />Statlog</td><td>180</td><td>30</td><td>150</td><td>85 (15, 70) </td><td>0.214 3:1</td><td>95 (15, 80) </td></tr><tr><td><br />abalone_I</td><td>374</td><td>115</td><td>259</td><td>259 (60, 199) </td><td>0.301 5:1</td><td>115 (55, 60) </td></tr><tr><td><br />Blood</td><td>748</td><td>178</td><td>570</td><td>500 (100, 400) </td><td>0.250 0:1</td><td>248 (78, 170) </td></tr><tr><td><br />Breast_I</td><td>106</td><td>21</td><td>85</td><td>45 (12, 33) </td><td>0.363 6:1</td><td>61 (9, 52) </td></tr><tr><td><br />Wine_I</td><td>178</td><td>59</td><td>119</td><td>100 (20, 80) </td><td>0.250 0:1</td><td>78 (39, 39) </td></tr><tr><td><br />Seeds_I</td><td>210</td><td>70</td><td>140</td><td>92 (16, 76) </td><td>0.210 5:1</td><td>118 (54, 64) </td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="91">其中选取的数据集abalone_I来自UCI中abalone数据集, abalone数据集中的样本共有28个类别, 人为将类别5作为正类样本, 类别6作为负类样本。glass_I来自UCI中glass数据集, glass数据集中的样本共有7个类别, 人为将类别5、6、7合成一类作为正类样本, 其余样本合为一类作为负类样本。Yeast_I来自UCI中Yeast数据集, Yeast数据集中的样本共有10个类别, 人为的将类别EXC作为正类样本, CYT作为负类样本。Ecoli_I来自UCI中Ecoli数据集, 共有8个类别, 人为的将类别im作为正类样本, 其余的合为一类作为负类样本。Breast数据集中的样本共有6个类别, 人为的将类别car作为正类样本, 其余法人合为一类作为负类样本。Wine_I来自UCI中Wine数据集, 共有3个类别, 人为的将类别1作为正类样本, 类别2和类别3作为负类样本。seeds_I数据集中的样本共有3个类别, 人为的将类别1作为正类样本, 类别2和类别3作为负类样本。数据集具有不平衡特征的界限是数据集中少数类样本个数与多数类样本个数的比例低于1∶2<citation id="136" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。本文采用R语言完成SCSMOTE、SMOTE和RF算法的构造。</p>
                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>2.2 评价度量</b></h4>
                <div class="p1">
                    <p id="93">对于非平衡数据集来说, 采用分类精度来评价分类器的性能是不合理的<citation id="137" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。一般使用混淆矩阵来评估, 分别将两类分为正类 (positive) 、负类 (negative) , 如表2所示<citation id="138" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>。混淆矩阵的列用来表示类的预测结果, 行用来表示类的实际类别<citation id="139" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>。其中, TP (ture positive) 表示正类样本中被划分正确的样本数, 即真正类, TN (true negative) 表示负类样本中被划分正确的样本数, 即真负类, FP (flase positive) 表示正类样本中被划分错误的样本数, 即假正类, FN (flase negative) 表示负类样本中被划分错误的样本数, 即假负类<citation id="140" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>。</p>
                </div>
                <div class="area_img" id="94">
                    <p class="img_tit"><b>表2 混淆矩阵</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="94" border="1"><tr><td><br />分类</td><td>预测为正类</td><td>预测为负类</td></tr><tr><td><br />实际正类</td><td>TP</td><td>FN</td></tr><tr><td><br />实际负类</td><td>FP</td><td>TN</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="95">由表2, 可得出准确率 (Precision) 、召回率 (Recall) 和真负类率如式 (6) -式 (8) 所示, 其是分类器最基本的指标<citation id="141" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>。定义为:</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ρ</mi></mrow></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="98"><mathml id="99"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>Ρ</mi><mi>R</mi><mo>=</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ρ</mi></mrow><mrow><mi>Τ</mi><mi>Ρ</mi><mo>+</mo><mi>F</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="100"><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><mi>Ν</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Τ</mi><mi>Ν</mi></mrow><mrow><mi>F</mi><mi>Ρ</mi><mo>+</mo><mi>Τ</mi><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="102">F-value是准确率和召回率的调和均值, 定义如下:</p>
                </div>
                <div class="p1">
                    <p id="103"><mathml id="104"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mo>-</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo>=</mo><mfrac><mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>+</mo><mi>β</mi><msup><mrow></mrow><mn>2</mn></msup><mo stretchy="false">) </mo><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>×</mo><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><mrow><mi>β</mi><msup><mrow></mrow><mn>2</mn></msup><mo>×</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>+</mo><mi>Ρ</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></mfrac></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="105">式中:参数<i>β</i>一般取值1, 可知只有准确率和召回率均较大时, F-value才会有较大值。</p>
                </div>
                <div class="p1">
                    <p id="106">若要对算法进行总体评价, 则要借助G-mean值, 它是用来衡量分类器对正负样本分类的平均性能<citation id="142" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>。其公式如下:</p>
                </div>
                <div class="p1">
                    <p id="107"><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>G</mi><mo>-</mo><mi>m</mi><mi>e</mi><mi>a</mi><mi>n</mi><mo>=</mo><msqrt><mrow><mtext>R</mtext><mtext>e</mtext><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>×</mo><mi>Τ</mi><mi>Ν</mi><mi>R</mi></mrow></msqrt></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="109">本文选用Recall、Precision、F-value、G-mean等值作为算法性能指标的度量。</p>
                </div>
                <h4 class="anchor-tag" id="110" name="110"><b>2.3 实验数据分析</b></h4>
                <div class="p1">
                    <p id="111">本文的仿真实验均是在R语言中实现, 记录了随机森林在三种实验方案下的实验数据, 即未采样、SMOTE采样和本文的采样算法。为了更好地分析近邻参数<i>K</i>值的影响, 首先随机选取4个数据集进行不同的近邻参数实验分析, 其F-value、G-mean值如图2-图3所示, 横坐标为<i>K</i>的取值, RF参数统一采用默认参数设置;然后对全部数据集采用默认的近邻参数 (<i>K</i>=5) 进行三种算法预处理。</p>
                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_11300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同近邻参数取值下的F-value值" src="Detail/GetImg?filename=images/JYRJ201904042_11300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同近邻参数取值下的F-value值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_11300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="113">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_11301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同近邻参数取值下的F-value值" src="Detail/GetImg?filename=images/JYRJ201904042_11301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同近邻参数取值下的F-value值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_11301.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="114">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同近邻参数取值下的G-mean值" src="Detail/GetImg?filename=images/JYRJ201904042_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同近邻参数取值下的G-mean值  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_114.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="115">从图2和图3可以看出, 当<i>K</i>取不同值时, 用SCSMOTE处理的数据集abalone_I、glass_I、SPECTE的F-value、G-mean值始终最大或者与SMOTE算法相等;对于数据集Statlog, SCSMOTE处理后的F-value值始终在最上方或者与SMOTE重合, 而当<i>K</i>=5时, SCSMOTE算法的G-mean值比SMOTE算法要小, 可知SCSMOTE算法提高了F-value值, 却降低了G-mean值。</p>
                </div>
                <div class="p1">
                    <p id="116">为了整体分析算法的优势, 采用统一的近邻参数 (<i>K</i>=5) 对全部数据集进行实验分析, 图4-图7绘制了11个数据集上3种算法的测试结果图, 其中, 横坐标为所选取的不同数据集, 纵坐标取值在0～1之间。表3-表6是它们的对应值表, 可以看出, 使用SCSMOTE算法进行过采样, 少数类的分类性能有所上升。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 少数类准确率 (Recall) 变化曲线图" src="Detail/GetImg?filename=images/JYRJ201904042_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 少数类准确率 (Recall) 变化曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_117.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表3 少数类准确率 (Recall</b>)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td><br />数据集</td><td>RF</td><td>RF+SMOTE</td><td>RF+SCSMOTE</td></tr><tr><td><br />Yeast_I</td><td>0.266 7</td><td>0.233 3</td><td>0.366 7</td></tr><tr><td><br />Ecoli_I</td><td>0.339 6</td><td>0.622 6</td><td>0.679 2</td></tr><tr><td><br />glass_I</td><td>0.800 0</td><td>0.766 7</td><td>0.866 7</td></tr><tr><td><br />Iris</td><td>0.875 0</td><td>0.975 0</td><td>0.975 0</td></tr><tr><td><br />SPECTE</td><td>0.200 0</td><td>0.266 7</td><td>0.333 3</td></tr><tr><td><br />Statlog</td><td>0.466 7</td><td>0.600 0</td><td>0.533 3</td></tr><tr><td><br />abalone_I</td><td>0.418 2</td><td>0.509 1</td><td>0.563 6</td></tr><tr><td><br />Blood</td><td>0.153 8</td><td>0.256 4</td><td>0.205 1</td></tr><tr><td><br />Breast_I</td><td>1.000 0</td><td>1.000 0</td><td>1.000 0</td></tr><tr><td><br />Wine_I</td><td>0.948 7</td><td>0.974 4</td><td>0.974 4</td></tr><tr><td><br />Seeds_I</td><td>0.629 6</td><td>0.703 7</td><td>0.685 2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 准确率 (Precision) 变化曲线图" src="Detail/GetImg?filename=images/JYRJ201904042_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 准确率 (Precision) 变化曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="120">
                    <p class="img_tit"><b>表4 准确率 (Precision</b>)  <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="120" border="1"><tr><td><br />数据集</td><td>RF</td><td>RF+SMOTE</td><td>RF+SCSMOTE</td></tr><tr><td><br />Yeast_I</td><td>1.000 0</td><td>0.875 0</td><td>1.000 0</td></tr><tr><td><br />Ecoli_I</td><td>1.000 0</td><td>1.000 0</td><td>1.000 0</td></tr><tr><td><br />glass_I</td><td>1.000 0</td><td>1.000 0</td><td>1.000 0</td></tr><tr><td><br />Iris</td><td>0.972 2</td><td>0.975 0</td><td>0.975 0</td></tr><tr><td><br />SPECTE</td><td>0.750 0</td><td>0.571 4</td><td>0.714 3</td></tr><tr><td><br />Statlog</td><td>0.700 0</td><td>0.600 0</td><td>0.727 3</td></tr><tr><td><br />abalone_I</td><td>0.766 7</td><td>0.717 9</td><td>0.775 0</td></tr><tr><td><br />Blood</td><td>0.600 0</td><td>0.350 9</td><td>0.615 4</td></tr><tr><td><br />Breast_I</td><td>0.600 0</td><td>0.600 0</td><td>0.692 3</td></tr><tr><td><br />Wine_I</td><td>0.948 7</td><td>0.950 0</td><td>0.974 4</td></tr><tr><td><br />Seeds_I</td><td>0.918 9</td><td>0.883 7</td><td>0.948 7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="121">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 F-value变化曲线图" src="Detail/GetImg?filename=images/JYRJ201904042_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 F-value变化曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_121.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="122">
                    <p class="img_tit"><b>表5 F-value值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="122" border="1"><tr><td><br />数据集</td><td>RF</td><td>RF+SMOTE</td><td>RF+SCSMOTE</td></tr><tr><td><br />Yeast_I</td><td>0.421 1</td><td>0.368 4</td><td>0.536 6</td></tr><tr><td><br />Ecoli_I</td><td>0.507 0</td><td>0.767 4</td><td>0.809 0</td></tr><tr><td><br />glass_I</td><td>0.888 9</td><td>0.867 9</td><td>0.928 6</td></tr><tr><td><br />Iris</td><td>0.921 0</td><td>0.975 0</td><td>0.975 0</td></tr><tr><td><br />SPECTE</td><td>0.315 8</td><td>0.363 7</td><td>0.454 5</td></tr><tr><td><br />Statlog</td><td>0.560 0</td><td>0.600 0</td><td>0.615 4</td></tr><tr><td><br />abalone_I</td><td>0.541 2</td><td>0.595 7</td><td>0.625 6</td></tr><tr><td><br />Blood</td><td>0.244 8</td><td>0.296 3</td><td>0.307 7</td></tr><tr><td><br />Breast_I</td><td>0.750 0</td><td>0.750 0</td><td>0.818 2</td></tr><tr><td><br />Wine_I</td><td>0.948 7</td><td>0.962 0</td><td>0.974 4</td></tr><tr><td><br />Seeds_I</td><td>0.747 2</td><td>0.783 5</td><td>0.795 7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="123">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904042_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 G-mean变化曲线图" src="Detail/GetImg?filename=images/JYRJ201904042_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 G-mean变化曲线图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904042_123.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="124">
                    <p class="img_tit"><b>表6 G-mean值</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="124" border="1"><tr><td><br />数据集</td><td>RF</td><td>RF+SMOTE</td><td>RF+SCSMOTE</td></tr><tr><td><br />Yeast_I</td><td>0.516 4</td><td>0.479 2</td><td>0.605 6</td></tr><tr><td><br />Ecoli_I</td><td>0.582 8</td><td>0.789 1</td><td>0.824 1</td></tr><tr><td><br />glass_I</td><td>0.894 4</td><td>0.875 6</td><td>0.931 0</td></tr><tr><td><br />Iris</td><td>0.916 5</td><td>0.967 5</td><td>0.967 5</td></tr><tr><td><br />SPECTE</td><td>0.441 6</td><td>0.496 7</td><td>0.562 7</td></tr><tr><td><br />Statlog</td><td>0.734 2</td><td>0.745 0</td><td>0.716 5</td></tr><tr><td><br />abalone_I</td><td>0.607 8</td><td>0.644 8</td><td>0.692 1</td></tr><tr><td><br />Blood</td><td>0.382 8</td><td>0.396 2</td><td>0.439 4</td></tr><tr><td><br />Breast_I</td><td>0.940 5</td><td>0.955 3</td><td>0.960 8</td></tr><tr><td><br />Wine_I</td><td>0.948 7</td><td>0.955 3</td><td>0.974 4</td></tr><tr><td><br />Seeds_I</td><td>0.774 7</td><td>0.805 4</td><td>0.814 7</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="125">由表3结合图4可知, 大部分数据集在SCSMOTE算法处理后, 经RF分类的Recall值大于未使用算法处理和SMOTE算法, 表明RF在对经过SCSMOTE算法处理后的数据集分类时, 有效地降低了实际正类预测为负类的错判个数。在表4和图5中, 可以看出数据集经过随机森林分类后, 准确率已经较高。然而大部分数据集在SMOTE算法处理后, 经随机森林分类的Precision值不升反而降低, 表明数据集经SMOTE算法处理后, 增多了实际负类预测为正类的错判个数, 从而使得Precision值有所降低, SMOTE算法并没有从根本上提高分类器的分类准确率。大部分数据集在SCSMOTE算法处理后, 经随机森林分类的Precision值相比于未经任何算法处理进行随机森林分类的Precision值有所提高, 并且相对于SMOTE算法有显著的优势。在表5和图6 中可以看到, 对于非平衡程度高的数据集, 其经过SCSMOTE算法处理后的数据集, 经RF分类的F-value值高于未使用任何算法和SMOTE算法处理后的F-value值。而用于评价非平衡数据集整体性能的G-mean指标则可从表6中观察, 表6和图7显示SCSMOTE算法在大部分的数据集上的 G-mean 值有显著的优势, 说明本文提出的算法在这些数据集上有较好的总体分类性能。</p>
                </div>
                <div class="p1">
                    <p id="126">综上所述, 图表中的Breast_I数据集的训练集中正类样本有12个, 经过SCSMOTE算法处理后, 得到危险区域中的正类样本个数为3个, 此时算法会选全部正类样本作为候选集 (种子样本) 。Wine_I数据集的训练集中正类样本个数为20个, 经过SCSMOTE算法处理后, 得到危险区域中的正类样本个数为3个, 此时算法会选全部正类样本作为候选集 (种子样本) 。Seeds数据集的训练集中正类样本个数为16个, 经过SCSMOTE算法处理后, 得到危险区域中的正类样本个数为2个, 此时算法会选全部正类样本作为候选集 (种子样本) 。由以上实验结果表明本文提出的算法在一定程度上提高了随机森林对非平衡数据分类的性能, 分类效果有一定程度的改进, 能够在不降低随机森林对多数类分类精度的同时, 保证分类器对少数类的正确分类, 并具有良好的适应性。</p>
                </div>
                <h3 id="127" name="127" class="anchor-tag"><b>3 结 语</b></h3>
                <div class="p1">
                    <p id="128">本文针对随机森林 (RF) 对非平衡数据集进行分类时所表现的不足, 在分类器训练样本数据集之前, 引入数据预处理, 提出一种新的过抽样算法SCSMOTE。算法的关键是根据数据集自身分布情况, 选择合适的候选样本, 以增加对数据合成质量的控制。实验结果表明, 经过本文方法处理的数据集, 在进行数据集分类时, 能有效地提高随机森林分类器的分类性能, 使得随机森林在病毒入侵、设备故障检测领域具有显著优势。但算法程序中用于判定危险区域的近邻参数<i>k</i>往往需要人工设定, 如何通过自适应方法产生类的近邻, 是本文进一步的研究方向。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001340271&amp;v=MjQ3Njc9Tmo3QmFyTzRIdEhOckl0Rlp1d09ZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpdmxWN3JKSkZr&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Breiman L. Random forests[J]. Machine Learning, 2001, 45 (1) :5-32.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning from Imbalanced Data">

                                <b>[2]</b> He H B, Garcia E A. Learning from imbalanced data[J].IEEE Transactions on Knowledge and Data Engineering, 2009, 21 (9) :1263-1284.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=RJZZ201206039&amp;v=MjM2NTVHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6Z1VydlBOeWZSZExHNEg5UE1xWTk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 黄衍, 查伟雄.随机森林与支持向量机分类性能比较[J].软件, 2012, 33 (6) :107-110.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=GYKJ201307042&amp;v=MTU1NzR6cXFCdEdGckNVUjdxZlp1WnRGeXpnVXJ2UElqVEFaTEc0SDlMTXFJOUJab1FLREg4NHZSNFQ2ajU0TzM=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 吴琼, 李运田, 郑献文.面向非平衡训练集分类的随机森林算法优化[J].工业控制计算机, 2013, 26 (7) :89-90.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SMOTE: synthetic minority over-sampling technique">

                                <b>[5]</b> Chawla N V, Bowyer K W, Hall L O, et al.SMOTE: synthetic minority over-sampling technique[J].Journal of artificial intelligence research, 2002, 16 (1) :321-357.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Analyzing the oversampling of different classes and types of examples in multi-class imbalanced datasets">

                                <b>[6]</b> Sáez J A, Krawczyk B , Wozniak M. Analyzing the oversampling of different classes and types of examples in multi-class imbalanced datasets[J]. Pattern Recognition, 2016, 57:164-178.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Borderline-SMOTE:A New Over-Sampling Method in Imbalanced Data Sets Learning">

                                <b>[7]</b> Han H , Wang W Y , Mao B H . Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning[C]// Proceedings of the 2005 international conference on Advances in Intelligent Computing-Volume Part I. Springer-Verlag , 2005:878-887.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJX201202003&amp;v=MDQwMzFNclk5Rlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emdVcnZQTHo3QmRyRzRIOVA=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 李雄飞, 李军, 董元方, 等.一种新的非平衡数据学习算法PCBoost[J].计算机学报, 2012, 35 (2) :202-209.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201102006&amp;v=MTIwNTJGeXpnVXJ2UEx6N0JiN0c0SDlETXJZOUZZb1FLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Gu Y X, Ding S F. Advances of support vector machines (SVM) [J]. Computer Science, 2011, 38 (2) :14-17.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A novel framework for class imbalance learning using intelligent under-sampling">

                                <b>[10]</b> Naganjaneyulu S, Kuppa M R.A novel frame work for class imbalance learning using intelligent under sampling[J].Progress in artificial intelligence, 2013, 2 (1) :73-84.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A dissimilarity-based imbalance data classification algorithm">

                                <b>[11]</b> Zhan X, Song Q, Wang G, et al. A dissimilarity based imbalance data classification algorithm[J]. Applied Intelligence, 2015, 42 (3) :544-565.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A Novel Algorithm for Imbalance Data Classification Based on Genetic Algorithm Improved SMOTE">

                                <b>[12]</b> Jiang K, Lu J, Xia K. A novel algorithm for imbalance data classification based on genetic algorithm improved SMOTE[J].Arabian journal for science and engineering, 2016, 41 (8) :3255-3266.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESB212599FFB63BC8B3A8C580CC357CA10&amp;v=MjczNTBRUW16Y09UWGZpMzJFMmZMWG5OTHVmQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRod0wyK3hLOD1OaWZPZmNHNkg5UEpwb1l6RXBrSkR3NUt4Mg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Xu Y, Yang Z, Zhang Y, et al. A maximum margin and minimum volume hyper-spheres machine with pinball loss for imbalanced data classification[J]. Knowledge Based Systems, 2016, 95:75-85.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD14052800000284&amp;v=MDExNTBzVmJoVT1OaWZjYXJLOEh0VE9wNDlGWk9zUERuUTlvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklKRg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> Anwar N , And G J , Ganesh S . Measurement of data complexity for classification problems with unbalanced data[J]. Statistical Analysis &amp; Data Mining the Asa Data Science Journal, 2014, 7 (3) :194-211.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201904042" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904042&amp;v=MTU1NzMzenFxQnRHRnJDVVI3cWZadVp0Rnl6Z1VydlBMelRaWkxHNEg5ak1xNDlCWm9RS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="2" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
