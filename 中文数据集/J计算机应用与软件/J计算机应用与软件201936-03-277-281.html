<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637136421648721250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201903050%26RESULT%3d1%26SIGN%3daznbHH8u8r5Ca1t8D59mrXLHOFo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903050&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201903050&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903050&amp;v=MzAxMDZxZlp1WnNGaURoVkw3Skx6VFpaTEc0SDlqTXJJOUFaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#27" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#31" data-title="&lt;b&gt;1 相关理论&lt;/b&gt; "><b>1 相关理论</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#32" data-title="&lt;b&gt;1.1 模拟退火算法&lt;/b&gt;"><b>1.1 模拟退火算法</b></a></li>
                                                <li><a href="#37" data-title="&lt;b&gt;1.2 支持向量机&lt;/b&gt;"><b>1.2 支持向量机</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#61" data-title="&lt;b&gt;2 SA-SVM文本分类方法&lt;/b&gt; "><b>2 SA-SVM文本分类方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#62" data-title="&lt;b&gt;2.1 参数对SVM分类性能的影响&lt;/b&gt;"><b>2.1 参数对SVM分类性能的影响</b></a></li>
                                                <li><a href="#67" data-title="&lt;b&gt;2.2 基于SA的SVM参数选择设计方案&lt;/b&gt;"><b>2.2 基于SA的SVM参数选择设计方案</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#88" data-title="&lt;b&gt;3 基于SA-SVM的中文文本分类&lt;/b&gt; "><b>3 基于SA-SVM的中文文本分类</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="&lt;b&gt;4 实验例证&lt;/b&gt; "><b>4 实验例证</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#121" data-title="&lt;b&gt;5 结 语&lt;/b&gt; "><b>5 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#64" data-title="&lt;b&gt;表1 &lt;i&gt;C&lt;/i&gt;=1时的分类结果&lt;/b&gt;"><b>表1 <i>C</i>=1时的分类结果</b></a></li>
                                                <li><a href="#65" data-title="&lt;b&gt;表2&lt;/b&gt;&lt;i&gt;σ&lt;/i&gt;=&lt;b&gt;1时的分类结果&lt;/b&gt;"><b>表2</b><i>σ</i>=<b>1时的分类结果</b></a></li>
                                                <li><a href="#90" data-title="图1 基于SA-SVM的中文文本分类过程">图1 基于SA-SVM的中文文本分类过程</a></li>
                                                <li><a href="#115" data-title="&lt;b&gt;表3 不同分类算法在复旦大学中文文本分类库的分类结果&lt;/b&gt; %"><b>表3 不同分类算法在复旦大学中文文本分类库的分类结果</b> %</a></li>
                                                <li><a href="#116" data-title="图2 不同分类算法在复旦大学中文文本分类库各类别分类精度">图2 不同分类算法在复旦大学中文文本分类库各类别分类精度</a></li>
                                                <li><a href="#118" data-title="&lt;b&gt;表4 不同分类算法在搜狗文本语料库的分类结果&lt;/b&gt; %"><b>表4 不同分类算法在搜狗文本语料库的分类结果</b> %</a></li>
                                                <li><a href="#119" data-title="图3 不同分类算法在搜狗文本语料库的各类别分类准确率">图3 不同分类算法在搜狗文本语料库的各类别分类准确率</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Burkhardt S, Kramer S. Online multi-label dependency topic models for text classification[J]. Machine Learning, 2018, 107 (5) :1-28." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Online multi-label dependency topic models for text classification">
                                        <b>[1]</b>
                                         Burkhardt S, Kramer S. Online multi-label dependency topic models for text classification[J]. Machine Learning, 2018, 107 (5) :1-28.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 钟将, 刘荣辉. 一种改进的KNN文本分类[J]. 计算机工程与应用, 2012, 48 (2) :142-144." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201202042&amp;v=MDkwNDBGckNVUjdxZlp1WnNGaURoVkw3Skx6N01hYkc0SDlQTXJZOUJab1FLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         钟将, 刘荣辉. 一种改进的KNN文本分类[J]. 计算机工程与应用, 2012, 48 (2) :142-144.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Shathi S P, Hossain M D, Nadim M, et al. Enhancing Performance of na&#239;ve bayes in text classification by introducing an extra weight using less number of training examples[C]//2016 International Workshop on Computational Intelligence (IWCI) . IEEE, 2017:142-147." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Enhancing Performance of na?ve bayes in text classification by introducing an extra weight using less number of training examples">
                                        <b>[3]</b>
                                         Shathi S P, Hossain M D, Nadim M, et al. Enhancing Performance of na&#239;ve bayes in text classification by introducing an extra weight using less number of training examples[C]//2016 International Workshop on Computational Intelligence (IWCI) . IEEE, 2017:142-147.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Bahassine S, Madani A, Kissi M. An improved Chi-sqaure feature selection for Arabic text classification using decision tree[C]//International Conference on Intelligent Systems: Theories and Applications. IEEE, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An improved Chi-sqaure feature selection for Arabic text classification using decision tree">
                                        <b>[4]</b>
                                         Bahassine S, Madani A, Kissi M. An improved Chi-sqaure feature selection for Arabic text classification using decision tree[C]//International Conference on Intelligent Systems: Theories and Applications. IEEE, 2016.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Goudjil M, Koudil M, Bedda M, et al. A novel active learning method using SVM for text classification[J]. International Journal of Automation and Computing, 2018 (3) :1-9." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDYS201803004&amp;v=MDg5NDJuU2ZiRzRIOW5Nckk5RllJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGhWTDdKTHk=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Goudjil M, Koudil M, Bedda M, et al. A novel active learning method using SVM for text classification[J]. International Journal of Automation and Computing, 2018 (3) :1-9.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 陈健飞, 蒋刚, 杨剑锋. 改进ABC-SVM的参数优化及应用[J]. 机械设计与制造, 2016 (1) :24-28." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYZ201601008&amp;v=MTkyNjRkTEc0SDlmTXJvOUZiSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURoVkw3Skx6N1M=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         陈健飞, 蒋刚, 杨剑锋. 改进ABC-SVM的参数优化及应用[J]. 机械设计与制造, 2016 (1) :24-28.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" 张进, 丁胜, 李波. 改进的基于粒子群优化的支持向量机特征选择和参数联合优化算法[J]. 计算机应用, 2016, 36 (5) : 1330-1335." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201605030&amp;v=MjI2NDg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnNGaURoVkw3Skx6N0JkN0c0SDlmTXFvOUdaSVFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         张进, 丁胜, 李波. 改进的基于粒子群优化的支持向量机特征选择和参数联合优化算法[J]. 计算机应用, 2016, 36 (5) : 1330-1335.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 庄严, 白振林, 许云峰. 基于蚁群算法的支持向量机参数选择方法研究[J]. 计算机仿真, 2011, 28 (5) :216-219." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201105055&amp;v=Mjc0NDY0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGhWTDdKTHo3QmRMRzRIOURNcW85QVlZUUtESDg0dlI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         庄严, 白振林, 许云峰. 基于蚁群算法的支持向量机参数选择方法研究[J]. 计算机仿真, 2011, 28 (5) :216-219.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" 陈晋音, 熊晖, 郑海斌. 基于粒子群算法的支持向量机的参数优化[J]. 计算机科学, 2018, 45 (6) :197-203." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201806035&amp;v=MjM4MDU3cWZadVpzRmlEaFZMN0pMejdCYjdHNEg5bk1xWTlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         陈晋音, 熊晖, 郑海斌. 基于粒子群算法的支持向量机的参数优化[J]. 计算机科学, 2018, 45 (6) :197-203.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 王克奇, 杨少春, 戴天虹, 等. 采用遗传算法优化最小二乘支持向量机参数的方法[J].计算机应用与软件, 2009, 26 (7) :109-111." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ200907036&amp;v=MTU4OTBac0ZpRGhWTDdKTHpUWlpMRzRIdGpNcUk5R1lvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         王克奇, 杨少春, 戴天虹, 等. 采用遗传算法优化最小二乘支持向量机参数的方法[J].计算机应用与软件, 2009, 26 (7) :109-111.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 王万良, 陈超, 李笠, 等. 基于模拟退火的自适应水波优化算法[J]. 计算机科学, 2017, 44 (10) :216-221." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201710039&amp;v=MDY3Mjk5Yk5yNDlHYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEaFZMN0pMejdCYjdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         王万良, 陈超, 李笠, 等. 基于模拟退火的自适应水波优化算法[J]. 计算机科学, 2017, 44 (10) :216-221.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" 司守奎, 孙玺菁. 数学建模算法与应用[M]. 北京:国防工业出版社, 2015." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787118100372000&amp;v=MjQzNzBadkZ5bm5VcmZNSjE4VlhGcXpHYks1RnRETXI0eENadXNQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlpl&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         司守奎, 孙玺菁. 数学建模算法与应用[M]. 北京:国防工业出版社, 2015.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(03),277-281 DOI:10.3969/j.issn.1000-386x.2019.03.049            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm">基于SA-SVM的中文文本分类研究</span>
                                    </h1>

            </div>
                        <h2>
                                <a href="javascript:;">郭超磊</a>
                                <a href="javascript:;">陈军华</a>
                </h2>
                    <h2>

                    <span>上海师范大学信息与机电工程学院</span>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>基于支持向量机SVM的中文文本分类方法的泛化能力与其参数选取紧密相关, 参数优化对文本分类精度有较大影响。为解决优化SVM参数难题, 提出一种基于模拟退火 (SA) 优化SVM的文本分类方法。将文本分类准确率作为模拟退火的优化目标, 利用SA良好的寻优能力搜索SVM的最优参数组合。在相同的数据集上进行实验, 结果表明模拟退火具有稳定的全局搜索性能, 是优化SVM参数的一种有效方式。相比其他文本分类算法, 基于SA-SVM的中文文本分类的分类准确率更高, 泛化能力更强, 具有良好的分类性能。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">中文文本分类;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">支持向量机;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">模拟退火;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">参数优化;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    郭超磊, 硕士生, 主研领域:数据处理, 机器学习。;
                                </span>
                                <span>
                                    陈军华, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-01</p>

                    <p>

                            <b>基金：</b>
                                                        <span>上海师范大学基金项目 (C-6105-15-057);</span>
                    </p>
            </div>
                    <h1><b>CHINESE TEXT CATEGORIZATION BASED ON SA-SVM</b></h1>
                    <h2>
                    <span>Guo Chaolei</span>
                    <span>Chen Junhua</span>
            </h2>
                    <h2>
                    <span>The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>The generalization ability of Chinese text categorization method based on SVM is closely related to its parameter selection, and parameter optimization has a great impact on the accuracy of text categorization. To solve the problem of optimizing SVM parameters, we proposed a text categorization method based on simulated annealing (SA) . The accuracy of text categorization was taken as the optimization objective of SA, and the optimal parameter combination of SVM was searched by SA's good optimization ability. Experiments on the same data set show that SA has stable global search performance and is an effective way to optimize the parameters of SVM. Compared with other text categorization algorithms, the Chinese text categorization method based on SA-SVM has higher classification accuracy, stronger generalization ability and better classification performance.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Chinese%20text%20categorization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Chinese text categorization;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=SVM&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">SVM;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Simulated%20annealing%20algorithm&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Simulated annealing algorithm;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Parameter%20optimization&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Parameter optimization;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-01</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="27" name="27" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="28">文本分类, 就是利用计算机相关技术将具有相同特征的文本信息根据文本内容自动划分到预先设定好的文本类别体系中的过程<citation id="123" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。众多学者在研究文本分类的过程中, 提供了许多优秀的分类算法, 钟将等<citation id="124" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>提出一种改进的KNN文本分类算法, 介绍KNN文本分类算法, 并基于LSA降维和样本密度对KNN进行改进;Shathi等<citation id="125" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>将贝叶斯算法应用于文本分类中;Bahassine等<citation id="126" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>使用决策树算法对文本进行分类;Goudjil等<citation id="127" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>采用SVM算法对文本分类进行技术研究。经过大量实验表明, 在中文文本分类上, SVM具有较强的泛化能力。基于SVM的文本分类性能与其惩罚因子<i>C</i>和核函数参数<i>σ</i>等密切相关, 直接影响文本分类精度<citation id="128" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="29">选择SVM的参数是一个优化问题, 近年来, 国内外学者提出了很多优化SVM参数的方法。庄严等<citation id="129" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出了基于蚁群优化算法 (ACO) 的支持向量机选取参数算法;陈晋音等<citation id="130" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>提出了基于粒子群算法 (PSO) 的支持向量机的参数优化;王克奇等<citation id="131" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>采用遗传算法 (GA) 优化支持向量机参数。ACO算法的收敛速度较慢易陷入局部最优, PSO算法易早熟收敛且局部寻优能力较差, GA算法实现比较复杂, 需先对问题进行编码, 然后再对最优解进行解码, 搜索速度较慢。模拟退火算法 (SA) 也是一种启发式算法<citation id="132" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>, 能较强地跳出局部最优, 提高全局寻优能力。</p>
                </div>
                <div class="p1">
                    <p id="30">本文提出一种基于模拟退火算法优化SVM参数的方法, 并应用于中文文本分类中。利用SA良好的寻优性能构建的SVM中文文本分类器, 与朴素贝叶斯、KNN算法、决策树算法、逻辑回归算法构建的分类器相比, 该分类器能达到更好的分类效果, 具有更强的鲁棒性。</p>
                </div>
                <h3 id="31" name="31" class="anchor-tag"><b>1 相关理论</b></h3>
                <h4 class="anchor-tag" id="32" name="32"><b>1.1 模拟退火算法</b></h4>
                <div class="p1">
                    <p id="33">模拟退火算法<citation id="133" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>来源于材料统计力学的研究成果, 它引入固体退火过程的自然机理并适当引入随机因素, 在整个解邻域范围内随机性地取值, 提高全局寻优能力, 有效地解决众多组合优化问题。</p>
                </div>
                <div class="p1">
                    <p id="34">引入Metropolis准则到优化过程, 以最大化目标函数为例, 对于某一温度<i>T</i><sub><i>i</i></sub>和优化问题的一个解<i>x</i> (<i>k</i>) , 可以生成<i>x</i>′。接受<i>x</i>′作为下一个新解<i>x</i> (<i>k</i>+1) 的概率为:</p>
                </div>
                <div class="p1">
                    <p id="35" class="code-formula">
                        <mathml id="35"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo><mo>→</mo><msup><mi>x</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mi>f</mi><mo stretchy="false"> (</mo><msup><mi>x</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>&gt;</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mtext>e</mtext><msup><mrow></mrow><mrow><mo>-</mo><mfrac><mrow><mi>f</mi><mo stretchy="false"> (</mo><msup><mi>x</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>-</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mi>Τ</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></mfrac></mrow></msup><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>f</mi><mo stretchy="false"> (</mo><msup><mi>x</mi><mo>′</mo></msup><mo stretchy="false">) </mo><mo>≤</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false"> (</mo><mi>k</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="36">在温度<i>T</i><sub><i>i</i></sub>下, 经过很多次的转移之后, 降低温度<i>T</i><sub><i>i</i></sub>, 得到<i>T</i><sub><i>i</i>+1</sub>&lt;<i>T</i><sub><i>i</i></sub>, <i>T</i><sub><i>i</i>+1</sub>重复上述过程, 直至达到某个停止准则。因此整个优化过程就是不断寻找新解和缓慢降温的交替过程, 最终的解是对该优化问题寻优的结果。</p>
                </div>
                <h4 class="anchor-tag" id="37" name="37"><b>1.2 支持向量机</b></h4>
                <div class="p1">
                    <p id="38">对于数据集<i>D</i>={ (<i>x</i><sub>1</sub>, <i>y</i><sub>1</sub>) , (<i>x</i><sub>2</sub>, <i>y</i><sub>2</sub>) , …, (<i>x</i><sub><i>n</i></sub>, <i>y</i><sub><i>n</i></sub>) }, 其中<i>x</i><sub><i>i</i></sub>∈<i>R</i><sup><i>n</i></sup>, 并表示输入, <i>y</i><sub><i>i</i></sub>表示对应输出, <i>n</i>为输入样本的维数。SVM分类目标是找到一个超平面, 这个超平面能将所有样本分开, 并使样本之间的距离尽可能最大。即有:</p>
                </div>
                <div class="p1">
                    <p id="39"><i>y</i>=<i>ω</i><sup>T</sup><i>Φ</i> (<i>x</i>) +<b><i>b</i></b>      (2) </p>
                </div>
                <div class="p1">
                    <p id="40">式中:<i>Φ</i> (<i>x</i>) 为标准正态分布函数, <i>ω</i>表示权值向量, <b><i>b</i></b>表示偏移向量。</p>
                </div>
                <div class="p1">
                    <p id="41">求解最优超平面, 就是针对所给定的数据集样本, 找到权值向量<i>ω</i>和偏移向量<b><i>b</i></b>的最优值, 使得权值代价函数最小化, 且正例和反例之间的间隔最大。对于式 (2) 而言, 难以对超平面参数<i>ω</i>和<b><i>b</i></b>直接求解, 因此利用增加非负的松弛因子将式 (2) 转变成二次优化问题:</p>
                </div>
                <div class="p1">
                    <p id="42"><mathml id="43"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>min</mi></mrow><mspace width="0.25em" /><mi>J</mi><mo stretchy="false"> (</mo><mi mathvariant="bold-italic">ω</mi><mo>, </mo><mi>ξ</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>|</mo><mi mathvariant="bold-italic">ω</mi><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>C</mi><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>ξ</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="44">s.t. <i>y</i><sub><i>i</i></sub> (<i>ωΦ</i> (<i>x</i><sub><i>i</i></sub>) +<b><i>b</i></b>) ≥1-<i>ξ</i><sub><i>i</i></sub><i>ξ</i>≥0, <i>i</i>=1, 2, …, <i>n</i></p>
                </div>
                <div class="p1">
                    <p id="45">式中:<i>C</i>为惩罚因子, <i>C</i>&gt;0;<i>ξ</i><sub><i>i</i></sub>表示松弛因子。将最少错分样本和最大分类间隔折衷考虑, 就能得到广义上的最优分类面。</p>
                </div>
                <div class="p1">
                    <p id="46">通过引入拉格朗日乘子将式 (3) 转化为对偶问题, 以便于更好地求解, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="47"><mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mi>max</mi></mrow><mi>W</mi><mo stretchy="false"> (</mo><mi>α</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></munderover><mi>α</mi></mstyle><msub><mrow></mrow><mi>i</mi></msub><mi>α</mi><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>⋅</mo><mi>x</mi><msub><mrow></mrow><mi>j</mi></msub></mrow></math></mathml>      (4) </p>
                </div>
                <div class="area_img" id="50">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201903050_05000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="51">式中:<i>α</i><sub><i>i</i></sub>为拉格朗日乘子。</p>
                </div>
                <div class="p1">
                    <p id="52">对式 (4) 进行求解得到<i>α</i><sub><i>i</i></sub>值, 那么<i>ω</i>为:</p>
                </div>
                <div class="p1">
                    <p id="53"><i>ω</i>=∑<i>α</i><sub><i>i</i></sub><i>y</i><sub><i>i</i></sub><i>Φ</i> (<i>x</i><sub><i>i</i></sub>) ·<i>Φ</i> (<i>x</i>)      (5) </p>
                </div>
                <div class="p1">
                    <p id="54">最终, SVM相应的分类决策函数为:</p>
                </div>
                <div class="p1">
                    <p id="55"><i>f</i> (<i>x</i>) =sgn (<i>α</i><sub><i>i</i></sub><i>y</i><sub><i>i</i></sub><i>Φ</i> (<i>x</i><sub><i>i</i></sub>) ·<i>Φ</i> (<i>x</i>) +<b><i>b</i></b>)      (6) </p>
                </div>
                <div class="p1">
                    <p id="56">RBF函数具有收敛域宽、参数少、通用性好等优点, 是一个很理想的分类依据函数, 因此采用RBF函数建立SVM, 公式如下:</p>
                </div>
                <div class="p1">
                    <p id="57"><mathml id="58"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mi>sgn</mi></mrow><mrow><mo> (</mo><mrow><mi>α</mi><msub><mrow></mrow><mi>i</mi></msub><mi>y</mi><msub><mrow></mrow><mi>i</mi></msub><mi>exp</mi><mrow><mo> (</mo><mrow><mo>-</mo><mfrac><mrow><mrow><mo>|</mo><mrow><mi>x</mi><mo>-</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub></mrow><mo>|</mo></mrow></mrow><mrow><mn>2</mn><mi>σ</mi><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow><mo>) </mo></mrow><mo>+</mo><mi>b</mi></mrow><mo>) </mo></mrow></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="59">式中:<i>σ</i>为RBF核函数参数。</p>
                </div>
                <div class="p1">
                    <p id="60">SVM进行分类的基本流程可归纳为:首先将输入的SVM向量映射到一个特征空间, 紧接着在这个特征空间中寻找优化的线性分界线, 于是就构建出了一个可分离类别的超平面, 使不同的类别正确分开。SVM的训练过程实质上就是寻找全局最优解。</p>
                </div>
                <h3 id="61" name="61" class="anchor-tag"><b>2 SA-SVM文本分类方法</b></h3>
                <h4 class="anchor-tag" id="62" name="62"><b>2.1 参数对SVM分类性能的影响</b></h4>
                <div class="p1">
                    <p id="63">为了验证惩罚因子<i>C</i>和核函数参数<i>σ</i>对SVM分类性能的影响, 随机选择四类3 306个文本作为训练集。建立分类SVM模型, 并选取适当数目的文本作为测试集, 分析不同<i>C</i>和<i>σ</i>对SVM分类精度的影响, 具体结果如表1、表2所示。</p>
                </div>
                <div class="area_img" id="64">
                    <p class="img_tit"><b>表1 <i>C</i>=1时的分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="64" border="1"><tr><td><br /><i>σ</i></td><td>分类准确率/%</td></tr><tr><td><br />0.01</td><td>57.5</td></tr><tr><td><br />0.1</td><td>83</td></tr><tr><td><br />2</td><td>82</td></tr><tr><td><br />10</td><td>61.5</td></tr><tr><td><br />100</td><td>58.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="65">
                    <p class="img_tit"><b>表2</b><i>σ</i>=<b>1时的分类结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="65" border="1"><tr><td><br /><i>C</i></td><td>分类准确率/%</td></tr><tr><td><br />0.01</td><td>57.5</td></tr><tr><td><br />0.1</td><td>59.5</td></tr><tr><td><br />1</td><td>90</td></tr><tr><td><br />10</td><td>89</td></tr><tr><td><br />100</td><td>89.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="66">从表1和表2的结果可知, 在相同的训练集、测试集下, 惩罚因子和核函数参数不同, SVM分类准确率不同, 这表明<i>C</i>和<i>σ</i>的取值影响基于SVM的文本分类结果, 要获得最优的SVM文本分类模型, 找到最优的<i>C</i>和<i>σ</i>值是关键。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.2 基于SA的SVM参数选择设计方案</b></h4>
                <div class="p1">
                    <p id="68">SA优化SVM的惩罚因子<i>C</i>和核函数参数<i>σ</i>的主要判定是取得更高的文本分类准确率, 在最优参数[<i>C</i>, <i>σ</i>]处能取得最高的分类准确率, 故最大化目标函数为<i>F</i>=<i>V</i><sub>precision</sub> (<i>C</i>, <i>σ</i>) 。</p>
                </div>
                <div class="p1">
                    <p id="69">相关设置如下:</p>
                </div>
                <div class="p1">
                    <p id="70"> (1) 设置温度<i>T</i>的初始值:SA算法的全局搜索性能受温度初始值的影响, 若初始值高, 则全局搜索能力强, 但需大量时间进行计算;反之, 虽可减少时间, 但会影响全局搜索性能。在具体操作时, <i>T</i>的初始值可根据实验结果进行灵活调整。</p>
                </div>
                <div class="p1">
                    <p id="71"> (2) 设置退火速度 (内循环每个温度的迭代次数) :SA算法的全局搜索性能同时也受退火速度的影响, 若在某个温度下充分搜索, 需要时间代价, 在具体执行时, 要根据实际问题设置合理的退火速度。</p>
                </div>
                <div class="p1">
                    <p id="72"> (3) 设置温度管理:权衡计算复杂度, 通常的降温方式为<i>T</i> (<i>k</i>+1) =<i>αT</i> (<i>k</i>) , <i>k</i>为降温次数, <i>α</i>一般取较接近1的正常数。</p>
                </div>
                <div class="p1">
                    <p id="73"> (4) 设置初始解和解的搜索范围:SA算法具有优良的健壮性, 求得的最优解不受初始解的影响, 可在解空间内随机设置初始解。不同的数据集的最优参数[<i>C</i>, <i>σ</i>]范围不同, 实际应用中可根据实验结果进行灵活调整。</p>
                </div>
                <div class="p1">
                    <p id="74"> (5) 设置记忆存储器:在搜索过程中, SA算法由于执行概率接受环节, 有可能遗漏当前取得的最优解, 增加记忆存储器, 存储搜索过程的中间最优解, 并及时更新。</p>
                </div>
                <div class="p1">
                    <p id="75"> (6) 设置终止条件:</p>
                </div>
                <div class="p1">
                    <p id="76">① 内循环终止条件:当前状态下连续若干个新解都未被接受或达到迭代次数。</p>
                </div>
                <div class="p1">
                    <p id="77">② 外循环终止条件:连续若干次降温所获得的最优解均不变或<i>T</i>&lt;<i>T</i><sub>min</sub>。</p>
                </div>
                <div class="p1">
                    <p id="78">SA优化SVM参数的过程具体操作描述如下:</p>
                </div>
                <div class="p1">
                    <p id="79"> (1) 初始化温度<i>T</i>, 设置终止温度<i>T</i><sub>min</sub>, 设置降温系数<i>α</i>。</p>
                </div>
                <div class="p1">
                    <p id="80"> (2) 产生随机初始解[<i>C</i><sub>0</sub>, <i>σ</i><sub>0</sub>] (是算法迭代起点) , 并以此作为当前最优解[<i>C</i><sub>best</sub>, <i>σ</i><sub>best</sub>]=[<i>C</i><sub>0</sub>, <i>σ</i><sub>0</sub>], 计算目标函数值<i>F</i> (<i>C</i><sub>best</sub>, <i>σ</i><sub>best</sub>) 。</p>
                </div>
                <div class="p1">
                    <p id="81"> (3) 设置每个<i>T</i>值的迭代次数<i>L</i>;对<i>l</i>=1, 2, …, <i>L</i>做第4至第6步。</p>
                </div>
                <div class="p1">
                    <p id="82"> (4) 在可行解空间内, 对当前最优解作一次随机扰动, 利用状态产生函数生成一个新解[<i>C</i><sub>new</sub>, <i>σ</i><sub>new</sub>], 并计算其目标函数值<i>F</i> (<i>C</i><sub>new</sub>, <i>σ</i><sub>new</sub>) 以及目标函数值增量<i>Δf</i>=<i>F</i> (<i>C</i><sub>new</sub>, <i>σ</i><sub>new</sub>) -<i>F</i> (<i>C</i><sub>best</sub>, <i>σ</i><sub>best</sub>) , 其中<i>F</i> (<i>C</i>, <i>σ</i>) 为优化目标。</p>
                </div>
                <div class="p1">
                    <p id="83"> (5) 采用状态接受函数, 判断是否接受新解:若<i>Δf</i>&gt;0, 则接受[<i>C</i><sub>new</sub>, <i>σ</i><sub>new</sub>]作为新的当前解;否则按式 (1) 中Metropolis准则判决, 以概率<i>p</i>接受[<i>C</i><sub>new</sub>, <i>σ</i><sub>new</sub>]为当前最优解。若接受, 设置当前状态为[<i>C</i><sub>new</sub>, <i>σ</i><sub>new</sub>], 存入记忆存储器;反之, 当前状态为[<i>C</i><sub>best</sub>, <i>σ</i><sub>best</sub>]。</p>
                </div>
                <div class="p1">
                    <p id="84"> (6) 判断是否满足内循环终止条件, 若是, 输出当前解为最优解并结束此次迭代, 转入 (7) ;否则转入 (4) 。</p>
                </div>
                <div class="p1">
                    <p id="85"> (7) 降温。根据设置的降温系数<i>α</i>进行降温, 取新的温度<i>T</i>=<i>αT</i> (其中<i>T</i>为上一步迭代的温度) 。</p>
                </div>
                <div class="p1">
                    <p id="86"> (8) 判断满足外循环终止条件, 退火过程终止, 转入 (9) ;否则转入 (3) ;</p>
                </div>
                <div class="p1">
                    <p id="87"> (9) 输出当前最优解与记忆存储器的中间最优解比较, 找到最优解[<i>C</i><sub>final</sub>, <i>σ</i><sub>final</sub>], 算法结束。</p>
                </div>
                <h3 id="88" name="88" class="anchor-tag"><b>3 基于SA-SVM的中文文本分类</b></h3>
                <div class="p1">
                    <p id="89">基于SA-SVM的中文文本分类过程如图1所示。</p>
                </div>
                <div class="area_img" id="90">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903050_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 基于SA-SVM的中文文本分类过程" src="Detail/GetImg?filename=images/JYRJ201903050_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 基于SA-SVM的中文文本分类过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903050_090.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="91">采用Python的第三方库jieba分词对数据集进行分词处理, 然后去除停用词。</p>
                </div>
                <div class="p1">
                    <p id="92">利用TFIDF进行权重计算, TF指的是特征词在文本中出现的绝对频率, 而IDF指的是特征词在文本中的文本内频率。常用的TFIDF公式如下:</p>
                </div>
                <div class="p1">
                    <p id="93" class="code-formula">
                        <mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><mo stretchy="false"> (</mo><mi>t</mi><mo>, </mo><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>t</mi><mi>f</mi><mo stretchy="false"> (</mo><mi>t</mi><mo>, </mo><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo><mo>×</mo><mi>log</mi><mo stretchy="false"> (</mo><mi>Ν</mi><mo>/</mo><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mn>0</mn><mo>.</mo><mn>0</mn><mn>1</mn><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>t</mi><mo>∈</mo><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover></mrow></munder><mo stretchy="false">[</mo></mstyle><mi>t</mi><mi>f</mi><mo stretchy="false"> (</mo><mi>t</mi><mo>, </mo><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo><mo>×</mo><mi>log</mi><mo stretchy="false"> (</mo><mi>Ν</mi><mo>/</mo><mi>n</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mn>0</mn><mo>.</mo><mn>0</mn><mn>1</mn><mo stretchy="false">) </mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>8</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="94">式中:<mathml id="95"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ω</mi><mo stretchy="false"> (</mo><mi>t</mi><mo>, </mo><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>为词<i>t</i>在<mathml id="96"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover></mrow></math></mathml>的权重;<mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>t</mi><mi>f</mi><mo stretchy="false"> (</mo><mi>t</mi><mo>, </mo><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo></mrow></math></mathml>为词<i>t</i>在<mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>d</mi><mo stretchy="true">¯</mo></mover></mrow></math></mathml>的词频;<i>N</i>为训练文本的总数;<i>n</i><sub><i>t</i></sub>为训练文本集中出现<i>t</i>的文本数, 分母为归一化因子。</p>
                </div>
                <div class="p1">
                    <p id="99">利用DF进行特征选择, 文档频率计算训练集中包含特征项<i>t</i>的文本数目。设<mathml id="100"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></math></mathml>为训练集中的文本总数, <i>d</i><sub><i>i</i></sub>为其中的一个训练文本, 于是有:</p>
                </div>
                <div class="p1">
                    <p id="101"><mathml id="102"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>F</mi><mo stretchy="false"> (</mo><mi>t</mi><mo stretchy="false">) </mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mrow><mo>|</mo><mi>D</mi><mo>|</mo></mrow></mrow></munderover><mi>p</mi></mstyle><mo stretchy="false"> (</mo><mi>t</mi><mo>, </mo><mi>d</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">) </mo></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="103">若<i>t</i>∈<i>d</i><sub><i>i</i></sub>, 则<i>p</i> (<i>t</i>, <i>d</i><sub><i>i</i></sub>) =1;若<i>t</i>∉<i>d</i><sub><i>i</i></sub>, 则<i>p</i> (<i>t</i>, <i>d</i><sub><i>i</i></sub>) =0。</p>
                </div>
                <div class="p1">
                    <p id="104">DF值低于某个设定阈值的特征词属于低频词, 它们可能不含或者含有很少的文本分类信息, 可以在原始特征空间剔除这样的特征项, 既能降低特征空间的维度, 还有可能提高文本分类的准确率。</p>
                </div>
                <div class="p1">
                    <p id="105">采用分类常用的评价指标:准确率<i>P</i>、召回率<i>R</i>和<i>F</i><sub>1</sub>度量, 具体表示如下:</p>
                </div>
                <div class="p1">
                    <p id="106"><i>P</i> (查准率) <mathml id="107"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mfrac><mrow><mtext>分</mtext><mtext>类</mtext><mtext>正</mtext><mtext>确</mtext><mtext>的</mtext><mtext>总</mtext><mtext>文</mtext><mtext>本</mtext><mtext>数</mtext></mrow><mrow><mtext>所</mtext><mtext>有</mtext><mtext>参</mtext><mtext>与</mtext><mtext>分</mtext><mtext>类</mtext><mtext>的</mtext><mtext>总</mtext><mtext>文</mtext><mtext>本</mtext><mtext>数</mtext></mrow></mfrac></mrow></math></mathml>      (10) </p>
                </div>
                <div class="p1">
                    <p id="108"><i>R</i> (查全率) <mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mfrac><mrow><mtext>分</mtext><mtext>类</mtext><mtext>正</mtext><mtext>确</mtext><mtext>的</mtext><mtext>总</mtext><mtext>文</mtext><mtext>本</mtext><mtext>数</mtext></mrow><mrow><mtext>数</mtext><mtext>据</mtext><mtext>集</mtext><mtext>中</mtext><mtext>样</mtext><mtext>本</mtext><mtext>的</mtext><mtext>总</mtext><mtext>文</mtext><mtext>本</mtext><mtext>数</mtext></mrow></mfrac></mrow></math></mathml>      (11) </p>
                </div>
                <div class="p1">
                    <p id="110"><i>F</i><sub>1</sub> (调和平均值) <mathml id="111"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>=</mo><mfrac><mrow><mn>2</mn><mi>Ρ</mi><mi>R</mi></mrow><mrow><mi>Ρ</mi><mo>+</mo><mi>R</mi></mrow></mfrac></mrow></math></mathml>      (12) </p>
                </div>
                <h3 id="112" name="112" class="anchor-tag"><b>4 实验例证</b></h3>
                <div class="p1">
                    <p id="113">为验证SA-SVM中文文本分类的有效性和可行性, 采用SA-SVM对中文文本进行分类实验。实验的硬件平台:操作系统为Windows 10专业版, 处理器为Inter (R) Core (TM) i5-3210M CPU @2.50 GHz, 内存为10 GB, 硬盘为256 GB;软件平台:Python 2.7。为保证实验具有全面性和代表性, 使用复旦大学中文文本分类库和搜狗文本语料库进行对比实验。</p>
                </div>
                <div class="p1">
                    <p id="114">复旦大学中文文本分类库共有9 804篇训练文本, 9 833篇测试文本, 分为20个类别, 每一个文本只属于一个类别。去除重复和损坏的文本以及文本数小于100篇的稀有类别, 共有9个类别, 其中训练文本9 318篇, 测试文本9 331篇。经过SA优化的SVM参数[<i>C</i><sub>final</sub>, <i>σ</i><sub>final</sub>]=[100, 0.05], 将其代入分类模型重新训练学习, 与常用的文本算法比较, 实验结果如表3和图2所示。</p>
                </div>
                <div class="area_img" id="115">
                    <p class="img_tit"><b>表3 不同分类算法在复旦大学中文文本分类库的分类结果</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="115" border="1"><tr><td><br />分类算法</td><td>P</td><td>R</td><td>F<sub>1</sub></td></tr><tr><td><br />SA-SVM</td><td>95.9</td><td>96.0</td><td>95.9</td></tr><tr><td><br />Naïve Bayes</td><td>92.1</td><td>92.0</td><td>92.0</td></tr><tr><td><br />Logistic Regression</td><td>93.0</td><td>93.1</td><td>92.9</td></tr><tr><td><br />KNN</td><td>91.7</td><td>91.7</td><td>91.6</td></tr><tr><td><br />Decision Tree</td><td>90.1</td><td>90.2</td><td>90.2</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="116">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903050_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 不同分类算法在复旦大学中文文本分类库各类别分类精度" src="Detail/GetImg?filename=images/JYRJ201903050_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 不同分类算法在复旦大学中文文本分类库各类别分类精度  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903050_116.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="117">搜狗文本语料库共有9个类别, 每个类别1 990篇文本, 随机将每个类别的1 400篇文本分为训练文本, 590篇文本分为测试文本。经过SA优化的SVM参数[<i>C</i><sub>final</sub>, <i>σ</i><sub>final</sub>]=[10, 0.5], 将其代入分类模型重新训练学习, 与常用的文本算法比较, 实验结果如表4和图3所示。</p>
                </div>
                <div class="area_img" id="118">
                    <p class="img_tit"><b>表4 不同分类算法在搜狗文本语料库的分类结果</b> % <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="118" border="1"><tr><td><br />分类算法</td><td>P</td><td>R</td><td>F<sub>1</sub></td></tr><tr><td><br />SA-SVM</td><td>90.0</td><td>89.6</td><td>89.7</td></tr><tr><td><br />Naïve Bayes</td><td>85.1</td><td>84.4</td><td>84.6</td></tr><tr><td><br />Logistic Regression</td><td>88.4</td><td>87.9</td><td>88.1</td></tr><tr><td><br />KNN</td><td>83.5</td><td>83.5</td><td>83.3</td></tr><tr><td><br />Decision Tree</td><td>79.6</td><td>79.3</td><td>79.4</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="119">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201903050_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 不同分类算法在搜狗文本语料库的各类别分类准确率" src="Detail/GetImg?filename=images/JYRJ201903050_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 不同分类算法在搜狗文本语料库的各类别分类准确率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201903050_119.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="120">实验表明, 不同数据集的最优参数[<i>C</i><sub>final</sub>, <i>σ</i><sub>final</sub>]不同, 两组数据集通过SA全局寻优能力搜索到最优的SVM参数。经过SA优化参数的SVM分类模型, 相比其他中文文本分类算法, 在准确率、召回率和F<sub>1</sub>度量各个方面有明显的优势, 具有较强的泛化能力, 展现了较为显著的分类性能。</p>
                </div>
                <h3 id="121" name="121" class="anchor-tag"><b>5 结 语</b></h3>
                <div class="p1">
                    <p id="122">基于SVM的文本分类模型的泛化能力与其参数选择紧密相关, 为解决优化SVM参数难题, 本文提出了一个基于SA优化SVM参数的方法, 以最大化文本分类准确率为目标全局搜索SVM的最优参数[<i>C</i><sub>final</sub>, <i>σ</i><sub>final</sub>]。在设计算法流程时, 合理灵活地设置模拟退火的关键参数, 并引入记忆存储器以防止因执行概率接受环节遗漏中间最优解, 使得模拟退火算法更为智能。在设置内外循环终止条件时充分考虑实际情况, 在保证最优性的基础上尽可能减少不必要的计算量。实验结果比较表明, 基于SA-SVM中文文本分类模型具有良好的使用价值, 展现出了非常显著的分类性能, 为今后的文本分类建模提供了一种可行的思路。由于在综合考虑分类性能时未能做到充分的特征降维, 使得分类过程时间较长, 因此下一步的工作将在文本分类的特征降维方法上进行改进, 进一步提高模型的计算效率。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Online multi-label dependency topic models for text classification">

                                <b>[1]</b> Burkhardt S, Kramer S. Online multi-label dependency topic models for text classification[J]. Machine Learning, 2018, 107 (5) :1-28.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201202042&amp;v=MTUzNTBac0ZpRGhWTDdKTHo3TWFiRzRIOVBNclk5QlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 钟将, 刘荣辉. 一种改进的KNN文本分类[J]. 计算机工程与应用, 2012, 48 (2) :142-144.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Enhancing Performance of na?ve bayes in text classification by introducing an extra weight using less number of training examples">

                                <b>[3]</b> Shathi S P, Hossain M D, Nadim M, et al. Enhancing Performance of naïve bayes in text classification by introducing an extra weight using less number of training examples[C]//2016 International Workshop on Computational Intelligence (IWCI) . IEEE, 2017:142-147.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An improved Chi-sqaure feature selection for Arabic text classification using decision tree">

                                <b>[4]</b> Bahassine S, Madani A, Kissi M. An improved Chi-sqaure feature selection for Arabic text classification using decision tree[C]//International Conference on Intelligent Systems: Theories and Applications. IEEE, 2016.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JDYS201803004&amp;v=MTUwMDZHNEg5bk1ySTlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEaFZMN0pMeW5TZmI=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Goudjil M, Koudil M, Bedda M, et al. A novel active learning method using SVM for text classification[J]. International Journal of Automation and Computing, 2018 (3) :1-9.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSYZ201601008&amp;v=MzExMDFIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEaFZMN0pMejdTZExHNEg5Zk1ybzlGYklRS0Q=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 陈健飞, 蒋刚, 杨剑锋. 改进ABC-SVM的参数优化及应用[J]. 机械设计与制造, 2016 (1) :24-28.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJY201605030&amp;v=MjQzOTMzenFxQnRHRnJDVVI3cWZadVpzRmlEaFZMN0pMejdCZDdHNEg5Zk1xbzlHWklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 张进, 丁胜, 李波. 改进的基于粒子群优化的支持向量机特征选择和参数联合优化算法[J]. 计算机应用, 2016, 36 (5) : 1330-1335.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJZ201105055&amp;v=MDM1NDhIOURNcW85QVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGhWTDdKTHo3QmRMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 庄严, 白振林, 许云峰. 基于蚁群算法的支持向量机参数选择方法研究[J]. 计算机仿真, 2011, 28 (5) :216-219.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201806035&amp;v=MTk2Mjk5bk1xWTlHWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEaFZMN0pMejdCYjdHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> 陈晋音, 熊晖, 郑海斌. 基于粒子群算法的支持向量机的参数优化[J]. 计算机科学, 2018, 45 (6) :197-203.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ200907036&amp;v=MTI2MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVac0ZpRGhWTDdKTHpUWlpMRzRIdGpNcUk5R1lvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 王克奇, 杨少春, 戴天虹, 等. 采用遗传算法优化最小二乘支持向量机参数的方法[J].计算机应用与软件, 2009, 26 (7) :109-111.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201710039&amp;v=MjQwODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVpzRmlEaFZMN0pMejdCYjdHNEg5Yk5yNDlHYllRS0RIODQ=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 王万良, 陈超, 李笠, 等. 基于模拟退火的自适应水波优化算法[J]. 计算机科学, 2017, 44 (10) :216-221.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787118100372000&amp;v=MTk5NTRadkZ5bm5VcmZNSjE4VlhGcXpHYks1RnRETXI0eENadXNQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlpl&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 司守奎, 孙玺菁. 数学建模算法与应用[M]. 北京:国防工业出版社, 2015.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201903050" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201903050&amp;v=MzAxMDZxZlp1WnNGaURoVkw3Skx6VFpaTEc0SDlqTXJJOUFaSVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjc=&amp;uid=WEEvREcwSlJHSldRa1FhcEFLUmVhZDN5c2Q1UnJpL2tUTHpCSWVzVW9XYz0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
