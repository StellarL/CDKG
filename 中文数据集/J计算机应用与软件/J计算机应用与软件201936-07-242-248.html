<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135626641096250%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201907042%26RESULT%3d1%26SIGN%3dC%252bfGuXM35T%252fEW17X4NvqKQg7dxA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907042&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907042&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907042&amp;v=MTI2MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVNzdOTHpUWlpMRzRIOWpNcUk5QlpvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#41" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#54" data-title="&lt;b&gt;1 面部特征选取&lt;/b&gt; "><b>1 面部特征选取</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#70" data-title="&lt;b&gt;2 相关性实验&lt;/b&gt; "><b>2 相关性实验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#71" data-title="&lt;b&gt;2.1 人脸库&lt;/b&gt;"><b>2.1 人脸库</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;2.2 实验结果与分析&lt;/b&gt;"><b>2.2 实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#102" data-title="&lt;b&gt;3 BMI预测&lt;/b&gt; "><b>3 BMI预测</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#112" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#46" data-title="图1 与BMI显著相关的面部特征 (文献) ">图1 与BMI显著相关的面部特征 (文献) </a></li>
                                                <li><a href="#57" data-title="图2 脂肪厚度与BMI显著相关的面部区域 (文献) ">图2 脂肪厚度与BMI显著相关的面部区域 (文献) </a></li>
                                                <li><a href="#59" data-title="图3 本文提出的三个新的面部比例特征">图3 本文提出的三个新的面部比例特征</a></li>
                                                <li><a href="#61" data-title="图4 使用ASM获取的特征点位置示意图">图4 使用ASM获取的特征点位置示意图</a></li>
                                                <li><a href="#73" data-title="&lt;b&gt;表1 人脸库分组&lt;/b&gt;"><b>表1 人脸库分组</b></a></li>
                                                <li><a href="#96" data-title="&lt;b&gt;表2 训练组相关性实验结果&lt;/b&gt;"><b>表2 训练组相关性实验结果</b></a></li>
                                                <li><a href="#97" data-title="&lt;b&gt;表3 测试组相关性实验结果&lt;/b&gt;"><b>表3 测试组相关性实验结果</b></a></li>
                                                <li><a href="#98" data-title="&lt;b&gt;表4 整体人脸库相关性实验结果&lt;/b&gt;"><b>表4 整体人脸库相关性实验结果</b></a></li>
                                                <li><a href="#99" data-title="&lt;b&gt;表5 面部深度特征与BMI之间的相关系数&lt;i&gt;r&lt;/i&gt;&lt;/b&gt;"><b>表5 面部深度特征与BMI之间的相关系数<i>r</i></b></a></li>
                                                <li><a href="#108" data-title="图5 本文使用的BMI预测算法框图">图5 本文使用的BMI预测算法框图</a></li>
                                                <li><a href="#110" data-title="&lt;b&gt;表6 预测BMI的平均绝对误差&lt;/b&gt;"><b>表6 预测BMI的平均绝对误差</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" Renehan A G, Tyson M, Egger M, et al.Body-mass Index and Incidence of Cancer:A Systematic Review and Meta-analysis of Prospective Observational Studies[J].Lancet, 2008, 371 (9612) :569-578." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600045222&amp;v=MjQwODRxWTlGWk84S0RuNDdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRm9VYXhjPU5pZk9mYks3SHRETg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Renehan A G, Tyson M, Egger M, et al.Body-mass Index and Incidence of Cancer:A Systematic Review and Meta-analysis of Prospective Observational Studies[J].Lancet, 2008, 371 (9612) :569-578.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Zhang L.Face Gender Recognition Research Based on Local Features and Support Vector Machine[J].Applied Mechanics &amp;amp; Materials, 2014, 687-691:3714-3717." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJTT&amp;filename=SJTT14120300089517&amp;v=MTk5NTQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRm9VYXhjPU5pZmZlcks4SDlQTXJJOUZaT01HQ1gwK29CTVQ2VA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         Zhang L.Face Gender Recognition Research Based on Local Features and Support Vector Machine[J].Applied Mechanics &amp;amp; Materials, 2014, 687-691:3714-3717.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Gavrilescu M, Vizireanu N.Predicting the Sixteen Personality Factors (16PF) of an individual by analyzing facial features[J].Eurasip Journal on Image &amp;amp; Video Processing, 2017, 2017 (1) :59." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Predicting the Sixteen Personality Factors (16PF) of an individual by analyzing facial features">
                                        <b>[3]</b>
                                         Gavrilescu M, Vizireanu N.Predicting the Sixteen Personality Factors (16PF) of an individual by analyzing facial features[J].Eurasip Journal on Image &amp;amp; Video Processing, 2017, 2017 (1) :59.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Re D E, Rule N O.Heavy Matters:The Relationship Between Just Noticeable Differences in Perceptions of Facial Adiposity and Facial Attractiveness[J].Social Psychological and Personality Science, 2016, 7 (1) :69-76." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRS15121700004540&amp;v=MTg3NTZVcnpJSUZvVWF4Yz1OaWZaZmJLOUg5UE5xSTlGWk9zTENYZzVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         Re D E, Rule N O.Heavy Matters:The Relationship Between Just Noticeable Differences in Perceptions of Facial Adiposity and Facial Attractiveness[J].Social Psychological and Personality Science, 2016, 7 (1) :69-76.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Pascali M A, Giorgi D, Bastiani L, et al.Face morphology:can it tell us something about body weight and fat?[J].Computers in Biology &amp;amp; Medicine, 2016, 76:238-249." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD1EE21A7B508744BC40765BB554685E6&amp;v=MTE4NDBhQnVIWWZPR1FsZkJyTFUwNXR0aHhMeS93YTA9TmlmT2ZjZTVhNlRPcnY1Q0Z1NFBCSHM5eTJSZzdqOTZUbnFRM2hjd2ZiU2NRTStaQ09OdkZTaVdXcjdKSUZwbQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         Pascali M A, Giorgi D, Bastiani L, et al.Face morphology:can it tell us something about body weight and fat?[J].Computers in Biology &amp;amp; Medicine, 2016, 76:238-249.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Coetzee V, Perrett D I, Stephen I D.Facial adiposity:a cue to health?[J].Perception, 2009, 38 (11) :1700-1711." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJIX&amp;filename=SJIX6ABFB34478AF7D66B660A344B7C8575F&amp;v=MDQ5NjYwPU5pZkNkclhKYktlK3JJdEJZK04rZW50TnlSQmg3RGw5T1h6bXFHQXlDcnFSUXIvcENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMeS93YQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Coetzee V, Perrett D I, Stephen I D.Facial adiposity:a cue to health?[J].Perception, 2009, 38 (11) :1700-1711.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Coetzee V, Chen J, Perrett D I, et al.Deciphering faces:quantifiable visual cues to weight[J].Perception, 2010, 39 (1) :51-61." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJIX&amp;filename=SJIX3A324CD96F6C35E3D2E92480E1FC9DC8&amp;v=MDczNzZZcDBKZjM4OHVoVm42RXAwU252cXJHYzBEOEdkTWNtWENPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMeS93YTA9TmlmQ2RyREpIZFBJM1B0TQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Coetzee V, Chen J, Perrett D I, et al.Deciphering faces:quantifiable visual cues to weight[J].Perception, 2010, 39 (1) :51-61.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Pham D D, Do J H, Ku B, et al.Body Mass Index and Facial Cues in Sasang Typology for Young and Elderly Persons[J].Evidence-based Complementary and Alternative Medicine, 2011, 2011:749209." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD120615018091&amp;v=MTM5MzFuS3JpZlplWnZGeW5tVTcvTUlGOFJOaWZEYXJLNkh0Zk5xbzlFYk9zR0RSTTh6eFVTbURkOVNIN24zeEU5ZmJ2&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Pham D D, Do J H, Ku B, et al.Body Mass Index and Facial Cues in Sasang Typology for Young and Elderly Persons[J].Evidence-based Complementary and Alternative Medicine, 2011, 2011:749209.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Wen L, Guo G.A computational approach to body mass index prediction from face images[J].Image &amp;amp; Vision Computing, 2013, 31 (5) :392-400." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600233483&amp;v=MjYzMDhJRm9VYXhjPU5pZk9mYks4SHRETXFZOUZadWdNQ0hRNm9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Wen L, Guo G.A computational approach to body mass index prediction from face images[J].Image &amp;amp; Vision Computing, 2013, 31 (5) :392-400.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Cootes T F, Taylor C J, Cooper D H, et al.Active Shape Models-Their Training and Application[J].Computer Vision &amp;amp; Image Understanding, 1995, 61 (1) :38-59." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501084429&amp;v=MTY5NDRxbzlFWk9NTENINHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRm9VYXhjPU5pZk9mYks3SHRETg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Cootes T F, Taylor C J, Cooper D H, et al.Active Shape Models-Their Training and Application[J].Computer Vision &amp;amp; Image Understanding, 1995, 61 (1) :38-59.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Barr M L, Guo G, Colby S E, et al.Detecting Body Mass Index from a Facial Photograph in Lifestyle Intervention[J].Technologies, 2018, 6 (3) :83." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting Body Mass Index from a Facial Photograph in Lifestyle Intervention">
                                        <b>[11]</b>
                                         Barr M L, Guo G, Colby S E, et al.Detecting Body Mass Index from a Facial Photograph in Lifestyle Intervention[J].Technologies, 2018, 6 (3) :83.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Kocabey E, Camurcu M, Ofli F, et al.Face-to-BMI:Using Computer Vision to Infer Body Mass Index on Social Media[C]//The Eleventh International AAAI Conference on Web and Social Media, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Face-to-BMI:Using Computer Vision to Infer Body Mass Index on Social Media">
                                        <b>[12]</b>
                                         Kocabey E, Camurcu M, Ofli F, et al.Face-to-BMI:Using Computer Vision to Infer Body Mass Index on Social Media[C]//The Eleventh International AAAI Conference on Web and Social Media, 2017.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Satoh M, Mori S, Yoshizuka N, et al.Facial distribution of subcutaneous fat in women[J].International Journal of Cosmetic Science, 2010, 26 (5) :266-266." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00000696694&amp;v=MzI0MzlsVTd2SUlWcz1OaWZjYXJPNEh0SE1xWVpEWXVJTFkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWRaK1p1Rml2&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         Satoh M, Mori S, Yoshizuka N, et al.Facial distribution of subcutaneous fat in women[J].International Journal of Cosmetic Science, 2010, 26 (5) :266-266.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Mayer C, Windhager S, Schaefer K, et al.BMI and WHR Are Reflected in Female Facial Shape and Texture:A Geometric Morphometric Image Analysis[J].Plos One, 2017, 12 (1) :e0169336." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=BMI and WHR are reflected in female facial shape and texture:a geometric morphometric image analysis">
                                        <b>[14]</b>
                                         Mayer C, Windhager S, Schaefer K, et al.BMI and WHR Are Reflected in Female Facial Shape and Texture:A Geometric Morphometric Image Analysis[J].Plos One, 2017, 12 (1) :e0169336.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Wilcox R R.Fundamentals of modern statistical methods:Substantially improving power and accuracy[J].Journal of the Royal Statistical Society Series D (The Statistician) , 2002, 51 (4) :590-591." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Fundamentals of modern statistical methods:Substantially improving power and accuracy">
                                        <b>[15]</b>
                                         Wilcox R R.Fundamentals of modern statistical methods:Substantially improving power and accuracy[J].Journal of the Royal Statistical Society Series D (The Statistician) , 2002, 51 (4) :590-591.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" Yang Z R.Single-Layer Neural Net Competes with Multi-layer Neural Net[M]//Intelligent Data Engineering and Automated Learning—IDEAL 2008.Springer Berlin Heidelberg, 2008:516-524." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Single-Layer Neural Net Competes with Multi-layer Neural Net">
                                        <b>[16]</b>
                                         Yang Z R.Single-Layer Neural Net Competes with Multi-layer Neural Net[M]//Intelligent Data Engineering and Automated Learning—IDEAL 2008.Springer Berlin Heidelberg, 2008:516-524.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Jeong K, Moon H, Kim S.3D Face Representation Using Inverse Compositional Image Alignment for Multimodal Face Recognition[M]//Frontier and Innovation in Future Computing and Communications.Springer Netherlands, 2014:423-429." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=3D Face Representation Using Inverse Compositional Image Alignment for Multimodal Face Recognition">
                                        <b>[17]</b>
                                         Jeong K, Moon H, Kim S.3D Face Representation Using Inverse Compositional Image Alignment for Multimodal Face Recognition[M]//Frontier and Innovation in Future Computing and Communications.Springer Netherlands, 2014:423-429.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Sharma A, Haj M A, Choi J, et al.Robust pose invariant face recognition using coupled latent space discriminant analysis[J].Computer Vision &amp;amp; Image Understanding, 2012, 116 (11) :1095-1110." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083298&amp;v=MjQ2MjZETnFvOUVaT01NRG5VeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SUlGb1VheGM9TmlmT2ZiSzdIdA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[18]</b>
                                         Sharma A, Haj M A, Choi J, et al.Robust pose invariant face recognition using coupled latent space discriminant analysis[J].Computer Vision &amp;amp; Image Understanding, 2012, 116 (11) :1095-1110.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Zhang Y N, Guo Z, Xia Y, et al.2D representation of facial surfaces for multi-pose 3D face recognition[J].Pattern Recognition Letters, 2012, 33 (5) :530-536." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413320&amp;v=MTEzMjNpclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUZvVWF4Yz1OaWZPZmJLN0h0RE9ySTlGWU9vTUQzNDVvQk1UNlQ0UFFILw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[19]</b>
                                         Zhang Y N, Guo Z, Xia Y, et al.2D representation of facial surfaces for multi-pose 3D face recognition[J].Pattern Recognition Letters, 2012, 33 (5) :530-536.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(07),242-248 DOI:10.3969/j.issn.1000-386x.2019.07.041            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于人脸图像的BMI预测算法研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B9%E7%9D%BF%E6%99%BA&amp;code=39449977&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邹睿智</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%9A%E5%AA%9B%E5%9B%AD&amp;code=21887500&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">尚媛园</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%83%AD%E5%9B%BD%E6%A0%8B&amp;code=38184549&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">郭国栋</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E9%82%B5%E7%8F%A0%E5%AE%8F&amp;code=34964239&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">邵珠宏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%81%E8%BE%89&amp;code=23740820&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">丁辉</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%A6%96%E9%83%BD%E5%B8%88%E8%8C%83%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&amp;code=0044636&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">首都师范大学信息工程学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E6%88%90%E5%83%8F%E6%8A%80%E6%9C%AF%E9%AB%98%E7%B2%BE%E5%B0%96%E5%88%9B%E6%96%B0%E4%B8%AD%E5%BF%83&amp;code=0217877&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京成像技术高精尖创新中心</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%BC%97%E5%90%89%E5%B0%BC%E4%BA%9A%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E7%94%B5%E6%B0%94%E5%B7%A5%E7%A8%8B%E7%B3%BB&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西弗吉尼亚大学计算机科学与电气工程系</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%8A%80%E6%9C%AF%E5%8C%97%E4%BA%AC%E5%B8%82%E9%87%8D%E7%82%B9%E5%AE%9E%E9%AA%8C%E5%AE%A4&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">电子系统可靠性技术北京市重点实验室</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>BMI是目前国际上常用的衡量人体胖瘦程度以及是否健康的一个标准。通常情况下, BMI是由个体的身高和体重计算得到的。目前, 国外的研究人员提出了基于人脸图像预测BMI的算法, 通过构建面部特征与BMI之间的关联集合, 利用SVR回归模型进行BMI预测工作。该算法在实验室实验环境下表现良好, 但在日常生活应用环境下仍有较大的预测误差。为了提高BMI预测算法在日常生活应用环境下的预测精度, 提出面部区域面积比 (RAR) 、嘴颌宽度比 (MJWR) 和颊宽高度比 (CWHR) 这三种新的面部特征用于补充改进BMI预测算法, 同时使用神经网络拟合代替SVR回归进行BMI预测实验。实验结果表明, 在日常生活应用环境下, 改进的BMI预测算法使得预测结果更加精确, BMI预测的平均绝对误差 (MAE) 降低了0.7。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BMI&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BMI;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%A2%E9%83%A8%E7%89%B9%E5%BE%81&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">面部特征;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BMI%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BMI预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%8B%9F%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">神经网络拟合;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    邹睿智, 硕士生, 主研领域:计算机视觉。;
                                </span>
                                <span>
                                    尚媛园, 教授。;
                                </span>
                                <span>
                                    郭国栋, 副教授。;
                                </span>
                                <span>
                                    邵珠宏, 副教授。;
                                </span>
                                <span>
                                    丁辉, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61876112, 61601311, 61603022);</span>
                                <span>北京市属高校高水平教师队伍建设支持计划项目 (CIT&amp;TCD20170322);</span>
                                <span>北京市优秀人才资助项目 (2016000020124G088);</span>
                                <span>北京市教委科研计划项目 (SQKM201810028018);</span>
                                <span>首都师范大学青年科研创新团队项目;</span>
                    </p>
            </div>
                    <h1><b>BMI PREDICTION ALGORITHM BASED ON FACE IMAGES</b></h1>
                    <h2>
                    <span>Zou Ruizhi</span>
                    <span>Shang Yuanyuan</span>
                    <span>Guo Guodong</span>
                    <span>Shao Zhuhong</span>
                    <span>Ding Hui</span>
            </h2>
                    <h2>
                    <span>College of Information Engineering, Capital Normal University</span>
                    <span>Beijing Advanced Innovation Center for Imaging Technology</span>
                    <span>Department of Computer Science and Electrical Engineering, West Virginia University</span>
                    <span>Beijing Key Laboratory of Electronic System Reliability Technology</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>BMI is a standard commonly used in the world to measure the obesity and health of the human body. Usually, the BMI is calculated from the height and weight of the individual. Nowadays, researchers have proposed the algorithm of the BMI prediction based on face images. They built the collection set between facial features and BMI, and predicted the BMI by SVR regression model. The algorithm performs well in the laboratory test environment, but there is still a large error when it is used in daily application. For improving prediction accuracy of the algorithm in daily application, we proposed three new facial features added to the algorithm. They are the region-to-area ratio (RAR) , the mouth-to-jaw-width ratio (MJWR) and the cheek width-to-height ratio (CWHR) . In addition, a neural network fitting model was used in BMI prediction instead of SVR regression. The experimental results show that in the daily life application environment, the improved BMI prediction algorithm makes the prediction results more accurate, and the MAE of BMI prediction is reduced by 0.7.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BMI&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BMI;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Facial%20features&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Facial features;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=BMI%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">BMI prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Neural%20network%20fitting&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Neural network fitting;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="41" name="41" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="42">随着经济的发展与社会的进步, 人们对健康问题的关注程度也日益增加。肥胖是一种严重影响身体健康的公共卫生问题, 因肥胖而引起的慢性疾病已经严重威胁到人们的健康。我国正处于经济快速稳步发展时期, 物质生活极大丰富所带来的肥胖问题已经严重影响了人民的身体健康水平。</p>
                </div>
                <div class="p1">
                    <p id="43">BMI是世界公认的一种评定肥胖程度的指标, 可以用来衡量人体胖瘦程度以及评估人体是否健康。在世界卫生组织 (WHO) 标准中, BMI被分为6个等级:偏瘦 (BMI&lt;18.5) , 正常 (18.5≤BMI&lt;25) , 超重 (25≤BMI&lt;30) , 肥胖 (30≤BMI&lt;35) , 重度肥胖 (35≤BMI&lt;40) , 极重度肥胖 (BMI≥40) 。BMI值越高, 表示个体的肥胖程度越严重。同时, 伴随着BMI值的升高, 某些疾病的患病率也会随之增加。Andrew等<citation id="114" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>通过研究发现, BMI与一些常见的成人癌症发病率之间具有关联性, 这些癌症的发病率随着BMI值的增加而升高。</p>
                </div>
                <div class="p1">
                    <p id="44">通常情况下, BMI是由个体的身高和体重计算得到的, 而在国民肥胖程度统计和国民健康程度监测工作中, 通过测量来获取每个公民的身高和体重数据是不切实际的。随着生物特征识别技术的发展, 研究人员通过分析个体的面部特征, 可以得到性别、种族、年龄、表情、性格偏好和面部吸引力等多种信息<citation id="115" type="reference"><link href="5" rel="bibliography" /><link href="7" rel="bibliography" /><link href="9" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。同时, 国外的研究人员也发现并证实人的面部特征与BMI之间具有显著的关联性。因此, 在获取个体身高体重数据较为困难或目标样本数目过于庞大的应用场景下, 基于人脸图像预测BMI的方法相比于传统的身高体重计算法有着巨大的优势。</p>
                </div>
                <div class="p1">
                    <p id="45">在社会心理学和医学领域, Pascali等<citation id="116" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>发现, 人的面部形态与体重和脂肪含量具有高度相关性。Coetzee等<citation id="117" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>招募了84名志愿者 (41名男性和43名女性) 参与实验, 在光照充足的条件下采集志愿者的面部图像, 统计他们的身高体重以及其他与实验相关的信息, 通过实验分析证明面部肥胖与心血管健康有关联, 且面部肥胖与BMI之间也有显著的相关性。随后, Coetzee等<citation id="118" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>在前作的基础上寻找与体重相关的可量化面部特征, Coetzee和他们的研究人员拍摄了95名白种人和99名非洲参与者的面部图像, 利用计算机软件根据瞳孔间距对齐所有的图像, 然后在每张照片上手动标记179个特征点以获取相应的特征数据, 这些特征数据与BMI之间的相关性用Pearson系数来衡量。研究表明, 面部宽高比 (width-to-height ratio, WHR) 、脸部周长与面积比 (perimeter-to-area ratio, PAR) 以及面颊与颌宽度比 (cheek-to-jaw-width ratio, 简称CJWR) 这3种特征 (如图1所示) 与BMI具有显著相关性。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907042_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 与BMI显著相关的面部特征 (文献[7])" src="Detail/GetImg?filename=images/JYRJ201907042_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 与BMI显著相关的面部特征 (文献<citation id="119" type="reference">[<a class="sup">7</a>]</citation>)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907042_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="47">Pham等<citation id="120" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>在文献<citation id="121" type="reference">[<a class="sup">7</a>]</citation>研究的基础之上, 提出了7种与BMI相关的面部特征, 这7种面部特征包含了文献<citation id="122" type="reference">[<a class="sup">7</a>]</citation>中使用的3种面部特征以及新提出的4种面部特征。这4种面部特征为:眼睛宽度 (the eye width, ES) 、面部长度比 (the lower face to face height ratio, LFH/FH) 、颧高比 (face width to the lower face height ratio, FW/LFH) 和眉眼均距 (the average distance between eyebrows and the upper edge of eyes, MEH) 。Pham与他的研究人员采集了911名志愿者的面部图像以及身高体重数据, 在面部图像中提取相应的7种面部特征, 分别计算7种特征与BMI之间的Pearson系数。实验证实, 这7种面部特征与BMI之间均具有一定的相关性。</p>
                </div>
                <div class="p1">
                    <p id="48">Coetzee和Pham等仅研究了面部特征与BMI之间的相关性, 受限于手工标记样本点方法的局限性以及实验样本不足带来的影响, 并没有验证面部特征能否用于预测BMI。因此, 计算机科学以及生物识别领域的研究人员在这7种面部特征的基础上增加测试样本数量, 同时使用面部特征提取算法代替人工标记样本的方法, 开发出了基于人脸图像的BMI预测算法。</p>
                </div>
                <div class="p1">
                    <p id="49">Wen<citation id="123" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>在Coetzee和Pham的研究<citation id="125" type="reference"><link href="13" rel="bibliography" /><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation>的基础上, 首次提出了利用大型数据库来验证面部特征与BMI之间的关联性。Wen使用Active Shape Model (ASM) <citation id="124" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>提取人脸图像的7种特征数据 (Coetzee和Pham提出的7种面部特征) , 计算其与BMI之间的相关性。同时利用这些面部特征与BMI构建“多对一”关联集合, 使用SVR回归模型预测BMI。实验结果证实了人脸特征预测BMI的可行性, 不足之处在于实验中使用的样本是类似于证件照的面部图像, 背景纯净, 光照充足, 头部姿态单一。因此, 该算法能否用于日常生活应用环境下的监测工作有待验证。</p>
                </div>
                <div class="p1">
                    <p id="50">Barr等<citation id="126" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>为了验证Wen的BMI预测算法能否应用在日常生活场景下, 收集了1 412名志愿者的日常生活照片, 记录他们的身高体重数据建立人脸数据库并测试文献<citation id="127" type="reference">[<a class="sup">9</a>]</citation>中提出的BMI预测算法。实验结果表明, 该算法在日常生活环境中使用时, BMI预测算法的精度降低。但Barr等并没有给出预测精度降低的原因, 也没有提出相应的改进算法。</p>
                </div>
                <div class="p1">
                    <p id="51">Kocabey等<citation id="128" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>提出了利用深度卷积网络 (VGG-net和VGG-face) 来提取面部的深度特征, 并利用深度特征建立回归预测模型 (epsilon支持向量回归模型) 的方法。但他们只计算了深度特征与BMI之间的Pearson相关性, 并没有给出BMI预测精度, 深度特征能否用于人脸图像预测BMI还有待验证。</p>
                </div>
                <div class="p1">
                    <p id="52">目前, 国外关于人脸图像预测BMI的研究较少, 国内研究尚未涉及与该方向相关的课题。考虑到文献<citation id="129" type="reference">[<a class="sup">9</a>]</citation>中提出的预测算法较为完善, 且该课题方向的其他研究人员并未给出改进的预测算法, 本文将主要与文献<citation id="130" type="reference">[<a class="sup">7</a>,<a class="sup">8</a>,<a class="sup">9</a>]</citation>中的实验结果进行对比。</p>
                </div>
                <div class="p1">
                    <p id="53">本文提出了三种与BMI相关性较强的新面部特征, 与文献<citation id="131" type="reference">[<a class="sup">7</a>]</citation>和文献<citation id="132" type="reference">[<a class="sup">8</a>]</citation>中提出的面部特征相比较, 本文提出的面部特征与BMI之间的相关性更强。同时, 本文基于文献<citation id="133" type="reference">[<a class="sup">9</a>]</citation>的研究内容改进预测算法, 保留了文献<citation id="134" type="reference">[<a class="sup">9</a>]</citation>中与BMI相关性较强的面部特征, 与本文提出的三种新面部特征共同构成面部特征集合, 并利用神经网络拟合代替SVR回归进行BMI预测, 实验结果证明, 日常生活应用环境下本文算法的BMI预测精度得到提高。</p>
                </div>
                <h3 id="54" name="54" class="anchor-tag"><b>1 面部特征选取</b></h3>
                <div class="p1">
                    <p id="55">为了能更加准确地预测BMI, 面部特征对面部肥胖和面部脂肪变化应具有较强的敏感性。因此, 我们在生物学和医学领域寻找相关研究以帮助我们寻找新的特征来提高算法的预测精度。</p>
                </div>
                <div class="p1">
                    <p id="56">Satoh等<citation id="135" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>使用核磁共振成像 (Magnetic Resonance Imaging, MRI) 技术, 拍摄了38名志愿者 (偏瘦10人, 正常18人, 肥胖10人) 的面部脂肪分布剖面图, 计算面部脂肪厚度与BMI之间的关联性。研究表明, 面部脂肪厚度与BMI之间存在相关性, 同时, 某些特定面部区域的脂肪厚度与BMI之间呈现出比其他面部区域更强的相关性, 这些区域标记在图2中。Mayer等<citation id="136" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation> 通过几何形态测量学和图像分析相结合的方法, 评估了中欧年轻女性样本中BMI与面部形状和纹理的关系, 该研究发现, 嘴部宽度与BMI之间具有一定的关联性。</p>
                </div>
                <div class="area_img" id="57">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907042_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 脂肪厚度与BMI显著相关的面部区域 (文献[13])" src="Detail/GetImg?filename=images/JYRJ201907042_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 脂肪厚度与BMI显著相关的面部区域 (文献<citation id="137" type="reference">[<a class="sup">13</a>]</citation>)   <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907042_057.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="58">Satoh和Mayer等的研究为寻找新的面部比例特征提供了强有力的数据支持, 我们希望依据这些数据支持来定位和提取新的面部特征, 从而使得新面部特征与BMI之间具有较强的关联性。基于此, 我们提出了三种新的特征用于人脸图像预测BMI的研究。这三种新的特征是面部区域面积比 (the region-to-area ratio, RAR) 、嘴颌宽度比 (the mouth-to-jaw-width ratio, MJWR) 和颊宽高度比 (the cheek width-to-height ratio, CWHR) 。图3给出了三种面部比例特征的示意。在实验过程中, 我们使用ASM获取面部特征点的坐标, 然后通过坐标计算相应的特征数值。为了保证特征点定位准确, 我们对每张人脸图像都采取了人工监督, 对定位不准的特征点加以修正。</p>
                </div>
                <div class="area_img" id="59">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907042_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 本文提出的三个新的面部比例特征" src="Detail/GetImg?filename=images/JYRJ201907042_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 本文提出的三个新的面部比例特征  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907042_059.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="60">图4是ASM特征点提取示意图, 每个特征点都有唯一的数字标号。通过这些特征点, 可以计算点与点之间的距离, 也可以计算多个点围成区域的面积或周长。面部区域面积比 (RAR) 表示的是两个面部区域之间的面积比值, 因此我们用<i>S</i> (<i>P</i><sub>0</sub><i>P</i><sub>4</sub><i>P</i><sub>8</sub><i>P</i><sub>12</sub><i>P</i><sub>16</sub>) 表示点0、4、8、12、16围成的面部区域的面积, 同理, 用<i>S</i> (<i>P</i><sub>36</sub><i>P</i><sub>48</sub><i>P</i><sub>54</sub><i>P</i><sub>45</sub>) 来表示点36、48、54、45围成的区域面积。嘴颌宽度比 (MJWR) 和颊宽高度比 (CWHR) 表示的是“宽-宽比”以及“长-宽比”, 因此用<i>P</i><sub><i>x</i></sub><i>P</i><sub><i>y</i></sub>表示<i>x</i>点与<i>y</i>点之间的距离, 以此来计算特征数据。例如点48与点54之间的距离代表了嘴部宽度, 因此使用<i>P</i><sub>48</sub><i>P</i><sub>54</sub>来表示嘴部宽度, 点4与点12之间的距离表示了颌部宽度, 因此使用<i>P</i><sub>4</sub><i>P</i><sub>12</sub>来表示颌部宽度, 两者的比值即为嘴颌宽度比 (MJWR) , 同理可以计算颊宽高度比 (CWHR) 。</p>
                </div>
                <div class="area_img" id="61">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907042_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 使用ASM获取的特征点位置示意图" src="Detail/GetImg?filename=images/JYRJ201907042_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 使用ASM获取的特征点位置示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907042_061.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="62">RAR、MJWR、CWHR的计算公式如下所示:</p>
                </div>
                <div class="p1">
                    <p id="63"><mathml id="64"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mn>0</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mn>4</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>6</mn></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>3</mn><mn>6</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>4</mn><mn>8</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>5</mn><mn>4</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>4</mn><mn>5</mn></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (1) </p>
                </div>
                <div class="p1">
                    <p id="65"><mathml id="66"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><mi>J</mi><mi>W</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>4</mn><mn>8</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>5</mn><mn>4</mn></mrow></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>4</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mrow></mfrac></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="67"><mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>W</mi><mi>Η</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>2</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>4</mn></mrow></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>7</mn></mrow></msub></mrow></mfrac></mrow></math></mathml>      (3) </p>
                </div>
                <div class="p1">
                    <p id="69">式中:<i>P</i><sub><i>x</i></sub><i>P</i><sub><i>y</i></sub>表示<i>x</i>点与<i>y</i>点之间的距离;<i>S</i> (<i>P</i><sub><i>x</i></sub><i>P</i><sub><i>y</i></sub><i>P</i><sub><i>z</i></sub>) 表示<i>x</i>、<i>y</i>、<i>z</i>点围成的面部区域的面积。</p>
                </div>
                <h3 id="70" name="70" class="anchor-tag"><b>2 相关性实验</b></h3>
                <h4 class="anchor-tag" id="71" name="71"><b>2.1 人脸库</b></h4>
                <div class="p1">
                    <p id="72">本文使用的人脸库包含了1 538张带有BMI标签的人脸照片。我们以WHO规定的BMI等级为标准对人脸库进行了分组, 并分别计算每组人脸样本的BMI预测精度和整体的预测精度。表1给出了人脸库的分组情况 (训练组1 024张, 测试组514张) 。在实验分组中, 并没有设计偏瘦 (BMI&lt;18.5) 分组, 这是因为该级别在人脸库中对应的样本极少 (占总样本数的0.58%) , 因此并不具备统计意义。</p>
                </div>
                <div class="area_img" id="73">
                    <p class="img_tit"><b>表1 人脸库分组</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="73" border="1"><tr><td>组别</td><td>BMI级别</td><td>样本数</td><td>总计</td></tr><tr><td rowspan="5"><br />训练组</td><td><br />正常 (18.5≤BMI&lt;25) </td><td>152</td><td rowspan="5">1 024</td></tr><tr><td><br />超重 (25≤BMI&lt;30) </td><td>345</td></tr><tr><td><br />肥胖 (30≤BMI&lt;35) </td><td>230</td></tr><tr><td><br />重度肥胖 (35≤BMI&lt;40) </td><td>147</td></tr><tr><td><br />极重度肥胖 (BMI&gt;40) </td><td>50</td></tr><tr><td rowspan="5"><br />测试组</td><td><br />正常 (18.5≤BMI&lt;25) </td><td>77</td><td rowspan="5">514</td></tr><tr><td><br />超重 (25≤BMI&lt;30) </td><td>172</td></tr><tr><td><br />肥胖 (30≤BMI&lt;35) </td><td>115</td></tr><tr><td><br />重度肥胖 (35≤BMI&lt;40) </td><td>74</td></tr><tr><td><br />极重度肥胖 (BMI&gt;40) </td><td>76</td></tr><tr><td><br />总计</td><td colspan="3">1 538</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="74">与文献<citation id="138" type="reference">[<a class="sup">9</a>]</citation>使用的人脸库不同, 该人脸库所包含的人脸照片像素各不相同, 头部姿态与背景环境也有十分大的差异。文献<citation id="139" type="reference">[<a class="sup">9</a>]</citation>使用的人脸库样本类似于证件照, 本算法使用的人脸库样本从分辨率、光照条件、拍摄角度以及背景的复杂程度都更加接近于监测设备拍摄的日常生活照。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.2 实验结果与分析</b></h4>
                <div class="p1">
                    <p id="76">为了验证面部特征与BMI之间的相关性, 本文使用皮尔逊相关系数以及假设检验来衡量面部特征与BMI之间的相关程度。皮尔逊相关系数能够衡量有限的样本数量与目标之间的相关性, 可以用<i>r</i>来表示。在假设检验中, 我们假设面部特征与BMI之间没有任何的关联性, 如果<i>p</i>-<i>value</i>很小, 则放弃假设, 表示BMI与面部特征之间有一定的关联性, 反之, 则接受假设, 表示面部特征与BMI之间没有任何关联性。当<i>p</i>-<i>value</i>小于一定阈值 (0.001, 0.01或0.05) 时, 就可以认为我们的假设是错误的, 因此可以证实面部特征与BMI之间具有相关性<citation id="140" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="77">皮尔逊相关系数的计算公式如下:</p>
                </div>
                <div class="p1">
                    <p id="78"><mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>r</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>X</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>Y</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>X</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>X</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false"> (</mo></mstyle><mi>Y</mi><msub><mrow></mrow><mi>i</mi></msub><mo>-</mo><mover accent="true"><mi>Y</mi><mo stretchy="true">¯</mo></mover><mo stretchy="false">) </mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mrow></math></mathml>      (4) </p>
                </div>
                <div class="p1">
                    <p id="80">式中:<i>X</i><sub><i>i</i></sub>表示第<i>i</i>个样本的特征值, <i>Y</i><sub><i>i</i></sub>表示第<i>i</i>个样本的BMI, <i>n</i>表示样本数量, <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>X</mi><mo stretchy="true">¯</mo></mover></mrow></math></mathml>和<mathml id="82"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>Y</mi><mo stretchy="true">¯</mo></mover></mrow></math></mathml>分别表示<i>n</i>个样本的特征值均值和BMI均值。<i>r</i>的取值范围为[-1, 1], <i>r</i>的绝对值越大, 则说明<i>X</i>与<i>Y</i>之间的相关性越强。</p>
                </div>
                <div class="p1">
                    <p id="83">为了方便对比相关性实验结果, 本文中给出了Coetzee等提出的3种面部特征与BMI之间的相关性以及Pham等提出的4种面部特征与BMI之间的相关性, 同时给出了Kocabey等使用的面部深度特征与BMI之间的相关性。Coetzee等使用的面部特征为颊颌宽度比、面部宽高比和面部周长面积比, Pham等使用的面部特征为眼睛宽度、面部长度比、颧高比和眉眼均距。其中, ES与MEH是面部绝对尺寸特征, 仅适用于固定焦距拍摄的面部图像, 对样本的要求过于严苛, 并不适用于日常生活环境下人脸图像预测BMI的算法, 因此暂不考虑使用这2种面部特征, 只考虑剩余的2种面部比例特征 (LFH/FH和FW/LFH) 。图4给出了ASM提取特征点的示意图, 式 (5) -式 (9) 解释了Coetzee和Pham提出的5种面部比例特征的获取方法, 计算方式与前文中提到的新的三种面部特征相同。Kocabey等的研究并未说明深度学习能否应用于人脸图像预测BMI, 因此对于面部的深度特征与BMI之间的相关性暂时仅作为参考进行对比, 在获取充足的实验样本以及已有算法成熟的基础上, 我们将会就面部深度特征进行研究。</p>
                </div>
                <div class="p1">
                    <p id="84"><mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>J</mi><mi>W</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>0</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>6</mn></mrow></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>4</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mrow></mfrac></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="86"><mathml id="87"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><mi>Η</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>4</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>7</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>6</mn><mn>4</mn></mrow></msub></mrow></mfrac></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="88"><mathml id="89"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Ρ</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>C</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mn>0</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mn>4</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>6</mn></mrow></msub><mo stretchy="false">) </mo></mrow><mrow><mi>S</mi><mo stretchy="false"> (</mo><mi>Ρ</mi><msub><mrow></mrow><mn>0</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mn>4</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>2</mn></mrow></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>6</mn></mrow></msub><mo stretchy="false">) </mo></mrow></mfrac></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="90"><mathml id="91"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>L</mi><mi>F</mi><mi>Η</mi><mo>/</mo><mi>F</mi><mi>Η</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>7</mn></mrow></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="92"><mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><mi>W</mi><mo>/</mo><mi>L</mi><mi>F</mi><mi>Η</mi><mo>=</mo><mfrac><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>0</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>1</mn><mn>6</mn></mrow></msub></mrow><mrow><mi>Ρ</mi><msub><mrow></mrow><mn>8</mn></msub><mi>Ρ</mi><msub><mrow></mrow><mrow><mn>2</mn><mn>7</mn></mrow></msub></mrow></mfrac></mrow></math></mathml>      (9) </p>
                </div>
                <div class="p1">
                    <p id="94"><i>P</i><sub><i>x</i></sub><i>P</i><sub><i>y</i></sub>表示<i>x</i>点与<i>y</i>点之间的距离;<i>C</i> (<i>P</i><sub><i>x</i></sub><i>P</i><sub><i>y</i></sub><i>P</i><sub><i>z</i></sub>) 表示点<i>x</i>、<i>y</i>、<i>z</i>围成的多边形的周长;<i>S</i> (<i>P</i><sub><i>x</i></sub><i>P</i><sub><i>y</i></sub><i>P</i><sub><i>z</i></sub>) 表示点<i>x</i>、<i>y</i>、<i>z</i>围成的多边形的面积;点<i>N</i>是由已知特征点推测得来的, 设点<i>N</i>1为点19和点20连线的中点, 连接点<i>N</i>1 与点36成一条直线, 设为直线<i>L</i>1;设点<i>N</i>2为点23和点24连线的中点, 连接点<i>N</i>2与点45成一条直线, 设为直线<i>L</i>2, 直线<i>L</i>1与直线<i>L</i>2的交点即为点<i>N</i>。</p>
                </div>
                <div class="p1">
                    <p id="95">实验过程中, 我们分别计算了本文提出的RAR、MJWR和CWHR与BMI之间的相关性以及Coetzee和Pham使用的CJWR、WHR、PAR、LFH/FH和FW/LFH与BMI之间的相关性。为了得出更加严谨的实验结论, 我们分别在训练组、测试组和整个人脸库上进行了相关性实验, 表2、表3和表4分别给出了训练组、测试组以及整个人脸库中的相关性计算结果。实验结果以皮尔逊相关系数<i>r</i>和假设检验的<i>p</i>-<i>value</i>来表示。<i>r</i>的取值范围为[-1, 1], <i>r</i>的绝对值越大, 说明面部特征与BMI之间的相关性越强;<i>p</i>-<i>value</i>的值越小, 说明面部特征与BMI之间的相关性越强, 反之, 则说明面部特征与BMI之间的关联性较弱。表5给出了Kocabey等使用的深度特征与BMI之间的相关性。</p>
                </div>
                <div class="area_img" id="96">
                    <p class="img_tit"><b>表2 训练组相关性实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="96" border="1"><tr><td>研究</td><td>面部特征</td><td><i>r</i></td><td><i>p</i>-<i>value</i></td></tr><tr><td rowspan="3"><br />Coetzee等<sup>[7]</sup></td><td><br />CJWR</td><td>-0.489 5</td><td>0.000 0</td></tr><tr><td><br />WHR</td><td>0.549 5</td><td>0.000 0</td></tr><tr><td><br />PAR</td><td>-0.119 6</td><td>0.000 1</td></tr><tr><td rowspan="2"><br />Pham等<sup>[8]</sup></td><td><br />FW/LFH</td><td>0.320 8</td><td>0.000 0</td></tr><tr><td><br />LFH/FH</td><td>0.165 5</td><td>0.000 0</td></tr><tr><td rowspan="3"><br />本文</td><td><br />RAR</td><td>-0.705 6</td><td>0.000 0</td></tr><tr><td><br />CWHR</td><td>0.519 9</td><td>0.000 0</td></tr><tr><td><br />MJWR</td><td>-0.414 2</td><td>0.000 0</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="97">
                    <p class="img_tit"><b>表3 测试组相关性实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="97" border="1"><tr><td>研究</td><td>面部特征</td><td><i>r</i></td><td><i>p</i>-<i>value</i></td></tr><tr><td rowspan="3"><br />Coetzee等<sup>[7]</sup></td><td><br />CJWR</td><td>-0.447 2</td><td>0.000 0</td></tr><tr><td><br />WHR</td><td>0.553 8</td><td>0.000 0</td></tr><tr><td><br />PAR</td><td>-0.065 9</td><td>0.136 0</td></tr><tr><td rowspan="2"><br />Pham等<sup>[8]</sup></td><td><br />FW/LFH</td><td>0.357 8</td><td>0.000 0</td></tr><tr><td><br />LFH/FH</td><td>0.124 5</td><td>0.004 7</td></tr><tr><td rowspan="3"><br />本文</td><td><br />RAR</td><td>-0.651 3</td><td>0.000 0</td></tr><tr><td><br />CWHR</td><td>0.545 2</td><td>0.000 0</td></tr><tr><td><br />MJWR</td><td>-0.408 8</td><td>0.000 0</td></tr><tr><td colspan="4"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="98">
                    <p class="img_tit"><b>表4 整体人脸库相关性实验结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="98" border="1"><tr><td>研究</td><td>面部特征</td><td><i>r</i></td><td><i>p</i>-<i>value</i></td></tr><tr><td rowspan="3"><br />Coetzee等<sup>[7]</sup></td><td><br />CJWR</td><td>-0.472 0</td><td>0.000 0</td></tr><tr><td><br />WHR</td><td>0.550 5</td><td>0.000 0</td></tr><tr><td><br />PAR</td><td>-0.101 4</td><td>0.000 1</td></tr><tr><td rowspan="2"><br />Pham等<sup>[8]</sup></td><td><br />FW/LFH</td><td>0.333 1</td><td>0.000 0</td></tr><tr><td><br />LFH/FH</td><td>0.151 7</td><td>0.000 0</td></tr><tr><td rowspan="3"><br />本文</td><td><br />RAR</td><td>-0.686 4</td><td>0.000 0</td></tr><tr><td><br />CWHR</td><td>0.528 8</td><td>0.000 0</td></tr><tr><td><br />MJWR</td><td>-0.412 0</td><td>0.000 0</td></tr><tr><td colspan="4"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="99">
                    <p class="img_tit"><b>表5 面部深度特征与BMI之间的相关系数<i>r</i></b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="99" border="1"><tr><td><br />研究</td><td>深度学习网络</td><td>皮尔逊系数<i>r</i></td></tr><tr><td rowspan="2"><br />Kocabey等<sup>[12]</sup></td><td><br />VGG-Net</td><td>0.47</td></tr><tr><td><br />VGG-Face</td><td>0.65</td></tr><tr><td colspan="3"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="100">分析表2、表3和表4可以得出结论:在Coetzee和Pham使用的面部特征中, CJWR和WHR这两个面部特征与BMI之间具有较强的相关性;FW/LFH与前两者相比相关性较弱, 但<i>p</i>-<i>value</i>近似为0表示不能完全认为FW/LFH与BMI无关;PAR和LFH/FH这两个面部特征与BMI之间的相关性非常微弱。 在本文提出的新面部特征中, RAR、MJWR以及CWHR与BMI之间的相关性均较强, 其中RAR与BMI之间的相关性已经达到强相关水平。因此, 相关性实验的结果证明, 本文新提出的三种面部比例特征与Wen使用的面部特征相比与BMI之间具有更强的相关性。</p>
                </div>
                <div class="p1">
                    <p id="101">对比表5可以得出结论:深度学习网络VGG-Face提取的面部深度特征与BMI之间的相关性比VGG-Net提取的面部深度特征更强, 同时我们发现, 深度特征与本文提出的面部比例特征相比并没有优势, 暂不考虑面部深度特征的使用。</p>
                </div>
                <h3 id="102" name="102" class="anchor-tag"><b>3 BMI预测</b></h3>
                <div class="p1">
                    <p id="103">特征的相关性实验证实本文提出的新的面部特征与BMI之间具有显著的相关性, 但能否提高BMI预测算法的精度需要通过BMI预测实验进行验证。</p>
                </div>
                <div class="p1">
                    <p id="104">目前, 基于人脸图像预测BMI的算法较少, 只有文献<citation id="141" type="reference">[<a class="sup">9</a>]</citation>系统地给出了预测算法与预测结果。因此, 在预测实验中, 我们将针对文献<citation id="142" type="reference">[<a class="sup">9</a>]</citation>中的预测算法进行改进。我们的改进分为两部分: (1) 在面部特征集合中增加本文提出的新面部特征, 以验证新特征的加入能够提高预测算法的精度; (2) 使用神经网络拟合代替SVR回归建立预测模型, 以验证神经网络拟合预测模型比SVR回归预测模型具有更好的预测效果。</p>
                </div>
                <div class="p1">
                    <p id="105">文献<citation id="143" type="reference">[<a class="sup">9</a>]</citation>使用的特征集合包括了Coetzee和Pham提出的7种面部比例特征:颊颌宽度比、面部宽高比、面部周长面积比、眼睛宽度、面部长度比、颧高比和眉眼均距。前文提到, 眼睛宽度与眉眼均距是面部绝对尺寸特征, 仅适用于固定焦距拍摄的面部图像, 对样本的要求过于严苛, 并不适用于日常生活环境下人脸图像预测BMI的算法。本文使用的人脸库样本类似于日常生活照, 因此暂不考虑使用这2种面部特征, 仅使用剩余的5种面部特征进行BMI预测实验。文献<citation id="144" type="reference">[<a class="sup">9</a>]</citation>中, Wen使用SVR多元回归建立BMI预测模型, 使用面部特征与BMI标签构建的“多对一”面部特征集合来训练神经网络模型, 最终使用训练好的模型进行BMI预测实验。</p>
                </div>
                <div class="p1">
                    <p id="106">本文使用的面部特征集合包含了8种面部特征:5种文献<citation id="145" type="reference">[<a class="sup">9</a>]</citation>使用的面部特征以及本文新提出的3中面部特征。同时, 使用神经网络拟合<citation id="146" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>建立模型预测BMI, 该神经网络包含一个S形隐藏层 (10个神经元) 和一个线性输出层。在给与充足的数据和足够多的隐藏层神经元的前提下, 一个含有S形隐藏层神经元和线性输出神经元的两层前馈网络可以很好地拟合多维映射问题。为了方便比较实验结果, 我们使用系统的平均绝对误差 (MAE) 来衡量BMI预测的准确性。</p>
                </div>
                <div class="p1">
                    <p id="107">本文中使用的预测算法框图见图5, 人脸库中的样本作为模型的输入端, 首先进行ASM特征点的提取, 根据提取到的特征点计算相应的特征数据, 然后将这些特征数据进行归一化处理, 以保证神经网络具有更好的拟合程度。最后, 我们使用面部特征与BMI标签构建的“多对一”特征集合来训练神经网络模型, 并使用训练好的模型进行BMI预测实验。</p>
                </div>
                <div class="area_img" id="108">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907042_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 本文使用的BMI预测算法框图" src="Detail/GetImg?filename=images/JYRJ201907042_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 本文使用的BMI预测算法框图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907042_108.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="109">为了验证本文提出的新面部特征可以提高BMI预测的准确率, 以及神经网络拟合相比于SVR回归的具有更好的预测结果。我们设置以下三个实验组: (1) 使用文献<citation id="147" type="reference">[<a class="sup">9</a>]</citation>中的面部特征集合以及SVR回归预测模型, 在本文人脸库上进行BMI预测实验; (2) 使用本文新提出的面部特征集合 (包含8种面部特征) 以及SVR回归预测模型, 在本文人脸库上进行BMI预测实验; (3) 使用本文新提出的面部特征集合 (包含8种面部特征) 以及神经网络拟合模型, 在本文人脸库上进行BMI预测实验。同时, 为了研究不同BMI组别的样本在预测实验中的表现, 我们对BMI预测结果进行了分组统计, 按照不同的BMI级别分别计算BMI预测的平均绝对误差 (MAE) 。BMI预测的结果在表6中给出, 表6的第1列给出了BMI的分组情况, 第2-4列分别给出实验组 (1) - (3) 的BMI预测平均绝对误差。</p>
                </div>
                <div class="area_img" id="110">
                    <p class="img_tit"><b>表6 预测BMI的平均绝对误差</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="110" border="1"><tr><td><br />BMI分级</td><td>实验组 (1) </td><td>实验组 (2) </td><td>实验组 (3) </td></tr><tr><td><br />正常 (18.5≤BMI&lt;25) </td><td>5.222</td><td>4.869</td><td>3.281</td></tr><tr><td><br />超重 (25≤BMI&lt;30) </td><td>2.721</td><td>2.658</td><td>2.455</td></tr><tr><td><br />肥胖 (30≤BMI&lt;35) </td><td>3.441</td><td>2.614</td><td>2.525</td></tr><tr><td><br />重度肥胖 (35≤BMI&lt;40) </td><td>4.331</td><td>4.219</td><td>3.911</td></tr><tr><td><br />极重度肥胖 (BMI&gt;40) </td><td>6.208</td><td>5.518</td><td>4.718</td></tr><tr><td><br />总体</td><td>4.325</td><td>3.937</td><td>3.631</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="111">由表6可以得出, 实验组 (1) 使用文献<citation id="148" type="reference">[<a class="sup">9</a>]</citation>算法, 在本文数据库中得到的BMI预测平均绝对误差为4.325;实验组 (2) 使用新特征集合和SVR回归模型, 在本文数据库中得到的BMI预测平均绝对误差为3.937。对比实验组 (1) 和实验组 (2) 的结果可以说明, 新的面部特征能够减少日常生活场景应用下BMI预测误差。实验组 (3) 使用新特征集合和神经网络拟合模型, 在本文数据库中得到的BMI预测平均绝对误差为3.631, 对比实验组 (2) 和实验组 (3) 可以说明, 神经网络拟合预测模型比SVR回归预测模型有更好的预测精度。对比实验组 (1) 和实验组 (3) 说明, 本文提出的基于文献<citation id="149" type="reference">[<a class="sup">9</a>]</citation>的算法改进使得日常生活场景应用下BMI的预测平均绝对误差减小了0.7。</p>
                </div>
                <h3 id="112" name="112" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="113">本文提出了三种新的面部比例特征, 这三种特征与BMI之间显示了较强的相关性。通过增加面部特征集合中的特征数量, 以及使用神经网络拟合代替SVR回归建立预测模型, 提高了BMI预测算法在日常生活场景应用下的精确度。在今后的研究中, 为了进一步提高算法性能, 可以考虑使用3D面部特征, 为研究人员提供更多类型的面部特征来预测BMI <citation id="150" type="reference"><link href="35" rel="bibliography" /><link href="37" rel="bibliography" /><link href="39" rel="bibliography" /><sup>[<a class="sup">17</a>,<a class="sup">18</a>,<a class="sup">19</a>]</sup></citation>。同时, 我们也将开展面部深度特征的研究工作, 以验证深度特征能否应用在BMI的预测算法中。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011600045222&amp;v=MDU1MzdUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUZvVWF4Yz1OaWZPZmJLN0h0RE5xWTlGWk84S0RuNDdvQk1UNg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Renehan A G, Tyson M, Egger M, et al.Body-mass Index and Incidence of Cancer:A Systematic Review and Meta-analysis of Prospective Observational Studies[J].Lancet, 2008, 371 (9612) :569-578.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJTT&amp;filename=SJTT14120300089517&amp;v=MjE1MzhadEZpbmxVcnpJSUZvVWF4Yz1OaWZmZXJLOEg5UE1ySTlGWk9NR0NYMCtvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> Zhang L.Face Gender Recognition Research Based on Local Features and Support Vector Machine[J].Applied Mechanics &amp; Materials, 2014, 687-691:3714-3717.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Predicting the Sixteen Personality Factors (16PF) of an individual by analyzing facial features">

                                <b>[3]</b> Gavrilescu M, Vizireanu N.Predicting the Sixteen Personality Factors (16PF) of an individual by analyzing facial features[J].Eurasip Journal on Image &amp; Video Processing, 2017, 2017 (1) :59.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJRS&amp;filename=SJRS15121700004540&amp;v=MTYxMThmWmZiSzlIOVBOcUk5RlpPc0xDWGc1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUZvVWF4Yz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> Re D E, Rule N O.Heavy Matters:The Relationship Between Just Noticeable Differences in Perceptions of Facial Adiposity and Facial Attractiveness[J].Social Psychological and Personality Science, 2016, 7 (1) :69-76.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJESD1EE21A7B508744BC40765BB554685E6&amp;v=MDIwODI3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHhMeS93YTA9TmlmT2ZjZTVhNlRPcnY1Q0Z1NFBCSHM5eTJSZzdqOTZUbnFRM2hjd2ZiU2NRTStaQ09OdkZTaVdXcg==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> Pascali M A, Giorgi D, Bastiani L, et al.Face morphology:can it tell us something about body weight and fat?[J].Computers in Biology &amp; Medicine, 2016, 76:238-249.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJIX&amp;filename=SJIX6ABFB34478AF7D66B660A344B7C8575F&amp;v=MjI5MjludE55UkJoN0RsOU9Yem1xR0F5Q3JxUlFyL3BDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh4THkvd2EwPU5pZkNkclhKYktlK3JJdEJZK04rZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Coetzee V, Perrett D I, Stephen I D.Facial adiposity:a cue to health?[J].Perception, 2009, 38 (11) :1700-1711.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJIX&amp;filename=SJIX3A324CD96F6C35E3D2E92480E1FC9DC8&amp;v=MTY1NDFsZkJyTFUwNXR0aHhMeS93YTA9TmlmQ2RyREpIZFBJM1B0TVlwMEpmMzg4dWhWbjZFcDBTbnZxckdjMEQ4R2RNY21YQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Coetzee V, Chen J, Perrett D I, et al.Deciphering faces:quantifiable visual cues to weight[J].Perception, 2010, 39 (1) :51-61.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJHD&amp;filename=SJHD120615018091&amp;v=MDQ4MzNIN24zeEU5ZmJ2bktyaWZaZVp2RnlubVU3L01JRjhSTmlmRGFySzZIdGZOcW85RWJPc0dEUk04enhVU21EZDlT&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Pham D D, Do J H, Ku B, et al.Body Mass Index and Facial Cues in Sasang Typology for Young and Elderly Persons[J].Evidence-based Complementary and Alternative Medicine, 2011, 2011:749209.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14010600233483&amp;v=MzExMTVHZXJxUVRNbndaZVp0RmlubFVyeklJRm9VYXhjPU5pZk9mYks4SHRETXFZOUZadWdNQ0hRNm9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Wen L, Guo G.A computational approach to body mass index prediction from face images[J].Image &amp; Vision Computing, 2013, 31 (5) :392-400.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501084429&amp;v=MDQ2MzlFWk9NTENINHdvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRm9VYXhjPU5pZk9mYks3SHRETnFvOQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Cootes T F, Taylor C J, Cooper D H, et al.Active Shape Models-Their Training and Application[J].Computer Vision &amp; Image Understanding, 1995, 61 (1) :38-59.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting Body Mass Index from a Facial Photograph in Lifestyle Intervention">

                                <b>[11]</b> Barr M L, Guo G, Colby S E, et al.Detecting Body Mass Index from a Facial Photograph in Lifestyle Intervention[J].Technologies, 2018, 6 (3) :83.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Face-to-BMI:Using Computer Vision to Infer Body Mass Index on Social Media">

                                <b>[12]</b> Kocabey E, Camurcu M, Ofli F, et al.Face-to-BMI:Using Computer Vision to Infer Body Mass Index on Social Media[C]//The Eleventh International AAAI Conference on Web and Social Media, 2017.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD00000696694&amp;v=Mjk2NThkaDRqOTlTWHFScnhveGNNSDdSN3FkWitadUZpdmxVN3ZJSVZzPU5pZmNhck80SHRITXFZWkRZdUlMWTNrNXpC&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> Satoh M, Mori S, Yoshizuka N, et al.Facial distribution of subcutaneous fat in women[J].International Journal of Cosmetic Science, 2010, 26 (5) :266-266.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=BMI and WHR are reflected in female facial shape and texture:a geometric morphometric image analysis">

                                <b>[14]</b> Mayer C, Windhager S, Schaefer K, et al.BMI and WHR Are Reflected in Female Facial Shape and Texture:A Geometric Morphometric Image Analysis[J].Plos One, 2017, 12 (1) :e0169336.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Fundamentals of modern statistical methods:Substantially improving power and accuracy">

                                <b>[15]</b> Wilcox R R.Fundamentals of modern statistical methods:Substantially improving power and accuracy[J].Journal of the Royal Statistical Society Series D (The Statistician) , 2002, 51 (4) :590-591.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Single-Layer Neural Net Competes with Multi-layer Neural Net">

                                <b>[16]</b> Yang Z R.Single-Layer Neural Net Competes with Multi-layer Neural Net[M]//Intelligent Data Engineering and Automated Learning—IDEAL 2008.Springer Berlin Heidelberg, 2008:516-524.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=3D Face Representation Using Inverse Compositional Image Alignment for Multimodal Face Recognition">

                                <b>[17]</b> Jeong K, Moon H, Kim S.3D Face Representation Using Inverse Compositional Image Alignment for Multimodal Face Recognition[M]//Frontier and Innovation in Future Computing and Communications.Springer Netherlands, 2014:423-429.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501083298&amp;v=MjI3MDRJRm9VYXhjPU5pZk9mYks3SHRETnFvOUVaT01NRG5VeG9CTVQ2VDRQUUgvaXJSZEdlcnFRVE1ud1plWnRGaW5sVXJ6SQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[18]</b> Sharma A, Haj M A, Choi J, et al.Robust pose invariant face recognition using coupled latent space discriminant analysis[J].Computer Vision &amp; Image Understanding, 2012, 116 (11) :1095-1110.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13012300413320&amp;v=MDk5MzBmT2ZiSzdIdERPckk5RllPb01EMzQ1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUZvVWF4Yz1OaQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[19]</b> Zhang Y N, Guo Z, Xia Y, et al.2D representation of facial surfaces for multi-pose 3D face recognition[J].Pattern Recognition Letters, 2012, 33 (5) :530-536.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201907042" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907042&amp;v=MTI2MjM0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVNzdOTHpUWlpMRzRIOWpNcUk5QlpvUUtESDg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
