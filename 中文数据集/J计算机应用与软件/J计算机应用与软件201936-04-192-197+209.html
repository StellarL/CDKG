<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135753906377500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201904031%26RESULT%3d1%26SIGN%3dWz3iwsEb%252bK0nAV7SkZ3jkVq9iBU%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904031&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904031&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904031&amp;v=MTk4MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXptVWI3UEx6VFpaTEc0SDlqTXE0OUdaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#33" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#37" data-title="&lt;b&gt;1 算法设计&lt;/b&gt; "><b>1 算法设计</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#44" data-title="&lt;b&gt;1.1 提取亮度分量&lt;/b&gt;"><b>1.1 提取亮度分量</b></a></li>
                                                <li><a href="#63" data-title="&lt;b&gt;1.2 获取分解系数&lt;/b&gt;"><b>1.2 获取分解系数</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;1.3 系数融合策略&lt;/b&gt;"><b>1.3 系数融合策略</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#96" data-title="&lt;b&gt;2 实 验&lt;/b&gt; "><b>2 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#98" data-title="&lt;b&gt;2.1 不同算法融合图像的视觉分析&lt;/b&gt;"><b>2.1 不同算法融合图像的视觉分析</b></a></li>
                                                <li><a href="#106" data-title="&lt;b&gt;2.2 不同算法融合图像的客观分析&lt;/b&gt;"><b>2.2 不同算法融合图像的客观分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#118" data-title="&lt;b&gt;3 结 论&lt;/b&gt; "><b>3 结 论</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#43" data-title="图1 本文遥感图像算法的融合过程">图1 本文遥感图像算法的融合过程</a></li>
                                                <li><a href="#46" data-title="图2 HSV变换空间示意图">图2 HSV变换空间示意图</a></li>
                                                <li><a href="#62" data-title="图3 亮度分量提取结果图">图3 亮度分量提取结果图</a></li>
                                                <li><a href="#67" data-title="图4 非下采样Contourlet变换系数分解效果图">图4 非下采样Contourlet变换系数分解效果图</a></li>
                                                <li><a href="#67" data-title="图4 非下采样Contourlet变换系数分解效果图">图4 非下采样Contourlet变换系数分解效果图</a></li>
                                                <li><a href="#95" data-title="图5 本文算法的融合结果">图5 本文算法的融合结果</a></li>
                                                <li><a href="#102" data-title="图6 不同算法的融合图像">图6 不同算法的融合图像</a></li>
                                                <li><a href="#102" data-title="图6 不同算法的融合图像">图6 不同算法的融合图像</a></li>
                                                <li><a href="#105" data-title="图7 不同算法的融合图像">图7 不同算法的融合图像</a></li>
                                                <li><a href="#117" data-title="图8 不同算法融合图像的量化结果">图8 不同算法融合图像的量化结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="150">


                                    <a id="bibliography_1" title=" Xu F, Liu J H, Dong C. Ship detection in optical remote sensing images based on wavelet transform and multi-level false alarm identification [J].Remote Sensing, 2017, 10 (9) : 1-19." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ship Detection in Optical Remote Sensing Images Based on Wavelet Transform and Multi-Level False Alarm Identification">
                                        <b>[1]</b>
                                         Xu F, Liu J H, Dong C. Ship detection in optical remote sensing images based on wavelet transform and multi-level false alarm identification [J].Remote Sensing, 2017, 10 (9) : 1-19.
                                    </a>
                                </li>
                                <li id="152">


                                    <a id="bibliography_2" title=" Deng C, Wang Z H, Li X W. An improved remote sensing image fusion algorithm based on IHS transformation [J]. KSII Transactions on Internet and Information Systems, 2017, 11 (3) : 1633-1649." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=An Improved Remote Sensing Image Fusion Algorithm Based on IHS Transformation">
                                        <b>[2]</b>
                                         Deng C, Wang Z H, Li X W. An improved remote sensing image fusion algorithm based on IHS transformation [J]. KSII Transactions on Internet and Information Systems, 2017, 11 (3) : 1633-1649.
                                    </a>
                                </li>
                                <li id="154">


                                    <a id="bibliography_3" title=" Zhang X F, Ni D, Gou Z J. Sparse representation and PCA method for image fusion in remote sensing [C]//Proceedings of 2016 the 2nd international conference on control, automation and robotics, 2016: 324-330." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Sparse representation and PCA method for image fusion in remote sensing">
                                        <b>[3]</b>
                                         Zhang X F, Ni D, Gou Z J. Sparse representation and PCA method for image fusion in remote sensing [C]//Proceedings of 2016 the 2nd international conference on control, automation and robotics, 2016: 324-330.
                                    </a>
                                </li>
                                <li id="156">


                                    <a id="bibliography_4" title=" 赵学军, 刘静. 基于Shearlet和稀疏表示的遥感图像融合[J].科学技术与工程, 2017, 17 (4) : 255-259." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201704043&amp;v=Mjg3MzBadEZ5em1VYjdPTGpYQmZiRzRIOWJNcTQ5Qlo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         赵学军, 刘静. 基于Shearlet和稀疏表示的遥感图像融合[J].科学技术与工程, 2017, 17 (4) : 255-259.
                                    </a>
                                </li>
                                <li id="158">


                                    <a id="bibliography_5" title=" 赵延芳, 王涛, 李鹏. 基于ZY3遥感图像的反立体校正方法研究[J]. 信息技术, 2017, 15 (3) : 60-64." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201703015&amp;v=MTcxMDRaTEc0SDliTXJJOUVZWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXptVWI3T0xTblI=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         赵延芳, 王涛, 李鹏. 基于ZY3遥感图像的反立体校正方法研究[J]. 信息技术, 2017, 15 (3) : 60-64.
                                    </a>
                                </li>
                                <li id="160">


                                    <a id="bibliography_6" title=" Wang W H, Sun S L, Jiang M X. Traffic lights detection and recognition based on multi-feature fusion [J]. Multimedia Tools and Applications, 2017, 76 (13) : 14829-14846." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDB424621BCD8AF05975389489CFF3CD9D&amp;v=MDMwNTEzRjU4SGZRbzV5aDhVN3p4MVFYdnFwV0ZERDdIbk1iUHJDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh3THU5d2E0PU5qN0Jhc0c4SE5YS3JZNA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         Wang W H, Sun S L, Jiang M X. Traffic lights detection and recognition based on multi-feature fusion [J]. Multimedia Tools and Applications, 2017, 76 (13) : 14829-14846.
                                    </a>
                                </li>
                                <li id="162">


                                    <a id="bibliography_7" title=" Panchal S, Thakker R A. Improved image pansharpening technique using nonsubsampled contourlet transform with sparse representation[J]. Journal of the Indian Society of Remote Sensing, 2017, 45 (3) : 385-394." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD29B484B1A96E44D941E9A268D3088E88&amp;v=MjI3NjhNTEtYQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRod0x1OXdhND1OajdCYXJHeGJOWEVxLzFFRmVJSmVYZzl1eDhYNjBwME9YM2twR1kyZWJxYw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         Panchal S, Thakker R A. Improved image pansharpening technique using nonsubsampled contourlet transform with sparse representation[J]. Journal of the Indian Society of Remote Sensing, 2017, 45 (3) : 385-394.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_8" title=" Peng G, Wang Z Y, Liu S Q. Image fusion by combining multiwavelet with nonsubsampled direction filter bank[J]. Soft Computing, 2017, 21 (8) :1977-1989." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD425A1FC670B13B1DDB31A82E13622071&amp;v=MzA3MzZHNkROMmZ4RFkrdDlEWDlMem1Kbm1EeDhPWGZnMlJNMmY3Q1dSYjJlQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRod0x1OXdhND1OajdCYXJlNg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         Peng G, Wang Z Y, Liu S Q. Image fusion by combining multiwavelet with nonsubsampled direction filter bank[J]. Soft Computing, 2017, 21 (8) :1977-1989.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_9" title=" Liu C P, Long Y H, Mao J X. Energy-efficient multi-focus image fusion based on neighbor distance and morphology [J]. Optik-International Journal for Light and Electron Optics, 2016, 127 (23) : 11354-11363." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Energy-efficient Multi-focus Image Fusion Based on Neighbor Distance and Morphology">
                                        <b>[9]</b>
                                         Liu C P, Long Y H, Mao J X. Energy-efficient multi-focus image fusion based on neighbor distance and morphology [J]. Optik-International Journal for Light and Electron Optics, 2016, 127 (23) : 11354-11363.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_10" title=" Udhaya Suriya T S, Rangarajan P. Brain tumour detection using discrete wavelet transform based medical image fusion [J]. Biomedical Research, 2017, 28 (2) : 684-688." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Brain tumour detection using discrete wavelet transform based medical image fusion">
                                        <b>[10]</b>
                                         Udhaya Suriya T S, Rangarajan P. Brain tumour detection using discrete wavelet transform based medical image fusion [J]. Biomedical Research, 2017, 28 (2) : 684-688.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_11" title=" Bao W X, Wang W, Zhu Y X. Pleiades satellite remote sensing image fusion algorithm based on shearlet transform [J].Journal of the Indian Society of Remote Sensing, 2018, 46 (1) : 19-29." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Pleiades satellite remote sensing image fusion algorithm based on shearlet transform">
                                        <b>[11]</b>
                                         Bao W X, Wang W, Zhu Y X. Pleiades satellite remote sensing image fusion algorithm based on shearlet transform [J].Journal of the Indian Society of Remote Sensing, 2018, 46 (1) : 19-29.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_12" title=" 李旭, 高雅楠, Yue S.一种尺度感知型遥感图像融合新方法[J].宇航学报, 2017, 38 (12) :1348-1353." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YHXB201712012&amp;v=MTkwOTQ5RVpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5em1VYjdPUENYVGJMRzRIOWJOclk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[12]</b>
                                         李旭, 高雅楠, Yue S.一种尺度感知型遥感图像融合新方法[J].宇航学报, 2017, 38 (12) :1348-1353.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_13" title=" Zhang J. A new saliency-driven fusion method based on complex wavelet transform for remote sensing images [J]. IEEE Geoscience and Remote Sensing Letters, 2017, 14 (12) :2433-2437." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A New saliency-driven fusion method based on complex wavelet transform for remote sensing images">
                                        <b>[13]</b>
                                         Zhang J. A new saliency-driven fusion method based on complex wavelet transform for remote sensing images [J]. IEEE Geoscience and Remote Sensing Letters, 2017, 14 (12) :2433-2437.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_14" title=" 杨艳春, 李娇, 王阳萍.图像融合质量评价方法研究综述[J].计算机科学与探索, 2018, 12 (7) : 1021-1035." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201807002&amp;v=MTUzNjBMalhmZmJHNEg5bk1xSTlGWm9RS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnl6bVViN08=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         杨艳春, 李娇, 王阳萍.图像融合质量评价方法研究综述[J].计算机科学与探索, 2018, 12 (7) : 1021-1035.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_15" title=" Sanli F B, Abdikan S, Esetlili M T, et al. Evaluation of image fusion methods using PALSAR, RADARSAT-1 and SPOT images for land use/land cover classification [J].Journal of the Indian Society of Remote Sensing, 2017, 45 (4) : 591-601." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD298D86D28A969C0AEA62F3BF84CCE69A&amp;v=MDA3MDBXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRod0x1OXdhND1OajdCYXJHeEZxWEVxZnRIYkpvR0NuVkt6MmRtbXpsL1BueVEyaG94Q3NIaFE3UHVDT052RlNpVw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Sanli F B, Abdikan S, Esetlili M T, et al. Evaluation of image fusion methods using PALSAR, RADARSAT-1 and SPOT images for land use/land cover classification [J].Journal of the Indian Society of Remote Sensing, 2017, 45 (4) : 591-601.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(04),192-197+209 DOI:10.3969/j.issn.1000-386x.2019.04.030            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>非下采样Contourlet变换耦合区域信息特征的遥感图像融合算法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E6%B7%91%E8%89%B3&amp;code=39600133&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张淑艳</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9C%B1%E5%A8%9F&amp;code=39600135&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">朱娟</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E8%B6%85&amp;code=39600134&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王超</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%94%B0%E7%BA%AA%E4%BA%9A&amp;code=35232963&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">田纪亚</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9B%BE%E5%B0%8F%E6%85%A7&amp;code=41483479&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">曾小慧</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E9%95%BF%E6%98%A5%E5%85%89%E5%8D%8E%E5%AD%A6%E9%99%A2%E7%94%B5%E6%B0%94%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=1699434&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长春光华学院电气信息学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%95%E5%86%88%E5%B1%B1%E5%A4%A7%E5%AD%A6%E7%94%B5%E4%BF%A1%E5%AD%A6%E9%99%A2&amp;code=0230004&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">井冈山大学电信学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>当前遥感图像融合算法主要是通过图像的能量信息来完成低频系数的融合, 忽略了图像的光谱信息特征, 导致融合图像中存在光谱扭曲等不足。设计基于非下采样Contourlet变换与区域信息特征的遥感图像融合算法。引入HSV (Hue, Saturation, Value) 变换, 从多光谱图像中提取亮度分量。采用非下采样Contourlet变换, 对全色图像与多光谱图像的亮度分量进行分解, 获取图像的低频系数与高频系数。联合低频系数的区域能量以及信息熵特征, 构造低频系数的融合模型, 完成低频信息的融合。通过高频系数的区域方差相似度, 建立高频系数融合规则, 对高频系数完成融合。通过非下采样Contourlet逆变换与HSV逆变换, 获取融合图像。实验结果表明, 与当前遥感图像融合方法相比, 该算法的融合图像具有更好的光谱与空间特性。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%81%A5%E6%84%9F%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">遥感图像融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9D%9E%E4%B8%8B%E9%87%87%E6%A0%B7Contourlet%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">非下采样Contourlet变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HSV%E5%8F%98%E6%8D%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HSV变换;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BA%E5%9F%9F%E8%83%BD%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">区域能量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BF%A1%E6%81%AF%E7%86%B5&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">信息熵;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BA%E5%9F%9F%E6%96%B9%E5%B7%AE%E7%9B%B8%E4%BC%BC%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">区域方差相似度;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    张淑艳, 副教授, 主研领域:数字图像处理, 遥感测绘技术, 嵌入式技术。;
                                </span>
                                <span>
                                    朱娟, 副教授。;
                                </span>
                                <span>
                                    王超, 副教授。;
                                </span>
                                <span>
                                    田纪亚, 研究员。;
                                </span>
                                <span>
                                    曾小慧, 副教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-10</p>

                    <p>

                            <b>基金：</b>
                                                        <span>吉林省教育厅自然科学技术研究重点项目 (JJKH20181376KJ);</span>
                    </p>
            </div>
                    <h1><b>REMOTE SENSING IMAGE FUSION ALGORITHM BASED ON NONSUBSAMPLED CONTOURLET TRANSFORM COUPLING REGION INFORMATION FEATURE</b></h1>
                    <h2>
                    <span>Zhang Shuyan</span>
                    <span>Zhu Juan</span>
                    <span>Wang Chao</span>
                    <span>Tian Jiya</span>
                    <span>Zeng Xiaohui</span>
            </h2>
                    <h2>
                    <span>School of Electrical Information, Changchun Guanghua College</span>
                    <span>School of Telecommunications, Jinggangshan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>At present, remote sensing image fusion algorithm mainly completes the fusion of low-frequency coefficients through the energy information of images, ignoring the spectral information characteristics of images, resulting in the existence of spectral distortion and other deficiencies in the fused image. To solve this problem, this paper designed a remote sensing image fusion algorithm based on nonsubsampled contourlet transform and the regional information features. HSV transform was introduced to extract luminance components from multispectral images. We used the nonsubsampled contourlet transform to decompose the luminance components of panchromatic image and multispectral image to obtain the low-frequency coefficients and high-frequency coefficients. Combining the regional energy of low-frequency coefficients and information entropy characteristics, we constructed the fusion model of low-frequency coefficients and completed the fusion of low-frequency information. Through the similarity of regional variance of high-frequency coefficients, the fusion rules of high-frequency coefficients were established, and the fusion of high-frequency coefficients was completed. The fused image was obtained by using the nonsubsampled contourlet inverse transform and HSV inverse transform. Experimental results show that compared with the current remote sensing image fusion method, the fusion image proposed by this paper has better spectral and spatial characteristics.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Remote%20sensing%20image%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Remote sensing image fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Nonsubsampled%20contourlet%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Nonsubsampled contourlet transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=HSV%20transform&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">HSV transform;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Regional%20energy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Regional energy;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Information%20entropy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Information entropy;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Similarity%20of%20regional%20variance&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Similarity of regional variance;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-10</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="33" name="33" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="34">遥感图像通常分为含有丰富光谱信息的多光谱图像, 以及具有较高空间分辨率的全色图像<citation id="180" type="reference"><link href="150" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。为了得到同时具有丰富光谱信息与较高分辨率的遥感图像, 通常需要将多光谱图像与全色图像进行融合, 即遥感图像融合<citation id="181" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。</p>
                </div>
                <div class="p1">
                    <p id="35">近年来, 国内外学者提出一系列的遥感融合方法, 如Deng等<citation id="182" type="reference"><link href="152" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>利用局部方差特征设计了一种遥感图像融合算法, 通过滑动窗口计算图像的局部方差, 利用IHS变换获取图像的亮度分量, 通过局部方差特征求取亮度分量以及SPOT图像的权重, 进而通过IHS逆变换获取融合图像。实验结果显示, 这种方法融合的图像具有较好的空间信息, 清晰度较高, 不存在模糊现象。但由于IHS变换获取的亮度分量与全色图像存在一定偏差, 导致融合结果中存在光谱失真现象, 使得融合图像的颜色偏深。Zhang等<citation id="183" type="reference"><link href="154" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>将PCA方法与稀疏表示用于遥感图像的融合, 通过PCA方法建立高空间分辨率的多光谱图像字典, 使用将稀疏表示产生的残差插值作为补偿, 进而实现遥感图像的融合, 实验结果显示, 该方法融合的图像具有较好的空间分辨率, 不存在块效应等, 融合图像的细节较为清晰, 而且图像质量指数也较好。但由于PCA方法存在光谱丢失的缺陷, 导致融合图像中具有光谱扭曲的缺陷, 融合图像的人眼视觉有待提升。赵学军等<citation id="184" type="reference"><link href="156" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>通过shearlet变换获取图像的高频系数与低频系数, 利用OMP算法获取稀疏系数, 并利用图像的能量信息完成低频系数的融合, 采用PCNN方法来实现高频系数的融合, 通过OMP重构及shearlet逆变换获取融合图像。实验结果显示, 该方法具有较好的融合图像的视觉效果, 其融合图像保持了源图像的绝大部分光谱色彩信息, 并改善了图像的空间细节信息, 其平均梯度值与信息熵分别保持在14.3、16以上。但是该方法在低频系数融合时, 只考虑了图像的能量信息, 而忽略了图像的光谱信息特征, 使得融合图像中存在光谱扭曲等缺陷, 而且shearlet变换具有下采样过程, 不具备平移不变性, 使得融合图像存在模糊效应。</p>
                </div>
                <div class="p1">
                    <p id="36">为了使得融合的遥感图像包含更多的光谱信息与空间信息, 本文提出了一种非下采样Contourlet变换与区域信息特征相结合的遥感图像融合算法。通过HSV变换分解出多光谱图像的亮度分量。利用具有平移不变性的非下采样Contourlet变换对亮度分量以及全色图像进行分解, 得到高频系数与低频系数。在低频系数融合时, 通过图像的区域能量度量图像特征信息的大小, 并通过信息熵度量图像中的光谱信息, 利用图像的区域能量以及信息熵特征作为低频系数的融合依据, 完成低频系数融合。通过图像的区域方差相似度对图像块的区域方差差异度进行度量, 建立高频系数融合规则, 完成高频系数融合。利用非下采样Contourlet逆变换以及HSV逆变换完成图像融合。最后, 测试了所提算法的融合质量。</p>
                </div>
                <h3 id="37" name="37" class="anchor-tag"><b>1 算法设计</b></h3>
                <div class="p1">
                    <p id="38">所提的基于非下采样Contourlet变换与区域信息特征的遥感图像融合算法过程见图1。从图1可知, 本文算法主要由提取亮度分量、获取分解系数以及系数融合三部分组成:</p>
                </div>
                <div class="p1">
                    <p id="39">1) 提取亮度分量。利用HSV变换从多光谱图像中提取出包含图像主要亮度信息的亮度分量<i>V</i>。</p>
                </div>
                <div class="p1">
                    <p id="40">2) 获取分解系数。通过非下采样Contourlet变换, 将亮度分量<i>V</i>及全色图像进行系数分解, 得到图像的低频系数与高频系数。</p>
                </div>
                <div class="p1">
                    <p id="41">3) 系数融合策略。利用图像的区域能量以及信息熵特征, 分别对低频系数所包含的特征信息以及光谱信息进行度量, 进而构造了低频系数的融合模型, 实现低频系数的融合。利用图像的区域方差特征, 对高频系数的差异度进行度量, 并根据度量结果, 建立高频系数融合规则, 实现高频系数的融合。完成高频系数与低频系数的融合后, 再通过非下采样Contourlet反变换获取新的亮度分量<mathml id="42"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>, 并将其与<i>H</i>、<i>S</i>分量进行HSV反变换, 从而完成遥感图像的融合。</p>
                </div>
                <div class="area_img" id="43">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 本文遥感图像算法的融合过程" src="Detail/GetImg?filename=images/JYRJ201904031_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 本文遥感图像算法的融合过程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_043.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="44" name="44"><b>1.1 提取亮度分量</b></h4>
                <div class="p1">
                    <p id="45">HSV变换过程中包含了色调分量<i>H</i>、饱和度分量<i>S</i>、亮度分量<i>V</i>。通过<i>H</i>、<i>S</i>、<i>V</i>三个分量、形成一个如图2所示的锥形HSV变换空间<citation id="185" type="reference"><link href="158" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>。多光谱图像通过HSV变换可被分解成<i>H</i>、<i>S</i>、<i>V</i>三个分量, 该分解过程如下。</p>
                </div>
                <div class="area_img" id="46">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 HSV变换空间示意图" src="Detail/GetImg?filename=images/JYRJ201904031_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 HSV变换空间示意图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_046.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="47">令<i>R</i>、<i>G</i>、<i>B</i>表示三原色中的三个分量, <i>a</i>=max (<i>R</i>, <i>G</i>, <i>B</i>) 以及<i>b</i>=min (<i>R</i>, <i>G</i>, <i>B</i>) 分别表示<i>R</i>、<i>G</i>、<i>B</i>分量中的最大值与最小值, 则HSV变换过程可表述为<citation id="186" type="reference"><link href="160" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="48" class="code-formula">
                        <mathml id="48"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Η</mi><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>2</mn><mn>4</mn><mn>0</mn><mo>+</mo><mn>6</mn><mn>0</mn><mo stretchy="false"> (</mo><mi>R</mi><mo>-</mo><mi>B</mi><mo stretchy="false">) </mo><mo>/</mo><mo stretchy="false"> (</mo><mi>a</mi><mo>-</mo><mi>b</mi><mo stretchy="false">) </mo><mtext> </mtext><mi>B</mi><mo>=</mo><mi>a</mi></mtd></mtr><mtr><mtd><mn>1</mn><mn>2</mn><mn>0</mn><mo>+</mo><mn>6</mn><mn>0</mn><mo stretchy="false"> (</mo><mi>G</mi><mo>-</mo><mi>B</mi><mo stretchy="false">) </mo><mo>/</mo><mo stretchy="false"> (</mo><mi>a</mi><mo>-</mo><mi>b</mi><mo stretchy="false">) </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>G</mi><mo>=</mo><mi>a</mi></mtd></mtr><mtr><mtd><mn>3</mn><mn>6</mn><mn>0</mn><mo>+</mo><mn>6</mn><mn>0</mn><mo stretchy="false"> (</mo><mi>R</mi><mo>-</mo><mi>B</mi><mo stretchy="false">) </mo><mo>/</mo><mo stretchy="false"> (</mo><mi>a</mi><mo>-</mo><mi>b</mi><mo stretchy="false">) </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>R</mi><mo>=</mo><mi>a</mi><mo>&amp;</mo><mi>G</mi><mo>&lt;</mo><mi>B</mi></mtd></mtr><mtr><mtd><mn>6</mn><mn>0</mn><mo stretchy="false"> (</mo><mi>G</mi><mo>-</mo><mi>B</mi><mo stretchy="false">) </mo><mo>/</mo><mo stretchy="false"> (</mo><mi>a</mi><mo>-</mo><mi>b</mi><mo stretchy="false">) </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>R</mi><mo>=</mo><mi>a</mi><mo>&amp;</mo><mi>G</mi><mo>≥</mo><mi>B</mi></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>S</mi><mo>=</mo><mn>0</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="area_img" id="49">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201904031_04900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="51"><i>V</i>=<i>a</i>      (3) </p>
                </div>
                <div class="p1">
                    <p id="52">令<i>H</i>=360°与<i>H</i>=0°时相等, 则HSV反变换可表述为:</p>
                </div>
                <div class="area_img" id="53">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201904031_05300.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="55">式中:<mathml id="56"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo>=</mo><mrow><mo>[</mo><mrow><mfrac><mi>Η</mi><mrow><mn>6</mn><mn>0</mn></mrow></mfrac></mrow><mo>]</mo></mrow></mrow></math></mathml>表示<i>H</i>分量与60相除后所得的商, <i>c</i>、<i>d</i>、<i>e</i>的表述为:</p>
                </div>
                <div class="area_img" id="57">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201904031_05700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="59">式中:<mathml id="60"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>g</mi><mo>=</mo><mfrac><mi>Η</mi><mrow><mn>6</mn><mn>0</mn></mrow></mfrac><mo>-</mo><mi>f</mi></mrow></math></mathml>。</p>
                </div>
                <div class="p1">
                    <p id="61">对多光谱图像进行HSV变换后, 可提取其亮度分量。以图3 (a) 所示多光谱图像为例, 对其进行HSV变换, 提取出的亮度分量如图3 (b) 所示。</p>
                </div>
                <div class="area_img" id="62">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 亮度分量提取结果图" src="Detail/GetImg?filename=images/JYRJ201904031_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 亮度分量提取结果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_06200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="63" name="63"><b>1.2 获取分解系数</b></h4>
                <div class="p1">
                    <p id="64">非下采样Contourlet变换不仅继承了Contourlet变换具有的多方向性, 而且还具有平移不变性, 克服了Contourlet变换在对图像进行系数分解时产生的块效应, 使得融合图像的质量得以提升。对此, 本文将采用非下采样Contourlet变换对图像进行系数分解, 获取低频与高频系数。</p>
                </div>
                <div class="p1">
                    <p id="65">非下采样Contourlet变换在结构上由非下采样金字塔NSP (Nonsubsampled Pyramid) 以及非下采样方向滤波器组NSDFB (Nonsubsampled Directional Filter Bank) 构成<citation id="187" type="reference"><link href="162" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>。下采样Contourlet变换中的NSP具有非下采样性, 其通过双通道的NSDFB进行迭代来构造NSP, 可以达到多尺度分解的效果。在实现NSP分解后, 非下采样Contourlet变换还将采用NSDFB对分解所得的高频子带进行多方向的分解<citation id="188" type="reference"><link href="164" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>。NSDFB通过利用多种采样矩阵对扇形滤波器进行上采样, 同时对前级分解子带采用滤波操作, 以实现对子带图像进行精细方向分解的效果。</p>
                </div>
                <div class="p1">
                    <p id="66">非下采样Contourlet变换利用NSP与NSDFB分别实现精细的多尺度与多方向的分解, 从而使得获取到的低频系数与高频系数能够包含更多的空间与光谱信息。图3 (b) 中的亮度分量和图4 (a) 中的全色图像经过非下采样Contourlet变换后所得到的结果分别如图4 (b) 与图4 (c) 所示。</p>
                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 非下采样Contourlet变换系数分解效果图" src="Detail/GetImg?filename=images/JYRJ201904031_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 非下采样Contourlet变换系数分解效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_06700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="67">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_06701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 非下采样Contourlet变换系数分解效果图" src="Detail/GetImg?filename=images/JYRJ201904031_06701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 非下采样Contourlet变换系数分解效果图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_06701.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>1.3 系数融合策略</b></h4>
                <div class="p1">
                    <p id="70">信息熵能够对图像所含信息量进行度量, 同时也能对图像的光谱信息量进行度量。本文将通过图像的区域能量以及信息熵两个特征, 构建低频系数融合模型, 使得在融合低频系数时不仅能够考虑图像的特征信息, 而且还能兼顾图像的光谱信息。</p>
                </div>
                <div class="p1">
                    <p id="71">在低频系数<i>H</i> (<i>x</i>, <i>y</i>) 中, 以任意像素点<i>p</i> (<i>i</i>, <i>j</i>) 为中心建立一个尺寸为3×3的矩形窗口<i>L</i>, 则该窗口内的区域能量<i>R</i>为<citation id="189" type="reference"><link href="166" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="72"><mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>R</mi><mo>=</mo><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>x</mi><mo>, </mo><mi>y</mi><mo>∈</mo><mi>L</mi></mrow></munder><mrow><mrow><mo>|</mo><mrow><mi>Η</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>+</mo><mi>x</mi><mo>, </mo><mi>j</mi><mo>+</mo><mi>y</mi><mo stretchy="false">) </mo></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup></mrow></math></mathml>      (6) </p>
                </div>
                <div class="p1">
                    <p id="74">通过式 (6) 求取不同低频系数<i>H</i><sub><i>a</i></sub>与<i>H</i><sub><i>b</i></sub>中区域能量的占比<i>E</i><sub><i>a</i></sub>与<i>E</i><sub><i>b</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>E</mi><msub><mrow></mrow><mi>a</mi></msub><mo>=</mo><mfrac><mrow><mi>R</mi><msub><mrow></mrow><mi>a</mi></msub></mrow><mrow><mi>R</mi><msub><mrow></mrow><mi>a</mi></msub><mo>+</mo><mi>R</mi><msub><mrow></mrow><mi>b</mi></msub></mrow></mfrac></mtd></mtr><mtr><mtd><mi>E</mi><msub><mrow></mrow><mi>b</mi></msub><mo>=</mo><mfrac><mrow><mi>R</mi><msub><mrow></mrow><mi>b</mi></msub></mrow><mrow><mi>R</mi><msub><mrow></mrow><mi>a</mi></msub><mo>+</mo><mi>R</mi><msub><mrow></mrow><mi>b</mi></msub></mrow></mfrac></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>7</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">令图像的灰度级为{0, 1, 2, …, <i>S</i>-1}, 其中灰度<i>n</i> (<i>n</i>&lt;<i>S</i>) 出现的概率为<i>G</i><sub><i>n</i></sub>, 则信息熵<i>W</i>为<citation id="190" type="reference"><link href="168" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="77"><mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>W</mi><mo>=</mo><mo>-</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>S</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>G</mi></mstyle><msub><mrow></mrow><mi>n</mi></msub><mtext>l</mtext><mtext>b</mtext><mi>G</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></math></mathml>      (8) </p>
                </div>
                <div class="p1">
                    <p id="79">式中:lb表示以2为底的对数运算。</p>
                </div>
                <div class="p1">
                    <p id="80">通过式 (8) 按照类似式 (7) 的方法, 求取不同低频系数<i>H</i><sub><i>a</i></sub>与<i>H</i><sub><i>b</i></sub>中信息熵的占比<i>W</i><sub><i>a</i></sub>与<i>W</i><sub><i>b</i></sub>。则通过区域能量与信息熵特征构造的低频系数融合模型为:</p>
                </div>
                <div class="p1">
                    <p id="81"><i>H</i><sub><i>c</i></sub>= (<i>E</i><sub><i>a</i></sub>+<i>W</i><sub><i>a</i></sub>) <i>H</i><sub><i>a</i></sub>+ (<i>E</i><sub><i>b</i></sub>+<i>W</i><sub><i>b</i></sub>) <i>H</i><sub><i>b</i></sub>      (9) </p>
                </div>
                <div class="p1">
                    <p id="82">式中:<i>H</i><sub><i>c</i></sub>表示融合后的低频系数。</p>
                </div>
                <div class="p1">
                    <p id="83">在高频系数融合的过程中, 本文将利用图像的方差, 对不同高频系数的区域方差差异度进行度量, 并根据度量结果, 建立高频系数融合规则, 实现高频系数的融合。</p>
                </div>
                <div class="p1">
                    <p id="84">令高频系数<i>T</i> (<i>x</i>, <i>y</i>) 中, 以任意像素点<i>p</i> (<i>n</i>, <i>m</i>) 为中心建立的尺寸为3×3的矩形窗口<i>U</i>中的系数平均值为<i>K</i> (<i>n</i>, <i>m</i>) , 方差为<i>F</i> (<i>n</i>, <i>m</i>) , 则不同高频系数<i>T</i><sub><i>a</i></sub>与<i>T</i><sub><i>b</i></sub>对应的区域方差相似度<i>D</i> (<i>n</i>, <i>m</i>) 为<citation id="191" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="85" class="code-formula">
                        <mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mn>2</mn><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><mn>3</mn></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>y</mi><mo>=</mo><mn>1</mn></mrow><mn>3</mn></munderover><mo stretchy="false"> (</mo></mstyle></mrow></mstyle><mi>Τ</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Κ</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false"> (</mo><mi>Τ</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>x</mi><mo>, </mo><mi>y</mi><mo stretchy="false">) </mo><mo>-</mo><mi>Κ</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow><mrow><mn>9</mn><mo stretchy="false"> (</mo><mi>F</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>+</mo><mi>F</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>0</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="86">区域方差相似度<i>D</i> (<i>n</i>, <i>m</i>) 的大小反映了不同高频系数的区域差异度, 其值越大表示不同高频系数的区域特征差异较小。本文根据区域方差相似度<i>D</i> (<i>n</i>, <i>m</i>) 建立的高频系数融合规则如下。</p>
                </div>
                <div class="p1">
                    <p id="87">选取相似度阈值<i>YF</i>对<i>D</i> (<i>n</i>, <i>m</i>) 大小进行判断, 若<i>D</i> (<i>n</i>, <i>m</i>) &lt;<i>YF</i>, 则高频系数的融合规则为:</p>
                </div>
                <div class="p1">
                    <p id="88" class="code-formula">
                        <mathml id="88"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mi>Τ</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mtext> </mtext><mi>F</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>≥</mo><mi>F</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo></mtd></mtr><mtr><mtd><mi>Τ</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>F</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>&lt;</mo><mi>F</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>1</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="89">若<i>D</i> (<i>n</i>, <i>m</i>) ≥<i>YF</i>, 则高频系数的融合规则为:</p>
                </div>
                <div class="p1">
                    <p id="90" class="code-formula">
                        <mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Τ</mi><msub><mrow></mrow><mi>c</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>=</mo><mfrac><mrow><mi>F</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mi>Τ</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>+</mo><mi>F</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mi>Τ</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo></mrow><mrow><mi>F</mi><msub><mrow></mrow><mi>a</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo><mo>+</mo><mi>F</mi><msub><mrow></mrow><mi>b</mi></msub><mo stretchy="false"> (</mo><mi>n</mi><mo>, </mo><mi>m</mi><mo stretchy="false">) </mo></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>2</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="91">式中:<i>T</i><sub><i>c</i></sub> (<i>n</i>, <i>m</i>) 为融合后的高频系数。</p>
                </div>
                <div class="p1">
                    <p id="92">将融合后低、高频系数, 通过非下采样Contourlet反变换获取新的亮度分量<mathml id="93"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi>V</mi><mo>¯</mo></mover></math></mathml>, 并将其与原<i>H</i>、<i>S</i>分量进行HSV反变换, 从而获取融合图像。</p>
                </div>
                <div class="p1">
                    <p id="94">以图3 (a) 与图4 (a) 为对象, 利用上述算法融合后所输出的结果如图5所示。从图5可见, 融合后图像具有较好的光谱特性与空间特性。</p>
                </div>
                <div class="area_img" id="95">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 本文算法的融合结果" src="Detail/GetImg?filename=images/JYRJ201904031_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 本文算法的融合结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_095.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="96" name="96" class="anchor-tag"><b>2 实 验</b></h3>
                <div class="p1">
                    <p id="97">实验硬件环境为AMDR3CPU、500 GB硬盘的PC机, 采用MATLAB 7.0作为软件环境。实验中设置的对照组为文献<citation id="192" type="reference">[<a class="sup">12</a>]</citation>及文献<citation id="193" type="reference">[<a class="sup">13</a>]</citation>中的算法。实验中将相似度阈值<i>YF</i>的值设置为0.4。</p>
                </div>
                <h4 class="anchor-tag" id="98" name="98"><b>2.1 不同算法融合图像的视觉分析</b></h4>
                <div class="p1">
                    <p id="99">图6为不同算法对SOPT5卫星拍摄的某绿化区的遥感图像 (大小为512×512) 融合结果。从图6可见, 文献<citation id="194" type="reference">[<a class="sup">12</a>]</citation>算法融合的图像 (见图6 (c) ) 中存在较为严重的光谱扭曲现象, 图像中的建筑物颜色偏紫色, 而且左下角的方框所示的观察区中存在块效应现象, 绿色植被轮廓不清晰。文献<citation id="195" type="reference">[<a class="sup">13</a>]</citation>算法融合的图像 (见图6 (d) ) 中存在的光谱失真现象, 图像中的绿色植被颜色偏浅, 而且左下角的方框所示的观察区中存在模糊效应现象, 绿色植被模糊不清。本文算法融合的图像 (见图6 (e) ) 中建筑物与绿色植被颜色较为正常, 但整体图像稍微偏亮, 方框所示的观察区中绿色植被轮廓较为清晰。图7为不同算法对QuickBird卫星拍摄的某生活区的遥感图像 (大小为512×512) 融合结果。通过对比图7中各算法的融合图像可见, 文献<citation id="196" type="reference">[<a class="sup">12</a>]</citation>算法的融合图像中存在较为严重的光谱失真现象, 整体图像的颜色偏绿, 而且左下角的方框所示的观察区中存在一定的模糊块现象, 建筑物与植被较为模糊, 见图7 (c) 。文献<citation id="197" type="reference">[<a class="sup">13</a>]</citation>算法的融合图像中存在一定的光谱丢失现象, 图像颜色偏暗, 而且方框所示的观察区中存在较为严重块效应现象, 建筑物之间的间隔变窄, 见图7 (d) 。本文算法的融合图像中明暗度以及颜色都较为正常, 左下角的方框所示的观察区建筑物与植被都较为清晰, 仅建筑物与植被间存在轻微的模糊效应, 见图7 (e) 。由此可见, 本文算法融合的图像具有更好的光谱信息与空间信息, 以及视觉效果。原因是本文算法采用了HSV变换对多光谱图像进行分解获取亮度分量, 较好地保持了多光谱图像中的亮度以及光谱信息。另外, 本文算法还根据图像的区域方差特征, 建立了高频系数融合规则, 较好地保留了高频系数中的细节信息, 使得融合图像具有较好的视觉效果。</p>
                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法的融合图像" src="Detail/GetImg?filename=images/JYRJ201904031_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法的融合图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_10200.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="102">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_10201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 不同算法的融合图像" src="Detail/GetImg?filename=images/JYRJ201904031_10201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 不同算法的融合图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_10201.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="105">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 不同算法的融合图像" src="Detail/GetImg?filename=images/JYRJ201904031_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 不同算法的融合图像  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_10500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="106" name="106"><b>2.2 不同算法融合图像的客观分析</b></h4>
                <div class="p1">
                    <p id="107">利用通用图像质量指数UIQI (universal image quality index) 能够对融合后图像与全色图像的相似程度进行度量。UIQI的理想值为1, 其值越趋近于1, 则说明融合后图像与全色图像的相似程度越高。UIQI的函数为<citation id="198" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="108"><mathml id="109"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>U</mi><mi>Ι</mi><mi>Q</mi><mi>Ι</mi><mo>=</mo><mfrac><mrow><mi>β</mi><msub><mrow></mrow><mrow><mi>B</mi><mi>Ρ</mi></mrow></msub></mrow><mrow><mi>β</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mi>β</mi><msub><mrow></mrow><mi>B</mi></msub></mrow></mfrac><mfrac><mrow><mn>2</mn><msup><mi>B</mi><mo>′</mo></msup><msup><mi>Ρ</mi><mo>′</mo></msup></mrow><mrow><msup><mi>B</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><msup><mi>Ρ</mi><mo>′</mo></msup><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac><mfrac><mrow><mn>2</mn><mi>β</mi><msub><mrow></mrow><mi>Ρ</mi></msub><mi>β</mi><msub><mrow></mrow><mi>B</mi></msub></mrow><mrow><mi>β</mi><msub><mrow></mrow><mrow><msub><mrow></mrow><mi>B</mi></msub></mrow></msub><msup><mrow></mrow><mn>2</mn></msup><mo>+</mo><mi>β</mi><msub><mrow></mrow><mrow><msub><mrow></mrow><mi>Ρ</mi></msub></mrow></msub><msup><mrow></mrow><mn>2</mn></msup></mrow></mfrac></mrow></math></mathml>      (13) </p>
                </div>
                <div class="p1">
                    <p id="110">式中:<i>B</i>′与<i>P</i>′分别代表了融合后图像<i>B</i>与全色图像<i>P</i>的像素平均值, <i>β</i><sub><i>B</i></sub>与<i>β</i><sub><i>P</i></sub>分别代表了图像<i>B</i>与<i>P</i>的像素标准差值, <i>β</i><sub><i>BP</i></sub>代表了图像<i>B</i>与<i>P</i>的协方差值。</p>
                </div>
                <div class="p1">
                    <p id="111">利用相关系数指标CC (Correlation Coefficient) 能够对融合后图像与多光谱图像的相关程度进行度量。CC的理想值为1, CC值越接近1, 则说明融合后图像与多光谱图像的相关程度越高, 所包含的光谱信息就越丰富。CC的表达式为<citation id="199" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="112" class="code-formula">
                        <mathml id="112"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>C</mi><mi>C</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>b</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><msup><mi>B</mi><mo>′</mo></msup><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mi>m</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><msup><mi>Μ</mi><mo>′</mo></msup><mo stretchy="false">]</mo></mrow><mrow><msqrt><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>b</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><msup><mi>B</mi><mo>′</mo></msup><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup><mo>×</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>Κ</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>m</mi><mo stretchy="false"> (</mo><mi>i</mi><mo>, </mo><mi>j</mi><mo stretchy="false">) </mo><mo>-</mo><msup><mi>Μ</mi><mo>′</mo></msup><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup></mrow></msqrt></mrow></mfrac><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mn>4</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="113">式中:<i>b</i> (<i>i</i>, <i>j</i>) 与<i>m</i> (<i>i</i>, <i>j</i>) 分别代表了尺寸为<i>K</i>×<i>J</i>的图像<i>B</i>与多光谱图像<i>M</i>中的像素点。</p>
                </div>
                <div class="p1">
                    <p id="114">从IKONOS卫星拍摄的遥感图像中任意选取12组图像用作客观分析对象, 并通过UIQI以及CC两个指标对不同算法融合图像的质量进行量化度量。</p>
                </div>
                <div class="p1">
                    <p id="115">不同算法所输出的融合图像对应的量化度量结果如图8所示。通过观察图8 (a) 可见, 在对不同图像组的融合结果中, 本文算法融合图像的UIQI值始终是最大的, 对3号图像组融合后, 本文算法融合图像的UIQI值为0.964 2, 文献<citation id="200" type="reference">[<a class="sup">13</a>]</citation>算法的融合图像对应的UIQI值为0.944 6, 文献<citation id="201" type="reference">[<a class="sup">12</a>]</citation>算法的融合图像对应的UIQI值为0.908 6。通过观察图8 (b) 可见, 在对不同图像组的融合结果中, 本文算法融合图像的CC指标值始终最大, 不同算法对3号图像组融合后, 本文算法融合图像的CC值为0.920 6, 文献<citation id="202" type="reference">[<a class="sup">13</a>]</citation>算法融合图像的CC值为0.897 5, 文献<citation id="203" type="reference">[<a class="sup">12</a>]</citation>算法融合图像的CC值为0.850 8。由此可见, 本文算法较对照组具有良好的融合性能。因为本文采用了具有多方向性以及平移不变性的非下采样contourlet变换对图像进行系数分解, 同时还通过图像的区域能量以及信息熵特征, 构造了低频系数的融合模型对低频系数进行融合, 较好地保留了图像的空间以及光谱信息, 克服了块效应的产生, 使得算法的融合性能得以提高。文献<citation id="204" type="reference">[<a class="sup">12</a>]</citation>算法中利用PCA方法与滚动导向滤波器相结合, 获取多光谱图像的大尺度结构信息, 以及全色图像的小尺度信息, 进而再通过PCA反变换获取融合图像。由于PCA方法在获取尺度信息时存在光谱丢失现象, 而且该方法中滚动导向滤波器对参数设置较为依赖, 易导致滤波出错, 从而使得算法的融合性能不佳。文献<citation id="205" type="reference">[<a class="sup">13</a>]</citation>算法中利用显著性方法对图像进行多分辨率分析, 将二叉树复小波变换与多分辨率分析相结合实现图像融合。由于小波变换不具备多方向性特征, 使得融合图像中存在光谱以及图像细节信息丢失现象, 导致算法融合性能有所下降。</p>
                </div>
                <div class="area_img" id="117">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904031_11700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图8 不同算法融合图像的量化结果" src="Detail/GetImg?filename=images/JYRJ201904031_11700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图8 不同算法融合图像的量化结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904031_11700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="118" name="118" class="anchor-tag"><b>3 结 论</b></h3>
                <div class="p1">
                    <p id="119">本文通过HSV变换提取多光谱图像的亮度分量。使用非下采样Contourlet获取图像的低频系数与高频系数, 使得所得高频系数与低频系数能够包含原图的更多细节信息。利用图像的区域能量以及信息熵特征完成低频系数的融合, 使得低频系数的融合过程既考虑了图像的结构特征, 也考虑了图像的光谱特征, 提高了融合图像的光谱与空间特性。利用图像的区域方差特征完成高频系数的融合。通过实验对比验证了本文算法的优越性能, 表明了本文算法能够较好地实现遥感图像的融合。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="150">
                            <a id="bibliography_1" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ship Detection in Optical Remote Sensing Images Based on Wavelet Transform and Multi-Level False Alarm Identification">

                                <b>[1]</b> Xu F, Liu J H, Dong C. Ship detection in optical remote sensing images based on wavelet transform and multi-level false alarm identification [J].Remote Sensing, 2017, 10 (9) : 1-19.
                            </a>
                        </p>
                        <p id="152">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=An Improved Remote Sensing Image Fusion Algorithm Based on IHS Transformation">

                                <b>[2]</b> Deng C, Wang Z H, Li X W. An improved remote sensing image fusion algorithm based on IHS transformation [J]. KSII Transactions on Internet and Information Systems, 2017, 11 (3) : 1633-1649.
                            </a>
                        </p>
                        <p id="154">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Sparse representation and PCA method for image fusion in remote sensing">

                                <b>[3]</b> Zhang X F, Ni D, Gou Z J. Sparse representation and PCA method for image fusion in remote sensing [C]//Proceedings of 2016 the 2nd international conference on control, automation and robotics, 2016: 324-330.
                            </a>
                        </p>
                        <p id="156">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXJS201704043&amp;v=MDcxMTVxcUJ0R0ZyQ1VSN3FmWnVadEZ5em1VYjdPTGpYQmZiRzRIOWJNcTQ5Qlo0UUtESDg0dlI0VDZqNTRPM3o=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 赵学军, 刘静. 基于Shearlet和稀疏表示的遥感图像融合[J].科学技术与工程, 2017, 17 (4) : 255-259.
                            </a>
                        </p>
                        <p id="158">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HDZJ201703015&amp;v=MDM2NTR6bVViN09MU25SWkxHNEg5Yk1ySTlFWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 赵延芳, 王涛, 李鹏. 基于ZY3遥感图像的反立体校正方法研究[J]. 信息技术, 2017, 15 (3) : 60-64.
                            </a>
                        </p>
                        <p id="160">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJDB424621BCD8AF05975389489CFF3CD9D&amp;v=MTE2NjFmT0dRbGZCckxVMDV0dGh3THU5d2E0PU5qN0Jhc0c4SE5YS3JZNDNGNThIZlFvNXloOFU3engxUVh2cXBXRkREN0huTWJQckNPTnZGU2lXV3I3SklGcG1hQnVIWQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> Wang W H, Sun S L, Jiang M X. Traffic lights detection and recognition based on multi-feature fusion [J]. Multimedia Tools and Applications, 2017, 76 (13) : 14829-14846.
                            </a>
                        </p>
                        <p id="162">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD29B484B1A96E44D941E9A268D3088E88&amp;v=MDcyOThwME9YM2twR1kyZWJxY01MS1hDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh3THU5d2E0PU5qN0Jhckd4Yk5YRXEvMUVGZUlKZVhnOXV4OFg2MA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> Panchal S, Thakker R A. Improved image pansharpening technique using nonsubsampled contourlet transform with sparse representation[J]. Journal of the Indian Society of Remote Sensing, 2017, 45 (3) : 385-394.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD425A1FC670B13B1DDB31A82E13622071&amp;v=MDU3NDliMmVDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh3THU5d2E0PU5qN0JhcmU2RzZETjJmeERZK3Q5RFg5THptSm5tRHg4T1hmZzJSTTJmN0NXUg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> Peng G, Wang Z Y, Liu S Q. Image fusion by combining multiwavelet with nonsubsampled direction filter bank[J]. Soft Computing, 2017, 21 (8) :1977-1989.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Energy-efficient Multi-focus Image Fusion Based on Neighbor Distance and Morphology">

                                <b>[9]</b> Liu C P, Long Y H, Mao J X. Energy-efficient multi-focus image fusion based on neighbor distance and morphology [J]. Optik-International Journal for Light and Electron Optics, 2016, 127 (23) : 11354-11363.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Brain tumour detection using discrete wavelet transform based medical image fusion">

                                <b>[10]</b> Udhaya Suriya T S, Rangarajan P. Brain tumour detection using discrete wavelet transform based medical image fusion [J]. Biomedical Research, 2017, 28 (2) : 684-688.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Pleiades satellite remote sensing image fusion algorithm based on shearlet transform">

                                <b>[11]</b> Bao W X, Wang W, Zhu Y X. Pleiades satellite remote sensing image fusion algorithm based on shearlet transform [J].Journal of the Indian Society of Remote Sensing, 2018, 46 (1) : 19-29.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_12" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=YHXB201712012&amp;v=MDMyMTlHRnJDVVI3cWZadVp0Rnl6bVViN09QQ1hUYkxHNEg5Yk5yWTlFWm9RS0RIODR2UjRUNmo1NE8zenFxQnQ=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[12]</b> 李旭, 高雅楠, Yue S.一种尺度感知型遥感图像融合新方法[J].宇航学报, 2017, 38 (12) :1348-1353.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A New saliency-driven fusion method based on complex wavelet transform for remote sensing images">

                                <b>[13]</b> Zhang J. A new saliency-driven fusion method based on complex wavelet transform for remote sensing images [J]. IEEE Geoscience and Remote Sensing Letters, 2017, 14 (12) :2433-2437.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=KXTS201807002&amp;v=MDUzODRSN3FmWnVadEZ5em1VYjdPTGpYZmZiRzRIOW5NcUk5RlpvUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 杨艳春, 李娇, 王阳萍.图像融合质量评价方法研究综述[J].计算机科学与探索, 2018, 12 (7) : 1021-1035.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD298D86D28A969C0AEA62F3BF84CCE69A&amp;v=MTQxMjVPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHdMdTl3YTQ9Tmo3QmFyR3hGcVhFcWZ0SGJKb0dDblZLejJkbW16bC9QbnlRMmhveENzSGhRN1B1Qw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Sanli F B, Abdikan S, Esetlili M T, et al. Evaluation of image fusion methods using PALSAR, RADARSAT-1 and SPOT images for land use/land cover classification [J].Journal of the Indian Society of Remote Sensing, 2017, 45 (4) : 591-601.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201904031" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904031&amp;v=MTk4MjVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXptVWI3UEx6VFpaTEc0SDlqTXE0OUdaWVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
