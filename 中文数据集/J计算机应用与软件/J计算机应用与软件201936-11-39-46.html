<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637134076642912500%26DBCODE%3dCJFD%26TABLEName%3dCJFDTEMP%26FileName%3dJYRJ201911008%26RESULT%3d1%26SIGN%3dnbY9vaRYtC%252fcwOwEb9DNSmyrnoA%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911008&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201911008&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911008&amp;v=MTU0ODNaWkxHNEg5ak5ybzlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvZ1Zick9MelQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#51" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#56" data-title="&lt;b&gt;1 相关理论基础&lt;/b&gt; "><b>1 相关理论基础</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#57" data-title="&lt;b&gt;1.1 长短期记忆网络&lt;/b&gt;"><b>1.1 长短期记忆网络</b></a></li>
                                                <li><a href="#69" data-title="&lt;b&gt;1.2 Snapshot模型集成方法&lt;/b&gt;"><b>1.2 Snapshot模型集成方法</b></a></li>
                                                <li><a href="#74" data-title="&lt;b&gt;1.3 Stacking模型集成方法&lt;/b&gt;"><b>1.3 Stacking模型集成方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#89" data-title="&lt;b&gt;2 基于LSTM的模型集成方法&lt;/b&gt; "><b>2 基于LSTM的模型集成方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#92" data-title="&lt;b&gt;2.1 基本思想&lt;/b&gt;"><b>2.1 基本思想</b></a></li>
                                                <li><a href="#94" data-title="&lt;b&gt;2.2 样本权重计算&lt;/b&gt;"><b>2.2 样本权重计算</b></a></li>
                                                <li><a href="#102" data-title="&lt;b&gt;2.3 LSTM模型&lt;/b&gt;"><b>2.3 LSTM模型</b></a></li>
                                                <li><a href="#105" data-title="&lt;b&gt;2.4 算法流程&lt;/b&gt;"><b>2.4 算法流程</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#120" data-title="&lt;b&gt;3 实 验&lt;/b&gt; "><b>3 实 验</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#121" data-title="&lt;b&gt;3.1 实验环境&lt;/b&gt;"><b>3.1 实验环境</b></a></li>
                                                <li><a href="#123" data-title="&lt;b&gt;3.2 数据介绍&lt;/b&gt;"><b>3.2 数据介绍</b></a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;3.3 特征工程&lt;/b&gt;"><b>3.3 特征工程</b></a></li>
                                                <li><a href="#130" data-title="&lt;b&gt;3.4 训练样本&lt;/b&gt;"><b>3.4 训练样本</b></a></li>
                                                <li><a href="#132" data-title="&lt;b&gt;3.5 评价指标&lt;/b&gt;"><b>3.5 评价指标</b></a></li>
                                                <li><a href="#142" data-title="&lt;b&gt;3.6 实验参数&lt;/b&gt;"><b>3.6 实验参数</b></a></li>
                                                <li><a href="#144" data-title="&lt;b&gt;3.7 实验结果&lt;/b&gt;"><b>3.7 实验结果</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#165" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#60" data-title="图1 LSTM单元结构图">图1 LSTM单元结构图</a></li>
                                                <li><a href="#91" data-title="图2 客户流失预测框架">图2 客户流失预测框架</a></li>
                                                <li><a href="#104" data-title="图3 LSTM模型结构图">图3 LSTM模型结构图</a></li>
                                                <li><a href="#126" data-title="&lt;b&gt;表1 原始数据字段示例&lt;/b&gt;"><b>表1 原始数据字段示例</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表2 模型效果对比结果&lt;/b&gt;"><b>表2 模型效果对比结果</b></a></li>
                                                <li><a href="#158" data-title="&lt;b&gt;表3 训练时间对比结果&lt;/b&gt;"><b>表3 训练时间对比结果</b></a></li>
                                                <li><a href="#161" data-title="图4 不同参数&lt;i&gt;c&lt;/i&gt;对比结果">图4 不同参数<i>c</i>对比结果</a></li>
                                                <li><a href="#164" data-title="图5 不同初始学习率对比结果">图5 不同初始学习率对比结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="202">


                                    <a id="bibliography_1" title=" Athanassopoulos A D.Customer satisfaction cues to support market segmentation and explain switching behavior [J].Journal of Business Research,2000,47(3):191-207." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011400022193&amp;v=MTk4NDRVYi9JSjFzU2J4cz1OaWZPZmJLN0h0RE5xNDlGWk9rTkRYVTZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Athanassopoulos A D.Customer satisfaction cues to support market segmentation and explain switching behavior [J].Journal of Business Research,2000,47(3):191-207.
                                    </a>
                                </li>
                                <li id="204">


                                    <a id="bibliography_2" title=" Idris A,Khan A.Ensemble based efficient churn prediction model for telecom [C]//2014 12th International Conference on Frontiers of Information Technology.Piscataway,NJ:IEEE,2014:238-244." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ensemble based efficient churn prediction model for telecom">
                                        <b>[2]</b>
                                         Idris A,Khan A.Ensemble based efficient churn prediction model for telecom [C]//2014 12th International Conference on Frontiers of Information Technology.Piscataway,NJ:IEEE,2014:238-244.
                                    </a>
                                </li>
                                <li id="206">


                                    <a id="bibliography_3" title=" 余路.电信客户流失的组合预测模型[J].华侨大学学报(自然科学版),2016,37(5):637-640." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HQDB201605022&amp;v=MTY2OTlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9nVmJyQkxUelBiTEc0SDlmTXFvOUhab1E=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         余路.电信客户流失的组合预测模型[J].华侨大学学报(自然科学版),2016,37(5):637-640.
                                    </a>
                                </li>
                                <li id="208">


                                    <a id="bibliography_4" title=" Prasad U D,Madhavi S.Prediction of churn behavior of bank customers using data mining tools[J].Business Intelligence Journal,2012,5(1):96-101." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Prediction of Churn Behavior of Bank Customer Customers Using Data Mining Tools">
                                        <b>[4]</b>
                                         Prasad U D,Madhavi S.Prediction of churn behavior of bank customers using data mining tools[J].Business Intelligence Journal,2012,5(1):96-101.
                                    </a>
                                </li>
                                <li id="210">


                                    <a id="bibliography_5" title=" Chen Y,Gel Y R,Lyubchich V,et al.Deep ensemble classifiers and peer effects analysis for churn forecasting in retail banking[C]//Pacific-Asia Conference on Knowledge Discovery and Data Mining.Berlin:Springer,2018:373-385." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Deep ensemble classifiers and peer effects analysis for churn forecasting in retail banking">
                                        <b>[5]</b>
                                         Chen Y,Gel Y R,Lyubchich V,et al.Deep ensemble classifiers and peer effects analysis for churn forecasting in retail banking[C]//Pacific-Asia Conference on Knowledge Discovery and Data Mining.Berlin:Springer,2018:373-385.
                                    </a>
                                </li>
                                <li id="212">


                                    <a id="bibliography_6" title=" 丁军,高大启,薛程元,等.基于社交网络的MMORPG玩家流失分析与预测[J].计算机应用与软件,2016,33(3):109-113." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201603025&amp;v=MDM0MDVMT2VaZVZ1RnkvZ1ZickJMelRaWkxHNEg5Zk1ySTlIWVlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         丁军,高大启,薛程元,等.基于社交网络的MMORPG玩家流失分析与预测[J].计算机应用与软件,2016,33(3):109-113.
                                    </a>
                                </li>
                                <li id="214">


                                    <a id="bibliography_7" title=" 吴悦昕,赵鑫,过岩巍,等.在线游戏用户的流失预测:基于不平衡数据的采样方法比较和分析[J].中文信息学报,2016,30(4):213-222." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201604029&amp;v=MDgyOTM0OUhiWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9nVmJyQktDallmYkc0SDlmTXE=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         吴悦昕,赵鑫,过岩巍,等.在线游戏用户的流失预测:基于不平衡数据的采样方法比较和分析[J].中文信息学报,2016,30(4):213-222.
                                    </a>
                                </li>
                                <li id="216">


                                    <a id="bibliography_8" title=" Dinis G.Churn analysis in a music streaming service:Predicting and understanding retention[D].Stockholm:KTH Royal Institute of Technology,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Churn analysis in a music streaming service:Predicting and understanding retention">
                                        <b>[8]</b>
                                         Dinis G.Churn analysis in a music streaming service:Predicting and understanding retention[D].Stockholm:KTH Royal Institute of Technology,2017.
                                    </a>
                                </li>
                                <li id="218">


                                    <a id="bibliography_9" title=" Nie G,Rowe W,Zhang L,et al.Credit card churn forecasting by logistic regression and decision tree[J].Expert Systems with Applications,2011,38(12):15273-15285." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638646&amp;v=MzEzMzVtVWIvSUoxc1NieHM9TmlmT2ZiSzdIdEROcW85RVl1Z0hDbmcvb0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5ag==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Nie G,Rowe W,Zhang L,et al.Credit card churn forecasting by logistic regression and decision tree[J].Expert Systems with Applications,2011,38(12):15273-15285.
                                    </a>
                                </li>
                                <li id="220">


                                    <a id="bibliography_10" title=" 杜修平,王中.基于决策树的证券客户流失模型 [J].计算机应用与软件,2009,26(9):230-233." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ200909070&amp;v=MDE3Nzh0R0ZyQ1VSTE9lWmVWdUZ5L2dWYnJCTHpUWlpMRzRIdGpNcG85Q1pJUUtESDg0dlI0VDZqNTRPM3pxcUI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         杜修平,王中.基于决策树的证券客户流失模型 [J].计算机应用与软件,2009,26(9):230-233.
                                    </a>
                                </li>
                                <li id="222">


                                    <a id="bibliography_11" title=" 贺本岚.支持向量机模型在银行客户流失预测中的应用研究[J].金融论坛,2014(9):70-74." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CSJR201409011&amp;v=MjE1ODBGckNVUkxPZVplVnVGeS9nVmJyQkpqN0JmTEc0SDlYTXBvOUVaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEc=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         贺本岚.支持向量机模型在银行客户流失预测中的应用研究[J].金融论坛,2014(9):70-74.
                                    </a>
                                </li>
                                <li id="224">


                                    <a id="bibliography_12" title=" Castanedo F,Valverde G,Zaratiegui J,et al.Using deep learning to predict customer churn in a mobile telecommunication network [EB/OL].[2019-01-15].http://www.wiseathena.com/pdf/wa_dl.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using deep learning to predict customer churn in a mobile telecommunication network">
                                        <b>[12]</b>
                                         Castanedo F,Valverde G,Zaratiegui J,et al.Using deep learning to predict customer churn in a mobile telecommunication network [EB/OL].[2019-01-15].http://www.wiseathena.com/pdf/wa_dl.pdf.
                                    </a>
                                </li>
                                <li id="226">


                                    <a id="bibliography_13" title=" Wangperawong A,Brun C,Laudy O,et al.Churn analysis using deep convolutional neural networks and autoencoders [EB/OL].(2016-04-18)[2018-12-29].https://arxiv.org/pdf/1604.05377.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Churn analysis using deepconvolutional neural networks and autoencoders">
                                        <b>[13]</b>
                                         Wangperawong A,Brun C,Laudy O,et al.Churn analysis using deep convolutional neural networks and autoencoders [EB/OL].(2016-04-18)[2018-12-29].https://arxiv.org/pdf/1604.05377.pdf.
                                    </a>
                                </li>
                                <li id="228">


                                    <a id="bibliography_14" title=" Dietterich T G.Ensemble methods in machine learning[C]//International workshop on multiple classifier systems.Berlin:Springer,2000:1-15." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Ensemble methods in Machine Learning">
                                        <b>[14]</b>
                                         Dietterich T G.Ensemble methods in machine learning[C]//International workshop on multiple classifier systems.Berlin:Springer,2000:1-15.
                                    </a>
                                </li>
                                <li id="230">


                                    <a id="bibliography_15" title=" Breiman L.Bagging predictors[J].Machine learning,1996,24(2):123-140." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339482&amp;v=MDI4NzFsVkxyT0pWYz1OajdCYXJPNEh0SE5ySXhNWU9NTlkzazV6QmRoNGo5OVNYcVJyeG94Y01IN1I3cWVidWR0RlNq&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Breiman L.Bagging predictors[J].Machine learning,1996,24(2):123-140.
                                    </a>
                                </li>
                                <li id="232">


                                    <a id="bibliography_16" title=" Yoav F,Robert E S.Experiments with a new boosting algorithm [C]//Proceedings of the Thirteenth International Conference on International Conference on Machine Learning.New York,NY:ACM,1996,148-156." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Experiments with a new boosting algorithm">
                                        <b>[16]</b>
                                         Yoav F,Robert E S.Experiments with a new boosting algorithm [C]//Proceedings of the Thirteenth International Conference on International Conference on Machine Learning.New York,NY:ACM,1996,148-156.
                                    </a>
                                </li>
                                <li id="234">


                                    <a id="bibliography_17" title=" Breiman L.Stacked regressions [J].Machine learning,1996,24(1):49-64." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339457&amp;v=MjUwMjJjPU5qN0Jhck80SHRITnJJeE1ZTzRJWTNrNXpCZGg0ajk5U1hxUnJ4b3hjTUg3UjdxZWJ1ZHRGU2psVkxyT0pW&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Breiman L.Stacked regressions [J].Machine learning,1996,24(1):49-64.
                                    </a>
                                </li>
                                <li id="236">


                                    <a id="bibliography_18" title=" Do D,Huynh P,Vo P,et al.Customer churn prediction in an internet service provider [C]//2017 IEEE International Conference on Big Data (Big Data).Piscataway,NJ:IEEE,2017:3928-3933." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Customer churn prediction in an internet service provider">
                                        <b>[18]</b>
                                         Do D,Huynh P,Vo P,et al.Customer churn prediction in an internet service provider [C]//2017 IEEE International Conference on Big Data (Big Data).Piscataway,NJ:IEEE,2017:3928-3933.
                                    </a>
                                </li>
                                <li id="238">


                                    <a id="bibliography_19" title=" Mishra A,Reddy U S.A comparative study of customer churn prediction in telecom industry using ensemble based classifiers [C]//2017 International Conference on Inventive Computing and Informatics(ICICI).Piscataway,NJ:IEEE,2017:721-725." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A comparative study of customer churn prediction in telecom industry using ensemble based classifiers">
                                        <b>[19]</b>
                                         Mishra A,Reddy U S.A comparative study of customer churn prediction in telecom industry using ensemble based classifiers [C]//2017 International Conference on Inventive Computing and Informatics(ICICI).Piscataway,NJ:IEEE,2017:721-725.
                                    </a>
                                </li>
                                <li id="240">


                                    <a id="bibliography_20" title=" Huang G,Li Y,Pleiss G,et al.Snapshot ensembles:Train 1,get M for free [EB/OL].(2017-04-01)[2018-12-29].https://arxiv.org/pdf/1704.00109.pdf." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Snapshot ensembles:Train 1,get M for free">
                                        <b>[20]</b>
                                         Huang G,Li Y,Pleiss G,et al.Snapshot ensembles:Train 1,get M for free [EB/OL].(2017-04-01)[2018-12-29].https://arxiv.org/pdf/1704.00109.pdf.
                                    </a>
                                </li>
                                <li id="242">


                                    <a id="bibliography_21" title=" Hochreiter S,Schmidhuber J.Long short-term memory [J].Neural computation,1997,9(8):1735-1780." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MDkxNTVRVE1ud1plWnVIeWptVWIvSUoxc1NieHM9TmlmSlpiSzlIdGpNcW85RlpPb0xEWFV4b0JNVDZUNFBRSC9pclJkR2VycQ==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         Hochreiter S,Schmidhuber J.Long short-term memory [J].Neural computation,1997,9(8):1735-1780.
                                    </a>
                                </li>
                                <li id="244">


                                    <a id="bibliography_22" title=" 周志华.机器学习[M].北京:清华大学出版社,2016:184." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MDk4NzhNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3JsVTdqTkpsc2RYRnF6R2JDNEhOWE9ySTFOWStzUERC&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         周志华.机器学习[M].北京:清华大学出版社,2016:184.
                                    </a>
                                </li>
                                <li id="246">


                                    <a id="bibliography_23" title=" Davis J,Goadrich M.The relationship between Precision-Recall and ROC curves[C]//Proceedings of the 23rd international conference on Machine learning.New York,NY:ACM,2006:233-240." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Relationship Between Precision-Recall and ROC Curves">
                                        <b>[23]</b>
                                         Davis J,Goadrich M.The relationship between Precision-Recall and ROC curves[C]//Proceedings of the 23rd international conference on Machine learning.New York,NY:ACM,2006:233-240.
                                    </a>
                                </li>
                                <li id="248">


                                    <a id="bibliography_24" title=" Reshef D N,Reshef Y A,Finucane H K,et al.Detecting Novel Associations in Large Data Sets[J].Science,2011,334 (6062):1518-1524." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Detecting Novel Associations in Large Data Sets">
                                        <b>[24]</b>
                                         Reshef D N,Reshef Y A,Finucane H K,et al.Detecting Novel Associations in Large Data Sets[J].Science,2011,334 (6062):1518-1524.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(11),39-46 DOI:10.3969/j.issn.1000-386x.2019.11.007            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>LSTM模型集成方法在客户流失预测中的应用</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E6%8D%B7&amp;code=28583486&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周捷</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%B8%A5%E5%BB%BA%E5%B3%B0&amp;code=22148822&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">严建峰</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%A8%E7%92%90&amp;code=26054849&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">杨璐</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%A4%8F%E9%B9%8F&amp;code=28148422&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">夏鹏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E7%8E%8B%E7%8C%9B&amp;code=24051611&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">王猛</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%8B%8F%E5%B7%9E%E5%A4%A7%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AD%A6%E9%99%A2&amp;code=0240077&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">苏州大学计算机科学与技术学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>目前客户流失预测任务中常用的模型集成方法采用传统机器学习模型作为基学习器。而传统机器学习模型相比于深度学习模型,存在无法对时序数据进行有效建模、特征工程对模型效果影响较大等缺点。针对这些问题,提出基于LSTM的模型集成方法。采用LSTM作为基学习器进行时序数据建模;改进snapshot模型集成方法,增加样本权重调整方法,在训练单个LSTM模型的过程中得到多个具有不同权值的模型;利用得到的多个模型构造新数据集,在新数据集上训练逻辑回归模型。实验结果表明,该方法相比于单模型LSTM,可以在仅花费其1.8倍训练时间的前提下,将查准率和PR-AUC分别提升4.67%和3.74%,显著提高了客户流失预测效果。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B5%81%E5%A4%B1%E9%A2%84%E6%B5%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">流失预测;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">长短期记忆网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">集成学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">时序数据;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    周捷，硕士生，主研领域:机器学习，数据挖掘。;
                                </span>
                                <span>
                                    严建峰，副教授。;
                                </span>
                                <span>
                                    杨璐，副教授。;
                                </span>
                                <span>
                                    夏鹏，硕士生。;
                                </span>
                                <span>
                                    王猛，硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-02-24</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61572339);</span>
                    </p>
            </div>
                    <h1><b>APPLICATION OF LSTM ENSEMBLE METHOD IN CUSTOMER CHURN PREDICTION</b></h1>
                    <h2>
                    <span>Zhou Jie</span>
                    <span>Yan Jianfeng</span>
                    <span>Yang Lu</span>
                    <span>Xia Peng</span>
                    <span>Wang Meng</span>
            </h2>
                    <h2>
                    <span>School of Computer Science and Technology, Soochow University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>At present, most of the ensemble learning methods used in customer churn prediction tasks use conventional machine learning models as a base learner. Compared with deep learning, the conventional machine learning models cannot efficiently model time series data and feature engineering has a great effect on the performance of models. To solve these problems, this paper proposed an ensemble learning method which was based on LSTM. We took LSTM as a base learner to model time series data, and used snapshot ensemble method and adjusted sample weights during the training process. Multi-models with different weights were saved in the process of training a single LSTM model. Finally, a new dataset was generated by using the multi-models, and a logistic regression model was trained on this dataset. Experimental results show that compared with LSTM, the proposed method improves the precision and PR-AUC by 4.67% and 3.74% respectively, and the training time is only 1.8 times as long as LSTM. This shows that the proposed method significantly improves the customer churn prediction effect.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Churn%20prediction&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Churn prediction;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Long%20short-term%20memory&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Long short-term memory;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Ensemble%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Ensemble learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Time%20series%20data&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Time series data;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-02-24</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="51" name="51" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="52">对企业而言,客户流失被定义为客户放弃继续购买该企业的商品或服务的情况。客户的流失会对企业造成直接经济损失。随着市场竞争的激烈程度逐年增高,企业所面临的客户流失问题日益严重。研究发现,企业成功获取新客户所需要的成本远高于保留已有客户<citation id="250" type="reference"><link href="202" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>,这使得客户保留对于企业来说格外重要。保留现有客户的常用方法是准确识别出高流失倾向的客户,然后针对这些客户实施多样性的挽留策略。客户流失预测作为客户关系管理的重要组成部分,通过对客户的历史数据进行分析建模,旨在准确识别出高流失倾向的客户,为企业后续的客户挽留策略制定提供指导。</p>
                </div>
                <div class="p1">
                    <p id="53">在过去数十年,客户流失预测已经在电信<citation id="264" type="reference"><link href="204" rel="bibliography" /><link href="206" rel="bibliography" /><sup>[<a class="sup">2</a>,<a class="sup">3</a>]</sup></citation>、银行<citation id="265" type="reference"><link href="208" rel="bibliography" /><link href="210" rel="bibliography" /><sup>[<a class="sup">4</a>,<a class="sup">5</a>]</sup></citation>、游戏<citation id="266" type="reference"><link href="212" rel="bibliography" /><link href="214" rel="bibliography" /><sup>[<a class="sup">6</a>,<a class="sup">7</a>]</sup></citation>以及音乐流媒体<citation id="251" type="reference"><link href="216" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>等不同领域内被广泛研究。学者通常把客户流失预测当作二分类数据挖掘任务处理,通过构造业务特征以及选择合适的分类器来预测客户未来流失与否。许多流行的机器学习模型和深度学习模型在客户流失预测中得到成功应用,如逻辑回归(Logistic Regression,LR)<citation id="252" type="reference"><link href="218" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>、决策树(Decision Tree,DT)<citation id="253" type="reference"><link href="220" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>、支持向量机(Support Vector Machine,SVM)<citation id="254" type="reference"><link href="222" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>、多层反馈神经网络(Neural Networks,NN)<citation id="255" type="reference"><link href="224" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>和卷积神经网络(Convolutional Neural Networks,CNN)<citation id="256" type="reference"><link href="226" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>等。模型集成<citation id="257" type="reference"><link href="228" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>是用来提升预测效果的一个有效方法,常用集成方法有bagging<citation id="258" type="reference"><link href="230" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>、boosting<citation id="259" type="reference"><link href="232" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>和stacking<citation id="260" type="reference"><link href="234" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>。文献<citation id="261" type="reference">[<a class="sup">18</a>]</citation>使用XGBoost(eXtreme Gradient Boosting,XGB)预测因特网服务提供商的客户流失情况,该模型是boosting集成方法的一种。文献<citation id="262" type="reference">[<a class="sup">19</a>]</citation>对比了几种集成学习分类器,发现随机森林(Random Forest,RF)效果最好,该模型是bagging集成方法的一种变体。文献<citation id="263" type="reference">[<a class="sup">2</a>]</citation>通过投票法集成了K近邻(K-Nearest Neighbor,KNN)、随机森林以及Rotation Forest三种模型,实验发现这三种模型的集成输出增加了模型多样性的同时提高了分类效果。</p>
                </div>
                <div class="p1">
                    <p id="54">与深度学习模型相比,传统机器学习模型存在特征工程对模型效果影响较大、模型容量小等缺点。目前客户流失预测任务中的模型集成方法的研究大多集中于传统机器学习模型方面,在深度学习模型集成方法方面的研究较少。文献<citation id="267" type="reference">[<a class="sup">5</a>]</citation>提出一种深度集成分类器用于银行客户流失预测,其采用k折交叉验证的stacking集成方法将深度学习模型和传统机器学习模型一起集成,这样可能会存在两个问题:一是通过k折交叉验证训练深度学习模型会带来高昂的训练时间成本;二是当用于集成的模型的性能相差较大时,会影响最终模型集成的效果。文献<citation id="268" type="reference">[<a class="sup">20</a>]</citation>提出snapshot模型集成方法,可以在训练单个深度学习模型的过程中得到多个具有不同权值的模型用于模型集成,降低了深度学习模型集成的时间成本,在多个图像数据集上进行实验,验证了该方法的有效性。</p>
                </div>
                <div class="p1">
                    <p id="55">为了在客户流失预测任务中发挥深度学习模型集成的效果,本文提出一种基于长短期记忆网络(Long short-term memory,LSTM)的模型集成方法(snapshot weighted LSTM,swLSTM)。该方法首先选择LSTM作为基学习器。然后对snapshot模型集成方法的训练过程进行改进,一方面是引入样本权重调整方法,根据当前子模型对训练样本的预测结果为下一个子模型计算训练样本权重;另一方面将各个子模型在验证集上的输出和对应的样本标签重组为一个新的训练集,再在新的训练集上训练逻辑回归模型。实验表明,本文方法能够显著提升客户流失预测效果。</p>
                </div>
                <h3 id="56" name="56" class="anchor-tag"><b>1 相关理论基础</b></h3>
                <h4 class="anchor-tag" id="57" name="57"><b>1.1 长短期记忆网络</b></h4>
                <div class="p1">
                    <p id="58">LSTM由Hochreiter等<citation id="269" type="reference"><link href="242" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>提出,广泛用于序列建模,其中门机制以及细胞状态的引入较好地缓解了经典循环神经网络中存在的梯度消失等问题。</p>
                </div>
                <div class="p1">
                    <p id="59">LSTM的基本单元包括输出门、输入门、遗忘门以及细胞状态,其中细胞状态可以保存长期历史信息,保证模型训练过程中信息的有效流通,门机制可以对信息量进行限制。基本单元的结构图如图1所示。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911008_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 LSTM单元结构图" src="Detail/GetImg?filename=images/JYRJ201911008_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 LSTM单元结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911008_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="61">图1中:<i>t</i>表示当前时刻,<i>t</i>-1表示上一时刻,<i><b>C</b></i><sub><i>t</i></sub><sub>-1</sub>、<i><b>h</b></i><sub><i>t</i></sub><sub>-1</sub>分别表示上一时刻细胞状态和隐藏层状态的输出,<i><b>C</b></i><sub><i>t</i></sub>、<i><b>h</b></i><sub><i>t</i></sub>分别表示当前时刻细胞状态和隐藏层状态的输出,<i><b>i</b></i><sub><i>t</i></sub>表示输入门,<i><b>f</b></i><sub><i>t</i></sub>表示遗忘门,<i><b>o</b></i><sub><i>t</i></sub>表示输出门,<i>σ</i>表示sigmoid激活函数。LSTM基本单元各组成部分的更新公式如下:</p>
                </div>
                <div class="p1">
                    <p id="62"><i>f</i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub>f</sub><sub><i>x</i></sub><i>x</i><sub><i>t</i></sub>+<i><b>W</b></i><sub>f</sub><sub><i>h</i></sub><i>h</i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub>f</sub>)      (1)</p>
                </div>
                <div class="p1">
                    <p id="63"><i>i</i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub>i</sub><sub><i>x</i></sub><i>x</i><sub><i>t</i></sub>+<i><b>W</b></i><sub>i</sub><sub><i>h</i></sub><i>h</i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub>i</sub>)      (2)</p>
                </div>
                <div class="p1">
                    <p id="64"><mathml id="167"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover><mstyle mathsize="140%" displaystyle="true"><mi mathvariant="bold-italic">C</mi></mstyle><mo>∼</mo></mover><mo>=</mo><mrow><mi>tanh</mi></mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mi>x</mi></mrow></msub><mi mathvariant="bold-italic">x</mi><msub><mrow></mrow><mi>t</mi></msub><mo>+</mo><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mrow><mtext>c</mtext><mi>h</mi></mrow></msub><mi mathvariant="bold-italic">h</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">b</mi><msub><mrow></mrow><mtext>c</mtext></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (3)</p>
                </div>
                <div class="p1">
                    <p id="65"><i><b>o</b></i><sub><i>t</i></sub>=<i>σ</i>(<i><b>W</b></i><sub>o</sub><sub><i>x</i></sub><i><b>x</b></i><sub><i>t</i></sub>+<i><b>W</b></i><sub>o</sub><sub><i>h</i></sub><i><b>h</b></i><sub><i>t</i></sub><sub>-1</sub>+<i><b>b</b></i><sub>o</sub>)      (4)</p>
                </div>
                <div class="p1">
                    <p id="66"><mathml id="168"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mi>t</mi></msub><mo>=</mo><mi mathvariant="bold-italic">f</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⋅</mo><mi mathvariant="bold-italic">C</mi><msub><mrow></mrow><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant="bold-italic">i</mi><msub><mrow></mrow><mi>t</mi></msub><mo>⋅</mo><mover><mstyle mathsize="140%" displaystyle="true"><mi>C</mi></mstyle><mo>∼</mo></mover><msub><mrow></mrow><mi>t</mi></msub></mrow></math></mathml>      (5)</p>
                </div>
                <div class="p1">
                    <p id="67"><i><b>h</b></i><sub><i>t</i></sub>=<i><b>o</b></i><sub><i>t</i></sub>·tanh(<i><b>C</b></i><sub><i>t</i></sub>)      (6)</p>
                </div>
                <div class="p1">
                    <p id="68">式中:<i><b>W</b></i><sub>o</sub><sub><i>x</i></sub>、<i><b>W</b></i><sub>i</sub><sub><i>x</i></sub>、<i><b>W</b></i><sub>f</sub><sub><i>x</i></sub>和<i><b>W</b></i><sub>c</sub><sub><i>x</i></sub>分别表示输出门、输入门、遗忘门、细胞状态对当前时刻输入<i>x</i><sub><i>t</i></sub>的权重;<i><b>W</b></i><sub>o</sub><sub><i>h</i></sub>、<i><b>W</b></i><sub>i</sub><sub><i>h</i></sub>、<i><b>W</b></i><sub>f</sub><sub><i>h</i></sub>和<i><b>W</b></i><sub>c</sub><sub><i>h</i></sub>分别表示输出门、输入门、遗忘门和细胞状态对隐藏层<i><b>h</b></i><sub><i>t</i></sub>的权重;<i><b>b</b></i><sub>*</sub>表示偏置项。</p>
                </div>
                <h4 class="anchor-tag" id="69" name="69"><b>1.2 Snapshot模型集成方法</b></h4>
                <div class="p1">
                    <p id="70">Snapshot模型集成方法是Huang等<citation id="270" type="reference"><link href="240" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>提出的基于深度学习的模型集成方法,该方法利用循环学习率的策略来训练深度学习模型。学习率变化计算式表示为:</p>
                </div>
                <div class="p1">
                    <p id="71"><mathml id="169"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>α</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>α</mi><msub><mrow></mrow><mn>0</mn></msub></mrow><mn>2</mn></mfrac><mrow><mo>(</mo><mrow><mi>cos</mi><mrow><mo>(</mo><mrow><mfrac><mrow><mtext>π</mtext><mspace width="0.25em" /><mtext>m</mtext><mtext>o</mtext><mtext>d</mtext><mo stretchy="false">(</mo><mi>t</mi><mo>-</mo><mn>1</mn><mo>,</mo><mrow><mo>/</mo><mo>/</mo></mrow><mi>Τ</mi><mo>/</mo><mi>Μ</mi><mrow><mo>/</mo><mo>/</mo></mrow><mo stretchy="false">)</mo></mrow><mrow><mrow><mo>/</mo><mo>/</mo></mrow><mi>Τ</mi><mo>/</mo><mi>Μ</mi><mrow><mo>/</mo><mo>/</mo></mrow></mrow></mfrac></mrow><mo>)</mo></mrow><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow></mrow></math></mathml>      (7)</p>
                </div>
                <div class="p1">
                    <p id="72">式中:<i>α</i><sub>0</sub>表示初始学习率。和原文中学习率在每个batch训练结束更新不同,本文实验中学习率会在每个epoch训练结束更新,<i>t</i>表示当前训练的epoch数,<i>T</i>表示训练总epoch数,<i>M</i>表示学习率的更新周期数。</p>
                </div>
                <div class="p1">
                    <p id="73">该模型集成方法的具体过程为:首先,将模型的整个训练过程分为<i>M</i>个循环周期,每个循环周期内模型训练 <i>T</i>/<i>M</i> 个epoch,学习率按照式(7)更新;其次,在每个循环周期结束时,学习率降到最低,模型可以收敛到局部最优的状态,保存此时的模型作为一个子模型;接着,在当前模型的基础上,以一个较大的学习率<i>α</i><sub>0</sub>开始一个新的循环周期,继续训练模型;最后,经过<i>M</i>个循环周期后可以得到<i>M</i>个子模型,直接取这些子模型输出的均值作为最终模型集成的输出。该方法显著减少了集成深度学习模型的时间。</p>
                </div>
                <h4 class="anchor-tag" id="74" name="74"><b>1.3 Stacking模型集成方法</b></h4>
                <div class="p1">
                    <p id="75">Stacking是一种强大的模型集成方法。该方法在原始数据集上训练初级学习器,利用初级学习器对原始样本的预测值构造一个新的数据集,新数据集和原始数据集中样本标签一一对应,最后在新的数据集上训练次级学习器。Stacking算法的具体流程如下<citation id="271" type="reference"><link href="244" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>:</p>
                </div>
                <div class="p1">
                    <p id="76">输入:训练集<i>D</i>={(<i>x</i><sub>1</sub>,<i>y</i><sub>1</sub>),(<i>x</i><sub>2</sub>,<i>y</i><sub>2</sub>),…,(<i>x</i><sub><i>m</i></sub>,<i>y</i><sub><i>m</i></sub>)}</p>
                </div>
                <div class="p1">
                    <p id="77">初级学习器<i>f</i><sub>1</sub>,<i>f</i><sub>2</sub>,…,<i>f</i><sub><i>M</i></sub></p>
                </div>
                <div class="p1">
                    <p id="78">次级学习器<i>f</i></p>
                </div>
                <div class="p1">
                    <p id="79">输出:<i>H</i>(<i>x</i>)=<i>h</i>′(<i>h</i><sub>1</sub>(<i>x</i>),<i>h</i><sub>2</sub>(<i>x</i>),…,<i>h</i><sub><i>M</i></sub>(<i>x</i>))</p>
                </div>
                <div class="p1">
                    <p id="80">1) for <i>t</i>=1 to <i>M</i>:</p>
                </div>
                <div class="p1">
                    <p id="81">2)  <i>h</i><sub><i>t</i></sub>=<i>f</i><sub><i>t</i></sub>(<i>D</i>)</p>
                </div>
                <div class="p1">
                    <p id="82">3) <i>D</i>′=Ø</p>
                </div>
                <div class="p1">
                    <p id="83">4) for <i>i</i>=1 to <i>m</i>:</p>
                </div>
                <div class="p1">
                    <p id="84">5)  for <i>t</i>=1 to <i>M</i>:</p>
                </div>
                <div class="p1">
                    <p id="85">6)  <i>o</i><sub><i>it</i></sub>=<i>h</i><sub><i>t</i></sub>(<i><b>x</b></i><sub><i>i</i></sub>)</p>
                </div>
                <div class="p1">
                    <p id="86">7)  <i>D</i>′=<i>D</i>′∪((<i>o</i><sub><i>i</i></sub><sub>1</sub>,<i>o</i><sub><i>i</i></sub><sub>2</sub>,…,<i>o</i><sub><i>iM</i></sub>),<i>y</i><sub><i>i</i></sub>)</p>
                </div>
                <div class="p1">
                    <p id="87">8)  <i>h</i>′=<i>f</i>(<i>D</i>′)</p>
                </div>
                <div class="p1">
                    <p id="88">为了防止过拟合以及达到充分使用训练集的目的,一般采用k折交叉验证的方法来使用stacking模型集成方法算法,利用初级学习器未使用的样本来生成次级学习器的训练数据。</p>
                </div>
                <h3 id="89" name="89" class="anchor-tag"><b>2 基于LSTM的模型集成方法</b></h3>
                <div class="p1">
                    <p id="90">本文提出基于LSTM的模型集成方法,对应的客户流失预测框架如图2所示,包括数据源、样本特征处理、建模以及预测四个部分。首先,日志系统所收集的客户历史数据将存储于Hadoop分布式文件系统HDFS中;其次利用Spark进行特征的构造和样本的生成;接着利用生成的样本训练相应合适的模型;最后模型输出客户未来流失的概率。企业客户关系管理相关人员可以根据模型最终输出的客户流失概率对高流失倾向的客户的实施相应的维挽操作。</p>
                </div>
                <div class="area_img" id="91">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911008_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 客户流失预测框架" src="Detail/GetImg?filename=images/JYRJ201911008_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 客户流失预测框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911008_091.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="92" name="92"><b>2.1 基本思想</b></h4>
                <div class="p1">
                    <p id="93">在客户流失预测任务中,时序数据可以反映客户的潜在行为趋势,如何利用好时序数据显得尤为关键。相比于传统机器学习模型,LSTM由于其具有天然的序列建模优势,可以自动学习序列隐含信息以及复杂高阶特征,减少了对特征工程的依赖。同时对LSTM进行模型集成可以有效增加模型的准确性和鲁棒性,从而提高预测效果。此外,在客户流失预测的样本中,往往存在容易分类的样本以及难分类的样本,例如一个历史行为规律的客户,比较容易判断其流失与否,而一个历史行为非常不规律的客户,往往很难判断其流失情况。本文提出的swLSTM方法对snapshot方法训练过程进行了改进,在每个循环周期结束之后,根据当前模型对训练样本的预测值计算出训练样本的权重,下一个循环周期模型的训练便在带有当前计算出的样本权重的训练集上进行。在集成多个子模型的输出阶段,将各个子模型在验证集上的输出和对应的样本标签重组为一个新的训练集并在该训练集上训练逻辑回归模型作为最终输出,这相比直接平均子模型的输出作为最终输出来说可以进一步提高分类效果。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"><b>2.2 样本权重计算</b></h4>
                <div class="p1">
                    <p id="95">假设训练集为<i>D</i>={(<i>x</i><sub>1</sub>,<i>y</i><sub>1</sub>),(<i>x</i><sub>2</sub>,<i>y</i><sub>2</sub>),…,(<i>x</i><sub><i>m</i></sub>,<i>y</i><sub><i>m</i></sub>)},本文提出的模型集成方法中针对样本<i>x</i><sub><i>i</i></sub>的权重计算式表示为:</p>
                </div>
                <div class="area_img" id="96">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201911008_09600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="area_img" id="98">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201911008_09800.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="100">式中:<i>p</i><sub><i>i</i></sub>表示模型对样本<i>x</i><sub><i>i</i></sub>预测的准确情况,0≤<i>p</i><sub><i>i</i></sub>≤1。由式(8)可知,当样本<i>x</i><sub><i>i</i></sub>标签为1时,模型输出的预测概率值<mathml id="170"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>越接近1,即<mathml id="171"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>越大,<mathml id="172"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>1</mn><mo>-</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>越小,说明模型对样本<i>x</i><sub><i>i</i></sub>预测得越好;当样本<i>x</i><sub><i>i</i></sub>标签为0时,模型输出的预测概率值<mathml id="173"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>越接近0,即<mathml id="174"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>越小,说明模型对样本<i>x</i><sub><i>i</i></sub>预测得越好。综上所述,<i>p</i><sub><i>i</i></sub>越小说明模型对样本<i>x</i><sub><i>i</i></sub>预测得越好。令<i>P</i>={<i>p</i><sub>0</sub>,<i>p</i><sub>1</sub>,…,<i>p</i><sub><i>m</i></sub>},在式(9)中,<i>c</i>是超参数。以<i>c</i>=30为例,<i>q</i>(30)表示集合<i>P</i>中有30%的元素取值都小于<i>q</i>(30)的值,认为模型对这30%的样本预测得足够好,对另外70%的样本预测得不够好。式(9)有<i>β</i>=<i>q</i>(<i>c</i>),<i>p</i><sub><i>i</i></sub>&gt;<i>β</i>的样本是当前模型测得不够好的样本,需要加大这部分样本的权重,使得下一个训练循环周期模型关注这些样本,设置权重为<i>e</i><sup><i>p</i></sup><sub><sup><i>i</i></sup></sub>;对于<i>p</i><sub><i>i</i></sub>≤<i>β</i>的样本是当前模型已经预测足够好的样本,保持这部分样本的权重为1。</p>
                </div>
                <div class="p1">
                    <p id="101">在snapshot模型集成方法中为训练样本设置权重有两个好处:一是在不同的循环周期中,可以让模型对不同样本的关注度不同,使得一些难分类的样本有机会被分得更准确,提高了单个子模型的分类效果;二是增加了各个子模型之间的差异性,有利于最终结果的集成输出。</p>
                </div>
                <h4 class="anchor-tag" id="102" name="102"><b>2.3 LSTM模型</b></h4>
                <div class="p1">
                    <p id="103">本文实验中使用的LSTM模型具体结构如图3所示。首先将不同时间跨度的时序特征输入到不同的LSTM分支中,本文使用的特征中包含两个不同时间跨度的时序特征集,所以模型包含两个LSTM分支;然后将各分支第一层LSTM层所有时间步上的隐藏状态输出到第二层LSTM中;接着第二层LSTM层仅将最后一个时间步的隐藏状态作为该分支的输出,不同分支的输出会拼接后输入到全连接层进行特征组合;最后将全连接层的输出输入到sigmoid层进行最终分类输出。</p>
                </div>
                <div class="area_img" id="104">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911008_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 LSTM模型结构图" src="Detail/GetImg?filename=images/JYRJ201911008_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 LSTM模型结构图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911008_104.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="105" name="105"><b>2.4 算法流程</b></h4>
                <div class="p1">
                    <p id="106">假设训练集<i>D</i>={(<i>x</i><sub>1</sub>,<i>y</i><sub>1</sub>),(<i>x</i><sub>2</sub>,<i>y</i><sub>2</sub>),…,(<i>x</i><sub><i>m</i></sub>,<i>y</i><sub><i>m</i></sub>)},验证集<i>D</i><sub><i>v</i></sub>={(<i>x</i><sub>1</sub>,<i>y</i><sub>1</sub>),(<i>x</i><sub>2</sub>,<i>y</i><sub>2</sub>),…,(<i>x</i><sub><i>n</i></sub>,<i>y</i><sub><i>n</i></sub>)},LSTM模型初始为<i>f</i><sub>0</sub>,模型训练总的epoch数为<i>T</i>,循环周期数为<i>M</i>,初始学习为<i>α</i><sub>0</sub>,训练集样本初始权重为<i>W</i><sub>0</sub>=1,逻辑回归模型为<i>h</i>。训练swLSTM的详细步骤如下:</p>
                </div>
                <div class="p1">
                    <p id="107">1)  fo<i>r k</i>=1 to <i>M</i>;</p>
                </div>
                <div class="p1">
                    <p id="108">2)  设置<i>D</i>的样本权重为<i>W</i><sub><i>k</i></sub><sub>-1</sub>,按照式(7)对应的循环学习率策略,在<i>f</i><sub><i>k</i></sub><sub>-1</sub>的基础上使用带权重的训练集<i>D</i>继续训练 <i>T</i>/<i>M</i> 个epoch后得到<i>f</i><sub><i>k</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="109">3)  for <i>i</i>=1 to <i>m</i>;</p>
                </div>
                <div class="p1">
                    <p id="110"><mathml id="175"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mn>4</mn><mo stretchy="false">)</mo><mspace width="0.25em" /><mspace width="0.25em" /><mtext> </mtext><mtext> </mtext><mover accent="true"><mi>y</mi><mo>^</mo></mover><msub><mrow></mrow><mi>i</mi></msub><mo>=</mo><mi>f</mi><msub><mrow></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo stretchy="false">)</mo><mo>,</mo><mi>x</mi><msub><mrow></mrow><mi>i</mi></msub><mo>∈</mo><mi>D</mi></mrow></math></mathml>,根据式(8)-式(9),得到样本<i>x</i><sub><i>i</i></sub>的权重<i>w</i><sub><i>i</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="111">5)  将<i>w</i><sub>0</sub>,<i>w</i><sub>1</sub>,…,<i>w</i><sub><i>m</i></sub>组织成<i>W</i><sub><i>k</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="112">6) 设置逻辑回归所用训练集<i>D</i>′=Ø。</p>
                </div>
                <div class="p1">
                    <p id="113">7) for <i>i</i>=1 to <i>n</i>;</p>
                </div>
                <div class="p1">
                    <p id="114">8)  for <i>k</i>=1 to <i>M</i>;</p>
                </div>
                <div class="p1">
                    <p id="115">9)  <i>o</i><sub><i>ik</i></sub>=<i>f</i><sub><i>k</i></sub>(<i><b>x</b></i><sub><i>i</i></sub>),<i><b>x</b></i><sub><i>i</i></sub>∈<i>D</i><sub><i>v</i></sub></p>
                </div>
                <div class="p1">
                    <p id="116">10)  <i>D</i>′=<i>D</i>′∪((<i>o</i><sub><i>i</i></sub><sub>1</sub>,<i>o</i><sub><i>i</i></sub><sub>2</sub>,…,<i>o</i><sub><i>iM</i></sub>),<i>y</i><sub><i>i</i></sub>),<i>y</i><sub><i>i</i></sub>∈<i>D</i><sub><i>v</i></sub></p>
                </div>
                <div class="p1">
                    <p id="117">11) 在<i>D</i>′上训练逻辑回归模型<i>h</i>。</p>
                </div>
                <div class="p1">
                    <p id="118">12) 模型训练完毕,得到逻辑回归模型<i>h</i>以及<i>M</i>个LSTM子模型<i>f</i><sub>1</sub>,<i>f</i><sub>2</sub>…,<i>f</i><sub><i>M</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="119">在测试阶段,利用上述训练完毕的<i>M</i>个模型<i>f</i><sub>1</sub>,<i>f</i><sub>2</sub>…,<i>f</i><sub><i>M</i></sub>对测试集进行预测,并生成新的测试集,具体步骤与上述训练步骤的第6步到第10步类似。然后用训练完毕的逻辑回归模型<i>h</i>对新的测试集进行预测得到最终预测结果。</p>
                </div>
                <h3 id="120" name="120" class="anchor-tag"><b>3 实 验</b></h3>
                <h4 class="anchor-tag" id="121" name="121"><b>3.1 实验环境</b></h4>
                <div class="p1">
                    <p id="122">本文实验在Linux服务器上进行,具体硬件配置如下:内存为32 GB;CPU型号为Intel(R) Core(TM) i7- 4790 CPU @ 3.60 GHz,数量为1,核心数为8;GPU型号为GeForce GTX TITAN X,数量为1。实验中使用的主要工具包括:Python 3.5、Pytorch、XGBoost、Scikit-learn。</p>
                </div>
                <h4 class="anchor-tag" id="123" name="123"><b>3.2 数据介绍</b></h4>
                <div class="p1">
                    <p id="124">本文实验数据采用的是WSDM CUP 2018的数据,旨在预测某音乐流媒体服务商的付费订阅客户流失率。官方对于其付费订阅客户流失的定义为:当客户的付费订阅到期后的30天内,客户仍然没有续订,则判定该客户为流失客户,否则为非流失客户。</p>
                </div>
                <div class="p1">
                    <p id="125">实验数据主要包括客户的交易日志数据以及听歌日志数据,表1展示了原始数据的部分字段名。</p>
                </div>
                <div class="area_img" id="126">
                    <p class="img_tit"><b>表1 原始数据字段示例</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="126" border="1"><tr><td>数据名</td><td>字段名</td><td>数据名</td><td>字段名</td></tr><tr><td rowspan="4">交易日志</td><td><br />交易发生日期</td><td rowspan="4">听歌日志</td><td><br />日志发生日期</td></tr><tr><td><br />当前交易金额</td><td><br />当天听歌时长</td></tr><tr><td><br />当前订阅天数</td><td><br />当天听歌数量</td></tr><tr><td><br />︙</td><td><br />︙</td></tr><tr><td colspan="4"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="127" name="127"><b>3.3 特征工程</b></h4>
                <div class="p1">
                    <p id="128">在特征构造方面,原始数据中每条记录均带有时间信息,所以本文实验中使用的特征均为原始数据经过简单处理的结果,没有进行额外的特征工程。具体地,从客户交易日志中截取最近一年的数据,并且对不同客户的交易日志数据详情按照时间先后进行排序,得到交易时序特征,例如客户过去一年交易每次交易的金额、每次交易的付费订阅天数等,总计7种特征,序列长度为20;从客户听歌日志中截取最近一个月的数据,并且对不同客户的听歌日志详情按照时间先后进行排序,得到听歌日志时序特征,例如客户最近一个月每天听歌的时长、每天听歌的歌曲数量等,总计7种特征,序列长度为30。</p>
                </div>
                <div class="p1">
                    <p id="129">在数据处理方面,对于特征中的缺失值用0填充,对于离散值类型的特征采用独热编码,对于连续值类型的特征进行标准化处理,这些处理方法有利于神经网络的训练。</p>
                </div>
                <h4 class="anchor-tag" id="130" name="130"><b>3.4 训练样本</b></h4>
                <div class="p1">
                    <p id="131">本文实验中,按照客户的订阅到期日进行训练样本生成,一个样本对应一个客户。具体地,2017年1月的样本生成过程如下:从2017年1月之前的客户交易数据中筛选出订阅到期日在2017年1月的所有客户,设为集合<i>U</i>。针对某客户<i>u</i><sub><i>i</i></sub>∈<i>U</i>,其当前订阅到期日为<i>t</i><sub><i>i</i></sub><sub>0</sub>,从2017年1月之后的交易数据中确定<i>u</i><sub><i>i</i></sub>的最早一次订阅交易日<i>t</i><sub><i>i</i></sub><sub>1</sub>,假设<i>t</i><sub><i>i</i></sub><sub>1</sub>和<i>t</i><sub><i>i</i></sub><sub>0</sub>之间的日期间隔天数为<i>gap</i>,<i>u</i><sub><i>i</i></sub>对应的标签为<i>y</i><sub><i>i</i></sub>,则如果<i>gap</i>&gt;30,那么<i>y</i><sub><i>i</i></sub>=1,否则<i>y</i><sub><i>i</i></sub>=0。然后从<i>u</i><sub><i>i</i></sub>的交易日志以及听歌日志数据中进行特征处理工作得到特征<i>x</i><sub><i>i</i></sub>,最终<i>u</i><sub><i>i</i></sub>对应的样本为(<i>x</i><sub><i>i</i></sub>,<i>y</i><sub><i>i</i></sub>)。本文实验所使用的训练集为2017年1月的样本,测试集为2017年2月的样本。训练集一共有670 897条样本,测试集合一共有447 266条样本。</p>
                </div>
                <h4 class="anchor-tag" id="132" name="132"><b>3.5 评价指标</b></h4>
                <div class="p1">
                    <p id="133">本文选择查准率(Precision)、查全率(Recall)、AUC以及PR-AUC作为实验指标,其中查准率和PR-AUC更为重要。PR-AUC在数据不平衡的情况下相比AUC更适合评价模型效果<citation id="272" type="reference"><link href="246" rel="bibliography" /><sup>[<a class="sup">23</a>]</sup></citation>,本文实验数据中正样本占5.5%左右。</p>
                </div>
                <div class="p1">
                    <p id="134">查全率和查准率的定义如下:</p>
                </div>
                <div class="p1">
                    <p id="135"><i>R</i><sub>ecall</sub>=<i>TP</i>/(<i>TP</i>+<i>FN</i>)      (10)</p>
                </div>
                <div class="p1">
                    <p id="136"><i>P</i><sub>recision</sub>=<i>TP</i>/(<i>TP</i>+<i>FP</i>)      (11)</p>
                </div>
                <div class="p1">
                    <p id="137">式中:<i>TP</i>、<i>FN</i>和<i>FP</i>分别表示真正例、假反例、假正例。本文实验计算Top <i>N</i>的查准率和查全率,详细步骤为:将模型对样本输出的预测概率值进行降序排序,将前<i>N</i>个样本标识为正例,其余标识为负例,并根据标识结果计算查全率和查准率。这前<i>N</i>个样本可以理解为模型预测出来的高流失倾向客户,企业可以对这部分客户实施针对性的挽留策略,在本文实验中<i>N</i>值设置为10 000。</p>
                </div>
                <div class="p1">
                    <p id="138">AUC是ROC下的面积,值越大意味着模型效果越好。除了可以通过计算面积得到AUC值外,还可以通过如下公式计算:</p>
                </div>
                <div class="p1">
                    <p id="139"><mathml id="176"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>A</mi><mi>U</mi><mi>C</mi><mo>=</mo><mfrac><mrow><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>u</mi><mo>∈</mo><mi>Ρ</mi></mrow></munder><mi>r</mi></mstyle><mi>a</mi><mi>n</mi><mi>k</mi><msub><mrow></mrow><mi>u</mi></msub><mo>-</mo><mfrac><mrow><mi>Κ</mi><mo>×</mo><mo stretchy="false">(</mo><mi>Κ</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mn>2</mn></mfrac></mrow><mrow><mi>Κ</mi><mo>×</mo><mi>Ν</mi></mrow></mfrac></mrow></math></mathml>      (12)</p>
                </div>
                <div class="p1">
                    <p id="140">式中:<i>P</i>表示所有正样本集合;<i>K</i>、<i>N</i>分别表示正样本、负样本的数量;<i>rank</i><sub><i>u</i></sub>表示样本<i>u</i>在模型对所有样本的预测概率值中的排名。具体地,假设样本总量为<i>n</i>,则模型预测概率值最大的样本所对应<i>rank</i>值为<i>n</i>,模型预测概率值第二大的样本所对应的<i>rank</i>值为<i>n</i>-1,依此类推。</p>
                </div>
                <div class="p1">
                    <p id="141">PR-AUC是PR曲线下的面积,PR曲线的横坐标为查全率,纵坐标为查准率。</p>
                </div>
                <h4 class="anchor-tag" id="142" name="142"><b>3.6 实验参数</b></h4>
                <div class="p1">
                    <p id="143">本文提出的swLSTM主要参数如下:所有LSTM层隐藏层单元数均为32;两层全连接层单元数分别为128、32,激活函数为relu;模型训练的循环周期数<i>M</i>为5,总epoch数<i>T</i>为100;batch size为512;初始学习率<i>α</i><sub>0</sub>为0.003;逻辑回归模型训练的epoch数为6,batch size为64,学习率为0.001;式(9)中的超参数<i>c</i>为50;优化器为Adam。</p>
                </div>
                <h4 class="anchor-tag" id="144" name="144"><b>3.7 实验结果</b></h4>
                <div class="p1">
                    <p id="145">为了验证本文提出的swLSTM的有效性并进行超参数选择,总共进行了三组实验:实验一为现有方法与本文提出的方法对比实验;实验二为超参数<i>c</i>的选择实验;实验三为初始学习率的选择实验。</p>
                </div>
                <h4 class="anchor-tag" id="146" name="146"><b>3.7.1 比较实验</b></h4>
                <div class="p1">
                    <p id="147">为了充分对比本文提出的swLSTM与单模型LSTM以及其他模型集成方法,本文采用了如下几个基准对比模型。</p>
                </div>
                <div class="p1">
                    <p id="148">随机森林:该模型在工业界使用较多,是客户流失预测的常用模型,由多棵决策树通过bagging方法集成。实验中设置每棵决策树深度为10,数量为200。</p>
                </div>
                <div class="p1">
                    <p id="149">XGBoost:该模型的基学习器为分类回归树,其对梯度提升算法进行改进,使得模型精度和训练效率得到了明显改善,且支持大规模机器学习。实验中设置每棵决策树深度为6,模型迭代200次,学习率为0.05。</p>
                </div>
                <div class="p1">
                    <p id="150">LSTM:该模型是本文提出的模型集成方法中的基学习器。实验中设置每层LSTM隐藏层单元数均为32,两层全连接单元数分别为128和32,激活函数为relu。</p>
                </div>
                <div class="p1">
                    <p id="151">avgLSTM:通过设置不同的随机种子训练3个结构如图3所示的LSTM模型,同时直接将这3个模型输出取平均作为集成输出。</p>
                </div>
                <div class="p1">
                    <p id="152">StCNN:该模型由文献<citation id="273" type="reference">[<a class="sup">5</a>]</citation>提出,原文中初级学习器使用随机森林、XGBoost、KNN、DNN和CNN。由于KNN、DNN在本文实验中效果较差,所以将其替换成LSTM。次级学习器使用CNN。实验中除CNN外,其他模型的参数设置和上述几个对比模型参数设置一样。CNN包含两层一维卷积层,卷积核大小均为2,步长均为1,数量均为32。每一层卷积层之后会接上最大池化层,池化层核心大小均为2,步长均为2。最后包含两层全连接层,其单元数依次为32和16。</p>
                </div>
                <div class="p1">
                    <p id="153">snapLSTM:该模型直接将snapshot模型集成方法应用于LSTM。</p>
                </div>
                <div class="p1">
                    <p id="154">上述模型对训练集的使用方式不完全相同,为了公平对比,设置各个模型使用训练集的方式如下:随机森林、XGBoost、LSTM和StCNN对训练集进行4折交叉验证训练;snapLSTM直接使用全部训练集进行训练;本文提出的模型集成方法在子模型训练阶段,将训练集随机划出10%的数据作为子模型的验证集,剩余90%的数据作为子模型的训练集;在逻辑回归模型训练阶段,将上述子模型的验证集随机划出10%的数据作为逻辑回归模型的验证集,剩余90%的数据作为逻辑回归模型的训练集。</p>
                </div>
                <div class="p1">
                    <p id="155">模型效果对比结果如表2所示。可以看出,本文提出的swLSTM各项指标均好于其他模型,相比于单模型LSTM,Precision、Recall、AUC和PR-AUC分别提升了4.67%、4.61%、0.55%和3.74%,这说明本文提出的基于LSTM的模型集成方法可以显著提升模型效果。LSTM的效果总体好于XGBoost和随机森林,主要原因是:这两个模型虽然属于集成学习模型,但是其基学习器是决策树,无法有效处理时序数据,特征工程的质量对模型效果影响较大,而本文训练样本中均为时序特征,LSTM可以自动学习其中的隐含序列信息。avgLSTM各项指标和LSTM基本持平,说明通过简单设置不同随机种子获得多个子模型进行平均输出不能明显改善预测结果。StCNN的AUC低于LSTM,其他指标有一定的提升,主要原因是:StCNN集成了多个差异性大的模型,可以总体带来模型效果的提升,但由于部分子模型的效果较差,导致最终集成带来部分指标下降的情况。snapLSTM相比于LSTM各项指标均有提升,同时本文提出的swLSTM各项指标均高于snapLSTM。本文比较了这两种模型集成方法生成的各个子模型之间的差异性,具体做法是:利用两种方法生成的子模型去预测相同的数据集,然后用预测值计算同一方法下不同子模型两两之间的最大信息系数(Maximal Information Coefficient,MIC)<citation id="274" type="reference"><link href="248" rel="bibliography" /><sup>[<a class="sup">24</a>]</sup></citation>,MIC值越大代表越相关。两个模型计算出的MIC的值便可以表示这两个模型之间的相关性。最终根据snapLSTM生成的子模型计算出的MIC平均值为0.934,而根据swLSTM生成的子模型计算出的MIC平均值为0.912,说明swLSTM最终生成子模型之间的差异性要高于snapLSTM生成的子模型,而差异性高的子模型一般会带来较好的集成效果。</p>
                </div>
                <div class="area_img" id="156">
                    <p class="img_tit"><b>表2 模型效果对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="156" border="1"><tr><td><br />模型</td><td>Precision</td><td>Recall</td><td>AUC</td><td>PR-AUC</td></tr><tr><td><br />Random Forest</td><td>0.530 2</td><td>0.217 1</td><td>0.838 9</td><td>0.380 5</td></tr><tr><td><br />XGBoost</td><td>0.551 5</td><td>0.223 6</td><td>0.851 4</td><td>0.391 8</td></tr><tr><td><br />LSTM</td><td>0.557 1</td><td>0.225 8</td><td>0.865 2</td><td>0.403 8</td></tr><tr><td><br />avgLSTM</td><td>0.558 9</td><td>0.226 3</td><td>0.864 9</td><td>0.405 1</td></tr><tr><td><br />StCNN</td><td>0.565 9</td><td>0.227 4</td><td>0.863 4</td><td>0.406 6</td></tr><tr><td><br />snapLSTM</td><td>0.569 7</td><td>0.229 8</td><td>0.866 9</td><td>0.409 2</td></tr><tr><td><br />swLSTM</td><td><b>0.583 1</b></td><td><b>0.236 2</b></td><td><b>0.870 0</b></td><td><b>0.418 9</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="157">表3展示了各个模型的训练时间。XGBoost和随机森林的训练时间较短,主要原因是:这两个模型属于传统机器学习模型,模型参数较少,所需的计算量也较少,同时可以利用全部CPU核心并行计算,不需要花费太多的时间训练。LSTM训练时间是上述两个模型的4～7倍左右,主要原因是:该模型包含多层LSTM层,需要进行大量计算更新模型参数,尽管使用了GPU进行训练,但依旧会耗费大量训练时间,这也是训练深度学习模型的一个特点。avgLSTM需要依次训练三个同样的模型,所以花费时间是LSTM的3倍左右。snapLSTM训练时间是LSTM的1.6倍左右,主要原因是:在相同的batch size前提下,snapLSTM总计训练100个epoch,而LSTM是根据验证集的损失进行早停策略的训练,最终平均只训练了60个epoch。swLSTM训练时间比snapLSTM稍长,主要原因是:在每个训练循环周期结束时,模型需要预测全部训练样本并计算样本权重,此外逻辑回归模型的训练也需要耗费部分时间。StCNN训练时间最长,并且远多于其他模型,主要原因是:训练StCNN必须通过4折交叉验证进行,同时需要训练的模型有4个,总计需要训练16个模型的时间,每个模型均根据验证集的损失进行早停策略的训练。</p>
                </div>
                <div class="area_img" id="158">
                    <p class="img_tit"><b>表3 训练时间对比结果</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="158" border="1"><tr><td><br />模型</td><td>训练时间/min</td></tr><tr><td><br />Random Forest</td><td>3.3</td></tr><tr><td><br />XGBoost</td><td>2.1</td></tr><tr><td><br />LSTM</td><td>15.2</td></tr><tr><td><br />avgLSTM</td><td>41.8</td></tr><tr><td><br />StCNN</td><td>118.5</td></tr><tr><td><br />snapLSTM</td><td>25.6</td></tr><tr><td><br />swLSTM</td><td>27.5</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <h4 class="anchor-tag" id="159" name="159"><b>3.7.2 参数</b><i><b>c</b></i><b>选择实验</b></h4>
                <div class="p1">
                    <p id="160">在本节实验中选择Precision和PR-AUC两个指标来分析式(9)计算样本权重步骤中不同的参数<i>c</i>对最终预测结果的影响。一方面是因为这两个指标更为重要,另一方面是因为相比其他两个指标,这两个指标的值变化幅度更大。图4为不同参数<i>c</i>的对比结果,可以看出,当<i>c</i>=50时,模型取得最好效果,所以本文最终设置<i>c</i>为50。同时还可以发现,当<i>c</i>&lt;50时,指标总体呈上升趋势,而当<i>c</i>&gt;50时,指标总体呈下降趋势。</p>
                </div>
                <div class="area_img" id="161">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911008_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 不同参数c对比结果" src="Detail/GetImg?filename=images/JYRJ201911008_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 不同参数<i>c</i>对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911008_161.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="162" name="162"><b>3.7.3 初始学习率选择实验</b></h4>
                <div class="p1">
                    <p id="163">从图5中可以看出,在初始学习率从0.01降低到0.003过程中,模型指标呈上升趋势,且在0.003处模型指标达到最优。当初始学习率从0.003降低到0.001时,模型指标下降明显。可能原因是:实验中优化算法选择的是Adam,其推荐的学习率为0.001,同时学习率变化周期为20个epoch,当初始学习率过高或者过低时,均会使得模型无法在有限的epoch内收敛到一个局部最优的状态;同时在学习率较低时,模型很难在新的训练周期开始时跳出当前的训练状态,使得得到的子模型之间差异性减小,影响最终模型集成效果。最终本文设置初始学习率为0.003。</p>
                </div>
                <div class="area_img" id="164">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201911008_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同初始学习率对比结果" src="Detail/GetImg?filename=images/JYRJ201911008_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同初始学习率对比结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201911008_164.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="165" name="165" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="166">本文提出了一种基于LSTM的模型集成方法用于客户流失预测任务。该方法采用LSTM作为基学习器,避免了复杂的特征工程,充分利用了时序特征。通过改进snapshot集成方法,提高了子模型的分类效果,增加了不同子模型之间的差异性,提升了模型集成效果。实验结果表明,该方法可以在仅花费训练单个LSTM模型1.8倍时间的基础上,比Precision和PR-AUC分别提升4.67%和3.74%,具有较好的实用性。不过该方法仍存在不足,其对于样本权重的修改需要通过超参数控制,下一步将研究如何让样本权重的修改可以在模型训练中变得可学习。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="202">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011400022193&amp;v=MTM5MzMxc1NieHM9TmlmT2ZiSzdIdEROcTQ5RlpPa05EWFU2b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Athanassopoulos A D.Customer satisfaction cues to support market segmentation and explain switching behavior [J].Journal of Business Research,2000,47(3):191-207.
                            </a>
                        </p>
                        <p id="204">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ensemble based efficient churn prediction model for telecom">

                                <b>[2]</b> Idris A,Khan A.Ensemble based efficient churn prediction model for telecom [C]//2014 12th International Conference on Frontiers of Information Technology.Piscataway,NJ:IEEE,2014:238-244.
                            </a>
                        </p>
                        <p id="206">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=HQDB201605022&amp;v=MDk1MTE0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9nVmJyQkxUelBiTEc0SDlmTXFvOUhab1FLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 余路.电信客户流失的组合预测模型[J].华侨大学学报(自然科学版),2016,37(5):637-640.
                            </a>
                        </p>
                        <p id="208">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Prediction of Churn Behavior of Bank Customer Customers Using Data Mining Tools">

                                <b>[4]</b> Prasad U D,Madhavi S.Prediction of churn behavior of bank customers using data mining tools[J].Business Intelligence Journal,2012,5(1):96-101.
                            </a>
                        </p>
                        <p id="210">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Deep ensemble classifiers and peer effects analysis for churn forecasting in retail banking">

                                <b>[5]</b> Chen Y,Gel Y R,Lyubchich V,et al.Deep ensemble classifiers and peer effects analysis for churn forecasting in retail banking[C]//Pacific-Asia Conference on Knowledge Discovery and Data Mining.Berlin:Springer,2018:373-385.
                            </a>
                        </p>
                        <p id="212">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201603025&amp;v=MDIyMTlCTHpUWlpMRzRIOWZNckk5SFlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSTE9lWmVWdUZ5L2dWYnI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 丁军,高大启,薛程元,等.基于社交网络的MMORPG玩家流失分析与预测[J].计算机应用与软件,2016,33(3):109-113.
                            </a>
                        </p>
                        <p id="214">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MESS201604029&amp;v=Mjg2MDVMT2VaZVZ1RnkvZ1ZickJLQ2pZZmJHNEg5Zk1xNDlIYllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 吴悦昕,赵鑫,过岩巍,等.在线游戏用户的流失预测:基于不平衡数据的采样方法比较和分析[J].中文信息学报,2016,30(4):213-222.
                            </a>
                        </p>
                        <p id="216">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Churn analysis in a music streaming service:Predicting and understanding retention">

                                <b>[8]</b> Dinis G.Churn analysis in a music streaming service:Predicting and understanding retention[D].Stockholm:KTH Royal Institute of Technology,2017.
                            </a>
                        </p>
                        <p id="218">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011501638646&amp;v=MjU0OTd4cz1OaWZPZmJLN0h0RE5xbzlFWXVnSENuZy9vQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp1SHlqbVViL0lKMXNTYg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Nie G,Rowe W,Zhang L,et al.Credit card churn forecasting by logistic regression and decision tree[J].Expert Systems with Applications,2011,38(12):15273-15285.
                            </a>
                        </p>
                        <p id="220">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ200909070&amp;v=MTMwNTE0TzN6cXFCdEdGckNVUkxPZVplVnVGeS9nVmJyQkx6VFpaTEc0SHRqTXBvOUNaSVFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 杜修平,王中.基于决策树的证券客户流失模型 [J].计算机应用与软件,2009,26(9):230-233.
                            </a>
                        </p>
                        <p id="222">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=CSJR201409011&amp;v=MDQ0NTVFWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvZ1ZickJKajdCZkxHNEg5WE1wbzk=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 贺本岚.支持向量机模型在银行客户流失预测中的应用研究[J].金融论坛,2014(9):70-74.
                            </a>
                        </p>
                        <p id="224">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using deep learning to predict customer churn in a mobile telecommunication network">

                                <b>[12]</b> Castanedo F,Valverde G,Zaratiegui J,et al.Using deep learning to predict customer churn in a mobile telecommunication network [EB/OL].[2019-01-15].http://www.wiseathena.com/pdf/wa_dl.pdf.
                            </a>
                        </p>
                        <p id="226">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Churn analysis using deepconvolutional neural networks and autoencoders">

                                <b>[13]</b> Wangperawong A,Brun C,Laudy O,et al.Churn analysis using deep convolutional neural networks and autoencoders [EB/OL].(2016-04-18)[2018-12-29].https://arxiv.org/pdf/1604.05377.pdf.
                            </a>
                        </p>
                        <p id="228">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Ensemble methods in Machine Learning">

                                <b>[14]</b> Dietterich T G.Ensemble methods in machine learning[C]//International workshop on multiple classifier systems.Berlin:Springer,2000:1-15.
                            </a>
                        </p>
                        <p id="230">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339482&amp;v=MjY2NTBkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZTamxWTHJPSlZjPU5qN0Jhck80SHRITnJJeE1ZT01OWTNrNXpC&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Breiman L.Bagging predictors[J].Machine learning,1996,24(2):123-140.
                            </a>
                        </p>
                        <p id="232">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Experiments with a new boosting algorithm">

                                <b>[16]</b> Yoav F,Robert E S.Experiments with a new boosting algorithm [C]//Proceedings of the Thirteenth International Conference on International Conference on Machine Learning.New York,NY:ACM,1996,148-156.
                            </a>
                        </p>
                        <p id="234">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD00001339457&amp;v=MTgxODFyTzRIdEhOckl4TVlPNElZM2s1ekJkaDRqOTlTWHFScnhveGNNSDdSN3FlYnVkdEZTamxWTHJPSlZjPU5qN0Jh&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Breiman L.Stacked regressions [J].Machine learning,1996,24(1):49-64.
                            </a>
                        </p>
                        <p id="236">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Customer churn prediction in an internet service provider">

                                <b>[18]</b> Do D,Huynh P,Vo P,et al.Customer churn prediction in an internet service provider [C]//2017 IEEE International Conference on Big Data (Big Data).Piscataway,NJ:IEEE,2017:3928-3933.
                            </a>
                        </p>
                        <p id="238">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A comparative study of customer churn prediction in telecom industry using ensemble based classifiers">

                                <b>[19]</b> Mishra A,Reddy U S.A comparative study of customer churn prediction in telecom industry using ensemble based classifiers [C]//2017 International Conference on Inventive Computing and Informatics(ICICI).Piscataway,NJ:IEEE,2017:721-725.
                            </a>
                        </p>
                        <p id="240">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Snapshot ensembles:Train 1,get M for free">

                                <b>[20]</b> Huang G,Li Y,Pleiss G,et al.Snapshot ensembles:Train 1,get M for free [EB/OL].(2017-04-01)[2018-12-29].https://arxiv.org/pdf/1704.00109.pdf.
                            </a>
                        </p>
                        <p id="242">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJBK&amp;filename=SJBK15090500014198&amp;v=MDU3MzhNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadUh5am1VYi9JSjFzU2J4cz1OaWZKWmJLOUh0ak1xbzlGWk9vTERYVXhvQg==&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> Hochreiter S,Schmidhuber J.Long short-term memory [J].Neural computation,1997,9(8):1735-1780.
                            </a>
                        </p>
                        <p id="244">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787302423287000&amp;v=MjU2NTlOSmxzZFhGcXpHYkM0SE5YT3JJMU5ZK3NQREJNOHp4VVNtRGQ5U0g3bjN4RTlmYnZuS3JpZlp1OXVGQ3JsVTdq&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> 周志华.机器学习[M].北京:清华大学出版社,2016:184.
                            </a>
                        </p>
                        <p id="246">
                            <a id="bibliography_23" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Relationship Between Precision-Recall and ROC Curves">

                                <b>[23]</b> Davis J,Goadrich M.The relationship between Precision-Recall and ROC curves[C]//Proceedings of the 23rd international conference on Machine learning.New York,NY:ACM,2006:233-240.
                            </a>
                        </p>
                        <p id="248">
                            <a id="bibliography_24" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Detecting Novel Associations in Large Data Sets">

                                <b>[24]</b> Reshef D N,Reshef Y A,Finucane H K,et al.Detecting Novel Associations in Large Data Sets[J].Science,2011,334 (6062):1518-1524.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201911008" />
        <input id="dpi" type="hidden" value="96" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201911008&amp;v=MTU0ODNaWkxHNEg5ak5ybzlGYklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVJMT2VaZVZ1RnkvZ1Zick9MelQ=&amp;uid=WEEvREcwSlJHSldRa1FhdXNXaEhoRFVsZkNHV25tS3FjcGR3SzhBTGdXQT0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="0" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
