<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135597816565000%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201909040%26RESULT%3d1%26SIGN%3diGDI6cUr1TeXMonm6I83XT83Bec%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909040&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201909040&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909040&amp;v=MjQ5ODdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlqa1ViN0lMelRaWkxHNEg5ak1wbzlCWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#51" data-title="&lt;b&gt;1 基本理论&lt;/b&gt; "><b>1 基本理论</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="&lt;b&gt;1.1 低秩表示LatentLRR&lt;/b&gt;"><b>1.1 低秩表示LatentLRR</b></a></li>
                                                <li><a href="#66" data-title="&lt;b&gt;1.2 非下采样剪切波变换NSST&lt;/b&gt;"><b>1.2 非下采样剪切波变换NSST</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#93" data-title="&lt;b&gt;2 融合规则及融合方法&lt;/b&gt; "><b>2 融合规则及融合方法</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#95" data-title="&lt;b&gt;2.1 特征图融合规则&lt;/b&gt;"><b>2.1 特征图融合规则</b></a></li>
                                                <li><a href="#114" data-title="&lt;b&gt;2.2 NSST低频部分融合规则&lt;/b&gt;"><b>2.2 NSST低频部分融合规则</b></a></li>
                                                <li><a href="#119" data-title="&lt;b&gt;2.3 NSST高频部分融合规则&lt;/b&gt;"><b>2.3 NSST高频部分融合规则</b></a></li>
                                                <li><a href="#141" data-title="&lt;b&gt;2.4 融合方法&lt;/b&gt;"><b>2.4 融合方法</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#144" data-title="&lt;b&gt;3 实验结果及分析&lt;/b&gt; "><b>3 实验结果及分析</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#158" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#65" data-title="图1 LatentLRR分解结果">图1 LatentLRR分解结果</a></li>
                                                <li><a href="#143" data-title="图2 本文算法融合框架">图2 本文算法融合框架</a></li>
                                                <li><a href="#147" data-title="图3 第一组融合结果">图3 第一组融合结果</a></li>
                                                <li><a href="#149" data-title="图4 第二组融合结果">图4 第二组融合结果</a></li>
                                                <li><a href="#151" data-title="图5 第三组融合结果">图5 第三组融合结果</a></li>
                                                <li><a href="#154" data-title="&lt;b&gt;表1 图3各算法的评测指标&lt;/b&gt;"><b>表1 图3各算法的评测指标</b></a></li>
                                                <li><a href="#155" data-title="&lt;b&gt;表2 图4各算法的评测指标&lt;/b&gt;"><b>表2 图4各算法的评测指标</b></a></li>
                                                <li><a href="#156" data-title="&lt;b&gt;表3 图5各算法的评测指标&lt;/b&gt;"><b>表3 图5各算法的评测指标</b></a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" title=" 李洪海,朱霞.采用双树小波变换的医学图像融合方法及实现[J].计算机应用与软件,2012,29(11):292-294,327." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201211077&amp;v=MDA5MDhIOVBOcm85Q1k0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJTHpUWlpMRzQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         李洪海,朱霞.采用双树小波变换的医学图像融合方法及实现[J].计算机应用与软件,2012,29(11):292-294,327.
                                    </a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" 田秀华,兴旺.基于NSCT变换的医学图像融合研究[J].计算机应用与软件,2013,30(4):287-289,329." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201304083&amp;v=MjYyMzVOWjRRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlqa1ViN0lMelRaWkxHNEg5TE1xNDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[2]</b>
                                         田秀华,兴旺.基于NSCT变换的医学图像融合研究[J].计算机应用与软件,2013,30(4):287-289,329.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" 楼建强,李俊峰,戴文战.非下采样剪切波变换的医学图像融合[J].中国图象图形学报,2017,22(11):1574-1583." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201711011&amp;v=MjQ3OTdZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJUHlyZmJMRzRIOWJOcm85RVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[3]</b>
                                         楼建强,李俊峰,戴文战.非下采样剪切波变换的医学图像融合[J].中国图象图形学报,2017,22(11):1574-1583.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" 王健,张修飞,任萍,等.基于增补小波变换和PCNN的NSCT域图像融合算法[J].计算机工程与科学,2018,40(10):1822-1828." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201810015&amp;v=MjA0NDRSN3FmWnVadEZ5amtVYjdJTHo3QlpiRzRIOW5OcjQ5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         王健,张修飞,任萍,等.基于增补小波变换和PCNN的NSCT域图像融合算法[J].计算机工程与科学,2018,40(10):1822-1828.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" 刘雯敏,陈秀宏.基于PCNN和非线性滤波万有引力的医学图像融合[J].计算机工程与应用,2014,50(24):191-198." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201424040&amp;v=MjA4Mjk5WE9xNDlCWklRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlqa1ViN0lMejdNYWJHNEg=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[5]</b>
                                         刘雯敏,陈秀宏.基于PCNN和非线性滤波万有引力的医学图像融合[J].计算机工程与应用,2014,50(24):191-198.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" 吴银芳.基于模糊变换耦合最大熵的医学图像融合算法[J].西南师范大学学报(自然科学版),2018,43(11):49-56." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNZK201811010&amp;v=MjYyNTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJUFNQUlpiRzRIOW5Ocm85RVpJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[6]</b>
                                         吴银芳.基于模糊变换耦合最大熵的医学图像融合算法[J].西南师范大学学报(自然科学版),2018,43(11):49-56.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Ramlal S D,Sachdeva J,Ahuja C K,et al.Multimodal Medical Image Fusion using Non-subsampled Shearlet Transform and Pulse Coupled Neural Network Incorporated with Morphological Gradient[J].Signal,Image and Video Processing,2018,12(8):1479-1487." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multimodal Medical Image Fusion using Non-subsampled Shearlet Transform and Pulse Coupled Neural Network Incorporated with Morphological Gradient">
                                        <b>[7]</b>
                                         Ramlal S D,Sachdeva J,Ahuja C K,et al.Multimodal Medical Image Fusion using Non-subsampled Shearlet Transform and Pulse Coupled Neural Network Incorporated with Morphological Gradient[J].Signal,Image and Video Processing,2018,12(8):1479-1487.
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" Hermessi H,Mourali O,Zagrouba E.Convolutional Neural Network Based Multimodal Image Fusion Via Similarity Learning in The Shearlet Domain[J].Neural Computing &amp;amp; Applications,2018(4):1-17." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Convolutional neural network-based multimodal image fusion via similarity learning in the shearletdomain">
                                        <b>[8]</b>
                                         Hermessi H,Mourali O,Zagrouba E.Convolutional Neural Network Based Multimodal Image Fusion Via Similarity Learning in The Shearlet Domain[J].Neural Computing &amp;amp; Applications,2018(4):1-17.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Liu G,Yan S.Latent Low-Rank Representation for subspace segmentation and feature extraction[C]//Proceedings of the 2011 International Conference on Computer Vision.IEEE,2011:1615-1622." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Latent Low-Rank Representation for subspace segmentation and feature extraction">
                                        <b>[9]</b>
                                         Liu G,Yan S.Latent Low-Rank Representation for subspace segmentation and feature extraction[C]//Proceedings of the 2011 International Conference on Computer Vision.IEEE,2011:1615-1622.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" 李娇,杨艳春,党建武,等.基于NSCT与引导滤波的多聚焦图像融合[J].激光与光电子学进展,2018,55(7):189-196." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201807023&amp;v=MDI2NTBuTXFJOUhaNFFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWprVWI3SUx5clBaTEc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         李娇,杨艳春,党建武,等.基于NSCT与引导滤波的多聚焦图像融合[J].激光与光电子学进展,2018,55(7):189-196.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" 王宇桐,禹晶,肖创柏.基于自相似性和低秩表示的有噪模糊图像盲复原算法[J].北京交通大学学报,2018,42(5):123-129." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BFJT201805017&amp;v=MDkxMDFyQ1VSN3FmWnVadEZ5amtVYjdJSnl2QmVyRzRIOW5NcW85RVk0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0Y=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[11]</b>
                                         王宇桐,禹晶,肖创柏.基于自相似性和低秩表示的有噪模糊图像盲复原算法[J].北京交通大学学报,2018,42(5):123-129.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Lin Z,Chen M,Ma Y.The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices[EB].arXiv:1009.5055,2010." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices[EB]">
                                        <b>[12]</b>
                                         Lin Z,Chen M,Ma Y.The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices[EB].arXiv:1009.5055,2010.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" 陈贞,邢笑雪.基于非下采样剪切波变换的医学图像融合算法[J].沈阳工业大学学报,2015,37(2):194-199." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201502014&amp;v=MzIyNzF0Rnlqa1ViN0lOalRNZDdHNEg5VE1yWTlFWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[13]</b>
                                         陈贞,邢笑雪.基于非下采样剪切波变换的医学图像融合算法[J].沈阳工业大学学报,2015,37(2):194-199.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" 蒋燕,范恩.基于非下采样剪切波变换域的图像增强方法[J].控制工程,2018,25(11):2022-2026." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=JZDF201811013&amp;v=MDgyOTc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJTHpmUGFMRzRIOW5Ocm85RVo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[14]</b>
                                         蒋燕,范恩.基于非下采样剪切波变换域的图像增强方法[J].控制工程,2018,25(11):2022-2026.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" 姚吉.基于引导滤波的NSCT域图像融合方法研究[D].南昌:南昌航空大学,2018." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018816519.nh&amp;v=MzA1MTJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJVkYyNkZydTVHTlROcHBFYlBJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         姚吉.基于引导滤波的NSCT域图像融合方法研究[D].南昌:南昌航空大学,2018.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" He K,Sun J,Tang X.Guided Image Filtering[J].IEEE Transactions on Software Engineering,2013,35(6):1397-1409." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Guided image filtering">
                                        <b>[16]</b>
                                         He K,Sun J,Tang X.Guided Image Filtering[J].IEEE Transactions on Software Engineering,2013,35(6):1397-1409.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Li S,Kang X,Hu J.Image Fusion with Guided Filtering[J].IEEE Transactions on Image Processing,2013,22(7):2864-2875." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image fusion with guided filtering">
                                        <b>[17]</b>
                                         Li S,Kang X,Hu J.Image Fusion with Guided Filtering[J].IEEE Transactions on Image Processing,2013,22(7):2864-2875.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Shensa M J.The Discrete Wavelet Transform:Wedding the &#192; Trous and Mallat Algorithms[J].IEEE Transactions on Signal Processing,1992,40(10):2464-2482." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=The discrete wavelet transform: wedding the &amp;#224;.trous and Mallat algorithms">
                                        <b>[18]</b>
                                         Shensa M J.The Discrete Wavelet Transform:Wedding the &#192; Trous and Mallat Algorithms[J].IEEE Transactions on Signal Processing,1992,40(10):2464-2482.
                                    </a>
                                </li>
                                <li id="39">


                                    <a id="bibliography_19" title=" Bavirisetti D P,Xiao G,Liu G.Multi-sensor Image Fusion Based on Fourth Order Partial Differential Equations[C]//2017 20th International Conference on Information Fusion(Fusion).IEEE,2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Multi-sensor image fusion based on fourth order partial differential equations[C/OL]">
                                        <b>[19]</b>
                                         Bavirisetti D P,Xiao G,Liu G.Multi-sensor Image Fusion Based on Fourth Order Partial Differential Equations[C]//2017 20th International Conference on Information Fusion(Fusion).IEEE,2017.
                                    </a>
                                </li>
                                <li id="41">


                                    <a id="bibliography_20" title=" Naidu V P S.Image Fusion Technique using Multi-resolution Singular Value Decomposition[J].Defence Science Journal,2011,61(5):479-484." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image Fusion Technique using Multi-resolution Singular Value Decomposition">
                                        <b>[20]</b>
                                         Naidu V P S.Image Fusion Technique using Multi-resolution Singular Value Decomposition[J].Defence Science Journal,2011,61(5):479-484.
                                    </a>
                                </li>
                                <li id="43">


                                    <a id="bibliography_21" title=" Qu X B,Yan J W,Xiao H Z,et al.Image Fusion Algorithm Based on Spatial Frequency-Motivated Pulse Coupled Neural Networks in Nonsubsampled Contourlet Transform Domain[J].Acta Automatica Sinica,2008,34(12):1508-1514." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300117360&amp;v=MzI1MjJvSUQzbzVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklJRjhXYXhJPU5pZk9mYks3SHRETnJJOUZaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[21]</b>
                                         Qu X B,Yan J W,Xiao H Z,et al.Image Fusion Algorithm Based on Spatial Frequency-Motivated Pulse Coupled Neural Networks in Nonsubsampled Contourlet Transform Domain[J].Acta Automatica Sinica,2008,34(12):1508-1514.
                                    </a>
                                </li>
                                <li id="45">


                                    <a id="bibliography_22" title=" Liu Y,Liu S,Wang Z.A General Framework for Image Fusion Based on Multi-scale Transform and Sparse Representation[J].Information Fusion,2015,24:147-164." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700451440&amp;v=MTI3NjZadEZpbmxVcnpJSUY4V2F4ST1OaWZPZmJLOEg5RE1xSTlGWU80T0NIZzVvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZQ==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[22]</b>
                                         Liu Y,Liu S,Wang Z.A General Framework for Image Fusion Based on Multi-scale Transform and Sparse Representation[J].Information Fusion,2015,24:147-164.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(09),220-225 DOI:10.3969/j.issn.1000-386x.2019.09.039            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于低秩表示和NSST的医学图像融合</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%9F%E4%BB%A4%E7%8E%89&amp;code=40948236&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孟令玉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%81%82%E4%BB%81%E7%81%BF&amp;code=10871435&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">聂仁灿</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E4%BD%95%E6%95%8F&amp;code=10263130&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">何敏</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%91%A8%E5%86%AC%E6%98%8E&amp;code=10264109&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">周冬明</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E5%8D%8E%E5%85%89&amp;code=41678156&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李华光</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E4%BA%91%E5%8D%97%E5%A4%A7%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%99%A2&amp;code=0233984&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">云南大学信息学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>针对不同模态的医学图像成像机理不同,对人体信息显示特性不同,融合结果噪声较大,梯度信息不足等问题,提出一种基于低秩表示和非下采样剪切波变换(NSST)的医学图像融合方法。采用低秩表示方法LatentLRR对原始医学图像进行去噪及特征信息提取,得到基础图像;通过NSST对基础图像分解得到高频图像和低频图像;对得到的相应特征信息运用引导滤波的方法进行处理得到融合后的特征图像,对高频图采用局部梯度能量算法进行融合,对低频图采用加权改进拉普拉斯能量和进行融合;采用逆NSST得到基础融合图像;将基础融合图与特征融合图结合得到最终融合图像。与几种经典图像融合算法相比较,该算法在客观评价和主观评价上均表现出优势。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">医学图像融合;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BD%8E%E7%A7%A9%E8%A1%A8%E7%A4%BA&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">低秩表示;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B1%80%E9%83%A8%E6%A2%AF%E5%BA%A6%E8%83%BD%E9%87%8F&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">局部梯度能量;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%BC%95%E5%AF%BC%E6%BB%A4%E6%B3%A2&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">引导滤波;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=NSST&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">NSST;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    孟令玉,硕士生,主研领域:图像处理。;
                                </span>
                                <span>
                                    聂仁灿,副教授。;
                                </span>
                                <span>
                                    何敏,副教授;
                                </span>
                                <span>
                                    周冬明,教授。;
                                </span>
                                <span>
                                    李华光,硕士生。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2019-01-29</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目(61463049,61463052,61365001);</span>
                    </p>
            </div>
                    <h1><b>MEDICAL IMAGE FUSION BASED ON LOW RANK REPRESENTATION AND NSST</b></h1>
                    <h2>
                    <span>Meng Lingyu</span>
                    <span>Nie Rencan</span>
                    <span>He Min</span>
                    <span>Zhou Dongming</span>
                    <span>Li Huaguang</span>
            </h2>
                    <h2>
                    <span>School of Information, Yunnan University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Different modes of medical images have different imaging mechanism and different display characteristics of human body information, which results in large noise of fusion results and insufficient gradient information. Therefore, this paper proposed a fusion algorithm for medical image based on low-rank representation and non-down sampling shearlet transform(NSST). The low-rank representation method LatentLRR was used to denoise the source medical image and extract the feature information, and the base images were obtained. The high-frequency images and the low-frequency images of the base images were obtained by NSST. The corresponding feature information was processed by guiding filter to get the fused feature image. We adopted the local gradient energy algorithm to fuse the high frequency image and used the weighted improved Laplace energy sum to fuse the low frequency image. The basic fusion image was obtained by inverse NSST. The final fusion image could be obtained by combining the basic fusion image with the feature fusion image. Compared with several classical image fusion algorithms, the proposed algorithm has advantages in both objective and subjective evaluation.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Medical%20image%20fusion&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Medical image fusion;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Low%20rank%20representation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Low rank representation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Local%20gradient%20energy&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Local gradient energy;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Guided%20filtering&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Guided filtering;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=NSST&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">NSST;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2019-01-29</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="47" name="47" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="48">随着成像技术的发展,医学图像在临床诊断等方面发挥着越来越重要的作用,已经成为医生疾病诊断、疾病治疗的得力助手,极大降低了误诊风险,提高了对症治疗的效率、速率。与普通的光学成像方式不同,医学图像成像机理比较复杂,涉及到物理、化学和生物等多个学科,因此,单模态医学图像的功能比较单一,很难全面显示人体器官组织的信息。例如,核磁共振成像(Magnetic Resonance Imaging,MRI)可以充分显示软组织的信息,但其骨骼等信息的探测存在很大缺陷。与MRI不同的是,计算机断层扫描成像(Computer Tomography,CT)可以很好地捕获骨骼信息,但其对软组织等结构信息缺乏探测能力<citation id="160" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>。此外,其他模态的医学图像还有具有很强病灶探测能力的正电子发射计算机断层成像(Positron Emission Tomography,PET)以及具有显示血液流动信息能力的单光子发射计算机断层成像(Single Photon Emission Tomography,SPECT)等。全面了解器官组织的各项信息可以更有针对性地进行临床诊断、疾病治疗,因此,有必要运用一定的图像融合算法将不同模态的医学图像根据需求进行融合得到一幅显示信息更为全面的医学图像。</p>
                </div>
                <div class="p1">
                    <p id="49">医学图像融合作为图像融合的重要应用领域之一,是当今国内外研究的热点问题,在医学领域有着广泛的应用前景和实用价值<citation id="161" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>。近年来,针对医学图像的融合方法已经得到很大发展,这些算法大致可以分为两类:基于频率域的算法和基于空间域的算法<citation id="162" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>。空间域类算法主要是在原始图像像素上直接进行相关处理,对图像主要特征信息捕捉并融合。此类方法实现起来比较简单,但是对图像的特性分析不够充分,人为痕迹较明显,噪声等干扰信息较多。相较而言,频率域类方法一般通过多尺度分析工具对图像在不同方向进行分解,可以充分挖掘图像的边缘、细节、轮廓等信息。目前,国内外研究学者已经提出很多可行的算法。王健等<citation id="163" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>提出一种非下采样轮廓波变换(NonSubsampled Contourlet Transform,NSCT)域内基于增补小波变换和脉冲耦合神经网络(Pulse Coupled Neural Network,PCNN)的图像融合方法,在一定程度上弥补了传统NSCT的缺陷,充分利用了其对图像的多分辨率、多方向性等分析特性,融合效果细节信息丰富,轮廓清晰,符合人眼视觉习惯。刘雯敏等<citation id="164" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>提出一种基于PCNN和非线性滤波万有引力的医学图像融合方法,很好地改善了融合图像的视觉效果,有效地保留了源始图像的各项信息,边缘和纹理信息突出。吴银芳等<citation id="165" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>提出一种基于模糊变换耦合最大熵的医学图像融合方法,可以有效克服融合过程中的边缘模糊和伪轮廓,对提高融合图像的边缘信息强度、峰值信噪比等效果显著。Ramla等<citation id="166" type="reference"><link href="15" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>提出一种非下采样剪切波变换(NonSubsampled Shearlet Transform,NSST)域内基于PCNN和形态学梯度的医学图像融合方法,其将图像的形态学梯度作为PCNN的激发项,以此作为高频信息部分的融合规则,很好地保留了源始医学图像的特征信息。同样是在NSST域内,Hermessi等<citation id="167" type="reference"><link href="17" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>提出一种将NSST结合全卷积神经网络(Fully Convolutional Neural Network,FCNN)学习框架的图像融合算法。通过训练好的CNN对NSST分解后的高频信息进行特征提取,很好地保留了源始医学图像各部分的信息,细节清晰,对比度、亮度等恰当,极大提高了医学融合图像的视觉效果,但是该算法执行起来耗时较长,对设备性能要求较高。</p>
                </div>
                <div class="p1">
                    <p id="50">为使不同模态医学图像的特征信息充分融合到一幅图像当中,提高图像融合质量,增强融合结果的抗噪能力,丰富梯度、细节等信息,本文提出一种基于低秩表示(Latent Low Rank Representation,LatentLRR)<citation id="168" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>和NSST的MRI和CT医学图像融合方法。低秩表示方法LatentLRR可以将原始图像分解成基础图、特征图像和噪声图三部分,具有很强的去噪和特征提取能力。对特征图使用方向引导滤波<citation id="169" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>进行融合;对基础图进行NSST分解后的高频部分采用本文的局部梯度能量方法进行融合,低频部分使用本文的加权改进拉普拉斯能量和SML(Sum of Modified Laplacian)进行融合。</p>
                </div>
                <h3 id="51" name="51" class="anchor-tag"><b>1 基本理论</b></h3>
                <h4 class="anchor-tag" id="52" name="52"><b>1.1 低秩表示LatentLRR</b></h4>
                <div class="p1">
                    <p id="53">低秩表示LRR<citation id="170" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>是在已经确定学习字典之后,一种从稀疏噪声中恢复低秩矩阵结构的有效模型。用最低秩数矩阵的线性组合表示所有的数据向量,近几年一直是图像领域的研究热点。相比于稀疏表示,低秩表示可以更好地表示数据的整体结构。LRR的一般模型可以表示表示为:</p>
                </div>
                <div class="area_img" id="199">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201909040_19900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="56">s.t. <b><i>X</i></b><sub><i>O</i></sub>=<b><i>A</i></b><i>Z</i></p>
                </div>
                <div class="p1">
                    <p id="57">式中:<i>Z</i>为优化得出的表示方法;<image id="58" type="formula" href="images/JYRJ201909040_05800.jpg" display="inline" placement="inline"><alt></alt></image>为核范数;<b><i>X</i></b><sub><i>O</i></sub>为观测矩阵,即被表示的数据矩阵;<b><i>A</i></b>为学习字典,一般<b><i>A</i>=<i>X</i></b><sub><i>O</i></sub>。</p>
                </div>
                <div class="p1">
                    <p id="59">LatentLRR是在LRR基础上发展而来,其不仅将已知的观测矩阵作为学习字典,并考虑了隐藏的数据信息对学习字典的影响,具有很强的特征信息提取能力和去噪能力。为实现秩数最小化表示,可将LatentLRR看作带有核范数的凸优化问题:</p>
                </div>
                <div class="area_img" id="200">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201909040_20000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="62">s.t. <b><i>X</i></b><sub><i>O</i></sub>=<b><i>X</i></b><sub><i>O</i></sub><i>Z</i>+<i>L</i><b><i>X</i></b><sub><i>O</i></sub>+<i>E</i></p>
                </div>
                <div class="p1">
                    <p id="63">式(2)观测矩阵看作由基础信息<b><i>X</i></b><sub><i>O</i></sub><i>Z</i>、特征信息<i>L</i><b><i>X</i></b><sub><i>O</i></sub>和噪声信息<i>E</i>组合而成,<image id="64" type="formula" href="images/JYRJ201909040_06400.jpg" display="inline" placement="inline"><alt></alt></image>为一阶范数。对式(2)可以通过增广拉格朗日乘子法ALM<citation id="171" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>得到最优解。LatentLRR对图像的分解效果如图1所示。</p>
                </div>
                <div class="area_img" id="65">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909040_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 LatentLRR分解结果" src="Detail/GetImg?filename=images/JYRJ201909040_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 LatentLRR分解结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909040_06500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="66" name="66"><b>1.2 非下采样剪切波变换NSST</b></h4>
                <div class="p1">
                    <p id="67">小波变换只能对图像在三个高通子带进行高频部分信息分析,方向性信息有限,而通过经典仿射系统理论将几何分析与多分辨率分析结合发展而来的剪切波变换可以将图像分解到各种方向上,可对图像的细节、边缘、轮廓等特征信息进行更加详细的分析处理。NSST<citation id="172" type="reference"><link href="27" rel="bibliography" /><link href="29" rel="bibliography" /><sup>[<a class="sup">13</a>,<a class="sup">14</a>]</sup></citation>不仅具有平移不变性等优良特性,并且由于分解过程没有使用采样运算,NSST不会产生吉布斯现象。在二维图像空间中,带有合成膨胀的仿射系统可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="68" class="code-formula">
                        <mathml id="68"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msub><mrow></mrow><mrow><mi>X</mi><mi>Y</mi></mrow></msub><mo stretchy="false">(</mo><mi>ψ</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>ψ</mi><msub><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo>|</mo><mrow><mtext>d</mtext><mtext>e</mtext><mtext>t</mtext><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mrow><mi>j</mi><mo>/</mo><mn>2</mn></mrow></msup></mrow><mo>|</mo></mrow><mi>ψ</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">Y</mi><msup><mrow></mrow><mi>l</mi></msup><mi mathvariant="bold-italic">X</mi><msup><mrow></mrow><mi>j</mi></msup><mi>x</mi><mo>-</mo><mi>k</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="69">式中:<i>l</i>,<i>j</i>∈<b>Z</b>,<i>k</i>∈<b>Z</b><sup>2</sup>,<i>ψ</i>∈<i>L</i><sup>2</sup>(<b>R</b><sup>2</sup>);<b><i>X</i></b>为二维几何变换矩阵,控制剪切波的缩放比例;<b><i>Y</i></b>为二维尺度变换矩阵,控制剪切波的伸展方向,且有<mathml id="70"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>det</mi><mspace width="0.25em" /><mi mathvariant="bold-italic">Y</mi></mrow><mo>|</mo></mrow><mo>=</mo><mn>1</mn></mrow></math></mathml>。通常有,<image id="201" type="formula" href="images/JYRJ201909040_20100.jpg" display="inline" placement="inline"><alt></alt></image>,且一般取<i>a</i>=4,<i>b</i>=1。</p>
                </div>
                <div class="p1">
                    <p id="73">取任意的<mathml id="74"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>ξ</mi><mo>=</mo><mo stretchy="false">(</mo><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>∈</mo><mover accent="true"><mi mathvariant="bold">R</mi><mo>^</mo></mover><mo>,</mo><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>≠</mo><mn>0</mn><mo>,</mo><mo>^</mo></mrow></math></mathml>为傅里叶变换运算标识。<i>M</i><sub><i>XY</i></sub>(<i>ψ</i>)为紧框架,因此,剪切波变换数学表达式为:</p>
                </div>
                <div class="p1">
                    <p id="75" class="code-formula">
                        <mathml id="75"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><mi>ξ</mi><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>ψ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mstyle><mo>^</mo></mover><mo stretchy="false">(</mo><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo><mover><mstyle mathsize="140%" displaystyle="true"><mrow><mi>ψ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></mstyle><mo>^</mo></mover><mo stretchy="false">(</mo><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub><mo>/</mo><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="76">为方便设计和实现剪切波的结构和特性,对<mathml id="77"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>1</mn></msub></mrow></math></mathml>和<mathml id="78"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>2</mn></msub></mrow></math></mathml>设定:</p>
                </div>
                <div class="p1">
                    <p id="79" class="code-formula">
                        <mathml id="79"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>≥</mo><mn>0</mn></mrow></munder><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mn>2</mn><msup><mrow></mrow><mrow><mo>-</mo><mn>2</mn><mi>j</mi></mrow></msup><mi>ω</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mn>1</mn><mtext> </mtext><mo stretchy="false">|</mo><mi>ω</mi><mo stretchy="false">|</mo><mo>≥</mo><mn>1</mn><mo>/</mo><mn>8</mn></mtd></mtr><mtr><mtd><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mo>-</mo><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup></mrow><mrow><mn>2</mn><msup><mrow></mrow><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow></munderover><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>2</mn><mi>j</mi></mrow></msup><mi>ω</mi><mo>-</mo><mi>l</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mn>1</mn><mtext> </mtext><mo stretchy="false">|</mo><mi>ω</mi><mo stretchy="false">|</mo><mo>≤</mo><mn>1</mn></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="80">为实现函数<i>ψ</i><sub><i>i</i>,<i>j</i>,<i>k</i></sub>(<i>x</i>)需要以下频率范围作为支撑集:</p>
                </div>
                <div class="p1">
                    <p id="81" class="code-formula">
                        <mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>⊂</mo><mrow><mo>{</mo><mrow><mtable columnalign="left" rowspacing="-0.1"><mtr><mtd><mtext> </mtext></mtd></mtr><mtr><mtd><mtext> </mtext></mtd></mtr></mtable><mo stretchy="false">(</mo><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>:</mo><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>∈</mo><mo stretchy="false">[</mo><mo>-</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>2</mn><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msup><mo>,</mo><mo>-</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>2</mn><mi>j</mi><mo>-</mo><mn>4</mn></mrow></msup><mo stretchy="false">]</mo><mstyle displaystyle="true"><mo>∪</mo><mrow></mrow></mstyle></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mo stretchy="false">[</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>2</mn><mi>j</mi><mo>-</mo><mn>4</mn></mrow></msup><mo>,</mo><mn>2</mn><msup><mrow></mrow><mrow><mn>2</mn><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msup><mo stretchy="false">]</mo><mo>,</mo><mrow><mo>|</mo><mrow><mfrac><mrow><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mo>+</mo><mi>l</mi><mn>2</mn><msup><mrow></mrow><mrow><mo>-</mo><mi>j</mi></mrow></msup></mrow><mo>|</mo></mrow><mo>≤</mo><mn>2</mn><msup><mrow></mrow><mrow><mo>-</mo><mi>j</mi></mrow></msup></mrow><mo>}</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>6</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="82">从式(6)可以看出,<mathml id="83"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msub><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi></mrow></msub></mrow></math></mathml>的元素被大小约为2<sup><i>j</i></sup>×2<sup>2<i>j</i></sup>、斜率为<i>l</i>2<sup>-<i>j</i></sup>的梯形区域支撑着。当<mathml id="84"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo stretchy="false">{</mo><mo stretchy="false">(</mo><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub><mo stretchy="false">)</mo><mo>∈</mo><mover accent="true"><mi mathvariant="bold">R</mi><mo>^</mo></mover></mrow></math></mathml>:<mathml id="85"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mrow><mo>|</mo><mrow><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow><mo>|</mo></mrow><mo>≥</mo><mfrac><mn>1</mn><mn>8</mn></mfrac><mo>,</mo><mrow><mo>|</mo><mrow><mfrac><mrow><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac></mrow><mo>|</mo></mrow><mo>≤</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></math></mathml>时,结合式(4)和式(5)可以得到该梯形区域支撑为:</p>
                </div>
                <div class="p1">
                    <p id="86" class="code-formula">
                        <mathml id="86"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>≥</mo><mn>0</mn></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mo>-</mo><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup></mrow><mrow><mn>2</mn><msup><mrow></mrow><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow></munderover><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msubsup><mrow></mrow><mrow><mi>l</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><mi>ξ</mi><mi>X</mi><msubsup><mrow></mrow><mn>0</mn><mrow><mo>-</mo><mi>j</mi></mrow></msubsup><mi>Y</mi><msubsup><mrow></mrow><mn>0</mn><mrow><mo>-</mo><mi>l</mi></mrow></msubsup><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo></mtd></mtr><mtr><mtd><mspace width="0.25em" /><mstyle displaystyle="true"><munder><mo>∑</mo><mrow><mi>j</mi><mo>≥</mo><mn>0</mn></mrow></munder><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>l</mi><mo>=</mo><mo>-</mo><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup></mrow><mrow><mn>2</mn><msup><mrow></mrow><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow></munderover><mrow><mrow><mo>|</mo><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">(</mo><mn>2</mn><msup><mrow></mrow><mrow><mo>-</mo><mn>2</mn><mi>j</mi></mrow></msup><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow></mrow></mstyle></mrow></mstyle><msup><mrow></mrow><mn>2</mn></msup><mrow><mo>|</mo><mrow><mover accent="true"><mi>ψ</mi><mo>^</mo></mover><msub><mrow></mrow><mn>2</mn></msub><mrow><mo>(</mo><mrow><mn>2</mn><msup><mrow></mrow><mi>j</mi></msup><mfrac><mrow><mi>ξ</mi><msub><mrow></mrow><mn>2</mn></msub></mrow><mrow><mi>ξ</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></mfrac><mo>-</mo><mi>l</mi></mrow><mo>)</mo></mrow></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mo>=</mo><mn>1</mn><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>7</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="87">式中:<image id="202" type="formula" href="images/JYRJ201909040_20200.jpg" display="inline" placement="inline"><alt></alt></image></p>
                </div>
                <div class="p1">
                    <p id="92">为实现NSST,先对源图像进行非下采样金字塔(Nosubsampled Pyramid,NSP)得到高频信息部分和低频信息部分。接着用以上方法对高频信息部分进行局部方向性分析。然后再对低频信息部分继续使用NSP分解,依次迭代操作完成对源始图像的分解过程。相应的对各子带信息处理后,通过逆NSST运算便可以得到重构图像。</p>
                </div>
                <h3 id="93" name="93" class="anchor-tag"><b>2 融合规则及融合方法</b></h3>
                <div class="p1">
                    <p id="94">图像融合一般包括三个研究方向:图像分解方法、图像融合规则和融合结果评价方法。当图像经过恰当的多尺度分解方法分解为高频部分和低频部分之后,需要一定的融合规则将对应的信息进行整合。融合规则作为图像融合过程中的重要组成部分,对源始图像信息的正确选取和最终融合结果的优良具有决定性的作用。</p>
                </div>
                <h4 class="anchor-tag" id="95" name="95"><b>2.1 特征图融合规则</b></h4>
                <div class="p1">
                    <p id="96">为充分将源始图像经过LatLRR分解得到的特征信息进行有效融合处理,更加高效地保留相关重要特征信息,本文将引导滤波<citation id="173" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>与一组方向矩阵结合作为特征图的融合规则。引导滤波是在局部线性模型的基础上发展而来,在滤波过程中,算法实施起来简单,使用一幅引导图指导整个滤波过程,效率高,对图像的边缘等信息有着很好的平滑特性,是一种边缘保持效果最好的边缘保持滤波器<citation id="174" type="reference"><link href="33" rel="bibliography" /><link href="35" rel="bibliography" /><sup>[<a class="sup">16</a>,<a class="sup">17</a>]</sup></citation>。本文中用GFF表示引导滤波器算法。</p>
                </div>
                <div class="p1">
                    <p id="97">设输入图像为<i>P</i><sub><i>n</i></sub>,则通过以下方式使用平均滤波器AVA将源始图像进行分解:</p>
                </div>
                <div class="p1">
                    <p id="98" class="code-formula">
                        <mathml id="98"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>*</mo><mtext>A</mtext><mtext>V</mtext><mtext>A</mtext></mtd></mtr><mtr><mtd><mi>D</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mi>Ρ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>-</mo><mi>B</mi></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="99">式中:*为卷积运算符;<i>B</i><sub><i>n</i></sub>、<i>D</i><sub><i>n</i></sub>为分解后得到的图像。为得到<i>B</i><sub><i>n</i></sub>、<i>D</i><sub><i>n</i></sub>的显著性成分图,并为提取更加丰富的细节信息,在计算权重图时使用一组方向性矩阵。设拉普拉斯滤波器为<i>LAPF</i>,<b><i>w</i></b><sub><i>i</i></sub>(<i>i</i>=1,2,…,8)为方向性矩阵,则有:</p>
                </div>
                <div class="p1">
                    <p id="100"><mathml id="101"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>S</mi><msub><mrow></mrow><mi>n</mi></msub><mo>=</mo><mfrac><mn>1</mn><mn>8</mn></mfrac><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>8</mn></munderover><mrow><mrow><mo>|</mo><mrow><mi>Ρ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>*</mo><mi>L</mi><mi>A</mi><mi>Ρ</mi><mi>F</mi></mrow><mo>|</mo></mrow></mrow></mstyle><mo>*</mo><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mi>i</mi></msub></mrow></math></mathml>      (9)</p>
                </div>
                <div class="p1">
                    <p id="102">式中:<i>S</i><sub><i>n</i></sub>为显著性成分图。8个方向性矩阵分别为:</p>
                </div>
                <div class="p1">
                    <p id="103" class="code-formula">
                        <mathml id="103"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>1</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>0</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>2</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>5</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mtd></mtr><mtr><mtd><mtext> </mtext><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>3</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>5</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>5</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>5</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>4</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>5</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mtd></mtr><mtr><mtd><mtext> </mtext><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>5</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mn>0</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>6</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>5</mn></mtd><mtd><mn>0</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow></mtd></mtr><mtr><mtd><mtext> </mtext><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>7</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>5</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>5</mn></mtd><mtd><mn>0</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>5</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mi mathvariant="bold-italic">w</mi><msub><mrow></mrow><mn>8</mn></msub><mo>=</mo><mrow><mo>[</mo><mrow><mtable><mtr><mtd><mn>5</mn></mtd><mtd><mn>5</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mn>5</mn></mtd><mtd><mn>0</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr><mtr><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd><mtd><mo>-</mo><mn>3</mn></mtd></mtr></mtable></mrow><mo>]</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>0</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="104">然后,通过取最大值得到权重图<i>M</i><mathml id="105"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mi>k</mi></msubsup></mrow></math></mathml>:</p>
                </div>
                <div class="p1">
                    <p id="106" class="code-formula">
                        <mathml id="106"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>Μ</mi><msubsup><mrow></mrow><mi>n</mi><mi>k</mi></msubsup><mo>=</mo><mrow><mo>{</mo><mtable columnalign="left"><mtr><mtd><mn>1</mn><mtext> </mtext><mi>S</mi><msubsup><mrow></mrow><mi>n</mi><mi>k</mi></msubsup><mo>=</mo><mi>max</mi><mo stretchy="false">(</mo><mi>S</mi><msubsup><mrow></mrow><mn>1</mn><mi>k</mi></msubsup><mo>,</mo><mi>S</mi><msubsup><mrow></mrow><mn>2</mn><mi>k</mi></msubsup><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>S</mi><msubsup><mrow></mrow><mi>Ν</mi><mi>k</mi></msubsup><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mn>0</mn><mtext> </mtext><mtext>其</mtext><mtext>他</mtext></mtd></mtr></mtable></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>1</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="107">式中:<i>N</i>为所要融合的原始图像的最大数量;<i>S</i><mathml id="108"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mrow></mrow><mi>n</mi><mi>k</mi></msubsup></mrow></math></mathml>为第<i>n</i>图像在位置为<i>k</i>处像素的主成分权重值;max为取最大值运算。</p>
                </div>
                <div class="p1">
                    <p id="109">通过引导滤波分别得到<i>B</i><sub><i>n</i></sub>、<i>D</i><sub><i>n</i></sub>的权重图:</p>
                </div>
                <div class="p1">
                    <p id="110" class="code-formula">
                        <mathml id="110"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>W</mi><msubsup><mrow></mrow><mi>n</mi><mi>B</mi></msubsup><mo>=</mo><mi>G</mi><mi>F</mi><mi>F</mi><msub><mrow></mrow><mrow><mi>r</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>ε</mi><msub><mrow></mrow><mn>1</mn></msub></mrow></msub><mo stretchy="false">(</mo><mi>Μ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>,</mo><mi>Ι</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>W</mi><msubsup><mrow></mrow><mi>n</mi><mi>D</mi></msubsup><mo>=</mo><mi>G</mi><mi>F</mi><mi>F</mi><msub><mrow></mrow><mrow><mi>r</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mi>ε</mi><msub><mrow></mrow><mn>2</mn></msub></mrow></msub><mo stretchy="false">(</mo><mi>Μ</mi><msub><mrow></mrow><mi>n</mi></msub><mo>,</mo><mi>Ι</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>2</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="111">式中:<i>r</i><sub>1</sub>、<i>ε</i><sub>1</sub>和<i>r</i><sub>2</sub>、<i>ε</i><sub>2</sub>为引导滤波相关参数。最后,可以通过以下方法得到特征图的融合结果<i>F</i><sub><i>f</i></sub>:</p>
                </div>
                <div class="p1">
                    <p id="112"><mathml id="113"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>F</mi><msub><mrow></mrow><mi>f</mi></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mo stretchy="false">(</mo></mstyle><mi>W</mi><msubsup><mrow></mrow><mi>n</mi><mi>B</mi></msubsup><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo>+</mo><mi>W</mi><msubsup><mrow></mrow><mi>n</mi><mi>D</mi></msubsup><mi>D</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mrow></math></mathml>      (13)</p>
                </div>
                <h4 class="anchor-tag" id="114" name="114"><b>2.2 NSST低频部分融合规则</b></h4>
                <div class="p1">
                    <p id="115">为提高融合图像的对比度、进一步提升对原始图像细节等信息的丰富程度,本文采用窗口大小为3×3的加权改进拉普拉斯能量和作为低频融合规则。设经过NSST分后的低频图为<i>DB</i><sub><i>n</i></sub>(<i>n</i>=1,2,…,<i>N</i>),则本文中在(<i>x</i>,<i>y</i>)位置处的加权拉普拉斯能量和<i>ML</i><sub><i>n</i></sub>(<i>x</i>,<i>y</i>)由以下方式计算得到:</p>
                </div>
                <div class="p1">
                    <p id="116" class="code-formula">
                        <mathml id="116"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><mi>Μ</mi><mi>L</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mn>1</mn><mo>.</mo><mn>6</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mn>0</mn><mo>.</mo><mn>8</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mn>0</mn><mo>.</mo><mn>8</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mn>1</mn><mo>.</mo><mn>6</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mn>0</mn><mo>.</mo><mn>8</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo><mo>-</mo><mn>0</mn><mo>.</mo><mn>8</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mn>2</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>,</mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo><mo>-</mo><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>y</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd><mrow><mo>|</mo><mrow><mn>2</mn><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>-</mo><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>y</mi><mo>-</mo><mn>1</mn><mo stretchy="false">)</mo><mo>-</mo><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>-</mo><mn>1</mn><mo>,</mo><mi>y</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mo>|</mo></mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>4</mn><mo stretchy="false">)</mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="117">然后,通过比较各个图像在(<i>x</i>,<i>y</i>)处的能量和得到融合图像<i>F</i><sub>fdb</sub>:</p>
                </div>
                <div class="p1">
                    <p id="118" class="code-formula">
                        <mathml id="118"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>F</mi><msub><mrow></mrow><mrow><mtext>f</mtext><mtext>d</mtext><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>D</mi><mi>B</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mtext>i</mtext><mtext>f</mtext><mspace width="0.25em" /><mi>Μ</mi><mi>L</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo stretchy="false">(</mo><mi>Μ</mi><mi>L</mi><msub><mrow></mrow><mn>1</mn></msub><mo>,</mo><mi>Μ</mi><mi>L</mi><msub><mrow></mrow><mn>2</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>Μ</mi><mi>L</mi><msub><mrow></mrow><mi>Ν</mi></msub><mo stretchy="false">)</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>5</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <h4 class="anchor-tag" id="119" name="119"><b>2.3 NSST高频部分融合规则</b></h4>
                <div class="p1">
                    <p id="120">经过多层次、多方向性分解后,得益于NSST的优良特性,图像的特征信息已经被充分表示出来。因此,本文中对NSST分解后的高频信息部分采用局部梯度能量的方法进行融合。</p>
                </div>
                <div class="p1">
                    <p id="121">首先,分别计算高频信息部分<i>DG</i><sub><i>n</i></sub>在横向和纵向的梯度<i>DG</i><sub>ngx</sub>、<i>DG</i><sub>ngy</sub>:</p>
                </div>
                <div class="p1">
                    <p id="122" class="code-formula">
                        <mathml id="122"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtable columnalign="left"><mtr><mtd><mi>D</mi><mi>G</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>g</mtext><mtext>x</mtext></mrow></msub><mo>=</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mrow></mrow><mtext>x</mtext></msub><mo stretchy="false">(</mo><mi>D</mi><mi>G</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd><mi>D</mi><mi>G</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>g</mtext><mtext>y</mtext></mrow></msub><mo>=</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mrow></mrow><mtext>y</mtext></msub><mo stretchy="false">(</mo><mi>D</mi><mi>G</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">)</mo></mtd></mtr></mtable><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>6</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="123">式中:<i>gradient</i><sub>x</sub>、<i>gradient</i><sub>y</sub>分别为横向和纵向的梯度算子。</p>
                </div>
                <div class="p1">
                    <p id="124">然后,取得综合性梯度信息<i>DG</i><sub>ng</sub>:</p>
                </div>
                <div class="p1">
                    <p id="125"><mathml id="126"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>G</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>g</mtext></mrow></msub><mo>=</mo><msqrt><mrow><mi>D</mi><mi>G</mi><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>g</mtext><mtext>x</mtext></mrow><mn>2</mn></msubsup><mo>+</mo><mi>D</mi><mi>G</mi><msubsup><mrow></mrow><mrow><mtext>n</mtext><mtext>g</mtext><mtext>y</mtext></mrow><mn>2</mn></msubsup></mrow></msqrt></mrow></math></mathml>      (17)</p>
                </div>
                <div class="p1">
                    <p id="127">通过以下方式计算<i>DG</i><sub>ng</sub>在(<i>x</i>,<i>y</i>)处的能量:</p>
                </div>
                <div class="p1">
                    <p id="128" class="code-formula">
                        <mathml id="128"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>E</mi><msub><mrow></mrow><mi>n</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>w</mi></munderover><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>w</mi></munderover><mo stretchy="false">[</mo></mstyle></mrow></mstyle><mi>D</mi><mi>G</mi><msub><mrow></mrow><mrow><mtext>n</mtext><mtext>g</mtext></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo>+</mo><mi>i</mi><mo>,</mo><mi>y</mi><mo>+</mo><mi>j</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><msup><mrow></mrow><mn>2</mn></msup><mi mathvariant="bold-italic">W</mi><msub><mrow></mrow><mtext>e</mtext></msub><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false">(</mo><mn>1</mn><mn>8</mn><mo stretchy="false">)</mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="129">式中:<i>w</i>=3为低频图像;<b><i>W</i></b><sub>e</sub>为大小为3×3的局部窗,</p>
                </div>
                <div class="area_img" id="130">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201909040_13000.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="132">设能量最大值为<i>F</i><sub><i>n</i></sub>(<i>x</i>,<i>y</i>):</p>
                </div>
                <div class="p1">
                    <p id="133"><i>F</i><sub><i>n</i></sub>(<i>x</i>,<i>y</i>)=max{<i>E</i><sub><i>n</i></sub>(<i>x</i>+<i>i</i>,<i>y</i>+<i>j</i>)|1≤<i>i</i>,<i>j</i>≤3}      (20)</p>
                </div>
                <div class="p1">
                    <p id="134">通过比较不同高频信息的局部梯度能量得到权重:</p>
                </div>
                <div class="area_img" id="135">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201909040_13500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="137">从而,高频部分融合后的图像系数可以表示为:</p>
                </div>
                <div class="p1">
                    <p id="138"><mathml id="139"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>D</mi><mi>G</mi><msub><mrow></mrow><mtext>f</mtext></msub><mo>=</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>Ν</mi></munderover><mi>D</mi></mstyle><mi>G</mi><msub><mrow></mrow><mi>n</mi></msub><mo>⋅</mo><mi>Ρ</mi><msub><mrow></mrow><mi>n</mi></msub></mrow></math></mathml>      (22)</p>
                </div>
                <div class="p1">
                    <p id="140">通过对<i>F</i><sub>fdb</sub>和<i>DG</i><sub>f</sub>使用逆NSST得到基础图融合结果。</p>
                </div>
                <h4 class="anchor-tag" id="141" name="141"><b>2.4 融合方法</b></h4>
                <div class="p1">
                    <p id="142">首先使用LatLRR将源始图像分解为特征图和基础图,对相应的特征图使用引导滤波进行融合得到特征融合图。然后将基础图进行NSST分解得到高频图、低频图,对低频图使用加权改进拉普拉斯能量和进行融合,对高频图运用局部梯度能量进行融合,对低频融合结果和高频融合结果使用逆NSST进行图像重构得到基础图的融合结果。由于特征图和基础图为互补的关系,因此最后通过加法运算将基础融合图和特征融合图结合得到最终融合结果。融合框架如图2所示。</p>
                </div>
                <div class="area_img" id="143">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909040_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 本文算法融合框架" src="Detail/GetImg?filename=images/JYRJ201909040_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 本文算法融合框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909040_143.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="144" name="144" class="anchor-tag"><b>3 实验结果及分析</b></h3>
                <div class="p1">
                    <p id="145">为验证本文算法的有效性,选取三组已经配准好的MRI-CT图作为实验对象,并与几种经典算法DWT(Discrete Wavelet Transform)<citation id="175" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>、FPDE(Fourth Order Partial Differential Equations)<citation id="176" type="reference"><link href="39" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>、MSVD(Multi-resolution Singular Value Decomposition)<citation id="177" type="reference"><link href="41" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>、NSCT-SF-PCNN<citation id="178" type="reference"><link href="43" rel="bibliography" /><sup>[<a class="sup">21</a>]</sup></citation>、CUR(Curvelet Transform)<citation id="179" type="reference"><link href="45" rel="bibliography" /><sup>[<a class="sup">22</a>]</sup></citation>作比较。其中,DWT、CUR的高频部分、低频部分分别采用取最大值、取平均值的融合方法。实验结果如图3-图5所示。</p>
                </div>
                <div class="area_img" id="147">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909040_14700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 第一组融合结果" src="Detail/GetImg?filename=images/JYRJ201909040_14700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 第一组融合结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909040_14700.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="149">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909040_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 第二组融合结果" src="Detail/GetImg?filename=images/JYRJ201909040_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 第二组融合结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909040_14900.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="151">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201909040_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 第三组融合结果" src="Detail/GetImg?filename=images/JYRJ201909040_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 第三组融合结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201909040_15100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="152">为方便客观评价各算法的融合结果,选取PSNR、VIF、STD、Qabf作为评价指标。PSNR可以反映算法在融合过程中对噪声的抑制能力;VIF是判断融合图像结果对人眼视觉习惯符合程度的重要指标;STD可以对图像对比度信息进行评测;Qabf是反映融合结果中对源始图像边缘信息保留情况的有效指标。以上各项评测方法均为值越大,融合效果越好。图3-图5的各项评测指标分别如表1-表3所示。</p>
                </div>
                <div class="area_img" id="154">
                    <p class="img_tit"><b>表1 图3各算法的评测指标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="154" border="1"><tr><td><br />算法</td><td>PSNR</td><td>VIF</td><td>STD</td><td>Qabf</td></tr><tr><td><br />文献[18]</td><td>17.520</td><td>0.490</td><td>0.163</td><td>0.624</td></tr><tr><td><br />文献[19]</td><td>16.357</td><td>0.421</td><td>0.147</td><td>0.579</td></tr><tr><td><br />文献[20]</td><td>16.167</td><td>0.475</td><td>0.154</td><td>0.605</td></tr><tr><td><br />文献[21]</td><td>16.382</td><td>0.293</td><td>0.135</td><td>0.496</td></tr><tr><td><br />文献[22]</td><td>16.656</td><td>0.325</td><td>0.137</td><td>0.358</td></tr><tr><td><br />本文算法</td><td><b>18.599</b></td><td><b>0.576 </b></td><td><b>0.206 </b></td><td><b>0.696</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="155">
                    <p class="img_tit"><b>表2 图4各算法的评测指标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="155" border="1"><tr><td><br />算法</td><td>PSNR</td><td>VIF</td><td>STD</td><td>Qabf</td></tr><tr><td><br />文献[18]</td><td>15.656</td><td>0.463</td><td>0.240</td><td>0.507</td></tr><tr><td><br />文献[19]</td><td>16.058</td><td>0.397</td><td>0.242</td><td>0.472</td></tr><tr><td><br />文献[20]</td><td>15.761</td><td>0.456</td><td>0.251</td><td>0.485</td></tr><tr><td><br />文献[21]</td><td>15.607</td><td>0.313</td><td>0.230</td><td>0.428</td></tr><tr><td><br />文献[22]</td><td>11.246</td><td>0.348</td><td>0.240</td><td>0.454</td></tr><tr><td><br />本文算法</td><td><b>19.021</b></td><td><b>0.470 </b></td><td><b>0.283 </b></td><td><b>0.520</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="area_img" id="156">
                    <p class="img_tit"><b>表3 图5各算法的评测指标</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="156" border="1"><tr><td><br />算法</td><td>PSNR</td><td>VIF</td><td>STD</td><td>Qabf</td></tr><tr><td><br />文献[18]</td><td>18.346</td><td>0.586</td><td>0.237</td><td>0.491</td></tr><tr><td><br />文献[19]</td><td>12.139</td><td>0.550</td><td>0.246</td><td>0.470</td></tr><tr><td><br />文献[20]</td><td>18.327</td><td>0.456</td><td>0.224</td><td>0.452</td></tr><tr><td><br />文献[21]</td><td>18.876</td><td>0.502</td><td>0.222</td><td>0.523</td></tr><tr><td><br />文献[22]</td><td>18.600</td><td>0.513</td><td>0.228</td><td>0.477</td></tr><tr><td><br />本文算法</td><td><b>20.731</b></td><td><b>0.62 </b></td><td><b>0.262 </b></td><td><b>0.557</b></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="157">从图3-图5各算法的融合结果可以看出,文献<citation id="197" type="reference">[<a class="sup">19</a>,<a class="sup">20</a>]</citation>边缘、细节信息不够清晰,有很强的涂抹感。文献<citation id="198" type="reference">[<a class="sup">18</a>,<a class="sup">21</a>,<a class="sup">22</a>]</citation>对CT图的信息保留较少,并带有噪点。文献<citation id="195" type="reference">[<a class="sup">18</a>]</citation>CT图信息明显融合不均,文献<citation id="196" type="reference">[<a class="sup">22</a>]</citation>细节信息丰富,但亮度、对比度不及本文算法。表1-表3更加客观地反映了各算法融合结果的差异性,这与图3-图5的视觉感受相符。显然,本文算法在各项指标中占有优势,具有很强的抗噪声能力,原始图像的细节信息保留最好,对比度、梯度信息丰富,更加符合人眼视觉习惯,更能满足临床诊断的需求。</p>
                </div>
                <h3 id="158" name="158" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="159">医学图像融合是提高临床诊断效率的重要方法。本文运用方向引导滤波、加权改进拉普拉斯能量和等作为融合规则,提出一种基于低秩表示和NSST的MRI/CT医学图像融合方法,其实现简单,在一定程度上提高了融合图像的抗噪能力、细节梯度信息,并拥有不错的视觉效果。今后将努力完善本文算法,挖掘本文算法在多通道医学图像中的应用价值。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201211077&amp;v=MTE2MjRSN3FmWnVadEZ5amtVYjdJTHpUWlpMRzRIOVBOcm85Q1k0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1U=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> 李洪海,朱霞.采用双树小波变换的医学图像融合方法及实现[J].计算机应用与软件,2012,29(11):292-294,327.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201304083&amp;v=MjU4OTMzenFxQnRHRnJDVVI3cWZadVp0Rnlqa1ViN0lMelRaWkxHNEg5TE1xNDlOWjRRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[2]</b> 田秀华,兴旺.基于NSCT变换的医学图像融合研究[J].计算机应用与软件,2013,30(4):287-289,329.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=ZGTB201711011&amp;v=MTkzNDBESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJUHlyZmJMRzRIOWJOcm85RVpZUUs=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[3]</b> 楼建强,李俊峰,戴文战.非下采样剪切波变换的医学图像融合[J].中国图象图形学报,2017,22(11):1574-1583.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJK201810015&amp;v=MDI0MTQ5RVlZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJTHo3QlpiRzRIOW5OcjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 王健,张修飞,任萍,等.基于增补小波变换和PCNN的NSCT域图像融合算法[J].计算机工程与科学,2018,40(10):1822-1828.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSGG201424040&amp;v=MjgzMzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWprVWI3SUx6N01hYkc0SDlYT3E0OUJaSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[5]</b> 刘雯敏,陈秀宏.基于PCNN和非线性滤波万有引力的医学图像融合[J].计算机工程与应用,2014,50(24):191-198.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=XNZK201811010&amp;v=MTkzNDVSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWprVWI3SVBTUFJaYkc0SDluTnJvOUVaSVFLREg4NHY=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[6]</b> 吴银芳.基于模糊变换耦合最大熵的医学图像融合算法[J].西南师范大学学报(自然科学版),2018,43(11):49-56.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multimodal Medical Image Fusion using Non-subsampled Shearlet Transform and Pulse Coupled Neural Network Incorporated with Morphological Gradient">

                                <b>[7]</b> Ramlal S D,Sachdeva J,Ahuja C K,et al.Multimodal Medical Image Fusion using Non-subsampled Shearlet Transform and Pulse Coupled Neural Network Incorporated with Morphological Gradient[J].Signal,Image and Video Processing,2018,12(8):1479-1487.
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Convolutional neural network-based multimodal image fusion via similarity learning in the shearletdomain">

                                <b>[8]</b> Hermessi H,Mourali O,Zagrouba E.Convolutional Neural Network Based Multimodal Image Fusion Via Similarity Learning in The Shearlet Domain[J].Neural Computing &amp; Applications,2018(4):1-17.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Latent Low-Rank Representation for subspace segmentation and feature extraction">

                                <b>[9]</b> Liu G,Yan S.Latent Low-Rank Representation for subspace segmentation and feature extraction[C]//Proceedings of the 2011 International Conference on Computer Vision.IEEE,2011:1615-1622.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JGDJ201807023&amp;v=MDQ3Njg2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWprVWI3SUx5clBaTEc0SDluTXFJOUhaNFFLREg4NHZSNFQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> 李娇,杨艳春,党建武,等.基于NSCT与引导滤波的多聚焦图像融合[J].激光与光电子学进展,2018,55(7):189-196.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=BFJT201805017&amp;v=MjI4OTE0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWprVWI3SUp5dkJlckc0SDluTXFvOUVZNFFLREg4NHZSNFQ2ajU=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[11]</b> 王宇桐,禹晶,肖创柏.基于自相似性和低秩表示的有噪模糊图像盲复原算法[J].北京交通大学学报,2018,42(5):123-129.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices[EB]">

                                <b>[12]</b> Lin Z,Chen M,Ma Y.The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices[EB].arXiv:1009.5055,2010.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=SYGY201502014&amp;v=MjEwNzlLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWprVWI3SU5qVE1kN0c0SDlUTXJZOUVZSVE=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[13]</b> 陈贞,邢笑雪.基于非下采样剪切波变换的医学图像融合算法[J].沈阳工业大学学报,2015,37(2):194-199.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="/kcms/detail/detail.aspx?dbcode=DKFX&amp;filename=JZDF201811013&amp;v=MjM1ODJmUGFMRzRIOW5Ocm85RVo0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJTHo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[14]</b> 蒋燕,范恩.基于非下采样剪切波变换域的图像增强方法[J].控制工程,2018,25(11):2022-2026.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CMFD&amp;filename=1018816519.nh&amp;v=MDMwMzJPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amtVYjdJVkYyNkZydTVHTlROcHBFYlBJUUtESDg0dlI0VDZqNTQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> 姚吉.基于引导滤波的NSCT域图像融合方法研究[D].南昌:南昌航空大学,2018.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Guided image filtering">

                                <b>[16]</b> He K,Sun J,Tang X.Guided Image Filtering[J].IEEE Transactions on Software Engineering,2013,35(6):1397-1409.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image fusion with guided filtering">

                                <b>[17]</b> Li S,Kang X,Hu J.Image Fusion with Guided Filtering[J].IEEE Transactions on Image Processing,2013,22(7):2864-2875.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=The discrete wavelet transform: wedding the &amp;#224;.trous and Mallat algorithms">

                                <b>[18]</b> Shensa M J.The Discrete Wavelet Transform:Wedding the À Trous and Mallat Algorithms[J].IEEE Transactions on Signal Processing,1992,40(10):2464-2482.
                            </a>
                        </p>
                        <p id="39">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Multi-sensor image fusion based on fourth order partial differential equations[C/OL]">

                                <b>[19]</b> Bavirisetti D P,Xiao G,Liu G.Multi-sensor Image Fusion Based on Fourth Order Partial Differential Equations[C]//2017 20th International Conference on Information Fusion(Fusion).IEEE,2017.
                            </a>
                        </p>
                        <p id="41">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image Fusion Technique using Multi-resolution Singular Value Decomposition">

                                <b>[20]</b> Naidu V P S.Image Fusion Technique using Multi-resolution Singular Value Decomposition[J].Defence Science Journal,2011,61(5):479-484.
                            </a>
                        </p>
                        <p id="43">
                            <a id="bibliography_21" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES13011300117360&amp;v=MjE4NjhlcnFRVE1ud1plWnRGaW5sVXJ6SUlGOFdheEk9TmlmT2ZiSzdIdEROckk5Rlplb0lEM281b0JNVDZUNFBRSC9pclJkRw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[21]</b> Qu X B,Yan J W,Xiao H Z,et al.Image Fusion Algorithm Based on Spatial Frequency-Motivated Pulse Coupled Neural Networks in Nonsubsampled Contourlet Transform Domain[J].Acta Automatica Sinica,2008,34(12):1508-1514.
                            </a>
                        </p>
                        <p id="45">
                            <a id="bibliography_22" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJES&amp;filename=SJES14110700451440&amp;v=MjgzMTE1b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSUY4V2F4ST1OaWZPZmJLOEg5RE1xSTlGWU80T0NIZw==&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[22]</b> Liu Y,Liu S,Wang Z.A General Framework for Image Fusion Based on Multi-scale Transform and Sparse Representation[J].Information Fusion,2015,24:147-164.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201909040" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201909040&amp;v=MjQ5ODdUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnlqa1ViN0lMelRaWkxHNEg5ak1wbzlCWklRS0RIODR2UjQ=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
