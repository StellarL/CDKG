<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135751197627500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201904004%26RESULT%3d1%26SIGN%3dB%252byOlD%252fxmVXroZOGdOpGW%252feMPJo%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904004&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201904004&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904004&amp;v=MDgxNTR6bFdyM1BMelRaWkxHNEg5ak1xNDlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#43" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#49" data-title="&lt;b&gt;1 执行模型和整体框架&lt;/b&gt; "><b>1 执行模型和整体框架</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#53" data-title="&lt;b&gt;2 推测代价评估&lt;/b&gt; "><b>2 推测代价评估</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#54" data-title="&lt;b&gt;2.1 推测级计算&lt;/b&gt;"><b>2.1 推测级计算</b></a></li>
                                                <li><a href="#61" data-title="&lt;b&gt;2.2 代价模型&lt;/b&gt;"><b>2.2 代价模型</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#73" data-title="&lt;b&gt;3 循环并行粒度选择&lt;/b&gt; "><b>3 循环并行粒度选择</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#109" data-title="&lt;b&gt;4 处理器核的动态调节机制&lt;/b&gt; "><b>4 处理器核的动态调节机制</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#125" data-title="&lt;b&gt;5 实验结果&lt;/b&gt; "><b>5 实验结果</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#138" data-title="&lt;b&gt;6 结 语&lt;/b&gt; "><b>6 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#52" data-title="图1 面向循环级推测的并行粒度调节框架">图1 面向循环级推测的并行粒度调节框架</a></li>
                                                <li><a href="#60" data-title="图2 推测循环的执行流程">图2 推测循环的执行流程</a></li>
                                                <li><a href="#127" data-title="&lt;b&gt;表 1 处理器配置信息&lt;/b&gt;"><b>表 1 处理器配置信息</b></a></li>
                                                <li><a href="#129" data-title="图3 基于CMP的循环级推测的加速比性能比较">图3 基于CMP的循环级推测的加速比性能比较</a></li>
                                                <li><a href="#130" data-title="图4 基于SMT的循环级推测的加速比性能比较">图4 基于SMT的循环级推测的加速比性能比较</a></li>
                                                <li><a href="#133" data-title="图5 基于CMP的循环级推测能耗开销比较">图5 基于CMP的循环级推测能耗开销比较</a></li>
                                                <li><a href="#134" data-title="图6 基于SMT的循环级推测能耗开销比较">图6 基于SMT的循环级推测能耗开销比较</a></li>
                                                <li><a href="#137" data-title="图7 ammp-200的并行粒度调节结果">图7 ammp-200的并行粒度调节结果</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="162">


                                    <a id="bibliography_1" title=" Martinsen J K, Grahn H, Isberg A. Combining thread-level speculation and just-in-time compilation in google’s V8 JavaScript engine[J]. Concurrency and Computation Practice &amp;amp; Experience, 2016, 29 (1) : 3826-3841." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD55ACE28B7A4A548C0A229CC02C148A30&amp;v=MjI3NjdjTkxtZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHdMaTJ3cTg9TmlmY2FyYTliNks1clljM1k1b0xmWGs5eDJVVG16MS9RUXlSckJCR2VMYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[1]</b>
                                         Martinsen J K, Grahn H, Isberg A. Combining thread-level speculation and just-in-time compilation in google’s V8 JavaScript engine[J]. Concurrency and Computation Practice &amp;amp; Experience, 2016, 29 (1) : 3826-3841.
                                    </a>
                                </li>
                                <li id="164">


                                    <a id="bibliography_2" title=" Wang Q, Wang J L, Shen L, et al. A software-hardware co-designed methodology for efficient thread level speculation[C]//Proceedings of IEEE International Conference on Computer and Information Technology, Helsinki, Aug 21-23, 2017. Piscataway: IEEE, 2017: 184-191." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=A software-hardware co-designed methodology for efficient thread level speculation">
                                        <b>[2]</b>
                                         Wang Q, Wang J L, Shen L, et al. A software-hardware co-designed methodology for efficient thread level speculation[C]//Proceedings of IEEE International Conference on Computer and Information Technology, Helsinki, Aug 21-23, 2017. Piscataway: IEEE, 2017: 184-191.
                                    </a>
                                </li>
                                <li id="166">


                                    <a id="bibliography_3" title=" Verbrugge C , Pickett C J F , Krolik A , et al. Exhaustive analysis of thread-level speculation[C]//Proceedings of the 30th International Workshop on Software Engineering for Parallel Systems, Amsterdam, November 01-01, 2016. New York: ACM, 2016: 25-34." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Exhaustive analysis of thread-level speculation">
                                        <b>[3]</b>
                                         Verbrugge C , Pickett C J F , Krolik A , et al. Exhaustive analysis of thread-level speculation[C]//Proceedings of the 30th International Workshop on Software Engineering for Parallel Systems, Amsterdam, November 01-01, 2016. New York: ACM, 2016: 25-34.
                                    </a>
                                </li>
                                <li id="168">


                                    <a id="bibliography_4" title=" 王家龙, 刘艳红, 沈立. 线程级猜测并行系统代码自动生成工具的设计与实现[J].计算机科学, 2017, 44 (11) : 114-119." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201711018&amp;v=MjA1MTBadEZ5emxXcjNQTHo3QmI3RzRIOWJOcm85RWJJUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnU=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[4]</b>
                                         王家龙, 刘艳红, 沈立. 线程级猜测并行系统代码自动生成工具的设计与实现[J].计算机科学, 2017, 44 (11) : 114-119.
                                    </a>
                                </li>
                                <li id="170">


                                    <a id="bibliography_5" title=" Wang S Y, Dai X R, Yellajyoaula K S, et al. Loop selection for thread-level speculation[C]//Proceedings of the 18th International Conference on Languages and Compilers for Parallel Computing, Hawthorne, October 20-22, 2006. Berlin, Heidelberg: Springer, 2006: 289-303." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Loop selection for thread-level speculation">
                                        <b>[5]</b>
                                         Wang S Y, Dai X R, Yellajyoaula K S, et al. Loop selection for thread-level speculation[C]//Proceedings of the 18th International Conference on Languages and Compilers for Parallel Computing, Hawthorne, October 20-22, 2006. Berlin, Heidelberg: Springer, 2006: 289-303.
                                    </a>
                                </li>
                                <li id="172">


                                    <a id="bibliography_6" title=" Gao L, Li L, Xue J L, et al. SEED: A statically greedy and dynamically adaptive approach for speculative loop execution[J]. IEEE Transactions on Computers, 2013, 62 (5) : 1004-1016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=SEED:a statically greedy and dynamically adaptive approach for speculative loop execution">
                                        <b>[6]</b>
                                         Gao L, Li L, Xue J L, et al. SEED: A statically greedy and dynamically adaptive approach for speculative loop execution[J]. IEEE Transactions on Computers, 2013, 62 (5) : 1004-1016.
                                    </a>
                                </li>
                                <li id="174">


                                    <a id="bibliography_7" title=" 刘斌, 赵银亮, 韩博, 等. 基于性能预测的推测多线程循环选择方法[J].电子与信息学报, 2014, 34 (11) : 2768-2774." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201411037&amp;v=MjI1MjI4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeXpsV3IzUElUZlNkckc0SDlYTnJvOUdZNFFLREg=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[7]</b>
                                         刘斌, 赵银亮, 韩博, 等. 基于性能预测的推测多线程循环选择方法[J].电子与信息学报, 2014, 34 (11) : 2768-2774.
                                    </a>
                                </li>
                                <li id="176">


                                    <a id="bibliography_8" title=" Shen L, Xu F, Wang Z Y. Optimization strategies oriented to loop characteristics in software thread level speculation systems[J]. Journal of Computer Science &amp;amp; Technology, 2016, 31 (1) : 60-76." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Optimization Strategies Oriented to Loop Characteristics in Software Thread Level Speculation Systems">
                                        <b>[8]</b>
                                         Shen L, Xu F, Wang Z Y. Optimization strategies oriented to loop characteristics in software thread level speculation systems[J]. Journal of Computer Science &amp;amp; Technology, 2016, 31 (1) : 60-76.
                                    </a>
                                </li>
                                <li id="178">


                                    <a id="bibliography_9" title=" Yiapanis P, Brown G, Lujan M. Compiler-driven software speculation for thread-level parallelism[J]. ACM Transactions on Programming Languages and Systems, 2015, 38 (2) : 1-45." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM356DC5AAB4B8D4CCD4C47E3CCCBB5A09&amp;v=MTQ4NzdCdUhZZk9HUWxmQnJMVTA1dHRod0xpMndxOD1OaWZJWTdDOUdLVy9xdjQwRnU5OUJBZzl2R1ZuN2t4NVR3cmgzMkZHQzhDUk5McVdDT052RlNpV1dyN0pJRnBtYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[9]</b>
                                         Yiapanis P, Brown G, Lujan M. Compiler-driven software speculation for thread-level parallelism[J]. ACM Transactions on Programming Languages and Systems, 2015, 38 (2) : 1-45.
                                    </a>
                                </li>
                                <li id="180">


                                    <a id="bibliography_10" title=" Dou J L, Cintra M. A compiler cost model for speculative parallelization[J]. ACM Transactions on Architecture and Code Optimization, 2007, 4 (2) : 1-36." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000090371&amp;v=MDgzNzg5RlpPSVBEM3M0b0JNVDZUNFBRSC9pclJkR2VycVFUTW53WmVadEZpbmxVcnpJSkY0ZGFCVT1OaWZJWTdLN0h0ak5yNA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[10]</b>
                                         Dou J L, Cintra M. A compiler cost model for speculative parallelization[J]. ACM Transactions on Architecture and Code Optimization, 2007, 4 (2) : 1-36.
                                    </a>
                                </li>
                                <li id="182">


                                    <a id="bibliography_11" title=" Liu W, Tuck J, Ceze L, et al. POSH: A tls compiler that exploits program structure[C]//Proceedings of the 11th ACM SIGPLAN symposium on Principles and Practice of Parallel Programming, New York, March 29-31, 2006. New York: ACM, 2006: 158-167." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=POSH:A TLS Compiler that Exploits Program Structure">
                                        <b>[11]</b>
                                         Liu W, Tuck J, Ceze L, et al. POSH: A tls compiler that exploits program structure[C]//Proceedings of the 11th ACM SIGPLAN symposium on Principles and Practice of Parallel Programming, New York, March 29-31, 2006. New York: ACM, 2006: 158-167.
                                    </a>
                                </li>
                                <li id="184">


                                    <a id="bibliography_12" title=" Gao L, Li L, Xue J L, et al. Loop recreation for thread-level speculation[C]//Proceedings of International Conference on Parallel and Distributed Systems, Hsinchu, Dec 5-7, 2007. Piscataway: IEEE, 2007: 45-72." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Loop recreation for thread-level speculation">
                                        <b>[12]</b>
                                         Gao L, Li L, Xue J L, et al. Loop recreation for thread-level speculation[C]//Proceedings of International Conference on Parallel and Distributed Systems, Hsinchu, Dec 5-7, 2007. Piscataway: IEEE, 2007: 45-72.
                                    </a>
                                </li>
                                <li id="186">


                                    <a id="bibliography_13" title=" Quinones C, Madriles C, Sanchez J, et al. Mitosis compiler: an infrastructure for speculative threading based on pre-computation slices[C]//Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, Chicago, June 12-15, 2005. New York: ACM, 2005: 269-279." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Mitosis Compiler: An Infrastructure forSpeculative Threading Based on Pre-Computation Slices">
                                        <b>[13]</b>
                                         Quinones C, Madriles C, Sanchez J, et al. Mitosis compiler: an infrastructure for speculative threading based on pre-computation slices[C]//Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, Chicago, June 12-15, 2005. New York: ACM, 2005: 269-279.
                                    </a>
                                </li>
                                <li id="188">


                                    <a id="bibliography_14" title=" Zhai A, Colohan C B, Steffan J G, et al. Compiler optimization of memory-resident value communication between speculative threads[C]//Proceedings of the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization, San Jose, March 20-24, 2004. Piscataway: IEEE, 2004: 39-50." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Compiler optimization of memory-resident value communication between speculative threads">
                                        <b>[14]</b>
                                         Zhai A, Colohan C B, Steffan J G, et al. Compiler optimization of memory-resident value communication between speculative threads[C]//Proceedings of the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization, San Jose, March 20-24, 2004. Piscataway: IEEE, 2004: 39-50.
                                    </a>
                                </li>
                                <li id="190">


                                    <a id="bibliography_15" title=" Li M R, Zhao Y L, Tao Y, et al. A static greedy and dynamic adaptive thread spawning approach for loop-level parallelism[J]. Journal of Computer Science &amp;amp; Technology, 2014, 29 (6) : 962-975." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14112700006300&amp;v=MDU5NTVHZXJxUVRNbndaZVp0RmlubFVyeklKRjRkYUJVPU5qN0Jhcks4SDlET3FJOUZaT3NKRDN3NW9CTVQ2VDRQUUgvaXJSZA==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[15]</b>
                                         Li M R, Zhao Y L, Tao Y, et al. A static greedy and dynamic adaptive thread spawning approach for loop-level parallelism[J]. Journal of Computer Science &amp;amp; Technology, 2014, 29 (6) : 962-975.
                                    </a>
                                </li>
                                <li id="192">


                                    <a id="bibliography_16" title=" Luo Y C, Zhai A. Dynamically dispatching speculative threads to improve sequential execution[J]. ACM Transactions on Architecture and Code Optimization, 2012, 9 (3) : 1-31." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000007303&amp;v=MDAwNTlJSkY0ZGFCVT1OaWZJWTdLN0h0ak5yNDlGWk9zSUQzdzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         Luo Y C, Zhai A. Dynamically dispatching speculative threads to improve sequential execution[J]. ACM Transactions on Architecture and Code Optimization, 2012, 9 (3) : 1-31.
                                    </a>
                                </li>
                                <li id="194">


                                    <a id="bibliography_17" title=" Martinescannmaňo J M, Selva M, Clauss P, et al. Full runtime polyhedral optimizing loop transformations with the generation, instantiation, and scheduling of code-bones[J].Concurrency and Computation Practice &amp;amp; Experience, 2017, 29 (4) : 4192-4197." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD53B05D1738640E758D1E987AB7C680A2&amp;v=MTU0OThTY1JjdWRDT052RlNpV1dyN0pJRnBtYUJ1SFlmT0dRbGZCckxVMDV0dGh3TGkyd3E4PU5pZmNhcmE3Yk5ISjI0NUNaK01KQ0h4TXlCTWJuajRJUVhmbDNXQXlDcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[17]</b>
                                         Martinescannmaňo J M, Selva M, Clauss P, et al. Full runtime polyhedral optimizing loop transformations with the generation, instantiation, and scheduling of code-bones[J].Concurrency and Computation Practice &amp;amp; Experience, 2017, 29 (4) : 4192-4197.
                                    </a>
                                </li>
                                <li id="196">


                                    <a id="bibliography_18" title=" Zier D A, Lee B. Performance evaluation of dynamic speculative multithreading with the cascadia architecture[J]. IEEE Transactions on Parallel and Distributed Systems, 2009, 21 (1) : 47-59." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Performance evaluation of dynamic speculative multithreading with the cascadia architecture">
                                        <b>[18]</b>
                                         Zier D A, Lee B. Performance evaluation of dynamic speculative multithreading with the cascadia architecture[J]. IEEE Transactions on Parallel and Distributed Systems, 2009, 21 (1) : 47-59.
                                    </a>
                                </li>
                                <li id="198">


                                    <a id="bibliography_19" title=" Salamanca J, Amaral J N, Araujo G. Using hardware-transactional-memory support to implement thread-level speculation[J]. IEEE Transactions on Parallel &amp;amp; Distributed Systems, 2018, 29 (2) : 466-480." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Using hardware-transactional-memory support to implement thread-level speculation">
                                        <b>[19]</b>
                                         Salamanca J, Amaral J N, Araujo G. Using hardware-transactional-memory support to implement thread-level speculation[J]. IEEE Transactions on Parallel &amp;amp; Distributed Systems, 2018, 29 (2) : 466-480.
                                    </a>
                                </li>
                                <li id="200">


                                    <a id="bibliography_20" title=" Martonosi M, Tiwari V, Brooks D. Wattch: A framework for architectural-level power analysis and optimizations[C]// Proceedings of International Symposium on Computer Architecture, Vancouver, June 10-14, 2000. New York: ACM, 2000: 83-94." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Wattch: A Framework for Architectural-Level Power Analysis and Optimization">
                                        <b>[20]</b>
                                         Martonosi M, Tiwari V, Brooks D. Wattch: A framework for architectural-level power analysis and optimizations[C]// Proceedings of International Symposium on Computer Architecture, Vancouver, June 10-14, 2000. New York: ACM, 2000: 83-94.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(04),29-36+90 DOI:10.3969/j.issn.1000-386x.2019.04.003            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>一种基于推测代价评估的推测多线程并行粒度调节方法</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E6%9D%8E%E7%BE%8E%E8%93%89&amp;code=40897378&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">李美蓉</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E8%B5%B5%E9%93%B6%E4%BA%AE&amp;code=09088330&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">赵银亮</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E8%88%AA%E7%A9%BA%E5%AD%A6%E9%99%A2&amp;code=1698686&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安航空学院</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6&amp;code=0189085&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安交通大学</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>传统的推测多线程技术总是假定程序的并行粒度大小应该随着处理器核资源数目的增加而增大, 未考虑不同数目的处理器核资源对程序自身并行性能的影响作用。针对这个问题, 提出一种自适应的循环并行粒度调节方法用于优化处理器核资源的分配过程。以推测级为单位, 通过动态收集循环中所有推测线程的性能量化分析结果, 进行推测代价评估。并利用评估结果动态调整循环的并行粒度大小, 优化所分配到的处理器核资源的数目, 以减少不必要的推测代价。实验表明, 该方法不但在SPEC CPU基准测试程序集上能取得较好的性能提升, 而且进一步优化了推测时的能耗开销。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%8E%A8%E6%B5%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">推测多线程;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E4%BB%A3%E4%BB%B7%E8%AF%84%E4%BC%B0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">代价评估;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%B9%B6%E8%A1%8C%E7%B2%92%E5%BA%A6&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">并行粒度;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    李美蓉, 讲师, 主研领域: 线程级推测, 编译优化, 并行计算, 性能分析, 机器学习。;
                                </span>
                                <span>
                                    赵银亮, 教授。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-10-31</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家自然科学基金项目 (61640219, 61173040);</span>
                                <span>校级科研基金项目 (2016KY1103);</span>
                    </p>
            </div>
                    <h1><b>A PARALLEL GRANULARITY TUNING APPROACH FOR SPECULATIVE MULTITHREADING BASED ON SPECULATIVE COST EVALUATION</b></h1>
                    <h2>
                    <span>Li Meirong</span>
                    <span>Zhao Yinliang</span>
            </h2>
                    <h2>
                    <span>Xi'an Aeronautical University</span>
                    <span>Xi'an Jiaotong University</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Traditional speculative multithreading always assumes that the size of program's parallel granularity should increase as the number of processor core resources increases. It doesn't consider the effect of different number of processor core resources on the parallel performance of a program. Therefore, we proposed a self-adaptive parallel granularity adjustment for loops to optimize the allocation of their processor core resources. This approach took the speculative level as the unit, and performed the speculative cost evaluation by mean of dynamically collecting the results of performance quantitative analysis for all speculative threads within a loop. The results of cost evaluation were used to dynamically adjust the size of loop's parallel granularity and optimize the number of their allocated processor core resources to reduce the unnecessary cost for speculation. The experimental results show that our approach not only achieves better performance on SPEC CPU benchmark assemblies, but also optimizes the power consumption for speculation.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Speculative%20multithreading&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Speculative multithreading;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Cost%20evaluation&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Cost evaluation;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Parallel%20granularity&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Parallel granularity;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-10-31</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="43" name="43" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="44">随着多核和众核技术的出现, 如何利用并行技术挖掘程序中潜在的并行性已成为研究热点。推测多线程SpMT (Speculative Multithreading) , 也称线程级推测, 作为一种自动化并行技术, 能够从串行程序中抽取出多个线程, 通过在多核框架中对它们进行推测并行来缩短程序的有效执行时间<citation id="202" type="reference"><link href="162" rel="bibliography" /><link href="164" rel="bibliography" /><link href="166" rel="bibliography" /><link href="168" rel="bibliography" /><sup>[<a class="sup">1</a>,<a class="sup">2</a>,<a class="sup">3</a>,<a class="sup">4</a>]</sup></citation>。由于采用推测并行而非真正意义上的并行执行, 此技术允许处于推测状态的线程间存在模糊的数据依赖关系。若在推测并行之前能准确确定所激发线程的推测时机, 则能有效隐藏这些数据依赖关系, 带来大幅度的并行性能提升。否则不准确的推测时机会造成线程间频繁的数据依赖违规现象, 将影响后继线程分派及推测并行的速度, 甚至导致并行性能下降。</p>
                </div>
                <div class="p1">
                    <p id="45">一般地, 循环结构在串行程序中占有较大比例的执行时间。若将每个循环迭代看作一个线程体作为推测对象, 则能得到循环级推测<citation id="211" type="reference"><link href="170" rel="bibliography" /><link href="172" rel="bibliography" /><link href="174" rel="bibliography" /><link href="176" rel="bibliography" /><sup>[<a class="sup">5</a>,<a class="sup">6</a>,<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation> 。本文重点对循环级推测展开研究。为了准确判定每个循环的推测时机, 很多性能预测和性能优化技术得到了广泛地研究。编译器作为其中一个典型代表, 因具有完整的源程序信息和相关编译优化技术等优势, 常用于预测循环推测时机的首选<citation id="203" type="reference"><link href="178" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>。多数基于编译端的循环级推测技术常借助于程序剖析技术预先得到一些程序执行信息, 如循环迭代次数、数据依赖个数、循环迭代指令数和缓存命中次数等, 再利用这些信息来预测循环并行性能, 以性能预测结果作为循环推测依据。并行性能预测主要采用估算误推测代价实现。Wang等<citation id="204" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>主要利用线程间的数据依赖概率、值通信延迟和线程自身的创建开销三者来估算误推测代价。Liu等<citation id="205" type="reference"><link href="174" rel="bibliography" /><sup>[<a class="sup">7</a>]</sup></citation>则侧重于分析线程粒度、数据依赖距离、线程创建以及激发所带来的性能影响作用。在计算误推测时, Dou等<citation id="206" type="reference"><link href="180" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>又引入了对运行时线程撤销重启和推测缓冲区溢出等因素的分析。而Liu等<citation id="207" type="reference"><link href="182" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>增加了推测数据预取计算, 量化了撤销线程所带来的并行收益大小。Gao等<citation id="208" type="reference"><link href="184" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation>利用编译时的误推测代价模型指导循环重构算法对循环迭代间的数据依赖关系进行重构, 提高循环推测并行的效率。此外, Mitosis<sup></sup><citation id="209" type="reference"><link href="186" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>采用一种预计算切片技术, 在循环推测之前利用数据流分析技术计算激发线程所需的预计算片段, 预先得到运行时所需的寄存器值, 减少数据依赖违规发生的概率。Zhai等<citation id="210" type="reference"><link href="188" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>则采用编译时激进的指令调度和指令同步技术, 减少指针变量间的关键传播路径, 优化循环推测性能。</p>
                </div>
                <div class="p1">
                    <p id="46">除了以上编译相关技术外, 还有不少研究采取编译时和运行时两者相结合的手段来判定循环推测时机。Gao等<citation id="212" type="reference"><link href="172" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>先借助于编译器贪心地选择同一循环中多个不同嵌套层作为候选推测对象, 然后利用运行时动态监测到的执行延迟和撤销次数来最终判定具有最优并行性能的循环嵌套层, 从而指导后续推测对象的选择。Li等<citation id="213" type="reference"><link href="190" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>在前者的基础上, 增加了编译时的循环性能评估模型, 并在运行时依据串行执行时间预测结果来选择最优的循环嵌套层, 确定循环推测次序。Luo等<citation id="214" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>侧重于利用硬件机制构建动态性能监测框架, 通过分析循环推测时一级数据缓存的行为特征变化预测循环的并行收益大小, 以选择循环的推测时机。部分研究采用循环特征优化技术改善循环推测时机, 文献<citation id="215" type="reference">[<a class="sup">17</a>]</citation>利用编译端生成的“code-bones”指导循环运行时进行动态重构生成高效的循环推测并行代码。Shen等<citation id="216" type="reference"><link href="176" rel="bibliography" /><sup>[<a class="sup">8</a>]</sup></citation>则提出采用线程间取值以及乱序提交等相关技术降低循环的各种推测代价开销。也有少数研究完全依赖硬件来判定循环的推测时机, 文献<citation id="217" type="reference">[<a class="sup">18</a>]</citation>提出了一种名叫Cascadia的动态推测多线程框架, 仅利用运行时监测到的IPC作为评估标准, 用于指导嵌套循环推测对象选择。而Salamanca等<citation id="218" type="reference"><link href="198" rel="bibliography" /><sup>[<a class="sup">19</a>]</sup></citation>则采用硬件事务内存实现对循环推测框架的支持, 优化循环推测对象的选择, 提升循环并行性能。</p>
                </div>
                <div class="p1">
                    <p id="47">以上循环级推测方面的研究虽然能带来不少性能的提升, 但存在的问题在于这些研究在确定循环推测时机时并未考虑硬件资源对候选循环推测对象自身特征以及不同程序阶段特征变化的影响作用, 总是假定所有推测对象需求相同的硬件资源。一旦循环被推测并行, 在整个推测周期内需要维护固定大小的并行粒度, 即采用相同数目的处理器核推测并行, 不能根据自身推测结果自适应调整处理器资源, 减少不合理的推测失败带来的额外开销。</p>
                </div>
                <div class="p1">
                    <p id="48">针对此问题, 本文提出了一种面向循环级推测的并行粒度调节框架。此框架以推测级为单位, 通过对运行在不同处理器核上的推测线程进行基于硬件的性能剖析之后, 构建了一个基于推测代价的评估模型, 量化各推测级的并行收益大小。并将此评估结果作为循环并行粒度选择的依据, 动态调整每个循环推测对象所需的处理器核资源, 优化循环推测时机的选择。</p>
                </div>
                <h3 id="49" name="49" class="anchor-tag"><b>1 执行模型和整体框架</b></h3>
                <div class="p1">
                    <p id="50">在推测系统中, 每个循环都是在执行模型的支持下推测并行。一般地, 执行模型中仅需维持一个非推测线程, 其他都是处于推测状态的线程。其中, 非推测线程负责维护程序的串行语义, 通过验证和提交直接后继推测线程的数据来保证程序的正确性。验证和提交工作通常在非推测线程执行结束时进行。一旦某后继推测线程被验证和提交后, 非推测线程会将自身的非推测权限传递给它, 并释放所占用的处理器核资源。也就是说, 在整个推测生命周期中, 每个线程的状态始终在不断地变化, 并且取决于当前整个循环的推测上下文环境。而处于推测状态的线程一般有多个, 为了判定其推测程度, 本文采用推测级来区分处于不同推测状态的线程对象, 并按照线程激发和分派的次序来确定推测级。非推测线程的推测级最低, 其所激发的直接后继线程次之, 其他后继线程以此类推。一旦某线程被激发并分派到某个处理器核上后, 在验证和提交之前并未发生任何数据依赖违规现象, 则认为是推测成功;否则若出现数据读后写现象, 需要撤销当前违规线程及其所有后继, 并利用所得到的正确数据进行再次推测, 保证程序本身的正确性。</p>
                </div>
                <div class="p1">
                    <p id="51">图1给出了本文的整体框架, 共分为编译时和运行时两个阶段。编译阶段负责选择候选循环推测对象, 主要借助于编译时循环并行性能预测手段得到。运行阶段负责对候选循环进行并行粒度调节和处理器核的重新分派。共包含五个模块。首先, 利用处理器核调度模型为每个循环分配所需数目的处理器核, 在循环推测并行中, 采用基于硬件的性能监测工具对循环进行性能剖析, 并对剖析信息进行分析和校正。接着, 利用所得到的性能分析结果, 构建一个推测代价评估模型, 并以推测级为单位, 对当前所采用的并行粒度进行量化分析。然后, 在循环并行粒度选择算法的作用下重新计算当前循环所需的最优并行粒度大小。最后, 将调整后的并行粒度值传递给处理器核的动态调节模块, 指导后续循环调用进行处理器核的重新分派。</p>
                </div>
                <div class="area_img" id="52">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904004_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 面向循环级推测的并行粒度调节框架" src="Detail/GetImg?filename=images/JYRJ201904004_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 面向循环级推测的并行粒度调节框架  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904004_052.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="53" name="53" class="anchor-tag"><b>2 推测代价评估</b></h3>
                <h4 class="anchor-tag" id="54" name="54"><b>2.1 推测级计算</b></h4>
                <div class="p1">
                    <p id="55">通常一个循环中的所有线程在激发后总是被分派到相邻连续的处理器核上进行反复推测并行。为了标识它们, 本文引入了推测级的概念。当一个刚激发线程被分派到某个处理器核上之后, 其推测级的大小采用当前激发线程所在处理器核位置 (即处理器核编号) 与非推测线程所在处理器核位置两者之间的差值来计算:</p>
                </div>
                <div class="area_img" id="56">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201904004_05600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="58">其中:<i>curr</i>_<i>cxt</i>和<i>non</i>_<i>spec</i>_<i>cxt</i>分别表示当前激发线程所在处理器核编号和非推测线程所在处理器核编号;<i>max</i>_<i>num</i>_<i>cxt</i>表示所允许并行的处理器核数目的最大值。本文总是假定非推测线程所属的推测级的大小为0, 而推测线程所属的推测级的大小取决于当前所分派到的处理器核编号。</p>
                </div>
                <div class="p1">
                    <p id="59">图2给出了一个循环的执行流程片段。图中T1到T8相当于从循环中激发的八个线程对象。假设T1初始时处于非推测状态, 处理器核[P0, P3]取值为[0, 3], 则利用以上计算公式可知, 由T1所激发的直接后继T2的推测级为1, T3和T4的推测级分别为2和3。在第1节中提到当T1执行结束时, 会向直接后继传递非推测权限, 同时释放所占用的处理器核资源。此时, T4的直接后继T5会被分派到当前T1所在的处理器核上执行, 依次类推。在这种情况下, 随着循环迭代次数的增加, 每个处理器核上会执行多个不同的线程对象, 且它们在不同的上下文环境中会拥有不同的推测级。若要量化当前所选并行粒度带来的性能影响作用, 很显然以处理器核为单位是不合适的, 需要以推测级为单位来计算, 对处于相同推测级的所有线程进行性能分析和代价评估, 以寻找候选循环所需的较优并行粒度大小。</p>
                </div>
                <div class="area_img" id="60">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904004_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 推测循环的执行流程" src="Detail/GetImg?filename=images/JYRJ201904004_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 推测循环的执行流程  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904004_060.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="61" name="61"><b>2.2 代价模型</b></h4>
                <div class="p1">
                    <p id="62">本文采用Luo等<citation id="219" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>所提出的基于硬件的性能计数器对每个线程进行执行周期分解, 共分解为六个部分:提交循环体内非推测指令执行延迟 (Busy) 、指令本身执行延迟 (ExeStall) 、取指令执行延迟 (iFetch) 、访问数据缓冲执行延迟 (dCache) 、线程撤销执行延迟 (Squash) , 以及其他推测带来的执行延迟 (Others) 。将分解后的结果与未并行之前的源程序的串行执行时间相比, 仅需校正数据缓冲执行延迟就能得到较为准确的并行性能预测结果。为了预测每个推测级中所有线程所带来的性能开销, 本文又将分解结果划分为四大类:基本正类开销 (<i>O</i><sub>basicPos<sub><i>i</i>, <i>j</i></sub></sub>) 、基本负类开销 (<i>O</i><sub>basicNeg<sub><i>i</i>, <i>k</i></sub></sub>) 、推测正类开销 (<i>O</i><sub>specPos<sub><i>i</i>, <i>l</i></sub></sub>) 和推测负类开销 (<i>O</i><sub>specNeg<sub><i>i</i>, <i>m</i></sub></sub>) 。<i>O</i><sub>basicPos<sub><i>i</i>, <i>j</i></sub></sub>由Busy、ExeStall、iFetch以及dCache中除去所需校正的那部分执行延迟四个部分得到;<i>O</i><sub>basicNeg<sub><i>i</i>, <i>k</i></sub></sub>由Others中线程激发、线程提交、线程同步以及执行因推测而引入的额外指令的执行延迟得到;<i>O</i><sub>specPos<sub><i>i</i>, <i>l</i></sub></sub>由校正访问数据缓冲行为中因推测而减少的那部分开销得到;<i>O</i><sub>nolimits<sub><i>i</i>, <i>m</i></sub></sub>由校正访问数据缓冲行为中因推测而增加的那部分开销得到。因此, 一个推测级中所有线程在推测并行中所带来的总正向开销 (<i>O</i><sub>nolimits<sub><i>i</i></sub></sub>) 和总负向开销 (<i>O</i><sub>neg<sub><i>i</i></sub></sub>) 可利用式 (2) 和式 (3) 计算得到。</p>
                </div>
                <div class="p1">
                    <p id="63"><i>O</i><sub>pos<sub><i>i</i></sub></sub>=∑<i>O</i><sub><i>basicPos</i><sub><i>i</i>, <i>j</i></sub></sub>+∑<i>O</i><sub><i>specPos</i><sub><i>i</i>, <i>l</i></sub></sub>      (2) </p>
                </div>
                <div class="p1">
                    <p id="64"><i>O</i><sub>neg<sub><i>i</i></sub></sub>=∑<i>O</i><sub><i>basicNeg</i><sub><i>i</i>, <i>k</i></sub></sub>+∑<i>O</i><sub><i>specNeg</i><sub><i>i</i>, <i>m</i></sub></sub>      (3) </p>
                </div>
                <div class="p1">
                    <p id="65">对于一个推测级来说, 当利用以上分解结果得到所有的正负开销之后, 则很容易对当前并行粒度下此推测级的并行性能进行评估。式 (4) 给出了基于推测级的推测代价模型。若一个推测级的总正向开销大于等于总负向开销时, 说明属于此推测级的线程对象适合在当前并行粒度下高效推测并行, 此时认为它们能带来并行收益提升;否则, 说明属于此推测级的线程对象在当前并行粒度下不能高效推测并行, 与得到的并行收益相比, 带来了过多的额外推测代价, 需要尽量减少这种推测级的存在。</p>
                </div>
                <div class="area_img" id="66">
                            <div class="imgformula">
                                <img class="pFormula" alt="" src="Detail/GetImg?filename=images/JYRJ201904004_06600.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                <p class="formula_seq"></p>
                            </div>

                </div>
                <div class="p1">
                    <p id="68">当同一循环采用两种不同的并行粒度都能带来并行收益时, 以上式 (4) 就很难判定应该选择哪一种更适合当前循环。由于非推测线程所带来的执行延迟在所有推测级的总正向开销中通常占用较大比例, 此时, 本文又引入了非推测比值评估, 计算在给定并行粒度下非推测线程所串行执行部分在整个循环推测所取得的并行收益中所占比例大小, 某种程度上也量化那些因不适合推测并行而频繁撤销和重启后串行执行带来的执行延迟, 如式 (5) 所示。<i>O</i><sub>pos<sub><i>nonspecThread</i></sub></sub>指从非推测线程中得到的执行延迟, <mathml id="69"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>i</mi></munderover><mi>Ο</mi></mstyle><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>o</mtext><mtext>s</mtext><msub><mrow></mrow><mi>i</mi></msub></mrow></msub></mrow></math></mathml>相当于除非推测线程之外其他推测线程所取得的正向开销的总和, 它们都很容易从运行时执行周期分解结果得到, 在此不再一一求解。</p>
                </div>
                <div class="p1">
                    <p id="70"><i>nonspecRatio</i>=<mathml id="71"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mfrac><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>o</mtext><mtext>s</mtext><msub><mrow></mrow><mrow><mi>n</mi><mi>o</mi><mi>n</mi><mi>s</mi><mi>p</mi><mi>e</mi><mi>c</mi><mi>Τ</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi><mspace width="0.25em" /></mrow></msub></mrow></msub></mrow><mrow><mi>Ο</mi><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>o</mtext><mtext>s</mtext><mspace width="0.25em" /><msub><mrow></mrow><mrow><mi>n</mi><mi>o</mi><mi>n</mi><mi>s</mi><mi>p</mi><mi>e</mi><mi>c</mi><mi>Τ</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow></msub><mo>+</mo><mstyle displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mspace width="0.25em" /><mo>=</mo><mspace width="0.25em" /><mn>1</mn></mrow><mi>i</mi></munderover><mi>Ο</mi></mstyle><msub><mrow></mrow><mrow><mtext>p</mtext><mtext>o</mtext><mtext>s</mtext><msub><mrow></mrow><mrow><mi>i</mi><mspace width="0.25em" /></mrow></msub></mrow></msub></mrow></mfrac></mrow></math></mathml>      (5) </p>
                </div>
                <div class="p1">
                    <p id="72">本文采用循环性能登记表来保存每个循环所有推测级的代价评估结果。表中包含以下表项信息:循环标识符、循环迭代次数、当前循环调用并行粒度大小和上次循环调用并行粒度大小、累计的总正向开销大小、累计的总负向开销大小、非推测所占比例值以及所预测的并行收益大小。当前循环调用并行粒度大小和上次循环调用并行粒度大小由第3节的循环并行粒度选择算法计算得到;循环并行收益大小主要通过预测的串行执行时间与实际得到的并行执行时间两者的差值计算得到<citation id="220" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 其他则利用运行时的性能剖析以及以上代价评估相关公式即可得到。</p>
                </div>
                <h3 id="73" name="73" class="anchor-tag"><b>3 循环并行粒度选择</b></h3>
                <div class="p1">
                    <p id="74">每个循环在推测并行之前, 处理器核调度机制需要根据当前循环所选定的并行粒度大小来分配所需的处理器核资源。为了寻找每个循环所需的最优并行粒度值, 本文引入了一种循环并行粒度选择算法, 如算法1所示。此算法共包含三种选择方案:激进递减模式、渐进递减模式和非递减模式。激进递减模式是一种快速收敛的并行粒度选择策略, 主要利用基于推测级的推测代价模型对推测级的性能评估结果来判定所需的并行粒度大小。相应地, 渐进递减模式是一种相对缓慢的并行粒度选择策略, 主要从相邻两次连续的循环调用所估算的并行收益大小的比较结果来确定所需的并行粒度大小。而在非递减模式下, 此时不再做任何并行粒度大小的调整, 从而也表明本算法已经找到了循环所需的最优并行粒度值。</p>
                </div>
                <div class="area_img" id="224">
                                <img alt="" src="Detail/GetImg?filename=images/JYRJ201904004_22400.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="224">
                                <img alt="" src="Detail/GetImg?filename=images/JYRJ201904004_22401.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="106">在为循环选择并行粒度之前, 算法1需要先根据循环标识符在循环性能登记表中查找当前循环是否存在。若不存在, 表明此循环从未参与过推测并行, 此时系统会把所有的处理器核资源分配它, 即允许该循环采用最大并行粒度值来推测并行。否则, 若当前循环处于激进递减模式下并行, 则需根据运行时执行周期分解所收集到的性能剖析信息, 采用基于推测级的推测代价评估结果来进一步判定。如果此次循环调用拥有较小的非推测比值, 表明当前所采用的并行粒度能带来性能提升, 则将继续激进地对每个推测级进行代价计算, 直到计算到不利于推测并行的推测级为止。显然所保留的推测级的个数即为下次循环调用时所需的并行粒度大小。反之, 如果此次循环调用中非推测比值较大, 与之前所得到的结果相比, 证明较优的并行粒度取值应存在于两者之间, 此时需要在两者之间采用渐进递减模式来逐步地逼近到最优的并行粒度结果。在渐进递减模式下, 主要侧重于考虑循环本身得到的并行性能开销。每次循环调用结束时, 只需与上次循环调用计算得到的并行收益大小进行比较即可。若当前循环调用具有较大的并行收益, 表明在此模式下还未找到最优的并行粒度结果, 则继续递减当前的并行粒度大小。否则, 直接在后续循环调用中复用上次循环调用的并行粒度大小即可, 此时整个循环也将直接进入到非递减模式下推测并行。</p>
                </div>
                <div class="p1">
                    <p id="107">算法1中<i>currLoop</i>表示当前采取并行粒度选择的循环对象, <i>loopId</i>表示相应的循环标识符, 函数<i>findLoopId</i>用于在循环性能登记表中查找当前循环所需的并行粒度大小;<i>currLoop</i>.<i>assigned</i>和<i>currLoop</i>.<i>lastAssigned</i>分别指当前所选择的并行粒度值和上次循环调用得到的并行粒度值, 两者可以从循环性能登记表中直接得到。而<i>currLoop</i>.<i>nonspecRatio</i>和<i>cost</i><sub><i>i</i></sub>指非推测所占比例值和第<i>i</i>个推测级的代价计算结果, 则可从第2.2节中计算获取到。最后, <i>currLoop</i>.<i>benefit</i>和<i>currLoop</i>.<i>lastBenefit</i>分别表示当前循环调用和上次循环调用所计算得到的并行收益大小。</p>
                </div>
                <div class="p1">
                    <p id="108">当一个循环的循环迭代次数随着循环调用次数的增加而不断变化时, 而又由于同一循环在不同循环迭代次数下经常展现出不同的并行收益结果, 若仅在算法中包含某次循环调用的循环迭代次数, 将会影响系统对并行粒度大小的正确判定。因此, 本文又进一步扩展了循环性能登记表, 在表中包含了每个循环在所有可能的循环迭代次数下的相关性能表项信息。每次循环调用时, 先通过查表确定所属的循环迭代次数, 再进行并行粒度大小的选择。而对于每种循环迭代次数所需的最优并行粒度值, 可利用循环并行粒度选择算法计算得到。</p>
                </div>
                <h3 id="109" name="109" class="anchor-tag"><b>4 处理器核的动态调节机制</b></h3>
                <div class="p1">
                    <p id="110">从循环并行粒度选择算法得到所需的并行粒度大小后, 需要根据此结果来调整处理器核资源, 保证每个循环所分派的线程对象能在所允许的推测级上正确地推测并行。算法2给出了相应的处理器核映射位置计算流程。若当前循环的某个线程对象要激发并分派其直接后继对象时, 需要先查循环性能登记表获取到当前循环的并行粒度大小。若不存在, 从第3节可知, 系统会默认当前循环分配到了最大数目的处理器核资源, 即该循环中所有线程将在所有的处理器核资源推测并行。此时当前线程对象所在处理器核的下一个相邻处理器核, 将认为是即将分派的具体位置。由于处理器核数目有限, 一旦处理器核资源被释放之后, 会立即被后继其他激发线程所占用, 也就是说, 所有的处理器核排成循环队列进行资源的循环利用。</p>
                </div>
                <div class="area_img" id="225">
                                <img alt="" src="Detail/GetImg?filename=images/JYRJ201904004_22500.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="124">在算法2中, 若当前循环在查找之前已被调用过, 则可在表中找到当前循环所需的并行粒度大小。在这种情况下, 刚激发线程即将映射到的处理器位置需要依据表中登记的信息来进一步确定。首先, 从表中得到当前循环所分配到的起始核编号, 即当前循环第一个线程所执行的处理器核编号, 用于确定处理器核的边界范围。接下来, 利用当前线程所在处理器核和起始核两者距离的差值来判定推测程度, 即获取到当前线程所属的推测级。再结合当前循环的并行粒度大小, 很容易计算出其后继对象所属的推测级。在此基础上, 有了起始核的边界限定, 再加上当前后继对象的推测级大小, 则能很快得到最终所要映射到的处理器核位置。在处理器核映射过程中, 至于那些未分派出去的处理器核, 本文仅让其处于空闲状态即可。其主要原因在于, 这些处理器核并不会对处于推测状态的其他核带来任何性能影响。</p>
                </div>
                <h3 id="125" name="125" class="anchor-tag"><b>5 实验结果</b></h3>
                <div class="p1">
                    <p id="126">为了验证所提出方法的有效性, 本文共采用了两种循环推测系统, 分别是基于CMP的循环推测系统和基于SMT的循环推测系统。两者均采用Open64编译器来选择循环, 循环选择的策略是性能预测<citation id="221" type="reference"><link href="170" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>, 首先利用程序剖析技术得到循环嵌套信息, 控制依赖和数据依赖信息, 接着根据这些信息来估算循环推测并行中所产生的同步代价和推测失败代价, 以预测循环的并行性能大小, 最终以此预测结果作为多层嵌套循环选择的依据。由于编译时很难得到准确估算结果, 本文对所有循环嵌套层进行贪心选择。表1分别给出了CMP和SMT这两种循环推测系统的处理器参数配置信息。基于CMP的循环推测系统采用SimpleScalar模拟器框架, 而基于SMT的循环推测系统则采用SMTSIM模拟器框架。前者最多允许16个线程同时在CMP处理器核上推测并行, 即在此推测系统中循环并行粒度的最大值为16。而后者则最多允许6个线程同时在SMT处理器核上推测并行。原因在于, 在SMT处理器核上并行的所有线程总是共享相同的处理器核资源, 过多的线程数目会造成激烈的资源竞争, 影响整体性能提升。</p>
                </div>
                <div class="area_img" id="127">
                    <p class="img_tit"><b>表 1 处理器配置信息</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="127" border="1"><tr><td><br /> 配置项</td><td>项目值</td></tr><tr><td><br />取指令/指令发射/提交宽度</td><td>CMP:6/4/4 SMT:4/4/4</td></tr><tr><td><br />ROB/LSQ大小</td><td>128/64条目</td></tr><tr><td><br />整数计算单元</td><td>6个单元/1个时钟周期</td></tr><tr><td><br />浮点数计算单元</td><td>4个单元/12个时钟周期</td></tr><tr><td><br />私有的L1 Data Cache和L1 Inst. Cache</td><td>64 KB, 4-way, 32 B</td></tr><tr><td><br />分支预测器</td><td>2-Level预测器</td></tr><tr><td><br />Level 1/Level 2大小, 历史寄存器</td><td>1/1 024条目, 8位</td></tr><tr><td><br />分支误推测延迟</td><td>6个周期</td></tr><tr><td><br />统一的L2 Cache</td><td>2 MB, 4-way, 64 B</td></tr><tr><td><br />L1/L2/内存访问延迟</td><td>1/80/150个时钟周期</td></tr><tr><td><br />内存端口</td><td>2个读, 1个写</td></tr><tr><td><br />线程数</td><td>CMP:16 SMT:6</td></tr><tr><td><br />线程激发/撤销/同步/提交</td><td>5/5/5/1</td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="128">本文共采用了SPEC CPU基准测试程序集中的8个测试程序, 分别将它们运行在这两种循环推测系统中, 图3和图4分别给出了相应的程序加速比计算结果。Only Compiler Used指仅采用编译端的循环性能预测结果作为循环选择的依据, 不允许出现多个循环嵌套的现象。被选择的循环在整个推测并行期间总是采用相同数量的处理器核资源直到并行结束。Compiler Hint允许在编译端贪心地选择多个循环嵌套层, 真正的并行目标则依据运行时循环性能量化结果来进一步判定<citation id="222" type="reference"><link href="192" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>。Compiler Hint+Benefit Guided指在前者的基础上, 仅可采用循环并行粒度选择算法中的渐进递减模式依据循环并行收益大小调整处理器核资源的数目。而Ours则采用循环并行粒度选择算法中的三种选择方案共同调整处理器核资源的数目。Oracle指在理想情况下假定每个循环总是在最优的并行粒度作用下所得到的加速比性能。</p>
                </div>
                <div class="area_img" id="129">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904004_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 基于CMP的循环级推测的加速比性能比较" src="Detail/GetImg?filename=images/JYRJ201904004_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 基于CMP的循环级推测的加速比性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904004_129.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="130">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904004_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 基于SMT的循环级推测的加速比性能比较" src="Detail/GetImg?filename=images/JYRJ201904004_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 基于SMT的循环级推测的加速比性能比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904004_130.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="131">从图3和图4可以很容易看出, Only Compiler Used是五种方法中性能提升最少的, 此方法主要取决于编译时循环性能预测的准确性。由于编译时尚未真正并行所有循环, 若选择不合适的循环会产生严重性能影响, 甚至加速比小于1, 即并行执行时间大于串行执行时间。在此方法下crafty、gzip、perlbmk和vortex这四个程序的加速比值均小于1。而Compiler Hint侧重于利用动态性能评估手段来确定真正的推测对象。由于运行时很容易监测到较准确的循环推测特征, 且贪心地选择多个循环嵌套层会允许更多的循环成为候选推测对象。因此, 与前者相比, 整体性能有了较显著地提升。Compiler Hint+Benefit Guided在此基础上能依据每次循环调用的并行收益计算结果动态调节所分配的处理器核资源的数目。主要目的在于减少不合适的并行粒度分配带来的额外推测代价开销, 经过多次并行粒度调整后, 基于SMT的循环推测系统均有较大幅度的性能提升。而基于CMP的循环推测系统由于处理器核的数目较多, 递减速度较慢, 性能提升有限。而Ours则采用了激进递减、渐进递减和非递减三种方案的组合来选择并行粒度大小, 一方面采用激进递减能有效地加速并行粒度的搜索过程得到快速收敛, 另一方面也可以采用渐进递减逐步逼近将要到达的最优并行粒度值。采用此方法后, gcc、mcf、gzip和perlbmk等多数程序都能取得较高的加速比值。与Compiler Hint相比, CMP和SMT这两种推测系统在增加了并行粒度调整后平均加速比值分别提高了约9.43%和20.04%。</p>
                </div>
                <div class="p1">
                    <p id="132">并行粒度调节方法不仅能有效改善并行循环的加速比性能, 而且对其能耗开销也有显著的影响作用。图5和图6分别给出了CMP和SMT这两种循环推测系统的能耗计算结果。能耗大小主要通过在模拟器端集成Wattch能耗分析模型<citation id="223" type="reference"><link href="200" rel="bibliography" /><sup>[<a class="sup">20</a>]</sup></citation>计算得到。且将收集到的能耗值与原始未并行之前的串行结果做归一化对比。</p>
                </div>
                <div class="area_img" id="133">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904004_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 基于CMP的循环级推测能耗开销比较" src="Detail/GetImg?filename=images/JYRJ201904004_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 基于CMP的循环级推测能耗开销比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904004_133.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="area_img" id="134">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904004_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 基于SMT的循环级推测能耗开销比较" src="Detail/GetImg?filename=images/JYRJ201904004_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 基于SMT的循环级推测能耗开销比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904004_134.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="135">从整体上看, 由于线程同步、推测指令执行延迟以及推测失败等原因, 以上方法计算得到的能耗值都相对较大一些, 且随着循环推测性能的改善, 明显呈现递减的趋势。结合图3和图4可知, 程序的加速比性能和能耗开销两者之间还存在密切的关系。Only Compiler Used是以上所有方法中性能估算最不准确的, 因此, 它的加速比值最小, 能耗开销相对来说是最大的。Compiler Hint次之, 虽然它能利用动态性能量结果总能选择到性能较优的循环嵌套层, 有效地减少了不必要的推测代价, 但却不能保证所选推测对象在当前给定并行粒度作用下充分发挥了自身潜在的并行性。而Compiler Hint+Benefit Guided和Ours在前者基础上增加了并行粒度调节方法, 允许推测对象根据自身性能自适应地调整并行粒度的大小, 优化资源配置, 减少了不合理的资源分配得到的额外能耗开销。与Compiler Hint相比, Ours采用激进递减模式能在较短时间内快速搜索到较优的并行粒度值, 因此, 能较大幅度地降低能耗开销。此外, 所有程序在CMP框架下的能耗值要大于其在SMT框架下的能耗值, 主要原因在于, 基于CMP的循环推测系统中具有较大的线程基数, 搜索时间相对较长, 且当搜索到较优并行粒度值时, 处于空闲状态的处理器核的数目较多, 也会产生一定的能耗开销。</p>
                </div>
                <div class="p1">
                    <p id="136">图7对ammp程序的某个循环在基于CMP的循环推测系统中的执行情况展开分析。对于当前循环ammp-200来说, 按照并行粒度选择算法的要求, 首先为其分配的默认值为16, 让它在最大并行粒度值下推测并行。当它运行结束时, 根据推测代价评估模型计算性能的正向开销和负向开销。从图中可知, 很明显在这种情况下总负向开销所占比值具有较大值, 需要采用激进递减模式立即调整并行粒度大小。重复此过程, 当并行粒度值取10时, 总正向开销和总负向开销所占比值相当, 且非推测所占比值下降到最低点, 此时加速比值取得最大值。若继续递减, 可从图中观察到非推测所占比值会逐步上升, 而加速比值却在快速下降, 表明当前循环中很多激发线程因缺乏足够的处理器核资源不得不推迟推测时机, 降低了其本身的并行性。因此, 合理选择循环并行粒度大小在整个循环推测过程中至关重要。</p>
                </div>
                <div class="area_img" id="137">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201904004_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图7 ammp-200的并行粒度调节结果" src="Detail/GetImg?filename=images/JYRJ201904004_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图7 ammp-200的并行粒度调节结果  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201904004_137.jpg&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="138" name="138" class="anchor-tag"><b>6 结 语</b></h3>
                <div class="p1">
                    <p id="139">本文提出一种基于推测代价评估的推测多线程并行粒度调节方法。此方法不以处理器核为单位, 而是以推测级为单位, 依据基于硬件的性能剖析技术所得到的循环性能剖析结果, 构建推测代价评估模型用于量化不同推测级在所选并行粒度作用下所带来的正向和负向性能代价开销。并将此代价评估结果作为循环并行粒度选择的重要判定依据。在激进递减、渐进递减和非递减三种选择策略共同作用下, 实现循环并行粒度的自适应调整和处理器核资源的动态调节。实验结果表明, 自适应的并行粒度选择不仅能揭示出程序潜在的并行性, 而且能有效地减少不必要的推测失败所带来的额外能耗开销。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="162">
                            <a id="bibliography_1" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD55ACE28B7A4A548C0A229CC02C148A30&amp;v=MTkyMzU5YjZLNXJZYzNZNW9MZlhrOXgyVVRtejEvUVF5UnJCQkdlTGFjTkxtZkNPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHdMaTJ3cTg9TmlmY2FyYQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[1]</b> Martinsen J K, Grahn H, Isberg A. Combining thread-level speculation and just-in-time compilation in google’s V8 JavaScript engine[J]. Concurrency and Computation Practice &amp; Experience, 2016, 29 (1) : 3826-3841.
                            </a>
                        </p>
                        <p id="164">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=A software-hardware co-designed methodology for efficient thread level speculation">

                                <b>[2]</b> Wang Q, Wang J L, Shen L, et al. A software-hardware co-designed methodology for efficient thread level speculation[C]//Proceedings of IEEE International Conference on Computer and Information Technology, Helsinki, Aug 21-23, 2017. Piscataway: IEEE, 2017: 184-191.
                            </a>
                        </p>
                        <p id="166">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Exhaustive analysis of thread-level speculation">

                                <b>[3]</b> Verbrugge C , Pickett C J F , Krolik A , et al. Exhaustive analysis of thread-level speculation[C]//Proceedings of the 30th International Workshop on Software Engineering for Parallel Systems, Amsterdam, November 01-01, 2016. New York: ACM, 2016: 25-34.
                            </a>
                        </p>
                        <p id="168">
                            <a id="bibliography_4" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JSJA201711018&amp;v=MDY0NTMzenFxQnRHRnJDVVI3cWZadVp0Rnl6bFdyM1BMejdCYjdHNEg5Yk5ybzlFYklRS0RIODR2UjRUNmo1NE8=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[4]</b> 王家龙, 刘艳红, 沈立. 线程级猜测并行系统代码自动生成工具的设计与实现[J].计算机科学, 2017, 44 (11) : 114-119.
                            </a>
                        </p>
                        <p id="170">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Loop selection for thread-level speculation">

                                <b>[5]</b> Wang S Y, Dai X R, Yellajyoaula K S, et al. Loop selection for thread-level speculation[C]//Proceedings of the 18th International Conference on Languages and Compilers for Parallel Computing, Hawthorne, October 20-22, 2006. Berlin, Heidelberg: Springer, 2006: 289-303.
                            </a>
                        </p>
                        <p id="172">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=SEED:a statically greedy and dynamically adaptive approach for speculative loop execution">

                                <b>[6]</b> Gao L, Li L, Xue J L, et al. SEED: A statically greedy and dynamically adaptive approach for speculative loop execution[J]. IEEE Transactions on Computers, 2013, 62 (5) : 1004-1016.
                            </a>
                        </p>
                        <p id="174">
                            <a id="bibliography_7" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=DZYX201411037&amp;v=MTMzMzc0UUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5emxXcjNQSVRmU2RyRzRIOVhOcm85R1k=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[7]</b> 刘斌, 赵银亮, 韩博, 等. 基于性能预测的推测多线程循环选择方法[J].电子与信息学报, 2014, 34 (11) : 2768-2774.
                            </a>
                        </p>
                        <p id="176">
                            <a id="bibliography_8" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Optimization Strategies Oriented to Loop Characteristics in Software Thread Level Speculation Systems">

                                <b>[8]</b> Shen L, Xu F, Wang Z Y. Optimization strategies oriented to loop characteristics in software thread level speculation systems[J]. Journal of Computer Science &amp; Technology, 2016, 31 (1) : 60-76.
                            </a>
                        </p>
                        <p id="178">
                            <a id="bibliography_9" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM356DC5AAB4B8D4CCD4C47E3CCCBB5A09&amp;v=MTUzNzd2NDBGdTk5QkFnOXZHVm43a3g1VHdyaDMyRkdDOENSTkxxV0NPTnZGU2lXV3I3SklGcG1hQnVIWWZPR1FsZkJyTFUwNXR0aHdMaTJ3cTg9TmlmSVk3QzlHS1cvcQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[9]</b> Yiapanis P, Brown G, Lujan M. Compiler-driven software speculation for thread-level parallelism[J]. ACM Transactions on Programming Languages and Systems, 2015, 38 (2) : 1-45.
                            </a>
                        </p>
                        <p id="180">
                            <a id="bibliography_10" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000090371&amp;v=MDg4MTRxUVRNbndaZVp0RmlubFVyeklKRjRkYUJVPU5pZklZN0s3SHRqTnI0OUZaT0lQRDNzNG9CTVQ2VDRQUUgvaXJSZEdlcg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[10]</b> Dou J L, Cintra M. A compiler cost model for speculative parallelization[J]. ACM Transactions on Architecture and Code Optimization, 2007, 4 (2) : 1-36.
                            </a>
                        </p>
                        <p id="182">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=POSH:A TLS Compiler that Exploits Program Structure">

                                <b>[11]</b> Liu W, Tuck J, Ceze L, et al. POSH: A tls compiler that exploits program structure[C]//Proceedings of the 11th ACM SIGPLAN symposium on Principles and Practice of Parallel Programming, New York, March 29-31, 2006. New York: ACM, 2006: 158-167.
                            </a>
                        </p>
                        <p id="184">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Loop recreation for thread-level speculation">

                                <b>[12]</b> Gao L, Li L, Xue J L, et al. Loop recreation for thread-level speculation[C]//Proceedings of International Conference on Parallel and Distributed Systems, Hsinchu, Dec 5-7, 2007. Piscataway: IEEE, 2007: 45-72.
                            </a>
                        </p>
                        <p id="186">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Mitosis Compiler: An Infrastructure forSpeculative Threading Based on Pre-Computation Slices">

                                <b>[13]</b> Quinones C, Madriles C, Sanchez J, et al. Mitosis compiler: an infrastructure for speculative threading based on pre-computation slices[C]//Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, Chicago, June 12-15, 2005. New York: ACM, 2005: 269-279.
                            </a>
                        </p>
                        <p id="188">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Compiler optimization of memory-resident value communication between speculative threads">

                                <b>[14]</b> Zhai A, Colohan C B, Steffan J G, et al. Compiler optimization of memory-resident value communication between speculative threads[C]//Proceedings of the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization, San Jose, March 20-24, 2004. Piscataway: IEEE, 2004: 39-50.
                            </a>
                        </p>
                        <p id="190">
                            <a id="bibliography_15" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SSJD&amp;filename=SSJD14112700006300&amp;v=MDcxNjRvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklKRjRkYUJVPU5qN0Jhcks4SDlET3FJOUZaT3NKRDN3NQ==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[15]</b> Li M R, Zhao Y L, Tao Y, et al. A static greedy and dynamic adaptive thread spawning approach for loop-level parallelism[J]. Journal of Computer Science &amp; Technology, 2014, 29 (6) : 962-975.
                            </a>
                        </p>
                        <p id="192">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJCM&amp;filename=SJCM13091000007303&amp;v=Mjk0NTZyNDlGWk9zSUQzdzZvQk1UNlQ0UFFIL2lyUmRHZXJxUVRNbndaZVp0RmlubFVyeklKRjRkYUJVPU5pZklZN0s3SHRqTg==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> Luo Y C, Zhai A. Dynamically dispatching speculative threads to improve sequential execution[J]. ACM Transactions on Architecture and Code Optimization, 2012, 9 (3) : 1-31.
                            </a>
                        </p>
                        <p id="194">
                            <a id="bibliography_17" target="_blank" href="/kcms/detail/detail.aspx?dbcode=SJWD&amp;filename=SJWD53B05D1738640E758D1E987AB7C680A2&amp;v=MDE0MjRSY3VkQ09OdkZTaVdXcjdKSUZwbWFCdUhZZk9HUWxmQnJMVTA1dHRod0xpMndxOD1OaWZjYXJhN2JOSEoyNDVDWitNSkNIeE15Qk1ibmo0SVFYZmwzV0F5Q3JTYw==&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[17]</b> Martinescannmaňo J M, Selva M, Clauss P, et al. Full runtime polyhedral optimizing loop transformations with the generation, instantiation, and scheduling of code-bones[J].Concurrency and Computation Practice &amp; Experience, 2017, 29 (4) : 4192-4197.
                            </a>
                        </p>
                        <p id="196">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Performance evaluation of dynamic speculative multithreading with the cascadia architecture">

                                <b>[18]</b> Zier D A, Lee B. Performance evaluation of dynamic speculative multithreading with the cascadia architecture[J]. IEEE Transactions on Parallel and Distributed Systems, 2009, 21 (1) : 47-59.
                            </a>
                        </p>
                        <p id="198">
                            <a id="bibliography_19" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Using hardware-transactional-memory support to implement thread-level speculation">

                                <b>[19]</b> Salamanca J, Amaral J N, Araujo G. Using hardware-transactional-memory support to implement thread-level speculation[J]. IEEE Transactions on Parallel &amp; Distributed Systems, 2018, 29 (2) : 466-480.
                            </a>
                        </p>
                        <p id="200">
                            <a id="bibliography_20" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Wattch: A Framework for Architectural-Level Power Analysis and Optimization">

                                <b>[20]</b> Martonosi M, Tiwari V, Brooks D. Wattch: A framework for architectural-level power analysis and optimizations[C]// Proceedings of International Symposium on Computer Architecture, Vancouver, June 10-14, 2000. New York: ACM, 2000: 83-94.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201904004" />
        <input id="dpi" type="hidden" value="300" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201904004&amp;v=MDgxNTR6bFdyM1BMelRaWkxHNEg5ak1xNDlGWUlRS0RIODR2UjRUNmo1NE8zenFxQnRHRnJDVVI3cWZadVp0Rnk=&amp;uid=WEEvREcwSlJHSldRa1FhcTdnTnhXM3ZKQ291S0FIT2hubWNrWXI0QkNHMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
