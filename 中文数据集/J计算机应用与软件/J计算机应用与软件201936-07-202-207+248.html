<!DOCTYPE html>
<html>
<head>
    <title>全文阅读--XML全文阅读--中国知网</title>
    <link rel="icon" href="/kxreader/favicon.ico" />
    <link rel="shortcut Icon" href="/kxreader/favicon.ico" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="文献 XML KBASE CNKI 中国知网" />
    <meta name="description" content="XML文献检索" />
    <link href="/kxreader/Content/css/detail?v=qX2z2KjRAEyQiNfAbKtl7dLnsqFoQ5Jdw3TZfDf0n1k1" rel="stylesheet"/>

    <script type="text/javascript">
        var APPPATH = '/kxreader';
    </script>
</head>

<body>
    
<script type="text/javascript" src="//login.cnki.net/TopLogin/api/loginapi/get?type=top&amp;localCSS=&amp;returnurl=%2f%2fkns.cnki.net%2f%2fKXReader%2fDetail%3fTIMESTAMP%3d637135626320002500%26DBCODE%3dCJFD%26TABLEName%3dCJFDLAST2019%26FileName%3dJYRJ201907035%26RESULT%3d1%26SIGN%3d%252frkrgPjDxl5pJhQ7cn93oH5pDME%253d"></script>

<div id="headerBox" class="header">
    <div class="topbar">
        <div class="textalign">
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907035&amp;align=md">
                <i class="icon-cen active" title="居中对齐"></i>
            </a>
            <a href="/kxreader/Detail?dbcode=CJFD&amp;filename=JYRJ201907035&amp;align=lt">
                <i class="icon-left " title="左对齐"></i>
            </a>
        </div>
        <h6 class="free-tip"><i class="icon"></i>HTML阅读开放试用阶段，欢迎体验！</h6>
    </div>
</div>

    



<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907035&amp;v=MzI1OTFNcUk5R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcjNMTHpUWlpMRzRIOWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>

    <div class="main">

        

    <div class="sidebar-a">
        <!--sidebar start-->
        <div class="sidenav">
            <div class="arrow"><span></span></div>
            <!--sidebar_list start-->
            <dl class="sidenav-list">
                    <dt class="tit">目录结构</dt>
                            <dd class="guide">
                                    <p><a href="#39" data-title="&lt;b&gt;0 引 言&lt;/b&gt; "><b>0 引 言</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#42" data-title="&lt;b&gt;1 相关研究&lt;/b&gt; "><b>1 相关研究</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#47" data-title="&lt;b&gt;2 生成对抗网络与对抗样本生成&lt;/b&gt; "><b>2 生成对抗网络与对抗样本生成</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#48" data-title="&lt;b&gt;2.1 生成对抗网络&lt;/b&gt;"><b>2.1 生成对抗网络</b></a></li>
                                                <li><a href="#56" data-title="&lt;b&gt;2.2 常见对抗样本生成方法&lt;/b&gt;"><b>2.2 常见对抗样本生成方法</b></a></li>
                                                <li><a href="#75" data-title="&lt;b&gt;2.3 基于GAN的对抗样本生成方法&lt;/b&gt;"><b>2.3 基于GAN的对抗样本生成方法</b></a></li>
                                                <li><a href="#113" data-title="&lt;b&gt;2.4 类别概率向量重排序函数&lt;/b&gt;"><b>2.4 类别概率向量重排序函数</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#117" data-title="&lt;b&gt;3 实验结果及分析&lt;/b&gt; "><b>3 实验结果及分析</b></a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#118" data-title="&lt;b&gt;3.1 实验环境和数据集&lt;/b&gt;"><b>3.1 实验环境和数据集</b></a></li>
                                                <li><a href="#120" data-title="&lt;b&gt;3.2 针对不同目标类别的定向攻击实验结果&lt;/b&gt;"><b>3.2 针对不同目标类别的定向攻击实验结果</b></a></li>
                                                <li><a href="#125" data-title="&lt;b&gt;3.3 不同方法比较实验结果与分析&lt;/b&gt;"><b>3.3 不同方法比较实验结果与分析</b></a></li>
                                    </ul>
                            </dd>
                            <dd class="guide">
                                    <p><a href="#132" data-title="&lt;b&gt;4 结 语&lt;/b&gt; "><b>4 结 语</b></a><i></i></p>
                                                            </dd>
                            <dd class="guide">
                                    <p><a href="#" data-title="文内图表 ">文内图表</a><i></i></p>
                                                                    <ul class="contentbox">
                                                <li><a href="#50" data-title="图1 生成对抗网络">图1 生成对抗网络</a></li>
                                                <li><a href="#86" data-title="图2 基于GAN的对抗样本生成">图2 基于GAN的对抗样本生成</a></li>
                                                <li><a href="#112" data-title="图3 训练流程图">图3 训练流程图</a></li>
                                                <li><a href="#122" data-title="图4 对抗攻击在所有目标类别的成功率">图4 对抗攻击在所有目标类别的成功率</a></li>
                                                <li><a href="#124" data-title="图5 不同目标类别的样本实验">图5 不同目标类别的样本实验</a></li>
                                                <li><a href="#128" data-title="&lt;b&gt;表1 对抗攻击的成功率和生成时间&lt;/b&gt;"><b>表1 对抗攻击的成功率和生成时间</b></a></li>
                                                <li><a href="#131" data-title="图6 生成图像比较">图6 生成图像比较</a></li>
                                    </ul>
                            </dd>
                                    <dd class="guide">
                                        <h6>
                                            <p><a href="#a_bibliography">参考文献</a> </p>
                                        </h6>
                                    </dd>

            </dl>
        </div>
        <!--sidebar end-->
        &nbsp;
        <!--此处有一空格符 勿删-->
    </div>

                <div class="sidebar-b three-collumn" style="width:0;">
            <div class="refer" style="width: 0;">
                <div class="arrow off" title="参考文献"><span></span></div>
                <div class="js-scrollbox" >
                    
                    <div class="subbox active">
                        <h4>
                            <span class="tit">参考文献</span>
                            <a class="close" href="javascript:void(0)">x</a>
                        </h4>
                        <div class="side-scroller">
                            <ul class="refer-list">
                                <li id="3">


                                    <a id="bibliography_1" >
                                        <b>[1]</b>
                                     Lecun Y, Bengio Y, Hinton G.Deep learning[J].Nature, 2015, 521 (7553) :436.</a>
                                </li>
                                <li id="5">


                                    <a id="bibliography_2" title=" Szegedy C, Zaremba W, Sutskever I, et al.Intriguing properties of neural networks[EB/OL].[2013-12-21].https://arxiv.org/abs/1312.6199v4." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Intriguing properties of neural networks">
                                        <b>[2]</b>
                                         Szegedy C, Zaremba W, Sutskever I, et al.Intriguing properties of neural networks[EB/OL].[2013-12-21].https://arxiv.org/abs/1312.6199v4.
                                    </a>
                                </li>
                                <li id="7">


                                    <a id="bibliography_3" title=" Goodfellow I, Shlens J, Szegedy C.Explaining and Harnessing Adversarial Examples[EB/OL].[2014-12-20].https://arxiv.org/abs/1412.6572." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Explaining and Harnessing Adversarial Examples">
                                        <b>[3]</b>
                                         Goodfellow I, Shlens J, Szegedy C.Explaining and Harnessing Adversarial Examples[EB/OL].[2014-12-20].https://arxiv.org/abs/1412.6572.
                                    </a>
                                </li>
                                <li id="9">


                                    <a id="bibliography_4" title=" Kurakin A, Goodfellow I, Bengio S.Adversarial Machine Learning at Scale[EB].arXiv:1611.01236, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adversarial Machine Learning at Scale[EB]">
                                        <b>[4]</b>
                                         Kurakin A, Goodfellow I, Bengio S.Adversarial Machine Learning at Scale[EB].arXiv:1611.01236, 2016.
                                    </a>
                                </li>
                                <li id="11">


                                    <a id="bibliography_5" title=" Papernot N, McDaniel P, Wu X, et al.Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks[C]//2016 IEEE Symposium on Security and Privacy (SP) .IEEE, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Distillation as a defense to adversarial perturbations against deep neural networks">
                                        <b>[5]</b>
                                         Papernot N, McDaniel P, Wu X, et al.Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks[C]//2016 IEEE Symposium on Security and Privacy (SP) .IEEE, 2015.
                                    </a>
                                </li>
                                <li id="13">


                                    <a id="bibliography_6" title=" Baluja S, Fischer I.Adversarial Transformation Networks:Learning to Generate Adversarial Examples[EB].arXiv:1703.09387, 2017." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Adversarial Transformation Networks:Learning to Generate Adversarial Examples[EB]">
                                        <b>[6]</b>
                                         Baluja S, Fischer I.Adversarial Transformation Networks:Learning to Generate Adversarial Examples[EB].arXiv:1703.09387, 2017.
                                    </a>
                                </li>
                                <li id="15">


                                    <a id="bibliography_7" title=" Goodfellow I, Pouget-Abadie J, Mirza M, et al.Generative Adversarial Networks[EB].arXiv:1406.2661, 2014" target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Generative Adversarial Networks[EB]">
                                        <b>[7]</b>
                                         Goodfellow I, Pouget-Abadie J, Mirza M, et al.Generative Adversarial Networks[EB].arXiv:1406.2661, 2014
                                    </a>
                                </li>
                                <li id="17">


                                    <a id="bibliography_8" title=" 王坤峰, 苟超, 段艳杰, 等.生成式对抗网络GAN的研究进展与展望[J].自动化学报, 2017, 43 (3) :321-332." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201703001&amp;v=MTg3NjJDVVI3cWZadVp0RnlqaFVyM0xLQ0xmWWJHNEg5Yk1ySTlGWllRS0RIODR2UjRUNmo1NE8zenFxQnRHRnI=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[8]</b>
                                         王坤峰, 苟超, 段艳杰, 等.生成式对抗网络GAN的研究进展与展望[J].自动化学报, 2017, 43 (3) :321-332.
                                    </a>
                                </li>
                                <li id="19">


                                    <a id="bibliography_9" title=" Reed S, Akata Z, Mohan S, et al.Learning What and Where to Draw[EB].arXiv:1610.02454, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Learning What and Where to Draw[EB]">
                                        <b>[9]</b>
                                         Reed S, Akata Z, Mohan S, et al.Learning What and Where to Draw[EB].arXiv:1610.02454, 2016.
                                    </a>
                                </li>
                                <li id="21">


                                    <a id="bibliography_10" title=" Isola P, Zhu J Y, Zhou T, et al.Image-to-Image Translation with Conditional Adversarial Networks[EB].arXiv:1611.07004, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Image-to-Image Translation with Conditional Adversarial Networks[EB]">
                                        <b>[10]</b>
                                         Isola P, Zhu J Y, Zhou T, et al.Image-to-Image Translation with Conditional Adversarial Networks[EB].arXiv:1611.07004, 2016.
                                    </a>
                                </li>
                                <li id="23">


                                    <a id="bibliography_11" title=" Zhu J Y, Park T, Isola P, et al.Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks[C]//2017 IEEE International Conference on Computer Vision (ICCV) .IEEE, 2017:2242-2251." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unpaired image-to-image translation using cycle-consistent adversarial networks">
                                        <b>[11]</b>
                                         Zhu J Y, Park T, Isola P, et al.Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks[C]//2017 IEEE International Conference on Computer Vision (ICCV) .IEEE, 2017:2242-2251.
                                    </a>
                                </li>
                                <li id="25">


                                    <a id="bibliography_12" title=" Radford A, Metz L, Chintala S.Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[EB].arXiv:1511.06434, 2015." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[EB]">
                                        <b>[12]</b>
                                         Radford A, Metz L, Chintala S.Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[EB].arXiv:1511.06434, 2015.
                                    </a>
                                </li>
                                <li id="27">


                                    <a id="bibliography_13" title=" Shi W, Caballero J, Huszar F, et al.Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network[C]//Computer Vision and Pattern Recognition.IEEE, 2016:1874-1883." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network.&amp;quot;">
                                        <b>[13]</b>
                                         Shi W, Caballero J, Huszar F, et al.Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network[C]//Computer Vision and Pattern Recognition.IEEE, 2016:1874-1883.
                                    </a>
                                </li>
                                <li id="29">


                                    <a id="bibliography_14" title=" Ioffe S, Szegedy C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//International Conference on International Conference on Machine Learning.JMLR.org, 2015:448-456." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">
                                        <b>[14]</b>
                                         Ioffe S, Szegedy C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//International Conference on International Conference on Machine Learning.JMLR.org, 2015:448-456.
                                    </a>
                                </li>
                                <li id="31">


                                    <a id="bibliography_15" title=" Ulyanov D, Vedaldi A, Lempitsky V.Instance Normalization:The Missing Ingredient for Fast Stylization[EB].arXiv:1607.08022, 2016." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Instance Normalization:The Missing Ingredient for Fast Stylization[EB]">
                                        <b>[15]</b>
                                         Ulyanov D, Vedaldi A, Lempitsky V.Instance Normalization:The Missing Ingredient for Fast Stylization[EB].arXiv:1607.08022, 2016.
                                    </a>
                                </li>
                                <li id="33">


                                    <a id="bibliography_16" title=" 廖星宇.深度学习入门之PyTorch[M].北京:电子工业出版社, 2017." target="_blank"
                                       href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121326202000&amp;v=MDE2NTVtVTcvTUlWd1hYRnF6R2JLNkg5TE9xWTFGWnVzUERCTTh6eFVTbURkOVNIN24zeEU5ZmJ2bktyaWZaZVp2Rnlu&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                        <b>[16]</b>
                                         廖星宇.深度学习入门之PyTorch[M].北京:电子工业出版社, 2017.
                                    </a>
                                </li>
                                <li id="35">


                                    <a id="bibliography_17" title=" Krizhevsky A, Sutskever I, Hinton G E.ImageNet classification with deep convolutional neural networks[C]//International Conference on Neural Information Processing Systems.Curran Associates Inc.2012:1097-1105." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">
                                        <b>[17]</b>
                                         Krizhevsky A, Sutskever I, Hinton G E.ImageNet classification with deep convolutional neural networks[C]//International Conference on Neural Information Processing Systems.Curran Associates Inc.2012:1097-1105.
                                    </a>
                                </li>
                                <li id="37">


                                    <a id="bibliography_18" title=" Russakovsky O, Deng J, Su H.et al.ImageNet Large Scale Visual Recognition Challenge[J].International Journal of Computer Vision, 2014, 115 (3) :211-252." target="_blank"
                                       href="http://scholar.cnki.net/result.aspx?q=Imagenet large scale visual recognition challenge">
                                        <b>[18]</b>
                                         Russakovsky O, Deng J, Su H.et al.ImageNet Large Scale Visual Recognition Challenge[J].International Journal of Computer Vision, 2014, 115 (3) :211-252.
                                    </a>
                                </li>
                            </ul>
                            <div style='display: none;' class="zqscroller" >
                                <h4 class="">附加材料</h4>
                                <ul></ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            &nbsp;
            <!--此处有一空格符 勿删-->
        </div>

        
    <div class="content">



        <!--tips start-->
                            <div class="tips">
                    <a href="http://navi.cnki.net/KNavi/JournalDetail?pcode=CJFD&amp;pykm=JYRJ" target="_blank">计算机应用与软件</a>
                2019,36(07),202-207+248 DOI:10.3969/j.issn.1000-386x.2019.07.034            </div>
        <!--tips end-->
            <div class="top-title">
                <h1 class="title">
                    <span class="vm"><b>基于GAN的对抗样本生成研究</b></span>
                                    </h1>

            </div>
                        <h2>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%AD%99%E6%9B%A6%E9%9F%B3&amp;code=41332558&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">孙曦音</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%B0%81%E5%8C%96%E6%B0%91&amp;code=17685345&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">封化民</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%88%98%E9%A3%9A&amp;code=13984864&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">刘飚</a>
                                <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=au&amp;skey=%E5%BC%A0%E5%81%A5%E6%AF%85&amp;code=40325829&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">张健毅</a>
                </h2>
                    <h2>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E8%A5%BF%E5%AE%89%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6&amp;code=0008505&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">西安电子科技大学</a>
                    <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=in&amp;skey=%E5%8C%97%E4%BA%AC%E7%94%B5%E5%AD%90%E7%A7%91%E6%8A%80%E5%AD%A6%E9%99%A2&amp;code=0030122&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">北京电子科技学院</a>
            </h2>

        
<div class="link">
    <a id="aexport" class="icon icon-output"  onclick="" href="javascript:void(0);"><i></i>导出/参考文献</a>
    
    <span class="shareBoard" onmouseover="$('#sharedet').show();$('#this').addClass('shareBoardCUR')" onmouseout="$('#sharedet').hide();$('#this').removeClass('shareBoardCUR')">
        <a class="icon icon-share" href="#"><i></i>分享<em></em></a>
        <ul class="shareHide" id="sharedet" style="display: none;">
            <li><a title="复制链接" class="copy" onclick="" href="#"><i></i>复制链接</a></li>
            <li><a title="分享到新浪微博" class="xl" onclick="" href="javascript:common.ShareAction('xl');"><i></i>新浪微博</a></li>
            <li>
                <a title="分享到微信" class="wx" onclick="" href="#"><i></i>微信扫一扫</a>
                <div class="qrcode"><img src='' alt='' /></div>
            </li>
        </ul>

    </span>
    
    <a id="RefTrack" title="创建引文跟踪" class="icon icon-track" onclick="" href="javascript:void(0);"> <i></i>创建引文跟踪 </a>
    <a id="ashoucang" title="收藏" class="icon icon-favor" onclick="" href="javascript:void(0);"><i></i>收藏</a>
    <a class="icon icon-print" onclick="window.print();" href="javascript:void(0);"><i></i>打印</a>
    
    <!--版本切换 end-->
</div>
                            <div class="data" id="a_abstract">
                <span class="keys">摘<span style="font-family: 'Times New Roman';">&nbsp;&nbsp;&nbsp;&nbsp;</span>要：</span>
                <p>深度卷积神经网络在图像分类、目标检测和人脸识别等任务上取得了较好性能, 但其在面临对抗攻击时容易发生误判。为了提高卷积神经网络的安全性, 针对图像分类中的定向对抗攻击问题, 提出一种基于生成对抗网络的对抗样本生成方法。利用类别概率向量重排序函数和生成对抗网络, 在待攻击神经网络内部结构未知的前提下对其作对抗攻击。实验结果显示, 提出的方法在对样本的扰动不超过5%的前提下, 定向对抗攻击的平均成功率较对抗变换网络提高了1.5%, 生成对抗样本所需平均时间降低了20%。</p>
            </div>
                    <div class="data" id="a_keywords">
                <span class="keys">关键词：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">对抗样本;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">生成对抗网络;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">深度学习;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">分类模型;</a>
                </p>
            </div>
        
        <!--brief start-->
        
            <div class="brief">
                    <p>
                            <b>作者简介：</b>
                                                        <span>
                                    孙曦音, 硕士, 主研领域:机器学习, 网络安全。;
                                </span>
                                <span>
                                    封化民, 教授。;
                                </span>
                                <span>
                                    刘飚, 讲师。;
                                </span>
                                <span>
                                    张健毅, 讲师。;
                                </span>
                    </p>
                                    <p><b>收稿日期：</b>2018-11-09</p>

                    <p>

                            <b>基金：</b>
                                                        <span>国家重点研发计划项目 (2018YFB0803600);</span>
                    </p>
            </div>
                    <h1><b>ADVERSARIAL EXAMPLES GENERATION BASED ON GAN</b></h1>
                    <h2>
                    <span>Sun Xiyin</span>
                    <span>Feng Huamin</span>
                    <span>Liu Biao</span>
                    <span>Zhang Jianyi</span>
            </h2>
                    <h2>
                    <span>Xidian University</span>
                    <span>Beijing Electronic Science and Technology Institution</span>
            </h2>
                            <div class="data" id="a_abstractEN">
                <span class="keys">Abstract：</span>
                <p>Deep convolution neural network has achieved good performance in image classification, target detection and face recognition. At the same time, some studies have found that deep convolution neural network is prone to misjudgment when facing adversarial attack. In order to improve the security of convolutional neural network, aiming at the problem of directional countermeasure attack in image classification, we proposed adversarial examples generation based on GAN. Using the re-ordering function of the class probability vector and GAN, the antagonistic attack was made on the premise that the internal structure of the neural network to be attacked was unknown. The experimental results show that the method improves the average success rate of directional countermeasure attack by 1.5% and reduces the average time required to generate countermeasure samples by 20% when the perturbation to the samples is not more than 5%.</p>
            </div>
                    <div class="data" id="a_keywordsEN">
                <span class="keys">Keyword：</span>
                <p>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Adversarial%20examples&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Adversarial examples;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=GAN&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">GAN;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Deep%20learning&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Deep learning;</a>
                        <a href="/kcms/detail/knetsearch.aspx?dbcode=CJFD&amp;sfield=kw&amp;skey=Classification%20model&amp;code=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" target="_blank">Classification model;</a>
                </p>
            </div>
                    <div class="brief">
                
                    <p>
                                            </p>
                                    <p><b>Received：</b> 2018-11-09</p>
                                    <p>
                                            </p>
            </div>


        <!--brief start-->
                        <h3 id="39" name="39" class="anchor-tag"><b>0 引 言</b></h3>
                <div class="p1">
                    <p id="40">随着人工智能技术的快速发展, 机器学习、深度学习<citation id="134" type="reference"><link href="3" rel="bibliography" /><sup>[<a class="sup">1</a>]</sup></citation>的算法被应用到许多复杂领域, 如图像识别、自然语言处理、人脸识别等, 在这些领域机器已经达到了和人类相似的准确性。但是有研究发现, 深度学习很容易受到微小输入扰动的干扰, 这些干扰人类无法察觉却会引起机器的错误, 我们将这个引起错误的数据叫作对抗样本<citation id="135" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>, 研究对抗样本对于提高深度学习算法安全性有着重要意义。</p>
                </div>
                <div class="p1">
                    <p id="41">目前对抗样本生成的方法主要分为两类:基于优化的方法<citation id="136" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>和快速梯度符号标记法<citation id="137" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation>等。本文提出一种基于生成对抗网络的方法, 通过生成对抗网络的生成器进行对抗样本生成。首先利用生成对抗网络中的生成器生成对抗样本数据, 然后用模型中的判别器约束对抗样本的分布和原数据相同, 保证对抗样本的逼真性;同时, 使用类别概率向量重排序函数约束对抗样本的类别为指定攻击类别, 保证对抗样本在被攻击模型上的有效性。最后, 我们对指定网络进行对抗攻击, 相较于已有的对抗攻击方法得到了两点提升, 一方面, 提高了生成样本的质量, 减少了纹路干扰, 边缘模糊等问题;另一方面, 提高了攻击的成功率, 即使得生成的对抗样本更好地欺骗过分类模型, 平均成功率可以达到80%。</p>
                </div>
                <h3 id="42" name="42" class="anchor-tag"><b>1 相关研究</b></h3>
                <div class="p1">
                    <p id="43">随着人工智能的发展, 深度学习在许多领域得到了很好的应用, 如人脸识别、目标检测、自然语言处理等等。而Szegedy<citation id="138" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>在2013年提出了一个现象, 在数据中加入轻微扰动得到的新样本, 会使得机器学习模型以高置信度得到错误的输出, 这个加入扰动的新样本就是对抗样本。而后又有学者研究表明机器学习模型在对这些对抗样本处理时会表现出脆弱性, 说明对抗样本成为了训练算法的盲点。</p>
                </div>
                <div class="p1">
                    <p id="44">而后Szegedy研究发现通过对抗训练可以增强深度神经网络的鲁棒性来抵抗对抗样本的攻击, Goodfellow等随之提出了一种有效的方法计算对抗扰动, 叫做快速梯度标记法<citation id="139" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation> (Fast Gradient Sign Method, FGSM) 。Kurakin等<citation id="140" type="reference"><link href="9" rel="bibliography" /><sup>[<a class="sup">4</a>]</sup></citation>研究证实FGSM在大型图片数据集ImageNet<citation id="141" type="reference"><link href="35" rel="bibliography" /><sup>[<a class="sup">17</a>]</sup></citation>中, 按照TOP1统计生成对抗样本的比例在63%到69%之间。Carlini和Wagner提出了一种称为蒸馏 (distillation) <citation id="142" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>的方法, 可以将已有的白盒攻击方法迁移到黑盒攻击问题中。</p>
                </div>
                <div class="p1">
                    <p id="45">对抗攻击的过程主要分为两个研究方向, 第一种是指定目标类型, 另一种是非指定目标类型。指定目标类型指的是对抗样本需要被分类为预先指定的类型, 若没有被分类成功即为攻击成功。非指定目标类型相反, 只要对抗样本被分类为非原类型即为攻击成功。</p>
                </div>
                <div class="p1">
                    <p id="46">目前已提出的几种不同的构建对抗样本的方法来攻击深度神经网络, 包括直接图像优化法、直接梯度法和快速梯度符号法。但是使用梯度法产生的对抗样本进行对抗训练存在退化极小值的问题, 并且会明显降低模型对干净样本的分类准确率。在此基础上Shumeet Baluja等<citation id="143" type="reference"><link href="13" rel="bibliography" /><sup>[<a class="sup">6</a>]</sup></citation>在2017年提出了一种对抗变换网络 (Adversarial Transformation Networks, ATN) 的方法来生成对抗样本, 可以有效地训练前馈神经网络以自我监督的方式产生针对目标网络的对抗样本。在给定原始输入的情况下最小化修改分类器的输出, 同时约束新的分类以匹配攻击目标类别。</p>
                </div>
                <h3 id="47" name="47" class="anchor-tag"><b>2 生成对抗网络与对抗样本生成</b></h3>
                <h4 class="anchor-tag" id="48" name="48"><b>2.1 生成对抗网络</b></h4>
                <div class="p1">
                    <p id="49"><citation id="145" type="reference"><link href="7" rel="bibliography" /><link href="15" rel="bibliography" />Goodfellow等在2014</citation>年提出生成对抗网络<citation id="144" type="reference"><link href="15" rel="bibliography" /><link href="17" rel="bibliography" /><sup>[<a class="sup">7</a>,<a class="sup">8</a>]</sup></citation> (Generative Adversarial Networks, GAN) , 这种网络模型是一种无监督学习方法, 由两部分组成, 一部分是生成器, 另一部分是判别器。整体过程如图1所示。</p>
                </div>
                <div class="area_img" id="50">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907035_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图1 生成对抗网络" src="Detail/GetImg?filename=images/JYRJ201907035_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图1 生成对抗网络  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907035_050.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="51">生成对抗网络 (GAN) 解决了一个问题:给定一批样本, 训练一个系统能够生成类似的新样本。GAN的核心思想是博弈论中的纳什均衡, 判别器D的目的是判断数据来自生成器还是训练集, 生成器的目的是学习真实数据的分布, 使得生成的数据更接近真实数据, 两者不断学习优化最后得到纳什平衡点。对于生成器和判别器可以使用任意可微分函数, 生成器使得<i>G</i> (<i>Z</i>) 在判别器上的分布<i>D</i> (<i>G</i> (<i>Z</i>) ) 更近似于真实数据在判别器上的分布<i>D</i> (<i>X</i>) , 直到判别器无法分别真假数据, 就得到了一个以假乱真的数据生成器。最终的优化目标表示为:</p>
                </div>
                <div class="p1">
                    <p id="52" class="code-formula">
                        <mathml id="52"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="left"><mtr><mtd><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mi>G</mi></munder><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mi>D</mi></munder><mi>f</mi><mo stretchy="false"> (</mo><mi>D</mi><mo>, </mo><mi>G</mi><mo stretchy="false">) </mo><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></mrow></msub><mo stretchy="false">[</mo><mrow><mi>log</mi></mrow><mi>D</mi><mo stretchy="false"> (</mo><mi>x</mi><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mo>+</mo></mtd></mtr><mtr><mtd><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext></mrow><mi>E</mi><msub><mrow></mrow><mrow><mi>z</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mi>Ζ</mi></msub></mrow></msub><mo stretchy="false">[</mo><mrow><mi>log</mi></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo>-</mo><mi>D</mi><mo stretchy="false"> (</mo><mi>G</mi><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo stretchy="false">]</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>1</mn><mo stretchy="false">) </mo></mtd></mtr></mtable></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="53">式中:<i>D</i> (<i>x</i>) 表示真实数据的概率分布, <i>G</i> (<i>z</i>) 表示输入噪声<i>z</i>产生的生成数据的概率分布, 通过交替训练生成器和判别器, 迭代优化。一般采用先固定G, 优化D, 使D判别准确率最大化, 再固定D, 优化G, 使D判别准确率最小化, 直到达到预定目标。</p>
                </div>
                <div class="p1">
                    <p id="54">GAN的模型从提出到现在发展飞速, 已有一系列衍生模型, 并应用在如图像生成、人脸识别、超分辨等方面。ConditionGAN<citation id="146" type="reference"><link href="19" rel="bibliography" /><sup>[<a class="sup">9</a>]</sup></citation>可以按照意愿生成图片, 将文字内容转为图片;PatchGAN<citation id="147" type="reference"><link href="21" rel="bibliography" /><sup>[<a class="sup">10</a>]</sup></citation>可以为图片进行上色;CycleGAN<citation id="148" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>用来生成相同风格的图片等。</p>
                </div>
                <div class="p1">
                    <p id="55">DCGAN<citation id="149" type="reference"><link href="25" rel="bibliography" /><sup>[<a class="sup">12</a>]</sup></citation> (Deep Convolutional Generative Adversarial Networks) 是在原始GAN的基础上结合了卷积神经网络的一种衍生模型, 主要贡献是将监督学习中的卷积模型和非监督学习的GAN模型相结合, 使得样本生成质量得到提高, 也提高了收敛速度, 已经有研究证明了其在图像识别分类的有效性。</p>
                </div>
                <h4 class="anchor-tag" id="56" name="56"><b>2.2 常见对抗样本生成方法</b></h4>
                <h4 class="anchor-tag" id="57" name="57"><b>2.2.1 对抗样本</b></h4>
                <div class="p1">
                    <p id="58">机器学习算法在处理对抗样本时会产生错误, 如在分类问题中, 将对抗样本输入到分类模型中, 会使得分类模型错误分类, 对抗样本即是那些有别于正常样本的负样本, 会使得模型输出错误的结果。</p>
                </div>
                <div class="p1">
                    <p id="59">对抗样本产生的方法主要有基于优化的方法和快速梯度标记法。</p>
                </div>
                <div class="p1">
                    <p id="60">基于优化<citation id="150" type="reference"><link href="5" rel="bibliography" /><sup>[<a class="sup">2</a>]</sup></citation>的方法是Szegedy等提出的一种针对深度神经网络生成对抗样本的方法, 该方法将其转化为如下的优化问题:</p>
                </div>
                <div class="p1">
                    <p id="61"><mathml id="62"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mrow><mtext>Δ</mtext><msub><mrow></mrow><mi>Ι</mi></msub></mrow></munder><mrow><mo>|</mo><mrow><mtext>Δ</mtext><msub><mrow></mrow><mi>Ι</mi></msub></mrow><mo>|</mo></mrow><msup><mrow></mrow><mn>2</mn></msup><mtext> </mtext><mtext>s</mtext><mo>.</mo><mtext>t</mtext><mo>.</mo><mspace width="0.25em" /><mi>Ν</mi><mi>e</mi><mi>t</mi><mo stretchy="false"> (</mo><mi>Ι</mi><mo>+</mo><mtext>Δ</mtext><msub><mrow></mrow><mi>Ι</mi></msub><mo stretchy="false">) </mo><mo>=</mo><mi>C</mi><msub><mrow></mrow><mi>d</mi></msub></mrow></math></mathml>      (2) </p>
                </div>
                <div class="p1">
                    <p id="63">式中:<i>I</i>是来自<i>C</i><sub><i>i</i></sub>类的原始输入, Δ<sub><i>I</i></sub>是对抗噪声, <i>Net</i>表示深度学习分类算法, <i>C</i><sub><i>d</i></sub>是对抗攻击的目标类别, 并且<i>C</i><sub><i>d</i></sub>≠<i>C</i><sub><i>i</i></sub>。一旦找到满足约束的对抗噪声Δ<i>I</i>, 即可构造出对抗样本<i>I</i>+Δ<i>I</i>。这种方法生成对抗样本的效率较低、资源消耗较多, 并且在某些类别上无法收敛。</p>
                </div>
                <div class="p1">
                    <p id="64">快速梯度标记法<citation id="151" type="reference"><link href="7" rel="bibliography" /><sup>[<a class="sup">3</a>]</sup></citation> (FGSM) 是一种能更快生成对抗样本的方法, 其计算对抗噪声公式如下:</p>
                </div>
                <div class="p1">
                    <p id="65">Δ<sub><i>I</i></sub>=<i>ε</i>·<i>sign</i> (ᐁ<sub><i>I</i></sub><i>J</i> (<i>W</i>, <i>I</i>, <i>C</i><sub><i>d</i></sub>) )      (3) </p>
                </div>
                <div class="p1">
                    <p id="66">式中:<i>J</i> (<i>W</i>, <i>I</i>, <i>C</i><sub><i>d</i></sub>) 是用来训练深度神经网络的代价函数, ᐁ<sub><i>I</i></sub><i>J</i> (<i>W</i>, <i>I</i>, <i>C</i><sub><i>d</i></sub>) 是代价函数对输入<i>I</i>的梯度, <i>W</i>是训练完毕的网络参数, <i>ε</i>是控制噪声强度的常量, <i>sign</i>是符号函数。快速梯度标记法通过计算目标类别对输入图像求梯度, 再对梯度求符号函数, 最后将求得的结果作为对抗噪声加到原始图像上获得对抗样本。这种方法的优点是速度快、生成的对抗样本可迁移性强, 而缺点是添加的噪声容易被去除, 如使用中值滤波等方法, 安全性不佳。</p>
                </div>
                <h4 class="anchor-tag" id="67" name="67"><b>2.2.2 对抗变换网络</b></h4>
                <div class="p1">
                    <p id="68">现有的对抗样本生成方法一般是针对样本自身做优化, 或者基于模型的梯度对样本添加扰动, Buluja&amp;Fischer<citation id="152" type="reference"><link href="11" rel="bibliography" /><sup>[<a class="sup">5</a>]</sup></citation>试图训练一个对抗变换网络 (ATN) 生成对抗样本, 使得生成的样本有较大概率被深度神经网络错分, 且添加的扰动最小。ATN可以实现指定预测类别的攻击和不指定预测类别的攻击。</p>
                </div>
                <div class="p1">
                    <p id="69">另外, 这种方法还可以使用神经网络将扰动建模为加性噪声, 此时网络的输出和输入的关系是:</p>
                </div>
                <div class="p1">
                    <p id="70"><i>I</i>′=tanh (<i>I</i>+<i>ATN</i> (<i>I</i>) )      (4) </p>
                </div>
                <div class="p1">
                    <p id="71">式中:<i>I</i>是输入的原始数据, <i>I</i>′是输出的对抗样本, tanh是反正切函数。</p>
                </div>
                <div class="p1">
                    <p id="72">ATN训练时需保证对抗样本的类别与目标类别一致, 且对抗样本与原始图像足够相似, 它的优化目标定义如下:</p>
                </div>
                <div class="p1">
                    <p id="73" class="code-formula">
                        <mathml id="73"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>arg</mi><mspace width="0.25em" /><mi>min</mi></mrow></mstyle><mi>θ</mi></munder><mi>β</mi><mi>L</mi><msub><mrow></mrow><mi>X</mi></msub><mo stretchy="false"> (</mo><mi>A</mi><mi>Τ</mi><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false">) </mo><mo>, </mo><mi>Ι</mi><mo stretchy="false">) </mo><mo>+</mo><mi>L</mi><msub><mrow></mrow><mi>Y</mi></msub><mo stretchy="false"> (</mo><mi>f</mi><mo stretchy="false"> (</mo><mi>A</mi><mi>Τ</mi><mi>Ν</mi><msub><mrow></mrow><mi>θ</mi></msub><mo stretchy="false"> (</mo><mi>Ι</mi><mo stretchy="false">) </mo><mo stretchy="false">) </mo><mo>, </mo><mi>r</mi><msub><mrow></mrow><mi>d</mi></msub><mo stretchy="false">) </mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mtext> </mtext><mrow><mtext> </mtext><mtext> </mtext><mtext> </mtext></mrow><mo stretchy="false"> (</mo><mn>5</mn><mo stretchy="false">) </mo></mrow></math></mathml>
                    </p>
                </div>
                <div class="p1">
                    <p id="74">式中:<i>f</i>是被攻击的模型 (输出为预测类别的概率分布) , <i>L</i><sub><i>X</i></sub>是对抗样本和原始图像的相似度量, <i>L</i><sub><i>Y</i></sub>是在指定对抗攻击目标类别<i>d</i>的前提下, 对抗样本的预测值与指定类别的差距度量, <i>r</i><sub><i>d</i></sub>是目标类别<i>d</i>的概率分布。这种方法的优点是推断速度快、攻击成功率高, 缺点是生成的对抗样本上残留有目标类别的典型模式, 如植物的纹理、动物的眼睛和皮毛等, 并且生成的对抗样本可迁移性较差。</p>
                </div>
                <h4 class="anchor-tag" id="75" name="75"><b>2.3 基于GAN的对抗样本生成方法</b></h4>
                <div class="p1">
                    <p id="76">ATN生成模型得到的对抗样本虽然能够骗过指定的机器学习模型, 但是生成的样本相对原图像的扰动较大, 且存在图像边缘模糊的问题。</p>
                </div>
                <div class="p1">
                    <p id="77">生成对抗网络GAN通过训练单独的判别器, 根据数据的分布来分辨真实样本和生成样本, 相对于L2损失函数, 它能更加有效地度量数据分布的差异。GAN生成的样本具有边缘锐利、更富有多样性的优点, 在半监督学习中得到了广泛的应用。但是GAN也存在训练不稳定, 生成的样本容易变形的问题。Zhu等<citation id="153" type="reference"><link href="23" rel="bibliography" /><sup>[<a class="sup">11</a>]</sup></citation>的研究表明, L2损失函数可以有效改善GAN训练过程中由于判别器的梯度不准确, 造成生成器生成的样本变形失真的问题。所以我们定义了3种约束函数 (对抗约束、像素级约束和类别约束) 保证GAN既能生成目标类别的对抗样本, 又不会发生明显的失真, 同时, 这3种约束仅使用了原始图像以及深度神经网络输出的样本所属的类别概率分布, 因此本方法可以在深度神经网络内部结构未知的前提下对其实行对抗攻击。</p>
                </div>
                <h4 class="anchor-tag" id="78" name="78"> (1) 对抗约束</h4>
                <div class="p1">
                    <p id="79">对抗样本生成的前提是对原始图像的扰动不能过大, 因此如何衡量对抗样本与原始图像的相似性, 成为一个至关重要的问题。我们利用生成对抗网络GAN中的判别器输出作为对抗样本与原始图像分布差异的测度, 并以此建立对抗约束保证生成器生成的对抗样本与原始图像的分布一致, 对抗约束的具体定义如下:</p>
                </div>
                <div class="p1">
                    <p id="80"><mathml id="81"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mtext>G</mtext></msub></mrow></munder><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>max</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mtext>D</mtext></msub></mrow></munder></mrow></math></mathml><image href="images/JYRJ201907035_082.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>GAN</sub>=<i>E</i><sub><i>x</i>～<i>p</i><sub><i>x</i></sub></sub>[log<i>D</i> (<i>x</i>) ]+</p>
                </div>
                <div class="p1">
                    <p id="83"><i>E</i><sub> (<i>z</i>, <i>x</i>) ～ (<i>p</i><sub><i>z</i></sub>, <i>p</i><sub><i>x</i></sub>) </sub>[log (1-<i>D</i> (<i>G</i> (<i>z</i>|<i>x</i>) ) ) ]      (6) </p>
                </div>
                <div class="p1">
                    <p id="84">式中:<i>θ</i><sub>G</sub>表示生成器G的网络参数, <i>θ</i><sub>D</sub>表示判别器D的网络参数, <i>p</i><sub><i>x</i></sub>和<i>p</i><sub><i>z</i></sub>分别表示原始图像<i>x</i>和随机噪声<i>z</i>的分布, <i>G</i> (<i>z</i>|<i>x</i>) 表示以原始图像<i>x</i>为条件, 生成器G通过随机噪声<i>z</i>生成的对抗样本。</p>
                </div>
                <div class="p1">
                    <p id="85">对抗约束是生成器和判别器之间零和博弈的体现:如图2所示, 对抗样本<i>G</i> (<i>z</i>|<i>x</i>) 由原始图像<i>x</i>经过生成器G的编码和解码后输出, 并与原始图像一起训练判别器D, 判别器D输出样本为真的概率, 我们以此作为代价, 反向传播更新生成器G的网络参数, 直到判别器D无法分辨真假, 停止更新, 就训练出了一个能生成逼真对抗样本的生成器G。</p>
                </div>
                <div class="area_img" id="86">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907035_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图2 基于GAN的对抗样本生成" src="Detail/GetImg?filename=images/JYRJ201907035_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图2 基于GAN的对抗样本生成  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907035_086.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="87" name="87"> (2) 像素级约束</h4>
                <div class="p1">
                    <p id="88">对抗约束使得对抗样本和真实图像在分布上一致, 但仅在生成器G和判别器D足够理想的情况下, 两者才能达到稳定的博弈, 为了保证训练过程中图像能保持基本的质量, 我们同时使用了像素级约束指导生成器G的训练:</p>
                </div>
                <div class="p1">
                    <p id="89"><mathml id="90"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mtext>G</mtext></msub></mrow></munder></mrow></math></mathml><image href="images/JYRJ201907035_091.jpg" type="" display="inline" placement="inline"><alt></alt></image><mathml id="92"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mrow></mrow><mtext>Ρ</mtext></msub><mo>=</mo><mi>E</mi><msub><mrow></mrow><mrow><mi>x</mi><mo>∼</mo><mi>p</mi><msub><mrow></mrow><mi>x</mi></msub></mrow></msub><mrow><mo>|</mo><mrow><mi>G</mi><mo stretchy="false"> (</mo><mi>z</mi><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">) </mo><mo>-</mo><mi>x</mi></mrow><mo>|</mo></mrow></mrow></math></mathml>      (7) </p>
                </div>
                <div class="p1">
                    <p id="93">我们不希望生成器G对像素级约束过于敏感, 因此我们使用L1范数表示生成的对抗样本和原始图像的像素级差异。</p>
                </div>
                <h4 class="anchor-tag" id="94" name="94"> (3) 类别约束</h4>
                <div class="p1">
                    <p id="95">对抗样本生成的另一要求是对抗样本的类别与目标类别一致。然而如果对抗样本在深度神经网络上的输出偏离原始图像的真实类别过大, 会造成对抗样本自身发生严重失真, 从而整个训练过程无法收敛。因此我们希望对抗样本在深度神经网络上的输出表现为:在目标类别上的概率最大, 而在真实类别上的概率次之。因此我们定义类别约束如下:</p>
                </div>
                <div class="p1">
                    <p id="96"><mathml id="97"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><munder><mstyle mathsize="140%" displaystyle="true"><mrow><mi>min</mi></mrow></mstyle><mrow><mi>θ</mi><msub><mrow></mrow><mtext>G</mtext></msub></mrow></munder></mrow></math></mathml><image href="images/JYRJ201907035_098.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>C</sub>=<i>E</i><sub><i>x</i>～<i>p</i><sub><i>x</i></sub></sub>[<i>CE</i> (<i>f</i> (<i>G</i> (<i>z</i>|<i>x</i>) ) , <i>h</i><sub><i>d</i></sub> (<i>f</i> (<i>x</i>) ) ) ]      (8) </p>
                </div>
                <div class="p1">
                    <p id="99">式中:<i>CE</i>是交叉熵函数, <i>f</i>是待攻击的深度神经网络, 它的输出是样本的类别概率向量, <i>h</i><sub><i>d</i></sub>是对原始图像和指定类别<i>d</i>的类别概率向量的重排序函数, 我们将在2.4节详细介绍。</p>
                </div>
                <div class="p1">
                    <p id="100">综合上述3种约束, 我们可以得到生成对抗网络中判别器D和生成器G的损失函数:</p>
                </div>
                <div class="p1">
                    <p id="101"><image href="images/JYRJ201907035_102.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>D</sub>=-<i>E</i><sub><i>x</i>～<i>p</i><sub><i>x</i></sub></sub>[log<i>D</i> (<i>x</i>) ]-</p>
                </div>
                <div class="p1">
                    <p id="103"><i>E</i><sub> (<i>z</i>, <i>x</i>) ～ (<i>p</i><sub><i>z</i></sub>, <i>p</i><sub><i>x</i></sub>) </sub>[log (1-<i>D</i> (<i>G</i> (<i>z</i>|<i>x</i>) ) ) ]      (9) </p>
                </div>
                <div class="p1">
                    <p id="104"><image href="images/JYRJ201907035_105.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>G</sub>=<i>α</i><image href="images/JYRJ201907035_106.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>GAN</sub>+<i>β</i><image href="images/JYRJ201907035_107.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>P</sub>+<i>γ</i><image href="images/JYRJ201907035_108.jpg" type="" display="inline" placement="inline"><alt></alt></image><sub>C</sub>      (10) </p>
                </div>
                <div class="p1">
                    <p id="109">式中:<i>α</i>、<i>β</i>、<i>γ</i>为平衡3种约束的参数, 且<i>α</i>+<i>β</i>+<i>γ</i>=1。</p>
                </div>
                <div class="p1">
                    <p id="110">判别器D和生成器G均采用深度神经网络模型, 为了保证梯度更新的稳定性, 我们使用了DCGAN中的判别器网络设计方法, 移除了所有的池化层, 并使用Leaky ReLU作为激活函数。生成器G采用编码器-解码器的结构, 为了降低棋盘格效应, 我们的上采样部分使用了Pixelshuffle<citation id="154" type="reference"><link href="27" rel="bibliography" /><sup>[<a class="sup">13</a>]</sup></citation>技术, 并且将Batch Normalization<citation id="155" type="reference"><link href="29" rel="bibliography" /><sup>[<a class="sup">14</a>]</sup></citation>归一化方法替换为Instance Normalization<citation id="156" type="reference"><link href="31" rel="bibliography" /><sup>[<a class="sup">15</a>]</sup></citation>, 明显改善了生成器G输出的对抗样本的图像质量。</p>
                </div>
                <div class="p1">
                    <p id="111">生成对抗网络的训练采用判别器D和生成器G交替训练的方式进行。如图3所示, 我们将一批原始图像分为两部分, 一部分用来更新判别器D, 另一部分输入生成器G得到生成的对抗样本, 再利用这一部分对抗样本更新判别器D和生成器G, 重复上述过程直到完成指定次数的训练。</p>
                </div>
                <div class="area_img" id="112">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907035_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图3 训练流程图" src="Detail/GetImg?filename=images/JYRJ201907035_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图3 训练流程图  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907035_112.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="113" name="113"><b>2.4 类别概率向量重排序函数</b></h4>
                <div class="p1">
                    <p id="114">对抗样本生成要求输出样本为指定类别, 且对原始图像的扰动不宜过大。然而同真实类别差异较大的指定类别会对样本的生成造成很大困难, 因此本节我们提出类别概率向量重排序函数。假设深度神经网络预测的类别共有<i>N</i>类, 原始图像<i>x</i>的类别概率向量为<b><i>V</i></b><sub><i>x</i></sub>= (<i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, …, <i>c</i><sub><i>N</i></sub>) , <i>c</i><sub>1</sub>&gt;<i>c</i><sub>2</sub>&gt;…&gt;<i>c</i><sub><i>N</i></sub>且<i>c</i><sub>1</sub>+<i>c</i><sub>2</sub>+…+<i>c</i><sub><i>N</i></sub>=1, 其中<i>c</i><sub>1</sub>为原始图像<i>x</i>的真实类别的概率。显然, 指定类别<i>d</i>的概率<i>c</i><sub><i>d</i></sub>∈{<i>c</i><sub>2</sub>, <i>c</i><sub>3, </sub>…, <i>c</i><sub><i>N</i></sub>} (不考虑指定类别<i>d</i>与真实类别相同的情况) 。对于原始图像<i>x</i>和指定类别<i>d</i>的类别概率向量重排序函数<i>h</i>, 我们定义如下:</p>
                </div>
                <div class="p1">
                    <p id="115"><i>h</i><sub><i>d</i></sub> (<b><i>V</i></b><sub><i>x</i></sub>) =<i>softmax</i> (<b><i>V</i></b><sub><i>d</i></sub>)      (11) </p>
                </div>
                <div class="p1">
                    <p id="116">式中:<b><i>V</i></b><sub><i>d</i></sub>= (<i>c</i><sub><i>d</i></sub>, <i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, …, <i>c</i><sub><i>N</i></sub>) , <i>c</i><sub><i>d</i></sub>=1, 经过<i>softmax</i>函数的放大, 我们最大程度上保留了原有的概率分布<b><i>V</i></b><sub><i>x</i></sub>, 并且指定类别<i>d</i>的概率值最大。使用类别概率向量重排序算法可以有效加快生成对抗网络训练过程的收敛, 提高攻击的成功率。</p>
                </div>
                <h3 id="117" name="117" class="anchor-tag"><b>3 实验结果及分析</b></h3>
                <h4 class="anchor-tag" id="118" name="118"><b>3.1 实验环境和数据集</b></h4>
                <div class="p1">
                    <p id="119">实验平台为PyTorch深度学习平台<citation id="157" type="reference"><link href="33" rel="bibliography" /><sup>[<a class="sup">16</a>]</sup></citation>, 工作站为NVIDIA GeForce GTX 980 Ti单卡的环境。为验证本文提出的模型在生成对抗样本问题上的可行性, 我们使用ILSVRC 2012<citation id="158" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>作为训练集, 测试集为NIPS 2017 Competition on Adversarial Attacks and Defenses提供的1 000张图片, 分别对应ImageNet<citation id="159" type="reference"><link href="37" rel="bibliography" /><sup>[<a class="sup">18</a>]</sup></citation>的1 000个类别。训练集每个类型包含500张图片, 一共1 000个类别, 测试集每个类别一张图片, 共1 000张图片。</p>
                </div>
                <h4 class="anchor-tag" id="120" name="120"><b>3.2 针对不同目标类别的定向攻击实验结果</b></h4>
                <div class="p1">
                    <p id="121">我们针对ImageNet的1 000个类别, 使用迭代FGSM、ATN和GAN方法分别做定向对抗攻击。我们将Inception-ResNet-v2深度网络模型作为待攻击模型, 输入图像的大小均为299×299, 并且要求对抗攻击方法对样本的扰动不超过5%。三种攻击方法在1 000类上的攻击成功率如图4所示, GAN方法生成的对抗样本在目标模型上的攻击成功率明显高于迭代FGSM和ATN, 并且GAN方法在大部分类别上的表现都很稳定。</p>
                </div>
                <div class="area_img" id="122">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907035_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图4 对抗攻击在所有目标类别的成功率" src="Detail/GetImg?filename=images/JYRJ201907035_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图4 对抗攻击在所有目标类别的成功率  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907035_122.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <div class="p1">
                    <p id="123">图5是针对若干不同目标类别 (tabby cat, espresso, whistle, sock) 生成对抗样本的攻击成功率示例, 即对三种攻击方法 (ATN, GAN, 迭代FGSM) , 分别指定所生成的对抗样本为固定类别。待训练完成, 用Inception-ResNet-v2模型对三种方法生成的对抗样本进行分类, 得到攻击成功率, 本文的GAN方法相较于ATN和FGSM方法在每种类别都有提高。</p>
                </div>
                <div class="area_img" id="124">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907035_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图5 不同目标类别的样本实验" src="Detail/GetImg?filename=images/JYRJ201907035_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图5 不同目标类别的样本实验  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907035_124.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h4 class="anchor-tag" id="125" name="125"><b>3.3 不同方法比较实验结果与分析</b></h4>
                <div class="p1">
                    <p id="126">对于ATN网络和FGSM进行复现, 并在同一数据集中对ATN模型和本文提出的模型进行训练和测试, 对比实验结果。针对Inception-ResNet-v2模型进行指定预测类别 (Tabby Cat, 281) 的白盒攻击。</p>
                </div>
                <div class="p1">
                    <p id="127">ATN模型、加入GAN的新模型和FGSM方法在此数据集上的结果比较, 指定目标类 (TabbyCat, 281) , 针对同一网络Inception-ResNet-v2进行攻击得到成功率和生成时间统计如表1所示。</p>
                </div>
                <div class="area_img" id="128">
                    <p class="img_tit"><b>表1 对抗攻击的成功率和生成时间</b> <a class="downexcel" onclick="DownLoadReportExcel(this)">导出到EXCEL</a></p>
                    <p class="img_tit"></p>
                    <p class="img_note"></p>
                    <table id="128" border="1"><tr><td>模型</td><td>生成图像的攻击<br />成功率/%</td><td>真实图像识别<br />成功率/%</td><td>平均生成<br />时间/s</td></tr><tr><td><br />ATN</td><td>78.8</td><td rowspan="3">80.4</td><td><br />0.99</td></tr><tr><td><br />GAN</td><td><b>80.0</b></td><td><br /><b>0.79</b></td></tr><tr><td><br />FGSM</td><td>70.2</td><td><br />17.10</td></tr><tr><td colspan="4"><br /></td></tr></table>
                    <form name="form" action="/kxreader/Detail/DownloadReportExcel" method="POST" style="display:inline">
                        <input type="hidden" name="hidTable" value="" />
                        <input type="hidden" name="hidFileName" value="" />
                    </form>
                    <p class="img_note"></p>
                    <p class="img_note"></p>
                </div>
                <div class="p1">
                    <p id="129">平均成功率取自多次试验的平均值, 针对同一数据和同一深度网络模型, 设置相同的目标类, 即虎斑猫 (Tabby Cat, 281) , TOP1的统计结果如表1所示。生成图像的攻击成功率指的是指定网络结构被错误分类的比率, 即用生成的图像去攻击指定深度网络模型得到的成功比例。从表1中可以得到, GAN生成图像的成功率相比于ATN生成图片的成功率提高了1.5%, 相比于FGSM方法生成图片的成功率提高了14%, 说明本文提出的新型方法相较之前的方法在欺骗指定机器学习网络的任务中有着更好的效果, 优化了原有模型使得攻击指定分类器的成功率得到提高。同时, 在平均生成时间上, GAN相比于ATN提升了0.2 s的时间, 在图像质量相同条件下, 所需时间更短。</p>
                </div>
                <div class="p1">
                    <p id="130">生成的图像比较如图6所示, 分别是ATN生成图像与原图比较, GAN生成图像和原图比较的结果, 在实验中设置了扰动误差最大值, 最大可接受扰动误差为5%, 即当输入为<i>x</i>, 输出为<i>y</i>且<i>x</i> (1-5%) &lt;<i>y</i>&lt;<i>x</i> (1+5%) 。如果经过生成器, 输出值超过5%, 那么就将其从上限处截断。由实验结果可知ATN生成的图像中存在目标类中的类似猫眼的图像痕迹, 而GAN相较于ATN的图像, 消除了图片目标类的原始条纹积累, 使得生成的图像和原始图像更加贴近, 图片质量更优。</p>
                </div>
                <div class="area_img" id="131">
                                <a class="zoom-in" href="Detail/GetImg?filename=images/JYRJ201907035_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">
                                    <img alt="图6 生成图像比较" src="Detail/GetImg?filename=images/JYRJ201907035_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
                                </a>
                                <p class="img_tit">图6 生成图像比较  <a class="btn-zoomin" href="Detail/GetImg?filename=images/JYRJ201907035_13100.jpg&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!"></a><a class="downimg">&nbsp;&nbsp;下载原图</a></p>
                            <p class="img_tit"></p>

                </div>
                <h3 id="132" name="132" class="anchor-tag"><b>4 结 语</b></h3>
                <div class="p1">
                    <p id="133">目前生成对抗样本的方法往往依赖目标深度网络模型的梯度, 需要已知网络的结构并且生成的样本可以使用去噪算法防御。本文提出了一种在深度网络模型的结构未知的前提下进行有效攻击的对抗样本生成方法, 并通过生成对抗网络 (GAN) 和概率向量重排序函数实现了一种新型网络模型的构建。实验结果表明本文的模型可以提高攻击深度网络的成功率, 同时提高生成图像的质量。另外, 将模型生成的对抗样本迁移到其他深度网络是一个研究难点, 现有对抗攻击方法生成的对抗样本往往只针对部分深度网络设计, 同时如何利用GAN生成的对抗样本进行对抗训练也是下一步要继续研究的方向。</p>
                </div>

        <!--brief end-->
        
        <!--conten left  end-->
        <!--增强附件-->
        

        <!--reference start-->
            <div class="reference anchor-tag" id="a_bibliography">
                    <h3>参考文献</h3>
                                        <p id="3">
                            <a id="bibliography_1" >
                                    <b>[1]</b>
                                 Lecun Y, Bengio Y, Hinton G.Deep learning[J].Nature, 2015, 521 (7553) :436.
                            </a>
                        </p>
                        <p id="5">
                            <a id="bibliography_2" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Intriguing properties of neural networks">

                                <b>[2]</b> Szegedy C, Zaremba W, Sutskever I, et al.Intriguing properties of neural networks[EB/OL].[2013-12-21].https://arxiv.org/abs/1312.6199v4.
                            </a>
                        </p>
                        <p id="7">
                            <a id="bibliography_3" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Explaining and Harnessing Adversarial Examples">

                                <b>[3]</b> Goodfellow I, Shlens J, Szegedy C.Explaining and Harnessing Adversarial Examples[EB/OL].[2014-12-20].https://arxiv.org/abs/1412.6572.
                            </a>
                        </p>
                        <p id="9">
                            <a id="bibliography_4" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adversarial Machine Learning at Scale[EB]">

                                <b>[4]</b> Kurakin A, Goodfellow I, Bengio S.Adversarial Machine Learning at Scale[EB].arXiv:1611.01236, 2016.
                            </a>
                        </p>
                        <p id="11">
                            <a id="bibliography_5" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Distillation as a defense to adversarial perturbations against deep neural networks">

                                <b>[5]</b> Papernot N, McDaniel P, Wu X, et al.Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks[C]//2016 IEEE Symposium on Security and Privacy (SP) .IEEE, 2015.
                            </a>
                        </p>
                        <p id="13">
                            <a id="bibliography_6" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Adversarial Transformation Networks:Learning to Generate Adversarial Examples[EB]">

                                <b>[6]</b> Baluja S, Fischer I.Adversarial Transformation Networks:Learning to Generate Adversarial Examples[EB].arXiv:1703.09387, 2017.
                            </a>
                        </p>
                        <p id="15">
                            <a id="bibliography_7" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Generative Adversarial Networks[EB]">

                                <b>[7]</b> Goodfellow I, Pouget-Abadie J, Mirza M, et al.Generative Adversarial Networks[EB].arXiv:1406.2661, 2014
                            </a>
                        </p>
                        <p id="17">
                            <a id="bibliography_8" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=MOTO201703001&amp;v=MTc0MTBiTXJJOUZaWVFLREg4NHZSNFQ2ajU0TzN6cXFCdEdGckNVUjdxZlp1WnRGeWpoVXIzTEtDTGZZYkc0SDk=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[8]</b> 王坤峰, 苟超, 段艳杰, 等.生成式对抗网络GAN的研究进展与展望[J].自动化学报, 2017, 43 (3) :321-332.
                            </a>
                        </p>
                        <p id="19">
                            <a id="bibliography_9" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Learning What and Where to Draw[EB]">

                                <b>[9]</b> Reed S, Akata Z, Mohan S, et al.Learning What and Where to Draw[EB].arXiv:1610.02454, 2016.
                            </a>
                        </p>
                        <p id="21">
                            <a id="bibliography_10" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Image-to-Image Translation with Conditional Adversarial Networks[EB]">

                                <b>[10]</b> Isola P, Zhu J Y, Zhou T, et al.Image-to-Image Translation with Conditional Adversarial Networks[EB].arXiv:1611.07004, 2016.
                            </a>
                        </p>
                        <p id="23">
                            <a id="bibliography_11" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unpaired image-to-image translation using cycle-consistent adversarial networks">

                                <b>[11]</b> Zhu J Y, Park T, Isola P, et al.Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks[C]//2017 IEEE International Conference on Computer Vision (ICCV) .IEEE, 2017:2242-2251.
                            </a>
                        </p>
                        <p id="25">
                            <a id="bibliography_12" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[EB]">

                                <b>[12]</b> Radford A, Metz L, Chintala S.Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[EB].arXiv:1511.06434, 2015.
                            </a>
                        </p>
                        <p id="27">
                            <a id="bibliography_13" target="_blank" href="http://scholar.cnki.net/result.aspx?q=&amp;quot;Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network.&amp;quot;">

                                <b>[13]</b> Shi W, Caballero J, Huszar F, et al.Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network[C]//Computer Vision and Pattern Recognition.IEEE, 2016:1874-1883.
                            </a>
                        </p>
                        <p id="29">
                            <a id="bibliography_14" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Batch normalization:Accelerating deep network training by reducing internal covariate shift">

                                <b>[14]</b> Ioffe S, Szegedy C.Batch normalization:accelerating deep network training by reducing internal covariate shift[C]//International Conference on International Conference on Machine Learning.JMLR.org, 2015:448-456.
                            </a>
                        </p>
                        <p id="31">
                            <a id="bibliography_15" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Instance Normalization:The Missing Ingredient for Fast Stylization[EB]">

                                <b>[15]</b> Ulyanov D, Vedaldi A, Lempitsky V.Instance Normalization:The Missing Ingredient for Fast Stylization[EB].arXiv:1607.08022, 2016.
                            </a>
                        </p>
                        <p id="33">
                            <a id="bibliography_16" target="_blank" href="/kcms/detail/detail.aspx?dbcode=CBBD&amp;filename=9787121326202000&amp;v=MDYzNTk4enhVU21EZDlTSDduM3hFOWZidm5LcmlmWmVadkZ5bm1VNy9NSVZ3WFhGcXpHYks2SDlMT3FZMUZadXNQREJN&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">

                                <b>[16]</b> 廖星宇.深度学习入门之PyTorch[M].北京:电子工业出版社, 2017.
                            </a>
                        </p>
                        <p id="35">
                            <a id="bibliography_17" target="_blank" href="http://scholar.cnki.net/result.aspx?q=ImageNet classification with deep convolutional neural networks">

                                <b>[17]</b> Krizhevsky A, Sutskever I, Hinton G E.ImageNet classification with deep convolutional neural networks[C]//International Conference on Neural Information Processing Systems.Curran Associates Inc.2012:1097-1105.
                            </a>
                        </p>
                        <p id="37">
                            <a id="bibliography_18" target="_blank" href="http://scholar.cnki.net/result.aspx?q=Imagenet large scale visual recognition challenge">

                                <b>[18]</b> Russakovsky O, Deng J, Su H.et al.ImageNet Large Scale Visual Recognition Challenge[J].International Journal of Computer Vision, 2014, 115 (3) :211-252.
                            </a>
                        </p>
            </div>
        <!--reference end-->
        <!--footnote start-->
        <!--footnote end-->



    </div>

        <input id="fileid" type="hidden" value="JYRJ201907035" />
        <input id="dpi" type="hidden" value="600" />
    </div>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6e967eb120601ea41b9d312166416aa6";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    


<input id="hid_uid" name="hid_uid" type="hidden" value="WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!" />
<input id="hid_kLogin_headerUrl" name="hid_kLogin_headerUrl" type="hidden" value="/KLogin/Request/GetKHeader.ashx%3Fcallback%3D%3F" />
<input id="hid_kLogin_footerUrl" name="hid_kLogin_footerUrl" type="hidden" value="/KLogin/Request/GetKFooter.ashx%3Fcallback%3D%3F" />
<div class="btn-link" style="display: none"><a target="_blank" href="/kcms/detail/detail.aspx?dbcode=CJFD&amp;filename=JYRJ201907035&amp;v=MzI1OTFNcUk5R1lZUUtESDg0dlI0VDZqNTRPM3pxcUJ0R0ZyQ1VSN3FmWnVadEZ5amhVcjNMTHpUWlpMRzRIOWo=&amp;uid=WEEvREcwSlJHSldRa1FhdkJtNEYxa3hKZG9XL1JrZXNhdGVWVEdvM0tSMD0=$9A4hF_YAuvQ5obgVAqNKPCYcEjKensW4IQMovwHtwkF4VYPoHbKxJw!!">知网节</a></div>
<div class="popflow" id="popupTips" style="display: none;">
    <div class="popflowArr"></div>
    <div class="popflowCot">
        <div class="hd"><a href="javascript:void(0);" onclick="$('#popupTips').hide();$('#popupmsg').html('')" class="close">X</a></div>
        <div class="bd">
            <p class="mes" id="popupmsg" name="popupmsg"></p>
          
        </div>
    </div>
</div>
<input type="hidden" id="myexport" value="//kns.cnki.net" />

<input type="hidden" id="KPCAPIPATH" value="//ishufang.cnki.net" />
<input type="hidden" id="CitedTimes" value="" />
<div class="link" id="GLSearch" style="display: none;">
    <i class="icon-trangle"></i>
    <div class="inner">
        <a class="icon" id="copytext">复制</a>
        <a class="icon" target="_blank" onclick="searchCRFD(this)">工具书搜索</a>
    </div>
</div>




<input id="hidVirtualPath" name="hidVirtualPath" type="hidden" value="/kxreader" />
<script src="/kxreader/bundles/detail?v=-ULdk-c6FkZHtJA2KAXPgHnyA8mtgyPnBde_C2VZ2BY1"></script>

<script src="/kxreader/Scripts/layer.min.js" type="text/javascript"></script>

<div id="footerBox" class="rootw footer">
</div>
<script>
    if (typeof FlushLogin == 'function') {
        FlushLogin();
    }
    modifyEcpHeader(true);
</script>

<!--图片放大功能 start-->
<script src="/kxreader/bundles/imagebox?v=W4phPu9SNkGcuPeJclikuVE3PpRyIW_gnfjm_19nynI1"></script>

<script type="text/javascript">
    $(function () {
        var j = $.noConflict();
        j(function () {
            j(".zoom-in,.btn-zoomin").imgbox({
                'alignment': 'center',
                'allowMultiple': false,
                'overlayShow': true
            });
        })
    });
</script>
<!--图片放大功能 end-->
<div class="fixedbar">
    <div class="backtop hiddenV" id="backtop">
        <a id="backTopSide" href="javascript:scroll(0,0);" title=""></a>
    </div>
</div>
<script type="text/javascript" src="/kxreader/Scripts/MathJax-2.6-latest/MathJax.js?config=MML_HTMLorMML-full"></script>

</body>
</html>
